Log file created at: 2016/07/11 14:16:35
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0711 14:16:35.164750 126720 caffe.cpp:184] Using GPUs 2
I0711 14:16:35.977082 126720 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 250
base_lr: 0.001
display: 100
max_iter: 500000
lr_policy: "fixed"
gamma: 0.1
momentum: 0.9
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/cnn10"
solver_mode: GPU
device_id: 2
net: "train_val.prototxt.full"
test_initialization: false
average_loss: 50
I0711 14:16:35.977430 126720 solver.cpp:90] Creating training net from net file: train_val.prototxt.full
I0711 14:16:35.988498 126720 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0711 14:16:35.988798 126720 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0711 14:16:35.988997 126720 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0711 14:16:35.989495 126720 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-train-L0.lst"
    batch_size: 128
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0711 14:16:35.992151 126720 layer_factory.hpp:76] Creating layer data
I0711 14:16:35.992234 126720 net.cpp:106] Creating Layer data
I0711 14:16:35.992259 126720 net.cpp:411] data -> data
I0711 14:16:35.992298 126720 net.cpp:411] data -> label
I0711 14:16:35.993008 126720 image_data_layer.cpp:36] Opening file ../lists/roi-train-L0.lst
I0711 14:16:36.128535 126720 image_data_layer.cpp:46] Shuffling data
I0711 14:16:36.159615 126720 image_data_layer.cpp:51] A total of 180262 images.
I0711 14:16:36.191612 126720 image_data_layer.cpp:78] output data size: 128,3,100,100
I0711 14:16:36.228337 126720 net.cpp:150] Setting up data
I0711 14:16:36.228500 126720 net.cpp:157] Top shape: 128 3 100 100 (3840000)
I0711 14:16:36.228544 126720 net.cpp:157] Top shape: 128 (128)
I0711 14:16:36.228550 126720 net.cpp:165] Memory required for data: 15360512
I0711 14:16:36.228564 126720 layer_factory.hpp:76] Creating layer label_data_1_split
I0711 14:16:36.228590 126720 net.cpp:106] Creating Layer label_data_1_split
I0711 14:16:36.228598 126720 net.cpp:454] label_data_1_split <- label
I0711 14:16:36.228617 126720 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0711 14:16:36.228631 126720 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0711 14:16:36.228689 126720 net.cpp:150] Setting up label_data_1_split
I0711 14:16:36.228696 126720 net.cpp:157] Top shape: 128 (128)
I0711 14:16:36.228701 126720 net.cpp:157] Top shape: 128 (128)
I0711 14:16:36.228706 126720 net.cpp:165] Memory required for data: 15361536
I0711 14:16:36.228711 126720 layer_factory.hpp:76] Creating layer conv11
I0711 14:16:36.228730 126720 net.cpp:106] Creating Layer conv11
I0711 14:16:36.228735 126720 net.cpp:454] conv11 <- data
I0711 14:16:36.228744 126720 net.cpp:411] conv11 -> conv11
I0711 14:16:36.365442 126720 net.cpp:150] Setting up conv11
I0711 14:16:36.365500 126720 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0711 14:16:36.365511 126720 net.cpp:165] Memory required for data: 179201536
I0711 14:16:36.365541 126720 layer_factory.hpp:76] Creating layer relu11
I0711 14:16:36.365562 126720 net.cpp:106] Creating Layer relu11
I0711 14:16:36.365574 126720 net.cpp:454] relu11 <- conv11
I0711 14:16:36.365589 126720 net.cpp:397] relu11 -> conv11 (in-place)
I0711 14:16:36.365784 126720 net.cpp:150] Setting up relu11
I0711 14:16:36.365803 126720 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0711 14:16:36.365810 126720 net.cpp:165] Memory required for data: 343041536
I0711 14:16:36.365819 126720 layer_factory.hpp:76] Creating layer conv12
I0711 14:16:36.365839 126720 net.cpp:106] Creating Layer conv12
I0711 14:16:36.365847 126720 net.cpp:454] conv12 <- conv11
I0711 14:16:36.365860 126720 net.cpp:411] conv12 -> conv12
I0711 14:16:36.368490 126720 net.cpp:150] Setting up conv12
I0711 14:16:36.368517 126720 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0711 14:16:36.368527 126720 net.cpp:165] Memory required for data: 506881536
I0711 14:16:36.368543 126720 layer_factory.hpp:76] Creating layer relu12
I0711 14:16:36.368559 126720 net.cpp:106] Creating Layer relu12
I0711 14:16:36.368569 126720 net.cpp:454] relu12 <- conv12
I0711 14:16:36.368580 126720 net.cpp:397] relu12 -> conv12 (in-place)
I0711 14:16:36.370173 126720 net.cpp:150] Setting up relu12
I0711 14:16:36.370194 126720 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0711 14:16:36.370203 126720 net.cpp:165] Memory required for data: 670721536
I0711 14:16:36.370213 126720 layer_factory.hpp:76] Creating layer pool1
I0711 14:16:36.370229 126720 net.cpp:106] Creating Layer pool1
I0711 14:16:36.370237 126720 net.cpp:454] pool1 <- conv12
I0711 14:16:36.370250 126720 net.cpp:411] pool1 -> pool1
I0711 14:16:36.371024 126720 net.cpp:150] Setting up pool1
I0711 14:16:36.371042 126720 net.cpp:157] Top shape: 128 32 50 50 (10240000)
I0711 14:16:36.371052 126720 net.cpp:165] Memory required for data: 711681536
I0711 14:16:36.371060 126720 layer_factory.hpp:76] Creating layer conv21
I0711 14:16:36.371089 126720 net.cpp:106] Creating Layer conv21
I0711 14:16:36.371098 126720 net.cpp:454] conv21 <- pool1
I0711 14:16:36.371111 126720 net.cpp:411] conv21 -> conv21
I0711 14:16:36.374048 126720 net.cpp:150] Setting up conv21
I0711 14:16:36.374081 126720 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0711 14:16:36.374091 126720 net.cpp:165] Memory required for data: 793601536
I0711 14:16:36.374110 126720 layer_factory.hpp:76] Creating layer relu21
I0711 14:16:36.374127 126720 net.cpp:106] Creating Layer relu21
I0711 14:16:36.374138 126720 net.cpp:454] relu21 <- conv21
I0711 14:16:36.374150 126720 net.cpp:397] relu21 -> conv21 (in-place)
I0711 14:16:36.374471 126720 net.cpp:150] Setting up relu21
I0711 14:16:36.374523 126720 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0711 14:16:36.374532 126720 net.cpp:165] Memory required for data: 875521536
I0711 14:16:36.374541 126720 layer_factory.hpp:76] Creating layer conv22
I0711 14:16:36.374559 126720 net.cpp:106] Creating Layer conv22
I0711 14:16:36.374572 126720 net.cpp:454] conv22 <- conv21
I0711 14:16:36.374583 126720 net.cpp:411] conv22 -> conv22
I0711 14:16:36.376682 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0711 14:16:36.377077 126720 net.cpp:150] Setting up conv22
I0711 14:16:36.377099 126720 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0711 14:16:36.377109 126720 net.cpp:165] Memory required for data: 957441536
I0711 14:16:36.377121 126720 layer_factory.hpp:76] Creating layer relu22
I0711 14:16:36.377135 126720 net.cpp:106] Creating Layer relu22
I0711 14:16:36.377143 126720 net.cpp:454] relu22 <- conv22
I0711 14:16:36.377153 126720 net.cpp:397] relu22 -> conv22 (in-place)
I0711 14:16:36.377614 126720 net.cpp:150] Setting up relu22
I0711 14:16:36.377641 126720 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0711 14:16:36.377650 126720 net.cpp:165] Memory required for data: 1039361536
I0711 14:16:36.377661 126720 layer_factory.hpp:76] Creating layer pool2
I0711 14:16:36.377674 126720 net.cpp:106] Creating Layer pool2
I0711 14:16:36.377682 126720 net.cpp:454] pool2 <- conv22
I0711 14:16:36.377693 126720 net.cpp:411] pool2 -> pool2
I0711 14:16:36.377897 126720 net.cpp:150] Setting up pool2
I0711 14:16:36.377914 126720 net.cpp:157] Top shape: 128 64 25 25 (5120000)
I0711 14:16:36.377923 126720 net.cpp:165] Memory required for data: 1059841536
I0711 14:16:36.377931 126720 layer_factory.hpp:76] Creating layer conv31
I0711 14:16:36.377948 126720 net.cpp:106] Creating Layer conv31
I0711 14:16:36.377956 126720 net.cpp:454] conv31 <- pool2
I0711 14:16:36.377969 126720 net.cpp:411] conv31 -> conv31
I0711 14:16:36.379626 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0711 14:16:36.379663 126720 net.cpp:150] Setting up conv31
I0711 14:16:36.379679 126720 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0711 14:16:36.379688 126720 net.cpp:165] Memory required for data: 1090561536
I0711 14:16:36.379703 126720 layer_factory.hpp:76] Creating layer relu31
I0711 14:16:36.379719 126720 net.cpp:106] Creating Layer relu31
I0711 14:16:36.379731 126720 net.cpp:454] relu31 <- conv31
I0711 14:16:36.379746 126720 net.cpp:397] relu31 -> conv31 (in-place)
I0711 14:16:36.380081 126720 net.cpp:150] Setting up relu31
I0711 14:16:36.380102 126720 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0711 14:16:36.380111 126720 net.cpp:165] Memory required for data: 1121281536
I0711 14:16:36.380120 126720 layer_factory.hpp:76] Creating layer conv32
I0711 14:16:36.380138 126720 net.cpp:106] Creating Layer conv32
I0711 14:16:36.380147 126720 net.cpp:454] conv32 <- conv31
I0711 14:16:36.380158 126720 net.cpp:411] conv32 -> conv32
I0711 14:16:36.382525 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0711 14:16:36.382566 126720 net.cpp:150] Setting up conv32
I0711 14:16:36.382582 126720 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0711 14:16:36.382596 126720 net.cpp:165] Memory required for data: 1152001536
I0711 14:16:36.382607 126720 layer_factory.hpp:76] Creating layer relu32
I0711 14:16:36.382623 126720 net.cpp:106] Creating Layer relu32
I0711 14:16:36.382650 126720 net.cpp:454] relu32 <- conv32
I0711 14:16:36.382670 126720 net.cpp:397] relu32 -> conv32 (in-place)
I0711 14:16:36.382848 126720 net.cpp:150] Setting up relu32
I0711 14:16:36.382865 126720 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0711 14:16:36.382874 126720 net.cpp:165] Memory required for data: 1182721536
I0711 14:16:36.382884 126720 layer_factory.hpp:76] Creating layer pool3
I0711 14:16:36.382899 126720 net.cpp:106] Creating Layer pool3
I0711 14:16:36.382906 126720 net.cpp:454] pool3 <- conv32
I0711 14:16:36.382920 126720 net.cpp:411] pool3 -> pool3
I0711 14:16:36.383457 126720 net.cpp:150] Setting up pool3
I0711 14:16:36.383482 126720 net.cpp:157] Top shape: 128 96 13 13 (2076672)
I0711 14:16:36.383527 126720 net.cpp:165] Memory required for data: 1191028224
I0711 14:16:36.383536 126720 layer_factory.hpp:76] Creating layer conv41
I0711 14:16:36.383554 126720 net.cpp:106] Creating Layer conv41
I0711 14:16:36.383565 126720 net.cpp:454] conv41 <- pool3
I0711 14:16:36.383577 126720 net.cpp:411] conv41 -> conv41
I0711 14:16:36.388180 126720 net.cpp:150] Setting up conv41
I0711 14:16:36.388211 126720 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0711 14:16:36.388221 126720 net.cpp:165] Memory required for data: 1202103808
I0711 14:16:36.388237 126720 layer_factory.hpp:76] Creating layer relu41
I0711 14:16:36.388250 126720 net.cpp:106] Creating Layer relu41
I0711 14:16:36.388260 126720 net.cpp:454] relu41 <- conv41
I0711 14:16:36.388272 126720 net.cpp:397] relu41 -> conv41 (in-place)
I0711 14:16:36.388926 126720 net.cpp:150] Setting up relu41
I0711 14:16:36.388947 126720 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0711 14:16:36.388954 126720 net.cpp:165] Memory required for data: 1213179392
I0711 14:16:36.388963 126720 layer_factory.hpp:76] Creating layer conv42
I0711 14:16:36.388981 126720 net.cpp:106] Creating Layer conv42
I0711 14:16:36.388990 126720 net.cpp:454] conv42 <- conv41
I0711 14:16:36.389003 126720 net.cpp:411] conv42 -> conv42
I0711 14:16:36.391875 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0711 14:16:36.391922 126720 net.cpp:150] Setting up conv42
I0711 14:16:36.391937 126720 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0711 14:16:36.391945 126720 net.cpp:165] Memory required for data: 1224254976
I0711 14:16:36.391959 126720 layer_factory.hpp:76] Creating layer relu42
I0711 14:16:36.391983 126720 net.cpp:106] Creating Layer relu42
I0711 14:16:36.391993 126720 net.cpp:454] relu42 <- conv42
I0711 14:16:36.392005 126720 net.cpp:397] relu42 -> conv42 (in-place)
I0711 14:16:36.393493 126720 net.cpp:150] Setting up relu42
I0711 14:16:36.393510 126720 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0711 14:16:36.393519 126720 net.cpp:165] Memory required for data: 1235330560
I0711 14:16:36.393527 126720 layer_factory.hpp:76] Creating layer pool4
I0711 14:16:36.393544 126720 net.cpp:106] Creating Layer pool4
I0711 14:16:36.393553 126720 net.cpp:454] pool4 <- conv42
I0711 14:16:36.393563 126720 net.cpp:411] pool4 -> pool4
I0711 14:16:36.393920 126720 net.cpp:150] Setting up pool4
I0711 14:16:36.393940 126720 net.cpp:157] Top shape: 128 128 7 7 (802816)
I0711 14:16:36.393949 126720 net.cpp:165] Memory required for data: 1238541824
I0711 14:16:36.393959 126720 layer_factory.hpp:76] Creating layer conv51
I0711 14:16:36.393975 126720 net.cpp:106] Creating Layer conv51
I0711 14:16:36.393985 126720 net.cpp:454] conv51 <- pool4
I0711 14:16:36.394001 126720 net.cpp:411] conv51 -> conv51
I0711 14:16:36.399826 126720 net.cpp:150] Setting up conv51
I0711 14:16:36.399863 126720 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0711 14:16:36.399873 126720 net.cpp:165] Memory required for data: 1244964352
I0711 14:16:36.399896 126720 layer_factory.hpp:76] Creating layer relu51
I0711 14:16:36.399911 126720 net.cpp:106] Creating Layer relu51
I0711 14:16:36.399925 126720 net.cpp:454] relu51 <- conv51
I0711 14:16:36.399943 126720 net.cpp:397] relu51 -> conv51 (in-place)
I0711 14:16:36.400395 126720 net.cpp:150] Setting up relu51
I0711 14:16:36.400413 126720 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0711 14:16:36.400420 126720 net.cpp:165] Memory required for data: 1251386880
I0711 14:16:36.400429 126720 layer_factory.hpp:76] Creating layer conv52
I0711 14:16:36.400449 126720 net.cpp:106] Creating Layer conv52
I0711 14:16:36.400457 126720 net.cpp:454] conv52 <- conv51
I0711 14:16:36.400467 126720 net.cpp:411] conv52 -> conv52
I0711 14:16:36.407112 126720 net.cpp:150] Setting up conv52
I0711 14:16:36.407157 126720 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0711 14:16:36.407168 126720 net.cpp:165] Memory required for data: 1257809408
I0711 14:16:36.407183 126720 layer_factory.hpp:76] Creating layer relu52
I0711 14:16:36.407202 126720 net.cpp:106] Creating Layer relu52
I0711 14:16:36.407251 126720 net.cpp:454] relu52 <- conv52
I0711 14:16:36.407265 126720 net.cpp:397] relu52 -> conv52 (in-place)
I0711 14:16:36.407598 126720 net.cpp:150] Setting up relu52
I0711 14:16:36.407623 126720 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0711 14:16:36.407631 126720 net.cpp:165] Memory required for data: 1264231936
I0711 14:16:36.407640 126720 layer_factory.hpp:76] Creating layer conv53
I0711 14:16:36.407656 126720 net.cpp:106] Creating Layer conv53
I0711 14:16:36.407665 126720 net.cpp:454] conv53 <- conv52
I0711 14:16:36.407678 126720 net.cpp:411] conv53 -> conv53
I0711 14:16:36.437551 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0711 14:16:36.437803 126720 net.cpp:150] Setting up conv53
I0711 14:16:36.437827 126720 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0711 14:16:36.437837 126720 net.cpp:165] Memory required for data: 1264363008
I0711 14:16:36.437855 126720 layer_factory.hpp:76] Creating layer relu53
I0711 14:16:36.437875 126720 net.cpp:106] Creating Layer relu53
I0711 14:16:36.437885 126720 net.cpp:454] relu53 <- conv53
I0711 14:16:36.437901 126720 net.cpp:397] relu53 -> conv53 (in-place)
I0711 14:16:36.438230 126720 net.cpp:150] Setting up relu53
I0711 14:16:36.438262 126720 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0711 14:16:36.438274 126720 net.cpp:165] Memory required for data: 1264494080
I0711 14:16:36.438283 126720 layer_factory.hpp:76] Creating layer drop6
I0711 14:16:36.438308 126720 net.cpp:106] Creating Layer drop6
I0711 14:16:36.438321 126720 net.cpp:454] drop6 <- conv53
I0711 14:16:36.438341 126720 net.cpp:411] drop6 -> drop6
I0711 14:16:36.438416 126720 net.cpp:150] Setting up drop6
I0711 14:16:36.438429 126720 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0711 14:16:36.438438 126720 net.cpp:165] Memory required for data: 1264625152
I0711 14:16:36.438446 126720 layer_factory.hpp:76] Creating layer conv54
I0711 14:16:36.438478 126720 net.cpp:106] Creating Layer conv54
I0711 14:16:36.438496 126720 net.cpp:454] conv54 <- drop6
I0711 14:16:36.438506 126720 net.cpp:411] conv54 -> conv54
I0711 14:16:36.439810 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0711 14:16:36.440026 126720 net.cpp:150] Setting up conv54
I0711 14:16:36.440044 126720 net.cpp:157] Top shape: 128 2 1 1 (256)
I0711 14:16:36.440055 126720 net.cpp:165] Memory required for data: 1264626176
I0711 14:16:36.440070 126720 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0711 14:16:36.440084 126720 net.cpp:106] Creating Layer conv54_conv54_0_split
I0711 14:16:36.440093 126720 net.cpp:454] conv54_conv54_0_split <- conv54
I0711 14:16:36.440104 126720 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0711 14:16:36.440115 126720 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0711 14:16:36.440165 126720 net.cpp:150] Setting up conv54_conv54_0_split
I0711 14:16:36.440179 126720 net.cpp:157] Top shape: 128 2 1 1 (256)
I0711 14:16:36.440188 126720 net.cpp:157] Top shape: 128 2 1 1 (256)
I0711 14:16:36.440197 126720 net.cpp:165] Memory required for data: 1264628224
I0711 14:16:36.440207 126720 layer_factory.hpp:76] Creating layer accuracy
I0711 14:16:36.440222 126720 net.cpp:106] Creating Layer accuracy
I0711 14:16:36.440230 126720 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0711 14:16:36.440240 126720 net.cpp:454] accuracy <- label_data_1_split_0
I0711 14:16:36.440261 126720 net.cpp:411] accuracy -> accuracy
I0711 14:16:36.440277 126720 net.cpp:150] Setting up accuracy
I0711 14:16:36.440292 126720 net.cpp:157] Top shape: (1)
I0711 14:16:36.440310 126720 net.cpp:165] Memory required for data: 1264628228
I0711 14:16:36.440318 126720 layer_factory.hpp:76] Creating layer loss
I0711 14:16:36.440338 126720 net.cpp:106] Creating Layer loss
I0711 14:16:36.440351 126720 net.cpp:454] loss <- conv54_conv54_0_split_1
I0711 14:16:36.440361 126720 net.cpp:454] loss <- label_data_1_split_1
I0711 14:16:36.440371 126720 net.cpp:411] loss -> loss
I0711 14:16:36.440389 126720 layer_factory.hpp:76] Creating layer loss
I0711 14:16:36.440701 126720 net.cpp:150] Setting up loss
I0711 14:16:36.440718 126720 net.cpp:157] Top shape: (1)
I0711 14:16:36.440726 126720 net.cpp:160]     with loss weight 1
I0711 14:16:36.440758 126720 net.cpp:165] Memory required for data: 1264628232
I0711 14:16:36.440768 126720 net.cpp:226] loss needs backward computation.
I0711 14:16:36.440776 126720 net.cpp:228] accuracy does not need backward computation.
I0711 14:16:36.440786 126720 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0711 14:16:36.440794 126720 net.cpp:226] conv54 needs backward computation.
I0711 14:16:36.440804 126720 net.cpp:226] drop6 needs backward computation.
I0711 14:16:36.440814 126720 net.cpp:226] relu53 needs backward computation.
I0711 14:16:36.440820 126720 net.cpp:226] conv53 needs backward computation.
I0711 14:16:36.440829 126720 net.cpp:226] relu52 needs backward computation.
I0711 14:16:36.440836 126720 net.cpp:226] conv52 needs backward computation.
I0711 14:16:36.440845 126720 net.cpp:226] relu51 needs backward computation.
I0711 14:16:36.440852 126720 net.cpp:226] conv51 needs backward computation.
I0711 14:16:36.440861 126720 net.cpp:226] pool4 needs backward computation.
I0711 14:16:36.440868 126720 net.cpp:226] relu42 needs backward computation.
I0711 14:16:36.440876 126720 net.cpp:226] conv42 needs backward computation.
I0711 14:16:36.440888 126720 net.cpp:226] relu41 needs backward computation.
I0711 14:16:36.440896 126720 net.cpp:226] conv41 needs backward computation.
I0711 14:16:36.440904 126720 net.cpp:226] pool3 needs backward computation.
I0711 14:16:36.440912 126720 net.cpp:226] relu32 needs backward computation.
I0711 14:16:36.440920 126720 net.cpp:226] conv32 needs backward computation.
I0711 14:16:36.440930 126720 net.cpp:226] relu31 needs backward computation.
I0711 14:16:36.440938 126720 net.cpp:226] conv31 needs backward computation.
I0711 14:16:36.440948 126720 net.cpp:226] pool2 needs backward computation.
I0711 14:16:36.440956 126720 net.cpp:226] relu22 needs backward computation.
I0711 14:16:36.440968 126720 net.cpp:226] conv22 needs backward computation.
I0711 14:16:36.440976 126720 net.cpp:226] relu21 needs backward computation.
I0711 14:16:36.440984 126720 net.cpp:226] conv21 needs backward computation.
I0711 14:16:36.440992 126720 net.cpp:226] pool1 needs backward computation.
I0711 14:16:36.441001 126720 net.cpp:226] relu12 needs backward computation.
I0711 14:16:36.441009 126720 net.cpp:226] conv12 needs backward computation.
I0711 14:16:36.441020 126720 net.cpp:226] relu11 needs backward computation.
I0711 14:16:36.441031 126720 net.cpp:226] conv11 needs backward computation.
I0711 14:16:36.441040 126720 net.cpp:228] label_data_1_split does not need backward computation.
I0711 14:16:36.441050 126720 net.cpp:228] data does not need backward computation.
I0711 14:16:36.441058 126720 net.cpp:270] This network produces output accuracy
I0711 14:16:36.441067 126720 net.cpp:270] This network produces output loss
I0711 14:16:36.441093 126720 net.cpp:283] Network initialization done.
I0711 14:16:36.441890 126720 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0711 14:16:36.441985 126720 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0711 14:16:36.442020 126720 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt.full
I0711 14:16:36.442068 126720 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0711 14:16:36.442283 126720 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-val-L0.lst"
    batch_size: 100
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0711 14:16:36.444015 126720 layer_factory.hpp:76] Creating layer data
I0711 14:16:36.444038 126720 net.cpp:106] Creating Layer data
I0711 14:16:36.444044 126720 net.cpp:411] data -> data
I0711 14:16:36.444057 126720 net.cpp:411] data -> label
I0711 14:16:36.444067 126720 image_data_layer.cpp:36] Opening file ../lists/roi-val-L0.lst
I0711 14:16:36.453863 126720 image_data_layer.cpp:46] Shuffling data
I0711 14:16:36.455127 126720 image_data_layer.cpp:51] A total of 20030 images.
I0711 14:16:36.470337 126720 image_data_layer.cpp:78] output data size: 100,3,100,100
I0711 14:16:36.506163 126720 net.cpp:150] Setting up data
I0711 14:16:36.506206 126720 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0711 14:16:36.506218 126720 net.cpp:157] Top shape: 100 (100)
I0711 14:16:36.506227 126720 net.cpp:165] Memory required for data: 12000400
I0711 14:16:36.506238 126720 layer_factory.hpp:76] Creating layer label_data_1_split
I0711 14:16:36.506256 126720 net.cpp:106] Creating Layer label_data_1_split
I0711 14:16:36.506265 126720 net.cpp:454] label_data_1_split <- label
I0711 14:16:36.506279 126720 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0711 14:16:36.506294 126720 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0711 14:16:36.506364 126720 net.cpp:150] Setting up label_data_1_split
I0711 14:16:36.506392 126720 net.cpp:157] Top shape: 100 (100)
I0711 14:16:36.506400 126720 net.cpp:157] Top shape: 100 (100)
I0711 14:16:36.506407 126720 net.cpp:165] Memory required for data: 12001200
I0711 14:16:36.506415 126720 layer_factory.hpp:76] Creating layer conv11
I0711 14:16:36.506433 126720 net.cpp:106] Creating Layer conv11
I0711 14:16:36.506443 126720 net.cpp:454] conv11 <- data
I0711 14:16:36.506454 126720 net.cpp:411] conv11 -> conv11
I0711 14:16:36.508023 126720 net.cpp:150] Setting up conv11
I0711 14:16:36.508059 126720 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0711 14:16:36.508069 126720 net.cpp:165] Memory required for data: 140001200
I0711 14:16:36.508110 126720 layer_factory.hpp:76] Creating layer relu11
I0711 14:16:36.508136 126720 net.cpp:106] Creating Layer relu11
I0711 14:16:36.508157 126720 net.cpp:454] relu11 <- conv11
I0711 14:16:36.508169 126720 net.cpp:397] relu11 -> conv11 (in-place)
I0711 14:16:36.508564 126720 net.cpp:150] Setting up relu11
I0711 14:16:36.508595 126720 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0711 14:16:36.508605 126720 net.cpp:165] Memory required for data: 268001200
I0711 14:16:36.508612 126720 layer_factory.hpp:76] Creating layer conv12
I0711 14:16:36.508635 126720 net.cpp:106] Creating Layer conv12
I0711 14:16:36.508644 126720 net.cpp:454] conv12 <- conv11
I0711 14:16:36.508656 126720 net.cpp:411] conv12 -> conv12
I0711 14:16:36.509768 126720 net.cpp:150] Setting up conv12
I0711 14:16:36.509799 126720 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0711 14:16:36.509817 126720 net.cpp:165] Memory required for data: 396001200
I0711 14:16:36.509848 126720 layer_factory.hpp:76] Creating layer relu12
I0711 14:16:36.509860 126720 net.cpp:106] Creating Layer relu12
I0711 14:16:36.509870 126720 net.cpp:454] relu12 <- conv12
I0711 14:16:36.509878 126720 net.cpp:397] relu12 -> conv12 (in-place)
I0711 14:16:36.510288 126720 net.cpp:150] Setting up relu12
I0711 14:16:36.510318 126720 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0711 14:16:36.510331 126720 net.cpp:165] Memory required for data: 524001200
I0711 14:16:36.510340 126720 layer_factory.hpp:76] Creating layer pool1
I0711 14:16:36.510356 126720 net.cpp:106] Creating Layer pool1
I0711 14:16:36.510365 126720 net.cpp:454] pool1 <- conv12
I0711 14:16:36.510375 126720 net.cpp:411] pool1 -> pool1
I0711 14:16:36.510659 126720 net.cpp:150] Setting up pool1
I0711 14:16:36.510687 126720 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0711 14:16:36.510696 126720 net.cpp:165] Memory required for data: 556001200
I0711 14:16:36.510704 126720 layer_factory.hpp:76] Creating layer conv21
I0711 14:16:36.510722 126720 net.cpp:106] Creating Layer conv21
I0711 14:16:36.510731 126720 net.cpp:454] conv21 <- pool1
I0711 14:16:36.510740 126720 net.cpp:411] conv21 -> conv21
I0711 14:16:36.513641 126720 net.cpp:150] Setting up conv21
I0711 14:16:36.513675 126720 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0711 14:16:36.513685 126720 net.cpp:165] Memory required for data: 620001200
I0711 14:16:36.513700 126720 layer_factory.hpp:76] Creating layer relu21
I0711 14:16:36.513716 126720 net.cpp:106] Creating Layer relu21
I0711 14:16:36.513727 126720 net.cpp:454] relu21 <- conv21
I0711 14:16:36.513762 126720 net.cpp:397] relu21 -> conv21 (in-place)
I0711 14:16:36.514165 126720 net.cpp:150] Setting up relu21
I0711 14:16:36.514195 126720 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0711 14:16:36.514204 126720 net.cpp:165] Memory required for data: 684001200
I0711 14:16:36.514212 126720 layer_factory.hpp:76] Creating layer conv22
I0711 14:16:36.514228 126720 net.cpp:106] Creating Layer conv22
I0711 14:16:36.514237 126720 net.cpp:454] conv22 <- conv21
I0711 14:16:36.514256 126720 net.cpp:411] conv22 -> conv22
I0711 14:16:36.515720 126720 net.cpp:150] Setting up conv22
I0711 14:16:36.515753 126720 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0711 14:16:36.515763 126720 net.cpp:165] Memory required for data: 748001200
I0711 14:16:36.515774 126720 layer_factory.hpp:76] Creating layer relu22
I0711 14:16:36.515784 126720 net.cpp:106] Creating Layer relu22
I0711 14:16:36.515792 126720 net.cpp:454] relu22 <- conv22
I0711 14:16:36.515806 126720 net.cpp:397] relu22 -> conv22 (in-place)
I0711 14:16:36.516041 126720 net.cpp:150] Setting up relu22
I0711 14:16:36.516055 126720 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0711 14:16:36.516074 126720 net.cpp:165] Memory required for data: 812001200
I0711 14:16:36.516083 126720 layer_factory.hpp:76] Creating layer pool2
I0711 14:16:36.516095 126720 net.cpp:106] Creating Layer pool2
I0711 14:16:36.516103 126720 net.cpp:454] pool2 <- conv22
I0711 14:16:36.516113 126720 net.cpp:411] pool2 -> pool2
I0711 14:16:36.516546 126720 net.cpp:150] Setting up pool2
I0711 14:16:36.516590 126720 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0711 14:16:36.516599 126720 net.cpp:165] Memory required for data: 828001200
I0711 14:16:36.516607 126720 layer_factory.hpp:76] Creating layer conv31
I0711 14:16:36.516625 126720 net.cpp:106] Creating Layer conv31
I0711 14:16:36.516634 126720 net.cpp:454] conv31 <- pool2
I0711 14:16:36.516645 126720 net.cpp:411] conv31 -> conv31
I0711 14:16:36.518074 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0711 14:16:36.518121 126720 net.cpp:150] Setting up conv31
I0711 14:16:36.518132 126720 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0711 14:16:36.518141 126720 net.cpp:165] Memory required for data: 852001200
I0711 14:16:36.518154 126720 layer_factory.hpp:76] Creating layer relu31
I0711 14:16:36.518183 126720 net.cpp:106] Creating Layer relu31
I0711 14:16:36.518193 126720 net.cpp:454] relu31 <- conv31
I0711 14:16:36.518203 126720 net.cpp:397] relu31 -> conv31 (in-place)
I0711 14:16:36.518591 126720 net.cpp:150] Setting up relu31
I0711 14:16:36.518621 126720 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0711 14:16:36.518635 126720 net.cpp:165] Memory required for data: 876001200
I0711 14:16:36.518643 126720 layer_factory.hpp:76] Creating layer conv32
I0711 14:16:36.518661 126720 net.cpp:106] Creating Layer conv32
I0711 14:16:36.518671 126720 net.cpp:454] conv32 <- conv31
I0711 14:16:36.518681 126720 net.cpp:411] conv32 -> conv32
I0711 14:16:36.520398 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0711 14:16:36.520447 126720 net.cpp:150] Setting up conv32
I0711 14:16:36.520459 126720 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0711 14:16:36.520467 126720 net.cpp:165] Memory required for data: 900001200
I0711 14:16:36.520479 126720 layer_factory.hpp:76] Creating layer relu32
I0711 14:16:36.520493 126720 net.cpp:106] Creating Layer relu32
I0711 14:16:36.520504 126720 net.cpp:454] relu32 <- conv32
I0711 14:16:36.520529 126720 net.cpp:397] relu32 -> conv32 (in-place)
I0711 14:16:36.520763 126720 net.cpp:150] Setting up relu32
I0711 14:16:36.520789 126720 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0711 14:16:36.520798 126720 net.cpp:165] Memory required for data: 924001200
I0711 14:16:36.520818 126720 layer_factory.hpp:76] Creating layer pool3
I0711 14:16:36.520833 126720 net.cpp:106] Creating Layer pool3
I0711 14:16:36.520841 126720 net.cpp:454] pool3 <- conv32
I0711 14:16:36.520851 126720 net.cpp:411] pool3 -> pool3
I0711 14:16:36.521275 126720 net.cpp:150] Setting up pool3
I0711 14:16:36.521304 126720 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I0711 14:16:36.521312 126720 net.cpp:165] Memory required for data: 930490800
I0711 14:16:36.521322 126720 layer_factory.hpp:76] Creating layer conv41
I0711 14:16:36.521342 126720 net.cpp:106] Creating Layer conv41
I0711 14:16:36.521350 126720 net.cpp:454] conv41 <- pool3
I0711 14:16:36.521360 126720 net.cpp:411] conv41 -> conv41
I0711 14:16:36.523946 126720 net.cpp:150] Setting up conv41
I0711 14:16:36.523977 126720 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0711 14:16:36.523985 126720 net.cpp:165] Memory required for data: 939143600
I0711 14:16:36.523996 126720 layer_factory.hpp:76] Creating layer relu41
I0711 14:16:36.524009 126720 net.cpp:106] Creating Layer relu41
I0711 14:16:36.524019 126720 net.cpp:454] relu41 <- conv41
I0711 14:16:36.524029 126720 net.cpp:397] relu41 -> conv41 (in-place)
I0711 14:16:36.524257 126720 net.cpp:150] Setting up relu41
I0711 14:16:36.524283 126720 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0711 14:16:36.524291 126720 net.cpp:165] Memory required for data: 947796400
I0711 14:16:36.524299 126720 layer_factory.hpp:76] Creating layer conv42
I0711 14:16:36.524313 126720 net.cpp:106] Creating Layer conv42
I0711 14:16:36.524322 126720 net.cpp:454] conv42 <- conv41
I0711 14:16:36.524334 126720 net.cpp:411] conv42 -> conv42
I0711 14:16:36.526269 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0711 14:16:36.526317 126720 net.cpp:150] Setting up conv42
I0711 14:16:36.526329 126720 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0711 14:16:36.526365 126720 net.cpp:165] Memory required for data: 956449200
I0711 14:16:36.526378 126720 layer_factory.hpp:76] Creating layer relu42
I0711 14:16:36.526388 126720 net.cpp:106] Creating Layer relu42
I0711 14:16:36.526397 126720 net.cpp:454] relu42 <- conv42
I0711 14:16:36.526410 126720 net.cpp:397] relu42 -> conv42 (in-place)
I0711 14:16:36.526811 126720 net.cpp:150] Setting up relu42
I0711 14:16:36.526830 126720 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0711 14:16:36.526839 126720 net.cpp:165] Memory required for data: 965102000
I0711 14:16:36.526845 126720 layer_factory.hpp:76] Creating layer pool4
I0711 14:16:36.526856 126720 net.cpp:106] Creating Layer pool4
I0711 14:16:36.526865 126720 net.cpp:454] pool4 <- conv42
I0711 14:16:36.526876 126720 net.cpp:411] pool4 -> pool4
I0711 14:16:36.527138 126720 net.cpp:150] Setting up pool4
I0711 14:16:36.527164 126720 net.cpp:157] Top shape: 100 128 7 7 (627200)
I0711 14:16:36.527173 126720 net.cpp:165] Memory required for data: 967610800
I0711 14:16:36.527180 126720 layer_factory.hpp:76] Creating layer conv51
I0711 14:16:36.527194 126720 net.cpp:106] Creating Layer conv51
I0711 14:16:36.527205 126720 net.cpp:454] conv51 <- pool4
I0711 14:16:36.527215 126720 net.cpp:411] conv51 -> conv51
I0711 14:16:36.531116 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0711 14:16:36.531164 126720 net.cpp:150] Setting up conv51
I0711 14:16:36.531177 126720 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0711 14:16:36.531185 126720 net.cpp:165] Memory required for data: 972628400
I0711 14:16:36.531205 126720 layer_factory.hpp:76] Creating layer relu51
I0711 14:16:36.531231 126720 net.cpp:106] Creating Layer relu51
I0711 14:16:36.531252 126720 net.cpp:454] relu51 <- conv51
I0711 14:16:36.531265 126720 net.cpp:397] relu51 -> conv51 (in-place)
I0711 14:16:36.531493 126720 net.cpp:150] Setting up relu51
I0711 14:16:36.531520 126720 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0711 14:16:36.531528 126720 net.cpp:165] Memory required for data: 977646000
I0711 14:16:36.531538 126720 layer_factory.hpp:76] Creating layer conv52
I0711 14:16:36.531553 126720 net.cpp:106] Creating Layer conv52
I0711 14:16:36.531561 126720 net.cpp:454] conv52 <- conv51
I0711 14:16:36.531574 126720 net.cpp:411] conv52 -> conv52
I0711 14:16:36.538157 126720 net.cpp:150] Setting up conv52
I0711 14:16:36.538193 126720 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0711 14:16:36.538203 126720 net.cpp:165] Memory required for data: 982663600
I0711 14:16:36.538214 126720 layer_factory.hpp:76] Creating layer relu52
I0711 14:16:36.538228 126720 net.cpp:106] Creating Layer relu52
I0711 14:16:36.538239 126720 net.cpp:454] relu52 <- conv52
I0711 14:16:36.538249 126720 net.cpp:397] relu52 -> conv52 (in-place)
I0711 14:16:36.538655 126720 net.cpp:150] Setting up relu52
I0711 14:16:36.538684 126720 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0711 14:16:36.538693 126720 net.cpp:165] Memory required for data: 987681200
I0711 14:16:36.538702 126720 layer_factory.hpp:76] Creating layer conv53
I0711 14:16:36.538718 126720 net.cpp:106] Creating Layer conv53
I0711 14:16:36.538727 126720 net.cpp:454] conv53 <- conv52
I0711 14:16:36.538740 126720 net.cpp:411] conv53 -> conv53
I0711 14:16:36.573452 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0711 14:16:36.573536 126720 net.cpp:150] Setting up conv53
I0711 14:16:36.573552 126720 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0711 14:16:36.573561 126720 net.cpp:165] Memory required for data: 987783600
I0711 14:16:36.573576 126720 layer_factory.hpp:76] Creating layer relu53
I0711 14:16:36.573596 126720 net.cpp:106] Creating Layer relu53
I0711 14:16:36.573609 126720 net.cpp:454] relu53 <- conv53
I0711 14:16:36.573622 126720 net.cpp:397] relu53 -> conv53 (in-place)
I0711 14:16:36.573860 126720 net.cpp:150] Setting up relu53
I0711 14:16:36.573886 126720 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0711 14:16:36.573906 126720 net.cpp:165] Memory required for data: 987886000
I0711 14:16:36.573940 126720 layer_factory.hpp:76] Creating layer drop6
I0711 14:16:36.573953 126720 net.cpp:106] Creating Layer drop6
I0711 14:16:36.573961 126720 net.cpp:454] drop6 <- conv53
I0711 14:16:36.573976 126720 net.cpp:411] drop6 -> drop6
I0711 14:16:36.574069 126720 net.cpp:150] Setting up drop6
I0711 14:16:36.574084 126720 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0711 14:16:36.574090 126720 net.cpp:165] Memory required for data: 987988400
I0711 14:16:36.574098 126720 layer_factory.hpp:76] Creating layer conv54
I0711 14:16:36.574115 126720 net.cpp:106] Creating Layer conv54
I0711 14:16:36.574139 126720 net.cpp:454] conv54 <- drop6
I0711 14:16:36.574165 126720 net.cpp:411] conv54 -> conv54
I0711 14:16:36.588831 126720 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0711 14:16:36.588878 126720 net.cpp:150] Setting up conv54
I0711 14:16:36.588891 126720 net.cpp:157] Top shape: 100 2 1 1 (200)
I0711 14:16:36.588898 126720 net.cpp:165] Memory required for data: 987989200
I0711 14:16:36.588912 126720 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0711 14:16:36.588924 126720 net.cpp:106] Creating Layer conv54_conv54_0_split
I0711 14:16:36.588933 126720 net.cpp:454] conv54_conv54_0_split <- conv54
I0711 14:16:36.588943 126720 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0711 14:16:36.588968 126720 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0711 14:16:36.589027 126720 net.cpp:150] Setting up conv54_conv54_0_split
I0711 14:16:36.589040 126720 net.cpp:157] Top shape: 100 2 1 1 (200)
I0711 14:16:36.589048 126720 net.cpp:157] Top shape: 100 2 1 1 (200)
I0711 14:16:36.589056 126720 net.cpp:165] Memory required for data: 987990800
I0711 14:16:36.589064 126720 layer_factory.hpp:76] Creating layer accuracy
I0711 14:16:36.589076 126720 net.cpp:106] Creating Layer accuracy
I0711 14:16:36.589085 126720 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0711 14:16:36.589094 126720 net.cpp:454] accuracy <- label_data_1_split_0
I0711 14:16:36.589103 126720 net.cpp:411] accuracy -> accuracy
I0711 14:16:36.589143 126720 net.cpp:150] Setting up accuracy
I0711 14:16:36.589162 126720 net.cpp:157] Top shape: (1)
I0711 14:16:36.589170 126720 net.cpp:165] Memory required for data: 987990804
I0711 14:16:36.589179 126720 layer_factory.hpp:76] Creating layer loss
I0711 14:16:36.589197 126720 net.cpp:106] Creating Layer loss
I0711 14:16:36.589220 126720 net.cpp:454] loss <- conv54_conv54_0_split_1
I0711 14:16:36.589229 126720 net.cpp:454] loss <- label_data_1_split_1
I0711 14:16:36.589239 126720 net.cpp:411] loss -> loss
I0711 14:16:36.589251 126720 layer_factory.hpp:76] Creating layer loss
I0711 14:16:36.589642 126720 net.cpp:150] Setting up loss
I0711 14:16:36.589668 126720 net.cpp:157] Top shape: (1)
I0711 14:16:36.589675 126720 net.cpp:160]     with loss weight 1
I0711 14:16:36.589689 126720 net.cpp:165] Memory required for data: 987990808
I0711 14:16:36.589696 126720 net.cpp:226] loss needs backward computation.
I0711 14:16:36.589716 126720 net.cpp:228] accuracy does not need backward computation.
I0711 14:16:36.589725 126720 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0711 14:16:36.589733 126720 net.cpp:226] conv54 needs backward computation.
I0711 14:16:36.589740 126720 net.cpp:226] drop6 needs backward computation.
I0711 14:16:36.589750 126720 net.cpp:226] relu53 needs backward computation.
I0711 14:16:36.589756 126720 net.cpp:226] conv53 needs backward computation.
I0711 14:16:36.589764 126720 net.cpp:226] relu52 needs backward computation.
I0711 14:16:36.589784 126720 net.cpp:226] conv52 needs backward computation.
I0711 14:16:36.589792 126720 net.cpp:226] relu51 needs backward computation.
I0711 14:16:36.589799 126720 net.cpp:226] conv51 needs backward computation.
I0711 14:16:36.589807 126720 net.cpp:226] pool4 needs backward computation.
I0711 14:16:36.589814 126720 net.cpp:226] relu42 needs backward computation.
I0711 14:16:36.589823 126720 net.cpp:226] conv42 needs backward computation.
I0711 14:16:36.589829 126720 net.cpp:226] relu41 needs backward computation.
I0711 14:16:36.589857 126720 net.cpp:226] conv41 needs backward computation.
I0711 14:16:36.589879 126720 net.cpp:226] pool3 needs backward computation.
I0711 14:16:36.589886 126720 net.cpp:226] relu32 needs backward computation.
I0711 14:16:36.589895 126720 net.cpp:226] conv32 needs backward computation.
I0711 14:16:36.589902 126720 net.cpp:226] relu31 needs backward computation.
I0711 14:16:36.589910 126720 net.cpp:226] conv31 needs backward computation.
I0711 14:16:36.589929 126720 net.cpp:226] pool2 needs backward computation.
I0711 14:16:36.589936 126720 net.cpp:226] relu22 needs backward computation.
I0711 14:16:36.589944 126720 net.cpp:226] conv22 needs backward computation.
I0711 14:16:36.589951 126720 net.cpp:226] relu21 needs backward computation.
I0711 14:16:36.589958 126720 net.cpp:226] conv21 needs backward computation.
I0711 14:16:36.589978 126720 net.cpp:226] pool1 needs backward computation.
I0711 14:16:36.589985 126720 net.cpp:226] relu12 needs backward computation.
I0711 14:16:36.589993 126720 net.cpp:226] conv12 needs backward computation.
I0711 14:16:36.589999 126720 net.cpp:226] relu11 needs backward computation.
I0711 14:16:36.590006 126720 net.cpp:226] conv11 needs backward computation.
I0711 14:16:36.590015 126720 net.cpp:228] label_data_1_split does not need backward computation.
I0711 14:16:36.590023 126720 net.cpp:228] data does not need backward computation.
I0711 14:16:36.590029 126720 net.cpp:270] This network produces output accuracy
I0711 14:16:36.590037 126720 net.cpp:270] This network produces output loss
I0711 14:16:36.590062 126720 net.cpp:283] Network initialization done.
I0711 14:16:36.590277 126720 solver.cpp:59] Solver scaffolding done.
I0711 14:16:36.591254 126720 caffe.cpp:202] Resuming from models/cnn10_iter_202741.solverstate
I0711 14:16:36.669631 126720 sgd_solver.cpp:314] SGDSolver: restoring history
I0711 14:16:36.690333 126720 caffe.cpp:212] Starting Optimization
I0711 14:16:36.690384 126720 solver.cpp:287] Solving FaceNN
I0711 14:16:36.690393 126720 solver.cpp:288] Learning Rate Policy: fixed
I0711 14:16:36.692080 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 14:17:06.208637 126720 solver.cpp:340] Iteration 202750, Testing net (#0)
I0711 14:20:49.812968 126720 solver.cpp:408]     Test net output #0: accuracy = 0.998
I0711 14:20:49.813037 126720 solver.cpp:408]     Test net output #1: loss = 0.00840822 (* 1 = 0.00840822 loss)
I0711 14:23:32.538010 126720 solver.cpp:236] Iteration 202800, loss = 0.0119185
I0711 14:23:32.538103 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 14:23:32.538122 126720 solver.cpp:252]     Train net output #1: loss = 0.00748418 (* 1 = 0.00748418 loss)
I0711 14:23:32.538135 126720 sgd_solver.cpp:106] Iteration 202800, lr = 0.001
I0711 14:29:25.838048 126720 solver.cpp:236] Iteration 202900, loss = 0.0064343
I0711 14:29:25.838188 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 14:29:25.838219 126720 solver.cpp:252]     Train net output #1: loss = 0.00654431 (* 1 = 0.00654431 loss)
I0711 14:29:25.838232 126720 sgd_solver.cpp:106] Iteration 202900, lr = 0.001
I0711 14:35:19.862032 126720 solver.cpp:340] Iteration 203000, Testing net (#0)
I0711 14:39:19.807914 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9968
I0711 14:39:19.808073 126720 solver.cpp:408]     Test net output #1: loss = 0.0099088 (* 1 = 0.0099088 loss)
I0711 14:39:20.055235 126720 solver.cpp:236] Iteration 203000, loss = 0.00593071
I0711 14:39:20.055286 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 14:39:20.055302 126720 solver.cpp:252]     Train net output #1: loss = 0.0118736 (* 1 = 0.0118736 loss)
I0711 14:39:20.055313 126720 sgd_solver.cpp:106] Iteration 203000, lr = 0.001
I0711 14:45:07.781266 126720 solver.cpp:236] Iteration 203100, loss = 0.0115651
I0711 14:45:07.781414 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0711 14:45:07.781460 126720 solver.cpp:252]     Train net output #1: loss = 0.0726992 (* 1 = 0.0726992 loss)
I0711 14:45:07.781471 126720 sgd_solver.cpp:106] Iteration 203100, lr = 0.001
I0711 14:51:00.327687 126720 solver.cpp:236] Iteration 203200, loss = 0.0146294
I0711 14:51:00.327980 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 14:51:00.328013 126720 solver.cpp:252]     Train net output #1: loss = 0.00570049 (* 1 = 0.00570049 loss)
I0711 14:51:00.328025 126720 sgd_solver.cpp:106] Iteration 203200, lr = 0.001
I0711 14:53:57.691990 126720 solver.cpp:340] Iteration 203250, Testing net (#0)
I0711 14:57:23.643375 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9985
I0711 14:57:23.643613 126720 solver.cpp:408]     Test net output #1: loss = 0.00609858 (* 1 = 0.00609858 loss)
I0711 15:00:15.052783 126720 solver.cpp:236] Iteration 203300, loss = 0.00362982
I0711 15:00:15.055938 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0711 15:00:15.055971 126720 solver.cpp:252]     Train net output #1: loss = 0.0232567 (* 1 = 0.0232567 loss)
I0711 15:00:15.055984 126720 sgd_solver.cpp:106] Iteration 203300, lr = 0.001
I0711 15:06:09.087247 126720 solver.cpp:236] Iteration 203400, loss = 0.00695161
I0711 15:06:09.087440 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 15:06:09.087471 126720 solver.cpp:252]     Train net output #1: loss = 0.00346098 (* 1 = 0.00346098 loss)
I0711 15:06:09.087483 126720 sgd_solver.cpp:106] Iteration 203400, lr = 0.001
I0711 15:09:36.373473 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 15:12:02.231806 126720 solver.cpp:340] Iteration 203500, Testing net (#0)
I0711 15:15:37.330404 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9976
I0711 15:15:37.330622 126720 solver.cpp:408]     Test net output #1: loss = 0.00943965 (* 1 = 0.00943965 loss)
I0711 15:15:37.645238 126720 solver.cpp:236] Iteration 203500, loss = 0.010535
I0711 15:15:37.645287 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 15:15:37.645300 126720 solver.cpp:252]     Train net output #1: loss = 0.00800291 (* 1 = 0.00800291 loss)
I0711 15:15:37.645311 126720 sgd_solver.cpp:106] Iteration 203500, lr = 0.001
I0711 15:21:30.187163 126720 solver.cpp:236] Iteration 203600, loss = 0.0124191
I0711 15:21:30.187357 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 15:21:30.187377 126720 solver.cpp:252]     Train net output #1: loss = 0.0289654 (* 1 = 0.0289654 loss)
I0711 15:21:30.187389 126720 sgd_solver.cpp:106] Iteration 203600, lr = 0.001
I0711 15:27:39.827785 126720 solver.cpp:236] Iteration 203700, loss = 0.00787219
I0711 15:27:39.827961 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 15:27:39.827993 126720 solver.cpp:252]     Train net output #1: loss = 0.00186334 (* 1 = 0.00186334 loss)
I0711 15:27:39.828006 126720 sgd_solver.cpp:106] Iteration 203700, lr = 0.001
I0711 15:30:40.049602 126720 solver.cpp:340] Iteration 203750, Testing net (#0)
I0711 15:34:05.978636 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9981
I0711 15:34:05.978878 126720 solver.cpp:408]     Test net output #1: loss = 0.00666105 (* 1 = 0.00666105 loss)
I0711 15:37:05.624505 126720 solver.cpp:236] Iteration 203800, loss = 0.00712302
I0711 15:37:05.624793 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0711 15:37:05.624825 126720 solver.cpp:252]     Train net output #1: loss = 0.0265754 (* 1 = 0.0265754 loss)
I0711 15:37:05.624840 126720 sgd_solver.cpp:106] Iteration 203800, lr = 0.001
I0711 15:43:25.266187 126720 solver.cpp:236] Iteration 203900, loss = 0.010223
I0711 15:43:25.266340 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 15:43:25.266360 126720 solver.cpp:252]     Train net output #1: loss = 0.00940729 (* 1 = 0.00940729 loss)
I0711 15:43:25.266371 126720 sgd_solver.cpp:106] Iteration 203900, lr = 0.001
I0711 15:49:46.241355 126720 solver.cpp:340] Iteration 204000, Testing net (#0)
I0711 15:53:10.147541 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9969
I0711 15:53:10.147696 126720 solver.cpp:408]     Test net output #1: loss = 0.00874886 (* 1 = 0.00874886 loss)
I0711 15:53:10.444222 126720 solver.cpp:236] Iteration 204000, loss = 0.00730995
I0711 15:53:10.444274 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 15:53:10.444290 126720 solver.cpp:252]     Train net output #1: loss = 0.000503645 (* 1 = 0.000503645 loss)
I0711 15:53:10.444300 126720 sgd_solver.cpp:106] Iteration 204000, lr = 0.001
I0711 15:59:22.945346 126720 solver.cpp:236] Iteration 204100, loss = 0.0082027
I0711 15:59:22.945646 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 15:59:22.945665 126720 solver.cpp:252]     Train net output #1: loss = 0.0012431 (* 1 = 0.0012431 loss)
I0711 15:59:22.945675 126720 sgd_solver.cpp:106] Iteration 204100, lr = 0.001
I0711 16:03:49.556722 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 16:05:05.977126 126720 solver.cpp:236] Iteration 204200, loss = 0.0100013
I0711 16:05:05.977309 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 16:05:05.977355 126720 solver.cpp:252]     Train net output #1: loss = 0.00148996 (* 1 = 0.00148996 loss)
I0711 16:05:05.977366 126720 sgd_solver.cpp:106] Iteration 204200, lr = 0.001
I0711 16:07:40.372316 126720 solver.cpp:340] Iteration 204250, Testing net (#0)
I0711 16:10:49.026010 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9976
I0711 16:10:49.026146 126720 solver.cpp:408]     Test net output #1: loss = 0.00704998 (* 1 = 0.00704998 loss)
I0711 16:13:31.502336 126720 solver.cpp:236] Iteration 204300, loss = 0.00663789
I0711 16:13:31.502527 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 16:13:31.502547 126720 solver.cpp:252]     Train net output #1: loss = 0.00156051 (* 1 = 0.00156051 loss)
I0711 16:13:31.502563 126720 sgd_solver.cpp:106] Iteration 204300, lr = 0.001
I0711 16:19:19.301494 126720 solver.cpp:236] Iteration 204400, loss = 0.00714376
I0711 16:19:19.301673 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 16:19:19.301707 126720 solver.cpp:252]     Train net output #1: loss = 0.0123723 (* 1 = 0.0123723 loss)
I0711 16:19:19.301718 126720 sgd_solver.cpp:106] Iteration 204400, lr = 0.001
I0711 16:25:14.561758 126720 solver.cpp:340] Iteration 204500, Testing net (#0)
I0711 16:28:21.422212 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9967
I0711 16:28:21.423399 126720 solver.cpp:408]     Test net output #1: loss = 0.00947475 (* 1 = 0.00947475 loss)
I0711 16:28:21.561108 126720 solver.cpp:236] Iteration 204500, loss = 0.00717639
I0711 16:28:21.561159 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 16:28:21.561177 126720 solver.cpp:252]     Train net output #1: loss = 0.00197606 (* 1 = 0.00197606 loss)
I0711 16:28:21.561188 126720 sgd_solver.cpp:106] Iteration 204500, lr = 0.001
I0711 16:34:22.303807 126720 solver.cpp:236] Iteration 204600, loss = 0.00953365
I0711 16:34:22.303964 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 16:34:22.304014 126720 solver.cpp:252]     Train net output #1: loss = 0.000828258 (* 1 = 0.000828258 loss)
I0711 16:34:22.304026 126720 sgd_solver.cpp:106] Iteration 204600, lr = 0.001
I0711 16:42:58.830595 126720 solver.cpp:236] Iteration 204700, loss = 0.00654488
I0711 16:42:58.830936 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 16:42:58.830971 126720 solver.cpp:252]     Train net output #1: loss = 0.0111849 (* 1 = 0.0111849 loss)
I0711 16:42:58.830982 126720 sgd_solver.cpp:106] Iteration 204700, lr = 0.001
I0711 16:45:53.808441 126720 solver.cpp:340] Iteration 204750, Testing net (#0)
I0711 16:49:00.807533 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9978
I0711 16:49:00.807711 126720 solver.cpp:408]     Test net output #1: loss = 0.00631746 (* 1 = 0.00631746 loss)
I0711 16:51:56.256394 126720 solver.cpp:236] Iteration 204800, loss = 0.00736827
I0711 16:51:56.256682 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 16:51:56.256705 126720 solver.cpp:252]     Train net output #1: loss = 0.0017082 (* 1 = 0.0017082 loss)
I0711 16:51:56.256716 126720 sgd_solver.cpp:106] Iteration 204800, lr = 0.001
I0711 16:57:40.570153 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 16:58:02.486855 126720 solver.cpp:236] Iteration 204900, loss = 0.0136499
I0711 16:58:02.486939 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 16:58:02.486964 126720 solver.cpp:252]     Train net output #1: loss = 0.00570755 (* 1 = 0.00570755 loss)
I0711 16:58:02.486980 126720 sgd_solver.cpp:106] Iteration 204900, lr = 0.001
I0711 17:04:09.049826 126720 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_205000.caffemodel
I0711 17:04:09.903846 126720 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_205000.solverstate
I0711 17:04:09.985285 126720 solver.cpp:340] Iteration 205000, Testing net (#0)
I0711 17:07:26.405453 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9979
I0711 17:07:26.405668 126720 solver.cpp:408]     Test net output #1: loss = 0.00635922 (* 1 = 0.00635922 loss)
I0711 17:07:26.665310 126720 solver.cpp:236] Iteration 205000, loss = 0.00708283
I0711 17:07:26.665369 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 17:07:26.665385 126720 solver.cpp:252]     Train net output #1: loss = 0.00112787 (* 1 = 0.00112787 loss)
I0711 17:07:26.665396 126720 sgd_solver.cpp:106] Iteration 205000, lr = 0.001
I0711 17:13:32.113595 126720 solver.cpp:236] Iteration 205100, loss = 0.0104664
I0711 17:13:32.113801 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 17:13:32.113831 126720 solver.cpp:252]     Train net output #1: loss = 0.00354913 (* 1 = 0.00354913 loss)
I0711 17:13:32.113843 126720 sgd_solver.cpp:106] Iteration 205100, lr = 0.001
I0711 17:19:38.029820 126720 solver.cpp:236] Iteration 205200, loss = 0.00625054
I0711 17:19:38.029959 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0711 17:19:38.029994 126720 solver.cpp:252]     Train net output #1: loss = 0.0275366 (* 1 = 0.0275366 loss)
I0711 17:19:38.030005 126720 sgd_solver.cpp:106] Iteration 205200, lr = 0.001
I0711 17:22:44.041172 126720 solver.cpp:340] Iteration 205250, Testing net (#0)
I0711 17:25:47.224436 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9976
I0711 17:25:47.224620 126720 solver.cpp:408]     Test net output #1: loss = 0.00742226 (* 1 = 0.00742226 loss)
I0711 17:28:52.392619 126720 solver.cpp:236] Iteration 205300, loss = 0.0071618
I0711 17:28:52.392925 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 17:28:52.392958 126720 solver.cpp:252]     Train net output #1: loss = 0.00240754 (* 1 = 0.00240754 loss)
I0711 17:28:52.392969 126720 sgd_solver.cpp:106] Iteration 205300, lr = 0.001
I0711 17:35:17.823786 126720 solver.cpp:236] Iteration 205400, loss = 0.00970955
I0711 17:35:17.824061 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 17:35:17.824092 126720 solver.cpp:252]     Train net output #1: loss = 0.00387617 (* 1 = 0.00387617 loss)
I0711 17:35:17.824102 126720 sgd_solver.cpp:106] Iteration 205400, lr = 0.001
I0711 17:41:33.686535 126720 solver.cpp:340] Iteration 205500, Testing net (#0)
I0711 17:44:52.645890 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9881
I0711 17:44:52.646262 126720 solver.cpp:408]     Test net output #1: loss = 0.0385097 (* 1 = 0.0385097 loss)
I0711 17:44:52.979235 126720 solver.cpp:236] Iteration 205500, loss = 0.0125207
I0711 17:44:52.979310 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0711 17:44:52.979339 126720 solver.cpp:252]     Train net output #1: loss = 0.0556015 (* 1 = 0.0556015 loss)
I0711 17:44:52.979362 126720 sgd_solver.cpp:106] Iteration 205500, lr = 0.001
I0711 17:50:41.603642 126720 solver.cpp:236] Iteration 205600, loss = 0.0114422
I0711 17:50:41.605238 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 17:50:41.605288 126720 solver.cpp:252]     Train net output #1: loss = 0.0155132 (* 1 = 0.0155132 loss)
I0711 17:50:41.605314 126720 sgd_solver.cpp:106] Iteration 205600, lr = 0.001
I0711 17:51:20.083495 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 17:56:16.826395 126720 solver.cpp:236] Iteration 205700, loss = 0.00648474
I0711 17:56:16.826731 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 17:56:16.826766 126720 solver.cpp:252]     Train net output #1: loss = 0.00267423 (* 1 = 0.00267423 loss)
I0711 17:56:16.826797 126720 sgd_solver.cpp:106] Iteration 205700, lr = 0.001
I0711 17:59:06.819337 126720 solver.cpp:340] Iteration 205750, Testing net (#0)
I0711 18:01:56.307107 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9944
I0711 18:01:56.307363 126720 solver.cpp:408]     Test net output #1: loss = 0.0154347 (* 1 = 0.0154347 loss)
I0711 18:04:45.424047 126720 solver.cpp:236] Iteration 205800, loss = 0.00696228
I0711 18:04:45.424188 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 18:04:45.424231 126720 solver.cpp:252]     Train net output #1: loss = 0.0045674 (* 1 = 0.0045674 loss)
I0711 18:04:45.424244 126720 sgd_solver.cpp:106] Iteration 205800, lr = 0.001
I0711 18:10:35.303452 126720 solver.cpp:236] Iteration 205900, loss = 0.00974291
I0711 18:10:35.303622 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 18:10:35.303652 126720 solver.cpp:252]     Train net output #1: loss = 0.00221884 (* 1 = 0.00221884 loss)
I0711 18:10:35.303663 126720 sgd_solver.cpp:106] Iteration 205900, lr = 0.001
I0711 18:16:28.653381 126720 solver.cpp:340] Iteration 206000, Testing net (#0)
I0711 18:19:22.200119 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9966
I0711 18:19:22.200278 126720 solver.cpp:408]     Test net output #1: loss = 0.00900494 (* 1 = 0.00900494 loss)
I0711 18:19:22.381074 126720 solver.cpp:236] Iteration 206000, loss = 0.00670741
I0711 18:19:22.381134 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 18:19:22.381150 126720 solver.cpp:252]     Train net output #1: loss = 0.00145313 (* 1 = 0.00145313 loss)
I0711 18:19:22.381161 126720 sgd_solver.cpp:106] Iteration 206000, lr = 0.001
I0711 18:25:22.438086 126720 solver.cpp:236] Iteration 206100, loss = 0.00646568
I0711 18:25:22.438285 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 18:25:22.438303 126720 solver.cpp:252]     Train net output #1: loss = 0.00200916 (* 1 = 0.00200916 loss)
I0711 18:25:22.438315 126720 sgd_solver.cpp:106] Iteration 206100, lr = 0.001
I0711 18:31:36.529474 126720 solver.cpp:236] Iteration 206200, loss = 0.00598437
I0711 18:31:36.529682 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 18:31:36.529705 126720 solver.cpp:252]     Train net output #1: loss = 0.00215877 (* 1 = 0.00215877 loss)
I0711 18:31:36.529716 126720 sgd_solver.cpp:106] Iteration 206200, lr = 0.001
I0711 18:34:36.757557 126720 solver.cpp:340] Iteration 206250, Testing net (#0)
I0711 18:37:16.257210 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9949
I0711 18:37:16.257496 126720 solver.cpp:408]     Test net output #1: loss = 0.0140374 (* 1 = 0.0140374 loss)
I0711 18:40:16.965418 126720 solver.cpp:236] Iteration 206300, loss = 0.0070216
I0711 18:40:16.965653 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 18:40:16.965672 126720 solver.cpp:252]     Train net output #1: loss = 0.00470639 (* 1 = 0.00470639 loss)
I0711 18:40:16.965683 126720 sgd_solver.cpp:106] Iteration 206300, lr = 0.001
I0711 18:42:08.338030 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 18:46:29.746795 126720 solver.cpp:236] Iteration 206400, loss = 0.00721228
I0711 18:46:29.747037 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 18:46:29.747087 126720 solver.cpp:252]     Train net output #1: loss = 0.00727913 (* 1 = 0.00727913 loss)
I0711 18:46:29.747095 126720 sgd_solver.cpp:106] Iteration 206400, lr = 0.001
I0711 18:52:38.328482 126720 solver.cpp:340] Iteration 206500, Testing net (#0)
I0711 18:55:15.056583 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9975
I0711 18:55:15.056785 126720 solver.cpp:408]     Test net output #1: loss = 0.00732597 (* 1 = 0.00732597 loss)
I0711 18:55:15.294524 126720 solver.cpp:236] Iteration 206500, loss = 0.00524311
I0711 18:55:15.294571 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 18:55:15.294586 126720 solver.cpp:252]     Train net output #1: loss = 0.0251352 (* 1 = 0.0251352 loss)
I0711 18:55:15.294597 126720 sgd_solver.cpp:106] Iteration 206500, lr = 0.001
I0711 19:01:24.026070 126720 solver.cpp:236] Iteration 206600, loss = 0.00966812
I0711 19:01:24.026245 126720 solver.cpp:252]     Train net output #0: accuracy = 0.976562
I0711 19:01:24.026295 126720 solver.cpp:252]     Train net output #1: loss = 0.0384458 (* 1 = 0.0384458 loss)
I0711 19:01:24.026307 126720 sgd_solver.cpp:106] Iteration 206600, lr = 0.001
I0711 19:07:43.261359 126720 solver.cpp:236] Iteration 206700, loss = 0.0118701
I0711 19:07:43.261507 126720 solver.cpp:252]     Train net output #0: accuracy = 0.976562
I0711 19:07:43.261538 126720 solver.cpp:252]     Train net output #1: loss = 0.052523 (* 1 = 0.052523 loss)
I0711 19:07:43.261557 126720 sgd_solver.cpp:106] Iteration 206700, lr = 0.001
I0711 19:10:52.673712 126720 solver.cpp:340] Iteration 206750, Testing net (#0)
I0711 19:13:28.733796 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9969
I0711 19:13:28.733989 126720 solver.cpp:408]     Test net output #1: loss = 0.00987162 (* 1 = 0.00987162 loss)
I0711 19:16:38.725291 126720 solver.cpp:236] Iteration 206800, loss = 0.00907744
I0711 19:16:38.725636 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0711 19:16:38.725669 126720 solver.cpp:252]     Train net output #1: loss = 0.0197878 (* 1 = 0.0197878 loss)
I0711 19:16:38.725680 126720 sgd_solver.cpp:106] Iteration 206800, lr = 0.001
I0711 19:23:00.994315 126720 solver.cpp:236] Iteration 206900, loss = 0.00588968
I0711 19:23:00.994592 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 19:23:00.994635 126720 solver.cpp:252]     Train net output #1: loss = 0.007294 (* 1 = 0.007294 loss)
I0711 19:23:00.994671 126720 sgd_solver.cpp:106] Iteration 206900, lr = 0.001
I0711 19:28:51.145493 126720 solver.cpp:340] Iteration 207000, Testing net (#0)
I0711 19:31:23.742830 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9978
I0711 19:31:23.743032 126720 solver.cpp:408]     Test net output #1: loss = 0.00707059 (* 1 = 0.00707059 loss)
I0711 19:31:23.997818 126720 solver.cpp:236] Iteration 207000, loss = 0.00916267
I0711 19:31:23.997895 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 19:31:23.997912 126720 solver.cpp:252]     Train net output #1: loss = 0.00188889 (* 1 = 0.00188889 loss)
I0711 19:31:23.997925 126720 sgd_solver.cpp:106] Iteration 207000, lr = 0.001
I0711 19:33:50.949107 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 19:36:43.370872 126720 solver.cpp:236] Iteration 207100, loss = 0.00567477
I0711 19:36:43.371062 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 19:36:43.371085 126720 solver.cpp:252]     Train net output #1: loss = 0.00514059 (* 1 = 0.00514059 loss)
I0711 19:36:43.371098 126720 sgd_solver.cpp:106] Iteration 207100, lr = 0.001
I0711 19:42:31.933388 126720 solver.cpp:236] Iteration 207200, loss = 0.00533459
I0711 19:42:31.933579 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 19:42:31.933610 126720 solver.cpp:252]     Train net output #1: loss = 0.0229775 (* 1 = 0.0229775 loss)
I0711 19:42:31.933629 126720 sgd_solver.cpp:106] Iteration 207200, lr = 0.001
I0711 19:45:27.054689 126720 solver.cpp:340] Iteration 207250, Testing net (#0)
I0711 19:47:52.973670 126720 solver.cpp:408]     Test net output #0: accuracy = 0.994
I0711 19:47:52.973824 126720 solver.cpp:408]     Test net output #1: loss = 0.018825 (* 1 = 0.018825 loss)
I0711 19:50:44.713053 126720 solver.cpp:236] Iteration 207300, loss = 0.00972009
I0711 19:50:44.713222 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 19:50:44.713243 126720 solver.cpp:252]     Train net output #1: loss = 0.00300497 (* 1 = 0.00300497 loss)
I0711 19:50:44.713253 126720 sgd_solver.cpp:106] Iteration 207300, lr = 0.001
I0711 19:56:42.680848 126720 solver.cpp:236] Iteration 207400, loss = 0.0105322
I0711 19:56:42.681080 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 19:56:42.681108 126720 solver.cpp:252]     Train net output #1: loss = 0.00183465 (* 1 = 0.00183465 loss)
I0711 19:56:42.681120 126720 sgd_solver.cpp:106] Iteration 207400, lr = 0.001
I0711 20:02:41.781865 126720 solver.cpp:340] Iteration 207500, Testing net (#0)
I0711 20:05:08.809650 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9978
I0711 20:05:08.809777 126720 solver.cpp:408]     Test net output #1: loss = 0.00654703 (* 1 = 0.00654703 loss)
I0711 20:05:09.000906 126720 solver.cpp:236] Iteration 207500, loss = 0.015644
I0711 20:05:09.000962 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 20:05:09.000977 126720 solver.cpp:252]     Train net output #1: loss = 0.0162537 (* 1 = 0.0162537 loss)
I0711 20:05:09.000989 126720 sgd_solver.cpp:106] Iteration 207500, lr = 0.001
I0711 20:11:05.745652 126720 solver.cpp:236] Iteration 207600, loss = 0.00952609
I0711 20:11:05.745851 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 20:11:05.745887 126720 solver.cpp:252]     Train net output #1: loss = 0.00627147 (* 1 = 0.00627147 loss)
I0711 20:11:05.745903 126720 sgd_solver.cpp:106] Iteration 207600, lr = 0.001
I0711 20:17:10.780053 126720 solver.cpp:236] Iteration 207700, loss = 0.00936105
I0711 20:17:10.780194 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 20:17:10.780243 126720 solver.cpp:252]     Train net output #1: loss = 0.00648177 (* 1 = 0.00648177 loss)
I0711 20:17:10.780267 126720 sgd_solver.cpp:106] Iteration 207700, lr = 0.001
I0711 20:20:07.875033 126720 solver.cpp:340] Iteration 207750, Testing net (#0)
I0711 20:22:23.106963 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9973
I0711 20:22:23.107170 126720 solver.cpp:408]     Test net output #1: loss = 0.00858989 (* 1 = 0.00858989 loss)
I0711 20:23:15.239220 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 20:25:22.684247 126720 solver.cpp:236] Iteration 207800, loss = 0.00747536
I0711 20:25:22.684438 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 20:25:22.684469 126720 solver.cpp:252]     Train net output #1: loss = 0.0227844 (* 1 = 0.0227844 loss)
I0711 20:25:22.684486 126720 sgd_solver.cpp:106] Iteration 207800, lr = 0.001
I0711 20:31:40.503512 126720 solver.cpp:236] Iteration 207900, loss = 0.0107158
I0711 20:31:40.503660 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 20:31:40.503710 126720 solver.cpp:252]     Train net output #1: loss = 0.0213166 (* 1 = 0.0213166 loss)
I0711 20:31:40.503722 126720 sgd_solver.cpp:106] Iteration 207900, lr = 0.001
I0711 20:37:58.335198 126720 solver.cpp:340] Iteration 208000, Testing net (#0)
I0711 20:40:17.788404 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9961
I0711 20:40:17.788664 126720 solver.cpp:408]     Test net output #1: loss = 0.0131469 (* 1 = 0.0131469 loss)
I0711 20:40:18.034991 126720 solver.cpp:236] Iteration 208000, loss = 0.00846504
I0711 20:40:18.035042 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 20:40:18.035055 126720 solver.cpp:252]     Train net output #1: loss = 0.00366571 (* 1 = 0.00366571 loss)
I0711 20:40:18.035066 126720 sgd_solver.cpp:106] Iteration 208000, lr = 0.001
I0711 20:46:35.086700 126720 solver.cpp:236] Iteration 208100, loss = 0.0142742
I0711 20:46:35.086911 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 20:46:35.086931 126720 solver.cpp:252]     Train net output #1: loss = 0.00152107 (* 1 = 0.00152107 loss)
I0711 20:46:35.086943 126720 sgd_solver.cpp:106] Iteration 208100, lr = 0.001
I0711 20:52:56.020862 126720 solver.cpp:236] Iteration 208200, loss = 0.00786977
I0711 20:52:56.021013 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 20:52:56.021044 126720 solver.cpp:252]     Train net output #1: loss = 0.00193638 (* 1 = 0.00193638 loss)
I0711 20:52:56.021067 126720 sgd_solver.cpp:106] Iteration 208200, lr = 0.001
I0711 20:56:02.353852 126720 solver.cpp:340] Iteration 208250, Testing net (#0)
I0711 20:58:19.612848 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9962
I0711 20:58:19.613010 126720 solver.cpp:408]     Test net output #1: loss = 0.0133155 (* 1 = 0.0133155 loss)
I0711 21:01:23.038292 126720 solver.cpp:236] Iteration 208300, loss = 0.011344
I0711 21:01:23.038589 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:01:23.038614 126720 solver.cpp:252]     Train net output #1: loss = 0.00469807 (* 1 = 0.00469807 loss)
I0711 21:01:23.038625 126720 sgd_solver.cpp:106] Iteration 208300, lr = 0.001
I0711 21:07:30.323256 126720 solver.cpp:236] Iteration 208400, loss = 0.0119092
I0711 21:07:30.323504 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:07:30.323539 126720 solver.cpp:252]     Train net output #1: loss = 0.00299426 (* 1 = 0.00299426 loss)
I0711 21:07:30.323549 126720 sgd_solver.cpp:106] Iteration 208400, lr = 0.001
I0711 21:12:50.514194 126720 solver.cpp:340] Iteration 208500, Testing net (#0)
I0711 21:14:40.951275 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 21:15:06.757563 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9983
I0711 21:15:06.757638 126720 solver.cpp:408]     Test net output #1: loss = 0.00755234 (* 1 = 0.00755234 loss)
I0711 21:15:06.920666 126720 solver.cpp:236] Iteration 208500, loss = 0.0103862
I0711 21:15:06.920722 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:15:06.920737 126720 solver.cpp:252]     Train net output #1: loss = 0.00507514 (* 1 = 0.00507514 loss)
I0711 21:15:06.920749 126720 sgd_solver.cpp:106] Iteration 208500, lr = 0.001
I0711 21:20:50.485075 126720 solver.cpp:236] Iteration 208600, loss = 0.0085658
I0711 21:20:50.485226 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:20:50.485268 126720 solver.cpp:252]     Train net output #1: loss = 0.00537101 (* 1 = 0.00537101 loss)
I0711 21:20:50.485280 126720 sgd_solver.cpp:106] Iteration 208600, lr = 0.001
I0711 21:26:40.683305 126720 solver.cpp:236] Iteration 208700, loss = 0.00768622
I0711 21:26:40.683511 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 21:26:40.683544 126720 solver.cpp:252]     Train net output #1: loss = 0.0139202 (* 1 = 0.0139202 loss)
I0711 21:26:40.683557 126720 sgd_solver.cpp:106] Iteration 208700, lr = 0.001
I0711 21:29:37.106170 126720 solver.cpp:340] Iteration 208750, Testing net (#0)
I0711 21:31:47.595780 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9965
I0711 21:31:47.596022 126720 solver.cpp:408]     Test net output #1: loss = 0.0097947 (* 1 = 0.0097947 loss)
I0711 21:34:40.176959 126720 solver.cpp:236] Iteration 208800, loss = 0.00623269
I0711 21:34:40.177134 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:34:40.177168 126720 solver.cpp:252]     Train net output #1: loss = 0.00241666 (* 1 = 0.00241666 loss)
I0711 21:34:40.177187 126720 sgd_solver.cpp:106] Iteration 208800, lr = 0.001
I0711 21:40:40.050274 126720 solver.cpp:236] Iteration 208900, loss = 0.0149339
I0711 21:40:40.050566 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:40:40.050606 126720 solver.cpp:252]     Train net output #1: loss = 0.00533126 (* 1 = 0.00533126 loss)
I0711 21:40:40.050626 126720 sgd_solver.cpp:106] Iteration 208900, lr = 0.001
I0711 21:46:38.104899 126720 solver.cpp:340] Iteration 209000, Testing net (#0)
I0711 21:48:56.499150 126720 solver.cpp:408]     Test net output #0: accuracy = 0.998
I0711 21:48:56.499354 126720 solver.cpp:408]     Test net output #1: loss = 0.00720631 (* 1 = 0.00720631 loss)
I0711 21:48:56.823329 126720 solver.cpp:236] Iteration 209000, loss = 0.0094707
I0711 21:48:56.823375 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 21:48:56.823390 126720 solver.cpp:252]     Train net output #1: loss = 0.00977822 (* 1 = 0.00977822 loss)
I0711 21:48:56.823413 126720 sgd_solver.cpp:106] Iteration 209000, lr = 0.001
I0711 21:54:54.600961 126720 solver.cpp:236] Iteration 209100, loss = 0.00645902
I0711 21:54:54.601210 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 21:54:54.601232 126720 solver.cpp:252]     Train net output #1: loss = 0.00154032 (* 1 = 0.00154032 loss)
I0711 21:54:54.601243 126720 sgd_solver.cpp:106] Iteration 209100, lr = 0.001
I0711 22:01:14.178155 126720 solver.cpp:236] Iteration 209200, loss = 0.00913142
I0711 22:01:14.178465 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 22:01:14.178489 126720 solver.cpp:252]     Train net output #1: loss = 0.0106622 (* 1 = 0.0106622 loss)
I0711 22:01:14.178500 126720 sgd_solver.cpp:106] Iteration 209200, lr = 0.001
I0711 22:04:19.551059 126720 solver.cpp:340] Iteration 209250, Testing net (#0)
I0711 22:05:22.598675 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 22:06:34.859117 126720 solver.cpp:408]     Test net output #0: accuracy = 0.996
I0711 22:06:34.859307 126720 solver.cpp:408]     Test net output #1: loss = 0.0156164 (* 1 = 0.0156164 loss)
I0711 22:09:37.092037 126720 solver.cpp:236] Iteration 209300, loss = 0.019082
I0711 22:09:37.092257 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 22:09:37.092303 126720 solver.cpp:252]     Train net output #1: loss = 0.00242041 (* 1 = 0.00242041 loss)
I0711 22:09:37.092316 126720 sgd_solver.cpp:106] Iteration 209300, lr = 0.001
I0711 22:16:01.937520 126720 solver.cpp:236] Iteration 209400, loss = 0.00902156
I0711 22:16:01.937798 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 22:16:01.937819 126720 solver.cpp:252]     Train net output #1: loss = 0.00359682 (* 1 = 0.00359682 loss)
I0711 22:16:01.937831 126720 sgd_solver.cpp:106] Iteration 209400, lr = 0.001
I0711 22:22:19.647150 126720 solver.cpp:340] Iteration 209500, Testing net (#0)
I0711 22:25:16.769888 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9969
I0711 22:25:16.770211 126720 solver.cpp:408]     Test net output #1: loss = 0.0107607 (* 1 = 0.0107607 loss)
I0711 22:25:16.908968 126720 solver.cpp:236] Iteration 209500, loss = 0.0130961
I0711 22:25:16.909006 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 22:25:16.909025 126720 solver.cpp:252]     Train net output #1: loss = 0.0018968 (* 1 = 0.0018968 loss)
I0711 22:25:16.909036 126720 sgd_solver.cpp:106] Iteration 209500, lr = 0.001
I0711 22:31:36.734282 126720 solver.cpp:236] Iteration 209600, loss = 0.0147467
I0711 22:31:36.742682 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 22:31:36.742705 126720 solver.cpp:252]     Train net output #1: loss = 0.00213339 (* 1 = 0.00213339 loss)
I0711 22:31:36.742717 126720 sgd_solver.cpp:106] Iteration 209600, lr = 0.001
I0711 22:37:58.804142 126720 solver.cpp:236] Iteration 209700, loss = 0.0101157
I0711 22:37:58.804278 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 22:37:58.804299 126720 solver.cpp:252]     Train net output #1: loss = 0.0237175 (* 1 = 0.0237175 loss)
I0711 22:37:58.804322 126720 sgd_solver.cpp:106] Iteration 209700, lr = 0.001
I0711 22:41:06.994699 126720 solver.cpp:340] Iteration 209750, Testing net (#0)
I0711 22:43:41.390719 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9971
I0711 22:43:41.390889 126720 solver.cpp:408]     Test net output #1: loss = 0.00800369 (* 1 = 0.00800369 loss)
I0711 22:47:02.155236 126720 solver.cpp:236] Iteration 209800, loss = 0.00691171
I0711 22:47:02.155436 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 22:47:02.155467 126720 solver.cpp:252]     Train net output #1: loss = 0.0118675 (* 1 = 0.0118675 loss)
I0711 22:47:02.155478 126720 sgd_solver.cpp:106] Iteration 209800, lr = 0.001
I0711 22:53:28.161211 126720 solver.cpp:236] Iteration 209900, loss = 0.0120701
I0711 22:53:28.161327 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 22:53:28.161346 126720 solver.cpp:252]     Train net output #1: loss = 0.0188931 (* 1 = 0.0188931 loss)
I0711 22:53:28.161353 126720 sgd_solver.cpp:106] Iteration 209900, lr = 0.001
I0711 22:59:12.759660 126720 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_210000.caffemodel
I0711 22:59:13.996742 126720 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_210000.solverstate
I0711 22:59:14.053865 126720 solver.cpp:340] Iteration 210000, Testing net (#0)
I0711 22:59:41.150040 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0711 23:02:11.494361 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9966
I0711 23:02:11.494607 126720 solver.cpp:408]     Test net output #1: loss = 0.0115605 (* 1 = 0.0115605 loss)
I0711 23:02:11.690448 126720 solver.cpp:236] Iteration 210000, loss = 0.00775034
I0711 23:02:11.690516 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 23:02:11.690546 126720 solver.cpp:252]     Train net output #1: loss = 0.00219192 (* 1 = 0.00219192 loss)
I0711 23:02:11.690569 126720 sgd_solver.cpp:106] Iteration 210000, lr = 0.001
I0711 23:09:26.565068 126720 solver.cpp:236] Iteration 210100, loss = 0.0109956
I0711 23:09:26.565366 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 23:09:26.565390 126720 solver.cpp:252]     Train net output #1: loss = 0.010819 (* 1 = 0.010819 loss)
I0711 23:09:26.565402 126720 sgd_solver.cpp:106] Iteration 210100, lr = 0.001
I0711 23:17:02.905834 126720 solver.cpp:236] Iteration 210200, loss = 0.0184384
I0711 23:17:02.905966 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 23:17:02.905997 126720 solver.cpp:252]     Train net output #1: loss = 0.00200152 (* 1 = 0.00200152 loss)
I0711 23:17:02.906008 126720 sgd_solver.cpp:106] Iteration 210200, lr = 0.001
I0711 23:20:47.389055 126720 solver.cpp:340] Iteration 210250, Testing net (#0)
I0711 23:24:17.958245 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9973
I0711 23:24:17.958413 126720 solver.cpp:408]     Test net output #1: loss = 0.00949666 (* 1 = 0.00949666 loss)
I0711 23:27:59.264401 126720 solver.cpp:236] Iteration 210300, loss = 0.00998174
I0711 23:27:59.264556 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 23:27:59.264611 126720 solver.cpp:252]     Train net output #1: loss = 0.0105651 (* 1 = 0.0105651 loss)
I0711 23:27:59.264626 126720 sgd_solver.cpp:106] Iteration 210300, lr = 0.001
I0711 23:35:41.314074 126720 solver.cpp:236] Iteration 210400, loss = 0.00644096
I0711 23:35:41.314304 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0711 23:35:41.314326 126720 solver.cpp:252]     Train net output #1: loss = 0.00122086 (* 1 = 0.00122086 loss)
I0711 23:35:41.314337 126720 sgd_solver.cpp:106] Iteration 210400, lr = 0.001
I0711 23:43:29.792243 126720 solver.cpp:340] Iteration 210500, Testing net (#0)
I0711 23:47:23.348394 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I0711 23:47:23.348546 126720 solver.cpp:408]     Test net output #1: loss = 0.0109127 (* 1 = 0.0109127 loss)
I0711 23:47:23.491973 126720 solver.cpp:236] Iteration 210500, loss = 0.0127369
I0711 23:47:23.492033 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 23:47:23.492051 126720 solver.cpp:252]     Train net output #1: loss = 0.0537219 (* 1 = 0.0537219 loss)
I0711 23:47:23.492063 126720 sgd_solver.cpp:106] Iteration 210500, lr = 0.001
I0711 23:55:09.269947 126720 solver.cpp:236] Iteration 210600, loss = 0.0104154
I0711 23:55:09.270217 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0711 23:55:09.270279 126720 solver.cpp:252]     Train net output #1: loss = 0.0132409 (* 1 = 0.0132409 loss)
I0711 23:55:09.270330 126720 sgd_solver.cpp:106] Iteration 210600, lr = 0.001
I0712 00:02:59.928391 126720 solver.cpp:236] Iteration 210700, loss = 0.0132546
I0712 00:02:59.928573 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 00:02:59.928611 126720 solver.cpp:252]     Train net output #1: loss = 0.0330045 (* 1 = 0.0330045 loss)
I0712 00:02:59.928622 126720 sgd_solver.cpp:106] Iteration 210700, lr = 0.001
I0712 00:05:30.762574 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 00:06:51.741984 126720 solver.cpp:340] Iteration 210750, Testing net (#0)
I0712 00:10:15.334934 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9975
I0712 00:10:15.335127 126720 solver.cpp:408]     Test net output #1: loss = 0.00731778 (* 1 = 0.00731778 loss)
I0712 00:14:01.675695 126720 solver.cpp:236] Iteration 210800, loss = 0.0146624
I0712 00:14:01.675864 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0712 00:14:01.675896 126720 solver.cpp:252]     Train net output #1: loss = 0.0740186 (* 1 = 0.0740186 loss)
I0712 00:14:01.675909 126720 sgd_solver.cpp:106] Iteration 210800, lr = 0.001
I0712 00:21:45.222859 126720 solver.cpp:236] Iteration 210900, loss = 0.0123265
I0712 00:21:45.223016 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 00:21:45.223059 126720 solver.cpp:252]     Train net output #1: loss = 0.00566848 (* 1 = 0.00566848 loss)
I0712 00:21:45.223075 126720 sgd_solver.cpp:106] Iteration 210900, lr = 0.001
I0712 00:29:19.706499 126720 solver.cpp:340] Iteration 211000, Testing net (#0)
I0712 00:32:51.612141 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9965
I0712 00:32:51.612998 126720 solver.cpp:408]     Test net output #1: loss = 0.0102445 (* 1 = 0.0102445 loss)
I0712 00:32:51.777798 126720 solver.cpp:236] Iteration 211000, loss = 0.0200246
I0712 00:32:51.777850 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 00:32:51.777865 126720 solver.cpp:252]     Train net output #1: loss = 0.0181473 (* 1 = 0.0181473 loss)
I0712 00:32:51.777875 126720 sgd_solver.cpp:106] Iteration 211000, lr = 0.001
I0712 00:40:27.865813 126720 solver.cpp:236] Iteration 211100, loss = 0.0118955
I0712 00:40:27.865922 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 00:40:27.865942 126720 solver.cpp:252]     Train net output #1: loss = 0.00174046 (* 1 = 0.00174046 loss)
I0712 00:40:27.865969 126720 sgd_solver.cpp:106] Iteration 211100, lr = 0.001
I0712 00:48:14.303376 126720 solver.cpp:236] Iteration 211200, loss = 0.00914095
I0712 00:48:14.303706 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0712 00:48:14.303755 126720 solver.cpp:252]     Train net output #1: loss = 0.0295201 (* 1 = 0.0295201 loss)
I0712 00:48:14.303788 126720 sgd_solver.cpp:106] Iteration 211200, lr = 0.001
I0712 00:51:38.771967 126720 solver.cpp:340] Iteration 211250, Testing net (#0)
I0712 00:54:59.000428 126720 solver.cpp:408]     Test net output #0: accuracy = 0.995
I0712 00:54:59.000579 126720 solver.cpp:408]     Test net output #1: loss = 0.0142278 (* 1 = 0.0142278 loss)
I0712 00:58:23.014839 126720 solver.cpp:236] Iteration 211300, loss = 0.0110245
I0712 00:58:23.014972 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 00:58:23.015004 126720 solver.cpp:252]     Train net output #1: loss = 0.0462851 (* 1 = 0.0462851 loss)
I0712 00:58:23.015019 126720 sgd_solver.cpp:106] Iteration 211300, lr = 0.001
I0712 01:05:47.561460 126720 solver.cpp:236] Iteration 211400, loss = 0.0102861
I0712 01:05:47.561666 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 01:05:47.561697 126720 solver.cpp:252]     Train net output #1: loss = 0.00177761 (* 1 = 0.00177761 loss)
I0712 01:05:47.561714 126720 sgd_solver.cpp:106] Iteration 211400, lr = 0.001
I0712 01:09:33.292932 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 01:13:11.212472 126720 solver.cpp:340] Iteration 211500, Testing net (#0)
I0712 01:16:35.331578 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9976
I0712 01:16:35.331843 126720 solver.cpp:408]     Test net output #1: loss = 0.00683078 (* 1 = 0.00683078 loss)
I0712 01:16:35.509115 126720 solver.cpp:236] Iteration 211500, loss = 0.0138479
I0712 01:16:35.509153 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 01:16:35.509168 126720 solver.cpp:252]     Train net output #1: loss = 0.00125222 (* 1 = 0.00125222 loss)
I0712 01:16:35.509178 126720 sgd_solver.cpp:106] Iteration 211500, lr = 0.001
I0712 01:24:04.651654 126720 solver.cpp:236] Iteration 211600, loss = 0.0123622
I0712 01:24:04.651840 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 01:24:04.651873 126720 solver.cpp:252]     Train net output #1: loss = 0.00221184 (* 1 = 0.00221184 loss)
I0712 01:24:04.651885 126720 sgd_solver.cpp:106] Iteration 211600, lr = 0.001
I0712 01:31:40.235440 126720 solver.cpp:236] Iteration 211700, loss = 0.0155512
I0712 01:31:40.235685 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0712 01:31:40.235723 126720 solver.cpp:252]     Train net output #1: loss = 0.0965271 (* 1 = 0.0965271 loss)
I0712 01:31:40.235749 126720 sgd_solver.cpp:106] Iteration 211700, lr = 0.001
I0712 01:35:24.950917 126720 solver.cpp:340] Iteration 211750, Testing net (#0)
I0712 01:38:25.610669 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9972
I0712 01:38:25.610867 126720 solver.cpp:408]     Test net output #1: loss = 0.00840796 (* 1 = 0.00840796 loss)
I0712 01:42:08.936056 126720 solver.cpp:236] Iteration 211800, loss = 0.00734614
I0712 01:42:08.936230 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 01:42:08.936264 126720 solver.cpp:252]     Train net output #1: loss = 0.00214338 (* 1 = 0.00214338 loss)
I0712 01:42:08.936276 126720 sgd_solver.cpp:106] Iteration 211800, lr = 0.001
I0712 01:49:52.876449 126720 solver.cpp:236] Iteration 211900, loss = 0.00912503
I0712 01:49:52.876605 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 01:49:52.876643 126720 solver.cpp:252]     Train net output #1: loss = 0.00689084 (* 1 = 0.00689084 loss)
I0712 01:49:52.876662 126720 sgd_solver.cpp:106] Iteration 211900, lr = 0.001
I0712 01:57:32.927426 126720 solver.cpp:340] Iteration 212000, Testing net (#0)
I0712 02:00:43.596752 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9943
I0712 02:00:43.596889 126720 solver.cpp:408]     Test net output #1: loss = 0.0175029 (* 1 = 0.0175029 loss)
I0712 02:00:43.798813 126720 solver.cpp:236] Iteration 212000, loss = 0.0103517
I0712 02:00:43.798853 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0712 02:00:43.798869 126720 solver.cpp:252]     Train net output #1: loss = 0.0719746 (* 1 = 0.0719746 loss)
I0712 02:00:43.798880 126720 sgd_solver.cpp:106] Iteration 212000, lr = 0.001
I0712 02:08:25.641211 126720 solver.cpp:236] Iteration 212100, loss = 0.0162535
I0712 02:08:25.641383 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 02:08:25.641428 126720 solver.cpp:252]     Train net output #1: loss = 0.00496561 (* 1 = 0.00496561 loss)
I0712 02:08:25.641450 126720 sgd_solver.cpp:106] Iteration 212100, lr = 0.001
I0712 02:13:42.195855 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 02:16:13.634954 126720 solver.cpp:236] Iteration 212200, loss = 0.0126906
I0712 02:16:13.635139 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 02:16:13.635195 126720 solver.cpp:252]     Train net output #1: loss = 0.00617311 (* 1 = 0.00617311 loss)
I0712 02:16:13.635221 126720 sgd_solver.cpp:106] Iteration 212200, lr = 0.001
I0712 02:20:01.905817 126720 solver.cpp:340] Iteration 212250, Testing net (#0)
I0712 02:22:56.622395 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9976
I0712 02:22:56.624176 126720 solver.cpp:408]     Test net output #1: loss = 0.00831811 (* 1 = 0.00831811 loss)
I0712 02:26:41.031523 126720 solver.cpp:236] Iteration 212300, loss = 0.0126253
I0712 02:26:41.031649 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 02:26:41.031680 126720 solver.cpp:252]     Train net output #1: loss = 0.00332083 (* 1 = 0.00332083 loss)
I0712 02:26:41.031697 126720 sgd_solver.cpp:106] Iteration 212300, lr = 0.001
I0712 02:34:25.426898 126720 solver.cpp:236] Iteration 212400, loss = 0.0112794
I0712 02:34:25.427090 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 02:34:25.427111 126720 solver.cpp:252]     Train net output #1: loss = 0.0039071 (* 1 = 0.0039071 loss)
I0712 02:34:25.427124 126720 sgd_solver.cpp:106] Iteration 212400, lr = 0.001
I0712 02:42:03.419668 126720 solver.cpp:340] Iteration 212500, Testing net (#0)
I0712 02:44:54.728802 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9971
I0712 02:44:54.729034 126720 solver.cpp:408]     Test net output #1: loss = 0.0082066 (* 1 = 0.0082066 loss)
I0712 02:44:55.272647 126720 solver.cpp:236] Iteration 212500, loss = 0.0104851
I0712 02:44:55.272696 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 02:44:55.272711 126720 solver.cpp:252]     Train net output #1: loss = 0.00425619 (* 1 = 0.00425619 loss)
I0712 02:44:55.272721 126720 sgd_solver.cpp:106] Iteration 212500, lr = 0.001
I0712 02:52:29.922933 126720 solver.cpp:236] Iteration 212600, loss = 0.0146741
I0712 02:52:29.923157 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 02:52:29.923190 126720 solver.cpp:252]     Train net output #1: loss = 0.0208699 (* 1 = 0.0208699 loss)
I0712 02:52:29.923203 126720 sgd_solver.cpp:106] Iteration 212600, lr = 0.001
I0712 02:59:27.400830 126720 solver.cpp:236] Iteration 212700, loss = 0.03884
I0712 02:59:27.400974 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 02:59:27.401017 126720 solver.cpp:252]     Train net output #1: loss = 0.0144128 (* 1 = 0.0144128 loss)
I0712 02:59:27.401036 126720 sgd_solver.cpp:106] Iteration 212700, lr = 0.001
I0712 03:02:58.327379 126720 solver.cpp:340] Iteration 212750, Testing net (#0)
I0712 03:05:40.019230 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9899
I0712 03:05:40.019489 126720 solver.cpp:408]     Test net output #1: loss = 0.0280875 (* 1 = 0.0280875 loss)
I0712 03:09:19.495698 126720 solver.cpp:236] Iteration 212800, loss = 0.0146742
I0712 03:09:19.495913 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 03:09:19.495935 126720 solver.cpp:252]     Train net output #1: loss = 0.00474351 (* 1 = 0.00474351 loss)
I0712 03:09:19.495946 126720 sgd_solver.cpp:106] Iteration 212800, lr = 0.001
I0712 03:15:45.652675 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 03:16:48.452455 126720 solver.cpp:236] Iteration 212900, loss = 0.00959422
I0712 03:16:48.452620 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 03:16:48.452680 126720 solver.cpp:252]     Train net output #1: loss = 0.0189941 (* 1 = 0.0189941 loss)
I0712 03:16:48.452698 126720 sgd_solver.cpp:106] Iteration 212900, lr = 0.001
I0712 03:24:14.886682 126720 solver.cpp:340] Iteration 213000, Testing net (#0)
I0712 03:27:29.579429 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9983
I0712 03:27:29.579599 126720 solver.cpp:408]     Test net output #1: loss = 0.00732795 (* 1 = 0.00732795 loss)
I0712 03:27:29.718170 126720 solver.cpp:236] Iteration 213000, loss = 0.00882476
I0712 03:27:29.718230 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 03:27:29.718255 126720 solver.cpp:252]     Train net output #1: loss = 0.0073002 (* 1 = 0.0073002 loss)
I0712 03:27:29.718278 126720 sgd_solver.cpp:106] Iteration 213000, lr = 0.001
I0712 03:35:00.081768 126720 solver.cpp:236] Iteration 213100, loss = 0.0152956
I0712 03:35:00.081931 126720 solver.cpp:252]     Train net output #0: accuracy = 0.96875
I0712 03:35:00.081984 126720 solver.cpp:252]     Train net output #1: loss = 0.06572 (* 1 = 0.06572 loss)
I0712 03:35:00.082002 126720 sgd_solver.cpp:106] Iteration 213100, lr = 0.001
I0712 03:42:39.037945 126720 solver.cpp:236] Iteration 213200, loss = 0.00804337
I0712 03:42:39.038172 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 03:42:39.038219 126720 solver.cpp:252]     Train net output #1: loss = 0.00305129 (* 1 = 0.00305129 loss)
I0712 03:42:39.038244 126720 sgd_solver.cpp:106] Iteration 213200, lr = 0.001
I0712 03:46:20.613613 126720 solver.cpp:340] Iteration 213250, Testing net (#0)
I0712 03:49:31.399588 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9973
I0712 03:49:31.399837 126720 solver.cpp:408]     Test net output #1: loss = 0.00769991 (* 1 = 0.00769991 loss)
I0712 03:53:14.631559 126720 solver.cpp:236] Iteration 213300, loss = 0.0102039
I0712 03:53:14.631734 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 03:53:14.631769 126720 solver.cpp:252]     Train net output #1: loss = 0.00132885 (* 1 = 0.00132885 loss)
I0712 03:53:14.631783 126720 sgd_solver.cpp:106] Iteration 213300, lr = 0.001
I0712 04:00:57.707000 126720 solver.cpp:236] Iteration 213400, loss = 0.00750718
I0712 04:00:57.707201 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0712 04:00:57.707231 126720 solver.cpp:252]     Train net output #1: loss = 0.014858 (* 1 = 0.014858 loss)
I0712 04:00:57.707240 126720 sgd_solver.cpp:106] Iteration 213400, lr = 0.001
I0712 04:08:35.196280 126720 solver.cpp:340] Iteration 213500, Testing net (#0)
I0712 04:11:55.475152 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I0712 04:11:55.475329 126720 solver.cpp:408]     Test net output #1: loss = 0.0107469 (* 1 = 0.0107469 loss)
I0712 04:11:55.746119 126720 solver.cpp:236] Iteration 213500, loss = 0.0104625
I0712 04:11:55.746162 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 04:11:55.746177 126720 solver.cpp:252]     Train net output #1: loss = 0.00230495 (* 1 = 0.00230495 loss)
I0712 04:11:55.746188 126720 sgd_solver.cpp:106] Iteration 213500, lr = 0.001
I0712 04:19:34.508116 126720 solver.cpp:236] Iteration 213600, loss = 0.011543
I0712 04:19:34.508312 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 04:19:34.508355 126720 solver.cpp:252]     Train net output #1: loss = 0.00468541 (* 1 = 0.00468541 loss)
I0712 04:19:34.508366 126720 sgd_solver.cpp:106] Iteration 213600, lr = 0.001
I0712 04:19:53.700165 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 04:27:33.644299 126720 solver.cpp:236] Iteration 213700, loss = 0.00955541
I0712 04:27:33.644425 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 04:27:33.644457 126720 solver.cpp:252]     Train net output #1: loss = 0.00189949 (* 1 = 0.00189949 loss)
I0712 04:27:33.644470 126720 sgd_solver.cpp:106] Iteration 213700, lr = 0.001
I0712 04:31:26.118254 126720 solver.cpp:340] Iteration 213750, Testing net (#0)
I0712 04:34:34.405306 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9979
I0712 04:34:34.405439 126720 solver.cpp:408]     Test net output #1: loss = 0.00715966 (* 1 = 0.00715966 loss)
I0712 04:38:21.938359 126720 solver.cpp:236] Iteration 213800, loss = 0.0233731
I0712 04:38:21.938524 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 04:38:21.938544 126720 solver.cpp:252]     Train net output #1: loss = 0.0273923 (* 1 = 0.0273923 loss)
I0712 04:38:21.938565 126720 sgd_solver.cpp:106] Iteration 213800, lr = 0.001
I0712 04:46:11.415036 126720 solver.cpp:236] Iteration 213900, loss = 0.0119207
I0712 04:46:11.415163 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 04:46:11.415207 126720 solver.cpp:252]     Train net output #1: loss = 0.0111465 (* 1 = 0.0111465 loss)
I0712 04:46:11.415222 126720 sgd_solver.cpp:106] Iteration 213900, lr = 0.001
I0712 04:53:56.201638 126720 solver.cpp:340] Iteration 214000, Testing net (#0)
I0712 04:57:34.344205 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9976
I0712 04:57:34.344384 126720 solver.cpp:408]     Test net output #1: loss = 0.00978278 (* 1 = 0.00978278 loss)
I0712 04:57:34.482548 126720 solver.cpp:236] Iteration 214000, loss = 0.0110309
I0712 04:57:34.482602 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 04:57:34.482619 126720 solver.cpp:252]     Train net output #1: loss = 0.00234868 (* 1 = 0.00234868 loss)
I0712 04:57:34.482635 126720 sgd_solver.cpp:106] Iteration 214000, lr = 0.001
I0712 05:04:31.384713 126720 solver.cpp:236] Iteration 214100, loss = 0.0104131
I0712 05:04:31.384856 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 05:04:31.384899 126720 solver.cpp:252]     Train net output #1: loss = 0.00434364 (* 1 = 0.00434364 loss)
I0712 05:04:31.384914 126720 sgd_solver.cpp:106] Iteration 214100, lr = 0.001
I0712 05:11:56.665076 126720 solver.cpp:236] Iteration 214200, loss = 0.0110152
I0712 05:11:56.665271 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 05:11:56.665307 126720 solver.cpp:252]     Train net output #1: loss = 0.0432797 (* 1 = 0.0432797 loss)
I0712 05:11:56.665316 126720 sgd_solver.cpp:106] Iteration 214200, lr = 0.001
I0712 05:15:33.859081 126720 solver.cpp:340] Iteration 214250, Testing net (#0)
I0712 05:18:39.621472 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9964
I0712 05:18:39.621809 126720 solver.cpp:408]     Test net output #1: loss = 0.0112999 (* 1 = 0.0112999 loss)
I0712 05:22:17.443990 126720 solver.cpp:236] Iteration 214300, loss = 0.0117053
I0712 05:22:17.444206 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 05:22:17.444228 126720 solver.cpp:252]     Train net output #1: loss = 0.0024355 (* 1 = 0.0024355 loss)
I0712 05:22:17.444239 126720 sgd_solver.cpp:106] Iteration 214300, lr = 0.001
I0712 05:23:56.294765 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 05:29:48.336132 126720 solver.cpp:236] Iteration 214400, loss = 0.0173548
I0712 05:29:48.336274 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 05:29:48.336323 126720 solver.cpp:252]     Train net output #1: loss = 0.00979779 (* 1 = 0.00979779 loss)
I0712 05:29:48.336335 126720 sgd_solver.cpp:106] Iteration 214400, lr = 0.001
I0712 05:37:12.423543 126720 solver.cpp:340] Iteration 214500, Testing net (#0)
I0712 05:40:25.618541 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I0712 05:40:25.618698 126720 solver.cpp:408]     Test net output #1: loss = 0.0170141 (* 1 = 0.0170141 loss)
I0712 05:40:25.962754 126720 solver.cpp:236] Iteration 214500, loss = 0.0142624
I0712 05:40:25.962801 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 05:40:25.962816 126720 solver.cpp:252]     Train net output #1: loss = 0.0142074 (* 1 = 0.0142074 loss)
I0712 05:40:25.962826 126720 sgd_solver.cpp:106] Iteration 214500, lr = 0.001
I0712 05:47:56.815623 126720 solver.cpp:236] Iteration 214600, loss = 0.00946781
I0712 05:47:56.815868 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 05:47:56.815888 126720 solver.cpp:252]     Train net output #1: loss = 0.00897896 (* 1 = 0.00897896 loss)
I0712 05:47:56.815899 126720 sgd_solver.cpp:106] Iteration 214600, lr = 0.001
I0712 05:55:40.713842 126720 solver.cpp:236] Iteration 214700, loss = 0.0154905
I0712 05:55:40.713966 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 05:55:40.713985 126720 solver.cpp:252]     Train net output #1: loss = 0.00215824 (* 1 = 0.00215824 loss)
I0712 05:55:40.714007 126720 sgd_solver.cpp:106] Iteration 214700, lr = 0.001
I0712 05:59:31.362684 126720 solver.cpp:340] Iteration 214750, Testing net (#0)
I0712 06:02:24.027104 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9964
I0712 06:02:24.027365 126720 solver.cpp:408]     Test net output #1: loss = 0.00975775 (* 1 = 0.00975775 loss)
I0712 06:06:07.356814 126720 solver.cpp:236] Iteration 214800, loss = 0.0100377
I0712 06:06:07.356981 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 06:06:07.357019 126720 solver.cpp:252]     Train net output #1: loss = 0.000878683 (* 1 = 0.000878683 loss)
I0712 06:06:07.357035 126720 sgd_solver.cpp:106] Iteration 214800, lr = 0.001
I0712 06:13:50.262940 126720 solver.cpp:236] Iteration 214900, loss = 0.0153498
I0712 06:13:50.263084 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 06:13:50.263119 126720 solver.cpp:252]     Train net output #1: loss = 0.00342746 (* 1 = 0.00342746 loss)
I0712 06:13:50.263139 126720 sgd_solver.cpp:106] Iteration 214900, lr = 0.001
I0712 06:21:30.270916 126720 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_215000.caffemodel
I0712 06:21:31.080617 126720 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_215000.solverstate
I0712 06:21:31.122036 126720 solver.cpp:340] Iteration 215000, Testing net (#0)
I0712 06:24:32.037724 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9942
I0712 06:24:32.037909 126720 solver.cpp:408]     Test net output #1: loss = 0.0218773 (* 1 = 0.0218773 loss)
I0712 06:24:32.285686 126720 solver.cpp:236] Iteration 215000, loss = 0.015022
I0712 06:24:32.285727 126720 solver.cpp:252]     Train net output #0: accuracy = 0.976562
I0712 06:24:32.285744 126720 solver.cpp:252]     Train net output #1: loss = 0.0816463 (* 1 = 0.0816463 loss)
I0712 06:24:32.285754 126720 sgd_solver.cpp:106] Iteration 215000, lr = 0.001
I0712 06:27:28.906519 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 06:33:09.354269 126720 solver.cpp:236] Iteration 215100, loss = 0.0145901
I0712 06:33:09.354430 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 06:33:09.354468 126720 solver.cpp:252]     Train net output #1: loss = 0.00544663 (* 1 = 0.00544663 loss)
I0712 06:33:09.354480 126720 sgd_solver.cpp:106] Iteration 215100, lr = 0.001
I0712 06:41:08.219794 126720 solver.cpp:236] Iteration 215200, loss = 0.0105464
I0712 06:41:08.220067 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 06:41:08.220091 126720 solver.cpp:252]     Train net output #1: loss = 0.0177779 (* 1 = 0.0177779 loss)
I0712 06:41:08.220108 126720 sgd_solver.cpp:106] Iteration 215200, lr = 0.001
I0712 06:44:57.499891 126720 solver.cpp:340] Iteration 215250, Testing net (#0)
I0712 06:47:47.975869 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9981
I0712 06:47:47.976128 126720 solver.cpp:408]     Test net output #1: loss = 0.00622564 (* 1 = 0.00622564 loss)
I0712 06:51:33.963827 126720 solver.cpp:236] Iteration 215300, loss = 0.01331
I0712 06:51:33.964001 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 06:51:33.964035 126720 solver.cpp:252]     Train net output #1: loss = 0.00192668 (* 1 = 0.00192668 loss)
I0712 06:51:33.964046 126720 sgd_solver.cpp:106] Iteration 215300, lr = 0.001
I0712 06:59:19.924510 126720 solver.cpp:236] Iteration 215400, loss = 0.0120958
I0712 06:59:19.924762 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 06:59:19.924785 126720 solver.cpp:252]     Train net output #1: loss = 0.0326918 (* 1 = 0.0326918 loss)
I0712 06:59:19.924798 126720 sgd_solver.cpp:106] Iteration 215400, lr = 0.001
I0712 07:06:15.750537 126720 solver.cpp:340] Iteration 215500, Testing net (#0)
I0712 07:10:09.965482 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9947
I0712 07:10:09.965662 126720 solver.cpp:408]     Test net output #1: loss = 0.0178227 (* 1 = 0.0178227 loss)
I0712 07:10:10.208341 126720 solver.cpp:236] Iteration 215500, loss = 0.0133883
I0712 07:10:10.208395 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 07:10:10.208417 126720 solver.cpp:252]     Train net output #1: loss = 0.0316939 (* 1 = 0.0316939 loss)
I0712 07:10:10.208434 126720 sgd_solver.cpp:106] Iteration 215500, lr = 0.001
I0712 07:17:30.543092 126720 solver.cpp:236] Iteration 215600, loss = 0.0117
I0712 07:17:30.543249 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 07:17:30.543269 126720 solver.cpp:252]     Train net output #1: loss = 0.0017612 (* 1 = 0.0017612 loss)
I0712 07:17:30.543287 126720 sgd_solver.cpp:106] Iteration 215600, lr = 0.001
I0712 07:24:50.913499 126720 solver.cpp:236] Iteration 215700, loss = 0.0130156
I0712 07:24:50.913691 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 07:24:50.913733 126720 solver.cpp:252]     Train net output #1: loss = 0.00385473 (* 1 = 0.00385473 loss)
I0712 07:24:50.913756 126720 sgd_solver.cpp:106] Iteration 215700, lr = 0.001
I0712 07:28:31.613821 126720 solver.cpp:340] Iteration 215750, Testing net (#0)
I0712 07:31:34.871770 126720 solver.cpp:408]     Test net output #0: accuracy = 0.998
I0712 07:31:34.871939 126720 solver.cpp:408]     Test net output #1: loss = 0.0060504 (* 1 = 0.0060504 loss)
I0712 07:32:01.366093 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 07:35:10.481735 126720 solver.cpp:236] Iteration 215800, loss = 0.0090569
I0712 07:35:10.481912 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 07:35:10.481943 126720 solver.cpp:252]     Train net output #1: loss = 0.00217539 (* 1 = 0.00217539 loss)
I0712 07:35:10.481956 126720 sgd_solver.cpp:106] Iteration 215800, lr = 0.001
I0712 07:42:42.614660 126720 solver.cpp:236] Iteration 215900, loss = 0.00703812
I0712 07:42:42.614806 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 07:42:42.614827 126720 solver.cpp:252]     Train net output #1: loss = 0.00509017 (* 1 = 0.00509017 loss)
I0712 07:42:42.614840 126720 sgd_solver.cpp:106] Iteration 215900, lr = 0.001
I0712 07:50:10.208641 126720 solver.cpp:340] Iteration 216000, Testing net (#0)
I0712 07:53:59.375717 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9894
I0712 07:53:59.375903 126720 solver.cpp:408]     Test net output #1: loss = 0.0292967 (* 1 = 0.0292967 loss)
I0712 07:54:00.445160 126720 solver.cpp:236] Iteration 216000, loss = 0.0112978
I0712 07:54:00.445206 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 07:54:00.445221 126720 solver.cpp:252]     Train net output #1: loss = 0.0333401 (* 1 = 0.0333401 loss)
I0712 07:54:00.445232 126720 sgd_solver.cpp:106] Iteration 216000, lr = 0.001
I0712 08:01:31.506781 126720 solver.cpp:236] Iteration 216100, loss = 0.0111222
I0712 08:01:31.506938 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 08:01:31.506971 126720 solver.cpp:252]     Train net output #1: loss = 0.0021112 (* 1 = 0.0021112 loss)
I0712 08:01:31.506994 126720 sgd_solver.cpp:106] Iteration 216100, lr = 0.001
I0712 08:09:20.292644 126720 solver.cpp:236] Iteration 216200, loss = 0.0150522
I0712 08:09:20.292783 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 08:09:20.292803 126720 solver.cpp:252]     Train net output #1: loss = 0.0112377 (* 1 = 0.0112377 loss)
I0712 08:09:20.292845 126720 sgd_solver.cpp:106] Iteration 216200, lr = 0.001
I0712 08:13:09.549726 126720 solver.cpp:340] Iteration 216250, Testing net (#0)
I0712 08:16:26.109985 126720 solver.cpp:408]     Test net output #0: accuracy = 0.995
I0712 08:16:26.110170 126720 solver.cpp:408]     Test net output #1: loss = 0.0147536 (* 1 = 0.0147536 loss)
I0712 08:20:13.501780 126720 solver.cpp:236] Iteration 216300, loss = 0.016246
I0712 08:20:13.501901 126720 solver.cpp:252]     Train net output #0: accuracy = 0.984375
I0712 08:20:13.501932 126720 solver.cpp:252]     Train net output #1: loss = 0.0387945 (* 1 = 0.0387945 loss)
I0712 08:20:13.501945 126720 sgd_solver.cpp:106] Iteration 216300, lr = 0.001
I0712 08:27:43.765456 126720 solver.cpp:236] Iteration 216400, loss = 0.0139061
I0712 08:27:43.765648 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 08:27:43.765681 126720 solver.cpp:252]     Train net output #1: loss = 0.0316157 (* 1 = 0.0316157 loss)
I0712 08:27:43.765693 126720 sgd_solver.cpp:106] Iteration 216400, lr = 0.001
I0712 08:34:03.234236 126720 solver.cpp:340] Iteration 216500, Testing net (#0)
I0712 08:36:15.449316 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 08:37:08.047291 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9974
I0712 08:37:08.047528 126720 solver.cpp:408]     Test net output #1: loss = 0.00827292 (* 1 = 0.00827292 loss)
I0712 08:37:08.256638 126720 solver.cpp:236] Iteration 216500, loss = 0.0245173
I0712 08:37:08.256690 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 08:37:08.256707 126720 solver.cpp:252]     Train net output #1: loss = 0.0016629 (* 1 = 0.0016629 loss)
I0712 08:37:08.256719 126720 sgd_solver.cpp:106] Iteration 216500, lr = 0.001
I0712 08:43:26.616402 126720 solver.cpp:236] Iteration 216600, loss = 0.00910697
I0712 08:43:26.616565 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 08:43:26.616597 126720 solver.cpp:252]     Train net output #1: loss = 0.00773114 (* 1 = 0.00773114 loss)
I0712 08:43:26.616612 126720 sgd_solver.cpp:106] Iteration 216600, lr = 0.001
I0712 08:49:50.176640 126720 solver.cpp:236] Iteration 216700, loss = 0.0119686
I0712 08:49:50.176890 126720 solver.cpp:252]     Train net output #0: accuracy = 0.992188
I0712 08:49:50.176910 126720 solver.cpp:252]     Train net output #1: loss = 0.0139285 (* 1 = 0.0139285 loss)
I0712 08:49:50.176921 126720 sgd_solver.cpp:106] Iteration 216700, lr = 0.001
I0712 08:52:59.939657 126720 solver.cpp:340] Iteration 216750, Testing net (#0)
I0712 08:55:27.522022 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9949
I0712 08:55:27.522210 126720 solver.cpp:408]     Test net output #1: loss = 0.0148093 (* 1 = 0.0148093 loss)
I0712 08:58:30.931161 126720 solver.cpp:236] Iteration 216800, loss = 0.0214906
I0712 08:58:30.931344 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 08:58:30.931363 126720 solver.cpp:252]     Train net output #1: loss = 0.00669468 (* 1 = 0.00669468 loss)
I0712 08:58:30.931373 126720 sgd_solver.cpp:106] Iteration 216800, lr = 0.001
I0712 09:04:18.801609 126720 solver.cpp:236] Iteration 216900, loss = 0.0141447
I0712 09:04:18.801951 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 09:04:18.801985 126720 solver.cpp:252]     Train net output #1: loss = 0.00193181 (* 1 = 0.00193181 loss)
I0712 09:04:18.801996 126720 sgd_solver.cpp:106] Iteration 216900, lr = 0.001
I0712 09:10:01.220302 126720 solver.cpp:340] Iteration 217000, Testing net (#0)
I0712 09:12:31.947648 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9974
I0712 09:12:31.947773 126720 solver.cpp:408]     Test net output #1: loss = 0.00760605 (* 1 = 0.00760605 loss)
I0712 09:12:32.152982 126720 solver.cpp:236] Iteration 217000, loss = 0.0115264
I0712 09:12:32.153033 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 09:12:32.153049 126720 solver.cpp:252]     Train net output #1: loss = 0.00191905 (* 1 = 0.00191905 loss)
I0712 09:12:32.153059 126720 sgd_solver.cpp:106] Iteration 217000, lr = 0.001
I0712 09:18:24.872103 126720 solver.cpp:236] Iteration 217100, loss = 0.0114374
I0712 09:18:24.872257 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 09:18:24.872289 126720 solver.cpp:252]     Train net output #1: loss = 0.00222259 (* 1 = 0.00222259 loss)
I0712 09:18:24.872311 126720 sgd_solver.cpp:106] Iteration 217100, lr = 0.001
I0712 09:24:39.050339 126720 solver.cpp:236] Iteration 217200, loss = 0.019515
I0712 09:24:39.050493 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 09:24:39.050513 126720 solver.cpp:252]     Train net output #1: loss = 0.0121934 (* 1 = 0.0121934 loss)
I0712 09:24:39.050536 126720 sgd_solver.cpp:106] Iteration 217200, lr = 0.001
I0712 09:27:37.432773 126720 solver.cpp:340] Iteration 217250, Testing net (#0)
I0712 09:28:32.385095 126720 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 09:29:47.131240 126720 solver.cpp:408]     Test net output #0: accuracy = 0.9962
I0712 09:29:47.131464 126720 solver.cpp:408]     Test net output #1: loss = 0.0102353 (* 1 = 0.0102353 loss)
I0712 09:32:43.556138 126720 solver.cpp:236] Iteration 217300, loss = 0.0106579
I0712 09:32:43.556308 126720 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 09:32:43.556352 126720 solver.cpp:252]     Train net output #1: loss = 0.00418352 (* 1 = 0.00418352 loss)
I0712 09:32:43.556377 126720 sgd_solver.cpp:106] Iteration 217300, lr = 0.001
I0712 09:33:38.257521 126720 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_217316.caffemodel
I0712 09:33:39.302003 126720 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_217316.solverstate
I0712 09:33:39.332784 126720 solver.cpp:308] Optimization stopped early.
I0712 09:33:39.343224 126720 caffe.cpp:215] Optimization Done.
