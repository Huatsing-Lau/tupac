Log file created at: 2016/07/05 13:34:12
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0705 13:34:12.837633 44772 caffe.cpp:184] Using GPUs 2
I0705 13:34:13.097237 44772 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 250
base_lr: 0.025
display: 10
max_iter: 180000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/cnn10"
solver_mode: GPU
device_id: 2
net: "train_val.prototxt.full"
test_initialization: false
average_loss: 50
I0705 13:34:13.097445 44772 solver.cpp:90] Creating training net from net file: train_val.prototxt.full
I0705 13:34:13.098001 44772 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0705 13:34:13.098140 44772 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0705 13:34:13.098235 44772 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0705 13:34:13.098413 44772 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-train-L0.lst"
    batch_size: 128
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0705 13:34:13.099845 44772 layer_factory.hpp:76] Creating layer data
I0705 13:34:13.099894 44772 net.cpp:106] Creating Layer data
I0705 13:34:13.099908 44772 net.cpp:411] data -> data
I0705 13:34:13.099936 44772 net.cpp:411] data -> label
I0705 13:34:13.100327 44772 image_data_layer.cpp:36] Opening file ../lists/roi-train-L0.lst
I0705 13:34:13.198076 44772 image_data_layer.cpp:46] Shuffling data
I0705 13:34:13.226172 44772 image_data_layer.cpp:51] A total of 211680 images.
I0705 13:34:13.260175 44772 image_data_layer.cpp:78] output data size: 128,3,100,100
I0705 13:34:13.289118 44772 net.cpp:150] Setting up data
I0705 13:34:13.289199 44772 net.cpp:157] Top shape: 128 3 100 100 (3840000)
I0705 13:34:13.289211 44772 net.cpp:157] Top shape: 128 (128)
I0705 13:34:13.289222 44772 net.cpp:165] Memory required for data: 15360512
I0705 13:34:13.289235 44772 layer_factory.hpp:76] Creating layer label_data_1_split
I0705 13:34:13.289253 44772 net.cpp:106] Creating Layer label_data_1_split
I0705 13:34:13.289268 44772 net.cpp:454] label_data_1_split <- label
I0705 13:34:13.289283 44772 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0705 13:34:13.289299 44772 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0705 13:34:13.289355 44772 net.cpp:150] Setting up label_data_1_split
I0705 13:34:13.289371 44772 net.cpp:157] Top shape: 128 (128)
I0705 13:34:13.289377 44772 net.cpp:157] Top shape: 128 (128)
I0705 13:34:13.289384 44772 net.cpp:165] Memory required for data: 15361536
I0705 13:34:13.289392 44772 layer_factory.hpp:76] Creating layer conv11
I0705 13:34:13.289412 44772 net.cpp:106] Creating Layer conv11
I0705 13:34:13.289422 44772 net.cpp:454] conv11 <- data
I0705 13:34:13.289430 44772 net.cpp:411] conv11 -> conv11
I0705 13:34:13.398530 44772 net.cpp:150] Setting up conv11
I0705 13:34:13.398576 44772 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 13:34:13.398586 44772 net.cpp:165] Memory required for data: 179201536
I0705 13:34:13.398612 44772 layer_factory.hpp:76] Creating layer relu11
I0705 13:34:13.398632 44772 net.cpp:106] Creating Layer relu11
I0705 13:34:13.398640 44772 net.cpp:454] relu11 <- conv11
I0705 13:34:13.398650 44772 net.cpp:397] relu11 -> conv11 (in-place)
I0705 13:34:13.398797 44772 net.cpp:150] Setting up relu11
I0705 13:34:13.398813 44772 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 13:34:13.398819 44772 net.cpp:165] Memory required for data: 343041536
I0705 13:34:13.398828 44772 layer_factory.hpp:76] Creating layer conv12
I0705 13:34:13.398844 44772 net.cpp:106] Creating Layer conv12
I0705 13:34:13.398851 44772 net.cpp:454] conv12 <- conv11
I0705 13:34:13.398864 44772 net.cpp:411] conv12 -> conv12
I0705 13:34:13.399720 44772 net.cpp:150] Setting up conv12
I0705 13:34:13.399740 44772 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 13:34:13.399749 44772 net.cpp:165] Memory required for data: 506881536
I0705 13:34:13.399760 44772 layer_factory.hpp:76] Creating layer relu12
I0705 13:34:13.399775 44772 net.cpp:106] Creating Layer relu12
I0705 13:34:13.399783 44772 net.cpp:454] relu12 <- conv12
I0705 13:34:13.399791 44772 net.cpp:397] relu12 -> conv12 (in-place)
I0705 13:34:13.400061 44772 net.cpp:150] Setting up relu12
I0705 13:34:13.400079 44772 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 13:34:13.400087 44772 net.cpp:165] Memory required for data: 670721536
I0705 13:34:13.400094 44772 layer_factory.hpp:76] Creating layer pool1
I0705 13:34:13.400107 44772 net.cpp:106] Creating Layer pool1
I0705 13:34:13.400115 44772 net.cpp:454] pool1 <- conv12
I0705 13:34:13.400125 44772 net.cpp:411] pool1 -> pool1
I0705 13:34:13.400313 44772 net.cpp:150] Setting up pool1
I0705 13:34:13.400329 44772 net.cpp:157] Top shape: 128 32 50 50 (10240000)
I0705 13:34:13.400336 44772 net.cpp:165] Memory required for data: 711681536
I0705 13:34:13.400343 44772 layer_factory.hpp:76] Creating layer conv21
I0705 13:34:13.400357 44772 net.cpp:106] Creating Layer conv21
I0705 13:34:13.400365 44772 net.cpp:454] conv21 <- pool1
I0705 13:34:13.400375 44772 net.cpp:411] conv21 -> conv21
I0705 13:34:13.402395 44772 net.cpp:150] Setting up conv21
I0705 13:34:13.402415 44772 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 13:34:13.402422 44772 net.cpp:165] Memory required for data: 793601536
I0705 13:34:13.402436 44772 layer_factory.hpp:76] Creating layer relu21
I0705 13:34:13.402452 44772 net.cpp:106] Creating Layer relu21
I0705 13:34:13.402461 44772 net.cpp:454] relu21 <- conv21
I0705 13:34:13.402469 44772 net.cpp:397] relu21 -> conv21 (in-place)
I0705 13:34:13.402771 44772 net.cpp:150] Setting up relu21
I0705 13:34:13.402789 44772 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 13:34:13.402825 44772 net.cpp:165] Memory required for data: 875521536
I0705 13:34:13.402833 44772 layer_factory.hpp:76] Creating layer conv22
I0705 13:34:13.402849 44772 net.cpp:106] Creating Layer conv22
I0705 13:34:13.402858 44772 net.cpp:454] conv22 <- conv21
I0705 13:34:13.402869 44772 net.cpp:411] conv22 -> conv22
I0705 13:34:13.403848 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0705 13:34:13.404036 44772 net.cpp:150] Setting up conv22
I0705 13:34:13.404054 44772 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 13:34:13.404062 44772 net.cpp:165] Memory required for data: 957441536
I0705 13:34:13.404074 44772 layer_factory.hpp:76] Creating layer relu22
I0705 13:34:13.404085 44772 net.cpp:106] Creating Layer relu22
I0705 13:34:13.404093 44772 net.cpp:454] relu22 <- conv22
I0705 13:34:13.404101 44772 net.cpp:397] relu22 -> conv22 (in-place)
I0705 13:34:13.404373 44772 net.cpp:150] Setting up relu22
I0705 13:34:13.404393 44772 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 13:34:13.404400 44772 net.cpp:165] Memory required for data: 1039361536
I0705 13:34:13.404408 44772 layer_factory.hpp:76] Creating layer pool2
I0705 13:34:13.404418 44772 net.cpp:106] Creating Layer pool2
I0705 13:34:13.404430 44772 net.cpp:454] pool2 <- conv22
I0705 13:34:13.404453 44772 net.cpp:411] pool2 -> pool2
I0705 13:34:13.404650 44772 net.cpp:150] Setting up pool2
I0705 13:34:13.404666 44772 net.cpp:157] Top shape: 128 64 25 25 (5120000)
I0705 13:34:13.404673 44772 net.cpp:165] Memory required for data: 1059841536
I0705 13:34:13.404680 44772 layer_factory.hpp:76] Creating layer conv31
I0705 13:34:13.404695 44772 net.cpp:106] Creating Layer conv31
I0705 13:34:13.404703 44772 net.cpp:454] conv31 <- pool2
I0705 13:34:13.404713 44772 net.cpp:411] conv31 -> conv31
I0705 13:34:13.405905 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0705 13:34:13.405936 44772 net.cpp:150] Setting up conv31
I0705 13:34:13.405946 44772 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 13:34:13.405953 44772 net.cpp:165] Memory required for data: 1090561536
I0705 13:34:13.405966 44772 layer_factory.hpp:76] Creating layer relu31
I0705 13:34:13.405978 44772 net.cpp:106] Creating Layer relu31
I0705 13:34:13.405987 44772 net.cpp:454] relu31 <- conv31
I0705 13:34:13.405995 44772 net.cpp:397] relu31 -> conv31 (in-place)
I0705 13:34:13.406275 44772 net.cpp:150] Setting up relu31
I0705 13:34:13.406291 44772 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 13:34:13.406298 44772 net.cpp:165] Memory required for data: 1121281536
I0705 13:34:13.406306 44772 layer_factory.hpp:76] Creating layer conv32
I0705 13:34:13.406334 44772 net.cpp:106] Creating Layer conv32
I0705 13:34:13.406342 44772 net.cpp:454] conv32 <- conv31
I0705 13:34:13.406352 44772 net.cpp:411] conv32 -> conv32
I0705 13:34:13.408326 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0705 13:34:13.408357 44772 net.cpp:150] Setting up conv32
I0705 13:34:13.408368 44772 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 13:34:13.408376 44772 net.cpp:165] Memory required for data: 1152001536
I0705 13:34:13.408386 44772 layer_factory.hpp:76] Creating layer relu32
I0705 13:34:13.408398 44772 net.cpp:106] Creating Layer relu32
I0705 13:34:13.408406 44772 net.cpp:454] relu32 <- conv32
I0705 13:34:13.408416 44772 net.cpp:397] relu32 -> conv32 (in-place)
I0705 13:34:13.408610 44772 net.cpp:150] Setting up relu32
I0705 13:34:13.408625 44772 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 13:34:13.408632 44772 net.cpp:165] Memory required for data: 1182721536
I0705 13:34:13.408640 44772 layer_factory.hpp:76] Creating layer pool3
I0705 13:34:13.408651 44772 net.cpp:106] Creating Layer pool3
I0705 13:34:13.408658 44772 net.cpp:454] pool3 <- conv32
I0705 13:34:13.408669 44772 net.cpp:411] pool3 -> pool3
I0705 13:34:13.409003 44772 net.cpp:150] Setting up pool3
I0705 13:34:13.409023 44772 net.cpp:157] Top shape: 128 96 13 13 (2076672)
I0705 13:34:13.409029 44772 net.cpp:165] Memory required for data: 1191028224
I0705 13:34:13.409036 44772 layer_factory.hpp:76] Creating layer conv41
I0705 13:34:13.409065 44772 net.cpp:106] Creating Layer conv41
I0705 13:34:13.409075 44772 net.cpp:454] conv41 <- pool3
I0705 13:34:13.409086 44772 net.cpp:411] conv41 -> conv41
I0705 13:34:13.410490 44772 net.cpp:150] Setting up conv41
I0705 13:34:13.410511 44772 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 13:34:13.410519 44772 net.cpp:165] Memory required for data: 1202103808
I0705 13:34:13.410531 44772 layer_factory.hpp:76] Creating layer relu41
I0705 13:34:13.410540 44772 net.cpp:106] Creating Layer relu41
I0705 13:34:13.410547 44772 net.cpp:454] relu41 <- conv41
I0705 13:34:13.410557 44772 net.cpp:397] relu41 -> conv41 (in-place)
I0705 13:34:13.410984 44772 net.cpp:150] Setting up relu41
I0705 13:34:13.411001 44772 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 13:34:13.411008 44772 net.cpp:165] Memory required for data: 1213179392
I0705 13:34:13.411016 44772 layer_factory.hpp:76] Creating layer conv42
I0705 13:34:13.411031 44772 net.cpp:106] Creating Layer conv42
I0705 13:34:13.411038 44772 net.cpp:454] conv42 <- conv41
I0705 13:34:13.411049 44772 net.cpp:411] conv42 -> conv42
I0705 13:34:13.413415 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0705 13:34:13.413447 44772 net.cpp:150] Setting up conv42
I0705 13:34:13.413460 44772 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 13:34:13.413466 44772 net.cpp:165] Memory required for data: 1224254976
I0705 13:34:13.413477 44772 layer_factory.hpp:76] Creating layer relu42
I0705 13:34:13.413487 44772 net.cpp:106] Creating Layer relu42
I0705 13:34:13.413497 44772 net.cpp:454] relu42 <- conv42
I0705 13:34:13.413508 44772 net.cpp:397] relu42 -> conv42 (in-place)
I0705 13:34:13.413661 44772 net.cpp:150] Setting up relu42
I0705 13:34:13.413676 44772 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 13:34:13.413683 44772 net.cpp:165] Memory required for data: 1235330560
I0705 13:34:13.413691 44772 layer_factory.hpp:76] Creating layer pool4
I0705 13:34:13.413699 44772 net.cpp:106] Creating Layer pool4
I0705 13:34:13.413707 44772 net.cpp:454] pool4 <- conv42
I0705 13:34:13.413715 44772 net.cpp:411] pool4 -> pool4
I0705 13:34:13.414017 44772 net.cpp:150] Setting up pool4
I0705 13:34:13.414036 44772 net.cpp:157] Top shape: 128 128 7 7 (802816)
I0705 13:34:13.414042 44772 net.cpp:165] Memory required for data: 1238541824
I0705 13:34:13.414049 44772 layer_factory.hpp:76] Creating layer conv51
I0705 13:34:13.414063 44772 net.cpp:106] Creating Layer conv51
I0705 13:34:13.414072 44772 net.cpp:454] conv51 <- pool4
I0705 13:34:13.414083 44772 net.cpp:411] conv51 -> conv51
I0705 13:34:13.417462 44772 net.cpp:150] Setting up conv51
I0705 13:34:13.417487 44772 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 13:34:13.417500 44772 net.cpp:165] Memory required for data: 1244964352
I0705 13:34:13.417511 44772 layer_factory.hpp:76] Creating layer relu51
I0705 13:34:13.417524 44772 net.cpp:106] Creating Layer relu51
I0705 13:34:13.417536 44772 net.cpp:454] relu51 <- conv51
I0705 13:34:13.417544 44772 net.cpp:397] relu51 -> conv51 (in-place)
I0705 13:34:13.417696 44772 net.cpp:150] Setting up relu51
I0705 13:34:13.417711 44772 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 13:34:13.417718 44772 net.cpp:165] Memory required for data: 1251386880
I0705 13:34:13.417726 44772 layer_factory.hpp:76] Creating layer conv52
I0705 13:34:13.417740 44772 net.cpp:106] Creating Layer conv52
I0705 13:34:13.417748 44772 net.cpp:454] conv52 <- conv51
I0705 13:34:13.417757 44772 net.cpp:411] conv52 -> conv52
I0705 13:34:13.423341 44772 net.cpp:150] Setting up conv52
I0705 13:34:13.423363 44772 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 13:34:13.423372 44772 net.cpp:165] Memory required for data: 1257809408
I0705 13:34:13.423382 44772 layer_factory.hpp:76] Creating layer relu52
I0705 13:34:13.423393 44772 net.cpp:106] Creating Layer relu52
I0705 13:34:13.423399 44772 net.cpp:454] relu52 <- conv52
I0705 13:34:13.423409 44772 net.cpp:397] relu52 -> conv52 (in-place)
I0705 13:34:13.423687 44772 net.cpp:150] Setting up relu52
I0705 13:34:13.423719 44772 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 13:34:13.423727 44772 net.cpp:165] Memory required for data: 1264231936
I0705 13:34:13.423735 44772 layer_factory.hpp:76] Creating layer conv53
I0705 13:34:13.423748 44772 net.cpp:106] Creating Layer conv53
I0705 13:34:13.423754 44772 net.cpp:454] conv53 <- conv52
I0705 13:34:13.423766 44772 net.cpp:411] conv53 -> conv53
I0705 13:34:13.450821 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0705 13:34:13.451028 44772 net.cpp:150] Setting up conv53
I0705 13:34:13.451048 44772 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0705 13:34:13.451057 44772 net.cpp:165] Memory required for data: 1264363008
I0705 13:34:13.451072 44772 layer_factory.hpp:76] Creating layer relu53
I0705 13:34:13.451086 44772 net.cpp:106] Creating Layer relu53
I0705 13:34:13.451094 44772 net.cpp:454] relu53 <- conv53
I0705 13:34:13.451105 44772 net.cpp:397] relu53 -> conv53 (in-place)
I0705 13:34:13.451391 44772 net.cpp:150] Setting up relu53
I0705 13:34:13.451411 44772 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0705 13:34:13.451417 44772 net.cpp:165] Memory required for data: 1264494080
I0705 13:34:13.451424 44772 layer_factory.hpp:76] Creating layer drop6
I0705 13:34:13.451442 44772 net.cpp:106] Creating Layer drop6
I0705 13:34:13.451452 44772 net.cpp:454] drop6 <- conv53
I0705 13:34:13.451459 44772 net.cpp:411] drop6 -> drop6
I0705 13:34:13.451509 44772 net.cpp:150] Setting up drop6
I0705 13:34:13.451524 44772 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0705 13:34:13.451530 44772 net.cpp:165] Memory required for data: 1264625152
I0705 13:34:13.451539 44772 layer_factory.hpp:76] Creating layer conv54
I0705 13:34:13.451553 44772 net.cpp:106] Creating Layer conv54
I0705 13:34:13.451561 44772 net.cpp:454] conv54 <- drop6
I0705 13:34:13.451571 44772 net.cpp:411] conv54 -> conv54
I0705 13:34:13.452469 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0705 13:34:13.452653 44772 net.cpp:150] Setting up conv54
I0705 13:34:13.452669 44772 net.cpp:157] Top shape: 128 2 1 1 (256)
I0705 13:34:13.452677 44772 net.cpp:165] Memory required for data: 1264626176
I0705 13:34:13.452689 44772 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0705 13:34:13.452702 44772 net.cpp:106] Creating Layer conv54_conv54_0_split
I0705 13:34:13.452709 44772 net.cpp:454] conv54_conv54_0_split <- conv54
I0705 13:34:13.452718 44772 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0705 13:34:13.452728 44772 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0705 13:34:13.452770 44772 net.cpp:150] Setting up conv54_conv54_0_split
I0705 13:34:13.452793 44772 net.cpp:157] Top shape: 128 2 1 1 (256)
I0705 13:34:13.452801 44772 net.cpp:157] Top shape: 128 2 1 1 (256)
I0705 13:34:13.452807 44772 net.cpp:165] Memory required for data: 1264628224
I0705 13:34:13.452816 44772 layer_factory.hpp:76] Creating layer accuracy
I0705 13:34:13.452828 44772 net.cpp:106] Creating Layer accuracy
I0705 13:34:13.452836 44772 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0705 13:34:13.452847 44772 net.cpp:454] accuracy <- label_data_1_split_0
I0705 13:34:13.452860 44772 net.cpp:411] accuracy -> accuracy
I0705 13:34:13.452875 44772 net.cpp:150] Setting up accuracy
I0705 13:34:13.452888 44772 net.cpp:157] Top shape: (1)
I0705 13:34:13.452898 44772 net.cpp:165] Memory required for data: 1264628228
I0705 13:34:13.452908 44772 layer_factory.hpp:76] Creating layer loss
I0705 13:34:13.452925 44772 net.cpp:106] Creating Layer loss
I0705 13:34:13.452937 44772 net.cpp:454] loss <- conv54_conv54_0_split_1
I0705 13:34:13.452952 44772 net.cpp:454] loss <- label_data_1_split_1
I0705 13:34:13.452961 44772 net.cpp:411] loss -> loss
I0705 13:34:13.452981 44772 layer_factory.hpp:76] Creating layer loss
I0705 13:34:13.453225 44772 net.cpp:150] Setting up loss
I0705 13:34:13.453241 44772 net.cpp:157] Top shape: (1)
I0705 13:34:13.453248 44772 net.cpp:160]     with loss weight 1
I0705 13:34:13.453275 44772 net.cpp:165] Memory required for data: 1264628232
I0705 13:34:13.453323 44772 net.cpp:226] loss needs backward computation.
I0705 13:34:13.453331 44772 net.cpp:228] accuracy does not need backward computation.
I0705 13:34:13.453338 44772 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0705 13:34:13.453346 44772 net.cpp:226] conv54 needs backward computation.
I0705 13:34:13.453352 44772 net.cpp:226] drop6 needs backward computation.
I0705 13:34:13.453359 44772 net.cpp:226] relu53 needs backward computation.
I0705 13:34:13.453373 44772 net.cpp:226] conv53 needs backward computation.
I0705 13:34:13.453379 44772 net.cpp:226] relu52 needs backward computation.
I0705 13:34:13.453385 44772 net.cpp:226] conv52 needs backward computation.
I0705 13:34:13.453392 44772 net.cpp:226] relu51 needs backward computation.
I0705 13:34:13.453398 44772 net.cpp:226] conv51 needs backward computation.
I0705 13:34:13.453404 44772 net.cpp:226] pool4 needs backward computation.
I0705 13:34:13.453411 44772 net.cpp:226] relu42 needs backward computation.
I0705 13:34:13.453418 44772 net.cpp:226] conv42 needs backward computation.
I0705 13:34:13.453424 44772 net.cpp:226] relu41 needs backward computation.
I0705 13:34:13.453430 44772 net.cpp:226] conv41 needs backward computation.
I0705 13:34:13.453438 44772 net.cpp:226] pool3 needs backward computation.
I0705 13:34:13.453445 44772 net.cpp:226] relu32 needs backward computation.
I0705 13:34:13.453451 44772 net.cpp:226] conv32 needs backward computation.
I0705 13:34:13.453457 44772 net.cpp:226] relu31 needs backward computation.
I0705 13:34:13.453464 44772 net.cpp:226] conv31 needs backward computation.
I0705 13:34:13.453470 44772 net.cpp:226] pool2 needs backward computation.
I0705 13:34:13.453477 44772 net.cpp:226] relu22 needs backward computation.
I0705 13:34:13.453483 44772 net.cpp:226] conv22 needs backward computation.
I0705 13:34:13.453492 44772 net.cpp:226] relu21 needs backward computation.
I0705 13:34:13.453498 44772 net.cpp:226] conv21 needs backward computation.
I0705 13:34:13.453505 44772 net.cpp:226] pool1 needs backward computation.
I0705 13:34:13.453511 44772 net.cpp:226] relu12 needs backward computation.
I0705 13:34:13.453517 44772 net.cpp:226] conv12 needs backward computation.
I0705 13:34:13.453524 44772 net.cpp:226] relu11 needs backward computation.
I0705 13:34:13.453531 44772 net.cpp:226] conv11 needs backward computation.
I0705 13:34:13.453537 44772 net.cpp:228] label_data_1_split does not need backward computation.
I0705 13:34:13.453544 44772 net.cpp:228] data does not need backward computation.
I0705 13:34:13.453550 44772 net.cpp:270] This network produces output accuracy
I0705 13:34:13.453557 44772 net.cpp:270] This network produces output loss
I0705 13:34:13.453580 44772 net.cpp:283] Network initialization done.
I0705 13:34:13.454246 44772 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0705 13:34:13.454345 44772 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0705 13:34:13.454377 44772 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt.full
I0705 13:34:13.454419 44772 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0705 13:34:13.454591 44772 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-val-L0.lst"
    batch_size: 32
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0705 13:34:13.455963 44772 layer_factory.hpp:76] Creating layer data
I0705 13:34:13.455984 44772 net.cpp:106] Creating Layer data
I0705 13:34:13.455992 44772 net.cpp:411] data -> data
I0705 13:34:13.456004 44772 net.cpp:411] data -> label
I0705 13:34:13.456027 44772 image_data_layer.cpp:36] Opening file ../lists/roi-val-L0.lst
I0705 13:34:13.466756 44772 image_data_layer.cpp:46] Shuffling data
I0705 13:34:13.468168 44772 image_data_layer.cpp:51] A total of 23520 images.
I0705 13:34:13.516320 44772 image_data_layer.cpp:78] output data size: 32,3,100,100
I0705 13:34:13.523591 44772 net.cpp:150] Setting up data
I0705 13:34:13.523625 44772 net.cpp:157] Top shape: 32 3 100 100 (960000)
I0705 13:34:13.523635 44772 net.cpp:157] Top shape: 32 (32)
I0705 13:34:13.523643 44772 net.cpp:165] Memory required for data: 3840128
I0705 13:34:13.523656 44772 layer_factory.hpp:76] Creating layer label_data_1_split
I0705 13:34:13.523672 44772 net.cpp:106] Creating Layer label_data_1_split
I0705 13:34:13.523680 44772 net.cpp:454] label_data_1_split <- label
I0705 13:34:13.523690 44772 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0705 13:34:13.523704 44772 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0705 13:34:13.523809 44772 net.cpp:150] Setting up label_data_1_split
I0705 13:34:13.523824 44772 net.cpp:157] Top shape: 32 (32)
I0705 13:34:13.523833 44772 net.cpp:157] Top shape: 32 (32)
I0705 13:34:13.523838 44772 net.cpp:165] Memory required for data: 3840384
I0705 13:34:13.523845 44772 layer_factory.hpp:76] Creating layer conv11
I0705 13:34:13.523862 44772 net.cpp:106] Creating Layer conv11
I0705 13:34:13.523869 44772 net.cpp:454] conv11 <- data
I0705 13:34:13.523880 44772 net.cpp:411] conv11 -> conv11
I0705 13:34:13.525178 44772 net.cpp:150] Setting up conv11
I0705 13:34:13.525202 44772 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 13:34:13.525209 44772 net.cpp:165] Memory required for data: 44800384
I0705 13:34:13.525223 44772 layer_factory.hpp:76] Creating layer relu11
I0705 13:34:13.525236 44772 net.cpp:106] Creating Layer relu11
I0705 13:34:13.525243 44772 net.cpp:454] relu11 <- conv11
I0705 13:34:13.525262 44772 net.cpp:397] relu11 -> conv11 (in-place)
I0705 13:34:13.525656 44772 net.cpp:150] Setting up relu11
I0705 13:34:13.525699 44772 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 13:34:13.525708 44772 net.cpp:165] Memory required for data: 85760384
I0705 13:34:13.525717 44772 layer_factory.hpp:76] Creating layer conv12
I0705 13:34:13.525729 44772 net.cpp:106] Creating Layer conv12
I0705 13:34:13.525738 44772 net.cpp:454] conv12 <- conv11
I0705 13:34:13.525751 44772 net.cpp:411] conv12 -> conv12
I0705 13:34:13.526618 44772 net.cpp:150] Setting up conv12
I0705 13:34:13.526638 44772 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 13:34:13.526646 44772 net.cpp:165] Memory required for data: 126720384
I0705 13:34:13.526659 44772 layer_factory.hpp:76] Creating layer relu12
I0705 13:34:13.526674 44772 net.cpp:106] Creating Layer relu12
I0705 13:34:13.526681 44772 net.cpp:454] relu12 <- conv12
I0705 13:34:13.526690 44772 net.cpp:397] relu12 -> conv12 (in-place)
I0705 13:34:13.526974 44772 net.cpp:150] Setting up relu12
I0705 13:34:13.526993 44772 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 13:34:13.526999 44772 net.cpp:165] Memory required for data: 167680384
I0705 13:34:13.527007 44772 layer_factory.hpp:76] Creating layer pool1
I0705 13:34:13.527019 44772 net.cpp:106] Creating Layer pool1
I0705 13:34:13.527027 44772 net.cpp:454] pool1 <- conv12
I0705 13:34:13.527037 44772 net.cpp:411] pool1 -> pool1
I0705 13:34:13.527214 44772 net.cpp:150] Setting up pool1
I0705 13:34:13.527230 44772 net.cpp:157] Top shape: 32 32 50 50 (2560000)
I0705 13:34:13.527236 44772 net.cpp:165] Memory required for data: 177920384
I0705 13:34:13.527243 44772 layer_factory.hpp:76] Creating layer conv21
I0705 13:34:13.527256 44772 net.cpp:106] Creating Layer conv21
I0705 13:34:13.527266 44772 net.cpp:454] conv21 <- pool1
I0705 13:34:13.527276 44772 net.cpp:411] conv21 -> conv21
I0705 13:34:13.528479 44772 net.cpp:150] Setting up conv21
I0705 13:34:13.528502 44772 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 13:34:13.528511 44772 net.cpp:165] Memory required for data: 198400384
I0705 13:34:13.528527 44772 layer_factory.hpp:76] Creating layer relu21
I0705 13:34:13.528542 44772 net.cpp:106] Creating Layer relu21
I0705 13:34:13.528549 44772 net.cpp:454] relu21 <- conv21
I0705 13:34:13.528558 44772 net.cpp:397] relu21 -> conv21 (in-place)
I0705 13:34:13.528895 44772 net.cpp:150] Setting up relu21
I0705 13:34:13.528918 44772 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 13:34:13.528928 44772 net.cpp:165] Memory required for data: 218880384
I0705 13:34:13.528936 44772 layer_factory.hpp:76] Creating layer conv22
I0705 13:34:13.528949 44772 net.cpp:106] Creating Layer conv22
I0705 13:34:13.528957 44772 net.cpp:454] conv22 <- conv21
I0705 13:34:13.528970 44772 net.cpp:411] conv22 -> conv22
I0705 13:34:13.530568 44772 net.cpp:150] Setting up conv22
I0705 13:34:13.530596 44772 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 13:34:13.530606 44772 net.cpp:165] Memory required for data: 239360384
I0705 13:34:13.530617 44772 layer_factory.hpp:76] Creating layer relu22
I0705 13:34:13.530630 44772 net.cpp:106] Creating Layer relu22
I0705 13:34:13.530639 44772 net.cpp:454] relu22 <- conv22
I0705 13:34:13.530648 44772 net.cpp:397] relu22 -> conv22 (in-place)
I0705 13:34:13.530820 44772 net.cpp:150] Setting up relu22
I0705 13:34:13.530838 44772 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 13:34:13.530845 44772 net.cpp:165] Memory required for data: 259840384
I0705 13:34:13.530853 44772 layer_factory.hpp:76] Creating layer pool2
I0705 13:34:13.530864 44772 net.cpp:106] Creating Layer pool2
I0705 13:34:13.530872 44772 net.cpp:454] pool2 <- conv22
I0705 13:34:13.530881 44772 net.cpp:411] pool2 -> pool2
I0705 13:34:13.531224 44772 net.cpp:150] Setting up pool2
I0705 13:34:13.531242 44772 net.cpp:157] Top shape: 32 64 25 25 (1280000)
I0705 13:34:13.531250 44772 net.cpp:165] Memory required for data: 264960384
I0705 13:34:13.531256 44772 layer_factory.hpp:76] Creating layer conv31
I0705 13:34:13.531271 44772 net.cpp:106] Creating Layer conv31
I0705 13:34:13.531280 44772 net.cpp:454] conv31 <- pool2
I0705 13:34:13.531291 44772 net.cpp:411] conv31 -> conv31
I0705 13:34:13.532447 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0705 13:34:13.532491 44772 net.cpp:150] Setting up conv31
I0705 13:34:13.532503 44772 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 13:34:13.532510 44772 net.cpp:165] Memory required for data: 272640384
I0705 13:34:13.532526 44772 layer_factory.hpp:76] Creating layer relu31
I0705 13:34:13.532534 44772 net.cpp:106] Creating Layer relu31
I0705 13:34:13.532546 44772 net.cpp:454] relu31 <- conv31
I0705 13:34:13.532558 44772 net.cpp:397] relu31 -> conv31 (in-place)
I0705 13:34:13.532840 44772 net.cpp:150] Setting up relu31
I0705 13:34:13.532860 44772 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 13:34:13.532866 44772 net.cpp:165] Memory required for data: 280320384
I0705 13:34:13.532873 44772 layer_factory.hpp:76] Creating layer conv32
I0705 13:34:13.532886 44772 net.cpp:106] Creating Layer conv32
I0705 13:34:13.532894 44772 net.cpp:454] conv32 <- conv31
I0705 13:34:13.532905 44772 net.cpp:411] conv32 -> conv32
I0705 13:34:13.534358 44772 net.cpp:150] Setting up conv32
I0705 13:34:13.534378 44772 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 13:34:13.534385 44772 net.cpp:165] Memory required for data: 288000384
I0705 13:34:13.534395 44772 layer_factory.hpp:76] Creating layer relu32
I0705 13:34:13.534407 44772 net.cpp:106] Creating Layer relu32
I0705 13:34:13.534415 44772 net.cpp:454] relu32 <- conv32
I0705 13:34:13.534423 44772 net.cpp:397] relu32 -> conv32 (in-place)
I0705 13:34:13.534577 44772 net.cpp:150] Setting up relu32
I0705 13:34:13.534592 44772 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 13:34:13.534600 44772 net.cpp:165] Memory required for data: 295680384
I0705 13:34:13.534606 44772 layer_factory.hpp:76] Creating layer pool3
I0705 13:34:13.534618 44772 net.cpp:106] Creating Layer pool3
I0705 13:34:13.534626 44772 net.cpp:454] pool3 <- conv32
I0705 13:34:13.534634 44772 net.cpp:411] pool3 -> pool3
I0705 13:34:13.534945 44772 net.cpp:150] Setting up pool3
I0705 13:34:13.534963 44772 net.cpp:157] Top shape: 32 96 13 13 (519168)
I0705 13:34:13.534970 44772 net.cpp:165] Memory required for data: 297757056
I0705 13:34:13.534978 44772 layer_factory.hpp:76] Creating layer conv41
I0705 13:34:13.534991 44772 net.cpp:106] Creating Layer conv41
I0705 13:34:13.534999 44772 net.cpp:454] conv41 <- pool3
I0705 13:34:13.535010 44772 net.cpp:411] conv41 -> conv41
I0705 13:34:13.537093 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0705 13:34:13.537129 44772 net.cpp:150] Setting up conv41
I0705 13:34:13.537142 44772 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 13:34:13.537149 44772 net.cpp:165] Memory required for data: 300525952
I0705 13:34:13.537159 44772 layer_factory.hpp:76] Creating layer relu41
I0705 13:34:13.537168 44772 net.cpp:106] Creating Layer relu41
I0705 13:34:13.537176 44772 net.cpp:454] relu41 <- conv41
I0705 13:34:13.537184 44772 net.cpp:397] relu41 -> conv41 (in-place)
I0705 13:34:13.537343 44772 net.cpp:150] Setting up relu41
I0705 13:34:13.537358 44772 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 13:34:13.537365 44772 net.cpp:165] Memory required for data: 303294848
I0705 13:34:13.537372 44772 layer_factory.hpp:76] Creating layer conv42
I0705 13:34:13.537385 44772 net.cpp:106] Creating Layer conv42
I0705 13:34:13.537394 44772 net.cpp:454] conv42 <- conv41
I0705 13:34:13.537405 44772 net.cpp:411] conv42 -> conv42
I0705 13:34:13.539199 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0705 13:34:13.539242 44772 net.cpp:150] Setting up conv42
I0705 13:34:13.539255 44772 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 13:34:13.539263 44772 net.cpp:165] Memory required for data: 306063744
I0705 13:34:13.539273 44772 layer_factory.hpp:76] Creating layer relu42
I0705 13:34:13.539288 44772 net.cpp:106] Creating Layer relu42
I0705 13:34:13.539296 44772 net.cpp:454] relu42 <- conv42
I0705 13:34:13.539306 44772 net.cpp:397] relu42 -> conv42 (in-place)
I0705 13:34:13.539590 44772 net.cpp:150] Setting up relu42
I0705 13:34:13.539608 44772 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 13:34:13.539633 44772 net.cpp:165] Memory required for data: 308832640
I0705 13:34:13.539640 44772 layer_factory.hpp:76] Creating layer pool4
I0705 13:34:13.539651 44772 net.cpp:106] Creating Layer pool4
I0705 13:34:13.539659 44772 net.cpp:454] pool4 <- conv42
I0705 13:34:13.539669 44772 net.cpp:411] pool4 -> pool4
I0705 13:34:13.539851 44772 net.cpp:150] Setting up pool4
I0705 13:34:13.539867 44772 net.cpp:157] Top shape: 32 128 7 7 (200704)
I0705 13:34:13.539875 44772 net.cpp:165] Memory required for data: 309635456
I0705 13:34:13.539881 44772 layer_factory.hpp:76] Creating layer conv51
I0705 13:34:13.539894 44772 net.cpp:106] Creating Layer conv51
I0705 13:34:13.539902 44772 net.cpp:454] conv51 <- pool4
I0705 13:34:13.539911 44772 net.cpp:411] conv51 -> conv51
I0705 13:34:13.543162 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0705 13:34:13.543356 44772 net.cpp:150] Setting up conv51
I0705 13:34:13.543375 44772 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 13:34:13.543382 44772 net.cpp:165] Memory required for data: 311241088
I0705 13:34:13.543396 44772 layer_factory.hpp:76] Creating layer relu51
I0705 13:34:13.543407 44772 net.cpp:106] Creating Layer relu51
I0705 13:34:13.543414 44772 net.cpp:454] relu51 <- conv51
I0705 13:34:13.543424 44772 net.cpp:397] relu51 -> conv51 (in-place)
I0705 13:34:13.543593 44772 net.cpp:150] Setting up relu51
I0705 13:34:13.543614 44772 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 13:34:13.543630 44772 net.cpp:165] Memory required for data: 312846720
I0705 13:34:13.543637 44772 layer_factory.hpp:76] Creating layer conv52
I0705 13:34:13.543653 44772 net.cpp:106] Creating Layer conv52
I0705 13:34:13.543663 44772 net.cpp:454] conv52 <- conv51
I0705 13:34:13.543673 44772 net.cpp:411] conv52 -> conv52
I0705 13:34:13.549232 44772 net.cpp:150] Setting up conv52
I0705 13:34:13.549252 44772 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 13:34:13.549259 44772 net.cpp:165] Memory required for data: 314452352
I0705 13:34:13.549268 44772 layer_factory.hpp:76] Creating layer relu52
I0705 13:34:13.549281 44772 net.cpp:106] Creating Layer relu52
I0705 13:34:13.549289 44772 net.cpp:454] relu52 <- conv52
I0705 13:34:13.549298 44772 net.cpp:397] relu52 -> conv52 (in-place)
I0705 13:34:13.549594 44772 net.cpp:150] Setting up relu52
I0705 13:34:13.549612 44772 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 13:34:13.549619 44772 net.cpp:165] Memory required for data: 316057984
I0705 13:34:13.549626 44772 layer_factory.hpp:76] Creating layer conv53
I0705 13:34:13.549641 44772 net.cpp:106] Creating Layer conv53
I0705 13:34:13.549649 44772 net.cpp:454] conv53 <- conv52
I0705 13:34:13.549660 44772 net.cpp:411] conv53 -> conv53
I0705 13:34:13.574568 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0705 13:34:13.574618 44772 net.cpp:150] Setting up conv53
I0705 13:34:13.574632 44772 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0705 13:34:13.574640 44772 net.cpp:165] Memory required for data: 316090752
I0705 13:34:13.574652 44772 layer_factory.hpp:76] Creating layer relu53
I0705 13:34:13.574667 44772 net.cpp:106] Creating Layer relu53
I0705 13:34:13.574679 44772 net.cpp:454] relu53 <- conv53
I0705 13:34:13.574688 44772 net.cpp:397] relu53 -> conv53 (in-place)
I0705 13:34:13.574852 44772 net.cpp:150] Setting up relu53
I0705 13:34:13.574868 44772 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0705 13:34:13.574875 44772 net.cpp:165] Memory required for data: 316123520
I0705 13:34:13.574882 44772 layer_factory.hpp:76] Creating layer drop6
I0705 13:34:13.574893 44772 net.cpp:106] Creating Layer drop6
I0705 13:34:13.574901 44772 net.cpp:454] drop6 <- conv53
I0705 13:34:13.574911 44772 net.cpp:411] drop6 -> drop6
I0705 13:34:13.574957 44772 net.cpp:150] Setting up drop6
I0705 13:34:13.574980 44772 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0705 13:34:13.574986 44772 net.cpp:165] Memory required for data: 316156288
I0705 13:34:13.574993 44772 layer_factory.hpp:76] Creating layer conv54
I0705 13:34:13.575011 44772 net.cpp:106] Creating Layer conv54
I0705 13:34:13.575045 44772 net.cpp:454] conv54 <- drop6
I0705 13:34:13.575055 44772 net.cpp:411] conv54 -> conv54
I0705 13:34:13.576002 44772 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0705 13:34:13.576033 44772 net.cpp:150] Setting up conv54
I0705 13:34:13.576045 44772 net.cpp:157] Top shape: 32 2 1 1 (64)
I0705 13:34:13.576052 44772 net.cpp:165] Memory required for data: 316156544
I0705 13:34:13.576062 44772 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0705 13:34:13.576073 44772 net.cpp:106] Creating Layer conv54_conv54_0_split
I0705 13:34:13.576092 44772 net.cpp:454] conv54_conv54_0_split <- conv54
I0705 13:34:13.576100 44772 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0705 13:34:13.576112 44772 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0705 13:34:13.576154 44772 net.cpp:150] Setting up conv54_conv54_0_split
I0705 13:34:13.576174 44772 net.cpp:157] Top shape: 32 2 1 1 (64)
I0705 13:34:13.576182 44772 net.cpp:157] Top shape: 32 2 1 1 (64)
I0705 13:34:13.576192 44772 net.cpp:165] Memory required for data: 316157056
I0705 13:34:13.576200 44772 layer_factory.hpp:76] Creating layer accuracy
I0705 13:34:13.576211 44772 net.cpp:106] Creating Layer accuracy
I0705 13:34:13.576218 44772 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0705 13:34:13.576226 44772 net.cpp:454] accuracy <- label_data_1_split_0
I0705 13:34:13.576236 44772 net.cpp:411] accuracy -> accuracy
I0705 13:34:13.576246 44772 net.cpp:150] Setting up accuracy
I0705 13:34:13.576256 44772 net.cpp:157] Top shape: (1)
I0705 13:34:13.576263 44772 net.cpp:165] Memory required for data: 316157060
I0705 13:34:13.576270 44772 layer_factory.hpp:76] Creating layer loss
I0705 13:34:13.576283 44772 net.cpp:106] Creating Layer loss
I0705 13:34:13.576292 44772 net.cpp:454] loss <- conv54_conv54_0_split_1
I0705 13:34:13.576298 44772 net.cpp:454] loss <- label_data_1_split_1
I0705 13:34:13.576308 44772 net.cpp:411] loss -> loss
I0705 13:34:13.576318 44772 layer_factory.hpp:76] Creating layer loss
I0705 13:34:13.576566 44772 net.cpp:150] Setting up loss
I0705 13:34:13.576582 44772 net.cpp:157] Top shape: (1)
I0705 13:34:13.576589 44772 net.cpp:160]     with loss weight 1
I0705 13:34:13.576603 44772 net.cpp:165] Memory required for data: 316157064
I0705 13:34:13.576611 44772 net.cpp:226] loss needs backward computation.
I0705 13:34:13.576619 44772 net.cpp:228] accuracy does not need backward computation.
I0705 13:34:13.576627 44772 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0705 13:34:13.576632 44772 net.cpp:226] conv54 needs backward computation.
I0705 13:34:13.576639 44772 net.cpp:226] drop6 needs backward computation.
I0705 13:34:13.576645 44772 net.cpp:226] relu53 needs backward computation.
I0705 13:34:13.576653 44772 net.cpp:226] conv53 needs backward computation.
I0705 13:34:13.576658 44772 net.cpp:226] relu52 needs backward computation.
I0705 13:34:13.576664 44772 net.cpp:226] conv52 needs backward computation.
I0705 13:34:13.576670 44772 net.cpp:226] relu51 needs backward computation.
I0705 13:34:13.576678 44772 net.cpp:226] conv51 needs backward computation.
I0705 13:34:13.576683 44772 net.cpp:226] pool4 needs backward computation.
I0705 13:34:13.576689 44772 net.cpp:226] relu42 needs backward computation.
I0705 13:34:13.576696 44772 net.cpp:226] conv42 needs backward computation.
I0705 13:34:13.576704 44772 net.cpp:226] relu41 needs backward computation.
I0705 13:34:13.576709 44772 net.cpp:226] conv41 needs backward computation.
I0705 13:34:13.576716 44772 net.cpp:226] pool3 needs backward computation.
I0705 13:34:13.576722 44772 net.cpp:226] relu32 needs backward computation.
I0705 13:34:13.576730 44772 net.cpp:226] conv32 needs backward computation.
I0705 13:34:13.576735 44772 net.cpp:226] relu31 needs backward computation.
I0705 13:34:13.576741 44772 net.cpp:226] conv31 needs backward computation.
I0705 13:34:13.576748 44772 net.cpp:226] pool2 needs backward computation.
I0705 13:34:13.576755 44772 net.cpp:226] relu22 needs backward computation.
I0705 13:34:13.576772 44772 net.cpp:226] conv22 needs backward computation.
I0705 13:34:13.576779 44772 net.cpp:226] relu21 needs backward computation.
I0705 13:34:13.576786 44772 net.cpp:226] conv21 needs backward computation.
I0705 13:34:13.576792 44772 net.cpp:226] pool1 needs backward computation.
I0705 13:34:13.576798 44772 net.cpp:226] relu12 needs backward computation.
I0705 13:34:13.576804 44772 net.cpp:226] conv12 needs backward computation.
I0705 13:34:13.576812 44772 net.cpp:226] relu11 needs backward computation.
I0705 13:34:13.576819 44772 net.cpp:226] conv11 needs backward computation.
I0705 13:34:13.576827 44772 net.cpp:228] label_data_1_split does not need backward computation.
I0705 13:34:13.576833 44772 net.cpp:228] data does not need backward computation.
I0705 13:34:13.576843 44772 net.cpp:270] This network produces output accuracy
I0705 13:34:13.576850 44772 net.cpp:270] This network produces output loss
I0705 13:34:13.576870 44772 net.cpp:283] Network initialization done.
I0705 13:34:13.577021 44772 solver.cpp:59] Solver scaffolding done.
I0705 13:34:13.577785 44772 caffe.cpp:202] Resuming from models/cnn10_iter_612.solverstate
I0705 13:34:13.655411 44772 sgd_solver.cpp:314] SGDSolver: restoring history
I0705 13:34:13.670709 44772 caffe.cpp:212] Starting Optimization
I0705 13:34:13.670778 44772 solver.cpp:287] Solving FaceNN
I0705 13:34:13.670789 44772 solver.cpp:288] Learning Rate Policy: step
I0705 13:34:13.702260 44772 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 13:35:00.751119 44772 solver.cpp:236] Iteration 620, loss = 0.692672
I0705 13:35:00.751287 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 13:35:00.751310 44772 solver.cpp:252]     Train net output #1: loss = 0.691887 (* 1 = 0.691887 loss)
I0705 13:35:00.751350 44772 sgd_solver.cpp:106] Iteration 620, lr = 0.025
I0705 13:35:46.110750 44772 solver.cpp:236] Iteration 630, loss = 0.693875
I0705 13:35:46.110965 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 13:35:46.110994 44772 solver.cpp:252]     Train net output #1: loss = 0.695907 (* 1 = 0.695907 loss)
I0705 13:35:46.111006 44772 sgd_solver.cpp:106] Iteration 630, lr = 0.025
I0705 13:36:29.276768 44772 solver.cpp:236] Iteration 640, loss = 0.693722
I0705 13:36:29.276965 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:36:29.276998 44772 solver.cpp:252]     Train net output #1: loss = 0.69333 (* 1 = 0.69333 loss)
I0705 13:36:29.277007 44772 sgd_solver.cpp:106] Iteration 640, lr = 0.025
I0705 13:37:19.478474 44772 solver.cpp:236] Iteration 650, loss = 0.693605
I0705 13:37:19.478615 44772 solver.cpp:252]     Train net output #0: accuracy = 0.429688
I0705 13:37:19.478647 44772 solver.cpp:252]     Train net output #1: loss = 0.694177 (* 1 = 0.694177 loss)
I0705 13:37:19.478662 44772 sgd_solver.cpp:106] Iteration 650, lr = 0.025
I0705 13:38:07.166749 44772 solver.cpp:236] Iteration 660, loss = 0.693497
I0705 13:38:07.166867 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 13:38:07.166895 44772 solver.cpp:252]     Train net output #1: loss = 0.6949 (* 1 = 0.6949 loss)
I0705 13:38:07.166906 44772 sgd_solver.cpp:106] Iteration 660, lr = 0.025
I0705 13:38:57.426334 44772 solver.cpp:236] Iteration 670, loss = 0.69373
I0705 13:38:57.426535 44772 solver.cpp:252]     Train net output #0: accuracy = 0.421875
I0705 13:38:57.426564 44772 solver.cpp:252]     Train net output #1: loss = 0.699378 (* 1 = 0.699378 loss)
I0705 13:38:57.426576 44772 sgd_solver.cpp:106] Iteration 670, lr = 0.025
I0705 13:39:46.242568 44772 solver.cpp:236] Iteration 680, loss = 0.693619
I0705 13:39:46.242712 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0705 13:39:46.242733 44772 solver.cpp:252]     Train net output #1: loss = 0.688508 (* 1 = 0.688508 loss)
I0705 13:39:46.242746 44772 sgd_solver.cpp:106] Iteration 680, lr = 0.025
I0705 13:40:23.829094 44772 solver.cpp:236] Iteration 690, loss = 0.693737
I0705 13:40:23.829263 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 13:40:23.829284 44772 solver.cpp:252]     Train net output #1: loss = 0.693025 (* 1 = 0.693025 loss)
I0705 13:40:23.829296 44772 sgd_solver.cpp:106] Iteration 690, lr = 0.025
I0705 13:41:02.202962 44772 solver.cpp:236] Iteration 700, loss = 0.693782
I0705 13:41:02.203102 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:41:02.203145 44772 solver.cpp:252]     Train net output #1: loss = 0.693996 (* 1 = 0.693996 loss)
I0705 13:41:02.203155 44772 sgd_solver.cpp:106] Iteration 700, lr = 0.025
I0705 13:41:42.224758 44772 solver.cpp:236] Iteration 710, loss = 0.693807
I0705 13:41:42.224900 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 13:41:42.224922 44772 solver.cpp:252]     Train net output #1: loss = 0.695031 (* 1 = 0.695031 loss)
I0705 13:41:42.224933 44772 sgd_solver.cpp:106] Iteration 710, lr = 0.025
I0705 13:42:21.640450 44772 solver.cpp:236] Iteration 720, loss = 0.693549
I0705 13:42:21.640588 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:42:21.640619 44772 solver.cpp:252]     Train net output #1: loss = 0.69397 (* 1 = 0.69397 loss)
I0705 13:42:21.640633 44772 sgd_solver.cpp:106] Iteration 720, lr = 0.025
I0705 13:43:02.272882 44772 solver.cpp:236] Iteration 730, loss = 0.693459
I0705 13:43:02.273023 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 13:43:02.273062 44772 solver.cpp:252]     Train net output #1: loss = 0.693825 (* 1 = 0.693825 loss)
I0705 13:43:02.273075 44772 sgd_solver.cpp:106] Iteration 730, lr = 0.025
I0705 13:43:41.515763 44772 solver.cpp:236] Iteration 740, loss = 0.69329
I0705 13:43:41.516010 44772 solver.cpp:252]     Train net output #0: accuracy = 0.617188
I0705 13:43:41.516043 44772 solver.cpp:252]     Train net output #1: loss = 0.691112 (* 1 = 0.691112 loss)
I0705 13:43:41.516059 44772 sgd_solver.cpp:106] Iteration 740, lr = 0.025
I0705 13:44:16.429903 44772 solver.cpp:340] Iteration 750, Testing net (#0)
I0705 13:45:52.164441 44772 solver.cpp:408]     Test net output #0: accuracy = 0.502813
I0705 13:45:52.164590 44772 solver.cpp:408]     Test net output #1: loss = 0.693589 (* 1 = 0.693589 loss)
I0705 13:45:52.314198 44772 solver.cpp:236] Iteration 750, loss = 0.693246
I0705 13:45:52.314220 44772 solver.cpp:252]     Train net output #0: accuracy = 0.554688
I0705 13:45:52.314232 44772 solver.cpp:252]     Train net output #1: loss = 0.689866 (* 1 = 0.689866 loss)
I0705 13:45:52.314245 44772 sgd_solver.cpp:106] Iteration 750, lr = 0.025
I0705 13:46:25.711318 44772 solver.cpp:236] Iteration 760, loss = 0.693337
I0705 13:46:25.711459 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 13:46:25.711505 44772 solver.cpp:252]     Train net output #1: loss = 0.693092 (* 1 = 0.693092 loss)
I0705 13:46:25.711521 44772 sgd_solver.cpp:106] Iteration 760, lr = 0.025
I0705 13:47:07.417843 44772 solver.cpp:236] Iteration 770, loss = 0.693486
I0705 13:47:07.418002 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 13:47:07.418032 44772 solver.cpp:252]     Train net output #1: loss = 0.692418 (* 1 = 0.692418 loss)
I0705 13:47:07.418045 44772 sgd_solver.cpp:106] Iteration 770, lr = 0.025
I0705 13:47:50.464643 44772 solver.cpp:236] Iteration 780, loss = 0.693324
I0705 13:47:50.464776 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 13:47:50.464824 44772 solver.cpp:252]     Train net output #1: loss = 0.695959 (* 1 = 0.695959 loss)
I0705 13:47:50.464840 44772 sgd_solver.cpp:106] Iteration 780, lr = 0.025
I0705 13:48:29.335256 44772 solver.cpp:236] Iteration 790, loss = 0.693375
I0705 13:48:29.335420 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 13:48:29.335448 44772 solver.cpp:252]     Train net output #1: loss = 0.692284 (* 1 = 0.692284 loss)
I0705 13:48:29.335474 44772 sgd_solver.cpp:106] Iteration 790, lr = 0.025
I0705 13:49:06.240248 44772 solver.cpp:236] Iteration 800, loss = 0.693429
I0705 13:49:06.240394 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 13:49:06.240444 44772 solver.cpp:252]     Train net output #1: loss = 0.692121 (* 1 = 0.692121 loss)
I0705 13:49:06.240460 44772 sgd_solver.cpp:106] Iteration 800, lr = 0.025
I0705 13:49:42.701864 44772 solver.cpp:236] Iteration 810, loss = 0.693584
I0705 13:49:42.702183 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:49:42.702208 44772 solver.cpp:252]     Train net output #1: loss = 0.693983 (* 1 = 0.693983 loss)
I0705 13:49:42.702224 44772 sgd_solver.cpp:106] Iteration 810, lr = 0.025
I0705 13:50:19.258700 44772 solver.cpp:236] Iteration 820, loss = 0.693511
I0705 13:50:19.258932 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:50:19.258968 44772 solver.cpp:252]     Train net output #1: loss = 0.693443 (* 1 = 0.693443 loss)
I0705 13:50:19.258985 44772 sgd_solver.cpp:106] Iteration 820, lr = 0.025
I0705 13:50:55.586261 44772 solver.cpp:236] Iteration 830, loss = 0.693329
I0705 13:50:55.586513 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 13:50:55.586555 44772 solver.cpp:252]     Train net output #1: loss = 0.690666 (* 1 = 0.690666 loss)
I0705 13:50:55.586573 44772 sgd_solver.cpp:106] Iteration 830, lr = 0.025
I0705 13:51:31.940330 44772 solver.cpp:236] Iteration 840, loss = 0.693718
I0705 13:51:31.940474 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0705 13:51:31.940500 44772 solver.cpp:252]     Train net output #1: loss = 0.692164 (* 1 = 0.692164 loss)
I0705 13:51:31.940518 44772 sgd_solver.cpp:106] Iteration 840, lr = 0.025
I0705 13:52:08.604583 44772 solver.cpp:236] Iteration 850, loss = 0.694071
I0705 13:52:08.604734 44772 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0705 13:52:08.604776 44772 solver.cpp:252]     Train net output #1: loss = 0.700215 (* 1 = 0.700215 loss)
I0705 13:52:08.604805 44772 sgd_solver.cpp:106] Iteration 850, lr = 0.025
I0705 13:52:47.455438 44772 solver.cpp:236] Iteration 860, loss = 0.693841
I0705 13:52:47.455638 44772 solver.cpp:252]     Train net output #0: accuracy = 0.554688
I0705 13:52:47.455680 44772 solver.cpp:252]     Train net output #1: loss = 0.689067 (* 1 = 0.689067 loss)
I0705 13:52:47.455699 44772 sgd_solver.cpp:106] Iteration 860, lr = 0.025
I0705 13:53:26.916086 44772 solver.cpp:236] Iteration 870, loss = 0.694431
I0705 13:53:26.916219 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 13:53:26.916270 44772 solver.cpp:252]     Train net output #1: loss = 0.690956 (* 1 = 0.690956 loss)
I0705 13:53:26.916288 44772 sgd_solver.cpp:106] Iteration 870, lr = 0.025
I0705 13:54:05.163717 44772 solver.cpp:236] Iteration 880, loss = 0.694544
I0705 13:54:05.163853 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:54:05.163883 44772 solver.cpp:252]     Train net output #1: loss = 0.693499 (* 1 = 0.693499 loss)
I0705 13:54:05.163899 44772 sgd_solver.cpp:106] Iteration 880, lr = 0.025
I0705 13:54:44.056990 44772 solver.cpp:236] Iteration 890, loss = 0.694046
I0705 13:54:44.057142 44772 solver.cpp:252]     Train net output #0: accuracy = 0.421875
I0705 13:54:44.057168 44772 solver.cpp:252]     Train net output #1: loss = 0.699402 (* 1 = 0.699402 loss)
I0705 13:54:44.057183 44772 sgd_solver.cpp:106] Iteration 890, lr = 0.025
I0705 13:55:24.035025 44772 solver.cpp:236] Iteration 900, loss = 0.693788
I0705 13:55:24.035145 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:55:24.035178 44772 solver.cpp:252]     Train net output #1: loss = 0.693954 (* 1 = 0.693954 loss)
I0705 13:55:24.035197 44772 sgd_solver.cpp:106] Iteration 900, lr = 0.025
I0705 13:56:06.011804 44772 solver.cpp:236] Iteration 910, loss = 0.69368
I0705 13:56:06.011968 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 13:56:06.012001 44772 solver.cpp:252]     Train net output #1: loss = 0.6901 (* 1 = 0.6901 loss)
I0705 13:56:06.012019 44772 sgd_solver.cpp:106] Iteration 910, lr = 0.025
I0705 13:56:54.030179 44772 solver.cpp:236] Iteration 920, loss = 0.693072
I0705 13:56:54.030426 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 13:56:54.030472 44772 solver.cpp:252]     Train net output #1: loss = 0.692873 (* 1 = 0.692873 loss)
I0705 13:56:54.030488 44772 sgd_solver.cpp:106] Iteration 920, lr = 0.025
I0705 13:57:42.223340 44772 solver.cpp:236] Iteration 930, loss = 0.693592
I0705 13:57:42.223459 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 13:57:42.223493 44772 solver.cpp:252]     Train net output #1: loss = 0.693958 (* 1 = 0.693958 loss)
I0705 13:57:42.223505 44772 sgd_solver.cpp:106] Iteration 930, lr = 0.025
I0705 13:58:29.846926 44772 solver.cpp:236] Iteration 940, loss = 0.693659
I0705 13:58:29.847062 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:58:29.847127 44772 solver.cpp:252]     Train net output #1: loss = 0.695512 (* 1 = 0.695512 loss)
I0705 13:58:29.847144 44772 sgd_solver.cpp:106] Iteration 940, lr = 0.025
I0705 13:59:17.421927 44772 solver.cpp:236] Iteration 950, loss = 0.693782
I0705 13:59:17.422199 44772 solver.cpp:252]     Train net output #0: accuracy = 0.390625
I0705 13:59:17.422220 44772 solver.cpp:252]     Train net output #1: loss = 0.695746 (* 1 = 0.695746 loss)
I0705 13:59:17.422235 44772 sgd_solver.cpp:106] Iteration 950, lr = 0.025
I0705 14:00:04.539504 44772 solver.cpp:236] Iteration 960, loss = 0.6939
I0705 14:00:04.539651 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:00:04.539682 44772 solver.cpp:252]     Train net output #1: loss = 0.694105 (* 1 = 0.694105 loss)
I0705 14:00:04.539695 44772 sgd_solver.cpp:106] Iteration 960, lr = 0.025
I0705 14:00:44.686077 44772 solver.cpp:236] Iteration 970, loss = 0.693992
I0705 14:00:44.686209 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 14:00:44.686251 44772 solver.cpp:252]     Train net output #1: loss = 0.69392 (* 1 = 0.69392 loss)
I0705 14:00:44.686262 44772 sgd_solver.cpp:106] Iteration 970, lr = 0.025
I0705 14:01:25.618912 44772 solver.cpp:236] Iteration 980, loss = 0.69354
I0705 14:01:25.619055 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 14:01:25.619102 44772 solver.cpp:252]     Train net output #1: loss = 0.694101 (* 1 = 0.694101 loss)
I0705 14:01:25.619119 44772 sgd_solver.cpp:106] Iteration 980, lr = 0.025
I0705 14:02:06.956132 44772 solver.cpp:236] Iteration 990, loss = 0.693511
I0705 14:02:06.956269 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 14:02:06.956315 44772 solver.cpp:252]     Train net output #1: loss = 0.696787 (* 1 = 0.696787 loss)
I0705 14:02:06.956329 44772 sgd_solver.cpp:106] Iteration 990, lr = 0.025
I0705 14:02:44.131273 44772 solver.cpp:340] Iteration 1000, Testing net (#0)
I0705 14:04:22.926453 44772 solver.cpp:408]     Test net output #0: accuracy = 0.513438
I0705 14:04:22.926707 44772 solver.cpp:408]     Test net output #1: loss = 0.692839 (* 1 = 0.692839 loss)
I0705 14:04:23.080940 44772 solver.cpp:236] Iteration 1000, loss = 0.693222
I0705 14:04:23.080962 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:04:23.080974 44772 solver.cpp:252]     Train net output #1: loss = 0.69035 (* 1 = 0.69035 loss)
I0705 14:04:23.080987 44772 sgd_solver.cpp:106] Iteration 1000, lr = 0.025
I0705 14:04:55.916193 44772 solver.cpp:236] Iteration 1010, loss = 0.693262
I0705 14:04:55.916326 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:04:55.916366 44772 solver.cpp:252]     Train net output #1: loss = 0.693204 (* 1 = 0.693204 loss)
I0705 14:04:55.916393 44772 sgd_solver.cpp:106] Iteration 1010, lr = 0.025
I0705 14:05:38.490416 44772 solver.cpp:236] Iteration 1020, loss = 0.693315
I0705 14:05:38.490559 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 14:05:38.490620 44772 solver.cpp:252]     Train net output #1: loss = 0.693026 (* 1 = 0.693026 loss)
I0705 14:05:38.490638 44772 sgd_solver.cpp:106] Iteration 1020, lr = 0.025
I0705 14:06:20.121670 44772 solver.cpp:236] Iteration 1030, loss = 0.693257
I0705 14:06:20.121867 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 14:06:20.121886 44772 solver.cpp:252]     Train net output #1: loss = 0.697791 (* 1 = 0.697791 loss)
I0705 14:06:20.121898 44772 sgd_solver.cpp:106] Iteration 1030, lr = 0.025
I0705 14:07:02.348917 44772 solver.cpp:236] Iteration 1040, loss = 0.693225
I0705 14:07:02.349125 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 14:07:02.349176 44772 solver.cpp:252]     Train net output #1: loss = 0.693511 (* 1 = 0.693511 loss)
I0705 14:07:02.349189 44772 sgd_solver.cpp:106] Iteration 1040, lr = 0.025
I0705 14:07:45.022275 44772 solver.cpp:236] Iteration 1050, loss = 0.693512
I0705 14:07:45.022454 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 14:07:45.022480 44772 solver.cpp:252]     Train net output #1: loss = 0.693024 (* 1 = 0.693024 loss)
I0705 14:07:45.022492 44772 sgd_solver.cpp:106] Iteration 1050, lr = 0.025
I0705 14:08:27.659868 44772 solver.cpp:236] Iteration 1060, loss = 0.693544
I0705 14:08:27.660068 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 14:08:27.660087 44772 solver.cpp:252]     Train net output #1: loss = 0.693047 (* 1 = 0.693047 loss)
I0705 14:08:27.660099 44772 sgd_solver.cpp:106] Iteration 1060, lr = 0.025
I0705 14:09:07.037390 44772 solver.cpp:236] Iteration 1070, loss = 0.69345
I0705 14:09:07.037544 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:09:07.037587 44772 solver.cpp:252]     Train net output #1: loss = 0.693206 (* 1 = 0.693206 loss)
I0705 14:09:07.037600 44772 sgd_solver.cpp:106] Iteration 1070, lr = 0.025
I0705 14:09:46.079187 44772 solver.cpp:236] Iteration 1080, loss = 0.693489
I0705 14:09:46.079313 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 14:09:46.079358 44772 solver.cpp:252]     Train net output #1: loss = 0.693166 (* 1 = 0.693166 loss)
I0705 14:09:46.079375 44772 sgd_solver.cpp:106] Iteration 1080, lr = 0.025
I0705 14:10:22.969882 44772 solver.cpp:236] Iteration 1090, loss = 0.693682
I0705 14:10:22.970067 44772 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0705 14:10:22.970085 44772 solver.cpp:252]     Train net output #1: loss = 0.695576 (* 1 = 0.695576 loss)
I0705 14:10:22.970095 44772 sgd_solver.cpp:106] Iteration 1090, lr = 0.025
I0705 14:11:00.565374 44772 solver.cpp:236] Iteration 1100, loss = 0.693346
I0705 14:11:00.572464 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:11:00.572477 44772 solver.cpp:252]     Train net output #1: loss = 0.69497 (* 1 = 0.69497 loss)
I0705 14:11:00.572486 44772 sgd_solver.cpp:106] Iteration 1100, lr = 0.025
I0705 14:11:40.209405 44772 solver.cpp:236] Iteration 1110, loss = 0.693067
I0705 14:11:40.209702 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:11:40.209722 44772 solver.cpp:252]     Train net output #1: loss = 0.689143 (* 1 = 0.689143 loss)
I0705 14:11:40.209738 44772 sgd_solver.cpp:106] Iteration 1110, lr = 0.025
I0705 14:12:19.185822 44772 solver.cpp:236] Iteration 1120, loss = 0.693335
I0705 14:12:19.185986 44772 solver.cpp:252]     Train net output #0: accuracy = 0.554688
I0705 14:12:19.186024 44772 solver.cpp:252]     Train net output #1: loss = 0.69257 (* 1 = 0.69257 loss)
I0705 14:12:19.186039 44772 sgd_solver.cpp:106] Iteration 1120, lr = 0.025
I0705 14:13:01.832104 44772 solver.cpp:236] Iteration 1130, loss = 0.693369
I0705 14:13:01.832407 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 14:13:01.832433 44772 solver.cpp:252]     Train net output #1: loss = 0.6932 (* 1 = 0.6932 loss)
I0705 14:13:01.832447 44772 sgd_solver.cpp:106] Iteration 1130, lr = 0.025
I0705 14:13:44.715673 44772 solver.cpp:236] Iteration 1140, loss = 0.693298
I0705 14:13:44.715898 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 14:13:44.715944 44772 solver.cpp:252]     Train net output #1: loss = 0.693666 (* 1 = 0.693666 loss)
I0705 14:13:44.715957 44772 sgd_solver.cpp:106] Iteration 1140, lr = 0.025
I0705 14:14:28.597851 44772 solver.cpp:236] Iteration 1150, loss = 0.693114
I0705 14:14:28.598145 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:14:28.598167 44772 solver.cpp:252]     Train net output #1: loss = 0.695485 (* 1 = 0.695485 loss)
I0705 14:14:28.598181 44772 sgd_solver.cpp:106] Iteration 1150, lr = 0.025
I0705 14:15:12.255270 44772 solver.cpp:236] Iteration 1160, loss = 0.693437
I0705 14:15:12.255430 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 14:15:12.255450 44772 solver.cpp:252]     Train net output #1: loss = 0.694028 (* 1 = 0.694028 loss)
I0705 14:15:12.255470 44772 sgd_solver.cpp:106] Iteration 1160, lr = 0.025
I0705 14:15:55.352946 44772 solver.cpp:236] Iteration 1170, loss = 0.693391
I0705 14:15:55.353139 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 14:15:55.353166 44772 solver.cpp:252]     Train net output #1: loss = 0.69347 (* 1 = 0.69347 loss)
I0705 14:15:55.353176 44772 sgd_solver.cpp:106] Iteration 1170, lr = 0.025
I0705 14:16:39.138919 44772 solver.cpp:236] Iteration 1180, loss = 0.693688
I0705 14:16:39.139179 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 14:16:39.139206 44772 solver.cpp:252]     Train net output #1: loss = 0.694083 (* 1 = 0.694083 loss)
I0705 14:16:39.139235 44772 sgd_solver.cpp:106] Iteration 1180, lr = 0.025
I0705 14:17:24.206508 44772 solver.cpp:236] Iteration 1190, loss = 0.693773
I0705 14:17:24.206718 44772 solver.cpp:252]     Train net output #0: accuracy = 0.421875
I0705 14:17:24.206738 44772 solver.cpp:252]     Train net output #1: loss = 0.694159 (* 1 = 0.694159 loss)
I0705 14:17:24.206759 44772 sgd_solver.cpp:106] Iteration 1190, lr = 0.025
I0705 14:18:12.483109 44772 solver.cpp:236] Iteration 1200, loss = 0.694038
I0705 14:18:12.483289 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 14:18:12.483319 44772 solver.cpp:252]     Train net output #1: loss = 0.690894 (* 1 = 0.690894 loss)
I0705 14:18:12.483331 44772 sgd_solver.cpp:106] Iteration 1200, lr = 0.025
I0705 14:19:00.722856 44772 solver.cpp:236] Iteration 1210, loss = 0.69403
I0705 14:19:00.723009 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:19:00.723038 44772 solver.cpp:252]     Train net output #1: loss = 0.693501 (* 1 = 0.693501 loss)
I0705 14:19:00.723062 44772 sgd_solver.cpp:106] Iteration 1210, lr = 0.025
I0705 14:19:50.070047 44772 solver.cpp:236] Iteration 1220, loss = 0.693903
I0705 14:19:50.070209 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 14:19:50.070253 44772 solver.cpp:252]     Train net output #1: loss = 0.69216 (* 1 = 0.69216 loss)
I0705 14:19:50.070267 44772 sgd_solver.cpp:106] Iteration 1220, lr = 0.025
I0705 14:20:39.222018 44772 solver.cpp:236] Iteration 1230, loss = 0.693612
I0705 14:20:39.222194 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 14:20:39.222246 44772 solver.cpp:252]     Train net output #1: loss = 0.692169 (* 1 = 0.692169 loss)
I0705 14:20:39.222264 44772 sgd_solver.cpp:106] Iteration 1230, lr = 0.025
I0705 14:21:27.191983 44772 solver.cpp:236] Iteration 1240, loss = 0.693316
I0705 14:21:27.192245 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:21:27.192279 44772 solver.cpp:252]     Train net output #1: loss = 0.690326 (* 1 = 0.690326 loss)
I0705 14:21:27.192292 44772 sgd_solver.cpp:106] Iteration 1240, lr = 0.025
I0705 14:22:09.937309 44772 solver.cpp:340] Iteration 1250, Testing net (#0)
I0705 14:24:04.907117 44772 solver.cpp:408]     Test net output #0: accuracy = 0.502187
I0705 14:24:04.907322 44772 solver.cpp:408]     Test net output #1: loss = 0.693249 (* 1 = 0.693249 loss)
I0705 14:24:05.061064 44772 solver.cpp:236] Iteration 1250, loss = 0.693471
I0705 14:24:05.061121 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 14:24:05.061139 44772 solver.cpp:252]     Train net output #1: loss = 0.694843 (* 1 = 0.694843 loss)
I0705 14:24:05.061153 44772 sgd_solver.cpp:106] Iteration 1250, lr = 0.025
I0705 14:24:43.731783 44772 solver.cpp:236] Iteration 1260, loss = 0.693283
I0705 14:24:43.731964 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:24:43.731994 44772 solver.cpp:252]     Train net output #1: loss = 0.697347 (* 1 = 0.697347 loss)
I0705 14:24:43.732008 44772 sgd_solver.cpp:106] Iteration 1260, lr = 0.025
I0705 14:25:27.789036 44772 solver.cpp:236] Iteration 1270, loss = 0.693533
I0705 14:25:27.789171 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:25:27.789225 44772 solver.cpp:252]     Train net output #1: loss = 0.69066 (* 1 = 0.69066 loss)
I0705 14:25:27.789239 44772 sgd_solver.cpp:106] Iteration 1270, lr = 0.025
I0705 14:26:07.073525 44772 solver.cpp:236] Iteration 1280, loss = 0.693556
I0705 14:26:07.073721 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:26:07.073746 44772 solver.cpp:252]     Train net output #1: loss = 0.693199 (* 1 = 0.693199 loss)
I0705 14:26:07.073761 44772 sgd_solver.cpp:106] Iteration 1280, lr = 0.025
I0705 14:26:46.832108 44772 solver.cpp:236] Iteration 1290, loss = 0.693738
I0705 14:26:46.832262 44772 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0705 14:26:46.832305 44772 solver.cpp:252]     Train net output #1: loss = 0.694062 (* 1 = 0.694062 loss)
I0705 14:26:46.832320 44772 sgd_solver.cpp:106] Iteration 1290, lr = 0.025
I0705 14:27:26.798774 44772 solver.cpp:236] Iteration 1300, loss = 0.693566
I0705 14:27:26.798915 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 14:27:26.798943 44772 solver.cpp:252]     Train net output #1: loss = 0.691678 (* 1 = 0.691678 loss)
I0705 14:27:26.798957 44772 sgd_solver.cpp:106] Iteration 1300, lr = 0.025
I0705 14:28:04.813427 44772 solver.cpp:236] Iteration 1310, loss = 0.693515
I0705 14:28:04.813616 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 14:28:04.813645 44772 solver.cpp:252]     Train net output #1: loss = 0.697791 (* 1 = 0.697791 loss)
I0705 14:28:04.813664 44772 sgd_solver.cpp:106] Iteration 1310, lr = 0.025
I0705 14:28:42.462363 44772 solver.cpp:236] Iteration 1320, loss = 0.69347
I0705 14:28:42.462488 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 14:28:42.462505 44772 solver.cpp:252]     Train net output #1: loss = 0.69338 (* 1 = 0.69338 loss)
I0705 14:28:42.462543 44772 sgd_solver.cpp:106] Iteration 1320, lr = 0.025
I0705 14:29:17.472123 44772 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 14:29:21.543223 44772 solver.cpp:236] Iteration 1330, loss = 0.693438
I0705 14:29:21.543275 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 14:29:21.543292 44772 solver.cpp:252]     Train net output #1: loss = 0.691667 (* 1 = 0.691667 loss)
I0705 14:29:21.543304 44772 sgd_solver.cpp:106] Iteration 1330, lr = 0.025
I0705 14:30:09.340070 44772 solver.cpp:236] Iteration 1340, loss = 0.693488
I0705 14:30:09.340215 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:30:09.340245 44772 solver.cpp:252]     Train net output #1: loss = 0.693253 (* 1 = 0.693253 loss)
I0705 14:30:09.340267 44772 sgd_solver.cpp:106] Iteration 1340, lr = 0.025
I0705 14:30:55.368813 44772 solver.cpp:236] Iteration 1350, loss = 0.693477
I0705 14:30:55.368979 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 14:30:55.369019 44772 solver.cpp:252]     Train net output #1: loss = 0.69266 (* 1 = 0.69266 loss)
I0705 14:30:55.369029 44772 sgd_solver.cpp:106] Iteration 1350, lr = 0.025
I0705 14:31:42.447558 44772 solver.cpp:236] Iteration 1360, loss = 0.693613
I0705 14:31:42.447692 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:31:42.447711 44772 solver.cpp:252]     Train net output #1: loss = 0.690279 (* 1 = 0.690279 loss)
I0705 14:31:42.447734 44772 sgd_solver.cpp:106] Iteration 1360, lr = 0.025
I0705 14:32:28.633031 44772 solver.cpp:236] Iteration 1370, loss = 0.693425
I0705 14:32:28.633189 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 14:32:28.633235 44772 solver.cpp:252]     Train net output #1: loss = 0.69409 (* 1 = 0.69409 loss)
I0705 14:32:28.633250 44772 sgd_solver.cpp:106] Iteration 1370, lr = 0.025
I0705 14:33:15.634475 44772 solver.cpp:236] Iteration 1380, loss = 0.693284
I0705 14:33:15.634697 44772 solver.cpp:252]     Train net output #0: accuracy = 0.570312
I0705 14:33:15.634719 44772 solver.cpp:252]     Train net output #1: loss = 0.687582 (* 1 = 0.687582 loss)
I0705 14:33:15.634733 44772 sgd_solver.cpp:106] Iteration 1380, lr = 0.025
I0705 14:34:01.565714 44772 solver.cpp:236] Iteration 1390, loss = 0.693417
I0705 14:34:01.568032 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:34:01.568058 44772 solver.cpp:252]     Train net output #1: loss = 0.694492 (* 1 = 0.694492 loss)
I0705 14:34:01.568073 44772 sgd_solver.cpp:106] Iteration 1390, lr = 0.025
I0705 14:34:48.432313 44772 solver.cpp:236] Iteration 1400, loss = 0.693637
I0705 14:34:48.432492 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 14:34:48.432538 44772 solver.cpp:252]     Train net output #1: loss = 0.699202 (* 1 = 0.699202 loss)
I0705 14:34:48.432557 44772 sgd_solver.cpp:106] Iteration 1400, lr = 0.025
I0705 14:35:35.099248 44772 solver.cpp:236] Iteration 1410, loss = 0.693749
I0705 14:35:35.099438 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:35:35.099464 44772 solver.cpp:252]     Train net output #1: loss = 0.694071 (* 1 = 0.694071 loss)
I0705 14:35:35.099484 44772 sgd_solver.cpp:106] Iteration 1410, lr = 0.025
I0705 14:36:22.666957 44772 solver.cpp:236] Iteration 1420, loss = 0.693611
I0705 14:36:22.667404 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 14:36:22.667424 44772 solver.cpp:252]     Train net output #1: loss = 0.693676 (* 1 = 0.693676 loss)
I0705 14:36:22.667433 44772 sgd_solver.cpp:106] Iteration 1420, lr = 0.025
I0705 14:37:09.498714 44772 solver.cpp:236] Iteration 1430, loss = 0.693707
I0705 14:37:09.499063 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 14:37:09.499079 44772 solver.cpp:252]     Train net output #1: loss = 0.692677 (* 1 = 0.692677 loss)
I0705 14:37:09.499092 44772 sgd_solver.cpp:106] Iteration 1430, lr = 0.025
I0705 14:37:55.468013 44772 solver.cpp:236] Iteration 1440, loss = 0.693679
I0705 14:37:55.468153 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:37:55.468184 44772 solver.cpp:252]     Train net output #1: loss = 0.692315 (* 1 = 0.692315 loss)
I0705 14:37:55.468205 44772 sgd_solver.cpp:106] Iteration 1440, lr = 0.025
I0705 14:38:38.064504 44772 solver.cpp:236] Iteration 1450, loss = 0.693602
I0705 14:38:38.064723 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 14:38:38.064743 44772 solver.cpp:252]     Train net output #1: loss = 0.697777 (* 1 = 0.697777 loss)
I0705 14:38:38.064754 44772 sgd_solver.cpp:106] Iteration 1450, lr = 0.025
I0705 14:39:17.295974 44772 solver.cpp:236] Iteration 1460, loss = 0.693246
I0705 14:39:17.296244 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:39:17.296270 44772 solver.cpp:252]     Train net output #1: loss = 0.695209 (* 1 = 0.695209 loss)
I0705 14:39:17.296289 44772 sgd_solver.cpp:106] Iteration 1460, lr = 0.025
I0705 14:39:57.919407 44772 solver.cpp:236] Iteration 1470, loss = 0.693308
I0705 14:39:57.919729 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:39:57.919751 44772 solver.cpp:252]     Train net output #1: loss = 0.6952 (* 1 = 0.6952 loss)
I0705 14:39:57.919765 44772 sgd_solver.cpp:106] Iteration 1470, lr = 0.025
I0705 14:40:38.202896 44772 solver.cpp:236] Iteration 1480, loss = 0.693407
I0705 14:40:38.203088 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 14:40:38.203112 44772 solver.cpp:252]     Train net output #1: loss = 0.693035 (* 1 = 0.693035 loss)
I0705 14:40:38.203126 44772 sgd_solver.cpp:106] Iteration 1480, lr = 0.025
I0705 14:41:18.393187 44772 solver.cpp:236] Iteration 1490, loss = 0.693251
I0705 14:41:18.393419 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 14:41:18.393442 44772 solver.cpp:252]     Train net output #1: loss = 0.701778 (* 1 = 0.701778 loss)
I0705 14:41:18.393461 44772 sgd_solver.cpp:106] Iteration 1490, lr = 0.025
I0705 14:41:56.305555 44772 solver.cpp:340] Iteration 1500, Testing net (#0)
I0705 14:43:36.512904 44772 solver.cpp:408]     Test net output #0: accuracy = 0.498437
I0705 14:43:36.513092 44772 solver.cpp:408]     Test net output #1: loss = 0.693162 (* 1 = 0.693162 loss)
I0705 14:43:36.666966 44772 solver.cpp:236] Iteration 1500, loss = 0.693883
I0705 14:43:36.667016 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:43:36.667032 44772 solver.cpp:252]     Train net output #1: loss = 0.693249 (* 1 = 0.693249 loss)
I0705 14:43:36.667047 44772 sgd_solver.cpp:106] Iteration 1500, lr = 0.025
I0705 14:44:09.615080 44772 solver.cpp:236] Iteration 1510, loss = 0.694141
I0705 14:44:09.615382 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 14:44:09.615401 44772 solver.cpp:252]     Train net output #1: loss = 0.693697 (* 1 = 0.693697 loss)
I0705 14:44:09.615417 44772 sgd_solver.cpp:106] Iteration 1510, lr = 0.025
I0705 14:44:51.581610 44772 solver.cpp:236] Iteration 1520, loss = 0.693901
I0705 14:44:51.581768 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 14:44:51.581818 44772 solver.cpp:252]     Train net output #1: loss = 0.6928 (* 1 = 0.6928 loss)
I0705 14:44:51.581830 44772 sgd_solver.cpp:106] Iteration 1520, lr = 0.025
I0705 14:45:33.250577 44772 solver.cpp:236] Iteration 1530, loss = 0.694291
I0705 14:45:33.250710 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 14:45:33.250742 44772 solver.cpp:252]     Train net output #1: loss = 0.693162 (* 1 = 0.693162 loss)
I0705 14:45:33.250774 44772 sgd_solver.cpp:106] Iteration 1530, lr = 0.025
I0705 14:46:15.254218 44772 solver.cpp:236] Iteration 1540, loss = 0.694104
I0705 14:46:15.254415 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 14:46:15.254444 44772 solver.cpp:252]     Train net output #1: loss = 0.689476 (* 1 = 0.689476 loss)
I0705 14:46:15.254467 44772 sgd_solver.cpp:106] Iteration 1540, lr = 0.025
I0705 14:46:55.281409 44772 solver.cpp:236] Iteration 1550, loss = 0.693346
I0705 14:46:55.281548 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 14:46:55.281590 44772 solver.cpp:252]     Train net output #1: loss = 0.694217 (* 1 = 0.694217 loss)
I0705 14:46:55.281610 44772 sgd_solver.cpp:106] Iteration 1550, lr = 0.025
I0705 14:47:34.633924 44772 solver.cpp:236] Iteration 1560, loss = 0.69345
I0705 14:47:34.634081 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 14:47:34.634124 44772 solver.cpp:252]     Train net output #1: loss = 0.69477 (* 1 = 0.69477 loss)
I0705 14:47:34.634138 44772 sgd_solver.cpp:106] Iteration 1560, lr = 0.025
I0705 14:48:13.842623 44772 solver.cpp:236] Iteration 1570, loss = 0.69367
I0705 14:48:13.842770 44772 solver.cpp:252]     Train net output #0: accuracy = 0.59375
I0705 14:48:13.842804 44772 solver.cpp:252]     Train net output #1: loss = 0.687379 (* 1 = 0.687379 loss)
I0705 14:48:13.842828 44772 sgd_solver.cpp:106] Iteration 1570, lr = 0.025
I0705 14:48:54.760637 44772 solver.cpp:236] Iteration 1580, loss = 0.693443
I0705 14:48:54.760819 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 14:48:54.760867 44772 solver.cpp:252]     Train net output #1: loss = 0.692275 (* 1 = 0.692275 loss)
I0705 14:48:54.760886 44772 sgd_solver.cpp:106] Iteration 1580, lr = 0.025
I0705 14:49:37.434010 44772 solver.cpp:236] Iteration 1590, loss = 0.69381
I0705 14:49:37.434207 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 14:49:37.434254 44772 solver.cpp:252]     Train net output #1: loss = 0.692086 (* 1 = 0.692086 loss)
I0705 14:49:37.434273 44772 sgd_solver.cpp:106] Iteration 1590, lr = 0.025
I0705 14:50:17.609809 44772 solver.cpp:236] Iteration 1600, loss = 0.693539
I0705 14:50:17.609956 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 14:50:17.610004 44772 solver.cpp:252]     Train net output #1: loss = 0.690904 (* 1 = 0.690904 loss)
I0705 14:50:17.610018 44772 sgd_solver.cpp:106] Iteration 1600, lr = 0.025
I0705 14:51:00.797708 44772 solver.cpp:236] Iteration 1610, loss = 0.693523
I0705 14:51:00.797880 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 14:51:00.797927 44772 solver.cpp:252]     Train net output #1: loss = 0.693333 (* 1 = 0.693333 loss)
I0705 14:51:00.797947 44772 sgd_solver.cpp:106] Iteration 1610, lr = 0.025
I0705 14:51:45.882014 44772 solver.cpp:236] Iteration 1620, loss = 0.693389
I0705 14:51:45.882216 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:51:45.882236 44772 solver.cpp:252]     Train net output #1: loss = 0.694568 (* 1 = 0.694568 loss)
I0705 14:51:45.882251 44772 sgd_solver.cpp:106] Iteration 1620, lr = 0.025
I0705 14:52:31.128603 44772 solver.cpp:236] Iteration 1630, loss = 0.693732
I0705 14:52:31.128770 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 14:52:31.128816 44772 solver.cpp:252]     Train net output #1: loss = 0.69858 (* 1 = 0.69858 loss)
I0705 14:52:31.128826 44772 sgd_solver.cpp:106] Iteration 1630, lr = 0.025
I0705 14:53:15.845149 44772 solver.cpp:236] Iteration 1640, loss = 0.693932
I0705 14:53:15.845306 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:53:15.845357 44772 solver.cpp:252]     Train net output #1: loss = 0.697511 (* 1 = 0.697511 loss)
I0705 14:53:15.845368 44772 sgd_solver.cpp:106] Iteration 1640, lr = 0.025
I0705 14:54:02.040791 44772 solver.cpp:236] Iteration 1650, loss = 0.694799
I0705 14:54:02.040931 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 14:54:02.040974 44772 solver.cpp:252]     Train net output #1: loss = 0.693204 (* 1 = 0.693204 loss)
I0705 14:54:02.040987 44772 sgd_solver.cpp:106] Iteration 1650, lr = 0.025
I0705 14:54:47.182466 44772 solver.cpp:236] Iteration 1660, loss = 0.694879
I0705 14:54:47.182706 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 14:54:47.182732 44772 solver.cpp:252]     Train net output #1: loss = 0.695248 (* 1 = 0.695248 loss)
I0705 14:54:47.182754 44772 sgd_solver.cpp:106] Iteration 1660, lr = 0.025
I0705 14:55:29.359617 44772 solver.cpp:236] Iteration 1670, loss = 0.694976
I0705 14:55:29.364511 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 14:55:29.364534 44772 solver.cpp:252]     Train net output #1: loss = 0.692823 (* 1 = 0.692823 loss)
I0705 14:55:29.364544 44772 sgd_solver.cpp:106] Iteration 1670, lr = 0.025
I0705 14:56:10.211344 44772 solver.cpp:236] Iteration 1680, loss = 0.69443
I0705 14:56:10.211644 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 14:56:10.211665 44772 solver.cpp:252]     Train net output #1: loss = 0.693225 (* 1 = 0.693225 loss)
I0705 14:56:10.211678 44772 sgd_solver.cpp:106] Iteration 1680, lr = 0.025
I0705 14:56:53.488391 44772 solver.cpp:236] Iteration 1690, loss = 0.694011
I0705 14:56:53.488592 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 14:56:53.488620 44772 solver.cpp:252]     Train net output #1: loss = 0.694191 (* 1 = 0.694191 loss)
I0705 14:56:53.488641 44772 sgd_solver.cpp:106] Iteration 1690, lr = 0.025
I0705 14:57:34.740814 44772 solver.cpp:236] Iteration 1700, loss = 0.693337
I0705 14:57:34.741027 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 14:57:34.741058 44772 solver.cpp:252]     Train net output #1: loss = 0.69313 (* 1 = 0.69313 loss)
I0705 14:57:34.741076 44772 sgd_solver.cpp:106] Iteration 1700, lr = 0.025
I0705 14:58:16.397233 44772 solver.cpp:236] Iteration 1710, loss = 0.693243
I0705 14:58:16.397388 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 14:58:16.397404 44772 solver.cpp:252]     Train net output #1: loss = 0.693577 (* 1 = 0.693577 loss)
I0705 14:58:16.397428 44772 sgd_solver.cpp:106] Iteration 1710, lr = 0.025
I0705 14:58:56.988755 44772 solver.cpp:236] Iteration 1720, loss = 0.693417
I0705 14:58:56.989006 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 14:58:56.989029 44772 solver.cpp:252]     Train net output #1: loss = 0.69369 (* 1 = 0.69369 loss)
I0705 14:58:56.989043 44772 sgd_solver.cpp:106] Iteration 1720, lr = 0.025
I0705 14:59:38.601644 44772 solver.cpp:236] Iteration 1730, loss = 0.693457
I0705 14:59:38.601847 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 14:59:38.601866 44772 solver.cpp:252]     Train net output #1: loss = 0.692933 (* 1 = 0.692933 loss)
I0705 14:59:38.601882 44772 sgd_solver.cpp:106] Iteration 1730, lr = 0.025
I0705 15:00:23.953465 44772 solver.cpp:236] Iteration 1740, loss = 0.69338
I0705 15:00:23.953640 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:00:23.953676 44772 solver.cpp:252]     Train net output #1: loss = 0.695657 (* 1 = 0.695657 loss)
I0705 15:00:23.953701 44772 sgd_solver.cpp:106] Iteration 1740, lr = 0.025
I0705 15:01:05.665217 44772 solver.cpp:340] Iteration 1750, Testing net (#0)
I0705 15:02:54.939662 44772 solver.cpp:408]     Test net output #0: accuracy = 0.494375
I0705 15:02:54.939849 44772 solver.cpp:408]     Test net output #1: loss = 0.695063 (* 1 = 0.695063 loss)
I0705 15:02:55.089112 44772 solver.cpp:236] Iteration 1750, loss = 0.693357
I0705 15:02:55.089157 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 15:02:55.089179 44772 solver.cpp:252]     Train net output #1: loss = 0.689637 (* 1 = 0.689637 loss)
I0705 15:02:55.089198 44772 sgd_solver.cpp:106] Iteration 1750, lr = 0.025
I0705 15:03:30.768651 44772 solver.cpp:236] Iteration 1760, loss = 0.693486
I0705 15:03:30.768887 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 15:03:30.768914 44772 solver.cpp:252]     Train net output #1: loss = 0.696269 (* 1 = 0.696269 loss)
I0705 15:03:30.768923 44772 sgd_solver.cpp:106] Iteration 1760, lr = 0.025
I0705 15:04:12.760800 44772 solver.cpp:236] Iteration 1770, loss = 0.693698
I0705 15:04:12.760957 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 15:04:12.760987 44772 solver.cpp:252]     Train net output #1: loss = 0.692729 (* 1 = 0.692729 loss)
I0705 15:04:12.760999 44772 sgd_solver.cpp:106] Iteration 1770, lr = 0.025
I0705 15:04:54.027532 44772 solver.cpp:236] Iteration 1780, loss = 0.693666
I0705 15:04:54.027667 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 15:04:54.027696 44772 solver.cpp:252]     Train net output #1: loss = 0.69345 (* 1 = 0.69345 loss)
I0705 15:04:54.027714 44772 sgd_solver.cpp:106] Iteration 1780, lr = 0.025
I0705 15:05:33.785420 44772 solver.cpp:236] Iteration 1790, loss = 0.693787
I0705 15:05:33.785565 44772 solver.cpp:252]     Train net output #0: accuracy = 0.414062
I0705 15:05:33.785598 44772 solver.cpp:252]     Train net output #1: loss = 0.698723 (* 1 = 0.698723 loss)
I0705 15:05:33.785621 44772 sgd_solver.cpp:106] Iteration 1790, lr = 0.025
I0705 15:06:12.788090 44772 solver.cpp:236] Iteration 1800, loss = 0.693942
I0705 15:06:12.788271 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 15:06:12.788303 44772 solver.cpp:252]     Train net output #1: loss = 0.693239 (* 1 = 0.693239 loss)
I0705 15:06:12.788316 44772 sgd_solver.cpp:106] Iteration 1800, lr = 0.025
I0705 15:06:52.612068 44772 solver.cpp:236] Iteration 1810, loss = 0.694054
I0705 15:06:52.612226 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:06:52.612248 44772 solver.cpp:252]     Train net output #1: loss = 0.696258 (* 1 = 0.696258 loss)
I0705 15:06:52.612267 44772 sgd_solver.cpp:106] Iteration 1810, lr = 0.025
I0705 15:07:31.918479 44772 solver.cpp:236] Iteration 1820, loss = 0.693972
I0705 15:07:31.918649 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 15:07:31.918678 44772 solver.cpp:252]     Train net output #1: loss = 0.691543 (* 1 = 0.691543 loss)
I0705 15:07:31.918692 44772 sgd_solver.cpp:106] Iteration 1820, lr = 0.025
I0705 15:08:15.819259 44772 solver.cpp:236] Iteration 1830, loss = 0.693873
I0705 15:08:15.819537 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 15:08:15.819562 44772 solver.cpp:252]     Train net output #1: loss = 0.699931 (* 1 = 0.699931 loss)
I0705 15:08:15.819576 44772 sgd_solver.cpp:106] Iteration 1830, lr = 0.025
I0705 15:09:03.366806 44772 solver.cpp:236] Iteration 1840, loss = 0.693792
I0705 15:09:03.366962 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 15:09:03.367012 44772 solver.cpp:252]     Train net output #1: loss = 0.695584 (* 1 = 0.695584 loss)
I0705 15:09:03.367024 44772 sgd_solver.cpp:106] Iteration 1840, lr = 0.025
I0705 15:09:51.270165 44772 solver.cpp:236] Iteration 1850, loss = 0.693955
I0705 15:09:51.270306 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 15:09:51.270361 44772 solver.cpp:252]     Train net output #1: loss = 0.692926 (* 1 = 0.692926 loss)
I0705 15:09:51.270378 44772 sgd_solver.cpp:106] Iteration 1850, lr = 0.025
I0705 15:10:41.112107 44772 solver.cpp:236] Iteration 1860, loss = 0.69359
I0705 15:10:41.112248 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 15:10:41.112278 44772 solver.cpp:252]     Train net output #1: loss = 0.693003 (* 1 = 0.693003 loss)
I0705 15:10:41.112303 44772 sgd_solver.cpp:106] Iteration 1860, lr = 0.025
I0705 15:11:29.191658 44772 solver.cpp:236] Iteration 1870, loss = 0.69334
I0705 15:11:29.191807 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 15:11:29.191857 44772 solver.cpp:252]     Train net output #1: loss = 0.693196 (* 1 = 0.693196 loss)
I0705 15:11:29.191870 44772 sgd_solver.cpp:106] Iteration 1870, lr = 0.025
I0705 15:12:16.242655 44772 solver.cpp:236] Iteration 1880, loss = 0.693409
I0705 15:12:16.242894 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 15:12:16.242916 44772 solver.cpp:252]     Train net output #1: loss = 0.692877 (* 1 = 0.692877 loss)
I0705 15:12:16.242929 44772 sgd_solver.cpp:106] Iteration 1880, lr = 0.025
I0705 15:12:58.914108 44772 solver.cpp:236] Iteration 1890, loss = 0.693714
I0705 15:12:58.914263 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 15:12:58.914305 44772 solver.cpp:252]     Train net output #1: loss = 0.695035 (* 1 = 0.695035 loss)
I0705 15:12:58.914331 44772 sgd_solver.cpp:106] Iteration 1890, lr = 0.025
I0705 15:13:40.323029 44772 solver.cpp:236] Iteration 1900, loss = 0.693487
I0705 15:13:40.323185 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 15:13:40.323220 44772 solver.cpp:252]     Train net output #1: loss = 0.693137 (* 1 = 0.693137 loss)
I0705 15:13:40.323231 44772 sgd_solver.cpp:106] Iteration 1900, lr = 0.025
I0705 15:14:21.500669 44772 solver.cpp:236] Iteration 1910, loss = 0.693474
I0705 15:14:21.500852 44772 solver.cpp:252]     Train net output #0: accuracy = 0.585938
I0705 15:14:21.500890 44772 solver.cpp:252]     Train net output #1: loss = 0.691103 (* 1 = 0.691103 loss)
I0705 15:14:21.500911 44772 sgd_solver.cpp:106] Iteration 1910, lr = 0.025
I0705 15:15:02.944814 44772 solver.cpp:236] Iteration 1920, loss = 0.693415
I0705 15:15:02.944962 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:15:02.945013 44772 solver.cpp:252]     Train net output #1: loss = 0.695123 (* 1 = 0.695123 loss)
I0705 15:15:02.945034 44772 sgd_solver.cpp:106] Iteration 1920, lr = 0.025
I0705 15:15:44.071653 44772 solver.cpp:236] Iteration 1930, loss = 0.693326
I0705 15:15:44.071816 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 15:15:44.071856 44772 solver.cpp:252]     Train net output #1: loss = 0.697189 (* 1 = 0.697189 loss)
I0705 15:15:44.071871 44772 sgd_solver.cpp:106] Iteration 1930, lr = 0.025
I0705 15:16:25.985663 44772 solver.cpp:236] Iteration 1940, loss = 0.693307
I0705 15:16:25.985816 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:16:25.985878 44772 solver.cpp:252]     Train net output #1: loss = 0.694675 (* 1 = 0.694675 loss)
I0705 15:16:25.985903 44772 sgd_solver.cpp:106] Iteration 1940, lr = 0.025
I0705 15:17:03.863826 44772 solver.cpp:236] Iteration 1950, loss = 0.693478
I0705 15:17:03.864035 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 15:17:03.864058 44772 solver.cpp:252]     Train net output #1: loss = 0.693512 (* 1 = 0.693512 loss)
I0705 15:17:03.864070 44772 sgd_solver.cpp:106] Iteration 1950, lr = 0.025
I0705 15:17:40.729822 44772 solver.cpp:236] Iteration 1960, loss = 0.693473
I0705 15:17:40.729969 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 15:17:40.730031 44772 solver.cpp:252]     Train net output #1: loss = 0.692199 (* 1 = 0.692199 loss)
I0705 15:17:40.730051 44772 sgd_solver.cpp:106] Iteration 1960, lr = 0.025
I0705 15:18:18.764116 44772 solver.cpp:236] Iteration 1970, loss = 0.693601
I0705 15:18:18.764346 44772 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0705 15:18:18.764372 44772 solver.cpp:252]     Train net output #1: loss = 0.694185 (* 1 = 0.694185 loss)
I0705 15:18:18.764399 44772 sgd_solver.cpp:106] Iteration 1970, lr = 0.025
I0705 15:18:59.043833 44772 solver.cpp:236] Iteration 1980, loss = 0.693807
I0705 15:18:59.043941 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 15:18:59.043972 44772 solver.cpp:252]     Train net output #1: loss = 0.696065 (* 1 = 0.696065 loss)
I0705 15:18:59.043989 44772 sgd_solver.cpp:106] Iteration 1980, lr = 0.025
I0705 15:19:38.397903 44772 solver.cpp:236] Iteration 1990, loss = 0.693512
I0705 15:19:38.398110 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 15:19:38.398141 44772 solver.cpp:252]     Train net output #1: loss = 0.692248 (* 1 = 0.692248 loss)
I0705 15:19:38.398154 44772 sgd_solver.cpp:106] Iteration 1990, lr = 0.025
I0705 15:20:12.909211 44772 solver.cpp:340] Iteration 2000, Testing net (#0)
I0705 15:21:48.876904 44772 solver.cpp:408]     Test net output #0: accuracy = 0.50375
I0705 15:21:48.877115 44772 solver.cpp:408]     Test net output #1: loss = 0.693937 (* 1 = 0.693937 loss)
I0705 15:21:49.030025 44772 solver.cpp:236] Iteration 2000, loss = 0.693329
I0705 15:21:49.030079 44772 solver.cpp:252]     Train net output #0: accuracy = 0.554688
I0705 15:21:49.030097 44772 solver.cpp:252]     Train net output #1: loss = 0.689052 (* 1 = 0.689052 loss)
I0705 15:21:49.030112 44772 sgd_solver.cpp:106] Iteration 2000, lr = 0.025
I0705 15:22:23.534387 44772 solver.cpp:236] Iteration 2010, loss = 0.693587
I0705 15:22:23.534528 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 15:22:23.534569 44772 solver.cpp:252]     Train net output #1: loss = 0.693315 (* 1 = 0.693315 loss)
I0705 15:22:23.534584 44772 sgd_solver.cpp:106] Iteration 2010, lr = 0.025
I0705 15:23:06.017763 44772 solver.cpp:236] Iteration 2020, loss = 0.693547
I0705 15:23:06.017931 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:23:06.017972 44772 solver.cpp:252]     Train net output #1: loss = 0.693493 (* 1 = 0.693493 loss)
I0705 15:23:06.017989 44772 sgd_solver.cpp:106] Iteration 2020, lr = 0.025
I0705 15:23:47.894757 44772 solver.cpp:236] Iteration 2030, loss = 0.693009
I0705 15:23:47.894953 44772 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 15:23:47.894976 44772 solver.cpp:252]     Train net output #1: loss = 0.688994 (* 1 = 0.688994 loss)
I0705 15:23:47.894994 44772 sgd_solver.cpp:106] Iteration 2030, lr = 0.025
I0705 15:24:31.735857 44772 solver.cpp:236] Iteration 2040, loss = 0.693662
I0705 15:24:31.736055 44772 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 15:24:31.736074 44772 solver.cpp:252]     Train net output #1: loss = 0.703665 (* 1 = 0.703665 loss)
I0705 15:24:31.736093 44772 sgd_solver.cpp:106] Iteration 2040, lr = 0.025
I0705 15:25:04.349628 44772 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 15:25:18.814877 44772 solver.cpp:236] Iteration 2050, loss = 0.693794
I0705 15:25:18.814929 44772 solver.cpp:252]     Train net output #0: accuracy = 0.578125
I0705 15:25:18.814945 44772 solver.cpp:252]     Train net output #1: loss = 0.692413 (* 1 = 0.692413 loss)
I0705 15:25:18.814959 44772 sgd_solver.cpp:106] Iteration 2050, lr = 0.025
I0705 15:26:07.927647 44772 solver.cpp:236] Iteration 2060, loss = 0.693676
I0705 15:26:07.927815 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:26:07.927856 44772 solver.cpp:252]     Train net output #1: loss = 0.693535 (* 1 = 0.693535 loss)
I0705 15:26:07.927870 44772 sgd_solver.cpp:106] Iteration 2060, lr = 0.025
I0705 15:26:56.657523 44772 solver.cpp:236] Iteration 2070, loss = 0.693673
I0705 15:26:56.657783 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 15:26:56.657816 44772 solver.cpp:252]     Train net output #1: loss = 0.696688 (* 1 = 0.696688 loss)
I0705 15:26:56.657845 44772 sgd_solver.cpp:106] Iteration 2070, lr = 0.025
I0705 15:27:44.952894 44772 solver.cpp:236] Iteration 2080, loss = 0.694447
I0705 15:27:44.953115 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 15:27:44.953147 44772 solver.cpp:252]     Train net output #1: loss = 0.693732 (* 1 = 0.693732 loss)
I0705 15:27:44.953160 44772 sgd_solver.cpp:106] Iteration 2080, lr = 0.025
I0705 15:28:34.696579 44772 solver.cpp:236] Iteration 2090, loss = 0.693796
I0705 15:28:34.696741 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 15:28:34.696779 44772 solver.cpp:252]     Train net output #1: loss = 0.697422 (* 1 = 0.697422 loss)
I0705 15:28:34.696799 44772 sgd_solver.cpp:106] Iteration 2090, lr = 0.025
I0705 15:29:24.762528 44772 solver.cpp:236] Iteration 2100, loss = 0.693816
I0705 15:29:24.762668 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 15:29:24.762717 44772 solver.cpp:252]     Train net output #1: loss = 0.697152 (* 1 = 0.697152 loss)
I0705 15:29:24.762730 44772 sgd_solver.cpp:106] Iteration 2100, lr = 0.025
I0705 15:30:06.040884 44772 solver.cpp:236] Iteration 2110, loss = 0.693592
I0705 15:30:06.041018 44772 solver.cpp:252]     Train net output #0: accuracy = 0.601562
I0705 15:30:06.041048 44772 solver.cpp:252]     Train net output #1: loss = 0.689858 (* 1 = 0.689858 loss)
I0705 15:30:06.041062 44772 sgd_solver.cpp:106] Iteration 2110, lr = 0.025
I0705 15:30:45.231534 44772 solver.cpp:236] Iteration 2120, loss = 0.693917
I0705 15:30:45.231693 44772 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 15:30:45.231709 44772 solver.cpp:252]     Train net output #1: loss = 0.693364 (* 1 = 0.693364 loss)
I0705 15:30:45.231735 44772 sgd_solver.cpp:106] Iteration 2120, lr = 0.025
I0705 15:31:23.530210 44772 solver.cpp:236] Iteration 2130, loss = 0.693564
I0705 15:31:23.530345 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 15:31:23.530372 44772 solver.cpp:252]     Train net output #1: loss = 0.691619 (* 1 = 0.691619 loss)
I0705 15:31:23.530387 44772 sgd_solver.cpp:106] Iteration 2130, lr = 0.025
I0705 15:32:03.849989 44772 solver.cpp:236] Iteration 2140, loss = 0.693891
I0705 15:32:03.850169 44772 solver.cpp:252]     Train net output #0: accuracy = 0.414062
I0705 15:32:03.850203 44772 solver.cpp:252]     Train net output #1: loss = 0.696709 (* 1 = 0.696709 loss)
I0705 15:32:03.850220 44772 sgd_solver.cpp:106] Iteration 2140, lr = 0.025
I0705 15:32:42.564955 44772 solver.cpp:236] Iteration 2150, loss = 0.693836
I0705 15:32:42.565199 44772 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 15:32:42.565222 44772 solver.cpp:252]     Train net output #1: loss = 0.692843 (* 1 = 0.692843 loss)
I0705 15:32:42.565245 44772 sgd_solver.cpp:106] Iteration 2150, lr = 0.025
I0705 15:33:20.861515 44772 solver.cpp:236] Iteration 2160, loss = 0.693954
I0705 15:33:20.861675 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 15:33:20.861728 44772 solver.cpp:252]     Train net output #1: loss = 0.693086 (* 1 = 0.693086 loss)
I0705 15:33:20.861742 44772 sgd_solver.cpp:106] Iteration 2160, lr = 0.025
I0705 15:34:01.171290 44772 solver.cpp:236] Iteration 2170, loss = 0.693638
I0705 15:34:01.171447 44772 solver.cpp:252]     Train net output #0: accuracy = 0.421875
I0705 15:34:01.171489 44772 solver.cpp:252]     Train net output #1: loss = 0.6951 (* 1 = 0.6951 loss)
I0705 15:34:01.171501 44772 sgd_solver.cpp:106] Iteration 2170, lr = 0.025
I0705 15:34:49.340872 44772 solver.cpp:236] Iteration 2180, loss = 0.693665
I0705 15:34:49.341058 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:34:49.341078 44772 solver.cpp:252]     Train net output #1: loss = 0.693824 (* 1 = 0.693824 loss)
I0705 15:34:49.341091 44772 sgd_solver.cpp:106] Iteration 2180, lr = 0.025
I0705 15:35:32.251915 44772 solver.cpp:236] Iteration 2190, loss = 0.693492
I0705 15:35:32.252142 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 15:35:32.252177 44772 solver.cpp:252]     Train net output #1: loss = 0.695443 (* 1 = 0.695443 loss)
I0705 15:35:32.252193 44772 sgd_solver.cpp:106] Iteration 2190, lr = 0.025
I0705 15:36:15.587491 44772 solver.cpp:236] Iteration 2200, loss = 0.693274
I0705 15:36:15.587611 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:36:15.587657 44772 solver.cpp:252]     Train net output #1: loss = 0.695562 (* 1 = 0.695562 loss)
I0705 15:36:15.587671 44772 sgd_solver.cpp:106] Iteration 2200, lr = 0.025
I0705 15:36:59.298079 44772 solver.cpp:236] Iteration 2210, loss = 0.693333
I0705 15:36:59.298241 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 15:36:59.298276 44772 solver.cpp:252]     Train net output #1: loss = 0.693068 (* 1 = 0.693068 loss)
I0705 15:36:59.298290 44772 sgd_solver.cpp:106] Iteration 2210, lr = 0.025
I0705 15:37:43.979256 44772 solver.cpp:236] Iteration 2220, loss = 0.693273
I0705 15:37:43.979396 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 15:37:43.979415 44772 solver.cpp:252]     Train net output #1: loss = 0.693862 (* 1 = 0.693862 loss)
I0705 15:37:43.979432 44772 sgd_solver.cpp:106] Iteration 2220, lr = 0.025
I0705 15:38:27.291935 44772 solver.cpp:236] Iteration 2230, loss = 0.693247
I0705 15:38:27.292093 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 15:38:27.292137 44772 solver.cpp:252]     Train net output #1: loss = 0.69271 (* 1 = 0.69271 loss)
I0705 15:38:27.292150 44772 sgd_solver.cpp:106] Iteration 2230, lr = 0.025
I0705 15:39:10.253741 44772 solver.cpp:236] Iteration 2240, loss = 0.693125
I0705 15:39:10.253921 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:39:10.253942 44772 solver.cpp:252]     Train net output #1: loss = 0.694363 (* 1 = 0.694363 loss)
I0705 15:39:10.253953 44772 sgd_solver.cpp:106] Iteration 2240, lr = 0.025
I0705 15:39:49.447134 44772 solver.cpp:340] Iteration 2250, Testing net (#0)
I0705 15:41:36.630329 44772 solver.cpp:408]     Test net output #0: accuracy = 0.5025
I0705 15:41:36.630496 44772 solver.cpp:408]     Test net output #1: loss = 0.693135 (* 1 = 0.693135 loss)
I0705 15:41:36.776599 44772 solver.cpp:236] Iteration 2250, loss = 0.693384
I0705 15:41:36.776636 44772 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 15:41:36.776654 44772 solver.cpp:252]     Train net output #1: loss = 0.693074 (* 1 = 0.693074 loss)
I0705 15:41:36.776669 44772 sgd_solver.cpp:106] Iteration 2250, lr = 0.025
I0705 15:42:11.489310 44772 solver.cpp:236] Iteration 2260, loss = 0.693325
I0705 15:42:11.489460 44772 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 15:42:11.489495 44772 solver.cpp:252]     Train net output #1: loss = 0.692436 (* 1 = 0.692436 loss)
I0705 15:42:11.489506 44772 sgd_solver.cpp:106] Iteration 2260, lr = 0.025
I0705 15:42:45.894752 44772 solver.cpp:236] Iteration 2270, loss = 0.693422
I0705 15:42:45.894881 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 15:42:45.894899 44772 solver.cpp:252]     Train net output #1: loss = 0.692514 (* 1 = 0.692514 loss)
I0705 15:42:45.894915 44772 sgd_solver.cpp:106] Iteration 2270, lr = 0.025
I0705 15:43:11.888351 44772 solver.cpp:236] Iteration 2280, loss = 0.693409
I0705 15:43:11.888407 44772 solver.cpp:252]     Train net output #0: accuracy = 0.585938
I0705 15:43:11.888428 44772 solver.cpp:252]     Train net output #1: loss = 0.689952 (* 1 = 0.689952 loss)
I0705 15:43:11.888453 44772 sgd_solver.cpp:106] Iteration 2280, lr = 0.025
I0705 15:43:39.230054 44772 solver.cpp:236] Iteration 2290, loss = 0.693366
I0705 15:43:39.230238 44772 solver.cpp:252]     Train net output #0: accuracy = 0.585938
I0705 15:43:39.230258 44772 solver.cpp:252]     Train net output #1: loss = 0.690196 (* 1 = 0.690196 loss)
I0705 15:43:39.230273 44772 sgd_solver.cpp:106] Iteration 2290, lr = 0.025
I0705 15:44:05.355916 44772 solver.cpp:236] Iteration 2300, loss = 0.693014
I0705 15:44:05.355976 44772 solver.cpp:252]     Train net output #0: accuracy = 0.585938
I0705 15:44:05.355993 44772 solver.cpp:252]     Train net output #1: loss = 0.685857 (* 1 = 0.685857 loss)
I0705 15:44:05.356005 44772 sgd_solver.cpp:106] Iteration 2300, lr = 0.025
I0705 15:44:31.269733 44772 solver.cpp:236] Iteration 2310, loss = 0.692865
I0705 15:44:31.269948 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 15:44:31.269973 44772 solver.cpp:252]     Train net output #1: loss = 0.69018 (* 1 = 0.69018 loss)
I0705 15:44:31.269989 44772 sgd_solver.cpp:106] Iteration 2310, lr = 0.025
I0705 15:44:57.958925 44772 solver.cpp:236] Iteration 2320, loss = 0.692948
I0705 15:44:57.958971 44772 solver.cpp:252]     Train net output #0: accuracy = 0.429688
I0705 15:44:57.958987 44772 solver.cpp:252]     Train net output #1: loss = 0.694241 (* 1 = 0.694241 loss)
I0705 15:44:57.959003 44772 sgd_solver.cpp:106] Iteration 2320, lr = 0.025
I0705 15:45:24.513867 44772 solver.cpp:236] Iteration 2330, loss = 0.693012
I0705 15:45:24.514025 44772 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 15:45:24.514056 44772 solver.cpp:252]     Train net output #1: loss = 0.69546 (* 1 = 0.69546 loss)
I0705 15:45:24.514081 44772 sgd_solver.cpp:106] Iteration 2330, lr = 0.025
I0705 15:45:51.519234 44772 solver.cpp:236] Iteration 2340, loss = 0.693543
I0705 15:45:51.519289 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 15:45:51.519315 44772 solver.cpp:252]     Train net output #1: loss = 0.696271 (* 1 = 0.696271 loss)
I0705 15:45:51.519326 44772 sgd_solver.cpp:106] Iteration 2340, lr = 0.025
I0705 15:46:18.633668 44772 solver.cpp:236] Iteration 2350, loss = 0.693902
I0705 15:46:18.633931 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 15:46:18.633955 44772 solver.cpp:252]     Train net output #1: loss = 0.692256 (* 1 = 0.692256 loss)
I0705 15:46:18.633976 44772 sgd_solver.cpp:106] Iteration 2350, lr = 0.025
I0705 15:46:48.924630 44772 solver.cpp:236] Iteration 2360, loss = 0.694021
I0705 15:46:48.924762 44772 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0705 15:46:48.924794 44772 solver.cpp:252]     Train net output #1: loss = 0.68938 (* 1 = 0.68938 loss)
I0705 15:46:48.924818 44772 sgd_solver.cpp:106] Iteration 2360, lr = 0.025
I0705 15:47:18.237126 44772 solver.cpp:236] Iteration 2370, loss = 0.694161
I0705 15:47:18.237186 44772 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 15:47:18.237203 44772 solver.cpp:252]     Train net output #1: loss = 0.694554 (* 1 = 0.694554 loss)
I0705 15:47:18.237215 44772 sgd_solver.cpp:106] Iteration 2370, lr = 0.025
I0705 15:47:47.745600 44772 solver.cpp:236] Iteration 2380, loss = 0.694294
I0705 15:47:47.752466 44772 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 15:47:47.752488 44772 solver.cpp:252]     Train net output #1: loss = 0.69479 (* 1 = 0.69479 loss)
I0705 15:47:47.752499 44772 sgd_solver.cpp:106] Iteration 2380, lr = 0.025
I0705 15:48:16.999037 44772 solver.cpp:236] Iteration 2390, loss = 0.69407
I0705 15:48:16.999100 44772 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 15:48:16.999117 44772 solver.cpp:252]     Train net output #1: loss = 0.694966 (* 1 = 0.694966 loss)
I0705 15:48:16.999130 44772 sgd_solver.cpp:106] Iteration 2390, lr = 0.025
I0705 15:48:48.524454 44772 solver.cpp:236] Iteration 2400, loss = 0.694314
I0705 15:48:48.524601 44772 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 15:48:48.524655 44772 solver.cpp:252]     Train net output #1: loss = 0.692776 (* 1 = 0.692776 loss)
I0705 15:48:48.524669 44772 sgd_solver.cpp:106] Iteration 2400, lr = 0.025
I0705 15:49:18.615576 44772 solver.cpp:236] Iteration 2410, loss = 0.694303
I0705 15:49:18.615784 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 15:49:18.615803 44772 solver.cpp:252]     Train net output #1: loss = 0.697748 (* 1 = 0.697748 loss)
I0705 15:49:18.615815 44772 sgd_solver.cpp:106] Iteration 2410, lr = 0.025
I0705 15:49:48.564652 44772 solver.cpp:236] Iteration 2420, loss = 0.694349
I0705 15:49:48.564713 44772 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 15:49:48.564729 44772 solver.cpp:252]     Train net output #1: loss = 0.69182 (* 1 = 0.69182 loss)
I0705 15:49:48.564743 44772 sgd_solver.cpp:106] Iteration 2420, lr = 0.025
I0705 15:50:18.209278 44772 solver.cpp:236] Iteration 2430, loss = 0.694224
I0705 15:50:18.209436 44772 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 15:50:18.209483 44772 solver.cpp:252]     Train net output #1: loss = 0.696852 (* 1 = 0.696852 loss)
I0705 15:50:18.209496 44772 sgd_solver.cpp:106] Iteration 2430, lr = 0.025
I0705 15:50:47.712069 44772 solver.cpp:236] Iteration 2440, loss = 0.694298
I0705 15:50:47.712153 44772 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 15:50:47.712170 44772 solver.cpp:252]     Train net output #1: loss = 0.696558 (* 1 = 0.696558 loss)
I0705 15:50:47.712183 44772 sgd_solver.cpp:106] Iteration 2440, lr = 0.025
I0705 15:51:15.959543 44772 solver.cpp:236] Iteration 2450, loss = 0.694333
I0705 15:51:15.959830 44772 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0705 15:51:15.959854 44772 solver.cpp:252]     Train net output #1: loss = 0.701821 (* 1 = 0.701821 loss)
I0705 15:51:15.959877 44772 sgd_solver.cpp:106] Iteration 2450, lr = 0.025
I0705 15:51:31.187927 44772 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_2456.caffemodel
I0705 15:51:32.033957 44772 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_2456.solverstate
I0705 15:51:32.066017 44772 solver.cpp:308] Optimization stopped early.
I0705 15:51:32.066068 44772 caffe.cpp:215] Optimization Done.
