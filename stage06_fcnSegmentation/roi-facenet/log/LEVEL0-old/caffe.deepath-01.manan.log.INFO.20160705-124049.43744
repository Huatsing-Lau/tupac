Log file created at: 2016/07/05 12:40:49
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0705 12:40:49.747859 43744 caffe.cpp:184] Using GPUs 2
I0705 12:40:50.011378 43744 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 250
base_lr: 0.015
display: 10
max_iter: 180000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/cnn10"
solver_mode: GPU
device_id: 2
net: "train_val.prototxt.full"
test_initialization: false
average_loss: 50
I0705 12:40:50.011613 43744 solver.cpp:90] Creating training net from net file: train_val.prototxt.full
I0705 12:40:50.012298 43744 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0705 12:40:50.012502 43744 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0705 12:40:50.012666 43744 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0705 12:40:50.012954 43744 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-train-L0.lst"
    batch_size: 128
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0705 12:40:50.014600 43744 layer_factory.hpp:76] Creating layer data
I0705 12:40:50.014678 43744 net.cpp:106] Creating Layer data
I0705 12:40:50.014696 43744 net.cpp:411] data -> data
I0705 12:40:50.014724 43744 net.cpp:411] data -> label
I0705 12:40:50.015269 43744 image_data_layer.cpp:36] Opening file ../lists/roi-train-L0.lst
I0705 12:40:50.125222 43744 image_data_layer.cpp:46] Shuffling data
I0705 12:40:50.158087 43744 image_data_layer.cpp:51] A total of 211680 images.
I0705 12:40:50.287070 43744 image_data_layer.cpp:78] output data size: 128,3,100,100
I0705 12:40:50.324177 43744 net.cpp:150] Setting up data
I0705 12:40:50.324247 43744 net.cpp:157] Top shape: 128 3 100 100 (3840000)
I0705 12:40:50.324265 43744 net.cpp:157] Top shape: 128 (128)
I0705 12:40:50.324276 43744 net.cpp:165] Memory required for data: 15360512
I0705 12:40:50.324295 43744 layer_factory.hpp:76] Creating layer label_data_1_split
I0705 12:40:50.324326 43744 net.cpp:106] Creating Layer label_data_1_split
I0705 12:40:50.324344 43744 net.cpp:454] label_data_1_split <- label
I0705 12:40:50.324369 43744 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0705 12:40:50.324393 43744 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0705 12:40:50.324475 43744 net.cpp:150] Setting up label_data_1_split
I0705 12:40:50.324501 43744 net.cpp:157] Top shape: 128 (128)
I0705 12:40:50.324517 43744 net.cpp:157] Top shape: 128 (128)
I0705 12:40:50.324529 43744 net.cpp:165] Memory required for data: 15361536
I0705 12:40:50.324543 43744 layer_factory.hpp:76] Creating layer conv11
I0705 12:40:50.324584 43744 net.cpp:106] Creating Layer conv11
I0705 12:40:50.324611 43744 net.cpp:454] conv11 <- data
I0705 12:40:50.324630 43744 net.cpp:411] conv11 -> conv11
I0705 12:40:50.454977 43744 net.cpp:150] Setting up conv11
I0705 12:40:50.455026 43744 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 12:40:50.455040 43744 net.cpp:165] Memory required for data: 179201536
I0705 12:40:50.455076 43744 layer_factory.hpp:76] Creating layer relu11
I0705 12:40:50.455102 43744 net.cpp:106] Creating Layer relu11
I0705 12:40:50.455118 43744 net.cpp:454] relu11 <- conv11
I0705 12:40:50.455134 43744 net.cpp:397] relu11 -> conv11 (in-place)
I0705 12:40:50.455371 43744 net.cpp:150] Setting up relu11
I0705 12:40:50.455405 43744 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 12:40:50.455418 43744 net.cpp:165] Memory required for data: 343041536
I0705 12:40:50.455431 43744 layer_factory.hpp:76] Creating layer conv12
I0705 12:40:50.455461 43744 net.cpp:106] Creating Layer conv12
I0705 12:40:50.455476 43744 net.cpp:454] conv12 <- conv11
I0705 12:40:50.455497 43744 net.cpp:411] conv12 -> conv12
I0705 12:40:50.456631 43744 net.cpp:150] Setting up conv12
I0705 12:40:50.456657 43744 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 12:40:50.456670 43744 net.cpp:165] Memory required for data: 506881536
I0705 12:40:50.456696 43744 layer_factory.hpp:76] Creating layer relu12
I0705 12:40:50.456714 43744 net.cpp:106] Creating Layer relu12
I0705 12:40:50.456728 43744 net.cpp:454] relu12 <- conv12
I0705 12:40:50.456744 43744 net.cpp:397] relu12 -> conv12 (in-place)
I0705 12:40:50.457118 43744 net.cpp:150] Setting up relu12
I0705 12:40:50.457142 43744 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0705 12:40:50.457155 43744 net.cpp:165] Memory required for data: 670721536
I0705 12:40:50.457170 43744 layer_factory.hpp:76] Creating layer pool1
I0705 12:40:50.457186 43744 net.cpp:106] Creating Layer pool1
I0705 12:40:50.457200 43744 net.cpp:454] pool1 <- conv12
I0705 12:40:50.457218 43744 net.cpp:411] pool1 -> pool1
I0705 12:40:50.457501 43744 net.cpp:150] Setting up pool1
I0705 12:40:50.457523 43744 net.cpp:157] Top shape: 128 32 50 50 (10240000)
I0705 12:40:50.457536 43744 net.cpp:165] Memory required for data: 711681536
I0705 12:40:50.457550 43744 layer_factory.hpp:76] Creating layer conv21
I0705 12:40:50.457574 43744 net.cpp:106] Creating Layer conv21
I0705 12:40:50.457589 43744 net.cpp:454] conv21 <- pool1
I0705 12:40:50.457610 43744 net.cpp:411] conv21 -> conv21
I0705 12:40:50.460121 43744 net.cpp:150] Setting up conv21
I0705 12:40:50.460147 43744 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 12:40:50.460160 43744 net.cpp:165] Memory required for data: 793601536
I0705 12:40:50.460182 43744 layer_factory.hpp:76] Creating layer relu21
I0705 12:40:50.460206 43744 net.cpp:106] Creating Layer relu21
I0705 12:40:50.460221 43744 net.cpp:454] relu21 <- conv21
I0705 12:40:50.460235 43744 net.cpp:397] relu21 -> conv21 (in-place)
I0705 12:40:50.460625 43744 net.cpp:150] Setting up relu21
I0705 12:40:50.460649 43744 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 12:40:50.460706 43744 net.cpp:165] Memory required for data: 875521536
I0705 12:40:50.460721 43744 layer_factory.hpp:76] Creating layer conv22
I0705 12:40:50.460746 43744 net.cpp:106] Creating Layer conv22
I0705 12:40:50.460760 43744 net.cpp:454] conv22 <- conv21
I0705 12:40:50.460788 43744 net.cpp:411] conv22 -> conv22
I0705 12:40:50.461956 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0705 12:40:50.462220 43744 net.cpp:150] Setting up conv22
I0705 12:40:50.462247 43744 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 12:40:50.462261 43744 net.cpp:165] Memory required for data: 957441536
I0705 12:40:50.462280 43744 layer_factory.hpp:76] Creating layer relu22
I0705 12:40:50.462296 43744 net.cpp:106] Creating Layer relu22
I0705 12:40:50.462309 43744 net.cpp:454] relu22 <- conv22
I0705 12:40:50.462326 43744 net.cpp:397] relu22 -> conv22 (in-place)
I0705 12:40:50.462761 43744 net.cpp:150] Setting up relu22
I0705 12:40:50.462785 43744 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0705 12:40:50.462798 43744 net.cpp:165] Memory required for data: 1039361536
I0705 12:40:50.462812 43744 layer_factory.hpp:76] Creating layer pool2
I0705 12:40:50.462829 43744 net.cpp:106] Creating Layer pool2
I0705 12:40:50.462842 43744 net.cpp:454] pool2 <- conv22
I0705 12:40:50.462862 43744 net.cpp:411] pool2 -> pool2
I0705 12:40:50.463147 43744 net.cpp:150] Setting up pool2
I0705 12:40:50.463170 43744 net.cpp:157] Top shape: 128 64 25 25 (5120000)
I0705 12:40:50.463182 43744 net.cpp:165] Memory required for data: 1059841536
I0705 12:40:50.463196 43744 layer_factory.hpp:76] Creating layer conv31
I0705 12:40:50.463218 43744 net.cpp:106] Creating Layer conv31
I0705 12:40:50.463232 43744 net.cpp:454] conv31 <- pool2
I0705 12:40:50.463253 43744 net.cpp:411] conv31 -> conv31
I0705 12:40:50.464725 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0705 12:40:50.464766 43744 net.cpp:150] Setting up conv31
I0705 12:40:50.464784 43744 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 12:40:50.464798 43744 net.cpp:165] Memory required for data: 1090561536
I0705 12:40:50.464823 43744 layer_factory.hpp:76] Creating layer relu31
I0705 12:40:50.464840 43744 net.cpp:106] Creating Layer relu31
I0705 12:40:50.464854 43744 net.cpp:454] relu31 <- conv31
I0705 12:40:50.464869 43744 net.cpp:397] relu31 -> conv31 (in-place)
I0705 12:40:50.465243 43744 net.cpp:150] Setting up relu31
I0705 12:40:50.465270 43744 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 12:40:50.465283 43744 net.cpp:165] Memory required for data: 1121281536
I0705 12:40:50.465296 43744 layer_factory.hpp:76] Creating layer conv32
I0705 12:40:50.465319 43744 net.cpp:106] Creating Layer conv32
I0705 12:40:50.465333 43744 net.cpp:454] conv32 <- conv31
I0705 12:40:50.465350 43744 net.cpp:411] conv32 -> conv32
I0705 12:40:50.467661 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0705 12:40:50.467702 43744 net.cpp:150] Setting up conv32
I0705 12:40:50.467721 43744 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 12:40:50.467735 43744 net.cpp:165] Memory required for data: 1152001536
I0705 12:40:50.467752 43744 layer_factory.hpp:76] Creating layer relu32
I0705 12:40:50.467773 43744 net.cpp:106] Creating Layer relu32
I0705 12:40:50.467787 43744 net.cpp:454] relu32 <- conv32
I0705 12:40:50.467803 43744 net.cpp:397] relu32 -> conv32 (in-place)
I0705 12:40:50.468044 43744 net.cpp:150] Setting up relu32
I0705 12:40:50.468066 43744 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0705 12:40:50.468078 43744 net.cpp:165] Memory required for data: 1182721536
I0705 12:40:50.468091 43744 layer_factory.hpp:76] Creating layer pool3
I0705 12:40:50.468111 43744 net.cpp:106] Creating Layer pool3
I0705 12:40:50.468123 43744 net.cpp:454] pool3 <- conv32
I0705 12:40:50.468143 43744 net.cpp:411] pool3 -> pool3
I0705 12:40:50.468611 43744 net.cpp:150] Setting up pool3
I0705 12:40:50.468634 43744 net.cpp:157] Top shape: 128 96 13 13 (2076672)
I0705 12:40:50.468647 43744 net.cpp:165] Memory required for data: 1191028224
I0705 12:40:50.468660 43744 layer_factory.hpp:76] Creating layer conv41
I0705 12:40:50.468708 43744 net.cpp:106] Creating Layer conv41
I0705 12:40:50.468739 43744 net.cpp:454] conv41 <- pool3
I0705 12:40:50.468767 43744 net.cpp:411] conv41 -> conv41
I0705 12:40:50.470412 43744 net.cpp:150] Setting up conv41
I0705 12:40:50.470448 43744 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 12:40:50.470458 43744 net.cpp:165] Memory required for data: 1202103808
I0705 12:40:50.470468 43744 layer_factory.hpp:76] Creating layer relu41
I0705 12:40:50.470479 43744 net.cpp:106] Creating Layer relu41
I0705 12:40:50.470487 43744 net.cpp:454] relu41 <- conv41
I0705 12:40:50.470496 43744 net.cpp:397] relu41 -> conv41 (in-place)
I0705 12:40:50.471027 43744 net.cpp:150] Setting up relu41
I0705 12:40:50.471057 43744 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 12:40:50.471066 43744 net.cpp:165] Memory required for data: 1213179392
I0705 12:40:50.471074 43744 layer_factory.hpp:76] Creating layer conv42
I0705 12:40:50.471091 43744 net.cpp:106] Creating Layer conv42
I0705 12:40:50.471099 43744 net.cpp:454] conv42 <- conv41
I0705 12:40:50.471109 43744 net.cpp:411] conv42 -> conv42
I0705 12:40:50.473901 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0705 12:40:50.473950 43744 net.cpp:150] Setting up conv42
I0705 12:40:50.473963 43744 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 12:40:50.473973 43744 net.cpp:165] Memory required for data: 1224254976
I0705 12:40:50.473984 43744 layer_factory.hpp:76] Creating layer relu42
I0705 12:40:50.473999 43744 net.cpp:106] Creating Layer relu42
I0705 12:40:50.474007 43744 net.cpp:454] relu42 <- conv42
I0705 12:40:50.474017 43744 net.cpp:397] relu42 -> conv42 (in-place)
I0705 12:40:50.474239 43744 net.cpp:150] Setting up relu42
I0705 12:40:50.474256 43744 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0705 12:40:50.474277 43744 net.cpp:165] Memory required for data: 1235330560
I0705 12:40:50.474284 43744 layer_factory.hpp:76] Creating layer pool4
I0705 12:40:50.474297 43744 net.cpp:106] Creating Layer pool4
I0705 12:40:50.474304 43744 net.cpp:454] pool4 <- conv42
I0705 12:40:50.474316 43744 net.cpp:411] pool4 -> pool4
I0705 12:40:50.474730 43744 net.cpp:150] Setting up pool4
I0705 12:40:50.474763 43744 net.cpp:157] Top shape: 128 128 7 7 (802816)
I0705 12:40:50.474772 43744 net.cpp:165] Memory required for data: 1238541824
I0705 12:40:50.474781 43744 layer_factory.hpp:76] Creating layer conv51
I0705 12:40:50.474797 43744 net.cpp:106] Creating Layer conv51
I0705 12:40:50.474805 43744 net.cpp:454] conv51 <- pool4
I0705 12:40:50.474822 43744 net.cpp:411] conv51 -> conv51
I0705 12:40:50.478839 43744 net.cpp:150] Setting up conv51
I0705 12:40:50.478880 43744 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 12:40:50.478900 43744 net.cpp:165] Memory required for data: 1244964352
I0705 12:40:50.478919 43744 layer_factory.hpp:76] Creating layer relu51
I0705 12:40:50.478932 43744 net.cpp:106] Creating Layer relu51
I0705 12:40:50.478941 43744 net.cpp:454] relu51 <- conv51
I0705 12:40:50.478951 43744 net.cpp:397] relu51 -> conv51 (in-place)
I0705 12:40:50.479187 43744 net.cpp:150] Setting up relu51
I0705 12:40:50.479202 43744 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 12:40:50.479221 43744 net.cpp:165] Memory required for data: 1251386880
I0705 12:40:50.479230 43744 layer_factory.hpp:76] Creating layer conv52
I0705 12:40:50.479244 43744 net.cpp:106] Creating Layer conv52
I0705 12:40:50.479254 43744 net.cpp:454] conv52 <- conv51
I0705 12:40:50.479264 43744 net.cpp:411] conv52 -> conv52
I0705 12:40:50.485723 43744 net.cpp:150] Setting up conv52
I0705 12:40:50.485769 43744 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 12:40:50.485777 43744 net.cpp:165] Memory required for data: 1257809408
I0705 12:40:50.485790 43744 layer_factory.hpp:76] Creating layer relu52
I0705 12:40:50.485801 43744 net.cpp:106] Creating Layer relu52
I0705 12:40:50.485811 43744 net.cpp:454] relu52 <- conv52
I0705 12:40:50.485821 43744 net.cpp:397] relu52 -> conv52 (in-place)
I0705 12:40:50.486196 43744 net.cpp:150] Setting up relu52
I0705 12:40:50.486248 43744 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0705 12:40:50.486258 43744 net.cpp:165] Memory required for data: 1264231936
I0705 12:40:50.486265 43744 layer_factory.hpp:76] Creating layer conv53
I0705 12:40:50.486281 43744 net.cpp:106] Creating Layer conv53
I0705 12:40:50.486290 43744 net.cpp:454] conv53 <- conv52
I0705 12:40:50.486300 43744 net.cpp:411] conv53 -> conv53
I0705 12:40:50.519122 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0705 12:40:50.519426 43744 net.cpp:150] Setting up conv53
I0705 12:40:50.519448 43744 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0705 12:40:50.519457 43744 net.cpp:165] Memory required for data: 1264363008
I0705 12:40:50.519475 43744 layer_factory.hpp:76] Creating layer relu53
I0705 12:40:50.519490 43744 net.cpp:106] Creating Layer relu53
I0705 12:40:50.519502 43744 net.cpp:454] relu53 <- conv53
I0705 12:40:50.519526 43744 net.cpp:397] relu53 -> conv53 (in-place)
I0705 12:40:50.519892 43744 net.cpp:150] Setting up relu53
I0705 12:40:50.519923 43744 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0705 12:40:50.519932 43744 net.cpp:165] Memory required for data: 1264494080
I0705 12:40:50.519940 43744 layer_factory.hpp:76] Creating layer drop6
I0705 12:40:50.519959 43744 net.cpp:106] Creating Layer drop6
I0705 12:40:50.519968 43744 net.cpp:454] drop6 <- conv53
I0705 12:40:50.519978 43744 net.cpp:411] drop6 -> drop6
I0705 12:40:50.520045 43744 net.cpp:150] Setting up drop6
I0705 12:40:50.520061 43744 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0705 12:40:50.520068 43744 net.cpp:165] Memory required for data: 1264625152
I0705 12:40:50.520076 43744 layer_factory.hpp:76] Creating layer conv54
I0705 12:40:50.520094 43744 net.cpp:106] Creating Layer conv54
I0705 12:40:50.520103 43744 net.cpp:454] conv54 <- drop6
I0705 12:40:50.520128 43744 net.cpp:411] conv54 -> conv54
I0705 12:40:50.521212 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0705 12:40:50.521486 43744 net.cpp:150] Setting up conv54
I0705 12:40:50.521518 43744 net.cpp:157] Top shape: 128 2 1 1 (256)
I0705 12:40:50.521528 43744 net.cpp:165] Memory required for data: 1264626176
I0705 12:40:50.521538 43744 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0705 12:40:50.521550 43744 net.cpp:106] Creating Layer conv54_conv54_0_split
I0705 12:40:50.521559 43744 net.cpp:454] conv54_conv54_0_split <- conv54
I0705 12:40:50.521569 43744 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0705 12:40:50.521579 43744 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0705 12:40:50.521641 43744 net.cpp:150] Setting up conv54_conv54_0_split
I0705 12:40:50.521656 43744 net.cpp:157] Top shape: 128 2 1 1 (256)
I0705 12:40:50.521666 43744 net.cpp:157] Top shape: 128 2 1 1 (256)
I0705 12:40:50.521672 43744 net.cpp:165] Memory required for data: 1264628224
I0705 12:40:50.521682 43744 layer_factory.hpp:76] Creating layer accuracy
I0705 12:40:50.521695 43744 net.cpp:106] Creating Layer accuracy
I0705 12:40:50.521704 43744 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0705 12:40:50.521724 43744 net.cpp:454] accuracy <- label_data_1_split_0
I0705 12:40:50.521736 43744 net.cpp:411] accuracy -> accuracy
I0705 12:40:50.521764 43744 net.cpp:150] Setting up accuracy
I0705 12:40:50.521777 43744 net.cpp:157] Top shape: (1)
I0705 12:40:50.521786 43744 net.cpp:165] Memory required for data: 1264628228
I0705 12:40:50.521795 43744 layer_factory.hpp:76] Creating layer loss
I0705 12:40:50.521813 43744 net.cpp:106] Creating Layer loss
I0705 12:40:50.521822 43744 net.cpp:454] loss <- conv54_conv54_0_split_1
I0705 12:40:50.521831 43744 net.cpp:454] loss <- label_data_1_split_1
I0705 12:40:50.521842 43744 net.cpp:411] loss -> loss
I0705 12:40:50.521870 43744 layer_factory.hpp:76] Creating layer loss
I0705 12:40:50.522214 43744 net.cpp:150] Setting up loss
I0705 12:40:50.522243 43744 net.cpp:157] Top shape: (1)
I0705 12:40:50.522251 43744 net.cpp:160]     with loss weight 1
I0705 12:40:50.522277 43744 net.cpp:165] Memory required for data: 1264628232
I0705 12:40:50.522325 43744 net.cpp:226] loss needs backward computation.
I0705 12:40:50.522336 43744 net.cpp:228] accuracy does not need backward computation.
I0705 12:40:50.522344 43744 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0705 12:40:50.522352 43744 net.cpp:226] conv54 needs backward computation.
I0705 12:40:50.522361 43744 net.cpp:226] drop6 needs backward computation.
I0705 12:40:50.522369 43744 net.cpp:226] relu53 needs backward computation.
I0705 12:40:50.522388 43744 net.cpp:226] conv53 needs backward computation.
I0705 12:40:50.522397 43744 net.cpp:226] relu52 needs backward computation.
I0705 12:40:50.522403 43744 net.cpp:226] conv52 needs backward computation.
I0705 12:40:50.522411 43744 net.cpp:226] relu51 needs backward computation.
I0705 12:40:50.522431 43744 net.cpp:226] conv51 needs backward computation.
I0705 12:40:50.522441 43744 net.cpp:226] pool4 needs backward computation.
I0705 12:40:50.522450 43744 net.cpp:226] relu42 needs backward computation.
I0705 12:40:50.522457 43744 net.cpp:226] conv42 needs backward computation.
I0705 12:40:50.522466 43744 net.cpp:226] relu41 needs backward computation.
I0705 12:40:50.522474 43744 net.cpp:226] conv41 needs backward computation.
I0705 12:40:50.522492 43744 net.cpp:226] pool3 needs backward computation.
I0705 12:40:50.522500 43744 net.cpp:226] relu32 needs backward computation.
I0705 12:40:50.522508 43744 net.cpp:226] conv32 needs backward computation.
I0705 12:40:50.522516 43744 net.cpp:226] relu31 needs backward computation.
I0705 12:40:50.522524 43744 net.cpp:226] conv31 needs backward computation.
I0705 12:40:50.522531 43744 net.cpp:226] pool2 needs backward computation.
I0705 12:40:50.522539 43744 net.cpp:226] relu22 needs backward computation.
I0705 12:40:50.522547 43744 net.cpp:226] conv22 needs backward computation.
I0705 12:40:50.522554 43744 net.cpp:226] relu21 needs backward computation.
I0705 12:40:50.522562 43744 net.cpp:226] conv21 needs backward computation.
I0705 12:40:50.522570 43744 net.cpp:226] pool1 needs backward computation.
I0705 12:40:50.522578 43744 net.cpp:226] relu12 needs backward computation.
I0705 12:40:50.522585 43744 net.cpp:226] conv12 needs backward computation.
I0705 12:40:50.522593 43744 net.cpp:226] relu11 needs backward computation.
I0705 12:40:50.522599 43744 net.cpp:226] conv11 needs backward computation.
I0705 12:40:50.522608 43744 net.cpp:228] label_data_1_split does not need backward computation.
I0705 12:40:50.522616 43744 net.cpp:228] data does not need backward computation.
I0705 12:40:50.522624 43744 net.cpp:270] This network produces output accuracy
I0705 12:40:50.522631 43744 net.cpp:270] This network produces output loss
I0705 12:40:50.522658 43744 net.cpp:283] Network initialization done.
I0705 12:40:50.523416 43744 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0705 12:40:50.523556 43744 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0705 12:40:50.523589 43744 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt.full
I0705 12:40:50.523638 43744 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0705 12:40:50.523893 43744 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-val-L0.lst"
    batch_size: 32
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0705 12:40:50.525588 43744 layer_factory.hpp:76] Creating layer data
I0705 12:40:50.525624 43744 net.cpp:106] Creating Layer data
I0705 12:40:50.525646 43744 net.cpp:411] data -> data
I0705 12:40:50.525660 43744 net.cpp:411] data -> label
I0705 12:40:50.525672 43744 image_data_layer.cpp:36] Opening file ../lists/roi-val-L0.lst
I0705 12:40:50.537909 43744 image_data_layer.cpp:46] Shuffling data
I0705 12:40:50.539985 43744 image_data_layer.cpp:51] A total of 23520 images.
I0705 12:40:50.616536 43744 image_data_layer.cpp:78] output data size: 32,3,100,100
I0705 12:40:50.624449 43744 net.cpp:150] Setting up data
I0705 12:40:50.624500 43744 net.cpp:157] Top shape: 32 3 100 100 (960000)
I0705 12:40:50.624511 43744 net.cpp:157] Top shape: 32 (32)
I0705 12:40:50.624519 43744 net.cpp:165] Memory required for data: 3840128
I0705 12:40:50.624541 43744 layer_factory.hpp:76] Creating layer label_data_1_split
I0705 12:40:50.624560 43744 net.cpp:106] Creating Layer label_data_1_split
I0705 12:40:50.624569 43744 net.cpp:454] label_data_1_split <- label
I0705 12:40:50.624582 43744 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0705 12:40:50.624595 43744 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0705 12:40:50.624650 43744 net.cpp:150] Setting up label_data_1_split
I0705 12:40:50.624665 43744 net.cpp:157] Top shape: 32 (32)
I0705 12:40:50.624673 43744 net.cpp:157] Top shape: 32 (32)
I0705 12:40:50.624680 43744 net.cpp:165] Memory required for data: 3840384
I0705 12:40:50.624688 43744 layer_factory.hpp:76] Creating layer conv11
I0705 12:40:50.624706 43744 net.cpp:106] Creating Layer conv11
I0705 12:40:50.624713 43744 net.cpp:454] conv11 <- data
I0705 12:40:50.624723 43744 net.cpp:411] conv11 -> conv11
I0705 12:40:50.626040 43744 net.cpp:150] Setting up conv11
I0705 12:40:50.626072 43744 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 12:40:50.626081 43744 net.cpp:165] Memory required for data: 44800384
I0705 12:40:50.626096 43744 layer_factory.hpp:76] Creating layer relu11
I0705 12:40:50.626111 43744 net.cpp:106] Creating Layer relu11
I0705 12:40:50.626118 43744 net.cpp:454] relu11 <- conv11
I0705 12:40:50.626128 43744 net.cpp:397] relu11 -> conv11 (in-place)
I0705 12:40:50.626423 43744 net.cpp:150] Setting up relu11
I0705 12:40:50.626469 43744 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 12:40:50.626477 43744 net.cpp:165] Memory required for data: 85760384
I0705 12:40:50.626485 43744 layer_factory.hpp:76] Creating layer conv12
I0705 12:40:50.626500 43744 net.cpp:106] Creating Layer conv12
I0705 12:40:50.626508 43744 net.cpp:454] conv12 <- conv11
I0705 12:40:50.626523 43744 net.cpp:411] conv12 -> conv12
I0705 12:40:50.627436 43744 net.cpp:150] Setting up conv12
I0705 12:40:50.627457 43744 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 12:40:50.627465 43744 net.cpp:165] Memory required for data: 126720384
I0705 12:40:50.627481 43744 layer_factory.hpp:76] Creating layer relu12
I0705 12:40:50.627492 43744 net.cpp:106] Creating Layer relu12
I0705 12:40:50.627501 43744 net.cpp:454] relu12 <- conv12
I0705 12:40:50.627511 43744 net.cpp:397] relu12 -> conv12 (in-place)
I0705 12:40:50.627811 43744 net.cpp:150] Setting up relu12
I0705 12:40:50.627830 43744 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0705 12:40:50.627838 43744 net.cpp:165] Memory required for data: 167680384
I0705 12:40:50.627846 43744 layer_factory.hpp:76] Creating layer pool1
I0705 12:40:50.627858 43744 net.cpp:106] Creating Layer pool1
I0705 12:40:50.627866 43744 net.cpp:454] pool1 <- conv12
I0705 12:40:50.627877 43744 net.cpp:411] pool1 -> pool1
I0705 12:40:50.628069 43744 net.cpp:150] Setting up pool1
I0705 12:40:50.628087 43744 net.cpp:157] Top shape: 32 32 50 50 (2560000)
I0705 12:40:50.628095 43744 net.cpp:165] Memory required for data: 177920384
I0705 12:40:50.628103 43744 layer_factory.hpp:76] Creating layer conv21
I0705 12:40:50.628116 43744 net.cpp:106] Creating Layer conv21
I0705 12:40:50.628125 43744 net.cpp:454] conv21 <- pool1
I0705 12:40:50.628137 43744 net.cpp:411] conv21 -> conv21
I0705 12:40:50.629413 43744 net.cpp:150] Setting up conv21
I0705 12:40:50.629436 43744 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 12:40:50.629444 43744 net.cpp:165] Memory required for data: 198400384
I0705 12:40:50.629458 43744 layer_factory.hpp:76] Creating layer relu21
I0705 12:40:50.629470 43744 net.cpp:106] Creating Layer relu21
I0705 12:40:50.629478 43744 net.cpp:454] relu21 <- conv21
I0705 12:40:50.629487 43744 net.cpp:397] relu21 -> conv21 (in-place)
I0705 12:40:50.630300 43744 net.cpp:150] Setting up relu21
I0705 12:40:50.630324 43744 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 12:40:50.630333 43744 net.cpp:165] Memory required for data: 218880384
I0705 12:40:50.630342 43744 layer_factory.hpp:76] Creating layer conv22
I0705 12:40:50.630358 43744 net.cpp:106] Creating Layer conv22
I0705 12:40:50.630367 43744 net.cpp:454] conv22 <- conv21
I0705 12:40:50.630379 43744 net.cpp:411] conv22 -> conv22
I0705 12:40:50.631825 43744 net.cpp:150] Setting up conv22
I0705 12:40:50.631850 43744 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 12:40:50.631857 43744 net.cpp:165] Memory required for data: 239360384
I0705 12:40:50.631870 43744 layer_factory.hpp:76] Creating layer relu22
I0705 12:40:50.631886 43744 net.cpp:106] Creating Layer relu22
I0705 12:40:50.631893 43744 net.cpp:454] relu22 <- conv22
I0705 12:40:50.631902 43744 net.cpp:397] relu22 -> conv22 (in-place)
I0705 12:40:50.632076 43744 net.cpp:150] Setting up relu22
I0705 12:40:50.632092 43744 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0705 12:40:50.632100 43744 net.cpp:165] Memory required for data: 259840384
I0705 12:40:50.632109 43744 layer_factory.hpp:76] Creating layer pool2
I0705 12:40:50.632120 43744 net.cpp:106] Creating Layer pool2
I0705 12:40:50.632128 43744 net.cpp:454] pool2 <- conv22
I0705 12:40:50.632139 43744 net.cpp:411] pool2 -> pool2
I0705 12:40:50.632488 43744 net.cpp:150] Setting up pool2
I0705 12:40:50.632508 43744 net.cpp:157] Top shape: 32 64 25 25 (1280000)
I0705 12:40:50.632516 43744 net.cpp:165] Memory required for data: 264960384
I0705 12:40:50.632537 43744 layer_factory.hpp:76] Creating layer conv31
I0705 12:40:50.632553 43744 net.cpp:106] Creating Layer conv31
I0705 12:40:50.632561 43744 net.cpp:454] conv31 <- pool2
I0705 12:40:50.632572 43744 net.cpp:411] conv31 -> conv31
I0705 12:40:50.633831 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0705 12:40:50.633862 43744 net.cpp:150] Setting up conv31
I0705 12:40:50.633873 43744 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 12:40:50.633884 43744 net.cpp:165] Memory required for data: 272640384
I0705 12:40:50.633896 43744 layer_factory.hpp:76] Creating layer relu31
I0705 12:40:50.633908 43744 net.cpp:106] Creating Layer relu31
I0705 12:40:50.633914 43744 net.cpp:454] relu31 <- conv31
I0705 12:40:50.633924 43744 net.cpp:397] relu31 -> conv31 (in-place)
I0705 12:40:50.634203 43744 net.cpp:150] Setting up relu31
I0705 12:40:50.634222 43744 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 12:40:50.634228 43744 net.cpp:165] Memory required for data: 280320384
I0705 12:40:50.634235 43744 layer_factory.hpp:76] Creating layer conv32
I0705 12:40:50.634249 43744 net.cpp:106] Creating Layer conv32
I0705 12:40:50.634258 43744 net.cpp:454] conv32 <- conv31
I0705 12:40:50.634268 43744 net.cpp:411] conv32 -> conv32
I0705 12:40:50.635671 43744 net.cpp:150] Setting up conv32
I0705 12:40:50.635689 43744 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 12:40:50.635697 43744 net.cpp:165] Memory required for data: 288000384
I0705 12:40:50.635706 43744 layer_factory.hpp:76] Creating layer relu32
I0705 12:40:50.635716 43744 net.cpp:106] Creating Layer relu32
I0705 12:40:50.635725 43744 net.cpp:454] relu32 <- conv32
I0705 12:40:50.635735 43744 net.cpp:397] relu32 -> conv32 (in-place)
I0705 12:40:50.635881 43744 net.cpp:150] Setting up relu32
I0705 12:40:50.635896 43744 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0705 12:40:50.635903 43744 net.cpp:165] Memory required for data: 295680384
I0705 12:40:50.635910 43744 layer_factory.hpp:76] Creating layer pool3
I0705 12:40:50.635922 43744 net.cpp:106] Creating Layer pool3
I0705 12:40:50.635932 43744 net.cpp:454] pool3 <- conv32
I0705 12:40:50.635941 43744 net.cpp:411] pool3 -> pool3
I0705 12:40:50.636260 43744 net.cpp:150] Setting up pool3
I0705 12:40:50.636278 43744 net.cpp:157] Top shape: 32 96 13 13 (519168)
I0705 12:40:50.636286 43744 net.cpp:165] Memory required for data: 297757056
I0705 12:40:50.636294 43744 layer_factory.hpp:76] Creating layer conv41
I0705 12:40:50.636310 43744 net.cpp:106] Creating Layer conv41
I0705 12:40:50.636318 43744 net.cpp:454] conv41 <- pool3
I0705 12:40:50.636328 43744 net.cpp:411] conv41 -> conv41
I0705 12:40:50.638609 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0705 12:40:50.638653 43744 net.cpp:150] Setting up conv41
I0705 12:40:50.638674 43744 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 12:40:50.638680 43744 net.cpp:165] Memory required for data: 300525952
I0705 12:40:50.638690 43744 layer_factory.hpp:76] Creating layer relu41
I0705 12:40:50.638701 43744 net.cpp:106] Creating Layer relu41
I0705 12:40:50.638708 43744 net.cpp:454] relu41 <- conv41
I0705 12:40:50.638720 43744 net.cpp:397] relu41 -> conv41 (in-place)
I0705 12:40:50.638875 43744 net.cpp:150] Setting up relu41
I0705 12:40:50.638892 43744 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 12:40:50.638905 43744 net.cpp:165] Memory required for data: 303294848
I0705 12:40:50.638911 43744 layer_factory.hpp:76] Creating layer conv42
I0705 12:40:50.638923 43744 net.cpp:106] Creating Layer conv42
I0705 12:40:50.638937 43744 net.cpp:454] conv42 <- conv41
I0705 12:40:50.638947 43744 net.cpp:411] conv42 -> conv42
I0705 12:40:50.640743 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0705 12:40:50.640777 43744 net.cpp:150] Setting up conv42
I0705 12:40:50.640789 43744 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 12:40:50.640796 43744 net.cpp:165] Memory required for data: 306063744
I0705 12:40:50.640806 43744 layer_factory.hpp:76] Creating layer relu42
I0705 12:40:50.640817 43744 net.cpp:106] Creating Layer relu42
I0705 12:40:50.640831 43744 net.cpp:454] relu42 <- conv42
I0705 12:40:50.640839 43744 net.cpp:397] relu42 -> conv42 (in-place)
I0705 12:40:50.641118 43744 net.cpp:150] Setting up relu42
I0705 12:40:50.641134 43744 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0705 12:40:50.641162 43744 net.cpp:165] Memory required for data: 308832640
I0705 12:40:50.641178 43744 layer_factory.hpp:76] Creating layer pool4
I0705 12:40:50.641193 43744 net.cpp:106] Creating Layer pool4
I0705 12:40:50.641201 43744 net.cpp:454] pool4 <- conv42
I0705 12:40:50.641209 43744 net.cpp:411] pool4 -> pool4
I0705 12:40:50.641422 43744 net.cpp:150] Setting up pool4
I0705 12:40:50.641438 43744 net.cpp:157] Top shape: 32 128 7 7 (200704)
I0705 12:40:50.641444 43744 net.cpp:165] Memory required for data: 309635456
I0705 12:40:50.641451 43744 layer_factory.hpp:76] Creating layer conv51
I0705 12:40:50.641463 43744 net.cpp:106] Creating Layer conv51
I0705 12:40:50.641471 43744 net.cpp:454] conv51 <- pool4
I0705 12:40:50.641482 43744 net.cpp:411] conv51 -> conv51
I0705 12:40:50.644760 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0705 12:40:50.644948 43744 net.cpp:150] Setting up conv51
I0705 12:40:50.644965 43744 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 12:40:50.644973 43744 net.cpp:165] Memory required for data: 311241088
I0705 12:40:50.644987 43744 layer_factory.hpp:76] Creating layer relu51
I0705 12:40:50.645000 43744 net.cpp:106] Creating Layer relu51
I0705 12:40:50.645007 43744 net.cpp:454] relu51 <- conv51
I0705 12:40:50.645016 43744 net.cpp:397] relu51 -> conv51 (in-place)
I0705 12:40:50.645184 43744 net.cpp:150] Setting up relu51
I0705 12:40:50.645197 43744 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 12:40:50.645205 43744 net.cpp:165] Memory required for data: 312846720
I0705 12:40:50.645211 43744 layer_factory.hpp:76] Creating layer conv52
I0705 12:40:50.645226 43744 net.cpp:106] Creating Layer conv52
I0705 12:40:50.645233 43744 net.cpp:454] conv52 <- conv51
I0705 12:40:50.645247 43744 net.cpp:411] conv52 -> conv52
I0705 12:40:50.650869 43744 net.cpp:150] Setting up conv52
I0705 12:40:50.650904 43744 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 12:40:50.650913 43744 net.cpp:165] Memory required for data: 314452352
I0705 12:40:50.650923 43744 layer_factory.hpp:76] Creating layer relu52
I0705 12:40:50.650931 43744 net.cpp:106] Creating Layer relu52
I0705 12:40:50.650943 43744 net.cpp:454] relu52 <- conv52
I0705 12:40:50.650950 43744 net.cpp:397] relu52 -> conv52 (in-place)
I0705 12:40:50.651309 43744 net.cpp:150] Setting up relu52
I0705 12:40:50.651341 43744 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0705 12:40:50.651348 43744 net.cpp:165] Memory required for data: 316057984
I0705 12:40:50.651356 43744 layer_factory.hpp:76] Creating layer conv53
I0705 12:40:50.651367 43744 net.cpp:106] Creating Layer conv53
I0705 12:40:50.651376 43744 net.cpp:454] conv53 <- conv52
I0705 12:40:50.651386 43744 net.cpp:411] conv53 -> conv53
I0705 12:40:50.677542 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0705 12:40:50.677594 43744 net.cpp:150] Setting up conv53
I0705 12:40:50.677608 43744 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0705 12:40:50.677618 43744 net.cpp:165] Memory required for data: 316090752
I0705 12:40:50.677629 43744 layer_factory.hpp:76] Creating layer relu53
I0705 12:40:50.677642 43744 net.cpp:106] Creating Layer relu53
I0705 12:40:50.677652 43744 net.cpp:454] relu53 <- conv53
I0705 12:40:50.677664 43744 net.cpp:397] relu53 -> conv53 (in-place)
I0705 12:40:50.677821 43744 net.cpp:150] Setting up relu53
I0705 12:40:50.677836 43744 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0705 12:40:50.677845 43744 net.cpp:165] Memory required for data: 316123520
I0705 12:40:50.677851 43744 layer_factory.hpp:76] Creating layer drop6
I0705 12:40:50.677863 43744 net.cpp:106] Creating Layer drop6
I0705 12:40:50.677871 43744 net.cpp:454] drop6 <- conv53
I0705 12:40:50.677881 43744 net.cpp:411] drop6 -> drop6
I0705 12:40:50.677927 43744 net.cpp:150] Setting up drop6
I0705 12:40:50.677939 43744 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0705 12:40:50.677947 43744 net.cpp:165] Memory required for data: 316156288
I0705 12:40:50.677956 43744 layer_factory.hpp:76] Creating layer conv54
I0705 12:40:50.677970 43744 net.cpp:106] Creating Layer conv54
I0705 12:40:50.678009 43744 net.cpp:454] conv54 <- drop6
I0705 12:40:50.678020 43744 net.cpp:411] conv54 -> conv54
I0705 12:40:50.678938 43744 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0705 12:40:50.678968 43744 net.cpp:150] Setting up conv54
I0705 12:40:50.678979 43744 net.cpp:157] Top shape: 32 2 1 1 (64)
I0705 12:40:50.678987 43744 net.cpp:165] Memory required for data: 316156544
I0705 12:40:50.678995 43744 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0705 12:40:50.679008 43744 net.cpp:106] Creating Layer conv54_conv54_0_split
I0705 12:40:50.679015 43744 net.cpp:454] conv54_conv54_0_split <- conv54
I0705 12:40:50.679025 43744 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0705 12:40:50.679038 43744 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0705 12:40:50.679080 43744 net.cpp:150] Setting up conv54_conv54_0_split
I0705 12:40:50.679092 43744 net.cpp:157] Top shape: 32 2 1 1 (64)
I0705 12:40:50.679100 43744 net.cpp:157] Top shape: 32 2 1 1 (64)
I0705 12:40:50.679111 43744 net.cpp:165] Memory required for data: 316157056
I0705 12:40:50.679117 43744 layer_factory.hpp:76] Creating layer accuracy
I0705 12:40:50.679132 43744 net.cpp:106] Creating Layer accuracy
I0705 12:40:50.679141 43744 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0705 12:40:50.679152 43744 net.cpp:454] accuracy <- label_data_1_split_0
I0705 12:40:50.679160 43744 net.cpp:411] accuracy -> accuracy
I0705 12:40:50.679186 43744 net.cpp:150] Setting up accuracy
I0705 12:40:50.679195 43744 net.cpp:157] Top shape: (1)
I0705 12:40:50.679203 43744 net.cpp:165] Memory required for data: 316157060
I0705 12:40:50.679214 43744 layer_factory.hpp:76] Creating layer loss
I0705 12:40:50.679229 43744 net.cpp:106] Creating Layer loss
I0705 12:40:50.679237 43744 net.cpp:454] loss <- conv54_conv54_0_split_1
I0705 12:40:50.679249 43744 net.cpp:454] loss <- label_data_1_split_1
I0705 12:40:50.679260 43744 net.cpp:411] loss -> loss
I0705 12:40:50.679277 43744 layer_factory.hpp:76] Creating layer loss
I0705 12:40:50.679514 43744 net.cpp:150] Setting up loss
I0705 12:40:50.679529 43744 net.cpp:157] Top shape: (1)
I0705 12:40:50.679536 43744 net.cpp:160]     with loss weight 1
I0705 12:40:50.679549 43744 net.cpp:165] Memory required for data: 316157064
I0705 12:40:50.679558 43744 net.cpp:226] loss needs backward computation.
I0705 12:40:50.679564 43744 net.cpp:228] accuracy does not need backward computation.
I0705 12:40:50.679571 43744 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0705 12:40:50.679579 43744 net.cpp:226] conv54 needs backward computation.
I0705 12:40:50.679585 43744 net.cpp:226] drop6 needs backward computation.
I0705 12:40:50.679591 43744 net.cpp:226] relu53 needs backward computation.
I0705 12:40:50.679597 43744 net.cpp:226] conv53 needs backward computation.
I0705 12:40:50.679605 43744 net.cpp:226] relu52 needs backward computation.
I0705 12:40:50.679610 43744 net.cpp:226] conv52 needs backward computation.
I0705 12:40:50.679616 43744 net.cpp:226] relu51 needs backward computation.
I0705 12:40:50.679625 43744 net.cpp:226] conv51 needs backward computation.
I0705 12:40:50.679632 43744 net.cpp:226] pool4 needs backward computation.
I0705 12:40:50.679638 43744 net.cpp:226] relu42 needs backward computation.
I0705 12:40:50.679646 43744 net.cpp:226] conv42 needs backward computation.
I0705 12:40:50.679651 43744 net.cpp:226] relu41 needs backward computation.
I0705 12:40:50.679657 43744 net.cpp:226] conv41 needs backward computation.
I0705 12:40:50.679664 43744 net.cpp:226] pool3 needs backward computation.
I0705 12:40:50.679672 43744 net.cpp:226] relu32 needs backward computation.
I0705 12:40:50.679677 43744 net.cpp:226] conv32 needs backward computation.
I0705 12:40:50.679683 43744 net.cpp:226] relu31 needs backward computation.
I0705 12:40:50.679689 43744 net.cpp:226] conv31 needs backward computation.
I0705 12:40:50.679697 43744 net.cpp:226] pool2 needs backward computation.
I0705 12:40:50.679702 43744 net.cpp:226] relu22 needs backward computation.
I0705 12:40:50.679723 43744 net.cpp:226] conv22 needs backward computation.
I0705 12:40:50.679729 43744 net.cpp:226] relu21 needs backward computation.
I0705 12:40:50.679735 43744 net.cpp:226] conv21 needs backward computation.
I0705 12:40:50.679743 43744 net.cpp:226] pool1 needs backward computation.
I0705 12:40:50.679749 43744 net.cpp:226] relu12 needs backward computation.
I0705 12:40:50.679754 43744 net.cpp:226] conv12 needs backward computation.
I0705 12:40:50.679760 43744 net.cpp:226] relu11 needs backward computation.
I0705 12:40:50.679769 43744 net.cpp:226] conv11 needs backward computation.
I0705 12:40:50.679775 43744 net.cpp:228] label_data_1_split does not need backward computation.
I0705 12:40:50.679781 43744 net.cpp:228] data does not need backward computation.
I0705 12:40:50.679787 43744 net.cpp:270] This network produces output accuracy
I0705 12:40:50.679795 43744 net.cpp:270] This network produces output loss
I0705 12:40:50.679816 43744 net.cpp:283] Network initialization done.
I0705 12:40:50.679996 43744 solver.cpp:59] Solver scaffolding done.
I0705 12:40:50.680789 43744 caffe.cpp:212] Starting Optimization
I0705 12:40:50.680807 43744 solver.cpp:287] Solving FaceNN
I0705 12:40:50.680814 43744 solver.cpp:288] Learning Rate Policy: step
I0705 12:40:50.682477 43744 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 12:40:57.682575 43744 solver.cpp:236] Iteration 0, loss = 1.62475
I0705 12:40:57.682624 43744 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 12:40:57.682641 43744 solver.cpp:252]     Train net output #1: loss = 1.62475 (* 1 = 1.62475 loss)
I0705 12:40:57.682667 43744 sgd_solver.cpp:106] Iteration 0, lr = 0.015
I0705 12:41:55.398200 43744 solver.cpp:236] Iteration 10, loss = 19.8424
I0705 12:41:55.398471 43744 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 12:41:55.398512 43744 solver.cpp:252]     Train net output #1: loss = 0.713294 (* 1 = 0.713294 loss)
I0705 12:41:55.398547 43744 sgd_solver.cpp:106] Iteration 10, lr = 0.015
I0705 12:42:54.233335 43744 solver.cpp:236] Iteration 20, loss = 10.7258
I0705 12:42:54.233537 43744 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 12:42:54.233579 43744 solver.cpp:252]     Train net output #1: loss = 0.693666 (* 1 = 0.693666 loss)
I0705 12:42:54.233592 43744 sgd_solver.cpp:106] Iteration 20, lr = 0.015
I0705 12:43:49.738664 43744 solver.cpp:236] Iteration 30, loss = 7.49
I0705 12:43:49.738975 43744 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 12:43:49.738999 43744 solver.cpp:252]     Train net output #1: loss = 0.693042 (* 1 = 0.693042 loss)
I0705 12:43:49.739029 43744 sgd_solver.cpp:106] Iteration 30, lr = 0.015
I0705 12:44:54.892822 43744 solver.cpp:236] Iteration 40, loss = 5.8327
I0705 12:44:54.893070 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 12:44:54.893103 43744 solver.cpp:252]     Train net output #1: loss = 0.695371 (* 1 = 0.695371 loss)
I0705 12:44:54.893134 43744 sgd_solver.cpp:106] Iteration 40, lr = 0.015
I0705 12:45:54.717730 43744 solver.cpp:236] Iteration 50, loss = 4.88906
I0705 12:45:54.717891 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 12:45:54.717927 43744 solver.cpp:252]     Train net output #1: loss = 0.694061 (* 1 = 0.694061 loss)
I0705 12:45:54.717941 43744 sgd_solver.cpp:106] Iteration 50, lr = 0.015
I0705 12:46:46.550101 43744 solver.cpp:236] Iteration 60, loss = 0.694867
I0705 12:46:46.550240 43744 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 12:46:46.550278 43744 solver.cpp:252]     Train net output #1: loss = 0.69265 (* 1 = 0.69265 loss)
I0705 12:46:46.550293 43744 sgd_solver.cpp:106] Iteration 60, lr = 0.015
I0705 12:47:38.086688 43744 solver.cpp:236] Iteration 70, loss = 0.693983
I0705 12:47:38.086835 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 12:47:38.086886 43744 solver.cpp:252]     Train net output #1: loss = 0.696533 (* 1 = 0.696533 loss)
I0705 12:47:38.086900 43744 sgd_solver.cpp:106] Iteration 70, lr = 0.015
I0705 12:48:28.015882 43744 solver.cpp:236] Iteration 80, loss = 0.693578
I0705 12:48:28.016073 43744 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 12:48:28.016108 43744 solver.cpp:252]     Train net output #1: loss = 0.699493 (* 1 = 0.699493 loss)
I0705 12:48:28.016124 43744 sgd_solver.cpp:106] Iteration 80, lr = 0.015
I0705 12:49:18.478057 43744 solver.cpp:236] Iteration 90, loss = 0.693541
I0705 12:49:18.478181 43744 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0705 12:49:18.478200 43744 solver.cpp:252]     Train net output #1: loss = 0.691786 (* 1 = 0.691786 loss)
I0705 12:49:18.478215 43744 sgd_solver.cpp:106] Iteration 90, lr = 0.015
I0705 12:50:06.456434 43744 solver.cpp:236] Iteration 100, loss = 0.693956
I0705 12:50:06.456634 43744 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 12:50:06.456670 43744 solver.cpp:252]     Train net output #1: loss = 0.695844 (* 1 = 0.695844 loss)
I0705 12:50:06.456681 43744 sgd_solver.cpp:106] Iteration 100, lr = 0.015
I0705 12:50:53.286614 43744 solver.cpp:236] Iteration 110, loss = 0.693892
I0705 12:50:53.286741 43744 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 12:50:53.286761 43744 solver.cpp:252]     Train net output #1: loss = 0.695845 (* 1 = 0.695845 loss)
I0705 12:50:53.286788 43744 sgd_solver.cpp:106] Iteration 110, lr = 0.015
I0705 12:51:40.121556 43744 solver.cpp:236] Iteration 120, loss = 0.694006
I0705 12:51:40.121681 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 12:51:40.121727 43744 solver.cpp:252]     Train net output #1: loss = 0.695144 (* 1 = 0.695144 loss)
I0705 12:51:40.121742 43744 sgd_solver.cpp:106] Iteration 120, lr = 0.015
I0705 12:52:25.814158 43744 solver.cpp:236] Iteration 130, loss = 0.694296
I0705 12:52:25.814373 43744 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 12:52:25.814404 43744 solver.cpp:252]     Train net output #1: loss = 0.693648 (* 1 = 0.693648 loss)
I0705 12:52:25.814416 43744 sgd_solver.cpp:106] Iteration 130, lr = 0.015
I0705 12:53:12.049515 43744 solver.cpp:236] Iteration 140, loss = 0.693979
I0705 12:53:12.049651 43744 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 12:53:12.049676 43744 solver.cpp:252]     Train net output #1: loss = 0.692894 (* 1 = 0.692894 loss)
I0705 12:53:12.049702 43744 sgd_solver.cpp:106] Iteration 140, lr = 0.015
I0705 12:54:02.157101 43744 solver.cpp:236] Iteration 150, loss = 0.693463
I0705 12:54:02.157280 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 12:54:02.157310 43744 solver.cpp:252]     Train net output #1: loss = 0.693196 (* 1 = 0.693196 loss)
I0705 12:54:02.157320 43744 sgd_solver.cpp:106] Iteration 150, lr = 0.015
I0705 12:54:48.607378 43744 solver.cpp:236] Iteration 160, loss = 0.693706
I0705 12:54:48.607597 43744 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 12:54:48.607633 43744 solver.cpp:252]     Train net output #1: loss = 0.690978 (* 1 = 0.690978 loss)
I0705 12:54:48.607652 43744 sgd_solver.cpp:106] Iteration 160, lr = 0.015
I0705 12:55:28.786731 43744 solver.cpp:236] Iteration 170, loss = 0.693683
I0705 12:55:28.786893 43744 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 12:55:28.786945 43744 solver.cpp:252]     Train net output #1: loss = 0.692989 (* 1 = 0.692989 loss)
I0705 12:55:28.786965 43744 sgd_solver.cpp:106] Iteration 170, lr = 0.015
I0705 12:56:11.207712 43744 solver.cpp:236] Iteration 180, loss = 0.693771
I0705 12:56:11.207834 43744 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 12:56:11.207875 43744 solver.cpp:252]     Train net output #1: loss = 0.694691 (* 1 = 0.694691 loss)
I0705 12:56:11.207902 43744 sgd_solver.cpp:106] Iteration 180, lr = 0.015
I0705 12:56:51.052728 43744 solver.cpp:236] Iteration 190, loss = 0.693971
I0705 12:56:51.052863 43744 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 12:56:51.052913 43744 solver.cpp:252]     Train net output #1: loss = 0.691018 (* 1 = 0.691018 loss)
I0705 12:56:51.052925 43744 sgd_solver.cpp:106] Iteration 190, lr = 0.015
I0705 12:57:31.054425 43744 solver.cpp:236] Iteration 200, loss = 0.694108
I0705 12:57:31.054637 43744 solver.cpp:252]     Train net output #0: accuracy = 0.445312
I0705 12:57:31.054658 43744 solver.cpp:252]     Train net output #1: loss = 0.694053 (* 1 = 0.694053 loss)
I0705 12:57:31.054671 43744 sgd_solver.cpp:106] Iteration 200, lr = 0.015
I0705 12:58:10.829917 43744 solver.cpp:236] Iteration 210, loss = 0.693888
I0705 12:58:10.830080 43744 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 12:58:10.830116 43744 solver.cpp:252]     Train net output #1: loss = 0.693056 (* 1 = 0.693056 loss)
I0705 12:58:10.830127 43744 sgd_solver.cpp:106] Iteration 210, lr = 0.015
I0705 12:58:50.397780 43744 solver.cpp:236] Iteration 220, loss = 0.693657
I0705 12:58:50.397915 43744 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 12:58:50.397971 43744 solver.cpp:252]     Train net output #1: loss = 0.695507 (* 1 = 0.695507 loss)
I0705 12:58:50.397986 43744 sgd_solver.cpp:106] Iteration 220, lr = 0.015
I0705 12:59:29.894286 43744 solver.cpp:236] Iteration 230, loss = 0.693555
I0705 12:59:29.894392 43744 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 12:59:29.894423 43744 solver.cpp:252]     Train net output #1: loss = 0.696752 (* 1 = 0.696752 loss)
I0705 12:59:29.894436 43744 sgd_solver.cpp:106] Iteration 230, lr = 0.015
I0705 13:00:11.750203 43744 solver.cpp:236] Iteration 240, loss = 0.693264
I0705 13:00:11.750447 43744 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 13:00:11.750526 43744 solver.cpp:252]     Train net output #1: loss = 0.692643 (* 1 = 0.692643 loss)
I0705 13:00:11.750569 43744 sgd_solver.cpp:106] Iteration 240, lr = 0.015
I0705 13:00:48.107230 43744 solver.cpp:340] Iteration 250, Testing net (#0)
I0705 13:02:27.676362 43744 solver.cpp:408]     Test net output #0: accuracy = 0.508125
I0705 13:02:27.676529 43744 solver.cpp:408]     Test net output #1: loss = 0.693031 (* 1 = 0.693031 loss)
I0705 13:02:27.831903 43744 solver.cpp:236] Iteration 250, loss = 0.693187
I0705 13:02:27.831979 43744 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 13:02:27.832008 43744 solver.cpp:252]     Train net output #1: loss = 0.692873 (* 1 = 0.692873 loss)
I0705 13:02:27.832026 43744 sgd_solver.cpp:106] Iteration 250, lr = 0.015
I0705 13:03:00.920852 43744 solver.cpp:236] Iteration 260, loss = 0.693277
I0705 13:03:00.920956 43744 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:03:00.920974 43744 solver.cpp:252]     Train net output #1: loss = 0.693169 (* 1 = 0.693169 loss)
I0705 13:03:00.920997 43744 sgd_solver.cpp:106] Iteration 260, lr = 0.015
I0705 13:03:43.245667 43744 solver.cpp:236] Iteration 270, loss = 0.693473
I0705 13:03:43.245786 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 13:03:43.245803 43744 solver.cpp:252]     Train net output #1: loss = 0.694576 (* 1 = 0.694576 loss)
I0705 13:03:43.245822 43744 sgd_solver.cpp:106] Iteration 270, lr = 0.015
I0705 13:04:26.856850 43744 solver.cpp:236] Iteration 280, loss = 0.693226
I0705 13:04:26.856994 43744 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 13:04:26.857051 43744 solver.cpp:252]     Train net output #1: loss = 0.692324 (* 1 = 0.692324 loss)
I0705 13:04:26.857064 43744 sgd_solver.cpp:106] Iteration 280, lr = 0.015
I0705 13:05:09.887091 43744 solver.cpp:236] Iteration 290, loss = 0.693447
I0705 13:05:09.887230 43744 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 13:05:09.887260 43744 solver.cpp:252]     Train net output #1: loss = 0.695585 (* 1 = 0.695585 loss)
I0705 13:05:09.887285 43744 sgd_solver.cpp:106] Iteration 290, lr = 0.015
I0705 13:05:53.761776 43744 solver.cpp:236] Iteration 300, loss = 0.693611
I0705 13:05:53.761916 43744 solver.cpp:252]     Train net output #0: accuracy = 0.429688
I0705 13:05:53.761962 43744 solver.cpp:252]     Train net output #1: loss = 0.697855 (* 1 = 0.697855 loss)
I0705 13:05:53.761976 43744 sgd_solver.cpp:106] Iteration 300, lr = 0.015
I0705 13:06:37.321691 43744 solver.cpp:236] Iteration 310, loss = 0.693554
I0705 13:06:37.321836 43744 solver.cpp:252]     Train net output #0: accuracy = 0.53125
I0705 13:06:37.321879 43744 solver.cpp:252]     Train net output #1: loss = 0.692615 (* 1 = 0.692615 loss)
I0705 13:06:37.321892 43744 sgd_solver.cpp:106] Iteration 310, lr = 0.015
I0705 13:07:18.697921 43744 solver.cpp:236] Iteration 320, loss = 0.693518
I0705 13:07:18.698071 43744 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 13:07:18.698106 43744 solver.cpp:252]     Train net output #1: loss = 0.692909 (* 1 = 0.692909 loss)
I0705 13:07:18.698138 43744 sgd_solver.cpp:106] Iteration 320, lr = 0.015
I0705 13:08:00.328243 43744 solver.cpp:236] Iteration 330, loss = 0.693587
I0705 13:08:00.328447 43744 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 13:08:00.328483 43744 solver.cpp:252]     Train net output #1: loss = 0.693271 (* 1 = 0.693271 loss)
I0705 13:08:00.328510 43744 sgd_solver.cpp:106] Iteration 330, lr = 0.015
I0705 13:08:40.504217 43744 solver.cpp:236] Iteration 340, loss = 0.693594
I0705 13:08:40.504413 43744 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0705 13:08:40.504446 43744 solver.cpp:252]     Train net output #1: loss = 0.695297 (* 1 = 0.695297 loss)
I0705 13:08:40.504461 43744 sgd_solver.cpp:106] Iteration 340, lr = 0.015
I0705 13:09:21.470798 43744 solver.cpp:236] Iteration 350, loss = 0.693427
I0705 13:09:21.470933 43744 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0705 13:09:21.470950 43744 solver.cpp:252]     Train net output #1: loss = 0.694727 (* 1 = 0.694727 loss)
I0705 13:09:21.470970 43744 sgd_solver.cpp:106] Iteration 350, lr = 0.015
I0705 13:10:02.544360 43744 solver.cpp:236] Iteration 360, loss = 0.693453
I0705 13:10:02.544649 43744 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 13:10:02.544670 43744 solver.cpp:252]     Train net output #1: loss = 0.693168 (* 1 = 0.693168 loss)
I0705 13:10:02.544693 43744 sgd_solver.cpp:106] Iteration 360, lr = 0.015
I0705 13:10:43.644250 43744 solver.cpp:236] Iteration 370, loss = 0.693527
I0705 13:10:43.644425 43744 solver.cpp:252]     Train net output #0: accuracy = 0.515625
I0705 13:10:43.644465 43744 solver.cpp:252]     Train net output #1: loss = 0.692781 (* 1 = 0.692781 loss)
I0705 13:10:43.644479 43744 sgd_solver.cpp:106] Iteration 370, lr = 0.015
I0705 13:11:23.874037 43744 solver.cpp:236] Iteration 380, loss = 0.693511
I0705 13:11:23.874156 43744 solver.cpp:252]     Train net output #0: accuracy = 0.523438
I0705 13:11:23.874210 43744 solver.cpp:252]     Train net output #1: loss = 0.693076 (* 1 = 0.693076 loss)
I0705 13:11:23.874224 43744 sgd_solver.cpp:106] Iteration 380, lr = 0.015
I0705 13:12:05.798280 43744 solver.cpp:236] Iteration 390, loss = 0.693341
I0705 13:12:05.798439 43744 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:12:05.798476 43744 solver.cpp:252]     Train net output #1: loss = 0.693503 (* 1 = 0.693503 loss)
I0705 13:12:05.798494 43744 sgd_solver.cpp:106] Iteration 390, lr = 0.015
I0705 13:12:47.419044 43744 solver.cpp:236] Iteration 400, loss = 0.693275
I0705 13:12:47.419168 43744 solver.cpp:252]     Train net output #0: accuracy = 0.421875
I0705 13:12:47.419200 43744 solver.cpp:252]     Train net output #1: loss = 0.698399 (* 1 = 0.698399 loss)
I0705 13:12:47.419224 43744 sgd_solver.cpp:106] Iteration 400, lr = 0.015
I0705 13:13:27.315440 43744 solver.cpp:236] Iteration 410, loss = 0.693192
I0705 13:13:27.315610 43744 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 13:13:27.315644 43744 solver.cpp:252]     Train net output #1: loss = 0.697502 (* 1 = 0.697502 loss)
I0705 13:13:27.315663 43744 sgd_solver.cpp:106] Iteration 410, lr = 0.015
I0705 13:14:08.059077 43744 solver.cpp:236] Iteration 420, loss = 0.693246
I0705 13:14:08.059311 43744 solver.cpp:252]     Train net output #0: accuracy = 0.453125
I0705 13:14:08.059331 43744 solver.cpp:252]     Train net output #1: loss = 0.693874 (* 1 = 0.693874 loss)
I0705 13:14:08.059347 43744 sgd_solver.cpp:106] Iteration 420, lr = 0.015
I0705 13:14:48.932834 43744 solver.cpp:236] Iteration 430, loss = 0.693307
I0705 13:14:48.932973 43744 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:14:48.933004 43744 solver.cpp:252]     Train net output #1: loss = 0.694451 (* 1 = 0.694451 loss)
I0705 13:14:48.933029 43744 sgd_solver.cpp:106] Iteration 430, lr = 0.015
I0705 13:15:31.736049 43744 solver.cpp:236] Iteration 440, loss = 0.69349
I0705 13:15:31.736227 43744 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 13:15:31.736268 43744 solver.cpp:252]     Train net output #1: loss = 0.693384 (* 1 = 0.693384 loss)
I0705 13:15:31.736279 43744 sgd_solver.cpp:106] Iteration 440, lr = 0.015
I0705 13:16:16.081902 43744 solver.cpp:236] Iteration 450, loss = 0.693564
I0705 13:16:16.082036 43744 solver.cpp:252]     Train net output #0: accuracy = 0.507812
I0705 13:16:16.082084 43744 solver.cpp:252]     Train net output #1: loss = 0.693032 (* 1 = 0.693032 loss)
I0705 13:16:16.082098 43744 sgd_solver.cpp:106] Iteration 450, lr = 0.015
I0705 13:17:00.429930 43744 solver.cpp:236] Iteration 460, loss = 0.69354
I0705 13:17:00.430042 43744 solver.cpp:252]     Train net output #0: accuracy = 0.539062
I0705 13:17:00.430071 43744 solver.cpp:252]     Train net output #1: loss = 0.691756 (* 1 = 0.691756 loss)
I0705 13:17:00.430088 43744 sgd_solver.cpp:106] Iteration 460, lr = 0.015
I0705 13:17:43.255316 43744 solver.cpp:236] Iteration 470, loss = 0.693508
I0705 13:17:43.255532 43744 solver.cpp:252]     Train net output #0: accuracy = 0.460938
I0705 13:17:43.255563 43744 solver.cpp:252]     Train net output #1: loss = 0.694741 (* 1 = 0.694741 loss)
I0705 13:17:43.255583 43744 sgd_solver.cpp:106] Iteration 470, lr = 0.015
I0705 13:18:26.901618 43744 solver.cpp:236] Iteration 480, loss = 0.693425
I0705 13:18:26.901737 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 13:18:26.901756 43744 solver.cpp:252]     Train net output #1: loss = 0.695392 (* 1 = 0.695392 loss)
I0705 13:18:26.901790 43744 sgd_solver.cpp:106] Iteration 480, lr = 0.015
I0705 13:19:10.957846 43744 solver.cpp:236] Iteration 490, loss = 0.693558
I0705 13:19:10.958019 43744 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 13:19:10.958061 43744 solver.cpp:252]     Train net output #1: loss = 0.693688 (* 1 = 0.693688 loss)
I0705 13:19:10.958073 43744 sgd_solver.cpp:106] Iteration 490, lr = 0.015
I0705 13:19:53.461066 43744 solver.cpp:340] Iteration 500, Testing net (#0)
I0705 13:21:48.335675 43744 solver.cpp:408]     Test net output #0: accuracy = 0.49625
I0705 13:21:48.335815 43744 solver.cpp:408]     Test net output #1: loss = 0.693191 (* 1 = 0.693191 loss)
I0705 13:21:48.489351 43744 solver.cpp:236] Iteration 500, loss = 0.693449
I0705 13:21:48.489394 43744 solver.cpp:252]     Train net output #0: accuracy = 0.554688
I0705 13:21:48.489409 43744 solver.cpp:252]     Train net output #1: loss = 0.692668 (* 1 = 0.692668 loss)
I0705 13:21:48.489424 43744 sgd_solver.cpp:106] Iteration 500, lr = 0.015
I0705 13:22:25.493290 43744 solver.cpp:236] Iteration 510, loss = 0.693587
I0705 13:22:25.493590 43744 solver.cpp:252]     Train net output #0: accuracy = 0.476562
I0705 13:22:25.493615 43744 solver.cpp:252]     Train net output #1: loss = 0.693255 (* 1 = 0.693255 loss)
I0705 13:22:25.493625 43744 sgd_solver.cpp:106] Iteration 510, lr = 0.015
I0705 13:23:12.858948 43744 solver.cpp:236] Iteration 520, loss = 0.693525
I0705 13:23:12.859087 43744 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0705 13:23:12.859130 43744 solver.cpp:252]     Train net output #1: loss = 0.693734 (* 1 = 0.693734 loss)
I0705 13:23:12.859156 43744 sgd_solver.cpp:106] Iteration 520, lr = 0.015
I0705 13:24:00.247764 43744 solver.cpp:236] Iteration 530, loss = 0.693773
I0705 13:24:00.247942 43744 solver.cpp:252]     Train net output #0: accuracy = 0.492188
I0705 13:24:00.247979 43744 solver.cpp:252]     Train net output #1: loss = 0.693611 (* 1 = 0.693611 loss)
I0705 13:24:00.247993 43744 sgd_solver.cpp:106] Iteration 530, lr = 0.015
I0705 13:24:49.699952 43744 solver.cpp:236] Iteration 540, loss = 0.693344
I0705 13:24:49.700191 43744 solver.cpp:252]     Train net output #0: accuracy = 0.554688
I0705 13:24:49.700222 43744 solver.cpp:252]     Train net output #1: loss = 0.689592 (* 1 = 0.689592 loss)
I0705 13:24:49.700233 43744 sgd_solver.cpp:106] Iteration 540, lr = 0.015
I0705 13:25:38.494606 43744 solver.cpp:236] Iteration 550, loss = 0.693744
I0705 13:25:38.494741 43744 solver.cpp:252]     Train net output #0: accuracy = 0.546875
I0705 13:25:38.494807 43744 solver.cpp:252]     Train net output #1: loss = 0.690579 (* 1 = 0.690579 loss)
I0705 13:25:38.494822 43744 sgd_solver.cpp:106] Iteration 550, lr = 0.015
I0705 13:26:27.883493 43744 solver.cpp:236] Iteration 560, loss = 0.693491
I0705 13:26:27.883723 43744 solver.cpp:252]     Train net output #0: accuracy = 0.570312
I0705 13:26:27.883759 43744 solver.cpp:252]     Train net output #1: loss = 0.690402 (* 1 = 0.690402 loss)
I0705 13:26:27.883786 43744 sgd_solver.cpp:106] Iteration 560, lr = 0.015
I0705 13:27:18.225225 43744 solver.cpp:236] Iteration 570, loss = 0.693643
I0705 13:27:18.225344 43744 solver.cpp:252]     Train net output #0: accuracy = 0.585938
I0705 13:27:18.225399 43744 solver.cpp:252]     Train net output #1: loss = 0.69261 (* 1 = 0.69261 loss)
I0705 13:27:18.225419 43744 sgd_solver.cpp:106] Iteration 570, lr = 0.015
I0705 13:28:07.235049 43744 solver.cpp:236] Iteration 580, loss = 0.693454
I0705 13:28:07.235213 43744 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:28:07.235254 43744 solver.cpp:252]     Train net output #1: loss = 0.693908 (* 1 = 0.693908 loss)
I0705 13:28:07.235266 43744 sgd_solver.cpp:106] Iteration 580, lr = 0.015
I0705 13:28:47.285992 43744 solver.cpp:236] Iteration 590, loss = 0.693649
I0705 13:28:47.286262 43744 solver.cpp:252]     Train net output #0: accuracy = 0.570312
I0705 13:28:47.286283 43744 solver.cpp:252]     Train net output #1: loss = 0.691661 (* 1 = 0.691661 loss)
I0705 13:28:47.286300 43744 sgd_solver.cpp:106] Iteration 590, lr = 0.015
I0705 13:29:27.135687 43744 solver.cpp:236] Iteration 600, loss = 0.693292
I0705 13:29:27.135869 43744 solver.cpp:252]     Train net output #0: accuracy = 0.46875
I0705 13:29:27.135901 43744 solver.cpp:252]     Train net output #1: loss = 0.696184 (* 1 = 0.696184 loss)
I0705 13:29:27.135915 43744 sgd_solver.cpp:106] Iteration 600, lr = 0.015
I0705 13:30:07.033696 43744 solver.cpp:236] Iteration 610, loss = 0.693684
I0705 13:30:07.033884 43744 solver.cpp:252]     Train net output #0: accuracy = 0.484375
I0705 13:30:07.033908 43744 solver.cpp:252]     Train net output #1: loss = 0.693767 (* 1 = 0.693767 loss)
I0705 13:30:07.033926 43744 sgd_solver.cpp:106] Iteration 610, lr = 0.015
I0705 13:30:11.087445 43744 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_612.caffemodel
I0705 13:30:11.656102 43744 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_612.solverstate
I0705 13:30:11.684550 43744 solver.cpp:308] Optimization stopped early.
I0705 13:30:11.684600 43744 caffe.cpp:215] Optimization Done.
