Log file created at: 2016/07/06 10:12:33
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0706 10:12:33.340762 54857 caffe.cpp:184] Using GPUs 2
I0706 10:12:33.867779 54857 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 250
base_lr: 0.005
display: 100
max_iter: 360000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/cnn10"
solver_mode: GPU
device_id: 2
net: "train_val.prototxt.full"
test_initialization: false
average_loss: 50
I0706 10:12:33.868194 54857 solver.cpp:90] Creating training net from net file: train_val.prototxt.full
I0706 10:12:33.868867 54857 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0706 10:12:33.869010 54857 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0706 10:12:33.869104 54857 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0706 10:12:33.869285 54857 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-train-L0.lst"
    batch_size: 128
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0706 10:12:33.869554 54857 layer_factory.hpp:76] Creating layer data
I0706 10:12:33.869595 54857 net.cpp:106] Creating Layer data
I0706 10:12:33.869603 54857 net.cpp:411] data -> data
I0706 10:12:33.869627 54857 net.cpp:411] data -> label
I0706 10:12:33.870008 54857 image_data_layer.cpp:36] Opening file ../lists/roi-train-L0.lst
I0706 10:12:33.971371 54857 image_data_layer.cpp:46] Shuffling data
I0706 10:12:33.998870 54857 image_data_layer.cpp:51] A total of 211680 images.
I0706 10:12:34.119982 54857 image_data_layer.cpp:78] output data size: 128,3,100,100
I0706 10:12:34.166919 54857 net.cpp:150] Setting up data
I0706 10:12:34.167001 54857 net.cpp:157] Top shape: 128 3 100 100 (3840000)
I0706 10:12:34.167013 54857 net.cpp:157] Top shape: 128 (128)
I0706 10:12:34.167021 54857 net.cpp:165] Memory required for data: 15360512
I0706 10:12:34.167035 54857 layer_factory.hpp:76] Creating layer label_data_1_split
I0706 10:12:34.167059 54857 net.cpp:106] Creating Layer label_data_1_split
I0706 10:12:34.167070 54857 net.cpp:454] label_data_1_split <- label
I0706 10:12:34.167100 54857 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0706 10:12:34.167116 54857 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0706 10:12:34.167168 54857 net.cpp:150] Setting up label_data_1_split
I0706 10:12:34.167181 54857 net.cpp:157] Top shape: 128 (128)
I0706 10:12:34.167191 54857 net.cpp:157] Top shape: 128 (128)
I0706 10:12:34.167197 54857 net.cpp:165] Memory required for data: 15361536
I0706 10:12:34.167206 54857 layer_factory.hpp:76] Creating layer conv11
I0706 10:12:34.167248 54857 net.cpp:106] Creating Layer conv11
I0706 10:12:34.167258 54857 net.cpp:454] conv11 <- data
I0706 10:12:34.167268 54857 net.cpp:411] conv11 -> conv11
I0706 10:12:34.424634 54857 net.cpp:150] Setting up conv11
I0706 10:12:34.424684 54857 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0706 10:12:34.424693 54857 net.cpp:165] Memory required for data: 179201536
I0706 10:12:34.424721 54857 layer_factory.hpp:76] Creating layer relu11
I0706 10:12:34.424741 54857 net.cpp:106] Creating Layer relu11
I0706 10:12:34.424751 54857 net.cpp:454] relu11 <- conv11
I0706 10:12:34.424763 54857 net.cpp:397] relu11 -> conv11 (in-place)
I0706 10:12:34.424964 54857 net.cpp:150] Setting up relu11
I0706 10:12:34.424981 54857 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0706 10:12:34.424990 54857 net.cpp:165] Memory required for data: 343041536
I0706 10:12:34.424998 54857 layer_factory.hpp:76] Creating layer conv12
I0706 10:12:34.425019 54857 net.cpp:106] Creating Layer conv12
I0706 10:12:34.425027 54857 net.cpp:454] conv12 <- conv11
I0706 10:12:34.425038 54857 net.cpp:411] conv12 -> conv12
I0706 10:12:34.427706 54857 net.cpp:150] Setting up conv12
I0706 10:12:34.427729 54857 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0706 10:12:34.427738 54857 net.cpp:165] Memory required for data: 506881536
I0706 10:12:34.427752 54857 layer_factory.hpp:76] Creating layer relu12
I0706 10:12:34.427765 54857 net.cpp:106] Creating Layer relu12
I0706 10:12:34.427774 54857 net.cpp:454] relu12 <- conv12
I0706 10:12:34.427788 54857 net.cpp:397] relu12 -> conv12 (in-place)
I0706 10:12:34.428107 54857 net.cpp:150] Setting up relu12
I0706 10:12:34.428128 54857 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0706 10:12:34.428138 54857 net.cpp:165] Memory required for data: 670721536
I0706 10:12:34.428148 54857 layer_factory.hpp:76] Creating layer pool1
I0706 10:12:34.428160 54857 net.cpp:106] Creating Layer pool1
I0706 10:12:34.428169 54857 net.cpp:454] pool1 <- conv12
I0706 10:12:34.428180 54857 net.cpp:411] pool1 -> pool1
I0706 10:12:34.430027 54857 net.cpp:150] Setting up pool1
I0706 10:12:34.430053 54857 net.cpp:157] Top shape: 128 32 50 50 (10240000)
I0706 10:12:34.430063 54857 net.cpp:165] Memory required for data: 711681536
I0706 10:12:34.430073 54857 layer_factory.hpp:76] Creating layer conv21
I0706 10:12:34.430088 54857 net.cpp:106] Creating Layer conv21
I0706 10:12:34.430095 54857 net.cpp:454] conv21 <- pool1
I0706 10:12:34.430109 54857 net.cpp:411] conv21 -> conv21
I0706 10:12:34.434486 54857 net.cpp:150] Setting up conv21
I0706 10:12:34.434519 54857 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0706 10:12:34.434527 54857 net.cpp:165] Memory required for data: 793601536
I0706 10:12:34.434545 54857 layer_factory.hpp:76] Creating layer relu21
I0706 10:12:34.434561 54857 net.cpp:106] Creating Layer relu21
I0706 10:12:34.434569 54857 net.cpp:454] relu21 <- conv21
I0706 10:12:34.434581 54857 net.cpp:397] relu21 -> conv21 (in-place)
I0706 10:12:34.436050 54857 net.cpp:150] Setting up relu21
I0706 10:12:34.436071 54857 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0706 10:12:34.436116 54857 net.cpp:165] Memory required for data: 875521536
I0706 10:12:34.436134 54857 layer_factory.hpp:76] Creating layer conv22
I0706 10:12:34.436152 54857 net.cpp:106] Creating Layer conv22
I0706 10:12:34.436161 54857 net.cpp:454] conv22 <- conv21
I0706 10:12:34.436174 54857 net.cpp:411] conv22 -> conv22
I0706 10:12:34.443397 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0706 10:12:34.443620 54857 net.cpp:150] Setting up conv22
I0706 10:12:34.443639 54857 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0706 10:12:34.443655 54857 net.cpp:165] Memory required for data: 957441536
I0706 10:12:34.443667 54857 layer_factory.hpp:76] Creating layer relu22
I0706 10:12:34.443683 54857 net.cpp:106] Creating Layer relu22
I0706 10:12:34.443692 54857 net.cpp:454] relu22 <- conv22
I0706 10:12:34.443709 54857 net.cpp:397] relu22 -> conv22 (in-place)
I0706 10:12:34.446985 54857 net.cpp:150] Setting up relu22
I0706 10:12:34.447012 54857 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0706 10:12:34.447021 54857 net.cpp:165] Memory required for data: 1039361536
I0706 10:12:34.447031 54857 layer_factory.hpp:76] Creating layer pool2
I0706 10:12:34.447046 54857 net.cpp:106] Creating Layer pool2
I0706 10:12:34.447053 54857 net.cpp:454] pool2 <- conv22
I0706 10:12:34.447065 54857 net.cpp:411] pool2 -> pool2
I0706 10:12:34.449417 54857 net.cpp:150] Setting up pool2
I0706 10:12:34.449436 54857 net.cpp:157] Top shape: 128 64 25 25 (5120000)
I0706 10:12:34.449450 54857 net.cpp:165] Memory required for data: 1059841536
I0706 10:12:34.449458 54857 layer_factory.hpp:76] Creating layer conv31
I0706 10:12:34.449473 54857 net.cpp:106] Creating Layer conv31
I0706 10:12:34.449481 54857 net.cpp:454] conv31 <- pool2
I0706 10:12:34.449496 54857 net.cpp:411] conv31 -> conv31
I0706 10:12:34.455718 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0706 10:12:34.455757 54857 net.cpp:150] Setting up conv31
I0706 10:12:34.455770 54857 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0706 10:12:34.455780 54857 net.cpp:165] Memory required for data: 1090561536
I0706 10:12:34.455799 54857 layer_factory.hpp:76] Creating layer relu31
I0706 10:12:34.455811 54857 net.cpp:106] Creating Layer relu31
I0706 10:12:34.455828 54857 net.cpp:454] relu31 <- conv31
I0706 10:12:34.455840 54857 net.cpp:397] relu31 -> conv31 (in-place)
I0706 10:12:34.458672 54857 net.cpp:150] Setting up relu31
I0706 10:12:34.458691 54857 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0706 10:12:34.458703 54857 net.cpp:165] Memory required for data: 1121281536
I0706 10:12:34.458711 54857 layer_factory.hpp:76] Creating layer conv32
I0706 10:12:34.458729 54857 net.cpp:106] Creating Layer conv32
I0706 10:12:34.458739 54857 net.cpp:454] conv32 <- conv31
I0706 10:12:34.458751 54857 net.cpp:411] conv32 -> conv32
I0706 10:12:34.463695 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0706 10:12:34.463740 54857 net.cpp:150] Setting up conv32
I0706 10:12:34.463753 54857 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0706 10:12:34.463763 54857 net.cpp:165] Memory required for data: 1152001536
I0706 10:12:34.463775 54857 layer_factory.hpp:76] Creating layer relu32
I0706 10:12:34.463800 54857 net.cpp:106] Creating Layer relu32
I0706 10:12:34.463812 54857 net.cpp:454] relu32 <- conv32
I0706 10:12:34.463824 54857 net.cpp:397] relu32 -> conv32 (in-place)
I0706 10:12:34.464771 54857 net.cpp:150] Setting up relu32
I0706 10:12:34.464792 54857 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0706 10:12:34.464799 54857 net.cpp:165] Memory required for data: 1182721536
I0706 10:12:34.464809 54857 layer_factory.hpp:76] Creating layer pool3
I0706 10:12:34.464828 54857 net.cpp:106] Creating Layer pool3
I0706 10:12:34.464838 54857 net.cpp:454] pool3 <- conv32
I0706 10:12:34.464848 54857 net.cpp:411] pool3 -> pool3
I0706 10:12:34.465956 54857 net.cpp:150] Setting up pool3
I0706 10:12:34.465977 54857 net.cpp:157] Top shape: 128 96 13 13 (2076672)
I0706 10:12:34.465986 54857 net.cpp:165] Memory required for data: 1191028224
I0706 10:12:34.465994 54857 layer_factory.hpp:76] Creating layer conv41
I0706 10:12:34.466038 54857 net.cpp:106] Creating Layer conv41
I0706 10:12:34.466053 54857 net.cpp:454] conv41 <- pool3
I0706 10:12:34.466066 54857 net.cpp:411] conv41 -> conv41
I0706 10:12:34.473563 54857 net.cpp:150] Setting up conv41
I0706 10:12:34.473587 54857 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0706 10:12:34.473597 54857 net.cpp:165] Memory required for data: 1202103808
I0706 10:12:34.473609 54857 layer_factory.hpp:76] Creating layer relu41
I0706 10:12:34.473623 54857 net.cpp:106] Creating Layer relu41
I0706 10:12:34.473633 54857 net.cpp:454] relu41 <- conv41
I0706 10:12:34.473645 54857 net.cpp:397] relu41 -> conv41 (in-place)
I0706 10:12:34.474797 54857 net.cpp:150] Setting up relu41
I0706 10:12:34.474817 54857 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0706 10:12:34.474829 54857 net.cpp:165] Memory required for data: 1213179392
I0706 10:12:34.474838 54857 layer_factory.hpp:76] Creating layer conv42
I0706 10:12:34.474858 54857 net.cpp:106] Creating Layer conv42
I0706 10:12:34.474866 54857 net.cpp:454] conv42 <- conv41
I0706 10:12:34.474879 54857 net.cpp:411] conv42 -> conv42
I0706 10:12:34.483465 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0706 10:12:34.483513 54857 net.cpp:150] Setting up conv42
I0706 10:12:34.483528 54857 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0706 10:12:34.483537 54857 net.cpp:165] Memory required for data: 1224254976
I0706 10:12:34.483558 54857 layer_factory.hpp:76] Creating layer relu42
I0706 10:12:34.483572 54857 net.cpp:106] Creating Layer relu42
I0706 10:12:34.483580 54857 net.cpp:454] relu42 <- conv42
I0706 10:12:34.483592 54857 net.cpp:397] relu42 -> conv42 (in-place)
I0706 10:12:34.485769 54857 net.cpp:150] Setting up relu42
I0706 10:12:34.485786 54857 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0706 10:12:34.485802 54857 net.cpp:165] Memory required for data: 1235330560
I0706 10:12:34.485811 54857 layer_factory.hpp:76] Creating layer pool4
I0706 10:12:34.485823 54857 net.cpp:106] Creating Layer pool4
I0706 10:12:34.485831 54857 net.cpp:454] pool4 <- conv42
I0706 10:12:34.485844 54857 net.cpp:411] pool4 -> pool4
I0706 10:12:34.488209 54857 net.cpp:150] Setting up pool4
I0706 10:12:34.488229 54857 net.cpp:157] Top shape: 128 128 7 7 (802816)
I0706 10:12:34.488241 54857 net.cpp:165] Memory required for data: 1238541824
I0706 10:12:34.488250 54857 layer_factory.hpp:76] Creating layer conv51
I0706 10:12:34.488268 54857 net.cpp:106] Creating Layer conv51
I0706 10:12:34.488277 54857 net.cpp:454] conv51 <- pool4
I0706 10:12:34.488293 54857 net.cpp:411] conv51 -> conv51
I0706 10:12:34.494307 54857 net.cpp:150] Setting up conv51
I0706 10:12:34.494333 54857 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0706 10:12:34.494341 54857 net.cpp:165] Memory required for data: 1244964352
I0706 10:12:34.494359 54857 layer_factory.hpp:76] Creating layer relu51
I0706 10:12:34.494374 54857 net.cpp:106] Creating Layer relu51
I0706 10:12:34.494386 54857 net.cpp:454] relu51 <- conv51
I0706 10:12:34.494396 54857 net.cpp:397] relu51 -> conv51 (in-place)
I0706 10:12:34.497331 54857 net.cpp:150] Setting up relu51
I0706 10:12:34.497349 54857 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0706 10:12:34.497362 54857 net.cpp:165] Memory required for data: 1251386880
I0706 10:12:34.497371 54857 layer_factory.hpp:76] Creating layer conv52
I0706 10:12:34.497388 54857 net.cpp:106] Creating Layer conv52
I0706 10:12:34.497397 54857 net.cpp:454] conv52 <- conv51
I0706 10:12:34.497411 54857 net.cpp:411] conv52 -> conv52
I0706 10:12:34.509024 54857 net.cpp:150] Setting up conv52
I0706 10:12:34.509053 54857 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0706 10:12:34.509068 54857 net.cpp:165] Memory required for data: 1257809408
I0706 10:12:34.509084 54857 layer_factory.hpp:76] Creating layer relu52
I0706 10:12:34.509099 54857 net.cpp:106] Creating Layer relu52
I0706 10:12:34.509109 54857 net.cpp:454] relu52 <- conv52
I0706 10:12:34.509120 54857 net.cpp:397] relu52 -> conv52 (in-place)
I0706 10:12:34.510084 54857 net.cpp:150] Setting up relu52
I0706 10:12:34.510131 54857 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0706 10:12:34.510141 54857 net.cpp:165] Memory required for data: 1264231936
I0706 10:12:34.510150 54857 layer_factory.hpp:76] Creating layer conv53
I0706 10:12:34.510169 54857 net.cpp:106] Creating Layer conv53
I0706 10:12:34.510179 54857 net.cpp:454] conv53 <- conv52
I0706 10:12:34.510191 54857 net.cpp:411] conv53 -> conv53
I0706 10:12:34.544798 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0706 10:12:34.545039 54857 net.cpp:150] Setting up conv53
I0706 10:12:34.545066 54857 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0706 10:12:34.545075 54857 net.cpp:165] Memory required for data: 1264363008
I0706 10:12:34.545091 54857 layer_factory.hpp:76] Creating layer relu53
I0706 10:12:34.545109 54857 net.cpp:106] Creating Layer relu53
I0706 10:12:34.545120 54857 net.cpp:454] relu53 <- conv53
I0706 10:12:34.545147 54857 net.cpp:397] relu53 -> conv53 (in-place)
I0706 10:12:34.545876 54857 net.cpp:150] Setting up relu53
I0706 10:12:34.545895 54857 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0706 10:12:34.545909 54857 net.cpp:165] Memory required for data: 1264494080
I0706 10:12:34.545918 54857 layer_factory.hpp:76] Creating layer drop6
I0706 10:12:34.545940 54857 net.cpp:106] Creating Layer drop6
I0706 10:12:34.545953 54857 net.cpp:454] drop6 <- conv53
I0706 10:12:34.545963 54857 net.cpp:411] drop6 -> drop6
I0706 10:12:34.546025 54857 net.cpp:150] Setting up drop6
I0706 10:12:34.546038 54857 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0706 10:12:34.546048 54857 net.cpp:165] Memory required for data: 1264625152
I0706 10:12:34.546058 54857 layer_factory.hpp:76] Creating layer conv54
I0706 10:12:34.546083 54857 net.cpp:106] Creating Layer conv54
I0706 10:12:34.546098 54857 net.cpp:454] conv54 <- drop6
I0706 10:12:34.546113 54857 net.cpp:411] conv54 -> conv54
I0706 10:12:34.554951 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0706 10:12:34.555155 54857 net.cpp:150] Setting up conv54
I0706 10:12:34.555173 54857 net.cpp:157] Top shape: 128 2 1 1 (256)
I0706 10:12:34.555186 54857 net.cpp:165] Memory required for data: 1264626176
I0706 10:12:34.555198 54857 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0706 10:12:34.555214 54857 net.cpp:106] Creating Layer conv54_conv54_0_split
I0706 10:12:34.555223 54857 net.cpp:454] conv54_conv54_0_split <- conv54
I0706 10:12:34.555234 54857 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0706 10:12:34.555248 54857 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0706 10:12:34.555301 54857 net.cpp:150] Setting up conv54_conv54_0_split
I0706 10:12:34.555317 54857 net.cpp:157] Top shape: 128 2 1 1 (256)
I0706 10:12:34.555326 54857 net.cpp:157] Top shape: 128 2 1 1 (256)
I0706 10:12:34.555335 54857 net.cpp:165] Memory required for data: 1264628224
I0706 10:12:34.555346 54857 layer_factory.hpp:76] Creating layer accuracy
I0706 10:12:34.555366 54857 net.cpp:106] Creating Layer accuracy
I0706 10:12:34.555377 54857 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0706 10:12:34.555387 54857 net.cpp:454] accuracy <- label_data_1_split_0
I0706 10:12:34.555397 54857 net.cpp:411] accuracy -> accuracy
I0706 10:12:34.555415 54857 net.cpp:150] Setting up accuracy
I0706 10:12:34.555425 54857 net.cpp:157] Top shape: (1)
I0706 10:12:34.555436 54857 net.cpp:165] Memory required for data: 1264628228
I0706 10:12:34.555444 54857 layer_factory.hpp:76] Creating layer loss
I0706 10:12:34.555465 54857 net.cpp:106] Creating Layer loss
I0706 10:12:34.555482 54857 net.cpp:454] loss <- conv54_conv54_0_split_1
I0706 10:12:34.555491 54857 net.cpp:454] loss <- label_data_1_split_1
I0706 10:12:34.555501 54857 net.cpp:411] loss -> loss
I0706 10:12:34.555521 54857 layer_factory.hpp:76] Creating layer loss
I0706 10:12:34.556792 54857 net.cpp:150] Setting up loss
I0706 10:12:34.556809 54857 net.cpp:157] Top shape: (1)
I0706 10:12:34.556818 54857 net.cpp:160]     with loss weight 1
I0706 10:12:34.556841 54857 net.cpp:165] Memory required for data: 1264628232
I0706 10:12:34.556885 54857 net.cpp:226] loss needs backward computation.
I0706 10:12:34.556895 54857 net.cpp:228] accuracy does not need backward computation.
I0706 10:12:34.556903 54857 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0706 10:12:34.556911 54857 net.cpp:226] conv54 needs backward computation.
I0706 10:12:34.556921 54857 net.cpp:226] drop6 needs backward computation.
I0706 10:12:34.556927 54857 net.cpp:226] relu53 needs backward computation.
I0706 10:12:34.556934 54857 net.cpp:226] conv53 needs backward computation.
I0706 10:12:34.556942 54857 net.cpp:226] relu52 needs backward computation.
I0706 10:12:34.556949 54857 net.cpp:226] conv52 needs backward computation.
I0706 10:12:34.556957 54857 net.cpp:226] relu51 needs backward computation.
I0706 10:12:34.556964 54857 net.cpp:226] conv51 needs backward computation.
I0706 10:12:34.556972 54857 net.cpp:226] pool4 needs backward computation.
I0706 10:12:34.556980 54857 net.cpp:226] relu42 needs backward computation.
I0706 10:12:34.556988 54857 net.cpp:226] conv42 needs backward computation.
I0706 10:12:34.556995 54857 net.cpp:226] relu41 needs backward computation.
I0706 10:12:34.557003 54857 net.cpp:226] conv41 needs backward computation.
I0706 10:12:34.557011 54857 net.cpp:226] pool3 needs backward computation.
I0706 10:12:34.557018 54857 net.cpp:226] relu32 needs backward computation.
I0706 10:12:34.557027 54857 net.cpp:226] conv32 needs backward computation.
I0706 10:12:34.557035 54857 net.cpp:226] relu31 needs backward computation.
I0706 10:12:34.557042 54857 net.cpp:226] conv31 needs backward computation.
I0706 10:12:34.557049 54857 net.cpp:226] pool2 needs backward computation.
I0706 10:12:34.557059 54857 net.cpp:226] relu22 needs backward computation.
I0706 10:12:34.557066 54857 net.cpp:226] conv22 needs backward computation.
I0706 10:12:34.557073 54857 net.cpp:226] relu21 needs backward computation.
I0706 10:12:34.557080 54857 net.cpp:226] conv21 needs backward computation.
I0706 10:12:34.557088 54857 net.cpp:226] pool1 needs backward computation.
I0706 10:12:34.557096 54857 net.cpp:226] relu12 needs backward computation.
I0706 10:12:34.557103 54857 net.cpp:226] conv12 needs backward computation.
I0706 10:12:34.557111 54857 net.cpp:226] relu11 needs backward computation.
I0706 10:12:34.557118 54857 net.cpp:226] conv11 needs backward computation.
I0706 10:12:34.557126 54857 net.cpp:228] label_data_1_split does not need backward computation.
I0706 10:12:34.557134 54857 net.cpp:228] data does not need backward computation.
I0706 10:12:34.557142 54857 net.cpp:270] This network produces output accuracy
I0706 10:12:34.557149 54857 net.cpp:270] This network produces output loss
I0706 10:12:34.557176 54857 net.cpp:283] Network initialization done.
I0706 10:12:34.557927 54857 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0706 10:12:34.558048 54857 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0706 10:12:34.558080 54857 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt.full
I0706 10:12:34.558131 54857 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0706 10:12:34.558321 54857 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-val-L0.lst"
    batch_size: 100
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0706 10:12:34.559924 54857 layer_factory.hpp:76] Creating layer data
I0706 10:12:34.559953 54857 net.cpp:106] Creating Layer data
I0706 10:12:34.559962 54857 net.cpp:411] data -> data
I0706 10:12:34.559978 54857 net.cpp:411] data -> label
I0706 10:12:34.559991 54857 image_data_layer.cpp:36] Opening file ../lists/roi-val-L0.lst
I0706 10:12:34.572377 54857 image_data_layer.cpp:46] Shuffling data
I0706 10:12:34.574529 54857 image_data_layer.cpp:51] A total of 23520 images.
I0706 10:12:34.577179 54857 image_data_layer.cpp:78] output data size: 100,3,100,100
I0706 10:12:34.627202 54857 net.cpp:150] Setting up data
I0706 10:12:34.627259 54857 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0706 10:12:34.627271 54857 net.cpp:157] Top shape: 100 (100)
I0706 10:12:34.627280 54857 net.cpp:165] Memory required for data: 12000400
I0706 10:12:34.627293 54857 layer_factory.hpp:76] Creating layer label_data_1_split
I0706 10:12:34.627313 54857 net.cpp:106] Creating Layer label_data_1_split
I0706 10:12:34.627329 54857 net.cpp:454] label_data_1_split <- label
I0706 10:12:34.627342 54857 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0706 10:12:34.627358 54857 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0706 10:12:34.627427 54857 net.cpp:150] Setting up label_data_1_split
I0706 10:12:34.627449 54857 net.cpp:157] Top shape: 100 (100)
I0706 10:12:34.627465 54857 net.cpp:157] Top shape: 100 (100)
I0706 10:12:34.627472 54857 net.cpp:165] Memory required for data: 12001200
I0706 10:12:34.627483 54857 layer_factory.hpp:76] Creating layer conv11
I0706 10:12:34.627501 54857 net.cpp:106] Creating Layer conv11
I0706 10:12:34.627509 54857 net.cpp:454] conv11 <- data
I0706 10:12:34.627519 54857 net.cpp:411] conv11 -> conv11
I0706 10:12:34.632169 54857 net.cpp:150] Setting up conv11
I0706 10:12:34.632192 54857 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0706 10:12:34.632201 54857 net.cpp:165] Memory required for data: 140001200
I0706 10:12:34.632217 54857 layer_factory.hpp:76] Creating layer relu11
I0706 10:12:34.632231 54857 net.cpp:106] Creating Layer relu11
I0706 10:12:34.632241 54857 net.cpp:454] relu11 <- conv11
I0706 10:12:34.632251 54857 net.cpp:397] relu11 -> conv11 (in-place)
I0706 10:12:34.637109 54857 net.cpp:150] Setting up relu11
I0706 10:12:34.637166 54857 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0706 10:12:34.637174 54857 net.cpp:165] Memory required for data: 268001200
I0706 10:12:34.637183 54857 layer_factory.hpp:76] Creating layer conv12
I0706 10:12:34.637200 54857 net.cpp:106] Creating Layer conv12
I0706 10:12:34.637210 54857 net.cpp:454] conv12 <- conv11
I0706 10:12:34.637223 54857 net.cpp:411] conv12 -> conv12
I0706 10:12:34.641047 54857 net.cpp:150] Setting up conv12
I0706 10:12:34.641068 54857 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0706 10:12:34.641079 54857 net.cpp:165] Memory required for data: 396001200
I0706 10:12:34.641094 54857 layer_factory.hpp:76] Creating layer relu12
I0706 10:12:34.641106 54857 net.cpp:106] Creating Layer relu12
I0706 10:12:34.641114 54857 net.cpp:454] relu12 <- conv12
I0706 10:12:34.641124 54857 net.cpp:397] relu12 -> conv12 (in-place)
I0706 10:12:34.642314 54857 net.cpp:150] Setting up relu12
I0706 10:12:34.642334 54857 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0706 10:12:34.642349 54857 net.cpp:165] Memory required for data: 524001200
I0706 10:12:34.642359 54857 layer_factory.hpp:76] Creating layer pool1
I0706 10:12:34.642370 54857 net.cpp:106] Creating Layer pool1
I0706 10:12:34.642381 54857 net.cpp:454] pool1 <- conv12
I0706 10:12:34.642395 54857 net.cpp:411] pool1 -> pool1
I0706 10:12:34.644006 54857 net.cpp:150] Setting up pool1
I0706 10:12:34.644023 54857 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0706 10:12:34.644038 54857 net.cpp:165] Memory required for data: 556001200
I0706 10:12:34.644047 54857 layer_factory.hpp:76] Creating layer conv21
I0706 10:12:34.644062 54857 net.cpp:106] Creating Layer conv21
I0706 10:12:34.644071 54857 net.cpp:454] conv21 <- pool1
I0706 10:12:34.644088 54857 net.cpp:411] conv21 -> conv21
I0706 10:12:34.650027 54857 net.cpp:150] Setting up conv21
I0706 10:12:34.650050 54857 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0706 10:12:34.650059 54857 net.cpp:165] Memory required for data: 620001200
I0706 10:12:34.650076 54857 layer_factory.hpp:76] Creating layer relu21
I0706 10:12:34.650090 54857 net.cpp:106] Creating Layer relu21
I0706 10:12:34.650099 54857 net.cpp:454] relu21 <- conv21
I0706 10:12:34.650111 54857 net.cpp:397] relu21 -> conv21 (in-place)
I0706 10:12:34.652209 54857 net.cpp:150] Setting up relu21
I0706 10:12:34.652230 54857 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0706 10:12:34.652245 54857 net.cpp:165] Memory required for data: 684001200
I0706 10:12:34.652253 54857 layer_factory.hpp:76] Creating layer conv22
I0706 10:12:34.652269 54857 net.cpp:106] Creating Layer conv22
I0706 10:12:34.652278 54857 net.cpp:454] conv22 <- conv21
I0706 10:12:34.652289 54857 net.cpp:411] conv22 -> conv22
I0706 10:12:34.667984 54857 net.cpp:150] Setting up conv22
I0706 10:12:34.668020 54857 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0706 10:12:34.668030 54857 net.cpp:165] Memory required for data: 748001200
I0706 10:12:34.668046 54857 layer_factory.hpp:76] Creating layer relu22
I0706 10:12:34.668058 54857 net.cpp:106] Creating Layer relu22
I0706 10:12:34.668067 54857 net.cpp:454] relu22 <- conv22
I0706 10:12:34.668077 54857 net.cpp:397] relu22 -> conv22 (in-place)
I0706 10:12:34.670897 54857 net.cpp:150] Setting up relu22
I0706 10:12:34.670914 54857 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0706 10:12:34.670923 54857 net.cpp:165] Memory required for data: 812001200
I0706 10:12:34.670933 54857 layer_factory.hpp:76] Creating layer pool2
I0706 10:12:34.670945 54857 net.cpp:106] Creating Layer pool2
I0706 10:12:34.670954 54857 net.cpp:454] pool2 <- conv22
I0706 10:12:34.670965 54857 net.cpp:411] pool2 -> pool2
I0706 10:12:34.672296 54857 net.cpp:150] Setting up pool2
I0706 10:12:34.672317 54857 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0706 10:12:34.672329 54857 net.cpp:165] Memory required for data: 828001200
I0706 10:12:34.672338 54857 layer_factory.hpp:76] Creating layer conv31
I0706 10:12:34.672355 54857 net.cpp:106] Creating Layer conv31
I0706 10:12:34.672363 54857 net.cpp:454] conv31 <- pool2
I0706 10:12:34.672376 54857 net.cpp:411] conv31 -> conv31
I0706 10:12:34.678266 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0706 10:12:34.678310 54857 net.cpp:150] Setting up conv31
I0706 10:12:34.678323 54857 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0706 10:12:34.678334 54857 net.cpp:165] Memory required for data: 852001200
I0706 10:12:34.678354 54857 layer_factory.hpp:76] Creating layer relu31
I0706 10:12:34.678374 54857 net.cpp:106] Creating Layer relu31
I0706 10:12:34.678383 54857 net.cpp:454] relu31 <- conv31
I0706 10:12:34.678395 54857 net.cpp:397] relu31 -> conv31 (in-place)
I0706 10:12:34.679713 54857 net.cpp:150] Setting up relu31
I0706 10:12:34.679733 54857 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0706 10:12:34.679744 54857 net.cpp:165] Memory required for data: 876001200
I0706 10:12:34.679754 54857 layer_factory.hpp:76] Creating layer conv32
I0706 10:12:34.679771 54857 net.cpp:106] Creating Layer conv32
I0706 10:12:34.679780 54857 net.cpp:454] conv32 <- conv31
I0706 10:12:34.679795 54857 net.cpp:411] conv32 -> conv32
I0706 10:12:34.687479 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0706 10:12:34.687518 54857 net.cpp:150] Setting up conv32
I0706 10:12:34.687530 54857 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0706 10:12:34.687542 54857 net.cpp:165] Memory required for data: 900001200
I0706 10:12:34.687553 54857 layer_factory.hpp:76] Creating layer relu32
I0706 10:12:34.687575 54857 net.cpp:106] Creating Layer relu32
I0706 10:12:34.687584 54857 net.cpp:454] relu32 <- conv32
I0706 10:12:34.687595 54857 net.cpp:397] relu32 -> conv32 (in-place)
I0706 10:12:34.690182 54857 net.cpp:150] Setting up relu32
I0706 10:12:34.690201 54857 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0706 10:12:34.690208 54857 net.cpp:165] Memory required for data: 924001200
I0706 10:12:34.690217 54857 layer_factory.hpp:76] Creating layer pool3
I0706 10:12:34.690233 54857 net.cpp:106] Creating Layer pool3
I0706 10:12:34.690243 54857 net.cpp:454] pool3 <- conv32
I0706 10:12:34.690253 54857 net.cpp:411] pool3 -> pool3
I0706 10:12:34.692739 54857 net.cpp:150] Setting up pool3
I0706 10:12:34.692759 54857 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I0706 10:12:34.692767 54857 net.cpp:165] Memory required for data: 930490800
I0706 10:12:34.692776 54857 layer_factory.hpp:76] Creating layer conv41
I0706 10:12:34.692792 54857 net.cpp:106] Creating Layer conv41
I0706 10:12:34.692800 54857 net.cpp:454] conv41 <- pool3
I0706 10:12:34.692814 54857 net.cpp:411] conv41 -> conv41
I0706 10:12:34.698462 54857 net.cpp:150] Setting up conv41
I0706 10:12:34.698485 54857 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0706 10:12:34.698495 54857 net.cpp:165] Memory required for data: 939143600
I0706 10:12:34.698508 54857 layer_factory.hpp:76] Creating layer relu41
I0706 10:12:34.698523 54857 net.cpp:106] Creating Layer relu41
I0706 10:12:34.698532 54857 net.cpp:454] relu41 <- conv41
I0706 10:12:34.698544 54857 net.cpp:397] relu41 -> conv41 (in-place)
I0706 10:12:34.700065 54857 net.cpp:150] Setting up relu41
I0706 10:12:34.700083 54857 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0706 10:12:34.700090 54857 net.cpp:165] Memory required for data: 947796400
I0706 10:12:34.700099 54857 layer_factory.hpp:76] Creating layer conv42
I0706 10:12:34.700131 54857 net.cpp:106] Creating Layer conv42
I0706 10:12:34.700142 54857 net.cpp:454] conv42 <- conv41
I0706 10:12:34.700155 54857 net.cpp:411] conv42 -> conv42
I0706 10:12:34.705943 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0706 10:12:34.705991 54857 net.cpp:150] Setting up conv42
I0706 10:12:34.706003 54857 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0706 10:12:34.706014 54857 net.cpp:165] Memory required for data: 956449200
I0706 10:12:34.706032 54857 layer_factory.hpp:76] Creating layer relu42
I0706 10:12:34.706048 54857 net.cpp:106] Creating Layer relu42
I0706 10:12:34.706063 54857 net.cpp:454] relu42 <- conv42
I0706 10:12:34.706075 54857 net.cpp:397] relu42 -> conv42 (in-place)
I0706 10:12:34.707746 54857 net.cpp:150] Setting up relu42
I0706 10:12:34.707792 54857 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0706 10:12:34.707801 54857 net.cpp:165] Memory required for data: 965102000
I0706 10:12:34.707810 54857 layer_factory.hpp:76] Creating layer pool4
I0706 10:12:34.707823 54857 net.cpp:106] Creating Layer pool4
I0706 10:12:34.707830 54857 net.cpp:454] pool4 <- conv42
I0706 10:12:34.707839 54857 net.cpp:411] pool4 -> pool4
I0706 10:12:34.709885 54857 net.cpp:150] Setting up pool4
I0706 10:12:34.709903 54857 net.cpp:157] Top shape: 100 128 7 7 (627200)
I0706 10:12:34.709911 54857 net.cpp:165] Memory required for data: 967610800
I0706 10:12:34.709920 54857 layer_factory.hpp:76] Creating layer conv51
I0706 10:12:34.709935 54857 net.cpp:106] Creating Layer conv51
I0706 10:12:34.709945 54857 net.cpp:454] conv51 <- pool4
I0706 10:12:34.709957 54857 net.cpp:411] conv51 -> conv51
I0706 10:12:34.718786 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0706 10:12:34.718827 54857 net.cpp:150] Setting up conv51
I0706 10:12:34.718847 54857 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0706 10:12:34.718855 54857 net.cpp:165] Memory required for data: 972628400
I0706 10:12:34.718893 54857 layer_factory.hpp:76] Creating layer relu51
I0706 10:12:34.718909 54857 net.cpp:106] Creating Layer relu51
I0706 10:12:34.718919 54857 net.cpp:454] relu51 <- conv51
I0706 10:12:34.718930 54857 net.cpp:397] relu51 -> conv51 (in-place)
I0706 10:12:34.720013 54857 net.cpp:150] Setting up relu51
I0706 10:12:34.720031 54857 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0706 10:12:34.720038 54857 net.cpp:165] Memory required for data: 977646000
I0706 10:12:34.720046 54857 layer_factory.hpp:76] Creating layer conv52
I0706 10:12:34.720067 54857 net.cpp:106] Creating Layer conv52
I0706 10:12:34.720077 54857 net.cpp:454] conv52 <- conv51
I0706 10:12:34.720087 54857 net.cpp:411] conv52 -> conv52
I0706 10:12:34.776195 54857 net.cpp:150] Setting up conv52
I0706 10:12:34.776237 54857 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0706 10:12:34.776247 54857 net.cpp:165] Memory required for data: 982663600
I0706 10:12:34.776262 54857 layer_factory.hpp:76] Creating layer relu52
I0706 10:12:34.776278 54857 net.cpp:106] Creating Layer relu52
I0706 10:12:34.776290 54857 net.cpp:454] relu52 <- conv52
I0706 10:12:34.776301 54857 net.cpp:397] relu52 -> conv52 (in-place)
I0706 10:12:34.778308 54857 net.cpp:150] Setting up relu52
I0706 10:12:34.778329 54857 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0706 10:12:34.778338 54857 net.cpp:165] Memory required for data: 987681200
I0706 10:12:34.778347 54857 layer_factory.hpp:76] Creating layer conv53
I0706 10:12:34.778365 54857 net.cpp:106] Creating Layer conv53
I0706 10:12:34.778374 54857 net.cpp:454] conv53 <- conv52
I0706 10:12:34.778385 54857 net.cpp:411] conv53 -> conv53
I0706 10:12:34.814483 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0706 10:12:34.814544 54857 net.cpp:150] Setting up conv53
I0706 10:12:34.814559 54857 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0706 10:12:34.814569 54857 net.cpp:165] Memory required for data: 987783600
I0706 10:12:34.814590 54857 layer_factory.hpp:76] Creating layer relu53
I0706 10:12:34.814609 54857 net.cpp:106] Creating Layer relu53
I0706 10:12:34.814623 54857 net.cpp:454] relu53 <- conv53
I0706 10:12:34.814638 54857 net.cpp:397] relu53 -> conv53 (in-place)
I0706 10:12:34.815589 54857 net.cpp:150] Setting up relu53
I0706 10:12:34.815606 54857 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0706 10:12:34.815615 54857 net.cpp:165] Memory required for data: 987886000
I0706 10:12:34.815623 54857 layer_factory.hpp:76] Creating layer drop6
I0706 10:12:34.815641 54857 net.cpp:106] Creating Layer drop6
I0706 10:12:34.815650 54857 net.cpp:454] drop6 <- conv53
I0706 10:12:34.815660 54857 net.cpp:411] drop6 -> drop6
I0706 10:12:34.815716 54857 net.cpp:150] Setting up drop6
I0706 10:12:34.815731 54857 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0706 10:12:34.815739 54857 net.cpp:165] Memory required for data: 987988400
I0706 10:12:34.815747 54857 layer_factory.hpp:76] Creating layer conv54
I0706 10:12:34.815804 54857 net.cpp:106] Creating Layer conv54
I0706 10:12:34.815815 54857 net.cpp:454] conv54 <- drop6
I0706 10:12:34.815829 54857 net.cpp:411] conv54 -> conv54
I0706 10:12:34.823977 54857 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0706 10:12:34.824015 54857 net.cpp:150] Setting up conv54
I0706 10:12:34.824028 54857 net.cpp:157] Top shape: 100 2 1 1 (200)
I0706 10:12:34.824036 54857 net.cpp:165] Memory required for data: 987989200
I0706 10:12:34.824048 54857 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0706 10:12:34.824064 54857 net.cpp:106] Creating Layer conv54_conv54_0_split
I0706 10:12:34.824084 54857 net.cpp:454] conv54_conv54_0_split <- conv54
I0706 10:12:34.824095 54857 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0706 10:12:34.824106 54857 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0706 10:12:34.824157 54857 net.cpp:150] Setting up conv54_conv54_0_split
I0706 10:12:34.824172 54857 net.cpp:157] Top shape: 100 2 1 1 (200)
I0706 10:12:34.824182 54857 net.cpp:157] Top shape: 100 2 1 1 (200)
I0706 10:12:34.824189 54857 net.cpp:165] Memory required for data: 987990800
I0706 10:12:34.824198 54857 layer_factory.hpp:76] Creating layer accuracy
I0706 10:12:34.824218 54857 net.cpp:106] Creating Layer accuracy
I0706 10:12:34.824229 54857 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0706 10:12:34.824237 54857 net.cpp:454] accuracy <- label_data_1_split_0
I0706 10:12:34.824254 54857 net.cpp:411] accuracy -> accuracy
I0706 10:12:34.824266 54857 net.cpp:150] Setting up accuracy
I0706 10:12:34.824276 54857 net.cpp:157] Top shape: (1)
I0706 10:12:34.824285 54857 net.cpp:165] Memory required for data: 987990804
I0706 10:12:34.824293 54857 layer_factory.hpp:76] Creating layer loss
I0706 10:12:34.824311 54857 net.cpp:106] Creating Layer loss
I0706 10:12:34.824321 54857 net.cpp:454] loss <- conv54_conv54_0_split_1
I0706 10:12:34.824329 54857 net.cpp:454] loss <- label_data_1_split_1
I0706 10:12:34.824342 54857 net.cpp:411] loss -> loss
I0706 10:12:34.824355 54857 layer_factory.hpp:76] Creating layer loss
I0706 10:12:34.825299 54857 net.cpp:150] Setting up loss
I0706 10:12:34.825319 54857 net.cpp:157] Top shape: (1)
I0706 10:12:34.825327 54857 net.cpp:160]     with loss weight 1
I0706 10:12:34.825341 54857 net.cpp:165] Memory required for data: 987990808
I0706 10:12:34.825350 54857 net.cpp:226] loss needs backward computation.
I0706 10:12:34.825358 54857 net.cpp:228] accuracy does not need backward computation.
I0706 10:12:34.825367 54857 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0706 10:12:34.825376 54857 net.cpp:226] conv54 needs backward computation.
I0706 10:12:34.825384 54857 net.cpp:226] drop6 needs backward computation.
I0706 10:12:34.825392 54857 net.cpp:226] relu53 needs backward computation.
I0706 10:12:34.825399 54857 net.cpp:226] conv53 needs backward computation.
I0706 10:12:34.825407 54857 net.cpp:226] relu52 needs backward computation.
I0706 10:12:34.825415 54857 net.cpp:226] conv52 needs backward computation.
I0706 10:12:34.825423 54857 net.cpp:226] relu51 needs backward computation.
I0706 10:12:34.825430 54857 net.cpp:226] conv51 needs backward computation.
I0706 10:12:34.825439 54857 net.cpp:226] pool4 needs backward computation.
I0706 10:12:34.825446 54857 net.cpp:226] relu42 needs backward computation.
I0706 10:12:34.825454 54857 net.cpp:226] conv42 needs backward computation.
I0706 10:12:34.825462 54857 net.cpp:226] relu41 needs backward computation.
I0706 10:12:34.825470 54857 net.cpp:226] conv41 needs backward computation.
I0706 10:12:34.825479 54857 net.cpp:226] pool3 needs backward computation.
I0706 10:12:34.825486 54857 net.cpp:226] relu32 needs backward computation.
I0706 10:12:34.825495 54857 net.cpp:226] conv32 needs backward computation.
I0706 10:12:34.825501 54857 net.cpp:226] relu31 needs backward computation.
I0706 10:12:34.825511 54857 net.cpp:226] conv31 needs backward computation.
I0706 10:12:34.825518 54857 net.cpp:226] pool2 needs backward computation.
I0706 10:12:34.825541 54857 net.cpp:226] relu22 needs backward computation.
I0706 10:12:34.825556 54857 net.cpp:226] conv22 needs backward computation.
I0706 10:12:34.825564 54857 net.cpp:226] relu21 needs backward computation.
I0706 10:12:34.825572 54857 net.cpp:226] conv21 needs backward computation.
I0706 10:12:34.825582 54857 net.cpp:226] pool1 needs backward computation.
I0706 10:12:34.825589 54857 net.cpp:226] relu12 needs backward computation.
I0706 10:12:34.825597 54857 net.cpp:226] conv12 needs backward computation.
I0706 10:12:34.825605 54857 net.cpp:226] relu11 needs backward computation.
I0706 10:12:34.825613 54857 net.cpp:226] conv11 needs backward computation.
I0706 10:12:34.825621 54857 net.cpp:228] label_data_1_split does not need backward computation.
I0706 10:12:34.825630 54857 net.cpp:228] data does not need backward computation.
I0706 10:12:34.825637 54857 net.cpp:270] This network produces output accuracy
I0706 10:12:34.825645 54857 net.cpp:270] This network produces output loss
I0706 10:12:34.825673 54857 net.cpp:283] Network initialization done.
I0706 10:12:34.825856 54857 solver.cpp:59] Solver scaffolding done.
I0706 10:12:34.826747 54857 caffe.cpp:202] Resuming from models/cnn10_iter_180765.solverstate
I0706 10:12:34.919580 54857 sgd_solver.cpp:314] SGDSolver: restoring history
I0706 10:12:34.940115 54857 caffe.cpp:212] Starting Optimization
I0706 10:12:34.940177 54857 solver.cpp:287] Solving FaceNN
I0706 10:12:34.940188 54857 solver.cpp:288] Learning Rate Policy: step
I0706 10:12:36.442102 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 10:13:11.552464 54857 solver.cpp:236] Iteration 180800, loss = 0.777724
I0706 10:13:11.552609 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 10:13:11.552628 54857 solver.cpp:252]     Train net output #1: loss = 0.953875 (* 1 = 0.953875 loss)
I0706 10:13:11.552644 54857 sgd_solver.cpp:106] Iteration 180800, lr = 5e-06
I0706 10:14:54.826669 54857 solver.cpp:236] Iteration 180900, loss = 0.724174
I0706 10:14:54.826848 54857 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0706 10:14:54.826889 54857 solver.cpp:252]     Train net output #1: loss = 0.867757 (* 1 = 0.867757 loss)
I0706 10:14:54.826903 54857 sgd_solver.cpp:106] Iteration 180900, lr = 5e-06
I0706 10:16:37.022775 54857 solver.cpp:340] Iteration 181000, Testing net (#0)
I0706 10:17:09.174881 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7333
I0706 10:17:09.175079 54857 solver.cpp:408]     Test net output #1: loss = 0.661662 (* 1 = 0.661662 loss)
I0706 10:17:09.391084 54857 solver.cpp:236] Iteration 181000, loss = 0.694261
I0706 10:17:09.391147 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 10:17:09.391165 54857 solver.cpp:252]     Train net output #1: loss = 0.654715 (* 1 = 0.654715 loss)
I0706 10:17:09.391181 54857 sgd_solver.cpp:106] Iteration 181000, lr = 5e-06
I0706 10:18:52.476234 54857 solver.cpp:236] Iteration 181100, loss = 0.674715
I0706 10:18:52.476387 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 10:18:52.476439 54857 solver.cpp:252]     Train net output #1: loss = 0.5944 (* 1 = 0.5944 loss)
I0706 10:18:52.476454 54857 sgd_solver.cpp:106] Iteration 181100, lr = 5e-06
I0706 10:20:35.531615 54857 solver.cpp:236] Iteration 181200, loss = 0.643347
I0706 10:20:35.531780 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 10:20:35.531815 54857 solver.cpp:252]     Train net output #1: loss = 0.582841 (* 1 = 0.582841 loss)
I0706 10:20:35.531829 54857 sgd_solver.cpp:106] Iteration 181200, lr = 5e-06
I0706 10:21:25.904045 54857 solver.cpp:340] Iteration 181250, Testing net (#0)
I0706 10:21:58.385085 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7347
I0706 10:21:58.385248 54857 solver.cpp:408]     Test net output #1: loss = 0.644955 (* 1 = 0.644955 loss)
I0706 10:22:50.222494 54857 solver.cpp:236] Iteration 181300, loss = 0.638595
I0706 10:22:50.222687 54857 solver.cpp:252]     Train net output #0: accuracy = 0.695312
I0706 10:22:50.222718 54857 solver.cpp:252]     Train net output #1: loss = 0.678857 (* 1 = 0.678857 loss)
I0706 10:22:50.222733 54857 sgd_solver.cpp:106] Iteration 181300, lr = 5e-06
I0706 10:24:33.415076 54857 solver.cpp:236] Iteration 181400, loss = 0.624434
I0706 10:24:33.415204 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 10:24:33.415235 54857 solver.cpp:252]     Train net output #1: loss = 0.612191 (* 1 = 0.612191 loss)
I0706 10:24:33.415261 54857 sgd_solver.cpp:106] Iteration 181400, lr = 5e-06
I0706 10:26:15.357581 54857 solver.cpp:340] Iteration 181500, Testing net (#0)
I0706 10:26:45.946852 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7392
I0706 10:26:45.946971 54857 solver.cpp:408]     Test net output #1: loss = 0.600344 (* 1 = 0.600344 loss)
I0706 10:26:46.197681 54857 solver.cpp:236] Iteration 181500, loss = 0.626416
I0706 10:26:46.197752 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 10:26:46.197772 54857 solver.cpp:252]     Train net output #1: loss = 0.594848 (* 1 = 0.594848 loss)
I0706 10:26:46.197788 54857 sgd_solver.cpp:106] Iteration 181500, lr = 5e-06
I0706 10:28:29.654942 54857 solver.cpp:236] Iteration 181600, loss = 0.590254
I0706 10:28:29.655035 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 10:28:29.655050 54857 solver.cpp:252]     Train net output #1: loss = 0.638782 (* 1 = 0.638782 loss)
I0706 10:28:29.655076 54857 sgd_solver.cpp:106] Iteration 181600, lr = 5e-06
I0706 10:30:12.921149 54857 solver.cpp:236] Iteration 181700, loss = 0.597702
I0706 10:30:12.921267 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0706 10:30:12.921298 54857 solver.cpp:252]     Train net output #1: loss = 0.525852 (* 1 = 0.525852 loss)
I0706 10:30:12.921326 54857 sgd_solver.cpp:106] Iteration 181700, lr = 5e-06
I0706 10:31:03.342430 54857 solver.cpp:340] Iteration 181750, Testing net (#0)
I0706 10:31:35.353101 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7402
I0706 10:31:35.353283 54857 solver.cpp:408]     Test net output #1: loss = 0.585924 (* 1 = 0.585924 loss)
I0706 10:32:27.083343 54857 solver.cpp:236] Iteration 181800, loss = 0.613923
I0706 10:32:27.083474 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 10:32:27.083505 54857 solver.cpp:252]     Train net output #1: loss = 0.460615 (* 1 = 0.460615 loss)
I0706 10:32:27.083516 54857 sgd_solver.cpp:106] Iteration 181800, lr = 5e-06
I0706 10:34:10.207938 54857 solver.cpp:236] Iteration 181900, loss = 0.566349
I0706 10:34:10.216527 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 10:34:10.216555 54857 solver.cpp:252]     Train net output #1: loss = 0.631877 (* 1 = 0.631877 loss)
I0706 10:34:10.216563 54857 sgd_solver.cpp:106] Iteration 181900, lr = 5e-06
I0706 10:35:52.118185 54857 solver.cpp:340] Iteration 182000, Testing net (#0)
I0706 10:36:23.444115 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7372
I0706 10:36:23.444239 54857 solver.cpp:408]     Test net output #1: loss = 0.567158 (* 1 = 0.567158 loss)
I0706 10:36:23.741921 54857 solver.cpp:236] Iteration 182000, loss = 0.592733
I0706 10:36:23.741961 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 10:36:23.741976 54857 solver.cpp:252]     Train net output #1: loss = 0.584713 (* 1 = 0.584713 loss)
I0706 10:36:23.741988 54857 sgd_solver.cpp:106] Iteration 182000, lr = 5e-06
I0706 10:38:07.106729 54857 solver.cpp:236] Iteration 182100, loss = 0.566885
I0706 10:38:07.106946 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 10:38:07.106967 54857 solver.cpp:252]     Train net output #1: loss = 0.503042 (* 1 = 0.503042 loss)
I0706 10:38:07.106987 54857 sgd_solver.cpp:106] Iteration 182100, lr = 5e-06
I0706 10:39:54.359530 54857 solver.cpp:236] Iteration 182200, loss = 0.570682
I0706 10:39:54.359680 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 10:39:54.359722 54857 solver.cpp:252]     Train net output #1: loss = 0.486274 (* 1 = 0.486274 loss)
I0706 10:39:54.359735 54857 sgd_solver.cpp:106] Iteration 182200, lr = 5e-06
I0706 10:40:49.054230 54857 solver.cpp:340] Iteration 182250, Testing net (#0)
I0706 10:41:30.928541 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7491
I0706 10:41:30.928694 54857 solver.cpp:408]     Test net output #1: loss = 0.548768 (* 1 = 0.548768 loss)
I0706 10:42:33.213348 54857 solver.cpp:236] Iteration 182300, loss = 0.554368
I0706 10:42:33.213465 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 10:42:33.213485 54857 solver.cpp:252]     Train net output #1: loss = 0.508586 (* 1 = 0.508586 loss)
I0706 10:42:33.213510 54857 sgd_solver.cpp:106] Iteration 182300, lr = 5e-06
I0706 10:44:43.325155 54857 solver.cpp:236] Iteration 182400, loss = 0.549093
I0706 10:44:43.325291 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 10:44:43.325333 54857 solver.cpp:252]     Train net output #1: loss = 0.585161 (* 1 = 0.585161 loss)
I0706 10:44:43.325364 54857 sgd_solver.cpp:106] Iteration 182400, lr = 5e-06
I0706 10:46:29.629690 54857 solver.cpp:340] Iteration 182500, Testing net (#0)
I0706 10:47:28.199668 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7487
I0706 10:47:28.199831 54857 solver.cpp:408]     Test net output #1: loss = 0.542611 (* 1 = 0.542611 loss)
I0706 10:47:28.499868 54857 solver.cpp:236] Iteration 182500, loss = 0.552003
I0706 10:47:28.499909 54857 solver.cpp:252]     Train net output #0: accuracy = 0.648438
I0706 10:47:28.499924 54857 solver.cpp:252]     Train net output #1: loss = 0.708254 (* 1 = 0.708254 loss)
I0706 10:47:28.499938 54857 sgd_solver.cpp:106] Iteration 182500, lr = 5e-06
I0706 10:47:37.770828 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 10:49:17.592396 54857 solver.cpp:236] Iteration 182600, loss = 0.554318
I0706 10:49:17.592617 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 10:49:17.592659 54857 solver.cpp:252]     Train net output #1: loss = 0.560582 (* 1 = 0.560582 loss)
I0706 10:49:17.592669 54857 sgd_solver.cpp:106] Iteration 182600, lr = 5e-06
I0706 10:51:23.069691 54857 solver.cpp:236] Iteration 182700, loss = 0.543672
I0706 10:51:23.069902 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 10:51:23.069921 54857 solver.cpp:252]     Train net output #1: loss = 0.529236 (* 1 = 0.529236 loss)
I0706 10:51:23.069936 54857 sgd_solver.cpp:106] Iteration 182700, lr = 5e-06
I0706 10:52:30.766324 54857 solver.cpp:340] Iteration 182750, Testing net (#0)
I0706 10:53:12.605499 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7517
I0706 10:53:12.605669 54857 solver.cpp:408]     Test net output #1: loss = 0.532879 (* 1 = 0.532879 loss)
I0706 10:54:22.237239 54857 solver.cpp:236] Iteration 182800, loss = 0.526661
I0706 10:54:22.237395 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 10:54:22.237442 54857 solver.cpp:252]     Train net output #1: loss = 0.477403 (* 1 = 0.477403 loss)
I0706 10:54:22.237458 54857 sgd_solver.cpp:106] Iteration 182800, lr = 5e-06
I0706 10:56:51.953675 54857 solver.cpp:236] Iteration 182900, loss = 0.542692
I0706 10:56:51.953851 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 10:56:51.953874 54857 solver.cpp:252]     Train net output #1: loss = 0.51313 (* 1 = 0.51313 loss)
I0706 10:56:51.953883 54857 sgd_solver.cpp:106] Iteration 182900, lr = 5e-06
I0706 10:59:31.035526 54857 solver.cpp:340] Iteration 183000, Testing net (#0)
I0706 11:00:13.528760 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7544
I0706 11:00:13.528993 54857 solver.cpp:408]     Test net output #1: loss = 0.528932 (* 1 = 0.528932 loss)
I0706 11:00:13.897322 54857 solver.cpp:236] Iteration 183000, loss = 0.533487
I0706 11:00:13.897375 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 11:00:13.897392 54857 solver.cpp:252]     Train net output #1: loss = 0.470448 (* 1 = 0.470448 loss)
I0706 11:00:13.897408 54857 sgd_solver.cpp:106] Iteration 183000, lr = 5e-06
I0706 11:03:09.213191 54857 solver.cpp:236] Iteration 183100, loss = 0.541766
I0706 11:03:09.213330 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 11:03:09.213376 54857 solver.cpp:252]     Train net output #1: loss = 0.527424 (* 1 = 0.527424 loss)
I0706 11:03:09.213400 54857 sgd_solver.cpp:106] Iteration 183100, lr = 5e-06
I0706 11:06:19.579835 54857 solver.cpp:236] Iteration 183200, loss = 0.534006
I0706 11:06:19.580024 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 11:06:19.580067 54857 solver.cpp:252]     Train net output #1: loss = 0.506467 (* 1 = 0.506467 loss)
I0706 11:06:19.580083 54857 sgd_solver.cpp:106] Iteration 183200, lr = 5e-06
I0706 11:07:54.637759 54857 solver.cpp:340] Iteration 183250, Testing net (#0)
I0706 11:08:32.062067 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 11:08:37.965852 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7502
I0706 11:08:37.965917 54857 solver.cpp:408]     Test net output #1: loss = 0.531946 (* 1 = 0.531946 loss)
I0706 11:10:18.129472 54857 solver.cpp:236] Iteration 183300, loss = 0.533773
I0706 11:10:18.129611 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 11:10:18.129644 54857 solver.cpp:252]     Train net output #1: loss = 0.56529 (* 1 = 0.56529 loss)
I0706 11:10:18.129674 54857 sgd_solver.cpp:106] Iteration 183300, lr = 5e-06
I0706 11:13:52.881079 54857 solver.cpp:236] Iteration 183400, loss = 0.52897
I0706 11:13:52.881198 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 11:13:52.881227 54857 solver.cpp:252]     Train net output #1: loss = 0.470743 (* 1 = 0.470743 loss)
I0706 11:13:52.881254 54857 sgd_solver.cpp:106] Iteration 183400, lr = 5e-06
I0706 11:17:35.393179 54857 solver.cpp:340] Iteration 183500, Testing net (#0)
I0706 11:18:08.218587 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7586
I0706 11:18:08.218739 54857 solver.cpp:408]     Test net output #1: loss = 0.51916 (* 1 = 0.51916 loss)
I0706 11:18:08.565414 54857 solver.cpp:236] Iteration 183500, loss = 0.519507
I0706 11:18:08.565467 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 11:18:08.565484 54857 solver.cpp:252]     Train net output #1: loss = 0.564112 (* 1 = 0.564112 loss)
I0706 11:18:08.565498 54857 sgd_solver.cpp:106] Iteration 183500, lr = 5e-06
I0706 11:22:21.676931 54857 solver.cpp:236] Iteration 183600, loss = 0.521089
I0706 11:22:21.677095 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 11:22:21.677137 54857 solver.cpp:252]     Train net output #1: loss = 0.474344 (* 1 = 0.474344 loss)
I0706 11:22:21.677156 54857 sgd_solver.cpp:106] Iteration 183600, lr = 5e-06
I0706 11:27:04.727459 54857 solver.cpp:236] Iteration 183700, loss = 0.522822
I0706 11:27:04.727632 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 11:27:04.727664 54857 solver.cpp:252]     Train net output #1: loss = 0.455144 (* 1 = 0.455144 loss)
I0706 11:27:04.727689 54857 sgd_solver.cpp:106] Iteration 183700, lr = 5e-06
I0706 11:29:23.819149 54857 solver.cpp:340] Iteration 183750, Testing net (#0)
I0706 11:30:20.484118 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7589
I0706 11:30:20.484266 54857 solver.cpp:408]     Test net output #1: loss = 0.512168 (* 1 = 0.512168 loss)
I0706 11:32:48.054699 54857 solver.cpp:236] Iteration 183800, loss = 0.542169
I0706 11:32:48.054879 54857 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0706 11:32:48.054898 54857 solver.cpp:252]     Train net output #1: loss = 0.505663 (* 1 = 0.505663 loss)
I0706 11:32:48.054911 54857 sgd_solver.cpp:106] Iteration 183800, lr = 5e-06
I0706 11:37:49.032061 54857 solver.cpp:236] Iteration 183900, loss = 0.513679
I0706 11:37:49.032188 54857 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0706 11:37:49.032232 54857 solver.cpp:252]     Train net output #1: loss = 0.607059 (* 1 = 0.607059 loss)
I0706 11:37:49.032248 54857 sgd_solver.cpp:106] Iteration 183900, lr = 5e-06
I0706 11:42:39.900679 54857 solver.cpp:340] Iteration 184000, Testing net (#0)
I0706 11:43:06.874749 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 11:43:29.605350 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7534
I0706 11:43:29.605540 54857 solver.cpp:408]     Test net output #1: loss = 0.512138 (* 1 = 0.512138 loss)
I0706 11:43:29.951827 54857 solver.cpp:236] Iteration 184000, loss = 0.520491
I0706 11:43:29.951869 54857 solver.cpp:252]     Train net output #0: accuracy = 0.648438
I0706 11:43:29.951894 54857 solver.cpp:252]     Train net output #1: loss = 0.641993 (* 1 = 0.641993 loss)
I0706 11:43:29.951918 54857 sgd_solver.cpp:106] Iteration 184000, lr = 5e-06
I0706 11:47:31.763108 54857 solver.cpp:236] Iteration 184100, loss = 0.505925
I0706 11:47:31.763234 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 11:47:31.763252 54857 solver.cpp:252]     Train net output #1: loss = 0.574275 (* 1 = 0.574275 loss)
I0706 11:47:31.763264 54857 sgd_solver.cpp:106] Iteration 184100, lr = 5e-06
I0706 11:49:42.844624 54857 solver.cpp:236] Iteration 184200, loss = 0.521292
I0706 11:49:42.844807 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 11:49:42.844832 54857 solver.cpp:252]     Train net output #1: loss = 0.480312 (* 1 = 0.480312 loss)
I0706 11:49:42.844841 54857 sgd_solver.cpp:106] Iteration 184200, lr = 5e-06
I0706 11:50:51.510042 54857 solver.cpp:340] Iteration 184250, Testing net (#0)
I0706 11:52:37.471673 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7649
I0706 11:52:37.471815 54857 solver.cpp:408]     Test net output #1: loss = 0.50344 (* 1 = 0.50344 loss)
I0706 11:53:48.818042 54857 solver.cpp:236] Iteration 184300, loss = 0.517556
I0706 11:53:48.818156 54857 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0706 11:53:48.818176 54857 solver.cpp:252]     Train net output #1: loss = 0.555266 (* 1 = 0.555266 loss)
I0706 11:53:48.818197 54857 sgd_solver.cpp:106] Iteration 184300, lr = 5e-06
I0706 11:56:30.297938 54857 solver.cpp:236] Iteration 184400, loss = 0.521317
I0706 11:56:30.298061 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 11:56:30.298079 54857 solver.cpp:252]     Train net output #1: loss = 0.566857 (* 1 = 0.566857 loss)
I0706 11:56:30.298091 54857 sgd_solver.cpp:106] Iteration 184400, lr = 5e-06
I0706 11:59:20.740939 54857 solver.cpp:340] Iteration 184500, Testing net (#0)
I0706 11:59:59.453209 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7605
I0706 11:59:59.453443 54857 solver.cpp:408]     Test net output #1: loss = 0.51135 (* 1 = 0.51135 loss)
I0706 11:59:59.741153 54857 solver.cpp:236] Iteration 184500, loss = 0.522875
I0706 11:59:59.741183 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 11:59:59.741197 54857 solver.cpp:252]     Train net output #1: loss = 0.474737 (* 1 = 0.474737 loss)
I0706 11:59:59.741211 54857 sgd_solver.cpp:106] Iteration 184500, lr = 5e-06
I0706 12:02:38.651428 54857 solver.cpp:236] Iteration 184600, loss = 0.518403
I0706 12:02:38.651592 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 12:02:38.651612 54857 solver.cpp:252]     Train net output #1: loss = 0.544945 (* 1 = 0.544945 loss)
I0706 12:02:38.651623 54857 sgd_solver.cpp:106] Iteration 184600, lr = 5e-06
I0706 12:05:32.521347 54857 solver.cpp:236] Iteration 184700, loss = 0.515827
I0706 12:05:32.521483 54857 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0706 12:05:32.521525 54857 solver.cpp:252]     Train net output #1: loss = 0.630713 (* 1 = 0.630713 loss)
I0706 12:05:32.521538 54857 sgd_solver.cpp:106] Iteration 184700, lr = 5e-06
I0706 12:06:58.922441 54857 solver.cpp:340] Iteration 184750, Testing net (#0)
I0706 12:07:10.373320 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 12:07:35.404806 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7635
I0706 12:07:35.404942 54857 solver.cpp:408]     Test net output #1: loss = 0.49986 (* 1 = 0.49986 loss)
I0706 12:09:03.337811 54857 solver.cpp:236] Iteration 184800, loss = 0.512771
I0706 12:09:03.338033 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 12:09:03.338065 54857 solver.cpp:252]     Train net output #1: loss = 0.496441 (* 1 = 0.496441 loss)
I0706 12:09:03.338076 54857 sgd_solver.cpp:106] Iteration 184800, lr = 5e-06
I0706 12:12:31.832618 54857 solver.cpp:236] Iteration 184900, loss = 0.507373
I0706 12:12:31.832762 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 12:12:31.832801 54857 solver.cpp:252]     Train net output #1: loss = 0.450427 (* 1 = 0.450427 loss)
I0706 12:12:31.832820 54857 sgd_solver.cpp:106] Iteration 184900, lr = 5e-06
I0706 12:16:20.800734 54857 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_185000.caffemodel
I0706 12:16:21.860827 54857 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_185000.solverstate
I0706 12:16:21.891625 54857 solver.cpp:340] Iteration 185000, Testing net (#0)
I0706 12:16:58.390730 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7617
I0706 12:16:58.390877 54857 solver.cpp:408]     Test net output #1: loss = 0.495033 (* 1 = 0.495033 loss)
I0706 12:16:58.632550 54857 solver.cpp:236] Iteration 185000, loss = 0.514783
I0706 12:16:58.632581 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 12:16:58.632596 54857 solver.cpp:252]     Train net output #1: loss = 0.454006 (* 1 = 0.454006 loss)
I0706 12:16:58.632611 54857 sgd_solver.cpp:106] Iteration 185000, lr = 5e-06
I0706 12:20:32.266702 54857 solver.cpp:236] Iteration 185100, loss = 0.505427
I0706 12:20:32.266852 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 12:20:32.266891 54857 solver.cpp:252]     Train net output #1: loss = 0.481315 (* 1 = 0.481315 loss)
I0706 12:20:32.266913 54857 sgd_solver.cpp:106] Iteration 185100, lr = 5e-06
I0706 12:24:46.283018 54857 solver.cpp:236] Iteration 185200, loss = 0.51162
I0706 12:24:46.283177 54857 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0706 12:24:46.283220 54857 solver.cpp:252]     Train net output #1: loss = 0.391474 (* 1 = 0.391474 loss)
I0706 12:24:46.283233 54857 sgd_solver.cpp:106] Iteration 185200, lr = 5e-06
I0706 12:26:58.356467 54857 solver.cpp:340] Iteration 185250, Testing net (#0)
I0706 12:27:28.283188 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7629
I0706 12:27:28.283244 54857 solver.cpp:408]     Test net output #1: loss = 0.501858 (* 1 = 0.501858 loss)
I0706 12:29:39.487895 54857 solver.cpp:236] Iteration 185300, loss = 0.507312
I0706 12:29:39.488093 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 12:29:39.488128 54857 solver.cpp:252]     Train net output #1: loss = 0.53124 (* 1 = 0.53124 loss)
I0706 12:29:39.488152 54857 sgd_solver.cpp:106] Iteration 185300, lr = 5e-06
I0706 12:34:14.444808 54857 solver.cpp:236] Iteration 185400, loss = 0.508024
I0706 12:34:14.445029 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 12:34:14.445056 54857 solver.cpp:252]     Train net output #1: loss = 0.500877 (* 1 = 0.500877 loss)
I0706 12:34:14.445066 54857 sgd_solver.cpp:106] Iteration 185400, lr = 5e-06
I0706 12:38:52.958951 54857 solver.cpp:340] Iteration 185500, Testing net (#0)
I0706 12:38:56.143873 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 12:39:40.598140 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7635
I0706 12:39:40.598342 54857 solver.cpp:408]     Test net output #1: loss = 0.498187 (* 1 = 0.498187 loss)
I0706 12:39:40.960021 54857 solver.cpp:236] Iteration 185500, loss = 0.509229
I0706 12:39:40.960048 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 12:39:40.960062 54857 solver.cpp:252]     Train net output #1: loss = 0.438879 (* 1 = 0.438879 loss)
I0706 12:39:40.960075 54857 sgd_solver.cpp:106] Iteration 185500, lr = 5e-06
I0706 12:44:34.665621 54857 solver.cpp:236] Iteration 185600, loss = 0.51194
I0706 12:44:34.665740 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 12:44:34.665768 54857 solver.cpp:252]     Train net output #1: loss = 0.57657 (* 1 = 0.57657 loss)
I0706 12:44:34.665781 54857 sgd_solver.cpp:106] Iteration 185600, lr = 5e-06
I0706 12:50:08.088562 54857 solver.cpp:236] Iteration 185700, loss = 0.497766
I0706 12:50:08.088788 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 12:50:08.088832 54857 solver.cpp:252]     Train net output #1: loss = 0.573747 (* 1 = 0.573747 loss)
I0706 12:50:08.088850 54857 sgd_solver.cpp:106] Iteration 185700, lr = 5e-06
I0706 12:52:39.710038 54857 solver.cpp:340] Iteration 185750, Testing net (#0)
I0706 12:53:42.184145 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7666
I0706 12:53:42.184314 54857 solver.cpp:408]     Test net output #1: loss = 0.496873 (* 1 = 0.496873 loss)
I0706 12:55:15.427997 54857 solver.cpp:236] Iteration 185800, loss = 0.507534
I0706 12:55:15.428203 54857 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0706 12:55:15.428225 54857 solver.cpp:252]     Train net output #1: loss = 0.55524 (* 1 = 0.55524 loss)
I0706 12:55:15.428236 54857 sgd_solver.cpp:106] Iteration 185800, lr = 5e-06
I0706 12:58:42.266088 54857 solver.cpp:236] Iteration 185900, loss = 0.496178
I0706 12:58:42.266259 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 12:58:42.266288 54857 solver.cpp:252]     Train net output #1: loss = 0.45487 (* 1 = 0.45487 loss)
I0706 12:58:42.266300 54857 sgd_solver.cpp:106] Iteration 185900, lr = 5e-06
I0706 13:02:05.561081 54857 solver.cpp:340] Iteration 186000, Testing net (#0)
I0706 13:04:05.893918 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7661
I0706 13:04:05.894057 54857 solver.cpp:408]     Test net output #1: loss = 0.492976 (* 1 = 0.492976 loss)
I0706 13:04:06.144340 54857 solver.cpp:236] Iteration 186000, loss = 0.500628
I0706 13:04:06.144376 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0706 13:04:06.144390 54857 solver.cpp:252]     Train net output #1: loss = 0.476145 (* 1 = 0.476145 loss)
I0706 13:04:06.144405 54857 sgd_solver.cpp:106] Iteration 186000, lr = 5e-06
I0706 13:07:35.777616 54857 solver.cpp:236] Iteration 186100, loss = 0.490334
I0706 13:07:35.777765 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 13:07:35.777806 54857 solver.cpp:252]     Train net output #1: loss = 0.45309 (* 1 = 0.45309 loss)
I0706 13:07:35.777822 54857 sgd_solver.cpp:106] Iteration 186100, lr = 5e-06
I0706 13:11:19.333431 54857 solver.cpp:236] Iteration 186200, loss = 0.507141
I0706 13:11:19.333596 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 13:11:19.333624 54857 solver.cpp:252]     Train net output #1: loss = 0.516531 (* 1 = 0.516531 loss)
I0706 13:11:19.333637 54857 sgd_solver.cpp:106] Iteration 186200, lr = 5e-06
I0706 13:12:14.016679 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:13:12.202070 54857 solver.cpp:340] Iteration 186250, Testing net (#0)
I0706 13:14:06.819162 54857 solver.cpp:408]     Test net output #0: accuracy = 0.768
I0706 13:14:06.819337 54857 solver.cpp:408]     Test net output #1: loss = 0.489929 (* 1 = 0.489929 loss)
I0706 13:15:54.831045 54857 solver.cpp:236] Iteration 186300, loss = 0.498734
I0706 13:15:54.831195 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 13:15:54.831226 54857 solver.cpp:252]     Train net output #1: loss = 0.516434 (* 1 = 0.516434 loss)
I0706 13:15:54.831239 54857 sgd_solver.cpp:106] Iteration 186300, lr = 5e-06
I0706 13:19:33.517187 54857 solver.cpp:236] Iteration 186400, loss = 0.501502
I0706 13:19:33.517336 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 13:19:33.517377 54857 solver.cpp:252]     Train net output #1: loss = 0.488787 (* 1 = 0.488787 loss)
I0706 13:19:33.517391 54857 sgd_solver.cpp:106] Iteration 186400, lr = 5e-06
I0706 13:23:08.298522 54857 solver.cpp:340] Iteration 186500, Testing net (#0)
I0706 13:23:48.622386 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7709
I0706 13:23:48.622558 54857 solver.cpp:408]     Test net output #1: loss = 0.48794 (* 1 = 0.48794 loss)
I0706 13:23:48.977156 54857 solver.cpp:236] Iteration 186500, loss = 0.494011
I0706 13:23:48.977202 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0706 13:23:48.977216 54857 solver.cpp:252]     Train net output #1: loss = 0.49023 (* 1 = 0.49023 loss)
I0706 13:23:48.977233 54857 sgd_solver.cpp:106] Iteration 186500, lr = 5e-06
I0706 13:27:26.907377 54857 solver.cpp:236] Iteration 186600, loss = 0.50023
I0706 13:27:26.907579 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 13:27:26.907611 54857 solver.cpp:252]     Train net output #1: loss = 0.529092 (* 1 = 0.529092 loss)
I0706 13:27:26.907627 54857 sgd_solver.cpp:106] Iteration 186600, lr = 5e-06
I0706 13:31:10.534358 54857 solver.cpp:236] Iteration 186700, loss = 0.506351
I0706 13:31:10.534489 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 13:31:10.534524 54857 solver.cpp:252]     Train net output #1: loss = 0.620008 (* 1 = 0.620008 loss)
I0706 13:31:10.534543 54857 sgd_solver.cpp:106] Iteration 186700, lr = 5e-06
I0706 13:32:58.256239 54857 solver.cpp:340] Iteration 186750, Testing net (#0)
I0706 13:34:18.300395 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7639
I0706 13:34:18.300585 54857 solver.cpp:408]     Test net output #1: loss = 0.491082 (* 1 = 0.491082 loss)
I0706 13:36:02.089814 54857 solver.cpp:236] Iteration 186800, loss = 0.498372
I0706 13:36:02.090006 54857 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0706 13:36:02.090032 54857 solver.cpp:252]     Train net output #1: loss = 0.413994 (* 1 = 0.413994 loss)
I0706 13:36:02.090042 54857 sgd_solver.cpp:106] Iteration 186800, lr = 5e-06
I0706 13:40:07.543889 54857 solver.cpp:236] Iteration 186900, loss = 0.495063
I0706 13:40:07.544014 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 13:40:07.544034 54857 solver.cpp:252]     Train net output #1: loss = 0.454728 (* 1 = 0.454728 loss)
I0706 13:40:07.544050 54857 sgd_solver.cpp:106] Iteration 186900, lr = 5e-06
I0706 13:42:07.313041 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:44:30.186489 54857 solver.cpp:340] Iteration 187000, Testing net (#0)
I0706 13:45:11.977177 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7706
I0706 13:45:11.977342 54857 solver.cpp:408]     Test net output #1: loss = 0.483763 (* 1 = 0.483763 loss)
I0706 13:45:12.332972 54857 solver.cpp:236] Iteration 187000, loss = 0.493165
I0706 13:45:12.333015 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 13:45:12.333031 54857 solver.cpp:252]     Train net output #1: loss = 0.503059 (* 1 = 0.503059 loss)
I0706 13:45:12.333046 54857 sgd_solver.cpp:106] Iteration 187000, lr = 5e-06
I0706 13:50:53.869838 54857 solver.cpp:236] Iteration 187100, loss = 0.506291
I0706 13:50:53.870023 54857 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0706 13:50:53.870043 54857 solver.cpp:252]     Train net output #1: loss = 0.622824 (* 1 = 0.622824 loss)
I0706 13:50:53.870064 54857 sgd_solver.cpp:106] Iteration 187100, lr = 5e-06
I0706 13:56:59.492131 54857 solver.cpp:236] Iteration 187200, loss = 0.502924
I0706 13:56:59.498003 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 13:56:59.498020 54857 solver.cpp:252]     Train net output #1: loss = 0.446882 (* 1 = 0.446882 loss)
I0706 13:56:59.498028 54857 sgd_solver.cpp:106] Iteration 187200, lr = 5e-06
I0706 14:00:09.830617 54857 solver.cpp:340] Iteration 187250, Testing net (#0)
I0706 14:02:15.037156 54857 solver.cpp:408]     Test net output #0: accuracy = 0.771
I0706 14:02:15.037339 54857 solver.cpp:408]     Test net output #1: loss = 0.482607 (* 1 = 0.482607 loss)
I0706 14:05:14.703763 54857 solver.cpp:236] Iteration 187300, loss = 0.481354
I0706 14:05:14.703994 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 14:05:14.704023 54857 solver.cpp:252]     Train net output #1: loss = 0.426871 (* 1 = 0.426871 loss)
I0706 14:05:14.704043 54857 sgd_solver.cpp:106] Iteration 187300, lr = 5e-06
I0706 14:11:00.109432 54857 solver.cpp:236] Iteration 187400, loss = 0.509506
I0706 14:11:00.109655 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 14:11:00.109678 54857 solver.cpp:252]     Train net output #1: loss = 0.583928 (* 1 = 0.583928 loss)
I0706 14:11:00.109694 54857 sgd_solver.cpp:106] Iteration 187400, lr = 5e-06
I0706 14:14:33.800310 54857 solver.cpp:340] Iteration 187500, Testing net (#0)
I0706 14:15:42.179384 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7663
I0706 14:15:42.179535 54857 solver.cpp:408]     Test net output #1: loss = 0.487265 (* 1 = 0.487265 loss)
I0706 14:15:42.409025 54857 solver.cpp:236] Iteration 187500, loss = 0.499551
I0706 14:15:42.409070 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 14:15:42.409086 54857 solver.cpp:252]     Train net output #1: loss = 0.496897 (* 1 = 0.496897 loss)
I0706 14:15:42.409101 54857 sgd_solver.cpp:106] Iteration 187500, lr = 5e-06
I0706 14:19:15.372134 54857 solver.cpp:236] Iteration 187600, loss = 0.486602
I0706 14:19:15.372318 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0706 14:19:15.372349 54857 solver.cpp:252]     Train net output #1: loss = 0.453765 (* 1 = 0.453765 loss)
I0706 14:19:15.372364 54857 sgd_solver.cpp:106] Iteration 187600, lr = 5e-06
I0706 14:21:44.165374 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:23:01.960618 54857 solver.cpp:236] Iteration 187700, loss = 0.488172
I0706 14:23:01.960777 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 14:23:01.960805 54857 solver.cpp:252]     Train net output #1: loss = 0.458509 (* 1 = 0.458509 loss)
I0706 14:23:01.960820 54857 sgd_solver.cpp:106] Iteration 187700, lr = 5e-06
I0706 14:24:57.132288 54857 solver.cpp:340] Iteration 187750, Testing net (#0)
I0706 14:26:44.887617 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7737
I0706 14:26:44.887840 54857 solver.cpp:408]     Test net output #1: loss = 0.478891 (* 1 = 0.478891 loss)
I0706 14:29:10.707285 54857 solver.cpp:236] Iteration 187800, loss = 0.495193
I0706 14:29:10.707437 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 14:29:10.707466 54857 solver.cpp:252]     Train net output #1: loss = 0.490317 (* 1 = 0.490317 loss)
I0706 14:29:10.707479 54857 sgd_solver.cpp:106] Iteration 187800, lr = 5e-06
I0706 14:33:52.194644 54857 solver.cpp:236] Iteration 187900, loss = 0.493555
I0706 14:33:52.194792 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 14:33:52.194813 54857 solver.cpp:252]     Train net output #1: loss = 0.514069 (* 1 = 0.514069 loss)
I0706 14:33:52.194838 54857 sgd_solver.cpp:106] Iteration 187900, lr = 5e-06
I0706 14:38:26.079197 54857 solver.cpp:340] Iteration 188000, Testing net (#0)
I0706 14:39:48.179376 54857 solver.cpp:408]     Test net output #0: accuracy = 0.774
I0706 14:39:48.179574 54857 solver.cpp:408]     Test net output #1: loss = 0.481137 (* 1 = 0.481137 loss)
I0706 14:39:48.431777 54857 solver.cpp:236] Iteration 188000, loss = 0.490247
I0706 14:39:48.431854 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 14:39:48.431896 54857 solver.cpp:252]     Train net output #1: loss = 0.458841 (* 1 = 0.458841 loss)
I0706 14:39:48.431921 54857 sgd_solver.cpp:106] Iteration 188000, lr = 5e-06
I0706 14:44:37.907497 54857 solver.cpp:236] Iteration 188100, loss = 0.492325
I0706 14:44:37.907665 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 14:44:37.907702 54857 solver.cpp:252]     Train net output #1: loss = 0.551815 (* 1 = 0.551815 loss)
I0706 14:44:37.907716 54857 sgd_solver.cpp:106] Iteration 188100, lr = 5e-06
I0706 14:49:16.015339 54857 solver.cpp:236] Iteration 188200, loss = 0.488796
I0706 14:49:16.015527 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 14:49:16.015565 54857 solver.cpp:252]     Train net output #1: loss = 0.492651 (* 1 = 0.492651 loss)
I0706 14:49:16.015590 54857 sgd_solver.cpp:106] Iteration 188200, lr = 5e-06
I0706 14:51:26.332737 54857 solver.cpp:340] Iteration 188250, Testing net (#0)
I0706 14:52:40.454757 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7686
I0706 14:52:40.454887 54857 solver.cpp:408]     Test net output #1: loss = 0.483096 (* 1 = 0.483096 loss)
I0706 14:54:58.225322 54857 solver.cpp:236] Iteration 188300, loss = 0.489315
I0706 14:54:58.225481 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 14:54:58.225512 54857 solver.cpp:252]     Train net output #1: loss = 0.562411 (* 1 = 0.562411 loss)
I0706 14:54:58.225534 54857 sgd_solver.cpp:106] Iteration 188300, lr = 5e-06
I0706 14:59:15.780226 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:59:59.526113 54857 solver.cpp:236] Iteration 188400, loss = 0.481645
I0706 14:59:59.526276 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 14:59:59.526301 54857 solver.cpp:252]     Train net output #1: loss = 0.456791 (* 1 = 0.456791 loss)
I0706 14:59:59.526315 54857 sgd_solver.cpp:106] Iteration 188400, lr = 5e-06
I0706 15:05:02.446195 54857 solver.cpp:340] Iteration 188500, Testing net (#0)
I0706 15:06:37.072052 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7708
I0706 15:06:37.072211 54857 solver.cpp:408]     Test net output #1: loss = 0.479523 (* 1 = 0.479523 loss)
I0706 15:06:37.430508 54857 solver.cpp:236] Iteration 188500, loss = 0.487324
I0706 15:06:37.430558 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 15:06:37.430578 54857 solver.cpp:252]     Train net output #1: loss = 0.525259 (* 1 = 0.525259 loss)
I0706 15:06:37.430600 54857 sgd_solver.cpp:106] Iteration 188500, lr = 5e-06
I0706 15:11:39.362625 54857 solver.cpp:236] Iteration 188600, loss = 0.486692
I0706 15:11:39.362782 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 15:11:39.362817 54857 solver.cpp:252]     Train net output #1: loss = 0.514323 (* 1 = 0.514323 loss)
I0706 15:11:39.362833 54857 sgd_solver.cpp:106] Iteration 188600, lr = 5e-06
I0706 15:17:56.454430 54857 solver.cpp:236] Iteration 188700, loss = 0.492649
I0706 15:17:56.454581 54857 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0706 15:17:56.454614 54857 solver.cpp:252]     Train net output #1: loss = 0.570457 (* 1 = 0.570457 loss)
I0706 15:17:56.454627 54857 sgd_solver.cpp:106] Iteration 188700, lr = 5e-06
I0706 15:21:47.134055 54857 solver.cpp:340] Iteration 188750, Testing net (#0)
I0706 15:24:00.808218 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7643
I0706 15:24:00.808387 54857 solver.cpp:408]     Test net output #1: loss = 0.482167 (* 1 = 0.482167 loss)
I0706 15:27:30.122767 54857 solver.cpp:236] Iteration 188800, loss = 0.479672
I0706 15:27:30.122980 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 15:27:30.123000 54857 solver.cpp:252]     Train net output #1: loss = 0.459376 (* 1 = 0.459376 loss)
I0706 15:27:30.123013 54857 sgd_solver.cpp:106] Iteration 188800, lr = 5e-06
I0706 15:35:21.083400 54857 solver.cpp:236] Iteration 188900, loss = 0.488097
I0706 15:35:21.083549 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 15:35:21.083581 54857 solver.cpp:252]     Train net output #1: loss = 0.451795 (* 1 = 0.451795 loss)
I0706 15:35:21.083608 54857 sgd_solver.cpp:106] Iteration 188900, lr = 5e-06
I0706 15:43:23.193369 54857 solver.cpp:340] Iteration 189000, Testing net (#0)
I0706 15:50:08.080376 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7784
I0706 15:50:08.116353 54857 solver.cpp:408]     Test net output #1: loss = 0.475614 (* 1 = 0.475614 loss)
I0706 15:50:08.357496 54857 solver.cpp:236] Iteration 189000, loss = 0.4941
I0706 15:50:08.357722 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 15:50:08.357743 54857 solver.cpp:252]     Train net output #1: loss = 0.524899 (* 1 = 0.524899 loss)
I0706 15:50:08.358127 54857 sgd_solver.cpp:106] Iteration 189000, lr = 5e-06
I0706 15:58:40.462473 54857 solver.cpp:236] Iteration 189100, loss = 0.491276
I0706 15:58:40.549780 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 15:58:40.549826 54857 solver.cpp:252]     Train net output #1: loss = 0.478314 (* 1 = 0.478314 loss)
I0706 15:58:40.549840 54857 sgd_solver.cpp:106] Iteration 189100, lr = 5e-06
I0706 15:59:09.292188 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 16:07:11.659378 54857 solver.cpp:236] Iteration 189200, loss = 0.495527
I0706 16:07:11.675498 54857 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0706 16:07:11.675529 54857 solver.cpp:252]     Train net output #1: loss = 0.424295 (* 1 = 0.424295 loss)
I0706 16:07:11.675541 54857 sgd_solver.cpp:106] Iteration 189200, lr = 5e-06
I0706 16:11:38.923269 54857 solver.cpp:340] Iteration 189250, Testing net (#0)
I0706 16:18:46.324957 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7694
I0706 16:18:46.350695 54857 solver.cpp:408]     Test net output #1: loss = 0.483014 (* 1 = 0.483014 loss)
I0706 16:23:39.013048 54857 solver.cpp:236] Iteration 189300, loss = 0.495897
I0706 16:23:39.028304 54857 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0706 16:23:39.028345 54857 solver.cpp:252]     Train net output #1: loss = 0.430114 (* 1 = 0.430114 loss)
I0706 16:23:39.028360 54857 sgd_solver.cpp:106] Iteration 189300, lr = 5e-06
I0706 16:31:52.640419 54857 solver.cpp:236] Iteration 189400, loss = 0.476321
I0706 16:31:52.640597 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 16:31:52.640645 54857 solver.cpp:252]     Train net output #1: loss = 0.453738 (* 1 = 0.453738 loss)
I0706 16:31:52.640655 54857 sgd_solver.cpp:106] Iteration 189400, lr = 5e-06
I0706 16:41:05.165796 54857 solver.cpp:340] Iteration 189500, Testing net (#0)
I0706 16:47:45.966447 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7738
I0706 16:47:45.983093 54857 solver.cpp:408]     Test net output #1: loss = 0.474294 (* 1 = 0.474294 loss)
I0706 16:47:46.246629 54857 solver.cpp:236] Iteration 189500, loss = 0.497161
I0706 16:47:46.246665 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 16:47:46.246680 54857 solver.cpp:252]     Train net output #1: loss = 0.495756 (* 1 = 0.495756 loss)
I0706 16:47:46.246695 54857 sgd_solver.cpp:106] Iteration 189500, lr = 5e-06
I0706 16:55:10.502156 54857 solver.cpp:236] Iteration 189600, loss = 0.485599
I0706 16:55:10.517452 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 16:55:10.517498 54857 solver.cpp:252]     Train net output #1: loss = 0.54451 (* 1 = 0.54451 loss)
I0706 16:55:10.517514 54857 sgd_solver.cpp:106] Iteration 189600, lr = 5e-06
I0706 17:03:34.455880 54857 solver.cpp:236] Iteration 189700, loss = 0.490591
I0706 17:03:34.496868 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 17:03:34.496901 54857 solver.cpp:252]     Train net output #1: loss = 0.47321 (* 1 = 0.47321 loss)
I0706 17:03:34.496917 54857 sgd_solver.cpp:106] Iteration 189700, lr = 5e-06
I0706 17:07:34.771519 54857 solver.cpp:340] Iteration 189750, Testing net (#0)
I0706 17:13:37.025431 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7768
I0706 17:13:37.025607 54857 solver.cpp:408]     Test net output #1: loss = 0.471347 (* 1 = 0.471347 loss)
I0706 17:17:34.247800 54857 solver.cpp:236] Iteration 189800, loss = 0.482727
I0706 17:17:34.256546 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 17:17:34.256561 54857 solver.cpp:252]     Train net output #1: loss = 0.473211 (* 1 = 0.473211 loss)
I0706 17:17:34.256570 54857 sgd_solver.cpp:106] Iteration 189800, lr = 5e-06
I0706 17:19:35.498539 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 17:25:23.670424 54857 solver.cpp:236] Iteration 189900, loss = 0.486441
I0706 17:25:23.729111 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 17:25:23.729151 54857 solver.cpp:252]     Train net output #1: loss = 0.494266 (* 1 = 0.494266 loss)
I0706 17:25:23.729163 54857 sgd_solver.cpp:106] Iteration 189900, lr = 5e-06
I0706 17:33:00.671731 54857 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_190000.caffemodel
I0706 17:33:01.697602 54857 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_190000.solverstate
I0706 17:33:01.727069 54857 solver.cpp:340] Iteration 190000, Testing net (#0)
I0706 17:37:49.509867 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7835
I0706 17:37:49.510067 54857 solver.cpp:408]     Test net output #1: loss = 0.469054 (* 1 = 0.469054 loss)
I0706 17:37:49.650825 54857 solver.cpp:236] Iteration 190000, loss = 0.489404
I0706 17:37:49.650851 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 17:37:49.650862 54857 solver.cpp:252]     Train net output #1: loss = 0.477421 (* 1 = 0.477421 loss)
I0706 17:37:49.650877 54857 sgd_solver.cpp:106] Iteration 190000, lr = 5e-06
I0706 17:43:56.454499 54857 solver.cpp:236] Iteration 190100, loss = 0.478678
I0706 17:43:56.501760 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 17:43:56.501794 54857 solver.cpp:252]     Train net output #1: loss = 0.471768 (* 1 = 0.471768 loss)
I0706 17:43:56.501809 54857 sgd_solver.cpp:106] Iteration 190100, lr = 5e-06
I0706 17:50:08.648900 54857 solver.cpp:236] Iteration 190200, loss = 0.482463
I0706 17:50:08.680933 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 17:50:08.680974 54857 solver.cpp:252]     Train net output #1: loss = 0.484214 (* 1 = 0.484214 loss)
I0706 17:50:08.680984 54857 sgd_solver.cpp:106] Iteration 190200, lr = 5e-06
I0706 17:53:13.921322 54857 solver.cpp:340] Iteration 190250, Testing net (#0)
I0706 17:57:46.633991 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7653
I0706 17:57:46.634199 54857 solver.cpp:408]     Test net output #1: loss = 0.481357 (* 1 = 0.481357 loss)
I0706 18:00:48.355712 54857 solver.cpp:236] Iteration 190300, loss = 0.477438
I0706 18:00:48.355880 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 18:00:48.355903 54857 solver.cpp:252]     Train net output #1: loss = 0.497664 (* 1 = 0.497664 loss)
I0706 18:00:48.355916 54857 sgd_solver.cpp:106] Iteration 190300, lr = 5e-06
I0706 18:07:05.242419 54857 solver.cpp:236] Iteration 190400, loss = 0.482126
I0706 18:07:05.242573 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 18:07:05.242616 54857 solver.cpp:252]     Train net output #1: loss = 0.479103 (* 1 = 0.479103 loss)
I0706 18:07:05.242637 54857 sgd_solver.cpp:106] Iteration 190400, lr = 5e-06
I0706 18:13:23.084645 54857 solver.cpp:340] Iteration 190500, Testing net (#0)
I0706 18:18:12.790820 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7744
I0706 18:18:12.791004 54857 solver.cpp:408]     Test net output #1: loss = 0.475876 (* 1 = 0.475876 loss)
I0706 18:18:12.936688 54857 solver.cpp:236] Iteration 190500, loss = 0.493099
I0706 18:18:12.936735 54857 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0706 18:18:12.936753 54857 solver.cpp:252]     Train net output #1: loss = 0.364158 (* 1 = 0.364158 loss)
I0706 18:18:12.936767 54857 sgd_solver.cpp:106] Iteration 190500, lr = 5e-06
I0706 18:20:49.692718 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 18:24:28.604079 54857 solver.cpp:236] Iteration 190600, loss = 0.476095
I0706 18:24:28.604235 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 18:24:28.604279 54857 solver.cpp:252]     Train net output #1: loss = 0.491154 (* 1 = 0.491154 loss)
I0706 18:24:28.604300 54857 sgd_solver.cpp:106] Iteration 190600, lr = 5e-06
I0706 18:30:39.578063 54857 solver.cpp:236] Iteration 190700, loss = 0.482945
I0706 18:30:39.578222 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 18:30:39.578259 54857 solver.cpp:252]     Train net output #1: loss = 0.495857 (* 1 = 0.495857 loss)
I0706 18:30:39.578279 54857 sgd_solver.cpp:106] Iteration 190700, lr = 5e-06
I0706 18:33:37.000653 54857 solver.cpp:340] Iteration 190750, Testing net (#0)
I0706 18:38:17.600031 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7773
I0706 18:38:17.600200 54857 solver.cpp:408]     Test net output #1: loss = 0.4719 (* 1 = 0.4719 loss)
I0706 18:41:22.787966 54857 solver.cpp:236] Iteration 190800, loss = 0.476757
I0706 18:41:22.788154 54857 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0706 18:41:22.788174 54857 solver.cpp:252]     Train net output #1: loss = 0.394628 (* 1 = 0.394628 loss)
I0706 18:41:22.788189 54857 sgd_solver.cpp:106] Iteration 190800, lr = 5e-06
I0706 18:47:41.998213 54857 solver.cpp:236] Iteration 190900, loss = 0.486116
I0706 18:47:42.007693 54857 solver.cpp:252]     Train net output #0: accuracy = 0.695312
I0706 18:47:42.007747 54857 solver.cpp:252]     Train net output #1: loss = 0.541997 (* 1 = 0.541997 loss)
I0706 18:47:42.007761 54857 sgd_solver.cpp:106] Iteration 190900, lr = 5e-06
I0706 18:53:51.699633 54857 solver.cpp:340] Iteration 191000, Testing net (#0)
I0706 18:58:34.893640 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7681
I0706 18:58:34.893800 54857 solver.cpp:408]     Test net output #1: loss = 0.482018 (* 1 = 0.482018 loss)
I0706 18:58:35.234493 54857 solver.cpp:236] Iteration 191000, loss = 0.479281
I0706 18:58:35.234535 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 18:58:35.234551 54857 solver.cpp:252]     Train net output #1: loss = 0.479887 (* 1 = 0.479887 loss)
I0706 18:58:35.234566 54857 sgd_solver.cpp:106] Iteration 191000, lr = 5e-06
I0706 19:04:47.051712 54857 solver.cpp:236] Iteration 191100, loss = 0.4797
I0706 19:04:47.051913 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 19:04:47.051931 54857 solver.cpp:252]     Train net output #1: loss = 0.492585 (* 1 = 0.492585 loss)
I0706 19:04:47.051952 54857 sgd_solver.cpp:106] Iteration 191100, lr = 5e-06
I0706 19:11:09.183219 54857 solver.cpp:236] Iteration 191200, loss = 0.475699
I0706 19:11:09.183363 54857 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0706 19:11:09.183393 54857 solver.cpp:252]     Train net output #1: loss = 0.35616 (* 1 = 0.35616 loss)
I0706 19:11:09.183420 54857 sgd_solver.cpp:106] Iteration 191200, lr = 5e-06
I0706 19:14:16.868919 54857 solver.cpp:340] Iteration 191250, Testing net (#0)
I0706 19:19:07.441727 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7812
I0706 19:19:07.441908 54857 solver.cpp:408]     Test net output #1: loss = 0.468872 (* 1 = 0.468872 loss)
I0706 19:19:39.102583 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 19:22:11.447527 54857 solver.cpp:236] Iteration 191300, loss = 0.47147
I0706 19:22:11.447705 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 19:22:11.447743 54857 solver.cpp:252]     Train net output #1: loss = 0.482181 (* 1 = 0.482181 loss)
I0706 19:22:11.447762 54857 sgd_solver.cpp:106] Iteration 191300, lr = 5e-06
I0706 19:28:32.130672 54857 solver.cpp:236] Iteration 191400, loss = 0.481479
I0706 19:28:32.130842 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 19:28:32.130885 54857 solver.cpp:252]     Train net output #1: loss = 0.523555 (* 1 = 0.523555 loss)
I0706 19:28:32.130904 54857 sgd_solver.cpp:106] Iteration 191400, lr = 5e-06
I0706 19:34:55.197113 54857 solver.cpp:340] Iteration 191500, Testing net (#0)
I0706 19:39:22.818229 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7814
I0706 19:39:22.818382 54857 solver.cpp:408]     Test net output #1: loss = 0.462749 (* 1 = 0.462749 loss)
I0706 19:39:23.044180 54857 solver.cpp:236] Iteration 191500, loss = 0.477263
I0706 19:39:23.044224 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 19:39:23.044240 54857 solver.cpp:252]     Train net output #1: loss = 0.499601 (* 1 = 0.499601 loss)
I0706 19:39:23.044255 54857 sgd_solver.cpp:106] Iteration 191500, lr = 5e-06
I0706 19:45:41.188235 54857 solver.cpp:236] Iteration 191600, loss = 0.476592
I0706 19:45:41.188388 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 19:45:41.188431 54857 solver.cpp:252]     Train net output #1: loss = 0.539586 (* 1 = 0.539586 loss)
I0706 19:45:41.188452 54857 sgd_solver.cpp:106] Iteration 191600, lr = 5e-06
I0706 19:52:00.549317 54857 solver.cpp:236] Iteration 191700, loss = 0.485978
I0706 19:52:00.549574 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 19:52:00.549597 54857 solver.cpp:252]     Train net output #1: loss = 0.442298 (* 1 = 0.442298 loss)
I0706 19:52:00.549621 54857 sgd_solver.cpp:106] Iteration 191700, lr = 5e-06
I0706 19:55:06.906211 54857 solver.cpp:340] Iteration 191750, Testing net (#0)
I0706 19:59:56.497352 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7771
I0706 19:59:56.506964 54857 solver.cpp:408]     Test net output #1: loss = 0.474716 (* 1 = 0.474716 loss)
I0706 20:03:03.695746 54857 solver.cpp:236] Iteration 191800, loss = 0.487399
I0706 20:03:03.695924 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 20:03:03.695977 54857 solver.cpp:252]     Train net output #1: loss = 0.476277 (* 1 = 0.476277 loss)
I0706 20:03:03.695993 54857 sgd_solver.cpp:106] Iteration 191800, lr = 5e-06
I0706 20:09:27.115862 54857 solver.cpp:236] Iteration 191900, loss = 0.483486
I0706 20:09:27.116014 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 20:09:27.116049 54857 solver.cpp:252]     Train net output #1: loss = 0.511439 (* 1 = 0.511439 loss)
I0706 20:09:27.116065 54857 sgd_solver.cpp:106] Iteration 191900, lr = 5e-06
I0706 20:15:51.596228 54857 solver.cpp:340] Iteration 192000, Testing net (#0)
I0706 20:19:26.453389 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 20:20:28.871395 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7739
I0706 20:20:28.871577 54857 solver.cpp:408]     Test net output #1: loss = 0.471984 (* 1 = 0.471984 loss)
I0706 20:20:29.258309 54857 solver.cpp:236] Iteration 192000, loss = 0.475303
I0706 20:20:29.258360 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 20:20:29.258378 54857 solver.cpp:252]     Train net output #1: loss = 0.467574 (* 1 = 0.467574 loss)
I0706 20:20:29.258395 54857 sgd_solver.cpp:106] Iteration 192000, lr = 5e-06
I0706 20:26:50.118238 54857 solver.cpp:236] Iteration 192100, loss = 0.468912
I0706 20:26:50.118427 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 20:26:50.118460 54857 solver.cpp:252]     Train net output #1: loss = 0.466739 (* 1 = 0.466739 loss)
I0706 20:26:50.118477 54857 sgd_solver.cpp:106] Iteration 192100, lr = 5e-06
I0706 20:33:05.049278 54857 solver.cpp:236] Iteration 192200, loss = 0.488786
I0706 20:33:05.049443 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 20:33:05.049494 54857 solver.cpp:252]     Train net output #1: loss = 0.448463 (* 1 = 0.448463 loss)
I0706 20:33:05.049507 54857 sgd_solver.cpp:106] Iteration 192200, lr = 5e-06
I0706 20:36:04.712987 54857 solver.cpp:340] Iteration 192250, Testing net (#0)
I0706 20:40:45.489948 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7744
I0706 20:40:45.490128 54857 solver.cpp:408]     Test net output #1: loss = 0.476286 (* 1 = 0.476286 loss)
I0706 20:43:48.555567 54857 solver.cpp:236] Iteration 192300, loss = 0.472602
I0706 20:43:48.555727 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 20:43:48.555770 54857 solver.cpp:252]     Train net output #1: loss = 0.440485 (* 1 = 0.440485 loss)
I0706 20:43:48.555785 54857 sgd_solver.cpp:106] Iteration 192300, lr = 5e-06
I0706 20:50:09.936195 54857 solver.cpp:236] Iteration 192400, loss = 0.474564
I0706 20:50:09.955188 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 20:50:09.955220 54857 solver.cpp:252]     Train net output #1: loss = 0.503672 (* 1 = 0.503672 loss)
I0706 20:50:09.955236 54857 sgd_solver.cpp:106] Iteration 192400, lr = 5e-06
I0706 20:55:40.523345 54857 solver.cpp:340] Iteration 192500, Testing net (#0)
I0706 20:58:57.631547 54857 solver.cpp:408]     Test net output #0: accuracy = 0.783
I0706 20:58:57.631733 54857 solver.cpp:408]     Test net output #1: loss = 0.459666 (* 1 = 0.459666 loss)
I0706 20:58:57.955610 54857 solver.cpp:236] Iteration 192500, loss = 0.487365
I0706 20:58:57.955660 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 20:58:57.955677 54857 solver.cpp:252]     Train net output #1: loss = 0.535193 (* 1 = 0.535193 loss)
I0706 20:58:57.955694 54857 sgd_solver.cpp:106] Iteration 192500, lr = 5e-06
I0706 21:03:08.035105 54857 solver.cpp:236] Iteration 192600, loss = 0.473912
I0706 21:03:08.035279 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 21:03:08.035308 54857 solver.cpp:252]     Train net output #1: loss = 0.474912 (* 1 = 0.474912 loss)
I0706 21:03:08.035322 54857 sgd_solver.cpp:106] Iteration 192600, lr = 5e-06
I0706 21:07:33.436956 54857 solver.cpp:236] Iteration 192700, loss = 0.480385
I0706 21:07:33.437165 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 21:07:33.437208 54857 solver.cpp:252]     Train net output #1: loss = 0.5415 (* 1 = 0.5415 loss)
I0706 21:07:33.437229 54857 sgd_solver.cpp:106] Iteration 192700, lr = 5e-06
I0706 21:09:37.100127 54857 solver.cpp:340] Iteration 192750, Testing net (#0)
I0706 21:11:00.992209 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 21:12:53.754670 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7802
I0706 21:12:53.754811 54857 solver.cpp:408]     Test net output #1: loss = 0.466809 (* 1 = 0.466809 loss)
I0706 21:15:15.649031 54857 solver.cpp:236] Iteration 192800, loss = 0.470611
I0706 21:15:15.649233 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 21:15:15.649252 54857 solver.cpp:252]     Train net output #1: loss = 0.457423 (* 1 = 0.457423 loss)
I0706 21:15:15.649271 54857 sgd_solver.cpp:106] Iteration 192800, lr = 5e-06
I0706 21:20:09.986006 54857 solver.cpp:236] Iteration 192900, loss = 0.476821
I0706 21:20:09.997962 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0706 21:20:09.998006 54857 solver.cpp:252]     Train net output #1: loss = 0.514451 (* 1 = 0.514451 loss)
I0706 21:20:09.998025 54857 sgd_solver.cpp:106] Iteration 192900, lr = 5e-06
I0706 21:25:01.128866 54857 solver.cpp:340] Iteration 193000, Testing net (#0)
I0706 21:30:09.410645 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7774
I0706 21:30:09.410817 54857 solver.cpp:408]     Test net output #1: loss = 0.470835 (* 1 = 0.470835 loss)
I0706 21:30:09.662927 54857 solver.cpp:236] Iteration 193000, loss = 0.486878
I0706 21:30:09.662971 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0706 21:30:09.662987 54857 solver.cpp:252]     Train net output #1: loss = 0.551915 (* 1 = 0.551915 loss)
I0706 21:30:09.663007 54857 sgd_solver.cpp:106] Iteration 193000, lr = 5e-06
I0706 21:36:48.251806 54857 solver.cpp:236] Iteration 193100, loss = 0.488476
I0706 21:36:48.290686 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0706 21:36:48.290720 54857 solver.cpp:252]     Train net output #1: loss = 0.535231 (* 1 = 0.535231 loss)
I0706 21:36:48.290740 54857 sgd_solver.cpp:106] Iteration 193100, lr = 5e-06
I0706 21:43:56.401425 54857 solver.cpp:236] Iteration 193200, loss = 0.482407
I0706 21:43:56.412329 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0706 21:43:56.412356 54857 solver.cpp:252]     Train net output #1: loss = 0.473827 (* 1 = 0.473827 loss)
I0706 21:43:56.412372 54857 sgd_solver.cpp:106] Iteration 193200, lr = 5e-06
I0706 21:47:24.200122 54857 solver.cpp:340] Iteration 193250, Testing net (#0)
I0706 21:52:19.432893 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7768
I0706 21:52:19.433035 54857 solver.cpp:408]     Test net output #1: loss = 0.468001 (* 1 = 0.468001 loss)
I0706 21:55:34.473899 54857 solver.cpp:236] Iteration 193300, loss = 0.469319
I0706 21:55:34.474086 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0706 21:55:34.474123 54857 solver.cpp:252]     Train net output #1: loss = 0.466763 (* 1 = 0.466763 loss)
I0706 21:55:34.474135 54857 sgd_solver.cpp:106] Iteration 193300, lr = 5e-06
I0706 22:04:44.113823 54857 solver.cpp:236] Iteration 193400, loss = 0.467875
I0706 22:04:44.113977 54857 solver.cpp:252]     Train net output #0: accuracy = 0.84375
I0706 22:04:44.113997 54857 solver.cpp:252]     Train net output #1: loss = 0.372018 (* 1 = 0.372018 loss)
I0706 22:04:44.114012 54857 sgd_solver.cpp:106] Iteration 193400, lr = 5e-06
I0706 22:12:40.433289 54857 solver.cpp:340] Iteration 193500, Testing net (#0)
I0706 22:13:12.657939 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 22:18:07.897033 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7803
I0706 22:18:07.897233 54857 solver.cpp:408]     Test net output #1: loss = 0.466282 (* 1 = 0.466282 loss)
I0706 22:18:08.061636 54857 solver.cpp:236] Iteration 193500, loss = 0.480747
I0706 22:18:08.061671 54857 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0706 22:18:08.061684 54857 solver.cpp:252]     Train net output #1: loss = 0.53846 (* 1 = 0.53846 loss)
I0706 22:18:08.061702 54857 sgd_solver.cpp:106] Iteration 193500, lr = 5e-06
I0706 22:24:54.845877 54857 solver.cpp:236] Iteration 193600, loss = 0.477266
I0706 22:24:54.846036 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 22:24:54.846086 54857 solver.cpp:252]     Train net output #1: loss = 0.46921 (* 1 = 0.46921 loss)
I0706 22:24:54.846096 54857 sgd_solver.cpp:106] Iteration 193600, lr = 5e-06
I0706 22:31:47.973765 54857 solver.cpp:236] Iteration 193700, loss = 0.484487
I0706 22:31:47.973930 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0706 22:31:47.973971 54857 solver.cpp:252]     Train net output #1: loss = 0.445401 (* 1 = 0.445401 loss)
I0706 22:31:47.973986 54857 sgd_solver.cpp:106] Iteration 193700, lr = 5e-06
I0706 22:35:06.995025 54857 solver.cpp:340] Iteration 193750, Testing net (#0)
I0706 22:40:30.590509 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7768
I0706 22:40:30.590698 54857 solver.cpp:408]     Test net output #1: loss = 0.468637 (* 1 = 0.468637 loss)
I0706 22:43:50.729181 54857 solver.cpp:236] Iteration 193800, loss = 0.45888
I0706 22:43:50.729406 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 22:43:50.729432 54857 solver.cpp:252]     Train net output #1: loss = 0.457161 (* 1 = 0.457161 loss)
I0706 22:43:50.729449 54857 sgd_solver.cpp:106] Iteration 193800, lr = 5e-06
I0706 22:50:35.518983 54857 solver.cpp:236] Iteration 193900, loss = 0.47201
I0706 22:50:35.519134 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0706 22:50:35.519175 54857 solver.cpp:252]     Train net output #1: loss = 0.544792 (* 1 = 0.544792 loss)
I0706 22:50:35.519188 54857 sgd_solver.cpp:106] Iteration 193900, lr = 5e-06
I0706 22:57:15.899608 54857 solver.cpp:340] Iteration 194000, Testing net (#0)
I0706 23:02:32.322532 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7805
I0706 23:02:32.322728 54857 solver.cpp:408]     Test net output #1: loss = 0.462278 (* 1 = 0.462278 loss)
I0706 23:02:32.671257 54857 solver.cpp:236] Iteration 194000, loss = 0.474395
I0706 23:02:32.671299 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 23:02:32.671316 54857 solver.cpp:252]     Train net output #1: loss = 0.523663 (* 1 = 0.523663 loss)
I0706 23:02:32.671332 54857 sgd_solver.cpp:106] Iteration 194000, lr = 5e-06
I0706 23:09:25.164640 54857 solver.cpp:236] Iteration 194100, loss = 0.474645
I0706 23:09:25.164876 54857 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0706 23:09:25.164894 54857 solver.cpp:252]     Train net output #1: loss = 0.403432 (* 1 = 0.403432 loss)
I0706 23:09:25.164907 54857 sgd_solver.cpp:106] Iteration 194100, lr = 5e-06
I0706 23:16:06.368728 54857 solver.cpp:236] Iteration 194200, loss = 0.474355
I0706 23:16:06.368876 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 23:16:06.368922 54857 solver.cpp:252]     Train net output #1: loss = 0.451662 (* 1 = 0.451662 loss)
I0706 23:16:06.368932 54857 sgd_solver.cpp:106] Iteration 194200, lr = 5e-06
I0706 23:17:47.127013 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 23:19:18.181907 54857 solver.cpp:340] Iteration 194250, Testing net (#0)
I0706 23:24:13.279621 54857 solver.cpp:408]     Test net output #0: accuracy = 0.778
I0706 23:24:13.279824 54857 solver.cpp:408]     Test net output #1: loss = 0.472366 (* 1 = 0.472366 loss)
I0706 23:27:24.403179 54857 solver.cpp:236] Iteration 194300, loss = 0.470734
I0706 23:27:24.403373 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0706 23:27:24.403416 54857 solver.cpp:252]     Train net output #1: loss = 0.435235 (* 1 = 0.435235 loss)
I0706 23:27:24.403429 54857 sgd_solver.cpp:106] Iteration 194300, lr = 5e-06
I0706 23:34:17.248523 54857 solver.cpp:236] Iteration 194400, loss = 0.465925
I0706 23:34:17.275285 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0706 23:34:17.275321 54857 solver.cpp:252]     Train net output #1: loss = 0.50317 (* 1 = 0.50317 loss)
I0706 23:34:17.275343 54857 sgd_solver.cpp:106] Iteration 194400, lr = 5e-06
I0706 23:40:44.842989 54857 solver.cpp:340] Iteration 194500, Testing net (#0)
I0706 23:45:31.006759 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7773
I0706 23:45:31.006943 54857 solver.cpp:408]     Test net output #1: loss = 0.465421 (* 1 = 0.465421 loss)
I0706 23:45:31.252768 54857 solver.cpp:236] Iteration 194500, loss = 0.488751
I0706 23:45:31.252812 54857 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0706 23:45:31.252830 54857 solver.cpp:252]     Train net output #1: loss = 0.610737 (* 1 = 0.610737 loss)
I0706 23:45:31.252847 54857 sgd_solver.cpp:106] Iteration 194500, lr = 5e-06
I0706 23:52:03.171211 54857 solver.cpp:236] Iteration 194600, loss = 0.474133
I0706 23:52:03.171358 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0706 23:52:03.171388 54857 solver.cpp:252]     Train net output #1: loss = 0.473078 (* 1 = 0.473078 loss)
I0706 23:52:03.171401 54857 sgd_solver.cpp:106] Iteration 194600, lr = 5e-06
I0706 23:58:48.349835 54857 solver.cpp:236] Iteration 194700, loss = 0.47105
I0706 23:58:48.350003 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0706 23:58:48.350040 54857 solver.cpp:252]     Train net output #1: loss = 0.477777 (* 1 = 0.477777 loss)
I0706 23:58:48.350054 54857 sgd_solver.cpp:106] Iteration 194700, lr = 5e-06
I0707 00:01:56.013840 54857 solver.cpp:340] Iteration 194750, Testing net (#0)
I0707 00:06:41.072186 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7797
I0707 00:06:41.072397 54857 solver.cpp:408]     Test net output #1: loss = 0.468539 (* 1 = 0.468539 loss)
I0707 00:09:40.677796 54857 solver.cpp:236] Iteration 194800, loss = 0.482479
I0707 00:09:40.677942 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 00:09:40.677975 54857 solver.cpp:252]     Train net output #1: loss = 0.443206 (* 1 = 0.443206 loss)
I0707 00:09:40.677995 54857 sgd_solver.cpp:106] Iteration 194800, lr = 5e-06
I0707 00:15:57.775117 54857 solver.cpp:236] Iteration 194900, loss = 0.470758
I0707 00:15:57.775279 54857 solver.cpp:252]     Train net output #0: accuracy = 0.835938
I0707 00:15:57.775321 54857 solver.cpp:252]     Train net output #1: loss = 0.371566 (* 1 = 0.371566 loss)
I0707 00:15:57.775334 54857 sgd_solver.cpp:106] Iteration 194900, lr = 5e-06
I0707 00:18:51.629459 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 00:22:27.382565 54857 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_195000.caffemodel
I0707 00:22:28.628290 54857 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_195000.solverstate
I0707 00:22:28.656126 54857 solver.cpp:340] Iteration 195000, Testing net (#0)
I0707 00:27:04.467003 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7829
I0707 00:27:04.467157 54857 solver.cpp:408]     Test net output #1: loss = 0.464353 (* 1 = 0.464353 loss)
I0707 00:27:04.659274 54857 solver.cpp:236] Iteration 195000, loss = 0.457694
I0707 00:27:04.659315 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 00:27:04.659330 54857 solver.cpp:252]     Train net output #1: loss = 0.509209 (* 1 = 0.509209 loss)
I0707 00:27:04.659345 54857 sgd_solver.cpp:106] Iteration 195000, lr = 5e-06
I0707 00:33:08.484014 54857 solver.cpp:236] Iteration 195100, loss = 0.474522
I0707 00:33:08.484161 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 00:33:08.484200 54857 solver.cpp:252]     Train net output #1: loss = 0.407064 (* 1 = 0.407064 loss)
I0707 00:33:08.484220 54857 sgd_solver.cpp:106] Iteration 195100, lr = 5e-06
I0707 00:39:17.753324 54857 solver.cpp:236] Iteration 195200, loss = 0.470969
I0707 00:39:17.753545 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 00:39:17.753563 54857 solver.cpp:252]     Train net output #1: loss = 0.420784 (* 1 = 0.420784 loss)
I0707 00:39:17.753577 54857 sgd_solver.cpp:106] Iteration 195200, lr = 5e-06
I0707 00:42:27.887928 54857 solver.cpp:340] Iteration 195250, Testing net (#0)
I0707 00:47:24.675547 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7845
I0707 00:47:24.697132 54857 solver.cpp:408]     Test net output #1: loss = 0.459599 (* 1 = 0.459599 loss)
I0707 00:50:33.604012 54857 solver.cpp:236] Iteration 195300, loss = 0.484183
I0707 00:50:33.604198 54857 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0707 00:50:33.604250 54857 solver.cpp:252]     Train net output #1: loss = 0.576605 (* 1 = 0.576605 loss)
I0707 00:50:33.604275 54857 sgd_solver.cpp:106] Iteration 195300, lr = 5e-06
I0707 00:56:51.428231 54857 solver.cpp:236] Iteration 195400, loss = 0.484125
I0707 00:56:51.428390 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0707 00:56:51.428439 54857 solver.cpp:252]     Train net output #1: loss = 0.535349 (* 1 = 0.535349 loss)
I0707 00:56:51.428462 54857 sgd_solver.cpp:106] Iteration 195400, lr = 5e-06
I0707 01:02:59.083509 54857 solver.cpp:340] Iteration 195500, Testing net (#0)
I0707 01:07:43.209944 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7758
I0707 01:07:43.210163 54857 solver.cpp:408]     Test net output #1: loss = 0.46777 (* 1 = 0.46777 loss)
I0707 01:07:43.456015 54857 solver.cpp:236] Iteration 195500, loss = 0.47499
I0707 01:07:43.456068 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 01:07:43.456084 54857 solver.cpp:252]     Train net output #1: loss = 0.450909 (* 1 = 0.450909 loss)
I0707 01:07:43.456102 54857 sgd_solver.cpp:106] Iteration 195500, lr = 5e-06
I0707 01:14:10.858832 54857 solver.cpp:236] Iteration 195600, loss = 0.46376
I0707 01:14:10.858983 54857 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0707 01:14:10.859040 54857 solver.cpp:252]     Train net output #1: loss = 0.554187 (* 1 = 0.554187 loss)
I0707 01:14:10.859057 54857 sgd_solver.cpp:106] Iteration 195600, lr = 5e-06
I0707 01:18:08.895525 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 01:20:33.437408 54857 solver.cpp:236] Iteration 195700, loss = 0.472438
I0707 01:20:33.437616 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 01:20:33.437657 54857 solver.cpp:252]     Train net output #1: loss = 0.457682 (* 1 = 0.457682 loss)
I0707 01:20:33.437680 54857 sgd_solver.cpp:106] Iteration 195700, lr = 5e-06
I0707 01:23:34.038386 54857 solver.cpp:340] Iteration 195750, Testing net (#0)
I0707 01:28:17.027863 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7797
I0707 01:28:17.028048 54857 solver.cpp:408]     Test net output #1: loss = 0.467723 (* 1 = 0.467723 loss)
I0707 01:31:14.207171 54857 solver.cpp:236] Iteration 195800, loss = 0.477548
I0707 01:31:14.207341 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 01:31:14.207361 54857 solver.cpp:252]     Train net output #1: loss = 0.457483 (* 1 = 0.457483 loss)
I0707 01:31:14.207376 54857 sgd_solver.cpp:106] Iteration 195800, lr = 5e-06
I0707 01:37:51.139637 54857 solver.cpp:236] Iteration 195900, loss = 0.478327
I0707 01:37:51.139780 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 01:37:51.139811 54857 solver.cpp:252]     Train net output #1: loss = 0.498018 (* 1 = 0.498018 loss)
I0707 01:37:51.139838 54857 sgd_solver.cpp:106] Iteration 195900, lr = 5e-06
I0707 01:44:19.375277 54857 solver.cpp:340] Iteration 196000, Testing net (#0)
I0707 01:49:11.226430 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7811
I0707 01:49:11.226637 54857 solver.cpp:408]     Test net output #1: loss = 0.463593 (* 1 = 0.463593 loss)
I0707 01:49:11.358330 54857 solver.cpp:236] Iteration 196000, loss = 0.461463
I0707 01:49:11.358383 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 01:49:11.358399 54857 solver.cpp:252]     Train net output #1: loss = 0.531553 (* 1 = 0.531553 loss)
I0707 01:49:11.358415 54857 sgd_solver.cpp:106] Iteration 196000, lr = 5e-06
I0707 01:55:13.743713 54857 solver.cpp:236] Iteration 196100, loss = 0.47448
I0707 01:55:13.743871 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 01:55:13.743914 54857 solver.cpp:252]     Train net output #1: loss = 0.484385 (* 1 = 0.484385 loss)
I0707 01:55:13.743927 54857 sgd_solver.cpp:106] Iteration 196100, lr = 5e-06
I0707 02:01:42.858530 54857 solver.cpp:236] Iteration 196200, loss = 0.471989
I0707 02:01:42.894479 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 02:01:42.894517 54857 solver.cpp:252]     Train net output #1: loss = 0.465208 (* 1 = 0.465208 loss)
I0707 02:01:42.894533 54857 sgd_solver.cpp:106] Iteration 196200, lr = 5e-06
I0707 02:05:01.244380 54857 solver.cpp:340] Iteration 196250, Testing net (#0)
I0707 02:09:49.850625 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7842
I0707 02:09:49.850796 54857 solver.cpp:408]     Test net output #1: loss = 0.458209 (* 1 = 0.458209 loss)
I0707 02:12:50.267590 54857 solver.cpp:236] Iteration 196300, loss = 0.457726
I0707 02:12:50.267771 54857 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 02:12:50.267807 54857 solver.cpp:252]     Train net output #1: loss = 0.423891 (* 1 = 0.423891 loss)
I0707 02:12:50.267828 54857 sgd_solver.cpp:106] Iteration 196300, lr = 5e-06
I0707 02:17:46.366521 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 02:19:01.554667 54857 solver.cpp:236] Iteration 196400, loss = 0.471354
I0707 02:19:01.554837 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 02:19:01.554855 54857 solver.cpp:252]     Train net output #1: loss = 0.423135 (* 1 = 0.423135 loss)
I0707 02:19:01.554870 54857 sgd_solver.cpp:106] Iteration 196400, lr = 5e-06
I0707 02:25:20.478329 54857 solver.cpp:340] Iteration 196500, Testing net (#0)
I0707 02:30:24.289335 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7755
I0707 02:30:24.289562 54857 solver.cpp:408]     Test net output #1: loss = 0.472328 (* 1 = 0.472328 loss)
I0707 02:30:24.445413 54857 solver.cpp:236] Iteration 196500, loss = 0.47002
I0707 02:30:24.445467 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 02:30:24.445484 54857 solver.cpp:252]     Train net output #1: loss = 0.417006 (* 1 = 0.417006 loss)
I0707 02:30:24.445502 54857 sgd_solver.cpp:106] Iteration 196500, lr = 5e-06
I0707 02:36:45.276271 54857 solver.cpp:236] Iteration 196600, loss = 0.484225
I0707 02:36:45.276468 54857 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0707 02:36:45.276531 54857 solver.cpp:252]     Train net output #1: loss = 0.500862 (* 1 = 0.500862 loss)
I0707 02:36:45.276548 54857 sgd_solver.cpp:106] Iteration 196600, lr = 5e-06
I0707 02:42:58.680122 54857 solver.cpp:236] Iteration 196700, loss = 0.455571
I0707 02:42:58.680284 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 02:42:58.680301 54857 solver.cpp:252]     Train net output #1: loss = 0.457226 (* 1 = 0.457226 loss)
I0707 02:42:58.680315 54857 sgd_solver.cpp:106] Iteration 196700, lr = 5e-06
I0707 02:45:59.216372 54857 solver.cpp:340] Iteration 196750, Testing net (#0)
I0707 02:50:39.391681 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7832
I0707 02:50:39.391942 54857 solver.cpp:408]     Test net output #1: loss = 0.459415 (* 1 = 0.459415 loss)
I0707 02:53:47.678650 54857 solver.cpp:236] Iteration 196800, loss = 0.466869
I0707 02:53:47.678858 54857 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 02:53:47.678879 54857 solver.cpp:252]     Train net output #1: loss = 0.437528 (* 1 = 0.437528 loss)
I0707 02:53:47.678892 54857 sgd_solver.cpp:106] Iteration 196800, lr = 5e-06
I0707 03:00:22.174227 54857 solver.cpp:236] Iteration 196900, loss = 0.474558
I0707 03:00:22.174554 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 03:00:22.174574 54857 solver.cpp:252]     Train net output #1: loss = 0.440265 (* 1 = 0.440265 loss)
I0707 03:00:22.174588 54857 sgd_solver.cpp:106] Iteration 196900, lr = 5e-06
I0707 03:06:34.718968 54857 solver.cpp:340] Iteration 197000, Testing net (#0)
I0707 03:11:15.700412 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7807
I0707 03:11:15.700618 54857 solver.cpp:408]     Test net output #1: loss = 0.463021 (* 1 = 0.463021 loss)
I0707 03:11:15.918133 54857 solver.cpp:236] Iteration 197000, loss = 0.474862
I0707 03:11:15.918189 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 03:11:15.918206 54857 solver.cpp:252]     Train net output #1: loss = 0.468193 (* 1 = 0.468193 loss)
I0707 03:11:15.918222 54857 sgd_solver.cpp:106] Iteration 197000, lr = 5e-06
I0707 03:17:27.242213 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 03:17:35.314270 54857 solver.cpp:236] Iteration 197100, loss = 0.471209
I0707 03:17:35.314314 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 03:17:35.314329 54857 solver.cpp:252]     Train net output #1: loss = 0.502366 (* 1 = 0.502366 loss)
I0707 03:17:35.314342 54857 sgd_solver.cpp:106] Iteration 197100, lr = 5e-06
I0707 03:24:13.361662 54857 solver.cpp:236] Iteration 197200, loss = 0.468883
I0707 03:24:13.361884 54857 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 03:24:13.361909 54857 solver.cpp:252]     Train net output #1: loss = 0.422105 (* 1 = 0.422105 loss)
I0707 03:24:13.361918 54857 sgd_solver.cpp:106] Iteration 197200, lr = 5e-06
I0707 03:27:20.231664 54857 solver.cpp:340] Iteration 197250, Testing net (#0)
I0707 03:32:02.988487 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7804
I0707 03:32:02.988646 54857 solver.cpp:408]     Test net output #1: loss = 0.462678 (* 1 = 0.462678 loss)
I0707 03:34:59.821245 54857 solver.cpp:236] Iteration 197300, loss = 0.473788
I0707 03:34:59.821472 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 03:34:59.821496 54857 solver.cpp:252]     Train net output #1: loss = 0.451714 (* 1 = 0.451714 loss)
I0707 03:34:59.821506 54857 sgd_solver.cpp:106] Iteration 197300, lr = 5e-06
I0707 03:41:21.833416 54857 solver.cpp:236] Iteration 197400, loss = 0.458466
I0707 03:41:21.882176 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 03:41:21.882205 54857 solver.cpp:252]     Train net output #1: loss = 0.420254 (* 1 = 0.420254 loss)
I0707 03:41:21.882230 54857 sgd_solver.cpp:106] Iteration 197400, lr = 5e-06
I0707 03:48:10.997762 54857 solver.cpp:340] Iteration 197500, Testing net (#0)
I0707 03:53:17.537909 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7876
I0707 03:53:17.551887 54857 solver.cpp:408]     Test net output #1: loss = 0.456971 (* 1 = 0.456971 loss)
I0707 03:53:17.739528 54857 solver.cpp:236] Iteration 197500, loss = 0.461832
I0707 03:53:17.739578 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 03:53:17.739594 54857 solver.cpp:252]     Train net output #1: loss = 0.459814 (* 1 = 0.459814 loss)
I0707 03:53:17.739611 54857 sgd_solver.cpp:106] Iteration 197500, lr = 5e-06
I0707 03:59:44.733708 54857 solver.cpp:236] Iteration 197600, loss = 0.462918
I0707 03:59:44.746837 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 03:59:44.746886 54857 solver.cpp:252]     Train net output #1: loss = 0.405309 (* 1 = 0.405309 loss)
I0707 03:59:44.746902 54857 sgd_solver.cpp:106] Iteration 197600, lr = 5e-06
I0707 04:06:16.142009 54857 solver.cpp:236] Iteration 197700, loss = 0.474351
I0707 04:06:16.156404 54857 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0707 04:06:16.156441 54857 solver.cpp:252]     Train net output #1: loss = 0.531022 (* 1 = 0.531022 loss)
I0707 04:06:16.156463 54857 sgd_solver.cpp:106] Iteration 197700, lr = 5e-06
I0707 04:09:40.781083 54857 solver.cpp:340] Iteration 197750, Testing net (#0)
I0707 04:14:53.179736 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7785
I0707 04:14:53.210403 54857 solver.cpp:408]     Test net output #1: loss = 0.465225 (* 1 = 0.465225 loss)
I0707 04:18:07.612120 54857 solver.cpp:236] Iteration 197800, loss = 0.459281
I0707 04:18:07.612298 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 04:18:07.612329 54857 solver.cpp:252]     Train net output #1: loss = 0.46391 (* 1 = 0.46391 loss)
I0707 04:18:07.612341 54857 sgd_solver.cpp:106] Iteration 197800, lr = 5e-06
I0707 04:19:11.194543 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 04:24:37.572291 54857 solver.cpp:236] Iteration 197900, loss = 0.468721
I0707 04:24:37.572445 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 04:24:37.572500 54857 solver.cpp:252]     Train net output #1: loss = 0.5279 (* 1 = 0.5279 loss)
I0707 04:24:37.572512 54857 sgd_solver.cpp:106] Iteration 197900, lr = 5e-06
I0707 04:31:06.735023 54857 solver.cpp:340] Iteration 198000, Testing net (#0)
I0707 04:36:09.569955 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7738
I0707 04:36:09.570160 54857 solver.cpp:408]     Test net output #1: loss = 0.466575 (* 1 = 0.466575 loss)
I0707 04:36:09.811902 54857 solver.cpp:236] Iteration 198000, loss = 0.47448
I0707 04:36:09.811952 54857 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 04:36:09.811969 54857 solver.cpp:252]     Train net output #1: loss = 0.428152 (* 1 = 0.428152 loss)
I0707 04:36:09.811988 54857 sgd_solver.cpp:106] Iteration 198000, lr = 5e-06
I0707 04:42:52.830893 54857 solver.cpp:236] Iteration 198100, loss = 0.476341
I0707 04:42:52.831055 54857 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 04:42:52.831109 54857 solver.cpp:252]     Train net output #1: loss = 0.423862 (* 1 = 0.423862 loss)
I0707 04:42:52.831123 54857 sgd_solver.cpp:106] Iteration 198100, lr = 5e-06
I0707 04:49:19.708235 54857 solver.cpp:236] Iteration 198200, loss = 0.46197
I0707 04:49:19.708428 54857 solver.cpp:252]     Train net output #0: accuracy = 0.695312
I0707 04:49:19.708453 54857 solver.cpp:252]     Train net output #1: loss = 0.506451 (* 1 = 0.506451 loss)
I0707 04:49:19.708467 54857 sgd_solver.cpp:106] Iteration 198200, lr = 5e-06
I0707 04:52:26.864640 54857 solver.cpp:340] Iteration 198250, Testing net (#0)
I0707 04:57:11.499997 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7803
I0707 04:57:11.500170 54857 solver.cpp:408]     Test net output #1: loss = 0.466435 (* 1 = 0.466435 loss)
I0707 05:00:23.557109 54857 solver.cpp:236] Iteration 198300, loss = 0.465632
I0707 05:00:23.557276 54857 solver.cpp:252]     Train net output #0: accuracy = 0.835938
I0707 05:00:23.557320 54857 solver.cpp:252]     Train net output #1: loss = 0.392321 (* 1 = 0.392321 loss)
I0707 05:00:23.557335 54857 sgd_solver.cpp:106] Iteration 198300, lr = 5e-06
I0707 05:07:00.847158 54857 solver.cpp:236] Iteration 198400, loss = 0.484912
I0707 05:07:00.847334 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 05:07:00.847367 54857 solver.cpp:252]     Train net output #1: loss = 0.463437 (* 1 = 0.463437 loss)
I0707 05:07:00.847381 54857 sgd_solver.cpp:106] Iteration 198400, lr = 5e-06
I0707 05:13:19.809427 54857 solver.cpp:340] Iteration 198500, Testing net (#0)
I0707 05:17:56.366410 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7811
I0707 05:17:56.366564 54857 solver.cpp:408]     Test net output #1: loss = 0.459028 (* 1 = 0.459028 loss)
I0707 05:17:56.626675 54857 solver.cpp:236] Iteration 198500, loss = 0.476616
I0707 05:17:56.626721 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 05:17:56.626739 54857 solver.cpp:252]     Train net output #1: loss = 0.505155 (* 1 = 0.505155 loss)
I0707 05:17:56.626759 54857 sgd_solver.cpp:106] Iteration 198500, lr = 5e-06
I0707 05:19:56.179788 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 05:24:02.364204 54857 solver.cpp:236] Iteration 198600, loss = 0.463202
I0707 05:24:02.364450 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 05:24:02.364495 54857 solver.cpp:252]     Train net output #1: loss = 0.473233 (* 1 = 0.473233 loss)
I0707 05:24:02.364511 54857 sgd_solver.cpp:106] Iteration 198600, lr = 5e-06
I0707 05:30:44.441642 54857 solver.cpp:236] Iteration 198700, loss = 0.473693
I0707 05:30:44.473255 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 05:30:44.473287 54857 solver.cpp:252]     Train net output #1: loss = 0.546917 (* 1 = 0.546917 loss)
I0707 05:30:44.473299 54857 sgd_solver.cpp:106] Iteration 198700, lr = 5e-06
I0707 05:33:55.514199 54857 solver.cpp:340] Iteration 198750, Testing net (#0)
I0707 05:38:46.912930 54857 solver.cpp:408]     Test net output #0: accuracy = 0.784
I0707 05:38:46.913081 54857 solver.cpp:408]     Test net output #1: loss = 0.456175 (* 1 = 0.456175 loss)
I0707 05:41:46.139008 54857 solver.cpp:236] Iteration 198800, loss = 0.461778
I0707 05:41:46.139220 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 05:41:46.139240 54857 solver.cpp:252]     Train net output #1: loss = 0.590038 (* 1 = 0.590038 loss)
I0707 05:41:46.139257 54857 sgd_solver.cpp:106] Iteration 198800, lr = 5e-06
I0707 05:47:57.328001 54857 solver.cpp:236] Iteration 198900, loss = 0.469825
I0707 05:47:57.328178 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 05:47:57.328222 54857 solver.cpp:252]     Train net output #1: loss = 0.489601 (* 1 = 0.489601 loss)
I0707 05:47:57.328236 54857 sgd_solver.cpp:106] Iteration 198900, lr = 5e-06
I0707 05:54:24.864073 54857 solver.cpp:340] Iteration 199000, Testing net (#0)
I0707 05:59:24.063024 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7821
I0707 05:59:24.074674 54857 solver.cpp:408]     Test net output #1: loss = 0.467918 (* 1 = 0.467918 loss)
I0707 05:59:24.206264 54857 solver.cpp:236] Iteration 199000, loss = 0.459265
I0707 05:59:24.206310 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 05:59:24.206327 54857 solver.cpp:252]     Train net output #1: loss = 0.486819 (* 1 = 0.486819 loss)
I0707 05:59:24.206343 54857 sgd_solver.cpp:106] Iteration 199000, lr = 5e-06
I0707 06:05:37.863850 54857 solver.cpp:236] Iteration 199100, loss = 0.450262
I0707 06:05:37.884819 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 06:05:37.884856 54857 solver.cpp:252]     Train net output #1: loss = 0.489351 (* 1 = 0.489351 loss)
I0707 06:05:37.884881 54857 sgd_solver.cpp:106] Iteration 199100, lr = 5e-06
I0707 06:11:48.816093 54857 solver.cpp:236] Iteration 199200, loss = 0.479784
I0707 06:11:48.816284 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 06:11:48.816332 54857 solver.cpp:252]     Train net output #1: loss = 0.509871 (* 1 = 0.509871 loss)
I0707 06:11:48.816354 54857 sgd_solver.cpp:106] Iteration 199200, lr = 5e-06
I0707 06:14:51.344564 54857 solver.cpp:340] Iteration 199250, Testing net (#0)
I0707 06:19:55.744833 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7819
I0707 06:19:55.744984 54857 solver.cpp:408]     Test net output #1: loss = 0.461481 (* 1 = 0.461481 loss)
I0707 06:19:57.843246 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 06:23:09.794313 54857 solver.cpp:236] Iteration 199300, loss = 0.477179
I0707 06:23:09.794491 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 06:23:09.794528 54857 solver.cpp:252]     Train net output #1: loss = 0.565913 (* 1 = 0.565913 loss)
I0707 06:23:09.794544 54857 sgd_solver.cpp:106] Iteration 199300, lr = 5e-06
I0707 06:30:38.879014 54857 solver.cpp:236] Iteration 199400, loss = 0.475753
I0707 06:30:38.908296 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 06:30:38.908327 54857 solver.cpp:252]     Train net output #1: loss = 0.469578 (* 1 = 0.469578 loss)
I0707 06:30:38.908344 54857 sgd_solver.cpp:106] Iteration 199400, lr = 5e-06
I0707 06:37:36.476265 54857 solver.cpp:340] Iteration 199500, Testing net (#0)
I0707 06:42:33.129009 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7834
I0707 06:42:33.142832 54857 solver.cpp:408]     Test net output #1: loss = 0.458891 (* 1 = 0.458891 loss)
I0707 06:42:33.322795 54857 solver.cpp:236] Iteration 199500, loss = 0.46637
I0707 06:42:33.322839 54857 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 06:42:33.322854 54857 solver.cpp:252]     Train net output #1: loss = 0.393999 (* 1 = 0.393999 loss)
I0707 06:42:33.322871 54857 sgd_solver.cpp:106] Iteration 199500, lr = 5e-06
I0707 06:49:16.806012 54857 solver.cpp:236] Iteration 199600, loss = 0.459737
I0707 06:49:16.829424 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 06:49:16.829463 54857 solver.cpp:252]     Train net output #1: loss = 0.466886 (* 1 = 0.466886 loss)
I0707 06:49:16.829480 54857 sgd_solver.cpp:106] Iteration 199600, lr = 5e-06
I0707 06:55:43.805992 54857 solver.cpp:236] Iteration 199700, loss = 0.46996
I0707 06:55:43.824429 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 06:55:43.824465 54857 solver.cpp:252]     Train net output #1: loss = 0.476656 (* 1 = 0.476656 loss)
I0707 06:55:43.824482 54857 sgd_solver.cpp:106] Iteration 199700, lr = 5e-06
I0707 06:58:48.617714 54857 solver.cpp:340] Iteration 199750, Testing net (#0)
I0707 07:03:21.820235 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7832
I0707 07:03:21.820427 54857 solver.cpp:408]     Test net output #1: loss = 0.455281 (* 1 = 0.455281 loss)
I0707 07:06:23.590502 54857 solver.cpp:236] Iteration 199800, loss = 0.469247
I0707 07:06:23.590678 54857 solver.cpp:252]     Train net output #0: accuracy = 0.84375
I0707 07:06:23.590723 54857 solver.cpp:252]     Train net output #1: loss = 0.450677 (* 1 = 0.450677 loss)
I0707 07:06:23.590737 54857 sgd_solver.cpp:106] Iteration 199800, lr = 5e-06
I0707 07:13:06.285898 54857 solver.cpp:236] Iteration 199900, loss = 0.472672
I0707 07:13:06.319746 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 07:13:06.319787 54857 solver.cpp:252]     Train net output #1: loss = 0.540723 (* 1 = 0.540723 loss)
I0707 07:13:06.319805 54857 sgd_solver.cpp:106] Iteration 199900, lr = 5e-06
I0707 07:19:33.112274 54857 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_200000.caffemodel
I0707 07:19:33.908018 54857 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_200000.solverstate
I0707 07:19:33.939008 54857 solver.cpp:340] Iteration 200000, Testing net (#0)
I0707 07:22:45.377660 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 07:24:18.489848 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7828
I0707 07:24:18.490597 54857 solver.cpp:408]     Test net output #1: loss = 0.45965 (* 1 = 0.45965 loss)
I0707 07:24:18.639605 54857 solver.cpp:236] Iteration 200000, loss = 0.467166
I0707 07:24:18.639652 54857 solver.cpp:252]     Train net output #0: accuracy = 0.851562
I0707 07:24:18.639668 54857 solver.cpp:252]     Train net output #1: loss = 0.358562 (* 1 = 0.358562 loss)
I0707 07:24:18.639683 54857 sgd_solver.cpp:106] Iteration 200000, lr = 5e-06
I0707 07:30:26.743736 54857 solver.cpp:236] Iteration 200100, loss = 0.464982
I0707 07:30:26.743912 54857 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 07:30:26.743938 54857 solver.cpp:252]     Train net output #1: loss = 0.42087 (* 1 = 0.42087 loss)
I0707 07:30:26.743960 54857 sgd_solver.cpp:106] Iteration 200100, lr = 5e-06
I0707 07:36:58.046691 54857 solver.cpp:236] Iteration 200200, loss = 0.473981
I0707 07:36:58.081529 54857 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 07:36:58.081560 54857 solver.cpp:252]     Train net output #1: loss = 0.383538 (* 1 = 0.383538 loss)
I0707 07:36:58.081580 54857 sgd_solver.cpp:106] Iteration 200200, lr = 5e-06
I0707 07:40:18.017230 54857 solver.cpp:340] Iteration 200250, Testing net (#0)
I0707 07:44:56.400430 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7769
I0707 07:44:56.400696 54857 solver.cpp:408]     Test net output #1: loss = 0.462405 (* 1 = 0.462405 loss)
I0707 07:47:59.323253 54857 solver.cpp:236] Iteration 200300, loss = 0.477084
I0707 07:47:59.323436 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 07:47:59.323462 54857 solver.cpp:252]     Train net output #1: loss = 0.502041 (* 1 = 0.502041 loss)
I0707 07:47:59.323480 54857 sgd_solver.cpp:106] Iteration 200300, lr = 5e-06
I0707 07:54:17.997545 54857 solver.cpp:236] Iteration 200400, loss = 0.464948
I0707 07:54:17.997738 54857 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 07:54:17.997771 54857 solver.cpp:252]     Train net output #1: loss = 0.558202 (* 1 = 0.558202 loss)
I0707 07:54:17.997789 54857 sgd_solver.cpp:106] Iteration 200400, lr = 5e-06
I0707 08:00:43.856266 54857 solver.cpp:340] Iteration 200500, Testing net (#0)
I0707 08:05:51.909724 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7868
I0707 08:05:51.920008 54857 solver.cpp:408]     Test net output #1: loss = 0.460041 (* 1 = 0.460041 loss)
I0707 08:05:52.174396 54857 solver.cpp:236] Iteration 200500, loss = 0.453
I0707 08:05:52.174446 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 08:05:52.174463 54857 solver.cpp:252]     Train net output #1: loss = 0.499041 (* 1 = 0.499041 loss)
I0707 08:05:52.174477 54857 sgd_solver.cpp:106] Iteration 200500, lr = 5e-06
I0707 08:12:11.830063 54857 solver.cpp:236] Iteration 200600, loss = 0.470351
I0707 08:12:11.852061 54857 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 08:12:11.852094 54857 solver.cpp:252]     Train net output #1: loss = 0.503853 (* 1 = 0.503853 loss)
I0707 08:12:11.852108 54857 sgd_solver.cpp:106] Iteration 200600, lr = 5e-06
I0707 08:18:19.152315 54857 solver.cpp:236] Iteration 200700, loss = 0.461233
I0707 08:18:19.152499 54857 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 08:18:19.152519 54857 solver.cpp:252]     Train net output #1: loss = 0.515456 (* 1 = 0.515456 loss)
I0707 08:18:19.152532 54857 sgd_solver.cpp:106] Iteration 200700, lr = 5e-06
I0707 08:21:24.771126 54857 solver.cpp:340] Iteration 200750, Testing net (#0)
I0707 08:23:05.458694 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 08:26:22.230124 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7809
I0707 08:26:22.230284 54857 solver.cpp:408]     Test net output #1: loss = 0.459567 (* 1 = 0.459567 loss)
I0707 08:29:38.220652 54857 solver.cpp:236] Iteration 200800, loss = 0.464703
I0707 08:29:38.262081 54857 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 08:29:38.262118 54857 solver.cpp:252]     Train net output #1: loss = 0.404859 (* 1 = 0.404859 loss)
I0707 08:29:38.262141 54857 sgd_solver.cpp:106] Iteration 200800, lr = 5e-06
I0707 08:36:16.459694 54857 solver.cpp:236] Iteration 200900, loss = 0.457856
I0707 08:36:16.484752 54857 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 08:36:16.484781 54857 solver.cpp:252]     Train net output #1: loss = 0.495964 (* 1 = 0.495964 loss)
I0707 08:36:16.484792 54857 sgd_solver.cpp:106] Iteration 200900, lr = 5e-06
I0707 08:42:27.079213 54857 solver.cpp:340] Iteration 201000, Testing net (#0)
I0707 08:47:13.542991 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7877
I0707 08:47:13.543136 54857 solver.cpp:408]     Test net output #1: loss = 0.453039 (* 1 = 0.453039 loss)
I0707 08:47:13.790691 54857 solver.cpp:236] Iteration 201000, loss = 0.466814
I0707 08:47:13.790735 54857 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 08:47:13.790751 54857 solver.cpp:252]     Train net output #1: loss = 0.470412 (* 1 = 0.470412 loss)
I0707 08:47:13.790768 54857 sgd_solver.cpp:106] Iteration 201000, lr = 5e-06
I0707 08:53:41.507953 54857 solver.cpp:236] Iteration 201100, loss = 0.477579
I0707 08:53:41.529320 54857 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 08:53:41.529355 54857 solver.cpp:252]     Train net output #1: loss = 0.510347 (* 1 = 0.510347 loss)
I0707 08:53:41.529376 54857 sgd_solver.cpp:106] Iteration 201100, lr = 5e-06
I0707 09:00:23.612714 54857 solver.cpp:236] Iteration 201200, loss = 0.46258
I0707 09:00:23.612998 54857 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 09:00:23.613023 54857 solver.cpp:252]     Train net output #1: loss = 0.474294 (* 1 = 0.474294 loss)
I0707 09:00:23.613041 54857 sgd_solver.cpp:106] Iteration 201200, lr = 5e-06
I0707 09:03:35.257102 54857 solver.cpp:340] Iteration 201250, Testing net (#0)
I0707 09:08:28.343936 54857 solver.cpp:408]     Test net output #0: accuracy = 0.7791
I0707 09:08:28.344537 54857 solver.cpp:408]     Test net output #1: loss = 0.468083 (* 1 = 0.468083 loss)
I0707 09:11:27.943562 54857 solver.cpp:236] Iteration 201300, loss = 0.465531
I0707 09:11:27.943733 54857 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 09:11:27.943758 54857 solver.cpp:252]     Train net output #1: loss = 0.466987 (* 1 = 0.466987 loss)
I0707 09:11:27.943774 54857 sgd_solver.cpp:106] Iteration 201300, lr = 5e-06
I0707 09:17:56.902016 54857 solver.cpp:236] Iteration 201400, loss = 0.466344
I0707 09:17:56.902216 54857 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 09:17:56.902256 54857 solver.cpp:252]     Train net output #1: loss = 0.472514 (* 1 = 0.472514 loss)
I0707 09:17:56.902268 54857 sgd_solver.cpp:106] Iteration 201400, lr = 5e-06
I0707 09:24:37.150322 54857 solver.cpp:340] Iteration 201500, Testing net (#0)
I0707 09:24:41.163311 54857 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 09:27:49.697283 54857 solver.cpp:390] Test interrupted.
I0707 09:27:49.731989 54857 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_201500.caffemodel
I0707 09:27:50.278534 54857 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_201500.solverstate
I0707 09:27:50.308168 54857 solver.cpp:308] Optimization stopped early.
I0707 09:27:50.323765 54857 caffe.cpp:215] Optimization Done.
