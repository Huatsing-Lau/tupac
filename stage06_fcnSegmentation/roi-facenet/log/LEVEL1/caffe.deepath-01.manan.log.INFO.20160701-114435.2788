Log file created at: 2016/07/01 11:44:35
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0701 11:44:35.551844  2788 caffe.cpp:184] Using GPUs 3
I0701 11:44:35.840215  2788 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 250
base_lr: 0.01
display: 10
max_iter: 180000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/cnn10"
solver_mode: GPU
device_id: 3
net: "train_val.prototxt.full"
test_initialization: false
average_loss: 50
I0701 11:44:35.840441  2788 solver.cpp:90] Creating training net from net file: train_val.prototxt.full
I0701 11:44:35.841336  2788 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0701 11:44:35.841501  2788 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0701 11:44:35.841621  2788 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0701 11:44:35.841655  2788 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0701 11:44:35.841845  2788 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-train.lst"
    batch_size: 128
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0701 11:44:35.843587  2788 layer_factory.hpp:76] Creating layer data
I0701 11:44:35.843636  2788 net.cpp:106] Creating Layer data
I0701 11:44:35.843652  2788 net.cpp:411] data -> data
I0701 11:44:35.843677  2788 net.cpp:411] data -> label
I0701 11:44:35.844105  2788 image_data_layer.cpp:36] Opening file ../lists/roi-train.lst
I0701 11:44:36.017283  2788 image_data_layer.cpp:46] Shuffling data
I0701 11:44:36.051539  2788 image_data_layer.cpp:51] A total of 211680 images.
I0701 11:44:36.205286  2788 image_data_layer.cpp:78] output data size: 128,3,100,100
I0701 11:44:36.234609  2788 net.cpp:150] Setting up data
I0701 11:44:36.234701  2788 net.cpp:157] Top shape: 128 3 100 100 (3840000)
I0701 11:44:36.234717  2788 net.cpp:157] Top shape: 128 (128)
I0701 11:44:36.234725  2788 net.cpp:165] Memory required for data: 15360512
I0701 11:44:36.234742  2788 layer_factory.hpp:76] Creating layer conv11
I0701 11:44:36.234772  2788 net.cpp:106] Creating Layer conv11
I0701 11:44:36.234788  2788 net.cpp:454] conv11 <- data
I0701 11:44:36.234805  2788 net.cpp:411] conv11 -> conv11
I0701 11:44:36.361101  2788 net.cpp:150] Setting up conv11
I0701 11:44:36.361160  2788 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0701 11:44:36.361169  2788 net.cpp:165] Memory required for data: 179200512
I0701 11:44:36.361198  2788 layer_factory.hpp:76] Creating layer relu11
I0701 11:44:36.361219  2788 net.cpp:106] Creating Layer relu11
I0701 11:44:36.361229  2788 net.cpp:454] relu11 <- conv11
I0701 11:44:36.361241  2788 net.cpp:397] relu11 -> conv11 (in-place)
I0701 11:44:36.361431  2788 net.cpp:150] Setting up relu11
I0701 11:44:36.361459  2788 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0701 11:44:36.361469  2788 net.cpp:165] Memory required for data: 343040512
I0701 11:44:36.361477  2788 layer_factory.hpp:76] Creating layer conv12
I0701 11:44:36.361495  2788 net.cpp:106] Creating Layer conv12
I0701 11:44:36.361503  2788 net.cpp:454] conv12 <- conv11
I0701 11:44:36.361513  2788 net.cpp:411] conv12 -> conv12
I0701 11:44:36.363293  2788 net.cpp:150] Setting up conv12
I0701 11:44:36.363332  2788 net.cpp:157] Top shape: 128 64 100 100 (81920000)
I0701 11:44:36.363342  2788 net.cpp:165] Memory required for data: 670720512
I0701 11:44:36.363356  2788 layer_factory.hpp:76] Creating layer relu12
I0701 11:44:36.363370  2788 net.cpp:106] Creating Layer relu12
I0701 11:44:36.363380  2788 net.cpp:454] relu12 <- conv12
I0701 11:44:36.363390  2788 net.cpp:397] relu12 -> conv12 (in-place)
I0701 11:44:36.363711  2788 net.cpp:150] Setting up relu12
I0701 11:44:36.363742  2788 net.cpp:157] Top shape: 128 64 100 100 (81920000)
I0701 11:44:36.363751  2788 net.cpp:165] Memory required for data: 998400512
I0701 11:44:36.363765  2788 layer_factory.hpp:76] Creating layer pool1
I0701 11:44:36.363778  2788 net.cpp:106] Creating Layer pool1
I0701 11:44:36.363787  2788 net.cpp:454] pool1 <- conv12
I0701 11:44:36.363797  2788 net.cpp:411] pool1 -> pool1
I0701 11:44:36.364033  2788 net.cpp:150] Setting up pool1
I0701 11:44:36.364063  2788 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0701 11:44:36.364073  2788 net.cpp:165] Memory required for data: 1080320512
I0701 11:44:36.364081  2788 layer_factory.hpp:76] Creating layer conv21
I0701 11:44:36.364099  2788 net.cpp:106] Creating Layer conv21
I0701 11:44:36.364107  2788 net.cpp:454] conv21 <- pool1
I0701 11:44:36.364120  2788 net.cpp:411] conv21 -> conv21
I0701 11:44:36.365900  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0701 11:44:36.366127  2788 net.cpp:150] Setting up conv21
I0701 11:44:36.366158  2788 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0701 11:44:36.366166  2788 net.cpp:165] Memory required for data: 1162240512
I0701 11:44:36.366181  2788 layer_factory.hpp:76] Creating layer relu21
I0701 11:44:36.366196  2788 net.cpp:106] Creating Layer relu21
I0701 11:44:36.366205  2788 net.cpp:454] relu21 <- conv21
I0701 11:44:36.366215  2788 net.cpp:397] relu21 -> conv21 (in-place)
I0701 11:44:36.366544  2788 net.cpp:150] Setting up relu21
I0701 11:44:36.366575  2788 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0701 11:44:36.366585  2788 net.cpp:165] Memory required for data: 1244160512
I0701 11:44:36.366593  2788 layer_factory.hpp:76] Creating layer conv22
I0701 11:44:36.366612  2788 net.cpp:106] Creating Layer conv22
I0701 11:44:36.366621  2788 net.cpp:454] conv22 <- conv21
I0701 11:44:36.366632  2788 net.cpp:411] conv22 -> conv22
I0701 11:44:36.368631  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0701 11:44:36.368677  2788 net.cpp:150] Setting up conv22
I0701 11:44:36.368692  2788 net.cpp:157] Top shape: 128 128 50 50 (40960000)
I0701 11:44:36.368724  2788 net.cpp:165] Memory required for data: 1408000512
I0701 11:44:36.368737  2788 layer_factory.hpp:76] Creating layer relu22
I0701 11:44:36.368749  2788 net.cpp:106] Creating Layer relu22
I0701 11:44:36.368758  2788 net.cpp:454] relu22 <- conv22
I0701 11:44:36.368768  2788 net.cpp:397] relu22 -> conv22 (in-place)
I0701 11:44:36.369094  2788 net.cpp:150] Setting up relu22
I0701 11:44:36.369125  2788 net.cpp:157] Top shape: 128 128 50 50 (40960000)
I0701 11:44:36.369134  2788 net.cpp:165] Memory required for data: 1571840512
I0701 11:44:36.369144  2788 layer_factory.hpp:76] Creating layer pool2
I0701 11:44:36.369155  2788 net.cpp:106] Creating Layer pool2
I0701 11:44:36.369164  2788 net.cpp:454] pool2 <- conv22
I0701 11:44:36.369174  2788 net.cpp:411] pool2 -> pool2
I0701 11:44:36.369386  2788 net.cpp:150] Setting up pool2
I0701 11:44:36.369415  2788 net.cpp:157] Top shape: 128 128 25 25 (10240000)
I0701 11:44:36.369423  2788 net.cpp:165] Memory required for data: 1612800512
I0701 11:44:36.369432  2788 layer_factory.hpp:76] Creating layer conv31
I0701 11:44:36.369448  2788 net.cpp:106] Creating Layer conv31
I0701 11:44:36.369457  2788 net.cpp:454] conv31 <- pool2
I0701 11:44:36.369469  2788 net.cpp:411] conv31 -> conv31
I0701 11:44:36.371222  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0701 11:44:36.371268  2788 net.cpp:150] Setting up conv31
I0701 11:44:36.371280  2788 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0701 11:44:36.371289  2788 net.cpp:165] Memory required for data: 1643520512
I0701 11:44:36.371306  2788 layer_factory.hpp:76] Creating layer relu31
I0701 11:44:36.371318  2788 net.cpp:106] Creating Layer relu31
I0701 11:44:36.371326  2788 net.cpp:454] relu31 <- conv31
I0701 11:44:36.371336  2788 net.cpp:397] relu31 -> conv31 (in-place)
I0701 11:44:36.371664  2788 net.cpp:150] Setting up relu31
I0701 11:44:36.371695  2788 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0701 11:44:36.371702  2788 net.cpp:165] Memory required for data: 1674240512
I0701 11:44:36.371711  2788 layer_factory.hpp:76] Creating layer conv32
I0701 11:44:36.371726  2788 net.cpp:106] Creating Layer conv32
I0701 11:44:36.371737  2788 net.cpp:454] conv32 <- conv31
I0701 11:44:36.371747  2788 net.cpp:411] conv32 -> conv32
I0701 11:44:36.374469  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0701 11:44:36.374511  2788 net.cpp:150] Setting up conv32
I0701 11:44:36.374523  2788 net.cpp:157] Top shape: 128 192 25 25 (15360000)
I0701 11:44:36.374532  2788 net.cpp:165] Memory required for data: 1735680512
I0701 11:44:36.374543  2788 layer_factory.hpp:76] Creating layer relu32
I0701 11:44:36.374557  2788 net.cpp:106] Creating Layer relu32
I0701 11:44:36.374567  2788 net.cpp:454] relu32 <- conv32
I0701 11:44:36.374577  2788 net.cpp:397] relu32 -> conv32 (in-place)
I0701 11:44:36.374768  2788 net.cpp:150] Setting up relu32
I0701 11:44:36.374795  2788 net.cpp:157] Top shape: 128 192 25 25 (15360000)
I0701 11:44:36.374804  2788 net.cpp:165] Memory required for data: 1797120512
I0701 11:44:36.374812  2788 layer_factory.hpp:76] Creating layer pool3
I0701 11:44:36.374824  2788 net.cpp:106] Creating Layer pool3
I0701 11:44:36.374831  2788 net.cpp:454] pool3 <- conv32
I0701 11:44:36.374841  2788 net.cpp:411] pool3 -> pool3
I0701 11:44:36.375224  2788 net.cpp:150] Setting up pool3
I0701 11:44:36.375255  2788 net.cpp:157] Top shape: 128 192 13 13 (4153344)
I0701 11:44:36.375264  2788 net.cpp:165] Memory required for data: 1813733888
I0701 11:44:36.375274  2788 layer_factory.hpp:76] Creating layer conv41
I0701 11:44:36.375291  2788 net.cpp:106] Creating Layer conv41
I0701 11:44:36.375301  2788 net.cpp:454] conv41 <- pool3
I0701 11:44:36.375314  2788 net.cpp:411] conv41 -> conv41
I0701 11:44:36.378476  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20736
I0701 11:44:36.378717  2788 net.cpp:150] Setting up conv41
I0701 11:44:36.378751  2788 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0701 11:44:36.378759  2788 net.cpp:165] Memory required for data: 1824809472
I0701 11:44:36.378787  2788 layer_factory.hpp:76] Creating layer relu41
I0701 11:44:36.378800  2788 net.cpp:106] Creating Layer relu41
I0701 11:44:36.378809  2788 net.cpp:454] relu41 <- conv41
I0701 11:44:36.378820  2788 net.cpp:397] relu41 -> conv41 (in-place)
I0701 11:44:36.379206  2788 net.cpp:150] Setting up relu41
I0701 11:44:36.379238  2788 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0701 11:44:36.379247  2788 net.cpp:165] Memory required for data: 1835885056
I0701 11:44:36.379256  2788 layer_factory.hpp:76] Creating layer conv42
I0701 11:44:36.379273  2788 net.cpp:106] Creating Layer conv42
I0701 11:44:36.379282  2788 net.cpp:454] conv42 <- conv41
I0701 11:44:36.379295  2788 net.cpp:411] conv42 -> conv42
I0701 11:44:36.382979  2788 net.cpp:150] Setting up conv42
I0701 11:44:36.383014  2788 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0701 11:44:36.383023  2788 net.cpp:165] Memory required for data: 1858036224
I0701 11:44:36.383035  2788 layer_factory.hpp:76] Creating layer relu42
I0701 11:44:36.383049  2788 net.cpp:106] Creating Layer relu42
I0701 11:44:36.383057  2788 net.cpp:454] relu42 <- conv42
I0701 11:44:36.383067  2788 net.cpp:397] relu42 -> conv42 (in-place)
I0701 11:44:36.383256  2788 net.cpp:150] Setting up relu42
I0701 11:44:36.383285  2788 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0701 11:44:36.383293  2788 net.cpp:165] Memory required for data: 1880187392
I0701 11:44:36.383302  2788 layer_factory.hpp:76] Creating layer pool4
I0701 11:44:36.383316  2788 net.cpp:106] Creating Layer pool4
I0701 11:44:36.383324  2788 net.cpp:454] pool4 <- conv42
I0701 11:44:36.383334  2788 net.cpp:411] pool4 -> pool4
I0701 11:44:36.383689  2788 net.cpp:150] Setting up pool4
I0701 11:44:36.383720  2788 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0701 11:44:36.383728  2788 net.cpp:165] Memory required for data: 1886609920
I0701 11:44:36.383738  2788 layer_factory.hpp:76] Creating layer conv51
I0701 11:44:36.383754  2788 net.cpp:106] Creating Layer conv51
I0701 11:44:36.383764  2788 net.cpp:454] conv51 <- pool4
I0701 11:44:36.383775  2788 net.cpp:411] conv51 -> conv51
I0701 11:44:36.388133  2788 net.cpp:150] Setting up conv51
I0701 11:44:36.388173  2788 net.cpp:157] Top shape: 128 160 7 7 (1003520)
I0701 11:44:36.388185  2788 net.cpp:165] Memory required for data: 1890624000
I0701 11:44:36.388202  2788 layer_factory.hpp:76] Creating layer relu51
I0701 11:44:36.388214  2788 net.cpp:106] Creating Layer relu51
I0701 11:44:36.388222  2788 net.cpp:454] relu51 <- conv51
I0701 11:44:36.388233  2788 net.cpp:397] relu51 -> conv51 (in-place)
I0701 11:44:36.388445  2788 net.cpp:150] Setting up relu51
I0701 11:44:36.388463  2788 net.cpp:157] Top shape: 128 160 7 7 (1003520)
I0701 11:44:36.388473  2788 net.cpp:165] Memory required for data: 1894638080
I0701 11:44:36.388480  2788 layer_factory.hpp:76] Creating layer conv52
I0701 11:44:36.388495  2788 net.cpp:106] Creating Layer conv52
I0701 11:44:36.388509  2788 net.cpp:454] conv52 <- conv51
I0701 11:44:36.388522  2788 net.cpp:411] conv52 -> conv52
I0701 11:44:36.393635  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 17280
I0701 11:44:36.393682  2788 net.cpp:150] Setting up conv52
I0701 11:44:36.393694  2788 net.cpp:157] Top shape: 128 320 7 7 (2007040)
I0701 11:44:36.393702  2788 net.cpp:165] Memory required for data: 1902666240
I0701 11:44:36.393714  2788 layer_factory.hpp:76] Creating layer relu52
I0701 11:44:36.393728  2788 net.cpp:106] Creating Layer relu52
I0701 11:44:36.393738  2788 net.cpp:454] relu52 <- conv52
I0701 11:44:36.393748  2788 net.cpp:397] relu52 -> conv52 (in-place)
I0701 11:44:36.394079  2788 net.cpp:150] Setting up relu52
I0701 11:44:36.394114  2788 net.cpp:157] Top shape: 128 320 7 7 (2007040)
I0701 11:44:36.394124  2788 net.cpp:165] Memory required for data: 1910694400
I0701 11:44:36.394131  2788 layer_factory.hpp:76] Creating layer conv53
I0701 11:44:36.394145  2788 net.cpp:106] Creating Layer conv53
I0701 11:44:36.394155  2788 net.cpp:454] conv53 <- conv52
I0701 11:44:36.394166  2788 net.cpp:411] conv53 -> conv53
I0701 11:44:36.441193  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 188160
I0701 11:44:36.441476  2788 net.cpp:150] Setting up conv53
I0701 11:44:36.441514  2788 net.cpp:157] Top shape: 128 320 1 1 (40960)
I0701 11:44:36.441524  2788 net.cpp:165] Memory required for data: 1910858240
I0701 11:44:36.441540  2788 layer_factory.hpp:76] Creating layer relu53
I0701 11:44:36.441556  2788 net.cpp:106] Creating Layer relu53
I0701 11:44:36.441566  2788 net.cpp:454] relu53 <- conv53
I0701 11:44:36.441578  2788 net.cpp:397] relu53 -> conv53 (in-place)
I0701 11:44:36.441917  2788 net.cpp:150] Setting up relu53
I0701 11:44:36.441948  2788 net.cpp:157] Top shape: 128 320 1 1 (40960)
I0701 11:44:36.441956  2788 net.cpp:165] Memory required for data: 1911022080
I0701 11:44:36.441967  2788 layer_factory.hpp:76] Creating layer drop6
I0701 11:44:36.441982  2788 net.cpp:106] Creating Layer drop6
I0701 11:44:36.441992  2788 net.cpp:454] drop6 <- conv53
I0701 11:44:36.442004  2788 net.cpp:411] drop6 -> drop6
I0701 11:44:36.442062  2788 net.cpp:150] Setting up drop6
I0701 11:44:36.442075  2788 net.cpp:157] Top shape: 128 320 1 1 (40960)
I0701 11:44:36.442085  2788 net.cpp:165] Memory required for data: 1911185920
I0701 11:44:36.442092  2788 layer_factory.hpp:76] Creating layer conv54
I0701 11:44:36.442109  2788 net.cpp:106] Creating Layer conv54
I0701 11:44:36.442118  2788 net.cpp:454] conv54 <- drop6
I0701 11:44:36.442131  2788 net.cpp:411] conv54 -> conv54
I0701 11:44:36.443161  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3840
I0701 11:44:36.443389  2788 net.cpp:150] Setting up conv54
I0701 11:44:36.443420  2788 net.cpp:157] Top shape: 128 2 1 1 (256)
I0701 11:44:36.443429  2788 net.cpp:165] Memory required for data: 1911186944
I0701 11:44:36.443441  2788 layer_factory.hpp:76] Creating layer loss
I0701 11:44:36.443456  2788 net.cpp:106] Creating Layer loss
I0701 11:44:36.443465  2788 net.cpp:454] loss <- conv54
I0701 11:44:36.443475  2788 net.cpp:454] loss <- label
I0701 11:44:36.443490  2788 net.cpp:411] loss -> loss
I0701 11:44:36.469101  2788 layer_factory.hpp:76] Creating layer loss
I0701 11:44:36.469449  2788 net.cpp:150] Setting up loss
I0701 11:44:36.469480  2788 net.cpp:157] Top shape: (1)
I0701 11:44:36.469487  2788 net.cpp:160]     with loss weight 1
I0701 11:44:36.469513  2788 net.cpp:165] Memory required for data: 1911186948
I0701 11:44:36.469522  2788 net.cpp:226] loss needs backward computation.
I0701 11:44:36.469532  2788 net.cpp:226] conv54 needs backward computation.
I0701 11:44:36.469542  2788 net.cpp:226] drop6 needs backward computation.
I0701 11:44:36.469549  2788 net.cpp:226] relu53 needs backward computation.
I0701 11:44:36.469558  2788 net.cpp:226] conv53 needs backward computation.
I0701 11:44:36.469566  2788 net.cpp:226] relu52 needs backward computation.
I0701 11:44:36.469574  2788 net.cpp:226] conv52 needs backward computation.
I0701 11:44:36.469583  2788 net.cpp:226] relu51 needs backward computation.
I0701 11:44:36.469590  2788 net.cpp:226] conv51 needs backward computation.
I0701 11:44:36.469599  2788 net.cpp:226] pool4 needs backward computation.
I0701 11:44:36.469607  2788 net.cpp:226] relu42 needs backward computation.
I0701 11:44:36.469615  2788 net.cpp:226] conv42 needs backward computation.
I0701 11:44:36.469624  2788 net.cpp:226] relu41 needs backward computation.
I0701 11:44:36.469631  2788 net.cpp:226] conv41 needs backward computation.
I0701 11:44:36.469640  2788 net.cpp:226] pool3 needs backward computation.
I0701 11:44:36.469647  2788 net.cpp:226] relu32 needs backward computation.
I0701 11:44:36.469655  2788 net.cpp:226] conv32 needs backward computation.
I0701 11:44:36.469663  2788 net.cpp:226] relu31 needs backward computation.
I0701 11:44:36.469671  2788 net.cpp:226] conv31 needs backward computation.
I0701 11:44:36.469679  2788 net.cpp:226] pool2 needs backward computation.
I0701 11:44:36.469687  2788 net.cpp:226] relu22 needs backward computation.
I0701 11:44:36.469696  2788 net.cpp:226] conv22 needs backward computation.
I0701 11:44:36.469703  2788 net.cpp:226] relu21 needs backward computation.
I0701 11:44:36.469727  2788 net.cpp:226] conv21 needs backward computation.
I0701 11:44:36.469738  2788 net.cpp:226] pool1 needs backward computation.
I0701 11:44:36.469748  2788 net.cpp:226] relu12 needs backward computation.
I0701 11:44:36.469758  2788 net.cpp:226] conv12 needs backward computation.
I0701 11:44:36.469765  2788 net.cpp:226] relu11 needs backward computation.
I0701 11:44:36.469774  2788 net.cpp:226] conv11 needs backward computation.
I0701 11:44:36.469782  2788 net.cpp:228] data does not need backward computation.
I0701 11:44:36.469791  2788 net.cpp:270] This network produces output loss
I0701 11:44:36.469815  2788 net.cpp:283] Network initialization done.
I0701 11:44:36.470572  2788 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0701 11:44:36.470692  2788 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0701 11:44:36.470741  2788 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt.full
I0701 11:44:36.470790  2788 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0701 11:44:36.471000  2788 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-val.lst"
    batch_size: 32
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0701 11:44:36.472674  2788 layer_factory.hpp:76] Creating layer data
I0701 11:44:36.472710  2788 net.cpp:106] Creating Layer data
I0701 11:44:36.472721  2788 net.cpp:411] data -> data
I0701 11:44:36.472735  2788 net.cpp:411] data -> label
I0701 11:44:36.472767  2788 image_data_layer.cpp:36] Opening file ../lists/roi-val.lst
I0701 11:44:36.576623  2788 image_data_layer.cpp:46] Shuffling data
I0701 11:44:36.578320  2788 image_data_layer.cpp:51] A total of 23520 images.
I0701 11:44:36.638490  2788 image_data_layer.cpp:78] output data size: 32,3,100,100
I0701 11:44:36.646257  2788 net.cpp:150] Setting up data
I0701 11:44:36.646301  2788 net.cpp:157] Top shape: 32 3 100 100 (960000)
I0701 11:44:36.646312  2788 net.cpp:157] Top shape: 32 (32)
I0701 11:44:36.646320  2788 net.cpp:165] Memory required for data: 3840128
I0701 11:44:36.646332  2788 layer_factory.hpp:76] Creating layer label_data_1_split
I0701 11:44:36.646366  2788 net.cpp:106] Creating Layer label_data_1_split
I0701 11:44:36.646376  2788 net.cpp:454] label_data_1_split <- label
I0701 11:44:36.646389  2788 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0701 11:44:36.646404  2788 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0701 11:44:36.646464  2788 net.cpp:150] Setting up label_data_1_split
I0701 11:44:36.646477  2788 net.cpp:157] Top shape: 32 (32)
I0701 11:44:36.646502  2788 net.cpp:157] Top shape: 32 (32)
I0701 11:44:36.646510  2788 net.cpp:165] Memory required for data: 3840384
I0701 11:44:36.646522  2788 layer_factory.hpp:76] Creating layer conv11
I0701 11:44:36.646540  2788 net.cpp:106] Creating Layer conv11
I0701 11:44:36.646549  2788 net.cpp:454] conv11 <- data
I0701 11:44:36.646559  2788 net.cpp:411] conv11 -> conv11
I0701 11:44:36.647966  2788 net.cpp:150] Setting up conv11
I0701 11:44:36.648001  2788 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0701 11:44:36.648011  2788 net.cpp:165] Memory required for data: 44800384
I0701 11:44:36.648027  2788 layer_factory.hpp:76] Creating layer relu11
I0701 11:44:36.648041  2788 net.cpp:106] Creating Layer relu11
I0701 11:44:36.648062  2788 net.cpp:454] relu11 <- conv11
I0701 11:44:36.648072  2788 net.cpp:397] relu11 -> conv11 (in-place)
I0701 11:44:36.648404  2788 net.cpp:150] Setting up relu11
I0701 11:44:36.648442  2788 net.cpp:157] Top shape: 32 32 100 100 (10240000)
I0701 11:44:36.648452  2788 net.cpp:165] Memory required for data: 85760384
I0701 11:44:36.648459  2788 layer_factory.hpp:76] Creating layer conv12
I0701 11:44:36.648474  2788 net.cpp:106] Creating Layer conv12
I0701 11:44:36.648483  2788 net.cpp:454] conv12 <- conv11
I0701 11:44:36.648510  2788 net.cpp:411] conv12 -> conv12
I0701 11:44:36.649691  2788 net.cpp:150] Setting up conv12
I0701 11:44:36.649713  2788 net.cpp:157] Top shape: 32 64 100 100 (20480000)
I0701 11:44:36.649722  2788 net.cpp:165] Memory required for data: 167680384
I0701 11:44:36.649736  2788 layer_factory.hpp:76] Creating layer relu12
I0701 11:44:36.649749  2788 net.cpp:106] Creating Layer relu12
I0701 11:44:36.649768  2788 net.cpp:454] relu12 <- conv12
I0701 11:44:36.649781  2788 net.cpp:397] relu12 -> conv12 (in-place)
I0701 11:44:36.650321  2788 net.cpp:150] Setting up relu12
I0701 11:44:36.650341  2788 net.cpp:157] Top shape: 32 64 100 100 (20480000)
I0701 11:44:36.650351  2788 net.cpp:165] Memory required for data: 249600384
I0701 11:44:36.650358  2788 layer_factory.hpp:76] Creating layer pool1
I0701 11:44:36.650382  2788 net.cpp:106] Creating Layer pool1
I0701 11:44:36.650390  2788 net.cpp:454] pool1 <- conv12
I0701 11:44:36.650403  2788 net.cpp:411] pool1 -> pool1
I0701 11:44:36.650648  2788 net.cpp:150] Setting up pool1
I0701 11:44:36.650665  2788 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0701 11:44:36.650676  2788 net.cpp:165] Memory required for data: 270080384
I0701 11:44:36.650684  2788 layer_factory.hpp:76] Creating layer conv21
I0701 11:44:36.650709  2788 net.cpp:106] Creating Layer conv21
I0701 11:44:36.650717  2788 net.cpp:454] conv21 <- pool1
I0701 11:44:36.650730  2788 net.cpp:411] conv21 -> conv21
I0701 11:44:36.652848  2788 net.cpp:150] Setting up conv21
I0701 11:44:36.652871  2788 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0701 11:44:36.652880  2788 net.cpp:165] Memory required for data: 290560384
I0701 11:44:36.652895  2788 layer_factory.hpp:76] Creating layer relu21
I0701 11:44:36.652943  2788 net.cpp:106] Creating Layer relu21
I0701 11:44:36.652952  2788 net.cpp:454] relu21 <- conv21
I0701 11:44:36.652966  2788 net.cpp:397] relu21 -> conv21 (in-place)
I0701 11:44:36.653324  2788 net.cpp:150] Setting up relu21
I0701 11:44:36.653345  2788 net.cpp:157] Top shape: 32 64 50 50 (5120000)
I0701 11:44:36.653353  2788 net.cpp:165] Memory required for data: 311040384
I0701 11:44:36.653362  2788 layer_factory.hpp:76] Creating layer conv22
I0701 11:44:36.653388  2788 net.cpp:106] Creating Layer conv22
I0701 11:44:36.653398  2788 net.cpp:454] conv22 <- conv21
I0701 11:44:36.653411  2788 net.cpp:411] conv22 -> conv22
I0701 11:44:36.655001  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0701 11:44:36.655053  2788 net.cpp:150] Setting up conv22
I0701 11:44:36.655066  2788 net.cpp:157] Top shape: 32 128 50 50 (10240000)
I0701 11:44:36.655086  2788 net.cpp:165] Memory required for data: 352000384
I0701 11:44:36.655098  2788 layer_factory.hpp:76] Creating layer relu22
I0701 11:44:36.655112  2788 net.cpp:106] Creating Layer relu22
I0701 11:44:36.655122  2788 net.cpp:454] relu22 <- conv22
I0701 11:44:36.655131  2788 net.cpp:397] relu22 -> conv22 (in-place)
I0701 11:44:36.655331  2788 net.cpp:150] Setting up relu22
I0701 11:44:36.655359  2788 net.cpp:157] Top shape: 32 128 50 50 (10240000)
I0701 11:44:36.655367  2788 net.cpp:165] Memory required for data: 392960384
I0701 11:44:36.655376  2788 layer_factory.hpp:76] Creating layer pool2
I0701 11:44:36.655390  2788 net.cpp:106] Creating Layer pool2
I0701 11:44:36.655397  2788 net.cpp:454] pool2 <- conv22
I0701 11:44:36.655421  2788 net.cpp:411] pool2 -> pool2
I0701 11:44:36.655843  2788 net.cpp:150] Setting up pool2
I0701 11:44:36.655874  2788 net.cpp:157] Top shape: 32 128 25 25 (2560000)
I0701 11:44:36.655882  2788 net.cpp:165] Memory required for data: 403200384
I0701 11:44:36.655890  2788 layer_factory.hpp:76] Creating layer conv31
I0701 11:44:36.655906  2788 net.cpp:106] Creating Layer conv31
I0701 11:44:36.655915  2788 net.cpp:454] conv31 <- pool2
I0701 11:44:36.655937  2788 net.cpp:411] conv31 -> conv31
I0701 11:44:36.658187  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0701 11:44:36.658237  2788 net.cpp:150] Setting up conv31
I0701 11:44:36.658249  2788 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0701 11:44:36.658257  2788 net.cpp:165] Memory required for data: 410880384
I0701 11:44:36.658284  2788 layer_factory.hpp:76] Creating layer relu31
I0701 11:44:36.658296  2788 net.cpp:106] Creating Layer relu31
I0701 11:44:36.658305  2788 net.cpp:454] relu31 <- conv31
I0701 11:44:36.658318  2788 net.cpp:397] relu31 -> conv31 (in-place)
I0701 11:44:36.658660  2788 net.cpp:150] Setting up relu31
I0701 11:44:36.658690  2788 net.cpp:157] Top shape: 32 96 25 25 (1920000)
I0701 11:44:36.658699  2788 net.cpp:165] Memory required for data: 418560384
I0701 11:44:36.658706  2788 layer_factory.hpp:76] Creating layer conv32
I0701 11:44:36.658722  2788 net.cpp:106] Creating Layer conv32
I0701 11:44:36.658730  2788 net.cpp:454] conv32 <- conv31
I0701 11:44:36.658756  2788 net.cpp:411] conv32 -> conv32
I0701 11:44:36.661707  2788 net.cpp:150] Setting up conv32
I0701 11:44:36.661752  2788 net.cpp:157] Top shape: 32 192 25 25 (3840000)
I0701 11:44:36.661761  2788 net.cpp:165] Memory required for data: 433920384
I0701 11:44:36.661773  2788 layer_factory.hpp:76] Creating layer relu32
I0701 11:44:36.661785  2788 net.cpp:106] Creating Layer relu32
I0701 11:44:36.661805  2788 net.cpp:454] relu32 <- conv32
I0701 11:44:36.661826  2788 net.cpp:397] relu32 -> conv32 (in-place)
I0701 11:44:36.662032  2788 net.cpp:150] Setting up relu32
I0701 11:44:36.662060  2788 net.cpp:157] Top shape: 32 192 25 25 (3840000)
I0701 11:44:36.662080  2788 net.cpp:165] Memory required for data: 449280384
I0701 11:44:36.662089  2788 layer_factory.hpp:76] Creating layer pool3
I0701 11:44:36.662104  2788 net.cpp:106] Creating Layer pool3
I0701 11:44:36.662113  2788 net.cpp:454] pool3 <- conv32
I0701 11:44:36.662123  2788 net.cpp:411] pool3 -> pool3
I0701 11:44:36.662591  2788 net.cpp:150] Setting up pool3
I0701 11:44:36.662624  2788 net.cpp:157] Top shape: 32 192 13 13 (1038336)
I0701 11:44:36.662645  2788 net.cpp:165] Memory required for data: 453433728
I0701 11:44:36.662653  2788 layer_factory.hpp:76] Creating layer conv41
I0701 11:44:36.662667  2788 net.cpp:106] Creating Layer conv41
I0701 11:44:36.662675  2788 net.cpp:454] conv41 <- pool3
I0701 11:44:36.662699  2788 net.cpp:411] conv41 -> conv41
I0701 11:44:36.665841  2788 net.cpp:150] Setting up conv41
I0701 11:44:36.665874  2788 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0701 11:44:36.665882  2788 net.cpp:165] Memory required for data: 456202624
I0701 11:44:36.665894  2788 layer_factory.hpp:76] Creating layer relu41
I0701 11:44:36.665907  2788 net.cpp:106] Creating Layer relu41
I0701 11:44:36.665916  2788 net.cpp:454] relu41 <- conv41
I0701 11:44:36.665938  2788 net.cpp:397] relu41 -> conv41 (in-place)
I0701 11:44:36.666144  2788 net.cpp:150] Setting up relu41
I0701 11:44:36.666172  2788 net.cpp:157] Top shape: 32 128 13 13 (692224)
I0701 11:44:36.666180  2788 net.cpp:165] Memory required for data: 458971520
I0701 11:44:36.666189  2788 layer_factory.hpp:76] Creating layer conv42
I0701 11:44:36.666204  2788 net.cpp:106] Creating Layer conv42
I0701 11:44:36.666213  2788 net.cpp:454] conv42 <- conv41
I0701 11:44:36.666234  2788 net.cpp:411] conv42 -> conv42
I0701 11:44:36.670020  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0701 11:44:36.670075  2788 net.cpp:150] Setting up conv42
I0701 11:44:36.670088  2788 net.cpp:157] Top shape: 32 256 13 13 (1384448)
I0701 11:44:36.670096  2788 net.cpp:165] Memory required for data: 464509312
I0701 11:44:36.670107  2788 layer_factory.hpp:76] Creating layer relu42
I0701 11:44:36.670121  2788 net.cpp:106] Creating Layer relu42
I0701 11:44:36.670130  2788 net.cpp:454] relu42 <- conv42
I0701 11:44:36.670140  2788 net.cpp:397] relu42 -> conv42 (in-place)
I0701 11:44:36.670482  2788 net.cpp:150] Setting up relu42
I0701 11:44:36.670512  2788 net.cpp:157] Top shape: 32 256 13 13 (1384448)
I0701 11:44:36.670521  2788 net.cpp:165] Memory required for data: 470047104
I0701 11:44:36.670529  2788 layer_factory.hpp:76] Creating layer pool4
I0701 11:44:36.670543  2788 net.cpp:106] Creating Layer pool4
I0701 11:44:36.670552  2788 net.cpp:454] pool4 <- conv42
I0701 11:44:36.670573  2788 net.cpp:411] pool4 -> pool4
I0701 11:44:36.670837  2788 net.cpp:150] Setting up pool4
I0701 11:44:36.670866  2788 net.cpp:157] Top shape: 32 256 7 7 (401408)
I0701 11:44:36.670873  2788 net.cpp:165] Memory required for data: 471652736
I0701 11:44:36.670882  2788 layer_factory.hpp:76] Creating layer conv51
I0701 11:44:36.670897  2788 net.cpp:106] Creating Layer conv51
I0701 11:44:36.670918  2788 net.cpp:454] conv51 <- pool4
I0701 11:44:36.670928  2788 net.cpp:411] conv51 -> conv51
I0701 11:44:36.675343  2788 net.cpp:150] Setting up conv51
I0701 11:44:36.675377  2788 net.cpp:157] Top shape: 32 160 7 7 (250880)
I0701 11:44:36.675386  2788 net.cpp:165] Memory required for data: 472656256
I0701 11:44:36.675401  2788 layer_factory.hpp:76] Creating layer relu51
I0701 11:44:36.675415  2788 net.cpp:106] Creating Layer relu51
I0701 11:44:36.675426  2788 net.cpp:454] relu51 <- conv51
I0701 11:44:36.675436  2788 net.cpp:397] relu51 -> conv51 (in-place)
I0701 11:44:36.675806  2788 net.cpp:150] Setting up relu51
I0701 11:44:36.675837  2788 net.cpp:157] Top shape: 32 160 7 7 (250880)
I0701 11:44:36.675845  2788 net.cpp:165] Memory required for data: 473659776
I0701 11:44:36.675854  2788 layer_factory.hpp:76] Creating layer conv52
I0701 11:44:36.675871  2788 net.cpp:106] Creating Layer conv52
I0701 11:44:36.675881  2788 net.cpp:454] conv52 <- conv51
I0701 11:44:36.675891  2788 net.cpp:411] conv52 -> conv52
I0701 11:44:36.681077  2788 net.cpp:150] Setting up conv52
I0701 11:44:36.681114  2788 net.cpp:157] Top shape: 32 320 7 7 (501760)
I0701 11:44:36.681124  2788 net.cpp:165] Memory required for data: 475666816
I0701 11:44:36.681136  2788 layer_factory.hpp:76] Creating layer relu52
I0701 11:44:36.681164  2788 net.cpp:106] Creating Layer relu52
I0701 11:44:36.681174  2788 net.cpp:454] relu52 <- conv52
I0701 11:44:36.681185  2788 net.cpp:397] relu52 -> conv52 (in-place)
I0701 11:44:36.681547  2788 net.cpp:150] Setting up relu52
I0701 11:44:36.681579  2788 net.cpp:157] Top shape: 32 320 7 7 (501760)
I0701 11:44:36.681588  2788 net.cpp:165] Memory required for data: 477673856
I0701 11:44:36.681597  2788 layer_factory.hpp:76] Creating layer conv53
I0701 11:44:36.681612  2788 net.cpp:106] Creating Layer conv53
I0701 11:44:36.681627  2788 net.cpp:454] conv53 <- conv52
I0701 11:44:36.681638  2788 net.cpp:411] conv53 -> conv53
I0701 11:44:36.726768  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 188160
I0701 11:44:36.726838  2788 net.cpp:150] Setting up conv53
I0701 11:44:36.726853  2788 net.cpp:157] Top shape: 32 320 1 1 (10240)
I0701 11:44:36.726862  2788 net.cpp:165] Memory required for data: 477714816
I0701 11:44:36.726888  2788 layer_factory.hpp:76] Creating layer relu53
I0701 11:44:36.726904  2788 net.cpp:106] Creating Layer relu53
I0701 11:44:36.726914  2788 net.cpp:454] relu53 <- conv53
I0701 11:44:36.726928  2788 net.cpp:397] relu53 -> conv53 (in-place)
I0701 11:44:36.727146  2788 net.cpp:150] Setting up relu53
I0701 11:44:36.727174  2788 net.cpp:157] Top shape: 32 320 1 1 (10240)
I0701 11:44:36.727182  2788 net.cpp:165] Memory required for data: 477755776
I0701 11:44:36.727191  2788 layer_factory.hpp:76] Creating layer drop6
I0701 11:44:36.727205  2788 net.cpp:106] Creating Layer drop6
I0701 11:44:36.727213  2788 net.cpp:454] drop6 <- conv53
I0701 11:44:36.727236  2788 net.cpp:411] drop6 -> drop6
I0701 11:44:36.727291  2788 net.cpp:150] Setting up drop6
I0701 11:44:36.727305  2788 net.cpp:157] Top shape: 32 320 1 1 (10240)
I0701 11:44:36.727313  2788 net.cpp:165] Memory required for data: 477796736
I0701 11:44:36.727322  2788 layer_factory.hpp:76] Creating layer conv54
I0701 11:44:36.727339  2788 net.cpp:106] Creating Layer conv54
I0701 11:44:36.727349  2788 net.cpp:454] conv54 <- drop6
I0701 11:44:36.727360  2788 net.cpp:411] conv54 -> conv54
I0701 11:44:36.728485  2788 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3840
I0701 11:44:36.728548  2788 net.cpp:150] Setting up conv54
I0701 11:44:36.728559  2788 net.cpp:157] Top shape: 32 2 1 1 (64)
I0701 11:44:36.728567  2788 net.cpp:165] Memory required for data: 477796992
I0701 11:44:36.728590  2788 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0701 11:44:36.728605  2788 net.cpp:106] Creating Layer conv54_conv54_0_split
I0701 11:44:36.728613  2788 net.cpp:454] conv54_conv54_0_split <- conv54
I0701 11:44:36.728624  2788 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0701 11:44:36.728636  2788 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0701 11:44:36.728687  2788 net.cpp:150] Setting up conv54_conv54_0_split
I0701 11:44:36.728699  2788 net.cpp:157] Top shape: 32 2 1 1 (64)
I0701 11:44:36.728708  2788 net.cpp:157] Top shape: 32 2 1 1 (64)
I0701 11:44:36.728718  2788 net.cpp:165] Memory required for data: 477797504
I0701 11:44:36.728725  2788 layer_factory.hpp:76] Creating layer accuracy
I0701 11:44:36.728742  2788 net.cpp:106] Creating Layer accuracy
I0701 11:44:36.728751  2788 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0701 11:44:36.728760  2788 net.cpp:454] accuracy <- label_data_1_split_0
I0701 11:44:36.728773  2788 net.cpp:411] accuracy -> accuracy
I0701 11:44:36.728790  2788 net.cpp:150] Setting up accuracy
I0701 11:44:36.728798  2788 net.cpp:157] Top shape: (1)
I0701 11:44:36.728806  2788 net.cpp:165] Memory required for data: 477797508
I0701 11:44:36.728816  2788 layer_factory.hpp:76] Creating layer loss
I0701 11:44:36.728833  2788 net.cpp:106] Creating Layer loss
I0701 11:44:36.728842  2788 net.cpp:454] loss <- conv54_conv54_0_split_1
I0701 11:44:36.728852  2788 net.cpp:454] loss <- label_data_1_split_1
I0701 11:44:36.728863  2788 net.cpp:411] loss -> loss
I0701 11:44:36.728876  2788 layer_factory.hpp:76] Creating layer loss
I0701 11:44:36.729169  2788 net.cpp:150] Setting up loss
I0701 11:44:36.729218  2788 net.cpp:157] Top shape: (1)
I0701 11:44:36.729226  2788 net.cpp:160]     with loss weight 1
I0701 11:44:36.729240  2788 net.cpp:165] Memory required for data: 477797512
I0701 11:44:36.729249  2788 net.cpp:226] loss needs backward computation.
I0701 11:44:36.729259  2788 net.cpp:228] accuracy does not need backward computation.
I0701 11:44:36.729266  2788 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0701 11:44:36.729274  2788 net.cpp:226] conv54 needs backward computation.
I0701 11:44:36.729282  2788 net.cpp:226] drop6 needs backward computation.
I0701 11:44:36.729290  2788 net.cpp:226] relu53 needs backward computation.
I0701 11:44:36.729297  2788 net.cpp:226] conv53 needs backward computation.
I0701 11:44:36.729307  2788 net.cpp:226] relu52 needs backward computation.
I0701 11:44:36.729316  2788 net.cpp:226] conv52 needs backward computation.
I0701 11:44:36.729326  2788 net.cpp:226] relu51 needs backward computation.
I0701 11:44:36.729333  2788 net.cpp:226] conv51 needs backward computation.
I0701 11:44:36.729341  2788 net.cpp:226] pool4 needs backward computation.
I0701 11:44:36.729349  2788 net.cpp:226] relu42 needs backward computation.
I0701 11:44:36.729357  2788 net.cpp:226] conv42 needs backward computation.
I0701 11:44:36.729365  2788 net.cpp:226] relu41 needs backward computation.
I0701 11:44:36.729373  2788 net.cpp:226] conv41 needs backward computation.
I0701 11:44:36.729382  2788 net.cpp:226] pool3 needs backward computation.
I0701 11:44:36.729389  2788 net.cpp:226] relu32 needs backward computation.
I0701 11:44:36.729398  2788 net.cpp:226] conv32 needs backward computation.
I0701 11:44:36.729405  2788 net.cpp:226] relu31 needs backward computation.
I0701 11:44:36.729413  2788 net.cpp:226] conv31 needs backward computation.
I0701 11:44:36.729420  2788 net.cpp:226] pool2 needs backward computation.
I0701 11:44:36.729429  2788 net.cpp:226] relu22 needs backward computation.
I0701 11:44:36.729436  2788 net.cpp:226] conv22 needs backward computation.
I0701 11:44:36.729444  2788 net.cpp:226] relu21 needs backward computation.
I0701 11:44:36.729452  2788 net.cpp:226] conv21 needs backward computation.
I0701 11:44:36.729460  2788 net.cpp:226] pool1 needs backward computation.
I0701 11:44:36.729467  2788 net.cpp:226] relu12 needs backward computation.
I0701 11:44:36.729475  2788 net.cpp:226] conv12 needs backward computation.
I0701 11:44:36.729483  2788 net.cpp:226] relu11 needs backward computation.
I0701 11:44:36.729491  2788 net.cpp:226] conv11 needs backward computation.
I0701 11:44:36.729499  2788 net.cpp:228] label_data_1_split does not need backward computation.
I0701 11:44:36.729508  2788 net.cpp:228] data does not need backward computation.
I0701 11:44:36.729516  2788 net.cpp:270] This network produces output accuracy
I0701 11:44:36.729526  2788 net.cpp:270] This network produces output loss
I0701 11:44:36.729552  2788 net.cpp:283] Network initialization done.
I0701 11:44:36.729766  2788 solver.cpp:59] Solver scaffolding done.
I0701 11:44:36.730690  2788 caffe.cpp:212] Starting Optimization
I0701 11:44:36.730720  2788 solver.cpp:287] Solving FaceNN
I0701 11:44:36.730728  2788 solver.cpp:288] Learning Rate Policy: step
I0701 11:44:36.732552  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 11:44:42.319022  2788 solver.cpp:236] Iteration 0, loss = 1.37971
I0701 11:44:42.319094  2788 solver.cpp:252]     Train net output #0: loss = 1.37971 (* 1 = 1.37971 loss)
I0701 11:44:42.319135  2788 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0701 11:45:16.536031  2788 solver.cpp:236] Iteration 10, loss = 14.8004
I0701 11:45:16.536165  2788 solver.cpp:252]     Train net output #0: loss = 0.693903 (* 1 = 0.693903 loss)
I0701 11:45:16.536185  2788 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I0701 11:45:46.788506  2788 solver.cpp:236] Iteration 20, loss = 8.08225
I0701 11:45:46.788741  2788 solver.cpp:252]     Train net output #0: loss = 0.69122 (* 1 = 0.69122 loss)
I0701 11:45:46.788761  2788 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0701 11:46:16.074908  2788 solver.cpp:236] Iteration 30, loss = 5.69893
I0701 11:46:16.074970  2788 solver.cpp:252]     Train net output #0: loss = 0.695579 (* 1 = 0.695579 loss)
I0701 11:46:16.074986  2788 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I0701 11:46:44.787117  2788 solver.cpp:236] Iteration 40, loss = 4.47795
I0701 11:46:44.787276  2788 solver.cpp:252]     Train net output #0: loss = 0.693098 (* 1 = 0.693098 loss)
I0701 11:46:44.787292  2788 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0701 11:47:24.240360  2788 solver.cpp:236] Iteration 50, loss = 3.78298
I0701 11:47:24.240573  2788 solver.cpp:252]     Train net output #0: loss = 0.694804 (* 1 = 0.694804 loss)
I0701 11:47:24.240592  2788 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I0701 11:48:02.664947  2788 solver.cpp:236] Iteration 60, loss = 0.693169
I0701 11:48:02.665242  2788 solver.cpp:252]     Train net output #0: loss = 0.693085 (* 1 = 0.693085 loss)
I0701 11:48:02.665261  2788 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0701 11:48:40.764075  2788 solver.cpp:236] Iteration 70, loss = 0.693354
I0701 11:48:40.764277  2788 solver.cpp:252]     Train net output #0: loss = 0.693471 (* 1 = 0.693471 loss)
I0701 11:48:40.764293  2788 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I0701 11:49:17.932646  2788 solver.cpp:236] Iteration 80, loss = 0.693166
I0701 11:49:17.932936  2788 solver.cpp:252]     Train net output #0: loss = 0.692805 (* 1 = 0.692805 loss)
I0701 11:49:17.932965  2788 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0701 11:49:52.718714  2788 solver.cpp:236] Iteration 90, loss = 0.693101
I0701 11:49:52.718880  2788 solver.cpp:252]     Train net output #0: loss = 0.692307 (* 1 = 0.692307 loss)
I0701 11:49:52.718904  2788 sgd_solver.cpp:106] Iteration 90, lr = 0.01
I0701 11:50:27.118221  2788 solver.cpp:236] Iteration 100, loss = 0.693213
I0701 11:50:27.118374  2788 solver.cpp:252]     Train net output #0: loss = 0.691831 (* 1 = 0.691831 loss)
I0701 11:50:27.118402  2788 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0701 11:51:01.528959  2788 solver.cpp:236] Iteration 110, loss = 0.693177
I0701 11:51:01.529106  2788 solver.cpp:252]     Train net output #0: loss = 0.694798 (* 1 = 0.694798 loss)
I0701 11:51:01.529140  2788 sgd_solver.cpp:106] Iteration 110, lr = 0.01
I0701 11:51:34.884613  2788 solver.cpp:236] Iteration 120, loss = 0.693246
I0701 11:51:34.884780  2788 solver.cpp:252]     Train net output #0: loss = 0.696577 (* 1 = 0.696577 loss)
I0701 11:51:34.884824  2788 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0701 11:52:02.976732  2788 solver.cpp:236] Iteration 130, loss = 0.693163
I0701 11:52:02.976805  2788 solver.cpp:252]     Train net output #0: loss = 0.6909 (* 1 = 0.6909 loss)
I0701 11:52:02.976827  2788 sgd_solver.cpp:106] Iteration 130, lr = 0.01
I0701 11:52:28.118582  2788 solver.cpp:236] Iteration 140, loss = 0.69358
I0701 11:52:28.118865  2788 solver.cpp:252]     Train net output #0: loss = 0.693987 (* 1 = 0.693987 loss)
I0701 11:52:28.118886  2788 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0701 11:52:52.799881  2788 solver.cpp:236] Iteration 150, loss = 0.693464
I0701 11:52:52.799968  2788 solver.cpp:252]     Train net output #0: loss = 0.693181 (* 1 = 0.693181 loss)
I0701 11:52:52.800004  2788 sgd_solver.cpp:106] Iteration 150, lr = 0.01
I0701 11:53:17.775236  2788 solver.cpp:236] Iteration 160, loss = 0.693504
I0701 11:53:17.775427  2788 solver.cpp:252]     Train net output #0: loss = 0.694301 (* 1 = 0.694301 loss)
I0701 11:53:17.775439  2788 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0701 11:53:42.241935  2788 solver.cpp:236] Iteration 170, loss = 0.693421
I0701 11:53:42.241993  2788 solver.cpp:252]     Train net output #0: loss = 0.692578 (* 1 = 0.692578 loss)
I0701 11:53:42.242008  2788 sgd_solver.cpp:106] Iteration 170, lr = 0.01
I0701 11:54:06.617054  2788 solver.cpp:236] Iteration 180, loss = 0.69357
I0701 11:54:06.617338  2788 solver.cpp:252]     Train net output #0: loss = 0.697972 (* 1 = 0.697972 loss)
I0701 11:54:06.617372  2788 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0701 11:54:31.381968  2788 solver.cpp:236] Iteration 190, loss = 0.693255
I0701 11:54:31.382042  2788 solver.cpp:252]     Train net output #0: loss = 0.690073 (* 1 = 0.690073 loss)
I0701 11:54:31.382068  2788 sgd_solver.cpp:106] Iteration 190, lr = 0.01
I0701 11:54:55.997051  2788 solver.cpp:236] Iteration 200, loss = 0.693269
I0701 11:54:55.997297  2788 solver.cpp:252]     Train net output #0: loss = 0.694651 (* 1 = 0.694651 loss)
I0701 11:54:55.997315  2788 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0701 11:55:20.836576  2788 solver.cpp:236] Iteration 210, loss = 0.693228
I0701 11:55:20.836628  2788 solver.cpp:252]     Train net output #0: loss = 0.693334 (* 1 = 0.693334 loss)
I0701 11:55:20.836645  2788 sgd_solver.cpp:106] Iteration 210, lr = 0.01
I0701 11:55:45.166631  2788 solver.cpp:236] Iteration 220, loss = 0.6933
I0701 11:55:45.166831  2788 solver.cpp:252]     Train net output #0: loss = 0.695842 (* 1 = 0.695842 loss)
I0701 11:55:45.166857  2788 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0701 11:56:09.442298  2788 solver.cpp:236] Iteration 230, loss = 0.693403
I0701 11:56:09.442366  2788 solver.cpp:252]     Train net output #0: loss = 0.693105 (* 1 = 0.693105 loss)
I0701 11:56:09.442383  2788 sgd_solver.cpp:106] Iteration 230, lr = 0.01
I0701 11:56:33.692637  2788 solver.cpp:236] Iteration 240, loss = 0.693445
I0701 11:56:33.692811  2788 solver.cpp:252]     Train net output #0: loss = 0.69358 (* 1 = 0.69358 loss)
I0701 11:56:33.692828  2788 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0701 11:56:55.332020  2788 solver.cpp:340] Iteration 250, Testing net (#0)
I0701 11:57:59.028882  2788 solver.cpp:408]     Test net output #0: accuracy = 0.501562
I0701 11:57:59.029014  2788 solver.cpp:408]     Test net output #1: loss = 0.693265 (* 1 = 0.693265 loss)
I0701 11:57:59.259953  2788 solver.cpp:236] Iteration 250, loss = 0.693437
I0701 11:57:59.260013  2788 solver.cpp:252]     Train net output #0: loss = 0.692148 (* 1 = 0.692148 loss)
I0701 11:57:59.260030  2788 sgd_solver.cpp:106] Iteration 250, lr = 0.01
I0701 11:58:19.915621  2788 solver.cpp:236] Iteration 260, loss = 0.693475
I0701 11:58:19.915716  2788 solver.cpp:252]     Train net output #0: loss = 0.693416 (* 1 = 0.693416 loss)
I0701 11:58:19.915734  2788 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0701 11:58:44.539237  2788 solver.cpp:236] Iteration 270, loss = 0.693419
I0701 11:58:44.539494  2788 solver.cpp:252]     Train net output #0: loss = 0.693315 (* 1 = 0.693315 loss)
I0701 11:58:44.539511  2788 sgd_solver.cpp:106] Iteration 270, lr = 0.01
I0701 11:59:08.769824  2788 solver.cpp:236] Iteration 280, loss = 0.693322
I0701 11:59:08.769888  2788 solver.cpp:252]     Train net output #0: loss = 0.693887 (* 1 = 0.693887 loss)
I0701 11:59:08.769903  2788 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0701 11:59:33.345000  2788 solver.cpp:236] Iteration 290, loss = 0.693318
I0701 11:59:33.345183  2788 solver.cpp:252]     Train net output #0: loss = 0.691673 (* 1 = 0.691673 loss)
I0701 11:59:33.345233  2788 sgd_solver.cpp:106] Iteration 290, lr = 0.01
I0701 11:59:57.888988  2788 solver.cpp:236] Iteration 300, loss = 0.693484
I0701 11:59:57.889045  2788 solver.cpp:252]     Train net output #0: loss = 0.695614 (* 1 = 0.695614 loss)
I0701 11:59:57.889060  2788 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0701 12:00:22.016494  2788 solver.cpp:236] Iteration 310, loss = 0.693355
I0701 12:00:22.016722  2788 solver.cpp:252]     Train net output #0: loss = 0.692775 (* 1 = 0.692775 loss)
I0701 12:00:22.016739  2788 sgd_solver.cpp:106] Iteration 310, lr = 0.01
I0701 12:00:46.546147  2788 solver.cpp:236] Iteration 320, loss = 0.693316
I0701 12:00:46.546216  2788 solver.cpp:252]     Train net output #0: loss = 0.693026 (* 1 = 0.693026 loss)
I0701 12:00:46.546231  2788 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0701 12:01:10.955200  2788 solver.cpp:236] Iteration 330, loss = 0.693345
I0701 12:01:10.955428  2788 solver.cpp:252]     Train net output #0: loss = 0.69475 (* 1 = 0.69475 loss)
I0701 12:01:10.955456  2788 sgd_solver.cpp:106] Iteration 330, lr = 0.01
I0701 12:01:35.094758  2788 solver.cpp:236] Iteration 340, loss = 0.693366
I0701 12:01:35.094823  2788 solver.cpp:252]     Train net output #0: loss = 0.693409 (* 1 = 0.693409 loss)
I0701 12:01:35.094843  2788 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0701 12:01:59.487423  2788 solver.cpp:236] Iteration 350, loss = 0.693327
I0701 12:01:59.487717  2788 solver.cpp:252]     Train net output #0: loss = 0.693563 (* 1 = 0.693563 loss)
I0701 12:01:59.487749  2788 sgd_solver.cpp:106] Iteration 350, lr = 0.01
I0701 12:02:23.684140  2788 solver.cpp:236] Iteration 360, loss = 0.693401
I0701 12:02:23.684216  2788 solver.cpp:252]     Train net output #0: loss = 0.69268 (* 1 = 0.69268 loss)
I0701 12:02:23.684231  2788 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0701 12:02:47.153093  2788 solver.cpp:236] Iteration 370, loss = 0.693595
I0701 12:02:47.153321  2788 solver.cpp:252]     Train net output #0: loss = 0.696836 (* 1 = 0.696836 loss)
I0701 12:02:47.153339  2788 sgd_solver.cpp:106] Iteration 370, lr = 0.01
I0701 12:03:11.425025  2788 solver.cpp:236] Iteration 380, loss = 0.693664
I0701 12:03:11.425091  2788 solver.cpp:252]     Train net output #0: loss = 0.693078 (* 1 = 0.693078 loss)
I0701 12:03:11.425106  2788 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0701 12:03:35.911725  2788 solver.cpp:236] Iteration 390, loss = 0.693659
I0701 12:03:35.911893  2788 solver.cpp:252]     Train net output #0: loss = 0.692994 (* 1 = 0.692994 loss)
I0701 12:03:35.911909  2788 sgd_solver.cpp:106] Iteration 390, lr = 0.01
I0701 12:04:00.038678  2788 solver.cpp:236] Iteration 400, loss = 0.693538
I0701 12:04:00.038753  2788 solver.cpp:252]     Train net output #0: loss = 0.692242 (* 1 = 0.692242 loss)
I0701 12:04:00.038769  2788 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0701 12:04:24.815531  2788 solver.cpp:236] Iteration 410, loss = 0.693468
I0701 12:04:24.815738  2788 solver.cpp:252]     Train net output #0: loss = 0.691667 (* 1 = 0.691667 loss)
I0701 12:04:24.815759  2788 sgd_solver.cpp:106] Iteration 410, lr = 0.01
I0701 12:04:49.417701  2788 solver.cpp:236] Iteration 420, loss = 0.693285
I0701 12:04:49.417762  2788 solver.cpp:252]     Train net output #0: loss = 0.698952 (* 1 = 0.698952 loss)
I0701 12:04:49.417776  2788 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0701 12:05:13.121773  2788 solver.cpp:236] Iteration 430, loss = 0.69322
I0701 12:05:13.122009  2788 solver.cpp:252]     Train net output #0: loss = 0.693028 (* 1 = 0.693028 loss)
I0701 12:05:13.122025  2788 sgd_solver.cpp:106] Iteration 430, lr = 0.01
I0701 12:05:37.257995  2788 solver.cpp:236] Iteration 440, loss = 0.69325
I0701 12:05:37.258054  2788 solver.cpp:252]     Train net output #0: loss = 0.692646 (* 1 = 0.692646 loss)
I0701 12:05:37.258070  2788 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0701 12:06:01.408753  2788 solver.cpp:236] Iteration 450, loss = 0.693219
I0701 12:06:01.409523  2788 solver.cpp:252]     Train net output #0: loss = 0.692594 (* 1 = 0.692594 loss)
I0701 12:06:01.409540  2788 sgd_solver.cpp:106] Iteration 450, lr = 0.01
I0701 12:06:26.620954  2788 solver.cpp:236] Iteration 460, loss = 0.69328
I0701 12:06:26.621016  2788 solver.cpp:252]     Train net output #0: loss = 0.69199 (* 1 = 0.69199 loss)
I0701 12:06:26.621031  2788 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0701 12:06:50.999477  2788 solver.cpp:236] Iteration 470, loss = 0.693471
I0701 12:06:50.999714  2788 solver.cpp:252]     Train net output #0: loss = 0.694079 (* 1 = 0.694079 loss)
I0701 12:06:50.999737  2788 sgd_solver.cpp:106] Iteration 470, lr = 0.01
I0701 12:07:15.140358  2788 solver.cpp:236] Iteration 480, loss = 0.693389
I0701 12:07:15.140416  2788 solver.cpp:252]     Train net output #0: loss = 0.692813 (* 1 = 0.692813 loss)
I0701 12:07:15.140450  2788 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0701 12:07:39.561874  2788 solver.cpp:236] Iteration 490, loss = 0.693413
I0701 12:07:39.562048  2788 solver.cpp:252]     Train net output #0: loss = 0.699539 (* 1 = 0.699539 loss)
I0701 12:07:39.562067  2788 sgd_solver.cpp:106] Iteration 490, lr = 0.01
I0701 12:08:01.360189  2788 solver.cpp:340] Iteration 500, Testing net (#0)
I0701 12:09:02.591886  2788 solver.cpp:408]     Test net output #0: accuracy = 0.503125
I0701 12:09:02.592067  2788 solver.cpp:408]     Test net output #1: loss = 0.693133 (* 1 = 0.693133 loss)
I0701 12:09:02.823982  2788 solver.cpp:236] Iteration 500, loss = 0.693515
I0701 12:09:02.824038  2788 solver.cpp:252]     Train net output #0: loss = 0.691694 (* 1 = 0.691694 loss)
I0701 12:09:02.824054  2788 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0701 12:09:22.503008  2788 solver.cpp:236] Iteration 510, loss = 0.693546
I0701 12:09:22.503068  2788 solver.cpp:252]     Train net output #0: loss = 0.692926 (* 1 = 0.692926 loss)
I0701 12:09:22.503084  2788 sgd_solver.cpp:106] Iteration 510, lr = 0.01
I0701 12:09:46.697450  2788 solver.cpp:236] Iteration 520, loss = 0.693378
I0701 12:09:46.697590  2788 solver.cpp:252]     Train net output #0: loss = 0.693112 (* 1 = 0.693112 loss)
I0701 12:09:46.697615  2788 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0701 12:10:10.158566  2788 solver.cpp:236] Iteration 530, loss = 0.693425
I0701 12:10:10.158622  2788 solver.cpp:252]     Train net output #0: loss = 0.693672 (* 1 = 0.693672 loss)
I0701 12:10:10.158635  2788 sgd_solver.cpp:106] Iteration 530, lr = 0.01
I0701 12:10:35.286368  2788 solver.cpp:236] Iteration 540, loss = 0.693315
I0701 12:10:35.286510  2788 solver.cpp:252]     Train net output #0: loss = 0.692725 (* 1 = 0.692725 loss)
I0701 12:10:35.286526  2788 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0701 12:10:59.834326  2788 solver.cpp:236] Iteration 550, loss = 0.693234
I0701 12:10:59.834398  2788 solver.cpp:252]     Train net output #0: loss = 0.695197 (* 1 = 0.695197 loss)
I0701 12:10:59.834414  2788 sgd_solver.cpp:106] Iteration 550, lr = 0.01
I0701 12:11:24.455235  2788 solver.cpp:236] Iteration 560, loss = 0.693225
I0701 12:11:24.455415  2788 solver.cpp:252]     Train net output #0: loss = 0.693604 (* 1 = 0.693604 loss)
I0701 12:11:24.455443  2788 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0701 12:11:48.723501  2788 solver.cpp:236] Iteration 570, loss = 0.693211
I0701 12:11:48.723569  2788 solver.cpp:252]     Train net output #0: loss = 0.694441 (* 1 = 0.694441 loss)
I0701 12:11:48.723585  2788 sgd_solver.cpp:106] Iteration 570, lr = 0.01
I0701 12:12:12.959588  2788 solver.cpp:236] Iteration 580, loss = 0.693231
I0701 12:12:12.959743  2788 solver.cpp:252]     Train net output #0: loss = 0.694219 (* 1 = 0.694219 loss)
I0701 12:12:12.959784  2788 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0701 12:12:37.508363  2788 solver.cpp:236] Iteration 590, loss = 0.693162
I0701 12:12:37.508419  2788 solver.cpp:252]     Train net output #0: loss = 0.690386 (* 1 = 0.690386 loss)
I0701 12:12:37.508455  2788 sgd_solver.cpp:106] Iteration 590, lr = 0.01
I0701 12:13:01.758623  2788 solver.cpp:236] Iteration 600, loss = 0.693198
I0701 12:13:01.758769  2788 solver.cpp:252]     Train net output #0: loss = 0.693964 (* 1 = 0.693964 loss)
I0701 12:13:01.758805  2788 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0701 12:13:25.794404  2788 solver.cpp:236] Iteration 610, loss = 0.693274
I0701 12:13:25.794443  2788 solver.cpp:252]     Train net output #0: loss = 0.693376 (* 1 = 0.693376 loss)
I0701 12:13:25.794455  2788 sgd_solver.cpp:106] Iteration 610, lr = 0.01
I0701 12:13:49.459230  2788 solver.cpp:236] Iteration 620, loss = 0.693255
I0701 12:13:49.459374  2788 solver.cpp:252]     Train net output #0: loss = 0.692833 (* 1 = 0.692833 loss)
I0701 12:13:49.459403  2788 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0701 12:14:13.752656  2788 solver.cpp:236] Iteration 630, loss = 0.693204
I0701 12:14:13.752708  2788 solver.cpp:252]     Train net output #0: loss = 0.692896 (* 1 = 0.692896 loss)
I0701 12:14:13.752728  2788 sgd_solver.cpp:106] Iteration 630, lr = 0.01
I0701 12:14:37.581256  2788 solver.cpp:236] Iteration 640, loss = 0.693327
I0701 12:14:37.581432  2788 solver.cpp:252]     Train net output #0: loss = 0.693644 (* 1 = 0.693644 loss)
I0701 12:14:37.581462  2788 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0701 12:15:01.414444  2788 solver.cpp:236] Iteration 650, loss = 0.693298
I0701 12:15:01.414521  2788 solver.cpp:252]     Train net output #0: loss = 0.694002 (* 1 = 0.694002 loss)
I0701 12:15:01.414552  2788 sgd_solver.cpp:106] Iteration 650, lr = 0.01
I0701 12:15:24.843045  2788 solver.cpp:236] Iteration 660, loss = 0.693206
I0701 12:15:24.843267  2788 solver.cpp:252]     Train net output #0: loss = 0.693043 (* 1 = 0.693043 loss)
I0701 12:15:24.843283  2788 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0701 12:15:48.456269  2788 solver.cpp:236] Iteration 670, loss = 0.69325
I0701 12:15:48.456324  2788 solver.cpp:252]     Train net output #0: loss = 0.691884 (* 1 = 0.691884 loss)
I0701 12:15:48.456338  2788 sgd_solver.cpp:106] Iteration 670, lr = 0.01
I0701 12:16:12.039645  2788 solver.cpp:236] Iteration 680, loss = 0.693301
I0701 12:16:12.039762  2788 solver.cpp:252]     Train net output #0: loss = 0.694048 (* 1 = 0.694048 loss)
I0701 12:16:12.039793  2788 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0701 12:16:36.261782  2788 solver.cpp:236] Iteration 690, loss = 0.693231
I0701 12:16:36.261826  2788 solver.cpp:252]     Train net output #0: loss = 0.69287 (* 1 = 0.69287 loss)
I0701 12:16:36.261839  2788 sgd_solver.cpp:106] Iteration 690, lr = 0.01
I0701 12:16:59.678172  2788 solver.cpp:236] Iteration 700, loss = 0.693086
I0701 12:16:59.678313  2788 solver.cpp:252]     Train net output #0: loss = 0.696206 (* 1 = 0.696206 loss)
I0701 12:16:59.678359  2788 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0701 12:17:23.475703  2788 solver.cpp:236] Iteration 710, loss = 0.692838
I0701 12:17:23.475755  2788 solver.cpp:252]     Train net output #0: loss = 0.689151 (* 1 = 0.689151 loss)
I0701 12:17:23.475769  2788 sgd_solver.cpp:106] Iteration 710, lr = 0.01
I0701 12:17:47.346542  2788 solver.cpp:236] Iteration 720, loss = 0.693033
I0701 12:17:47.346683  2788 solver.cpp:252]     Train net output #0: loss = 0.698745 (* 1 = 0.698745 loss)
I0701 12:17:47.346725  2788 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0701 12:18:11.466903  2788 solver.cpp:236] Iteration 730, loss = 0.693063
I0701 12:18:11.466956  2788 solver.cpp:252]     Train net output #0: loss = 0.69229 (* 1 = 0.69229 loss)
I0701 12:18:11.466971  2788 sgd_solver.cpp:106] Iteration 730, lr = 0.01
I0701 12:18:35.645301  2788 solver.cpp:236] Iteration 740, loss = 0.693098
I0701 12:18:35.645458  2788 solver.cpp:252]     Train net output #0: loss = 0.693052 (* 1 = 0.693052 loss)
I0701 12:18:35.645485  2788 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0701 12:18:57.273782  2788 solver.cpp:340] Iteration 750, Testing net (#0)
I0701 12:19:37.550645  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 12:19:58.761085  2788 solver.cpp:408]     Test net output #0: accuracy = 0.500625
I0701 12:19:58.761137  2788 solver.cpp:408]     Test net output #1: loss = 0.694195 (* 1 = 0.694195 loss)
I0701 12:19:58.995786  2788 solver.cpp:236] Iteration 750, loss = 0.692968
I0701 12:19:58.995839  2788 solver.cpp:252]     Train net output #0: loss = 0.690578 (* 1 = 0.690578 loss)
I0701 12:19:58.995865  2788 sgd_solver.cpp:106] Iteration 750, lr = 0.01
I0701 12:20:24.413585  2788 solver.cpp:236] Iteration 760, loss = 0.693678
I0701 12:20:24.413766  2788 solver.cpp:252]     Train net output #0: loss = 0.689867 (* 1 = 0.689867 loss)
I0701 12:20:24.413810  2788 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0701 12:20:57.442731  2788 solver.cpp:236] Iteration 770, loss = 0.693512
I0701 12:20:57.442874  2788 solver.cpp:252]     Train net output #0: loss = 0.692742 (* 1 = 0.692742 loss)
I0701 12:20:57.442901  2788 sgd_solver.cpp:106] Iteration 770, lr = 0.01
I0701 12:21:30.382055  2788 solver.cpp:236] Iteration 780, loss = 0.693439
I0701 12:21:30.382182  2788 solver.cpp:252]     Train net output #0: loss = 0.692523 (* 1 = 0.692523 loss)
I0701 12:21:30.382210  2788 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0701 12:22:02.618580  2788 solver.cpp:236] Iteration 790, loss = 0.69359
I0701 12:22:02.618739  2788 solver.cpp:252]     Train net output #0: loss = 0.692884 (* 1 = 0.692884 loss)
I0701 12:22:02.618779  2788 sgd_solver.cpp:106] Iteration 790, lr = 0.01
I0701 12:22:33.958075  2788 solver.cpp:236] Iteration 800, loss = 0.693866
I0701 12:22:33.958228  2788 solver.cpp:252]     Train net output #0: loss = 0.694563 (* 1 = 0.694563 loss)
I0701 12:22:33.958247  2788 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0701 12:23:04.879462  2788 solver.cpp:236] Iteration 810, loss = 0.693474
I0701 12:23:04.879586  2788 solver.cpp:252]     Train net output #0: loss = 0.693108 (* 1 = 0.693108 loss)
I0701 12:23:04.879612  2788 sgd_solver.cpp:106] Iteration 810, lr = 0.01
I0701 12:23:36.666904  2788 solver.cpp:236] Iteration 820, loss = 0.693461
I0701 12:23:36.667039  2788 solver.cpp:252]     Train net output #0: loss = 0.693038 (* 1 = 0.693038 loss)
I0701 12:23:36.667065  2788 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0701 12:24:07.668694  2788 solver.cpp:236] Iteration 830, loss = 0.693503
I0701 12:24:07.668807  2788 solver.cpp:252]     Train net output #0: loss = 0.692918 (* 1 = 0.692918 loss)
I0701 12:24:07.668823  2788 sgd_solver.cpp:106] Iteration 830, lr = 0.01
I0701 12:24:38.844642  2788 solver.cpp:236] Iteration 840, loss = 0.69335
I0701 12:24:38.844785  2788 solver.cpp:252]     Train net output #0: loss = 0.694786 (* 1 = 0.694786 loss)
I0701 12:24:38.844833  2788 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0701 12:25:08.716712  2788 solver.cpp:236] Iteration 850, loss = 0.693249
I0701 12:25:08.716768  2788 solver.cpp:252]     Train net output #0: loss = 0.69303 (* 1 = 0.69303 loss)
I0701 12:25:08.716781  2788 sgd_solver.cpp:106] Iteration 850, lr = 0.01
I0701 12:25:38.668594  2788 solver.cpp:236] Iteration 860, loss = 0.693241
I0701 12:25:38.668758  2788 solver.cpp:252]     Train net output #0: loss = 0.693034 (* 1 = 0.693034 loss)
I0701 12:25:38.668797  2788 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0701 12:26:08.164319  2788 solver.cpp:236] Iteration 870, loss = 0.693252
I0701 12:26:08.164372  2788 solver.cpp:252]     Train net output #0: loss = 0.69307 (* 1 = 0.69307 loss)
I0701 12:26:08.164386  2788 sgd_solver.cpp:106] Iteration 870, lr = 0.01
I0701 12:26:36.637394  2788 solver.cpp:236] Iteration 880, loss = 0.693191
I0701 12:26:36.637598  2788 solver.cpp:252]     Train net output #0: loss = 0.693047 (* 1 = 0.693047 loss)
I0701 12:26:36.637616  2788 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0701 12:27:05.133152  2788 solver.cpp:236] Iteration 890, loss = 0.693228
I0701 12:27:05.133218  2788 solver.cpp:252]     Train net output #0: loss = 0.693075 (* 1 = 0.693075 loss)
I0701 12:27:05.133232  2788 sgd_solver.cpp:106] Iteration 890, lr = 0.01
I0701 12:27:32.912292  2788 solver.cpp:236] Iteration 900, loss = 0.693215
I0701 12:27:32.912449  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 12:27:32.912473  2788 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0701 12:28:00.758903  2788 solver.cpp:236] Iteration 910, loss = 0.693043
I0701 12:28:00.758960  2788 solver.cpp:252]     Train net output #0: loss = 0.690058 (* 1 = 0.690058 loss)
I0701 12:28:00.758975  2788 sgd_solver.cpp:106] Iteration 910, lr = 0.01
I0701 12:28:28.650394  2788 solver.cpp:236] Iteration 920, loss = 0.693081
I0701 12:28:28.650553  2788 solver.cpp:252]     Train net output #0: loss = 0.691584 (* 1 = 0.691584 loss)
I0701 12:28:28.650576  2788 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0701 12:28:55.176347  2788 solver.cpp:236] Iteration 930, loss = 0.693181
I0701 12:28:55.176409  2788 solver.cpp:252]     Train net output #0: loss = 0.692554 (* 1 = 0.692554 loss)
I0701 12:28:55.176429  2788 sgd_solver.cpp:106] Iteration 930, lr = 0.01
I0701 12:29:22.006757  2788 solver.cpp:236] Iteration 940, loss = 0.693143
I0701 12:29:22.006940  2788 solver.cpp:252]     Train net output #0: loss = 0.692219 (* 1 = 0.692219 loss)
I0701 12:29:22.006983  2788 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0701 12:29:47.822758  2788 solver.cpp:236] Iteration 950, loss = 0.693446
I0701 12:29:47.822824  2788 solver.cpp:252]     Train net output #0: loss = 0.694953 (* 1 = 0.694953 loss)
I0701 12:29:47.822839  2788 sgd_solver.cpp:106] Iteration 950, lr = 0.01
I0701 12:30:12.079111  2788 solver.cpp:236] Iteration 960, loss = 0.693542
I0701 12:30:12.079370  2788 solver.cpp:252]     Train net output #0: loss = 0.692781 (* 1 = 0.692781 loss)
I0701 12:30:12.079401  2788 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0701 12:30:36.447929  2788 solver.cpp:236] Iteration 970, loss = 0.693274
I0701 12:30:36.456915  2788 solver.cpp:252]     Train net output #0: loss = 0.69126 (* 1 = 0.69126 loss)
I0701 12:30:36.456933  2788 sgd_solver.cpp:106] Iteration 970, lr = 0.01
I0701 12:31:01.629084  2788 solver.cpp:236] Iteration 980, loss = 0.693443
I0701 12:31:01.629261  2788 solver.cpp:252]     Train net output #0: loss = 0.692732 (* 1 = 0.692732 loss)
I0701 12:31:01.629284  2788 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0701 12:31:28.741797  2788 solver.cpp:236] Iteration 990, loss = 0.693524
I0701 12:31:28.741858  2788 solver.cpp:252]     Train net output #0: loss = 0.692454 (* 1 = 0.692454 loss)
I0701 12:31:28.741874  2788 sgd_solver.cpp:106] Iteration 990, lr = 0.01
I0701 12:31:58.940899  2788 solver.cpp:340] Iteration 1000, Testing net (#0)
I0701 12:33:09.761235  2788 solver.cpp:408]     Test net output #0: accuracy = 0.508125
I0701 12:33:09.761358  2788 solver.cpp:408]     Test net output #1: loss = 0.693046 (* 1 = 0.693046 loss)
I0701 12:33:09.989727  2788 solver.cpp:236] Iteration 1000, loss = 0.693373
I0701 12:33:09.989792  2788 solver.cpp:252]     Train net output #0: loss = 0.694616 (* 1 = 0.694616 loss)
I0701 12:33:09.989809  2788 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0701 12:33:30.023733  2788 solver.cpp:236] Iteration 1010, loss = 0.693447
I0701 12:33:30.023815  2788 solver.cpp:252]     Train net output #0: loss = 0.694215 (* 1 = 0.694215 loss)
I0701 12:33:30.023838  2788 sgd_solver.cpp:106] Iteration 1010, lr = 0.01
I0701 12:33:54.843179  2788 solver.cpp:236] Iteration 1020, loss = 0.693638
I0701 12:33:54.843317  2788 solver.cpp:252]     Train net output #0: loss = 0.6975 (* 1 = 0.6975 loss)
I0701 12:33:54.843333  2788 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0701 12:34:20.057160  2788 solver.cpp:236] Iteration 1030, loss = 0.693309
I0701 12:34:20.057214  2788 solver.cpp:252]     Train net output #0: loss = 0.693468 (* 1 = 0.693468 loss)
I0701 12:34:20.057227  2788 sgd_solver.cpp:106] Iteration 1030, lr = 0.01
I0701 12:34:45.019979  2788 solver.cpp:236] Iteration 1040, loss = 0.693202
I0701 12:34:45.020138  2788 solver.cpp:252]     Train net output #0: loss = 0.69114 (* 1 = 0.69114 loss)
I0701 12:34:45.020172  2788 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0701 12:35:09.200325  2788 solver.cpp:236] Iteration 1050, loss = 0.69302
I0701 12:35:09.200371  2788 solver.cpp:252]     Train net output #0: loss = 0.690374 (* 1 = 0.690374 loss)
I0701 12:35:09.200384  2788 sgd_solver.cpp:106] Iteration 1050, lr = 0.01
I0701 12:35:33.641253  2788 solver.cpp:236] Iteration 1060, loss = 0.693198
I0701 12:35:33.641399  2788 solver.cpp:252]     Train net output #0: loss = 0.69354 (* 1 = 0.69354 loss)
I0701 12:35:33.641429  2788 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0701 12:35:58.219944  2788 solver.cpp:236] Iteration 1070, loss = 0.693327
I0701 12:35:58.220000  2788 solver.cpp:252]     Train net output #0: loss = 0.693658 (* 1 = 0.693658 loss)
I0701 12:35:58.220013  2788 sgd_solver.cpp:106] Iteration 1070, lr = 0.01
I0701 12:36:21.969388  2788 solver.cpp:236] Iteration 1080, loss = 0.693324
I0701 12:36:21.969655  2788 solver.cpp:252]     Train net output #0: loss = 0.692766 (* 1 = 0.692766 loss)
I0701 12:36:21.969673  2788 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0701 12:36:46.251616  2788 solver.cpp:236] Iteration 1090, loss = 0.693479
I0701 12:36:46.251677  2788 solver.cpp:252]     Train net output #0: loss = 0.69738 (* 1 = 0.69738 loss)
I0701 12:36:46.251696  2788 sgd_solver.cpp:106] Iteration 1090, lr = 0.01
I0701 12:37:10.191684  2788 solver.cpp:236] Iteration 1100, loss = 0.693566
I0701 12:37:10.191875  2788 solver.cpp:252]     Train net output #0: loss = 0.691184 (* 1 = 0.691184 loss)
I0701 12:37:10.191906  2788 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0701 12:37:34.542253  2788 solver.cpp:236] Iteration 1110, loss = 0.693417
I0701 12:37:34.542297  2788 solver.cpp:252]     Train net output #0: loss = 0.693346 (* 1 = 0.693346 loss)
I0701 12:37:34.542309  2788 sgd_solver.cpp:106] Iteration 1110, lr = 0.01
I0701 12:37:58.735676  2788 solver.cpp:236] Iteration 1120, loss = 0.693303
I0701 12:37:58.735833  2788 solver.cpp:252]     Train net output #0: loss = 0.693366 (* 1 = 0.693366 loss)
I0701 12:37:58.735873  2788 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0701 12:38:23.305071  2788 solver.cpp:236] Iteration 1130, loss = 0.693354
I0701 12:38:23.305126  2788 solver.cpp:252]     Train net output #0: loss = 0.693293 (* 1 = 0.693293 loss)
I0701 12:38:23.305145  2788 sgd_solver.cpp:106] Iteration 1130, lr = 0.01
I0701 12:38:48.185422  2788 solver.cpp:236] Iteration 1140, loss = 0.693264
I0701 12:38:48.185549  2788 solver.cpp:252]     Train net output #0: loss = 0.692628 (* 1 = 0.692628 loss)
I0701 12:38:48.185576  2788 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0701 12:39:13.141113  2788 solver.cpp:236] Iteration 1150, loss = 0.693252
I0701 12:39:13.141168  2788 solver.cpp:252]     Train net output #0: loss = 0.69326 (* 1 = 0.69326 loss)
I0701 12:39:13.141182  2788 sgd_solver.cpp:106] Iteration 1150, lr = 0.01
I0701 12:39:37.393532  2788 solver.cpp:236] Iteration 1160, loss = 0.693195
I0701 12:39:37.393704  2788 solver.cpp:252]     Train net output #0: loss = 0.693877 (* 1 = 0.693877 loss)
I0701 12:39:37.393723  2788 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0701 12:40:01.540818  2788 solver.cpp:236] Iteration 1170, loss = 0.693185
I0701 12:40:01.540874  2788 solver.cpp:252]     Train net output #0: loss = 0.694663 (* 1 = 0.694663 loss)
I0701 12:40:01.540889  2788 sgd_solver.cpp:106] Iteration 1170, lr = 0.01
I0701 12:40:25.955152  2788 solver.cpp:236] Iteration 1180, loss = 0.693194
I0701 12:40:25.955297  2788 solver.cpp:252]     Train net output #0: loss = 0.693159 (* 1 = 0.693159 loss)
I0701 12:40:25.955325  2788 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0701 12:40:50.068174  2788 solver.cpp:236] Iteration 1190, loss = 0.693179
I0701 12:40:50.068223  2788 solver.cpp:252]     Train net output #0: loss = 0.693003 (* 1 = 0.693003 loss)
I0701 12:40:50.068238  2788 sgd_solver.cpp:106] Iteration 1190, lr = 0.01
I0701 12:41:15.467613  2788 solver.cpp:236] Iteration 1200, loss = 0.6932
I0701 12:41:15.467862  2788 solver.cpp:252]     Train net output #0: loss = 0.694513 (* 1 = 0.694513 loss)
I0701 12:41:15.467883  2788 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0701 12:41:39.360319  2788 solver.cpp:236] Iteration 1210, loss = 0.693368
I0701 12:41:39.360396  2788 solver.cpp:252]     Train net output #0: loss = 0.694977 (* 1 = 0.694977 loss)
I0701 12:41:39.360411  2788 sgd_solver.cpp:106] Iteration 1210, lr = 0.01
I0701 12:42:03.318672  2788 solver.cpp:236] Iteration 1220, loss = 0.693349
I0701 12:42:03.318863  2788 solver.cpp:252]     Train net output #0: loss = 0.693119 (* 1 = 0.693119 loss)
I0701 12:42:03.318877  2788 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0701 12:42:27.216186  2788 solver.cpp:236] Iteration 1230, loss = 0.693354
I0701 12:42:27.216251  2788 solver.cpp:252]     Train net output #0: loss = 0.693671 (* 1 = 0.693671 loss)
I0701 12:42:27.216269  2788 sgd_solver.cpp:106] Iteration 1230, lr = 0.01
I0701 12:42:50.687129  2788 solver.cpp:236] Iteration 1240, loss = 0.693325
I0701 12:42:50.687307  2788 solver.cpp:252]     Train net output #0: loss = 0.692435 (* 1 = 0.692435 loss)
I0701 12:42:50.687350  2788 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0701 12:43:12.689290  2788 solver.cpp:340] Iteration 1250, Testing net (#0)
I0701 12:44:03.920259  2788 solver.cpp:408]     Test net output #0: accuracy = 0.502187
I0701 12:44:03.920424  2788 solver.cpp:408]     Test net output #1: loss = 0.69314 (* 1 = 0.69314 loss)
I0701 12:44:04.152570  2788 solver.cpp:236] Iteration 1250, loss = 0.693381
I0701 12:44:04.152626  2788 solver.cpp:252]     Train net output #0: loss = 0.693011 (* 1 = 0.693011 loss)
I0701 12:44:04.152643  2788 sgd_solver.cpp:106] Iteration 1250, lr = 0.01
I0701 12:44:23.824383  2788 solver.cpp:236] Iteration 1260, loss = 0.693209
I0701 12:44:23.824456  2788 solver.cpp:252]     Train net output #0: loss = 0.693079 (* 1 = 0.693079 loss)
I0701 12:44:23.824472  2788 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0701 12:44:47.607415  2788 solver.cpp:236] Iteration 1270, loss = 0.693218
I0701 12:44:47.607617  2788 solver.cpp:252]     Train net output #0: loss = 0.693089 (* 1 = 0.693089 loss)
I0701 12:44:47.607635  2788 sgd_solver.cpp:106] Iteration 1270, lr = 0.01
I0701 12:45:11.679174  2788 solver.cpp:236] Iteration 1280, loss = 0.693186
I0701 12:45:11.679229  2788 solver.cpp:252]     Train net output #0: loss = 0.692099 (* 1 = 0.692099 loss)
I0701 12:45:11.679244  2788 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0701 12:45:35.834154  2788 solver.cpp:236] Iteration 1290, loss = 0.693201
I0701 12:45:35.834311  2788 solver.cpp:252]     Train net output #0: loss = 0.691664 (* 1 = 0.691664 loss)
I0701 12:45:35.834333  2788 sgd_solver.cpp:106] Iteration 1290, lr = 0.01
I0701 12:45:59.940491  2788 solver.cpp:236] Iteration 1300, loss = 0.693177
I0701 12:45:59.940572  2788 solver.cpp:252]     Train net output #0: loss = 0.69434 (* 1 = 0.69434 loss)
I0701 12:45:59.940590  2788 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0701 12:46:23.753044  2788 solver.cpp:236] Iteration 1310, loss = 0.693174
I0701 12:46:23.753190  2788 solver.cpp:252]     Train net output #0: loss = 0.694746 (* 1 = 0.694746 loss)
I0701 12:46:23.753226  2788 sgd_solver.cpp:106] Iteration 1310, lr = 0.01
I0701 12:46:47.562546  2788 solver.cpp:236] Iteration 1320, loss = 0.693183
I0701 12:46:47.562610  2788 solver.cpp:252]     Train net output #0: loss = 0.692104 (* 1 = 0.692104 loss)
I0701 12:46:47.562628  2788 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0701 12:47:11.836220  2788 solver.cpp:236] Iteration 1330, loss = 0.693233
I0701 12:47:11.836356  2788 solver.cpp:252]     Train net output #0: loss = 0.692558 (* 1 = 0.692558 loss)
I0701 12:47:11.836383  2788 sgd_solver.cpp:106] Iteration 1330, lr = 0.01
I0701 12:47:35.731088  2788 solver.cpp:236] Iteration 1340, loss = 0.693105
I0701 12:47:35.731127  2788 solver.cpp:252]     Train net output #0: loss = 0.69185 (* 1 = 0.69185 loss)
I0701 12:47:35.731137  2788 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0701 12:47:59.334182  2788 solver.cpp:236] Iteration 1350, loss = 0.692899
I0701 12:47:59.334345  2788 solver.cpp:252]     Train net output #0: loss = 0.687522 (* 1 = 0.687522 loss)
I0701 12:47:59.334362  2788 sgd_solver.cpp:106] Iteration 1350, lr = 0.01
I0701 12:48:24.048557  2788 solver.cpp:236] Iteration 1360, loss = 0.693074
I0701 12:48:24.048610  2788 solver.cpp:252]     Train net output #0: loss = 0.692166 (* 1 = 0.692166 loss)
I0701 12:48:24.048624  2788 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0701 12:48:47.976053  2788 solver.cpp:236] Iteration 1370, loss = 0.693102
I0701 12:48:47.976188  2788 solver.cpp:252]     Train net output #0: loss = 0.695899 (* 1 = 0.695899 loss)
I0701 12:48:47.976217  2788 sgd_solver.cpp:106] Iteration 1370, lr = 0.01
I0701 12:49:12.160665  2788 solver.cpp:236] Iteration 1380, loss = 0.693054
I0701 12:49:12.160730  2788 solver.cpp:252]     Train net output #0: loss = 0.693231 (* 1 = 0.693231 loss)
I0701 12:49:12.160745  2788 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0701 12:49:36.085813  2788 solver.cpp:236] Iteration 1390, loss = 0.692944
I0701 12:49:36.085955  2788 solver.cpp:252]     Train net output #0: loss = 0.685589 (* 1 = 0.685589 loss)
I0701 12:49:36.085999  2788 sgd_solver.cpp:106] Iteration 1390, lr = 0.01
I0701 12:50:00.014348  2788 solver.cpp:236] Iteration 1400, loss = 0.69364
I0701 12:50:00.014403  2788 solver.cpp:252]     Train net output #0: loss = 0.693216 (* 1 = 0.693216 loss)
I0701 12:50:00.014417  2788 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0701 12:50:23.857214  2788 solver.cpp:236] Iteration 1410, loss = 0.69361
I0701 12:50:23.857367  2788 solver.cpp:252]     Train net output #0: loss = 0.694139 (* 1 = 0.694139 loss)
I0701 12:50:23.857388  2788 sgd_solver.cpp:106] Iteration 1410, lr = 0.01
I0701 12:50:48.328847  2788 solver.cpp:236] Iteration 1420, loss = 0.693639
I0701 12:50:48.328913  2788 solver.cpp:252]     Train net output #0: loss = 0.693269 (* 1 = 0.693269 loss)
I0701 12:50:48.328927  2788 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0701 12:51:12.722741  2788 solver.cpp:236] Iteration 1430, loss = 0.693651
I0701 12:51:12.722885  2788 solver.cpp:252]     Train net output #0: loss = 0.692686 (* 1 = 0.692686 loss)
I0701 12:51:12.722940  2788 sgd_solver.cpp:106] Iteration 1430, lr = 0.01
I0701 12:51:36.634858  2788 solver.cpp:236] Iteration 1440, loss = 0.693982
I0701 12:51:36.634920  2788 solver.cpp:252]     Train net output #0: loss = 0.697376 (* 1 = 0.697376 loss)
I0701 12:51:36.634941  2788 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0701 12:52:01.305510  2788 solver.cpp:236] Iteration 1450, loss = 0.69347
I0701 12:52:01.305632  2788 solver.cpp:252]     Train net output #0: loss = 0.692903 (* 1 = 0.692903 loss)
I0701 12:52:01.305665  2788 sgd_solver.cpp:106] Iteration 1450, lr = 0.01
I0701 12:52:25.205518  2788 solver.cpp:236] Iteration 1460, loss = 0.693296
I0701 12:52:25.205575  2788 solver.cpp:252]     Train net output #0: loss = 0.692669 (* 1 = 0.692669 loss)
I0701 12:52:25.205590  2788 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0701 12:52:49.339169  2788 solver.cpp:236] Iteration 1470, loss = 0.693256
I0701 12:52:49.339269  2788 solver.cpp:252]     Train net output #0: loss = 0.6928 (* 1 = 0.6928 loss)
I0701 12:52:49.339285  2788 sgd_solver.cpp:106] Iteration 1470, lr = 0.01
I0701 12:53:13.606070  2788 solver.cpp:236] Iteration 1480, loss = 0.693173
I0701 12:53:13.606130  2788 solver.cpp:252]     Train net output #0: loss = 0.692328 (* 1 = 0.692328 loss)
I0701 12:53:13.606145  2788 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0701 12:53:37.542106  2788 solver.cpp:236] Iteration 1490, loss = 0.693244
I0701 12:53:37.542248  2788 solver.cpp:252]     Train net output #0: loss = 0.695972 (* 1 = 0.695972 loss)
I0701 12:53:37.542268  2788 sgd_solver.cpp:106] Iteration 1490, lr = 0.01
I0701 12:53:59.149018  2788 solver.cpp:340] Iteration 1500, Testing net (#0)
I0701 12:54:17.111562  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 12:54:50.603302  2788 solver.cpp:408]     Test net output #0: accuracy = 0.50375
I0701 12:54:50.603422  2788 solver.cpp:408]     Test net output #1: loss = 0.693139 (* 1 = 0.693139 loss)
I0701 12:54:50.833654  2788 solver.cpp:236] Iteration 1500, loss = 0.693247
I0701 12:54:50.833715  2788 solver.cpp:252]     Train net output #0: loss = 0.693304 (* 1 = 0.693304 loss)
I0701 12:54:50.833731  2788 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0701 12:55:10.497633  2788 solver.cpp:236] Iteration 1510, loss = 0.693154
I0701 12:55:10.497702  2788 solver.cpp:252]     Train net output #0: loss = 0.693834 (* 1 = 0.693834 loss)
I0701 12:55:10.497717  2788 sgd_solver.cpp:106] Iteration 1510, lr = 0.01
I0701 12:55:34.465566  2788 solver.cpp:236] Iteration 1520, loss = 0.693398
I0701 12:55:34.465749  2788 solver.cpp:252]     Train net output #0: loss = 0.698048 (* 1 = 0.698048 loss)
I0701 12:55:34.465770  2788 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0701 12:55:58.266880  2788 solver.cpp:236] Iteration 1530, loss = 0.693224
I0701 12:55:58.266947  2788 solver.cpp:252]     Train net output #0: loss = 0.693545 (* 1 = 0.693545 loss)
I0701 12:55:58.266963  2788 sgd_solver.cpp:106] Iteration 1530, lr = 0.01
I0701 12:56:22.532699  2788 solver.cpp:236] Iteration 1540, loss = 0.693153
I0701 12:56:22.532819  2788 solver.cpp:252]     Train net output #0: loss = 0.693802 (* 1 = 0.693802 loss)
I0701 12:56:22.532845  2788 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0701 12:56:46.670328  2788 solver.cpp:236] Iteration 1550, loss = 0.692983
I0701 12:56:46.670389  2788 solver.cpp:252]     Train net output #0: loss = 0.692236 (* 1 = 0.692236 loss)
I0701 12:56:46.670404  2788 sgd_solver.cpp:106] Iteration 1550, lr = 0.01
I0701 12:57:10.660411  2788 solver.cpp:236] Iteration 1560, loss = 0.693143
I0701 12:57:10.660607  2788 solver.cpp:252]     Train net output #0: loss = 0.695553 (* 1 = 0.695553 loss)
I0701 12:57:10.660624  2788 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0701 12:57:35.004283  2788 solver.cpp:236] Iteration 1570, loss = 0.692801
I0701 12:57:35.004355  2788 solver.cpp:252]     Train net output #0: loss = 0.692158 (* 1 = 0.692158 loss)
I0701 12:57:35.004370  2788 sgd_solver.cpp:106] Iteration 1570, lr = 0.01
I0701 12:57:58.936761  2788 solver.cpp:236] Iteration 1580, loss = 0.692975
I0701 12:57:58.936914  2788 solver.cpp:252]     Train net output #0: loss = 0.692295 (* 1 = 0.692295 loss)
I0701 12:57:58.936941  2788 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0701 12:58:23.064713  2788 solver.cpp:236] Iteration 1590, loss = 0.692908
I0701 12:58:23.064777  2788 solver.cpp:252]     Train net output #0: loss = 0.693301 (* 1 = 0.693301 loss)
I0701 12:58:23.064795  2788 sgd_solver.cpp:106] Iteration 1590, lr = 0.01
I0701 12:58:47.349145  2788 solver.cpp:236] Iteration 1600, loss = 0.69319
I0701 12:58:47.349274  2788 solver.cpp:252]     Train net output #0: loss = 0.695936 (* 1 = 0.695936 loss)
I0701 12:58:47.349301  2788 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0701 12:59:11.001974  2788 solver.cpp:236] Iteration 1610, loss = 0.693188
I0701 12:59:11.002032  2788 solver.cpp:252]     Train net output #0: loss = 0.693489 (* 1 = 0.693489 loss)
I0701 12:59:11.002050  2788 sgd_solver.cpp:106] Iteration 1610, lr = 0.01
I0701 12:59:34.886405  2788 solver.cpp:236] Iteration 1620, loss = 0.693371
I0701 12:59:34.886519  2788 solver.cpp:252]     Train net output #0: loss = 0.694948 (* 1 = 0.694948 loss)
I0701 12:59:34.886546  2788 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0701 12:59:59.139590  2788 solver.cpp:236] Iteration 1630, loss = 0.693512
I0701 12:59:59.139652  2788 solver.cpp:252]     Train net output #0: loss = 0.693161 (* 1 = 0.693161 loss)
I0701 12:59:59.139667  2788 sgd_solver.cpp:106] Iteration 1630, lr = 0.01
I0701 13:00:23.624145  2788 solver.cpp:236] Iteration 1640, loss = 0.6935
I0701 13:00:23.624243  2788 solver.cpp:252]     Train net output #0: loss = 0.69393 (* 1 = 0.69393 loss)
I0701 13:00:23.624258  2788 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0701 13:00:47.722852  2788 solver.cpp:236] Iteration 1650, loss = 0.693438
I0701 13:00:47.722919  2788 solver.cpp:252]     Train net output #0: loss = 0.692874 (* 1 = 0.692874 loss)
I0701 13:00:47.722937  2788 sgd_solver.cpp:106] Iteration 1650, lr = 0.01
I0701 13:01:03.566714  2788 solver.cpp:236] Iteration 1660, loss = 0.693404
I0701 13:01:03.566843  2788 solver.cpp:252]     Train net output #0: loss = 0.693734 (* 1 = 0.693734 loss)
I0701 13:01:03.566872  2788 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0701 13:01:16.738859  2788 solver.cpp:236] Iteration 1670, loss = 0.693244
I0701 13:01:16.738934  2788 solver.cpp:252]     Train net output #0: loss = 0.69201 (* 1 = 0.69201 loss)
I0701 13:01:16.738950  2788 sgd_solver.cpp:106] Iteration 1670, lr = 0.01
I0701 13:01:29.404372  2788 solver.cpp:236] Iteration 1680, loss = 0.693187
I0701 13:01:29.404433  2788 solver.cpp:252]     Train net output #0: loss = 0.688923 (* 1 = 0.688923 loss)
I0701 13:01:29.404449  2788 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0701 13:01:42.891156  2788 solver.cpp:236] Iteration 1690, loss = 0.69318
I0701 13:01:42.891362  2788 solver.cpp:252]     Train net output #0: loss = 0.694185 (* 1 = 0.694185 loss)
I0701 13:01:42.891381  2788 sgd_solver.cpp:106] Iteration 1690, lr = 0.01
I0701 13:01:56.262045  2788 solver.cpp:236] Iteration 1700, loss = 0.693154
I0701 13:01:56.262109  2788 solver.cpp:252]     Train net output #0: loss = 0.696419 (* 1 = 0.696419 loss)
I0701 13:01:56.262125  2788 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0701 13:02:09.525530  2788 solver.cpp:236] Iteration 1710, loss = 0.692903
I0701 13:02:09.525593  2788 solver.cpp:252]     Train net output #0: loss = 0.694966 (* 1 = 0.694966 loss)
I0701 13:02:09.525610  2788 sgd_solver.cpp:106] Iteration 1710, lr = 0.01
I0701 13:02:22.344620  2788 solver.cpp:236] Iteration 1720, loss = 0.693237
I0701 13:02:22.344792  2788 solver.cpp:252]     Train net output #0: loss = 0.692608 (* 1 = 0.692608 loss)
I0701 13:02:22.344808  2788 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0701 13:02:34.786854  2788 solver.cpp:236] Iteration 1730, loss = 0.693104
I0701 13:02:34.786914  2788 solver.cpp:252]     Train net output #0: loss = 0.6911 (* 1 = 0.6911 loss)
I0701 13:02:34.786929  2788 sgd_solver.cpp:106] Iteration 1730, lr = 0.01
I0701 13:02:48.193425  2788 solver.cpp:236] Iteration 1740, loss = 0.693134
I0701 13:02:48.193495  2788 solver.cpp:252]     Train net output #0: loss = 0.690632 (* 1 = 0.690632 loss)
I0701 13:02:48.193511  2788 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0701 13:02:59.732209  2788 solver.cpp:340] Iteration 1750, Testing net (#0)
I0701 13:03:50.477473  2788 solver.cpp:408]     Test net output #0: accuracy = 0.489688
I0701 13:03:50.477638  2788 solver.cpp:408]     Test net output #1: loss = 0.693616 (* 1 = 0.693616 loss)
I0701 13:03:50.705781  2788 solver.cpp:236] Iteration 1750, loss = 0.693263
I0701 13:03:50.705860  2788 solver.cpp:252]     Train net output #0: loss = 0.693535 (* 1 = 0.693535 loss)
I0701 13:03:50.705883  2788 sgd_solver.cpp:106] Iteration 1750, lr = 0.01
I0701 13:04:01.643198  2788 solver.cpp:236] Iteration 1760, loss = 0.693443
I0701 13:04:01.643270  2788 solver.cpp:252]     Train net output #0: loss = 0.693728 (* 1 = 0.693728 loss)
I0701 13:04:01.643286  2788 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0701 13:04:14.802120  2788 solver.cpp:236] Iteration 1770, loss = 0.693173
I0701 13:04:14.802191  2788 solver.cpp:252]     Train net output #0: loss = 0.69344 (* 1 = 0.69344 loss)
I0701 13:04:14.802207  2788 sgd_solver.cpp:106] Iteration 1770, lr = 0.01
I0701 13:04:27.842231  2788 solver.cpp:236] Iteration 1780, loss = 0.693352
I0701 13:04:27.842334  2788 solver.cpp:252]     Train net output #0: loss = 0.693217 (* 1 = 0.693217 loss)
I0701 13:04:27.842349  2788 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0701 13:04:41.190709  2788 solver.cpp:236] Iteration 1790, loss = 0.693315
I0701 13:04:41.190773  2788 solver.cpp:252]     Train net output #0: loss = 0.69308 (* 1 = 0.69308 loss)
I0701 13:04:41.190788  2788 sgd_solver.cpp:106] Iteration 1790, lr = 0.01
I0701 13:04:54.355572  2788 solver.cpp:236] Iteration 1800, loss = 0.693168
I0701 13:04:54.355625  2788 solver.cpp:252]     Train net output #0: loss = 0.693585 (* 1 = 0.693585 loss)
I0701 13:04:54.355641  2788 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0701 13:05:07.946226  2788 solver.cpp:236] Iteration 1810, loss = 0.693327
I0701 13:05:07.946341  2788 solver.cpp:252]     Train net output #0: loss = 0.69356 (* 1 = 0.69356 loss)
I0701 13:05:07.946357  2788 sgd_solver.cpp:106] Iteration 1810, lr = 0.01
I0701 13:05:20.632118  2788 solver.cpp:236] Iteration 1820, loss = 0.693325
I0701 13:05:20.632194  2788 solver.cpp:252]     Train net output #0: loss = 0.689842 (* 1 = 0.689842 loss)
I0701 13:05:20.632215  2788 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0701 13:05:33.437841  2788 solver.cpp:236] Iteration 1830, loss = 0.693251
I0701 13:05:33.437912  2788 solver.cpp:252]     Train net output #0: loss = 0.693761 (* 1 = 0.693761 loss)
I0701 13:05:33.437937  2788 sgd_solver.cpp:106] Iteration 1830, lr = 0.01
I0701 13:05:46.212566  2788 solver.cpp:236] Iteration 1840, loss = 0.693398
I0701 13:05:46.212705  2788 solver.cpp:252]     Train net output #0: loss = 0.692558 (* 1 = 0.692558 loss)
I0701 13:05:46.212733  2788 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0701 13:05:59.177856  2788 solver.cpp:236] Iteration 1850, loss = 0.693432
I0701 13:05:59.177919  2788 solver.cpp:252]     Train net output #0: loss = 0.693016 (* 1 = 0.693016 loss)
I0701 13:05:59.177943  2788 sgd_solver.cpp:106] Iteration 1850, lr = 0.01
I0701 13:06:12.215788  2788 solver.cpp:236] Iteration 1860, loss = 0.693334
I0701 13:06:12.215852  2788 solver.cpp:252]     Train net output #0: loss = 0.693174 (* 1 = 0.693174 loss)
I0701 13:06:12.215869  2788 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0701 13:06:25.850332  2788 solver.cpp:236] Iteration 1870, loss = 0.693283
I0701 13:06:25.850534  2788 solver.cpp:252]     Train net output #0: loss = 0.691627 (* 1 = 0.691627 loss)
I0701 13:06:25.850551  2788 sgd_solver.cpp:106] Iteration 1870, lr = 0.01
I0701 13:06:39.039139  2788 solver.cpp:236] Iteration 1880, loss = 0.693453
I0701 13:06:39.039207  2788 solver.cpp:252]     Train net output #0: loss = 0.693273 (* 1 = 0.693273 loss)
I0701 13:06:39.039223  2788 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0701 13:06:52.339350  2788 solver.cpp:236] Iteration 1890, loss = 0.693308
I0701 13:06:52.339418  2788 solver.cpp:252]     Train net output #0: loss = 0.693346 (* 1 = 0.693346 loss)
I0701 13:06:52.339433  2788 sgd_solver.cpp:106] Iteration 1890, lr = 0.01
I0701 13:07:05.329159  2788 solver.cpp:236] Iteration 1900, loss = 0.693222
I0701 13:07:05.329273  2788 solver.cpp:252]     Train net output #0: loss = 0.691353 (* 1 = 0.691353 loss)
I0701 13:07:05.329288  2788 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0701 13:07:18.172457  2788 solver.cpp:236] Iteration 1910, loss = 0.693238
I0701 13:07:18.172516  2788 solver.cpp:252]     Train net output #0: loss = 0.696493 (* 1 = 0.696493 loss)
I0701 13:07:18.172536  2788 sgd_solver.cpp:106] Iteration 1910, lr = 0.01
I0701 13:07:31.980394  2788 solver.cpp:236] Iteration 1920, loss = 0.693364
I0701 13:07:31.980479  2788 solver.cpp:252]     Train net output #0: loss = 0.696499 (* 1 = 0.696499 loss)
I0701 13:07:31.980495  2788 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0701 13:07:44.719061  2788 solver.cpp:236] Iteration 1930, loss = 0.693089
I0701 13:07:44.719245  2788 solver.cpp:252]     Train net output #0: loss = 0.691938 (* 1 = 0.691938 loss)
I0701 13:07:44.719272  2788 sgd_solver.cpp:106] Iteration 1930, lr = 0.01
I0701 13:07:57.461568  2788 solver.cpp:236] Iteration 1940, loss = 0.692946
I0701 13:07:57.461635  2788 solver.cpp:252]     Train net output #0: loss = 0.694137 (* 1 = 0.694137 loss)
I0701 13:07:57.461650  2788 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0701 13:08:10.807350  2788 solver.cpp:236] Iteration 1950, loss = 0.693092
I0701 13:08:10.807402  2788 solver.cpp:252]     Train net output #0: loss = 0.693126 (* 1 = 0.693126 loss)
I0701 13:08:10.807416  2788 sgd_solver.cpp:106] Iteration 1950, lr = 0.01
I0701 13:08:23.666095  2788 solver.cpp:236] Iteration 1960, loss = 0.6933
I0701 13:08:23.666272  2788 solver.cpp:252]     Train net output #0: loss = 0.693152 (* 1 = 0.693152 loss)
I0701 13:08:23.666301  2788 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0701 13:08:36.828647  2788 solver.cpp:236] Iteration 1970, loss = 0.693223
I0701 13:08:36.828702  2788 solver.cpp:252]     Train net output #0: loss = 0.693029 (* 1 = 0.693029 loss)
I0701 13:08:36.828716  2788 sgd_solver.cpp:106] Iteration 1970, lr = 0.01
I0701 13:08:49.644471  2788 solver.cpp:236] Iteration 1980, loss = 0.693319
I0701 13:08:49.644553  2788 solver.cpp:252]     Train net output #0: loss = 0.69466 (* 1 = 0.69466 loss)
I0701 13:08:49.644567  2788 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0701 13:09:02.075426  2788 solver.cpp:236] Iteration 1990, loss = 0.693477
I0701 13:09:02.075544  2788 solver.cpp:252]     Train net output #0: loss = 0.693383 (* 1 = 0.693383 loss)
I0701 13:09:02.075570  2788 sgd_solver.cpp:106] Iteration 1990, lr = 0.01
I0701 13:09:14.548910  2788 solver.cpp:340] Iteration 2000, Testing net (#0)
I0701 13:09:49.027786  2788 solver.cpp:408]     Test net output #0: accuracy = 0.501875
I0701 13:09:49.027899  2788 solver.cpp:408]     Test net output #1: loss = 0.693141 (* 1 = 0.693141 loss)
I0701 13:09:49.263636  2788 solver.cpp:236] Iteration 2000, loss = 0.693448
I0701 13:09:49.263700  2788 solver.cpp:252]     Train net output #0: loss = 0.693241 (* 1 = 0.693241 loss)
I0701 13:09:49.263716  2788 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0701 13:09:59.809952  2788 solver.cpp:236] Iteration 2010, loss = 0.693223
I0701 13:09:59.810008  2788 solver.cpp:252]     Train net output #0: loss = 0.693195 (* 1 = 0.693195 loss)
I0701 13:09:59.810020  2788 sgd_solver.cpp:106] Iteration 2010, lr = 0.01
I0701 13:10:12.552723  2788 solver.cpp:236] Iteration 2020, loss = 0.693281
I0701 13:10:12.552784  2788 solver.cpp:252]     Train net output #0: loss = 0.693194 (* 1 = 0.693194 loss)
I0701 13:10:12.552799  2788 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0701 13:10:25.742492  2788 solver.cpp:236] Iteration 2030, loss = 0.693347
I0701 13:10:25.742641  2788 solver.cpp:252]     Train net output #0: loss = 0.697169 (* 1 = 0.697169 loss)
I0701 13:10:25.742665  2788 sgd_solver.cpp:106] Iteration 2030, lr = 0.01
I0701 13:10:38.773321  2788 solver.cpp:236] Iteration 2040, loss = 0.693397
I0701 13:10:38.773383  2788 solver.cpp:252]     Train net output #0: loss = 0.693977 (* 1 = 0.693977 loss)
I0701 13:10:38.773397  2788 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0701 13:10:51.230886  2788 solver.cpp:236] Iteration 2050, loss = 0.693381
I0701 13:10:51.230950  2788 solver.cpp:252]     Train net output #0: loss = 0.694558 (* 1 = 0.694558 loss)
I0701 13:10:51.230964  2788 sgd_solver.cpp:106] Iteration 2050, lr = 0.01
I0701 13:11:03.753180  2788 solver.cpp:236] Iteration 2060, loss = 0.693495
I0701 13:11:03.753317  2788 solver.cpp:252]     Train net output #0: loss = 0.692924 (* 1 = 0.692924 loss)
I0701 13:11:03.753334  2788 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0701 13:11:16.546675  2788 solver.cpp:236] Iteration 2070, loss = 0.693398
I0701 13:11:16.546737  2788 solver.cpp:252]     Train net output #0: loss = 0.691702 (* 1 = 0.691702 loss)
I0701 13:11:16.546752  2788 sgd_solver.cpp:106] Iteration 2070, lr = 0.01
I0701 13:11:30.239639  2788 solver.cpp:236] Iteration 2080, loss = 0.693421
I0701 13:11:30.239708  2788 solver.cpp:252]     Train net output #0: loss = 0.696971 (* 1 = 0.696971 loss)
I0701 13:11:30.239727  2788 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0701 13:11:43.424775  2788 solver.cpp:236] Iteration 2090, loss = 0.693466
I0701 13:11:43.424898  2788 solver.cpp:252]     Train net output #0: loss = 0.693168 (* 1 = 0.693168 loss)
I0701 13:11:43.424914  2788 sgd_solver.cpp:106] Iteration 2090, lr = 0.01
I0701 13:11:56.357632  2788 solver.cpp:236] Iteration 2100, loss = 0.693421
I0701 13:11:56.357697  2788 solver.cpp:252]     Train net output #0: loss = 0.693067 (* 1 = 0.693067 loss)
I0701 13:11:56.357712  2788 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0701 13:12:09.523252  2788 solver.cpp:236] Iteration 2110, loss = 0.693412
I0701 13:12:09.523318  2788 solver.cpp:252]     Train net output #0: loss = 0.694779 (* 1 = 0.694779 loss)
I0701 13:12:09.523331  2788 sgd_solver.cpp:106] Iteration 2110, lr = 0.01
I0701 13:12:22.201522  2788 solver.cpp:236] Iteration 2120, loss = 0.693485
I0701 13:12:22.201647  2788 solver.cpp:252]     Train net output #0: loss = 0.69327 (* 1 = 0.69327 loss)
I0701 13:12:22.201673  2788 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0701 13:12:35.300217  2788 solver.cpp:236] Iteration 2130, loss = 0.693535
I0701 13:12:35.300298  2788 solver.cpp:252]     Train net output #0: loss = 0.695624 (* 1 = 0.695624 loss)
I0701 13:12:35.300314  2788 sgd_solver.cpp:106] Iteration 2130, lr = 0.01
I0701 13:12:48.702455  2788 solver.cpp:236] Iteration 2140, loss = 0.69346
I0701 13:12:48.702538  2788 solver.cpp:252]     Train net output #0: loss = 0.696447 (* 1 = 0.696447 loss)
I0701 13:12:48.702554  2788 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0701 13:13:01.094018  2788 solver.cpp:236] Iteration 2150, loss = 0.693423
I0701 13:13:01.094156  2788 solver.cpp:252]     Train net output #0: loss = 0.693142 (* 1 = 0.693142 loss)
I0701 13:13:01.094193  2788 sgd_solver.cpp:106] Iteration 2150, lr = 0.01
I0701 13:13:13.648238  2788 solver.cpp:236] Iteration 2160, loss = 0.693542
I0701 13:13:13.648300  2788 solver.cpp:252]     Train net output #0: loss = 0.694005 (* 1 = 0.694005 loss)
I0701 13:13:13.648314  2788 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0701 13:13:26.806637  2788 solver.cpp:236] Iteration 2170, loss = 0.693484
I0701 13:13:26.806705  2788 solver.cpp:252]     Train net output #0: loss = 0.692972 (* 1 = 0.692972 loss)
I0701 13:13:26.806720  2788 sgd_solver.cpp:106] Iteration 2170, lr = 0.01
I0701 13:13:39.298795  2788 solver.cpp:236] Iteration 2180, loss = 0.693389
I0701 13:13:39.298972  2788 solver.cpp:252]     Train net output #0: loss = 0.692169 (* 1 = 0.692169 loss)
I0701 13:13:39.298991  2788 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0701 13:13:52.655895  2788 solver.cpp:236] Iteration 2190, loss = 0.693362
I0701 13:13:52.655957  2788 solver.cpp:252]     Train net output #0: loss = 0.692952 (* 1 = 0.692952 loss)
I0701 13:13:52.655974  2788 sgd_solver.cpp:106] Iteration 2190, lr = 0.01
I0701 13:14:05.274441  2788 solver.cpp:236] Iteration 2200, loss = 0.693408
I0701 13:14:05.274507  2788 solver.cpp:252]     Train net output #0: loss = 0.693042 (* 1 = 0.693042 loss)
I0701 13:14:05.274521  2788 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0701 13:14:18.418535  2788 solver.cpp:236] Iteration 2210, loss = 0.693208
I0701 13:14:18.418666  2788 solver.cpp:252]     Train net output #0: loss = 0.694913 (* 1 = 0.694913 loss)
I0701 13:14:18.418683  2788 sgd_solver.cpp:106] Iteration 2210, lr = 0.01
I0701 13:14:31.281368  2788 solver.cpp:236] Iteration 2220, loss = 0.693247
I0701 13:14:31.281436  2788 solver.cpp:252]     Train net output #0: loss = 0.691578 (* 1 = 0.691578 loss)
I0701 13:14:31.281450  2788 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0701 13:14:43.471146  2788 solver.cpp:236] Iteration 2230, loss = 0.693222
I0701 13:14:43.471212  2788 solver.cpp:252]     Train net output #0: loss = 0.702076 (* 1 = 0.702076 loss)
I0701 13:14:43.471230  2788 sgd_solver.cpp:106] Iteration 2230, lr = 0.01
I0701 13:14:55.731840  2788 solver.cpp:236] Iteration 2240, loss = 0.693385
I0701 13:14:55.731956  2788 solver.cpp:252]     Train net output #0: loss = 0.686987 (* 1 = 0.686987 loss)
I0701 13:14:55.731984  2788 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0701 13:15:06.115479  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 13:15:07.372123  2788 solver.cpp:340] Iteration 2250, Testing net (#0)
I0701 13:15:34.074872  2788 solver.cpp:408]     Test net output #0: accuracy = 0.493437
I0701 13:15:34.074995  2788 solver.cpp:408]     Test net output #1: loss = 0.693215 (* 1 = 0.693215 loss)
I0701 13:15:34.314899  2788 solver.cpp:236] Iteration 2250, loss = 0.693597
I0701 13:15:34.314963  2788 solver.cpp:252]     Train net output #0: loss = 0.693506 (* 1 = 0.693506 loss)
I0701 13:15:34.314980  2788 sgd_solver.cpp:106] Iteration 2250, lr = 0.01
I0701 13:15:45.300740  2788 solver.cpp:236] Iteration 2260, loss = 0.693542
I0701 13:15:45.300788  2788 solver.cpp:252]     Train net output #0: loss = 0.696075 (* 1 = 0.696075 loss)
I0701 13:15:45.300802  2788 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0701 13:15:58.233613  2788 solver.cpp:236] Iteration 2270, loss = 0.693665
I0701 13:15:58.233676  2788 solver.cpp:252]     Train net output #0: loss = 0.699944 (* 1 = 0.699944 loss)
I0701 13:15:58.233690  2788 sgd_solver.cpp:106] Iteration 2270, lr = 0.01
I0701 13:16:10.562525  2788 solver.cpp:236] Iteration 2280, loss = 0.693771
I0701 13:16:10.562659  2788 solver.cpp:252]     Train net output #0: loss = 0.693283 (* 1 = 0.693283 loss)
I0701 13:16:10.562686  2788 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0701 13:16:23.193203  2788 solver.cpp:236] Iteration 2290, loss = 0.693631
I0701 13:16:23.193269  2788 solver.cpp:252]     Train net output #0: loss = 0.696549 (* 1 = 0.696549 loss)
I0701 13:16:23.193284  2788 sgd_solver.cpp:106] Iteration 2290, lr = 0.01
I0701 13:16:35.629623  2788 solver.cpp:236] Iteration 2300, loss = 0.693485
I0701 13:16:35.629685  2788 solver.cpp:252]     Train net output #0: loss = 0.692588 (* 1 = 0.692588 loss)
I0701 13:16:35.629710  2788 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0701 13:16:47.640444  2788 solver.cpp:236] Iteration 2310, loss = 0.693525
I0701 13:16:47.640599  2788 solver.cpp:252]     Train net output #0: loss = 0.692777 (* 1 = 0.692777 loss)
I0701 13:16:47.640628  2788 sgd_solver.cpp:106] Iteration 2310, lr = 0.01
I0701 13:17:00.379426  2788 solver.cpp:236] Iteration 2320, loss = 0.693424
I0701 13:17:00.379492  2788 solver.cpp:252]     Train net output #0: loss = 0.69424 (* 1 = 0.69424 loss)
I0701 13:17:00.379513  2788 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0701 13:17:12.561471  2788 solver.cpp:236] Iteration 2330, loss = 0.693378
I0701 13:17:12.561527  2788 solver.cpp:252]     Train net output #0: loss = 0.693584 (* 1 = 0.693584 loss)
I0701 13:17:12.561542  2788 sgd_solver.cpp:106] Iteration 2330, lr = 0.01
I0701 13:17:25.312095  2788 solver.cpp:236] Iteration 2340, loss = 0.693317
I0701 13:17:25.312275  2788 solver.cpp:252]     Train net output #0: loss = 0.694828 (* 1 = 0.694828 loss)
I0701 13:17:25.312304  2788 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0701 13:17:38.326928  2788 solver.cpp:236] Iteration 2350, loss = 0.693339
I0701 13:17:38.327000  2788 solver.cpp:252]     Train net output #0: loss = 0.696048 (* 1 = 0.696048 loss)
I0701 13:17:38.327016  2788 sgd_solver.cpp:106] Iteration 2350, lr = 0.01
I0701 13:17:50.878937  2788 solver.cpp:236] Iteration 2360, loss = 0.693119
I0701 13:17:50.879001  2788 solver.cpp:252]     Train net output #0: loss = 0.691819 (* 1 = 0.691819 loss)
I0701 13:17:50.879017  2788 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0701 13:18:03.227905  2788 solver.cpp:236] Iteration 2370, loss = 0.693281
I0701 13:18:03.228050  2788 solver.cpp:252]     Train net output #0: loss = 0.695765 (* 1 = 0.695765 loss)
I0701 13:18:03.228078  2788 sgd_solver.cpp:106] Iteration 2370, lr = 0.01
I0701 13:18:16.794190  2788 solver.cpp:236] Iteration 2380, loss = 0.693199
I0701 13:18:16.794248  2788 solver.cpp:252]     Train net output #0: loss = 0.693566 (* 1 = 0.693566 loss)
I0701 13:18:16.794262  2788 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0701 13:18:29.175756  2788 solver.cpp:236] Iteration 2390, loss = 0.693244
I0701 13:18:29.175833  2788 solver.cpp:252]     Train net output #0: loss = 0.693707 (* 1 = 0.693707 loss)
I0701 13:18:29.175853  2788 sgd_solver.cpp:106] Iteration 2390, lr = 0.01
I0701 13:18:41.817667  2788 solver.cpp:236] Iteration 2400, loss = 0.693146
I0701 13:18:41.817847  2788 solver.cpp:252]     Train net output #0: loss = 0.693091 (* 1 = 0.693091 loss)
I0701 13:18:41.817865  2788 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0701 13:18:54.006474  2788 solver.cpp:236] Iteration 2410, loss = 0.693366
I0701 13:18:54.006526  2788 solver.cpp:252]     Train net output #0: loss = 0.692926 (* 1 = 0.692926 loss)
I0701 13:18:54.006541  2788 sgd_solver.cpp:106] Iteration 2410, lr = 0.01
I0701 13:19:07.125206  2788 solver.cpp:236] Iteration 2420, loss = 0.693189
I0701 13:19:07.125273  2788 solver.cpp:252]     Train net output #0: loss = 0.692934 (* 1 = 0.692934 loss)
I0701 13:19:07.125286  2788 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0701 13:19:20.250488  2788 solver.cpp:236] Iteration 2430, loss = 0.693248
I0701 13:19:20.250600  2788 solver.cpp:252]     Train net output #0: loss = 0.692747 (* 1 = 0.692747 loss)
I0701 13:19:20.250617  2788 sgd_solver.cpp:106] Iteration 2430, lr = 0.01
I0701 13:19:32.394366  2788 solver.cpp:236] Iteration 2440, loss = 0.693243
I0701 13:19:32.394431  2788 solver.cpp:252]     Train net output #0: loss = 0.693239 (* 1 = 0.693239 loss)
I0701 13:19:32.394445  2788 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0701 13:19:45.005987  2788 solver.cpp:236] Iteration 2450, loss = 0.693283
I0701 13:19:45.006070  2788 solver.cpp:252]     Train net output #0: loss = 0.69264 (* 1 = 0.69264 loss)
I0701 13:19:45.006088  2788 sgd_solver.cpp:106] Iteration 2450, lr = 0.01
I0701 13:19:58.169315  2788 solver.cpp:236] Iteration 2460, loss = 0.693275
I0701 13:19:58.169456  2788 solver.cpp:252]     Train net output #0: loss = 0.693296 (* 1 = 0.693296 loss)
I0701 13:19:58.169472  2788 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0701 13:20:10.817003  2788 solver.cpp:236] Iteration 2470, loss = 0.693174
I0701 13:20:10.817067  2788 solver.cpp:252]     Train net output #0: loss = 0.691786 (* 1 = 0.691786 loss)
I0701 13:20:10.817081  2788 sgd_solver.cpp:106] Iteration 2470, lr = 0.01
I0701 13:20:23.948079  2788 solver.cpp:236] Iteration 2480, loss = 0.693248
I0701 13:20:23.948146  2788 solver.cpp:252]     Train net output #0: loss = 0.690277 (* 1 = 0.690277 loss)
I0701 13:20:23.948163  2788 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0701 13:20:36.646222  2788 solver.cpp:236] Iteration 2490, loss = 0.69334
I0701 13:20:36.646399  2788 solver.cpp:252]     Train net output #0: loss = 0.69316 (* 1 = 0.69316 loss)
I0701 13:20:36.646414  2788 sgd_solver.cpp:106] Iteration 2490, lr = 0.01
I0701 13:20:48.717367  2788 solver.cpp:340] Iteration 2500, Testing net (#0)
I0701 13:21:15.035266  2788 solver.cpp:408]     Test net output #0: accuracy = 0.504062
I0701 13:21:15.035390  2788 solver.cpp:408]     Test net output #1: loss = 0.693114 (* 1 = 0.693114 loss)
I0701 13:21:15.269443  2788 solver.cpp:236] Iteration 2500, loss = 0.6933
I0701 13:21:15.269502  2788 solver.cpp:252]     Train net output #0: loss = 0.692502 (* 1 = 0.692502 loss)
I0701 13:21:15.269520  2788 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0701 13:21:25.815127  2788 solver.cpp:236] Iteration 2510, loss = 0.693304
I0701 13:21:25.815196  2788 solver.cpp:252]     Train net output #0: loss = 0.69383 (* 1 = 0.69383 loss)
I0701 13:21:25.815212  2788 sgd_solver.cpp:106] Iteration 2510, lr = 0.01
I0701 13:21:38.572654  2788 solver.cpp:236] Iteration 2520, loss = 0.693381
I0701 13:21:38.572711  2788 solver.cpp:252]     Train net output #0: loss = 0.693007 (* 1 = 0.693007 loss)
I0701 13:21:38.572726  2788 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0701 13:21:51.223024  2788 solver.cpp:236] Iteration 2530, loss = 0.693339
I0701 13:21:51.223168  2788 solver.cpp:252]     Train net output #0: loss = 0.692874 (* 1 = 0.692874 loss)
I0701 13:21:51.223196  2788 sgd_solver.cpp:106] Iteration 2530, lr = 0.01
I0701 13:22:03.750730  2788 solver.cpp:236] Iteration 2540, loss = 0.693279
I0701 13:22:03.750793  2788 solver.cpp:252]     Train net output #0: loss = 0.695335 (* 1 = 0.695335 loss)
I0701 13:22:03.750808  2788 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0701 13:22:17.262953  2788 solver.cpp:236] Iteration 2550, loss = 0.693277
I0701 13:22:17.263025  2788 solver.cpp:252]     Train net output #0: loss = 0.692012 (* 1 = 0.692012 loss)
I0701 13:22:17.263041  2788 sgd_solver.cpp:106] Iteration 2550, lr = 0.01
I0701 13:22:30.273391  2788 solver.cpp:236] Iteration 2560, loss = 0.693284
I0701 13:22:30.273535  2788 solver.cpp:252]     Train net output #0: loss = 0.693576 (* 1 = 0.693576 loss)
I0701 13:22:30.273555  2788 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0701 13:22:42.746789  2788 solver.cpp:236] Iteration 2570, loss = 0.693295
I0701 13:22:42.746860  2788 solver.cpp:252]     Train net output #0: loss = 0.692692 (* 1 = 0.692692 loss)
I0701 13:22:42.746877  2788 sgd_solver.cpp:106] Iteration 2570, lr = 0.01
I0701 13:22:55.689543  2788 solver.cpp:236] Iteration 2580, loss = 0.693347
I0701 13:22:55.689612  2788 solver.cpp:252]     Train net output #0: loss = 0.696159 (* 1 = 0.696159 loss)
I0701 13:22:55.689626  2788 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0701 13:23:07.879333  2788 solver.cpp:236] Iteration 2590, loss = 0.693318
I0701 13:23:07.879451  2788 solver.cpp:252]     Train net output #0: loss = 0.693496 (* 1 = 0.693496 loss)
I0701 13:23:07.879467  2788 sgd_solver.cpp:106] Iteration 2590, lr = 0.01
I0701 13:23:20.634750  2788 solver.cpp:236] Iteration 2600, loss = 0.693273
I0701 13:23:20.634812  2788 solver.cpp:252]     Train net output #0: loss = 0.691465 (* 1 = 0.691465 loss)
I0701 13:23:20.634829  2788 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0701 13:23:33.062468  2788 solver.cpp:236] Iteration 2610, loss = 0.693272
I0701 13:23:33.062538  2788 solver.cpp:252]     Train net output #0: loss = 0.691724 (* 1 = 0.691724 loss)
I0701 13:23:33.062553  2788 sgd_solver.cpp:106] Iteration 2610, lr = 0.01
I0701 13:23:45.680699  2788 solver.cpp:236] Iteration 2620, loss = 0.693351
I0701 13:23:45.680841  2788 solver.cpp:252]     Train net output #0: loss = 0.694311 (* 1 = 0.694311 loss)
I0701 13:23:45.680876  2788 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0701 13:23:58.148319  2788 solver.cpp:236] Iteration 2630, loss = 0.693113
I0701 13:23:58.148388  2788 solver.cpp:252]     Train net output #0: loss = 0.691556 (* 1 = 0.691556 loss)
I0701 13:23:58.148406  2788 sgd_solver.cpp:106] Iteration 2630, lr = 0.01
I0701 13:24:10.822258  2788 solver.cpp:236] Iteration 2640, loss = 0.693099
I0701 13:24:10.822299  2788 solver.cpp:252]     Train net output #0: loss = 0.693732 (* 1 = 0.693732 loss)
I0701 13:24:10.822306  2788 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0701 13:24:23.874186  2788 solver.cpp:236] Iteration 2650, loss = 0.69313
I0701 13:24:23.874331  2788 solver.cpp:252]     Train net output #0: loss = 0.692475 (* 1 = 0.692475 loss)
I0701 13:24:23.874361  2788 sgd_solver.cpp:106] Iteration 2650, lr = 0.01
I0701 13:24:37.137270  2788 solver.cpp:236] Iteration 2660, loss = 0.693161
I0701 13:24:37.137326  2788 solver.cpp:252]     Train net output #0: loss = 0.693446 (* 1 = 0.693446 loss)
I0701 13:24:37.137346  2788 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0701 13:24:50.113603  2788 solver.cpp:236] Iteration 2670, loss = 0.693062
I0701 13:24:50.113667  2788 solver.cpp:252]     Train net output #0: loss = 0.692308 (* 1 = 0.692308 loss)
I0701 13:24:50.113689  2788 sgd_solver.cpp:106] Iteration 2670, lr = 0.01
I0701 13:25:03.180833  2788 solver.cpp:236] Iteration 2680, loss = 0.693239
I0701 13:25:03.180963  2788 solver.cpp:252]     Train net output #0: loss = 0.692525 (* 1 = 0.692525 loss)
I0701 13:25:03.180994  2788 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0701 13:25:16.226269  2788 solver.cpp:236] Iteration 2690, loss = 0.693258
I0701 13:25:16.226330  2788 solver.cpp:252]     Train net output #0: loss = 0.692891 (* 1 = 0.692891 loss)
I0701 13:25:16.226351  2788 sgd_solver.cpp:106] Iteration 2690, lr = 0.01
I0701 13:25:29.115423  2788 solver.cpp:236] Iteration 2700, loss = 0.693301
I0701 13:25:29.115480  2788 solver.cpp:252]     Train net output #0: loss = 0.693149 (* 1 = 0.693149 loss)
I0701 13:25:29.115499  2788 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0701 13:25:42.398288  2788 solver.cpp:236] Iteration 2710, loss = 0.693274
I0701 13:25:42.398427  2788 solver.cpp:252]     Train net output #0: loss = 0.693258 (* 1 = 0.693258 loss)
I0701 13:25:42.398454  2788 sgd_solver.cpp:106] Iteration 2710, lr = 0.01
I0701 13:25:54.777854  2788 solver.cpp:236] Iteration 2720, loss = 0.693215
I0701 13:25:54.777915  2788 solver.cpp:252]     Train net output #0: loss = 0.691794 (* 1 = 0.691794 loss)
I0701 13:25:54.777930  2788 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0701 13:26:07.572067  2788 solver.cpp:236] Iteration 2730, loss = 0.693054
I0701 13:26:07.572120  2788 solver.cpp:252]     Train net output #0: loss = 0.693889 (* 1 = 0.693889 loss)
I0701 13:26:07.572134  2788 sgd_solver.cpp:106] Iteration 2730, lr = 0.01
I0701 13:26:20.324730  2788 solver.cpp:236] Iteration 2740, loss = 0.692931
I0701 13:26:20.324856  2788 solver.cpp:252]     Train net output #0: loss = 0.69207 (* 1 = 0.69207 loss)
I0701 13:26:20.324872  2788 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0701 13:26:31.894254  2788 solver.cpp:340] Iteration 2750, Testing net (#0)
I0701 13:26:57.811467  2788 solver.cpp:408]     Test net output #0: accuracy = 0.49
I0701 13:26:57.811615  2788 solver.cpp:408]     Test net output #1: loss = 0.693677 (* 1 = 0.693677 loss)
I0701 13:26:58.042395  2788 solver.cpp:236] Iteration 2750, loss = 0.693153
I0701 13:26:58.042459  2788 solver.cpp:252]     Train net output #0: loss = 0.691891 (* 1 = 0.691891 loss)
I0701 13:26:58.042475  2788 sgd_solver.cpp:106] Iteration 2750, lr = 0.01
I0701 13:27:08.713976  2788 solver.cpp:236] Iteration 2760, loss = 0.693146
I0701 13:27:08.714041  2788 solver.cpp:252]     Train net output #0: loss = 0.693003 (* 1 = 0.693003 loss)
I0701 13:27:08.714056  2788 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0701 13:27:21.677249  2788 solver.cpp:236] Iteration 2770, loss = 0.693253
I0701 13:27:21.677320  2788 solver.cpp:252]     Train net output #0: loss = 0.693197 (* 1 = 0.693197 loss)
I0701 13:27:21.677337  2788 sgd_solver.cpp:106] Iteration 2770, lr = 0.01
I0701 13:27:34.436877  2788 solver.cpp:236] Iteration 2780, loss = 0.69339
I0701 13:27:34.437103  2788 solver.cpp:252]     Train net output #0: loss = 0.69291 (* 1 = 0.69291 loss)
I0701 13:27:34.437119  2788 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0701 13:27:47.269713  2788 solver.cpp:236] Iteration 2790, loss = 0.693494
I0701 13:27:47.269783  2788 solver.cpp:252]     Train net output #0: loss = 0.693091 (* 1 = 0.693091 loss)
I0701 13:27:47.269798  2788 sgd_solver.cpp:106] Iteration 2790, lr = 0.01
I0701 13:27:59.850646  2788 solver.cpp:236] Iteration 2800, loss = 0.693287
I0701 13:27:59.850705  2788 solver.cpp:252]     Train net output #0: loss = 0.693591 (* 1 = 0.693591 loss)
I0701 13:27:59.850719  2788 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0701 13:28:12.867108  2788 solver.cpp:236] Iteration 2810, loss = 0.693322
I0701 13:28:12.867228  2788 solver.cpp:252]     Train net output #0: loss = 0.693299 (* 1 = 0.693299 loss)
I0701 13:28:12.867247  2788 sgd_solver.cpp:106] Iteration 2810, lr = 0.01
I0701 13:28:25.583299  2788 solver.cpp:236] Iteration 2820, loss = 0.693356
I0701 13:28:25.583359  2788 solver.cpp:252]     Train net output #0: loss = 0.69346 (* 1 = 0.69346 loss)
I0701 13:28:25.583380  2788 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0701 13:28:38.016568  2788 solver.cpp:236] Iteration 2830, loss = 0.693364
I0701 13:28:38.016624  2788 solver.cpp:252]     Train net output #0: loss = 0.693343 (* 1 = 0.693343 loss)
I0701 13:28:38.016638  2788 sgd_solver.cpp:106] Iteration 2830, lr = 0.01
I0701 13:28:50.725612  2788 solver.cpp:236] Iteration 2840, loss = 0.693405
I0701 13:28:50.725775  2788 solver.cpp:252]     Train net output #0: loss = 0.693368 (* 1 = 0.693368 loss)
I0701 13:28:50.725803  2788 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0701 13:29:03.812942  2788 solver.cpp:236] Iteration 2850, loss = 0.693086
I0701 13:29:03.813002  2788 solver.cpp:252]     Train net output #0: loss = 0.685319 (* 1 = 0.685319 loss)
I0701 13:29:03.813017  2788 sgd_solver.cpp:106] Iteration 2850, lr = 0.01
I0701 13:29:16.948401  2788 solver.cpp:236] Iteration 2860, loss = 0.69328
I0701 13:29:16.948487  2788 solver.cpp:252]     Train net output #0: loss = 0.692684 (* 1 = 0.692684 loss)
I0701 13:29:16.948504  2788 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0701 13:29:30.066262  2788 solver.cpp:236] Iteration 2870, loss = 0.693212
I0701 13:29:30.066390  2788 solver.cpp:252]     Train net output #0: loss = 0.694308 (* 1 = 0.694308 loss)
I0701 13:29:30.066416  2788 sgd_solver.cpp:106] Iteration 2870, lr = 0.01
I0701 13:29:43.035392  2788 solver.cpp:236] Iteration 2880, loss = 0.6933
I0701 13:29:43.035457  2788 solver.cpp:252]     Train net output #0: loss = 0.693389 (* 1 = 0.693389 loss)
I0701 13:29:43.035472  2788 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0701 13:29:56.245045  2788 solver.cpp:236] Iteration 2890, loss = 0.693258
I0701 13:29:56.245105  2788 solver.cpp:252]     Train net output #0: loss = 0.691923 (* 1 = 0.691923 loss)
I0701 13:29:56.245118  2788 sgd_solver.cpp:106] Iteration 2890, lr = 0.01
I0701 13:30:08.918539  2788 solver.cpp:236] Iteration 2900, loss = 0.693668
I0701 13:30:08.918663  2788 solver.cpp:252]     Train net output #0: loss = 0.694922 (* 1 = 0.694922 loss)
I0701 13:30:08.918694  2788 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0701 13:30:21.680163  2788 solver.cpp:236] Iteration 2910, loss = 0.693479
I0701 13:30:21.680238  2788 solver.cpp:252]     Train net output #0: loss = 0.693535 (* 1 = 0.693535 loss)
I0701 13:30:21.680253  2788 sgd_solver.cpp:106] Iteration 2910, lr = 0.01
I0701 13:30:34.486352  2788 solver.cpp:236] Iteration 2920, loss = 0.69351
I0701 13:30:34.486426  2788 solver.cpp:252]     Train net output #0: loss = 0.694803 (* 1 = 0.694803 loss)
I0701 13:30:34.486443  2788 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0701 13:30:48.128880  2788 solver.cpp:236] Iteration 2930, loss = 0.693401
I0701 13:30:48.129050  2788 solver.cpp:252]     Train net output #0: loss = 0.692845 (* 1 = 0.692845 loss)
I0701 13:30:48.129073  2788 sgd_solver.cpp:106] Iteration 2930, lr = 0.01
I0701 13:31:01.097729  2788 solver.cpp:236] Iteration 2940, loss = 0.693414
I0701 13:31:01.097791  2788 solver.cpp:252]     Train net output #0: loss = 0.693443 (* 1 = 0.693443 loss)
I0701 13:31:01.097806  2788 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0701 13:31:14.060014  2788 solver.cpp:236] Iteration 2950, loss = 0.69321
I0701 13:31:14.060065  2788 solver.cpp:252]     Train net output #0: loss = 0.691254 (* 1 = 0.691254 loss)
I0701 13:31:14.060078  2788 sgd_solver.cpp:106] Iteration 2950, lr = 0.01
I0701 13:31:26.946277  2788 solver.cpp:236] Iteration 2960, loss = 0.693091
I0701 13:31:26.946504  2788 solver.cpp:252]     Train net output #0: loss = 0.690734 (* 1 = 0.690734 loss)
I0701 13:31:26.946538  2788 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0701 13:31:38.112154  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 13:31:39.275954  2788 solver.cpp:236] Iteration 2970, loss = 0.693384
I0701 13:31:39.276015  2788 solver.cpp:252]     Train net output #0: loss = 0.695693 (* 1 = 0.695693 loss)
I0701 13:31:39.276031  2788 sgd_solver.cpp:106] Iteration 2970, lr = 0.01
I0701 13:31:52.245079  2788 solver.cpp:236] Iteration 2980, loss = 0.693397
I0701 13:31:52.245133  2788 solver.cpp:252]     Train net output #0: loss = 0.693112 (* 1 = 0.693112 loss)
I0701 13:31:52.245148  2788 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0701 13:32:05.540982  2788 solver.cpp:236] Iteration 2990, loss = 0.693382
I0701 13:32:05.541144  2788 solver.cpp:252]     Train net output #0: loss = 0.69318 (* 1 = 0.69318 loss)
I0701 13:32:05.541165  2788 sgd_solver.cpp:106] Iteration 2990, lr = 0.01
I0701 13:32:16.534973  2788 solver.cpp:340] Iteration 3000, Testing net (#0)
I0701 13:32:42.728417  2788 solver.cpp:408]     Test net output #0: accuracy = 0.499375
I0701 13:32:42.728574  2788 solver.cpp:408]     Test net output #1: loss = 0.693152 (* 1 = 0.693152 loss)
I0701 13:32:42.961176  2788 solver.cpp:236] Iteration 3000, loss = 0.693479
I0701 13:32:42.961223  2788 solver.cpp:252]     Train net output #0: loss = 0.693027 (* 1 = 0.693027 loss)
I0701 13:32:42.961238  2788 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0701 13:32:53.650014  2788 solver.cpp:236] Iteration 3010, loss = 0.693565
I0701 13:32:53.650073  2788 solver.cpp:252]     Train net output #0: loss = 0.692761 (* 1 = 0.692761 loss)
I0701 13:32:53.650089  2788 sgd_solver.cpp:106] Iteration 3010, lr = 0.01
I0701 13:33:06.294400  2788 solver.cpp:236] Iteration 3020, loss = 0.693241
I0701 13:33:06.294459  2788 solver.cpp:252]     Train net output #0: loss = 0.69457 (* 1 = 0.69457 loss)
I0701 13:33:06.294474  2788 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0701 13:33:19.785135  2788 solver.cpp:236] Iteration 3030, loss = 0.693292
I0701 13:33:19.785351  2788 solver.cpp:252]     Train net output #0: loss = 0.693273 (* 1 = 0.693273 loss)
I0701 13:33:19.785372  2788 sgd_solver.cpp:106] Iteration 3030, lr = 0.01
I0701 13:33:32.304659  2788 solver.cpp:236] Iteration 3040, loss = 0.693295
I0701 13:33:32.304705  2788 solver.cpp:252]     Train net output #0: loss = 0.693708 (* 1 = 0.693708 loss)
I0701 13:33:32.304719  2788 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0701 13:33:45.464777  2788 solver.cpp:236] Iteration 3050, loss = 0.693309
I0701 13:33:45.464839  2788 solver.cpp:252]     Train net output #0: loss = 0.693051 (* 1 = 0.693051 loss)
I0701 13:33:45.464854  2788 sgd_solver.cpp:106] Iteration 3050, lr = 0.01
I0701 13:33:58.264855  2788 solver.cpp:236] Iteration 3060, loss = 0.693286
I0701 13:33:58.264987  2788 solver.cpp:252]     Train net output #0: loss = 0.692791 (* 1 = 0.692791 loss)
I0701 13:33:58.265003  2788 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0701 13:34:11.092102  2788 solver.cpp:236] Iteration 3070, loss = 0.693238
I0701 13:34:11.092154  2788 solver.cpp:252]     Train net output #0: loss = 0.692304 (* 1 = 0.692304 loss)
I0701 13:34:11.092167  2788 sgd_solver.cpp:106] Iteration 3070, lr = 0.01
I0701 13:34:24.393733  2788 solver.cpp:236] Iteration 3080, loss = 0.693273
I0701 13:34:24.393782  2788 solver.cpp:252]     Train net output #0: loss = 0.693095 (* 1 = 0.693095 loss)
I0701 13:34:24.393795  2788 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0701 13:34:36.903146  2788 solver.cpp:236] Iteration 3090, loss = 0.693272
I0701 13:34:36.903319  2788 solver.cpp:252]     Train net output #0: loss = 0.69296 (* 1 = 0.69296 loss)
I0701 13:34:36.903348  2788 sgd_solver.cpp:106] Iteration 3090, lr = 0.01
I0701 13:34:50.187518  2788 solver.cpp:236] Iteration 3100, loss = 0.69325
I0701 13:34:50.187569  2788 solver.cpp:252]     Train net output #0: loss = 0.693663 (* 1 = 0.693663 loss)
I0701 13:34:50.187583  2788 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0701 13:35:02.685322  2788 solver.cpp:236] Iteration 3110, loss = 0.693364
I0701 13:35:02.685364  2788 solver.cpp:252]     Train net output #0: loss = 0.696612 (* 1 = 0.696612 loss)
I0701 13:35:02.685376  2788 sgd_solver.cpp:106] Iteration 3110, lr = 0.01
I0701 13:35:15.820911  2788 solver.cpp:236] Iteration 3120, loss = 0.693399
I0701 13:35:15.821038  2788 solver.cpp:252]     Train net output #0: loss = 0.692967 (* 1 = 0.692967 loss)
I0701 13:35:15.821068  2788 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0701 13:35:28.950886  2788 solver.cpp:236] Iteration 3130, loss = 0.693249
I0701 13:35:28.950969  2788 solver.cpp:252]     Train net output #0: loss = 0.691825 (* 1 = 0.691825 loss)
I0701 13:35:28.950997  2788 sgd_solver.cpp:106] Iteration 3130, lr = 0.01
I0701 13:35:41.679771  2788 solver.cpp:236] Iteration 3140, loss = 0.693237
I0701 13:35:41.679822  2788 solver.cpp:252]     Train net output #0: loss = 0.691736 (* 1 = 0.691736 loss)
I0701 13:35:41.679836  2788 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0701 13:35:55.041220  2788 solver.cpp:236] Iteration 3150, loss = 0.693379
I0701 13:35:55.041347  2788 solver.cpp:252]     Train net output #0: loss = 0.693257 (* 1 = 0.693257 loss)
I0701 13:35:55.041363  2788 sgd_solver.cpp:106] Iteration 3150, lr = 0.01
I0701 13:36:07.664276  2788 solver.cpp:236] Iteration 3160, loss = 0.69332
I0701 13:36:07.664329  2788 solver.cpp:252]     Train net output #0: loss = 0.693028 (* 1 = 0.693028 loss)
I0701 13:36:07.664342  2788 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0701 13:36:20.664144  2788 solver.cpp:236] Iteration 3170, loss = 0.693372
I0701 13:36:20.664193  2788 solver.cpp:252]     Train net output #0: loss = 0.693314 (* 1 = 0.693314 loss)
I0701 13:36:20.664206  2788 sgd_solver.cpp:106] Iteration 3170, lr = 0.01
I0701 13:36:33.787081  2788 solver.cpp:236] Iteration 3180, loss = 0.693405
I0701 13:36:33.787207  2788 solver.cpp:252]     Train net output #0: loss = 0.691727 (* 1 = 0.691727 loss)
I0701 13:36:33.787236  2788 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0701 13:36:47.222219  2788 solver.cpp:236] Iteration 3190, loss = 0.693337
I0701 13:36:47.222280  2788 solver.cpp:252]     Train net output #0: loss = 0.693432 (* 1 = 0.693432 loss)
I0701 13:36:47.222295  2788 sgd_solver.cpp:106] Iteration 3190, lr = 0.01
I0701 13:37:00.097880  2788 solver.cpp:236] Iteration 3200, loss = 0.69343
I0701 13:37:00.097980  2788 solver.cpp:252]     Train net output #0: loss = 0.691774 (* 1 = 0.691774 loss)
I0701 13:37:00.097997  2788 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0701 13:37:12.914945  2788 solver.cpp:236] Iteration 3210, loss = 0.693381
I0701 13:37:12.915077  2788 solver.cpp:252]     Train net output #0: loss = 0.693924 (* 1 = 0.693924 loss)
I0701 13:37:12.915103  2788 sgd_solver.cpp:106] Iteration 3210, lr = 0.01
I0701 13:37:26.019331  2788 solver.cpp:236] Iteration 3220, loss = 0.693104
I0701 13:37:26.019376  2788 solver.cpp:252]     Train net output #0: loss = 0.699094 (* 1 = 0.699094 loss)
I0701 13:37:26.019389  2788 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0701 13:37:39.233819  2788 solver.cpp:236] Iteration 3230, loss = 0.69354
I0701 13:37:39.233872  2788 solver.cpp:252]     Train net output #0: loss = 0.701382 (* 1 = 0.701382 loss)
I0701 13:37:39.233886  2788 sgd_solver.cpp:106] Iteration 3230, lr = 0.01
I0701 13:37:51.781347  2788 solver.cpp:236] Iteration 3240, loss = 0.693898
I0701 13:37:51.781474  2788 solver.cpp:252]     Train net output #0: loss = 0.693196 (* 1 = 0.693196 loss)
I0701 13:37:51.781502  2788 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0701 13:38:03.124959  2788 solver.cpp:340] Iteration 3250, Testing net (#0)
I0701 13:38:29.608841  2788 solver.cpp:408]     Test net output #0: accuracy = 0.499063
I0701 13:38:29.609009  2788 solver.cpp:408]     Test net output #1: loss = 0.693418 (* 1 = 0.693418 loss)
I0701 13:38:29.845161  2788 solver.cpp:236] Iteration 3250, loss = 0.693674
I0701 13:38:29.845211  2788 solver.cpp:252]     Train net output #0: loss = 0.693711 (* 1 = 0.693711 loss)
I0701 13:38:29.845227  2788 sgd_solver.cpp:106] Iteration 3250, lr = 0.01
I0701 13:38:40.480651  2788 solver.cpp:236] Iteration 3260, loss = 0.693539
I0701 13:38:40.480707  2788 solver.cpp:252]     Train net output #0: loss = 0.690283 (* 1 = 0.690283 loss)
I0701 13:38:40.480721  2788 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0701 13:38:53.205296  2788 solver.cpp:236] Iteration 3270, loss = 0.693582
I0701 13:38:53.205360  2788 solver.cpp:252]     Train net output #0: loss = 0.689352 (* 1 = 0.689352 loss)
I0701 13:38:53.205375  2788 sgd_solver.cpp:106] Iteration 3270, lr = 0.01
I0701 13:39:06.283177  2788 solver.cpp:236] Iteration 3280, loss = 0.693301
I0701 13:39:06.283298  2788 solver.cpp:252]     Train net output #0: loss = 0.692078 (* 1 = 0.692078 loss)
I0701 13:39:06.283325  2788 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0701 13:39:18.957289  2788 solver.cpp:236] Iteration 3290, loss = 0.693139
I0701 13:39:18.957343  2788 solver.cpp:252]     Train net output #0: loss = 0.693591 (* 1 = 0.693591 loss)
I0701 13:39:18.957357  2788 sgd_solver.cpp:106] Iteration 3290, lr = 0.01
I0701 13:39:31.315982  2788 solver.cpp:236] Iteration 3300, loss = 0.693085
I0701 13:39:31.316035  2788 solver.cpp:252]     Train net output #0: loss = 0.692733 (* 1 = 0.692733 loss)
I0701 13:39:31.316048  2788 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0701 13:39:41.958154  2788 solver.cpp:236] Iteration 3310, loss = 0.693382
I0701 13:39:41.958472  2788 solver.cpp:252]     Train net output #0: loss = 0.693506 (* 1 = 0.693506 loss)
I0701 13:39:41.958495  2788 sgd_solver.cpp:106] Iteration 3310, lr = 0.01
I0701 13:39:48.720779  2788 solver.cpp:236] Iteration 3320, loss = 0.69362
I0701 13:39:48.720824  2788 solver.cpp:252]     Train net output #0: loss = 0.693834 (* 1 = 0.693834 loss)
I0701 13:39:48.720837  2788 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0701 13:39:55.518342  2788 solver.cpp:236] Iteration 3330, loss = 0.693504
I0701 13:39:55.518390  2788 solver.cpp:252]     Train net output #0: loss = 0.693155 (* 1 = 0.693155 loss)
I0701 13:39:55.518404  2788 sgd_solver.cpp:106] Iteration 3330, lr = 0.01
I0701 13:40:02.305459  2788 solver.cpp:236] Iteration 3340, loss = 0.693338
I0701 13:40:02.305510  2788 solver.cpp:252]     Train net output #0: loss = 0.691725 (* 1 = 0.691725 loss)
I0701 13:40:02.305524  2788 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0701 13:40:09.113641  2788 solver.cpp:236] Iteration 3350, loss = 0.693469
I0701 13:40:09.113679  2788 solver.cpp:252]     Train net output #0: loss = 0.702728 (* 1 = 0.702728 loss)
I0701 13:40:09.113689  2788 sgd_solver.cpp:106] Iteration 3350, lr = 0.01
I0701 13:40:15.932267  2788 solver.cpp:236] Iteration 3360, loss = 0.693492
I0701 13:40:15.932389  2788 solver.cpp:252]     Train net output #0: loss = 0.693046 (* 1 = 0.693046 loss)
I0701 13:40:15.932404  2788 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0701 13:40:22.735712  2788 solver.cpp:236] Iteration 3370, loss = 0.693522
I0701 13:40:22.735759  2788 solver.cpp:252]     Train net output #0: loss = 0.695703 (* 1 = 0.695703 loss)
I0701 13:40:22.735774  2788 sgd_solver.cpp:106] Iteration 3370, lr = 0.01
I0701 13:40:29.565191  2788 solver.cpp:236] Iteration 3380, loss = 0.693479
I0701 13:40:29.565249  2788 solver.cpp:252]     Train net output #0: loss = 0.694058 (* 1 = 0.694058 loss)
I0701 13:40:29.565264  2788 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0701 13:40:36.371250  2788 solver.cpp:236] Iteration 3390, loss = 0.693551
I0701 13:40:36.371296  2788 solver.cpp:252]     Train net output #0: loss = 0.693149 (* 1 = 0.693149 loss)
I0701 13:40:36.371311  2788 sgd_solver.cpp:106] Iteration 3390, lr = 0.01
I0701 13:40:43.188323  2788 solver.cpp:236] Iteration 3400, loss = 0.693468
I0701 13:40:43.188364  2788 solver.cpp:252]     Train net output #0: loss = 0.693392 (* 1 = 0.693392 loss)
I0701 13:40:43.188376  2788 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0701 13:40:50.019743  2788 solver.cpp:236] Iteration 3410, loss = 0.693239
I0701 13:40:50.019923  2788 solver.cpp:252]     Train net output #0: loss = 0.692472 (* 1 = 0.692472 loss)
I0701 13:40:50.019940  2788 sgd_solver.cpp:106] Iteration 3410, lr = 0.01
I0701 13:40:56.838992  2788 solver.cpp:236] Iteration 3420, loss = 0.69316
I0701 13:40:56.839038  2788 solver.cpp:252]     Train net output #0: loss = 0.690875 (* 1 = 0.690875 loss)
I0701 13:40:56.839051  2788 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0701 13:41:03.660784  2788 solver.cpp:236] Iteration 3430, loss = 0.693094
I0701 13:41:03.660836  2788 solver.cpp:252]     Train net output #0: loss = 0.693676 (* 1 = 0.693676 loss)
I0701 13:41:03.660851  2788 sgd_solver.cpp:106] Iteration 3430, lr = 0.01
I0701 13:41:10.485983  2788 solver.cpp:236] Iteration 3440, loss = 0.693004
I0701 13:41:10.486038  2788 solver.cpp:252]     Train net output #0: loss = 0.694417 (* 1 = 0.694417 loss)
I0701 13:41:10.486052  2788 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0701 13:41:17.313241  2788 solver.cpp:236] Iteration 3450, loss = 0.692856
I0701 13:41:17.313285  2788 solver.cpp:252]     Train net output #0: loss = 0.692112 (* 1 = 0.692112 loss)
I0701 13:41:17.313297  2788 sgd_solver.cpp:106] Iteration 3450, lr = 0.01
I0701 13:41:24.131078  2788 solver.cpp:236] Iteration 3460, loss = 0.692891
I0701 13:41:24.136508  2788 solver.cpp:252]     Train net output #0: loss = 0.690191 (* 1 = 0.690191 loss)
I0701 13:41:24.136530  2788 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0701 13:41:30.944015  2788 solver.cpp:236] Iteration 3470, loss = 0.693011
I0701 13:41:30.944061  2788 solver.cpp:252]     Train net output #0: loss = 0.694622 (* 1 = 0.694622 loss)
I0701 13:41:30.944075  2788 sgd_solver.cpp:106] Iteration 3470, lr = 0.01
I0701 13:41:37.769314  2788 solver.cpp:236] Iteration 3480, loss = 0.69324
I0701 13:41:37.769361  2788 solver.cpp:252]     Train net output #0: loss = 0.693063 (* 1 = 0.693063 loss)
I0701 13:41:37.769374  2788 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0701 13:41:44.583904  2788 solver.cpp:236] Iteration 3490, loss = 0.693425
I0701 13:41:44.583956  2788 solver.cpp:252]     Train net output #0: loss = 0.691016 (* 1 = 0.691016 loss)
I0701 13:41:44.583969  2788 sgd_solver.cpp:106] Iteration 3490, lr = 0.01
I0701 13:41:50.727937  2788 solver.cpp:340] Iteration 3500, Testing net (#0)
I0701 13:42:16.507570  2788 solver.cpp:408]     Test net output #0: accuracy = 0.491875
I0701 13:42:16.507760  2788 solver.cpp:408]     Test net output #1: loss = 0.693314 (* 1 = 0.693314 loss)
I0701 13:42:16.746484  2788 solver.cpp:236] Iteration 3500, loss = 0.693689
I0701 13:42:16.746531  2788 solver.cpp:252]     Train net output #0: loss = 0.694333 (* 1 = 0.694333 loss)
I0701 13:42:16.746547  2788 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0701 13:42:23.547160  2788 solver.cpp:236] Iteration 3510, loss = 0.693714
I0701 13:42:23.547206  2788 solver.cpp:252]     Train net output #0: loss = 0.691962 (* 1 = 0.691962 loss)
I0701 13:42:23.547219  2788 sgd_solver.cpp:106] Iteration 3510, lr = 0.01
I0701 13:42:30.342730  2788 solver.cpp:236] Iteration 3520, loss = 0.693696
I0701 13:42:30.342782  2788 solver.cpp:252]     Train net output #0: loss = 0.69383 (* 1 = 0.69383 loss)
I0701 13:42:30.342797  2788 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0701 13:42:37.138702  2788 solver.cpp:236] Iteration 3530, loss = 0.693603
I0701 13:42:37.138746  2788 solver.cpp:252]     Train net output #0: loss = 0.694086 (* 1 = 0.694086 loss)
I0701 13:42:37.138759  2788 sgd_solver.cpp:106] Iteration 3530, lr = 0.01
I0701 13:42:43.940325  2788 solver.cpp:236] Iteration 3540, loss = 0.693501
I0701 13:42:43.940371  2788 solver.cpp:252]     Train net output #0: loss = 0.693604 (* 1 = 0.693604 loss)
I0701 13:42:43.940384  2788 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0701 13:42:50.720731  2788 solver.cpp:236] Iteration 3550, loss = 0.693394
I0701 13:42:50.720922  2788 solver.cpp:252]     Train net output #0: loss = 0.694348 (* 1 = 0.694348 loss)
I0701 13:42:50.720947  2788 sgd_solver.cpp:106] Iteration 3550, lr = 0.01
I0701 13:42:57.522032  2788 solver.cpp:236] Iteration 3560, loss = 0.693317
I0701 13:42:57.522075  2788 solver.cpp:252]     Train net output #0: loss = 0.692874 (* 1 = 0.692874 loss)
I0701 13:42:57.522088  2788 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0701 13:43:04.340160  2788 solver.cpp:236] Iteration 3570, loss = 0.693262
I0701 13:43:04.340214  2788 solver.cpp:252]     Train net output #0: loss = 0.693503 (* 1 = 0.693503 loss)
I0701 13:43:04.340229  2788 sgd_solver.cpp:106] Iteration 3570, lr = 0.01
I0701 13:43:11.161272  2788 solver.cpp:236] Iteration 3580, loss = 0.69322
I0701 13:43:11.161319  2788 solver.cpp:252]     Train net output #0: loss = 0.693443 (* 1 = 0.693443 loss)
I0701 13:43:11.161332  2788 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0701 13:43:17.971949  2788 solver.cpp:236] Iteration 3590, loss = 0.693237
I0701 13:43:17.972007  2788 solver.cpp:252]     Train net output #0: loss = 0.693417 (* 1 = 0.693417 loss)
I0701 13:43:17.972025  2788 sgd_solver.cpp:106] Iteration 3590, lr = 0.01
I0701 13:43:24.783996  2788 solver.cpp:236] Iteration 3600, loss = 0.693226
I0701 13:43:24.784152  2788 solver.cpp:252]     Train net output #0: loss = 0.692981 (* 1 = 0.692981 loss)
I0701 13:43:24.784198  2788 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0701 13:43:31.603121  2788 solver.cpp:236] Iteration 3610, loss = 0.693353
I0701 13:43:31.603173  2788 solver.cpp:252]     Train net output #0: loss = 0.694041 (* 1 = 0.694041 loss)
I0701 13:43:31.603193  2788 sgd_solver.cpp:106] Iteration 3610, lr = 0.01
I0701 13:43:38.436512  2788 solver.cpp:236] Iteration 3620, loss = 0.693342
I0701 13:43:38.436558  2788 solver.cpp:252]     Train net output #0: loss = 0.692661 (* 1 = 0.692661 loss)
I0701 13:43:38.436570  2788 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0701 13:43:45.263953  2788 solver.cpp:236] Iteration 3630, loss = 0.693635
I0701 13:43:45.263998  2788 solver.cpp:252]     Train net output #0: loss = 0.693885 (* 1 = 0.693885 loss)
I0701 13:43:45.264011  2788 sgd_solver.cpp:106] Iteration 3630, lr = 0.01
I0701 13:43:52.090929  2788 solver.cpp:236] Iteration 3640, loss = 0.693637
I0701 13:43:52.090972  2788 solver.cpp:252]     Train net output #0: loss = 0.694176 (* 1 = 0.694176 loss)
I0701 13:43:52.090984  2788 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0701 13:43:58.907917  2788 solver.cpp:236] Iteration 3650, loss = 0.693658
I0701 13:43:58.908017  2788 solver.cpp:252]     Train net output #0: loss = 0.696021 (* 1 = 0.696021 loss)
I0701 13:43:58.908032  2788 sgd_solver.cpp:106] Iteration 3650, lr = 0.01
I0701 13:44:05.744222  2788 solver.cpp:236] Iteration 3660, loss = 0.693701
I0701 13:44:05.744280  2788 solver.cpp:252]     Train net output #0: loss = 0.694327 (* 1 = 0.694327 loss)
I0701 13:44:05.744295  2788 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0701 13:44:12.579656  2788 solver.cpp:236] Iteration 3670, loss = 0.69365
I0701 13:44:12.579704  2788 solver.cpp:252]     Train net output #0: loss = 0.69265 (* 1 = 0.69265 loss)
I0701 13:44:12.579717  2788 sgd_solver.cpp:106] Iteration 3670, lr = 0.01
I0701 13:44:19.391187  2788 solver.cpp:236] Iteration 3680, loss = 0.693567
I0701 13:44:19.391228  2788 solver.cpp:252]     Train net output #0: loss = 0.693507 (* 1 = 0.693507 loss)
I0701 13:44:19.391242  2788 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0701 13:44:26.221084  2788 solver.cpp:236] Iteration 3690, loss = 0.693598
I0701 13:44:26.221127  2788 solver.cpp:252]     Train net output #0: loss = 0.694199 (* 1 = 0.694199 loss)
I0701 13:44:26.221139  2788 sgd_solver.cpp:106] Iteration 3690, lr = 0.01
I0701 13:44:33.038025  2788 solver.cpp:236] Iteration 3700, loss = 0.69344
I0701 13:44:33.038223  2788 solver.cpp:252]     Train net output #0: loss = 0.692301 (* 1 = 0.692301 loss)
I0701 13:44:33.038239  2788 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0701 13:44:39.873467  2788 solver.cpp:236] Iteration 3710, loss = 0.6935
I0701 13:44:39.873514  2788 solver.cpp:252]     Train net output #0: loss = 0.69246 (* 1 = 0.69246 loss)
I0701 13:44:39.873528  2788 sgd_solver.cpp:106] Iteration 3710, lr = 0.01
I0701 13:44:46.701210  2788 solver.cpp:236] Iteration 3720, loss = 0.693603
I0701 13:44:46.701251  2788 solver.cpp:252]     Train net output #0: loss = 0.689066 (* 1 = 0.689066 loss)
I0701 13:44:46.701263  2788 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0701 13:44:53.519773  2788 solver.cpp:236] Iteration 3730, loss = 0.693336
I0701 13:44:53.519814  2788 solver.cpp:252]     Train net output #0: loss = 0.696842 (* 1 = 0.696842 loss)
I0701 13:44:53.519829  2788 sgd_solver.cpp:106] Iteration 3730, lr = 0.01
I0701 13:45:00.354928  2788 solver.cpp:236] Iteration 3740, loss = 0.693377
I0701 13:45:00.354970  2788 solver.cpp:252]     Train net output #0: loss = 0.695063 (* 1 = 0.695063 loss)
I0701 13:45:00.354982  2788 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0701 13:45:06.487902  2788 solver.cpp:340] Iteration 3750, Testing net (#0)
I0701 13:45:28.056471  2788 solver.cpp:408]     Test net output #0: accuracy = 0.502187
I0701 13:45:28.056524  2788 solver.cpp:408]     Test net output #1: loss = 0.693172 (* 1 = 0.693172 loss)
I0701 13:45:28.234781  2788 solver.cpp:236] Iteration 3750, loss = 0.693797
I0701 13:45:28.234828  2788 solver.cpp:252]     Train net output #0: loss = 0.692632 (* 1 = 0.692632 loss)
I0701 13:45:28.234841  2788 sgd_solver.cpp:106] Iteration 3750, lr = 0.01
I0701 13:45:35.015063  2788 solver.cpp:236] Iteration 3760, loss = 0.693911
I0701 13:45:35.015110  2788 solver.cpp:252]     Train net output #0: loss = 0.695606 (* 1 = 0.695606 loss)
I0701 13:45:35.015130  2788 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0701 13:45:41.779786  2788 solver.cpp:236] Iteration 3770, loss = 0.693923
I0701 13:45:41.784497  2788 solver.cpp:252]     Train net output #0: loss = 0.693123 (* 1 = 0.693123 loss)
I0701 13:45:41.784512  2788 sgd_solver.cpp:106] Iteration 3770, lr = 0.01
I0701 13:45:48.560170  2788 solver.cpp:236] Iteration 3780, loss = 0.693931
I0701 13:45:48.560214  2788 solver.cpp:252]     Train net output #0: loss = 0.692664 (* 1 = 0.692664 loss)
I0701 13:45:48.560226  2788 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0701 13:45:55.358798  2788 solver.cpp:236] Iteration 3790, loss = 0.69377
I0701 13:45:55.358839  2788 solver.cpp:252]     Train net output #0: loss = 0.692674 (* 1 = 0.692674 loss)
I0701 13:45:55.358851  2788 sgd_solver.cpp:106] Iteration 3790, lr = 0.01
I0701 13:46:02.145126  2788 solver.cpp:236] Iteration 3800, loss = 0.6936
I0701 13:46:02.145170  2788 solver.cpp:252]     Train net output #0: loss = 0.690134 (* 1 = 0.690134 loss)
I0701 13:46:02.145184  2788 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0701 13:46:08.960263  2788 solver.cpp:236] Iteration 3810, loss = 0.693458
I0701 13:46:08.960309  2788 solver.cpp:252]     Train net output #0: loss = 0.694571 (* 1 = 0.694571 loss)
I0701 13:46:08.960322  2788 sgd_solver.cpp:106] Iteration 3810, lr = 0.01
I0701 13:46:15.746064  2788 solver.cpp:236] Iteration 3820, loss = 0.693417
I0701 13:46:15.746170  2788 solver.cpp:252]     Train net output #0: loss = 0.696814 (* 1 = 0.696814 loss)
I0701 13:46:15.746183  2788 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0701 13:46:22.549487  2788 solver.cpp:236] Iteration 3830, loss = 0.693726
I0701 13:46:22.549535  2788 solver.cpp:252]     Train net output #0: loss = 0.692582 (* 1 = 0.692582 loss)
I0701 13:46:22.549548  2788 sgd_solver.cpp:106] Iteration 3830, lr = 0.01
I0701 13:46:29.359617  2788 solver.cpp:236] Iteration 3840, loss = 0.693749
I0701 13:46:29.359669  2788 solver.cpp:252]     Train net output #0: loss = 0.693558 (* 1 = 0.693558 loss)
I0701 13:46:29.359683  2788 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0701 13:46:36.133960  2788 solver.cpp:236] Iteration 3850, loss = 0.693665
I0701 13:46:36.134004  2788 solver.cpp:252]     Train net output #0: loss = 0.693071 (* 1 = 0.693071 loss)
I0701 13:46:36.134018  2788 sgd_solver.cpp:106] Iteration 3850, lr = 0.01
I0701 13:46:42.948884  2788 solver.cpp:236] Iteration 3860, loss = 0.693559
I0701 13:46:42.948930  2788 solver.cpp:252]     Train net output #0: loss = 0.694737 (* 1 = 0.694737 loss)
I0701 13:46:42.948942  2788 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0701 13:46:49.761061  2788 solver.cpp:236] Iteration 3870, loss = 0.693498
I0701 13:46:49.761211  2788 solver.cpp:252]     Train net output #0: loss = 0.693757 (* 1 = 0.693757 loss)
I0701 13:46:49.761240  2788 sgd_solver.cpp:106] Iteration 3870, lr = 0.01
I0701 13:46:56.554615  2788 solver.cpp:236] Iteration 3880, loss = 0.693211
I0701 13:46:56.554661  2788 solver.cpp:252]     Train net output #0: loss = 0.692498 (* 1 = 0.692498 loss)
I0701 13:46:56.554675  2788 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0701 13:47:03.364738  2788 solver.cpp:236] Iteration 3890, loss = 0.693344
I0701 13:47:03.364783  2788 solver.cpp:252]     Train net output #0: loss = 0.692234 (* 1 = 0.692234 loss)
I0701 13:47:03.364794  2788 sgd_solver.cpp:106] Iteration 3890, lr = 0.01
I0701 13:47:10.167016  2788 solver.cpp:236] Iteration 3900, loss = 0.693305
I0701 13:47:10.167063  2788 solver.cpp:252]     Train net output #0: loss = 0.69289 (* 1 = 0.69289 loss)
I0701 13:47:10.167078  2788 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0701 13:47:16.994982  2788 solver.cpp:236] Iteration 3910, loss = 0.693294
I0701 13:47:16.995028  2788 solver.cpp:252]     Train net output #0: loss = 0.69606 (* 1 = 0.69606 loss)
I0701 13:47:16.995041  2788 sgd_solver.cpp:106] Iteration 3910, lr = 0.01
I0701 13:47:23.790904  2788 solver.cpp:236] Iteration 3920, loss = 0.693242
I0701 13:47:23.791002  2788 solver.cpp:252]     Train net output #0: loss = 0.693689 (* 1 = 0.693689 loss)
I0701 13:47:23.791015  2788 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0701 13:47:30.603915  2788 solver.cpp:236] Iteration 3930, loss = 0.693432
I0701 13:47:30.603958  2788 solver.cpp:252]     Train net output #0: loss = 0.693173 (* 1 = 0.693173 loss)
I0701 13:47:30.603971  2788 sgd_solver.cpp:106] Iteration 3930, lr = 0.01
I0701 13:47:37.426612  2788 solver.cpp:236] Iteration 3940, loss = 0.693261
I0701 13:47:37.426662  2788 solver.cpp:252]     Train net output #0: loss = 0.691152 (* 1 = 0.691152 loss)
I0701 13:47:37.426676  2788 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0701 13:47:44.222697  2788 solver.cpp:236] Iteration 3950, loss = 0.693422
I0701 13:47:44.222741  2788 solver.cpp:252]     Train net output #0: loss = 0.700131 (* 1 = 0.700131 loss)
I0701 13:47:44.222754  2788 sgd_solver.cpp:106] Iteration 3950, lr = 0.01
I0701 13:47:51.015357  2788 solver.cpp:236] Iteration 3960, loss = 0.693466
I0701 13:47:51.015395  2788 solver.cpp:252]     Train net output #0: loss = 0.692141 (* 1 = 0.692141 loss)
I0701 13:47:51.015409  2788 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0701 13:47:57.851369  2788 solver.cpp:236] Iteration 3970, loss = 0.69353
I0701 13:47:57.851562  2788 solver.cpp:252]     Train net output #0: loss = 0.693096 (* 1 = 0.693096 loss)
I0701 13:47:57.851575  2788 sgd_solver.cpp:106] Iteration 3970, lr = 0.01
I0701 13:48:04.654196  2788 solver.cpp:236] Iteration 3980, loss = 0.693353
I0701 13:48:04.654233  2788 solver.cpp:252]     Train net output #0: loss = 0.693488 (* 1 = 0.693488 loss)
I0701 13:48:04.654247  2788 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0701 13:48:11.455317  2788 solver.cpp:236] Iteration 3990, loss = 0.693404
I0701 13:48:11.455363  2788 solver.cpp:252]     Train net output #0: loss = 0.69807 (* 1 = 0.69807 loss)
I0701 13:48:11.455377  2788 sgd_solver.cpp:106] Iteration 3990, lr = 0.01
I0701 13:48:17.571388  2788 solver.cpp:340] Iteration 4000, Testing net (#0)
I0701 13:48:28.742372  2788 solver.cpp:408]     Test net output #0: accuracy = 0.5025
I0701 13:48:28.742486  2788 solver.cpp:408]     Test net output #1: loss = 0.693353 (* 1 = 0.693353 loss)
I0701 13:48:28.923682  2788 solver.cpp:236] Iteration 4000, loss = 0.693173
I0701 13:48:28.923720  2788 solver.cpp:252]     Train net output #0: loss = 0.691459 (* 1 = 0.691459 loss)
I0701 13:48:28.923734  2788 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0701 13:48:35.731799  2788 solver.cpp:236] Iteration 4010, loss = 0.693255
I0701 13:48:35.731844  2788 solver.cpp:252]     Train net output #0: loss = 0.693395 (* 1 = 0.693395 loss)
I0701 13:48:35.731858  2788 sgd_solver.cpp:106] Iteration 4010, lr = 0.01
I0701 13:48:42.528879  2788 solver.cpp:236] Iteration 4020, loss = 0.693245
I0701 13:48:42.528928  2788 solver.cpp:252]     Train net output #0: loss = 0.694462 (* 1 = 0.694462 loss)
I0701 13:48:42.528941  2788 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0701 13:48:49.330430  2788 solver.cpp:236] Iteration 4030, loss = 0.693247
I0701 13:48:49.330474  2788 solver.cpp:252]     Train net output #0: loss = 0.693352 (* 1 = 0.693352 loss)
I0701 13:48:49.330487  2788 sgd_solver.cpp:106] Iteration 4030, lr = 0.01
I0701 13:48:56.128310  2788 solver.cpp:236] Iteration 4040, loss = 0.693365
I0701 13:48:56.128353  2788 solver.cpp:252]     Train net output #0: loss = 0.692768 (* 1 = 0.692768 loss)
I0701 13:48:56.128366  2788 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0701 13:49:02.941959  2788 solver.cpp:236] Iteration 4050, loss = 0.693399
I0701 13:49:02.942101  2788 solver.cpp:252]     Train net output #0: loss = 0.69185 (* 1 = 0.69185 loss)
I0701 13:49:02.942144  2788 sgd_solver.cpp:106] Iteration 4050, lr = 0.01
I0701 13:49:09.740696  2788 solver.cpp:236] Iteration 4060, loss = 0.693065
I0701 13:49:09.740746  2788 solver.cpp:252]     Train net output #0: loss = 0.690135 (* 1 = 0.690135 loss)
I0701 13:49:09.740761  2788 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0701 13:49:16.549599  2788 solver.cpp:236] Iteration 4070, loss = 0.69331
I0701 13:49:16.549641  2788 solver.cpp:252]     Train net output #0: loss = 0.695747 (* 1 = 0.695747 loss)
I0701 13:49:16.549655  2788 sgd_solver.cpp:106] Iteration 4070, lr = 0.01
I0701 13:49:23.327419  2788 solver.cpp:236] Iteration 4080, loss = 0.693367
I0701 13:49:23.327461  2788 solver.cpp:252]     Train net output #0: loss = 0.692942 (* 1 = 0.692942 loss)
I0701 13:49:23.327474  2788 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0701 13:49:30.136013  2788 solver.cpp:236] Iteration 4090, loss = 0.693144
I0701 13:49:30.136051  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 13:49:30.136068  2788 sgd_solver.cpp:106] Iteration 4090, lr = 0.01
I0701 13:49:36.956007  2788 solver.cpp:236] Iteration 4100, loss = 0.692942
I0701 13:49:36.956118  2788 solver.cpp:252]     Train net output #0: loss = 0.693202 (* 1 = 0.693202 loss)
I0701 13:49:36.956135  2788 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0701 13:49:43.743541  2788 solver.cpp:236] Iteration 4110, loss = 0.693727
I0701 13:49:43.743590  2788 solver.cpp:252]     Train net output #0: loss = 0.698805 (* 1 = 0.698805 loss)
I0701 13:49:43.743604  2788 sgd_solver.cpp:106] Iteration 4110, lr = 0.01
I0701 13:49:50.544489  2788 solver.cpp:236] Iteration 4120, loss = 0.693565
I0701 13:49:50.544531  2788 solver.cpp:252]     Train net output #0: loss = 0.692949 (* 1 = 0.692949 loss)
I0701 13:49:50.544548  2788 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0701 13:49:57.346743  2788 solver.cpp:236] Iteration 4130, loss = 0.693735
I0701 13:49:57.346786  2788 solver.cpp:252]     Train net output #0: loss = 0.691536 (* 1 = 0.691536 loss)
I0701 13:49:57.346801  2788 sgd_solver.cpp:106] Iteration 4130, lr = 0.01
I0701 13:50:04.147313  2788 solver.cpp:236] Iteration 4140, loss = 0.693743
I0701 13:50:04.147363  2788 solver.cpp:252]     Train net output #0: loss = 0.691813 (* 1 = 0.691813 loss)
I0701 13:50:04.147377  2788 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0701 13:50:10.943639  2788 solver.cpp:236] Iteration 4150, loss = 0.693938
I0701 13:50:10.943753  2788 solver.cpp:252]     Train net output #0: loss = 0.693822 (* 1 = 0.693822 loss)
I0701 13:50:10.943783  2788 sgd_solver.cpp:106] Iteration 4150, lr = 0.01
I0701 13:50:17.739315  2788 solver.cpp:236] Iteration 4160, loss = 0.693372
I0701 13:50:17.739364  2788 solver.cpp:252]     Train net output #0: loss = 0.694369 (* 1 = 0.694369 loss)
I0701 13:50:17.739379  2788 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0701 13:50:24.529356  2788 solver.cpp:236] Iteration 4170, loss = 0.693275
I0701 13:50:24.529397  2788 solver.cpp:252]     Train net output #0: loss = 0.692705 (* 1 = 0.692705 loss)
I0701 13:50:24.529410  2788 sgd_solver.cpp:106] Iteration 4170, lr = 0.01
I0701 13:50:31.332132  2788 solver.cpp:236] Iteration 4180, loss = 0.693017
I0701 13:50:31.332175  2788 solver.cpp:252]     Train net output #0: loss = 0.694038 (* 1 = 0.694038 loss)
I0701 13:50:31.332190  2788 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0701 13:50:38.149219  2788 solver.cpp:236] Iteration 4190, loss = 0.692879
I0701 13:50:38.149266  2788 solver.cpp:252]     Train net output #0: loss = 0.694249 (* 1 = 0.694249 loss)
I0701 13:50:38.149281  2788 sgd_solver.cpp:106] Iteration 4190, lr = 0.01
I0701 13:50:44.950124  2788 solver.cpp:236] Iteration 4200, loss = 0.693301
I0701 13:50:44.950294  2788 solver.cpp:252]     Train net output #0: loss = 0.693045 (* 1 = 0.693045 loss)
I0701 13:50:44.950309  2788 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0701 13:50:51.759400  2788 solver.cpp:236] Iteration 4210, loss = 0.693213
I0701 13:50:51.759443  2788 solver.cpp:252]     Train net output #0: loss = 0.692418 (* 1 = 0.692418 loss)
I0701 13:50:51.759456  2788 sgd_solver.cpp:106] Iteration 4210, lr = 0.01
I0701 13:50:58.572336  2788 solver.cpp:236] Iteration 4220, loss = 0.693225
I0701 13:50:58.572374  2788 solver.cpp:252]     Train net output #0: loss = 0.693128 (* 1 = 0.693128 loss)
I0701 13:50:58.572387  2788 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0701 13:51:05.366184  2788 solver.cpp:236] Iteration 4230, loss = 0.693278
I0701 13:51:05.366230  2788 solver.cpp:252]     Train net output #0: loss = 0.693012 (* 1 = 0.693012 loss)
I0701 13:51:05.366245  2788 sgd_solver.cpp:106] Iteration 4230, lr = 0.01
I0701 13:51:12.189589  2788 solver.cpp:236] Iteration 4240, loss = 0.693546
I0701 13:51:12.189628  2788 solver.cpp:252]     Train net output #0: loss = 0.69286 (* 1 = 0.69286 loss)
I0701 13:51:12.189642  2788 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0701 13:51:18.324903  2788 solver.cpp:340] Iteration 4250, Testing net (#0)
I0701 13:51:29.512295  2788 solver.cpp:408]     Test net output #0: accuracy = 0.493125
I0701 13:51:29.512351  2788 solver.cpp:408]     Test net output #1: loss = 0.693185 (* 1 = 0.693185 loss)
I0701 13:51:29.690160  2788 solver.cpp:236] Iteration 4250, loss = 0.693204
I0701 13:51:29.690223  2788 solver.cpp:252]     Train net output #0: loss = 0.69371 (* 1 = 0.69371 loss)
I0701 13:51:29.690244  2788 sgd_solver.cpp:106] Iteration 4250, lr = 0.01
I0701 13:51:36.500751  2788 solver.cpp:236] Iteration 4260, loss = 0.693268
I0701 13:51:36.500804  2788 solver.cpp:252]     Train net output #0: loss = 0.693501 (* 1 = 0.693501 loss)
I0701 13:51:36.500818  2788 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0701 13:51:43.291478  2788 solver.cpp:236] Iteration 4270, loss = 0.693034
I0701 13:51:43.291529  2788 solver.cpp:252]     Train net output #0: loss = 0.693472 (* 1 = 0.693472 loss)
I0701 13:51:43.291543  2788 sgd_solver.cpp:106] Iteration 4270, lr = 0.01
I0701 13:51:50.085222  2788 solver.cpp:236] Iteration 4280, loss = 0.693001
I0701 13:51:50.085330  2788 solver.cpp:252]     Train net output #0: loss = 0.687257 (* 1 = 0.687257 loss)
I0701 13:51:50.085345  2788 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0701 13:51:56.896718  2788 solver.cpp:236] Iteration 4290, loss = 0.692691
I0701 13:51:56.896767  2788 solver.cpp:252]     Train net output #0: loss = 0.682757 (* 1 = 0.682757 loss)
I0701 13:51:56.896780  2788 sgd_solver.cpp:106] Iteration 4290, lr = 0.01
I0701 13:52:03.694964  2788 solver.cpp:236] Iteration 4300, loss = 0.693062
I0701 13:52:03.695008  2788 solver.cpp:252]     Train net output #0: loss = 0.69842 (* 1 = 0.69842 loss)
I0701 13:52:03.695021  2788 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0701 13:52:10.492441  2788 solver.cpp:236] Iteration 4310, loss = 0.693024
I0701 13:52:10.492494  2788 solver.cpp:252]     Train net output #0: loss = 0.692931 (* 1 = 0.692931 loss)
I0701 13:52:10.492511  2788 sgd_solver.cpp:106] Iteration 4310, lr = 0.01
I0701 13:52:17.309505  2788 solver.cpp:236] Iteration 4320, loss = 0.693252
I0701 13:52:17.309554  2788 solver.cpp:252]     Train net output #0: loss = 0.693325 (* 1 = 0.693325 loss)
I0701 13:52:17.309567  2788 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0701 13:52:24.120345  2788 solver.cpp:236] Iteration 4330, loss = 0.693228
I0701 13:52:24.120509  2788 solver.cpp:252]     Train net output #0: loss = 0.691556 (* 1 = 0.691556 loss)
I0701 13:52:24.120525  2788 sgd_solver.cpp:106] Iteration 4330, lr = 0.01
I0701 13:52:30.919301  2788 solver.cpp:236] Iteration 4340, loss = 0.693552
I0701 13:52:30.919344  2788 solver.cpp:252]     Train net output #0: loss = 0.692277 (* 1 = 0.692277 loss)
I0701 13:52:30.919358  2788 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0701 13:52:37.733052  2788 solver.cpp:236] Iteration 4350, loss = 0.692896
I0701 13:52:37.733106  2788 solver.cpp:252]     Train net output #0: loss = 0.696713 (* 1 = 0.696713 loss)
I0701 13:52:37.733120  2788 sgd_solver.cpp:106] Iteration 4350, lr = 0.01
I0701 13:52:44.541978  2788 solver.cpp:236] Iteration 4360, loss = 0.693104
I0701 13:52:44.542026  2788 solver.cpp:252]     Train net output #0: loss = 0.692667 (* 1 = 0.692667 loss)
I0701 13:52:44.542040  2788 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0701 13:52:51.345717  2788 solver.cpp:236] Iteration 4370, loss = 0.692846
I0701 13:52:51.345758  2788 solver.cpp:252]     Train net output #0: loss = 0.692141 (* 1 = 0.692141 loss)
I0701 13:52:51.345772  2788 sgd_solver.cpp:106] Iteration 4370, lr = 0.01
I0701 13:52:58.167399  2788 solver.cpp:236] Iteration 4380, loss = 0.692977
I0701 13:52:58.167562  2788 solver.cpp:252]     Train net output #0: loss = 0.690793 (* 1 = 0.690793 loss)
I0701 13:52:58.167579  2788 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0701 13:53:04.966065  2788 solver.cpp:236] Iteration 4390, loss = 0.69298
I0701 13:53:04.966109  2788 solver.cpp:252]     Train net output #0: loss = 0.69188 (* 1 = 0.69188 loss)
I0701 13:53:04.966125  2788 sgd_solver.cpp:106] Iteration 4390, lr = 0.01
I0701 13:53:11.777426  2788 solver.cpp:236] Iteration 4400, loss = 0.693247
I0701 13:53:11.777487  2788 solver.cpp:252]     Train net output #0: loss = 0.692436 (* 1 = 0.692436 loss)
I0701 13:53:11.777501  2788 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0701 13:53:18.580994  2788 solver.cpp:236] Iteration 4410, loss = 0.693122
I0701 13:53:18.581038  2788 solver.cpp:252]     Train net output #0: loss = 0.693176 (* 1 = 0.693176 loss)
I0701 13:53:18.581050  2788 sgd_solver.cpp:106] Iteration 4410, lr = 0.01
I0701 13:53:25.389940  2788 solver.cpp:236] Iteration 4420, loss = 0.693384
I0701 13:53:25.389983  2788 solver.cpp:252]     Train net output #0: loss = 0.692888 (* 1 = 0.692888 loss)
I0701 13:53:25.390009  2788 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0701 13:53:32.207594  2788 solver.cpp:236] Iteration 4430, loss = 0.693326
I0701 13:53:32.212517  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 13:53:32.212545  2788 sgd_solver.cpp:106] Iteration 4430, lr = 0.01
I0701 13:53:39.008502  2788 solver.cpp:236] Iteration 4440, loss = 0.69333
I0701 13:53:39.008569  2788 solver.cpp:252]     Train net output #0: loss = 0.693255 (* 1 = 0.693255 loss)
I0701 13:53:39.008585  2788 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0701 13:53:45.816371  2788 solver.cpp:236] Iteration 4450, loss = 0.693311
I0701 13:53:45.816442  2788 solver.cpp:252]     Train net output #0: loss = 0.694313 (* 1 = 0.694313 loss)
I0701 13:53:45.816458  2788 sgd_solver.cpp:106] Iteration 4450, lr = 0.01
I0701 13:53:52.630015  2788 solver.cpp:236] Iteration 4460, loss = 0.693247
I0701 13:53:52.630059  2788 solver.cpp:252]     Train net output #0: loss = 0.69398 (* 1 = 0.69398 loss)
I0701 13:53:52.630074  2788 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0701 13:53:59.406137  2788 solver.cpp:236] Iteration 4470, loss = 0.69325
I0701 13:53:59.406180  2788 solver.cpp:252]     Train net output #0: loss = 0.69401 (* 1 = 0.69401 loss)
I0701 13:53:59.406193  2788 sgd_solver.cpp:106] Iteration 4470, lr = 0.01
I0701 13:54:06.208817  2788 solver.cpp:236] Iteration 4480, loss = 0.693382
I0701 13:54:06.209036  2788 solver.cpp:252]     Train net output #0: loss = 0.692971 (* 1 = 0.692971 loss)
I0701 13:54:06.209058  2788 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0701 13:54:13.003307  2788 solver.cpp:236] Iteration 4490, loss = 0.69329
I0701 13:54:13.003355  2788 solver.cpp:252]     Train net output #0: loss = 0.690752 (* 1 = 0.690752 loss)
I0701 13:54:13.003368  2788 sgd_solver.cpp:106] Iteration 4490, lr = 0.01
I0701 13:54:19.105059  2788 solver.cpp:340] Iteration 4500, Testing net (#0)
I0701 13:54:29.209115  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 13:54:30.362375  2788 solver.cpp:408]     Test net output #0: accuracy = 0.501875
I0701 13:54:30.362423  2788 solver.cpp:408]     Test net output #1: loss = 0.693895 (* 1 = 0.693895 loss)
I0701 13:54:30.532133  2788 solver.cpp:236] Iteration 4500, loss = 0.69326
I0701 13:54:30.532174  2788 solver.cpp:252]     Train net output #0: loss = 0.693389 (* 1 = 0.693389 loss)
I0701 13:54:30.532187  2788 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0701 13:54:37.313313  2788 solver.cpp:236] Iteration 4510, loss = 0.693635
I0701 13:54:37.313503  2788 solver.cpp:252]     Train net output #0: loss = 0.693354 (* 1 = 0.693354 loss)
I0701 13:54:37.313525  2788 sgd_solver.cpp:106] Iteration 4510, lr = 0.01
I0701 13:54:44.107585  2788 solver.cpp:236] Iteration 4520, loss = 0.693705
I0701 13:54:44.107632  2788 solver.cpp:252]     Train net output #0: loss = 0.692765 (* 1 = 0.692765 loss)
I0701 13:54:44.107650  2788 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0701 13:54:50.891528  2788 solver.cpp:236] Iteration 4530, loss = 0.693482
I0701 13:54:50.891571  2788 solver.cpp:252]     Train net output #0: loss = 0.694117 (* 1 = 0.694117 loss)
I0701 13:54:50.891589  2788 sgd_solver.cpp:106] Iteration 4530, lr = 0.01
I0701 13:54:57.703466  2788 solver.cpp:236] Iteration 4540, loss = 0.693611
I0701 13:54:57.703505  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 13:54:57.703517  2788 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0701 13:55:04.495486  2788 solver.cpp:236] Iteration 4550, loss = 0.693627
I0701 13:55:04.495529  2788 solver.cpp:252]     Train net output #0: loss = 0.693584 (* 1 = 0.693584 loss)
I0701 13:55:04.495543  2788 sgd_solver.cpp:106] Iteration 4550, lr = 0.01
I0701 13:55:11.268925  2788 solver.cpp:236] Iteration 4560, loss = 0.693279
I0701 13:55:11.269059  2788 solver.cpp:252]     Train net output #0: loss = 0.693177 (* 1 = 0.693177 loss)
I0701 13:55:11.269083  2788 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0701 13:55:18.074579  2788 solver.cpp:236] Iteration 4570, loss = 0.693204
I0701 13:55:18.074636  2788 solver.cpp:252]     Train net output #0: loss = 0.693079 (* 1 = 0.693079 loss)
I0701 13:55:18.074656  2788 sgd_solver.cpp:106] Iteration 4570, lr = 0.01
I0701 13:55:24.847802  2788 solver.cpp:236] Iteration 4580, loss = 0.693316
I0701 13:55:24.847851  2788 solver.cpp:252]     Train net output #0: loss = 0.693276 (* 1 = 0.693276 loss)
I0701 13:55:24.847864  2788 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0701 13:55:31.648589  2788 solver.cpp:236] Iteration 4590, loss = 0.693276
I0701 13:55:31.648636  2788 solver.cpp:252]     Train net output #0: loss = 0.695216 (* 1 = 0.695216 loss)
I0701 13:55:31.648650  2788 sgd_solver.cpp:106] Iteration 4590, lr = 0.01
I0701 13:55:38.445657  2788 solver.cpp:236] Iteration 4600, loss = 0.693241
I0701 13:55:38.445713  2788 solver.cpp:252]     Train net output #0: loss = 0.69424 (* 1 = 0.69424 loss)
I0701 13:55:38.445727  2788 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0701 13:55:45.241497  2788 solver.cpp:236] Iteration 4610, loss = 0.693283
I0701 13:55:45.241673  2788 solver.cpp:252]     Train net output #0: loss = 0.693038 (* 1 = 0.693038 loss)
I0701 13:55:45.241688  2788 sgd_solver.cpp:106] Iteration 4610, lr = 0.01
I0701 13:55:52.050976  2788 solver.cpp:236] Iteration 4620, loss = 0.69329
I0701 13:55:52.051054  2788 solver.cpp:252]     Train net output #0: loss = 0.693358 (* 1 = 0.693358 loss)
I0701 13:55:52.051075  2788 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0701 13:55:58.854110  2788 solver.cpp:236] Iteration 4630, loss = 0.693269
I0701 13:55:58.854156  2788 solver.cpp:252]     Train net output #0: loss = 0.69355 (* 1 = 0.69355 loss)
I0701 13:55:58.854167  2788 sgd_solver.cpp:106] Iteration 4630, lr = 0.01
I0701 13:56:05.665405  2788 solver.cpp:236] Iteration 4640, loss = 0.693248
I0701 13:56:05.665443  2788 solver.cpp:252]     Train net output #0: loss = 0.693763 (* 1 = 0.693763 loss)
I0701 13:56:05.665457  2788 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0701 13:56:12.479223  2788 solver.cpp:236] Iteration 4650, loss = 0.693179
I0701 13:56:12.479269  2788 solver.cpp:252]     Train net output #0: loss = 0.692253 (* 1 = 0.692253 loss)
I0701 13:56:12.479284  2788 sgd_solver.cpp:106] Iteration 4650, lr = 0.01
I0701 13:56:19.286607  2788 solver.cpp:236] Iteration 4660, loss = 0.693262
I0701 13:56:19.286743  2788 solver.cpp:252]     Train net output #0: loss = 0.702959 (* 1 = 0.702959 loss)
I0701 13:56:19.286761  2788 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0701 13:56:26.088546  2788 solver.cpp:236] Iteration 4670, loss = 0.693336
I0701 13:56:26.088589  2788 solver.cpp:252]     Train net output #0: loss = 0.693462 (* 1 = 0.693462 loss)
I0701 13:56:26.088603  2788 sgd_solver.cpp:106] Iteration 4670, lr = 0.01
I0701 13:56:32.897545  2788 solver.cpp:236] Iteration 4680, loss = 0.693318
I0701 13:56:32.897595  2788 solver.cpp:252]     Train net output #0: loss = 0.692834 (* 1 = 0.692834 loss)
I0701 13:56:32.897608  2788 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0701 13:56:39.706085  2788 solver.cpp:236] Iteration 4690, loss = 0.693205
I0701 13:56:39.706128  2788 solver.cpp:252]     Train net output #0: loss = 0.695007 (* 1 = 0.695007 loss)
I0701 13:56:39.706141  2788 sgd_solver.cpp:106] Iteration 4690, lr = 0.01
I0701 13:56:46.507916  2788 solver.cpp:236] Iteration 4700, loss = 0.69349
I0701 13:56:46.507982  2788 solver.cpp:252]     Train net output #0: loss = 0.697476 (* 1 = 0.697476 loss)
I0701 13:56:46.507997  2788 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0701 13:56:53.290616  2788 solver.cpp:236] Iteration 4710, loss = 0.693596
I0701 13:56:53.290721  2788 solver.cpp:252]     Train net output #0: loss = 0.693137 (* 1 = 0.693137 loss)
I0701 13:56:53.290747  2788 sgd_solver.cpp:106] Iteration 4710, lr = 0.01
I0701 13:57:00.098757  2788 solver.cpp:236] Iteration 4720, loss = 0.693575
I0701 13:57:00.098799  2788 solver.cpp:252]     Train net output #0: loss = 0.69325 (* 1 = 0.69325 loss)
I0701 13:57:00.098812  2788 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0701 13:57:06.899349  2788 solver.cpp:236] Iteration 4730, loss = 0.693589
I0701 13:57:06.899401  2788 solver.cpp:252]     Train net output #0: loss = 0.693255 (* 1 = 0.693255 loss)
I0701 13:57:06.899415  2788 sgd_solver.cpp:106] Iteration 4730, lr = 0.01
I0701 13:57:13.694011  2788 solver.cpp:236] Iteration 4740, loss = 0.693794
I0701 13:57:13.694074  2788 solver.cpp:252]     Train net output #0: loss = 0.69348 (* 1 = 0.69348 loss)
I0701 13:57:13.694088  2788 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0701 13:57:19.814967  2788 solver.cpp:340] Iteration 4750, Testing net (#0)
I0701 13:57:31.604063  2788 solver.cpp:408]     Test net output #0: accuracy = 0.513125
I0701 13:57:31.604199  2788 solver.cpp:408]     Test net output #1: loss = 0.692806 (* 1 = 0.692806 loss)
I0701 13:57:31.776239  2788 solver.cpp:236] Iteration 4750, loss = 0.693628
I0701 13:57:31.776283  2788 solver.cpp:252]     Train net output #0: loss = 0.69086 (* 1 = 0.69086 loss)
I0701 13:57:31.776298  2788 sgd_solver.cpp:106] Iteration 4750, lr = 0.01
I0701 13:57:38.557636  2788 solver.cpp:236] Iteration 4760, loss = 0.693355
I0701 13:57:38.557699  2788 solver.cpp:252]     Train net output #0: loss = 0.69593 (* 1 = 0.69593 loss)
I0701 13:57:38.557714  2788 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0701 13:57:45.336112  2788 solver.cpp:236] Iteration 4770, loss = 0.693422
I0701 13:57:45.336171  2788 solver.cpp:252]     Train net output #0: loss = 0.692724 (* 1 = 0.692724 loss)
I0701 13:57:45.336185  2788 sgd_solver.cpp:106] Iteration 4770, lr = 0.01
I0701 13:57:52.132141  2788 solver.cpp:236] Iteration 4780, loss = 0.693408
I0701 13:57:52.132192  2788 solver.cpp:252]     Train net output #0: loss = 0.696028 (* 1 = 0.696028 loss)
I0701 13:57:52.132206  2788 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0701 13:57:58.919163  2788 solver.cpp:236] Iteration 4790, loss = 0.693319
I0701 13:57:58.919219  2788 solver.cpp:252]     Train net output #0: loss = 0.693978 (* 1 = 0.693978 loss)
I0701 13:57:58.919234  2788 sgd_solver.cpp:106] Iteration 4790, lr = 0.01
I0701 13:58:05.696688  2788 solver.cpp:236] Iteration 4800, loss = 0.693274
I0701 13:58:05.696880  2788 solver.cpp:252]     Train net output #0: loss = 0.692519 (* 1 = 0.692519 loss)
I0701 13:58:05.696925  2788 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0701 13:58:12.493371  2788 solver.cpp:236] Iteration 4810, loss = 0.693371
I0701 13:58:12.493449  2788 solver.cpp:252]     Train net output #0: loss = 0.692788 (* 1 = 0.692788 loss)
I0701 13:58:12.493464  2788 sgd_solver.cpp:106] Iteration 4810, lr = 0.01
I0701 13:58:19.275902  2788 solver.cpp:236] Iteration 4820, loss = 0.693141
I0701 13:58:19.275945  2788 solver.cpp:252]     Train net output #0: loss = 0.692743 (* 1 = 0.692743 loss)
I0701 13:58:19.275959  2788 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0701 13:58:26.071895  2788 solver.cpp:236] Iteration 4830, loss = 0.693188
I0701 13:58:26.071956  2788 solver.cpp:252]     Train net output #0: loss = 0.692007 (* 1 = 0.692007 loss)
I0701 13:58:26.071970  2788 sgd_solver.cpp:106] Iteration 4830, lr = 0.01
I0701 13:58:32.859839  2788 solver.cpp:236] Iteration 4840, loss = 0.693116
I0701 13:58:32.859880  2788 solver.cpp:252]     Train net output #0: loss = 0.691513 (* 1 = 0.691513 loss)
I0701 13:58:32.859894  2788 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0701 13:58:39.647322  2788 solver.cpp:236] Iteration 4850, loss = 0.693231
I0701 13:58:39.647446  2788 solver.cpp:252]     Train net output #0: loss = 0.694828 (* 1 = 0.694828 loss)
I0701 13:58:39.647478  2788 sgd_solver.cpp:106] Iteration 4850, lr = 0.01
I0701 13:58:46.461300  2788 solver.cpp:236] Iteration 4860, loss = 0.693195
I0701 13:58:46.461349  2788 solver.cpp:252]     Train net output #0: loss = 0.693251 (* 1 = 0.693251 loss)
I0701 13:58:46.461362  2788 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0701 13:58:53.264027  2788 solver.cpp:236] Iteration 4870, loss = 0.693325
I0701 13:58:53.264075  2788 solver.cpp:252]     Train net output #0: loss = 0.69331 (* 1 = 0.69331 loss)
I0701 13:58:53.264088  2788 sgd_solver.cpp:106] Iteration 4870, lr = 0.01
I0701 13:59:00.065558  2788 solver.cpp:236] Iteration 4880, loss = 0.693295
I0701 13:59:00.065601  2788 solver.cpp:252]     Train net output #0: loss = 0.693917 (* 1 = 0.693917 loss)
I0701 13:59:00.065613  2788 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0701 13:59:06.871743  2788 solver.cpp:236] Iteration 4890, loss = 0.693564
I0701 13:59:06.871801  2788 solver.cpp:252]     Train net output #0: loss = 0.69325 (* 1 = 0.69325 loss)
I0701 13:59:06.871815  2788 sgd_solver.cpp:106] Iteration 4890, lr = 0.01
I0701 13:59:13.709851  2788 solver.cpp:236] Iteration 4900, loss = 0.693521
I0701 13:59:13.709949  2788 solver.cpp:252]     Train net output #0: loss = 0.693156 (* 1 = 0.693156 loss)
I0701 13:59:13.709962  2788 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0701 13:59:20.495304  2788 solver.cpp:236] Iteration 4910, loss = 0.693626
I0701 13:59:20.495349  2788 solver.cpp:252]     Train net output #0: loss = 0.696508 (* 1 = 0.696508 loss)
I0701 13:59:20.495363  2788 sgd_solver.cpp:106] Iteration 4910, lr = 0.01
I0701 13:59:27.305063  2788 solver.cpp:236] Iteration 4920, loss = 0.693746
I0701 13:59:27.305110  2788 solver.cpp:252]     Train net output #0: loss = 0.693605 (* 1 = 0.693605 loss)
I0701 13:59:27.305124  2788 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0701 13:59:34.131368  2788 solver.cpp:236] Iteration 4930, loss = 0.693852
I0701 13:59:34.131414  2788 solver.cpp:252]     Train net output #0: loss = 0.694649 (* 1 = 0.694649 loss)
I0701 13:59:34.131428  2788 sgd_solver.cpp:106] Iteration 4930, lr = 0.01
I0701 13:59:40.946516  2788 solver.cpp:236] Iteration 4940, loss = 0.693637
I0701 13:59:40.946562  2788 solver.cpp:252]     Train net output #0: loss = 0.693488 (* 1 = 0.693488 loss)
I0701 13:59:40.946576  2788 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0701 13:59:47.774765  2788 solver.cpp:236] Iteration 4950, loss = 0.693532
I0701 13:59:47.774945  2788 solver.cpp:252]     Train net output #0: loss = 0.693027 (* 1 = 0.693027 loss)
I0701 13:59:47.774960  2788 sgd_solver.cpp:106] Iteration 4950, lr = 0.01
I0701 13:59:54.578018  2788 solver.cpp:236] Iteration 4960, loss = 0.693315
I0701 13:59:54.578063  2788 solver.cpp:252]     Train net output #0: loss = 0.695012 (* 1 = 0.695012 loss)
I0701 13:59:54.578076  2788 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0701 14:00:01.417886  2788 solver.cpp:236] Iteration 4970, loss = 0.693363
I0701 14:00:01.417927  2788 solver.cpp:252]     Train net output #0: loss = 0.69372 (* 1 = 0.69372 loss)
I0701 14:00:01.417939  2788 sgd_solver.cpp:106] Iteration 4970, lr = 0.01
I0701 14:00:08.232986  2788 solver.cpp:236] Iteration 4980, loss = 0.693341
I0701 14:00:08.233065  2788 solver.cpp:252]     Train net output #0: loss = 0.692049 (* 1 = 0.692049 loss)
I0701 14:00:08.233080  2788 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0701 14:00:15.053575  2788 solver.cpp:236] Iteration 4990, loss = 0.693372
I0701 14:00:15.053619  2788 solver.cpp:252]     Train net output #0: loss = 0.694314 (* 1 = 0.694314 loss)
I0701 14:00:15.053632  2788 sgd_solver.cpp:106] Iteration 4990, lr = 0.01
I0701 14:00:21.217315  2788 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_5000.caffemodel
I0701 14:00:21.896891  2788 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_5000.solverstate
I0701 14:00:21.977857  2788 solver.cpp:340] Iteration 5000, Testing net (#0)
I0701 14:00:32.843916  2788 solver.cpp:408]     Test net output #0: accuracy = 0.505625
I0701 14:00:32.843962  2788 solver.cpp:408]     Test net output #1: loss = 0.693124 (* 1 = 0.693124 loss)
I0701 14:00:33.011843  2788 solver.cpp:236] Iteration 5000, loss = 0.693375
I0701 14:00:33.011884  2788 solver.cpp:252]     Train net output #0: loss = 0.694301 (* 1 = 0.694301 loss)
I0701 14:00:33.011898  2788 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0701 14:00:39.821141  2788 solver.cpp:236] Iteration 5010, loss = 0.693594
I0701 14:00:39.821199  2788 solver.cpp:252]     Train net output #0: loss = 0.693417 (* 1 = 0.693417 loss)
I0701 14:00:39.821213  2788 sgd_solver.cpp:106] Iteration 5010, lr = 0.01
I0701 14:00:46.632869  2788 solver.cpp:236] Iteration 5020, loss = 0.693405
I0701 14:00:46.632910  2788 solver.cpp:252]     Train net output #0: loss = 0.693186 (* 1 = 0.693186 loss)
I0701 14:00:46.632923  2788 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0701 14:00:53.440282  2788 solver.cpp:236] Iteration 5030, loss = 0.693275
I0701 14:00:53.440451  2788 solver.cpp:252]     Train net output #0: loss = 0.693816 (* 1 = 0.693816 loss)
I0701 14:00:53.440482  2788 sgd_solver.cpp:106] Iteration 5030, lr = 0.01
I0701 14:01:00.256047  2788 solver.cpp:236] Iteration 5040, loss = 0.693318
I0701 14:01:00.256090  2788 solver.cpp:252]     Train net output #0: loss = 0.693056 (* 1 = 0.693056 loss)
I0701 14:01:00.256104  2788 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0701 14:01:07.065835  2788 solver.cpp:236] Iteration 5050, loss = 0.693412
I0701 14:01:07.065884  2788 solver.cpp:252]     Train net output #0: loss = 0.693181 (* 1 = 0.693181 loss)
I0701 14:01:07.065897  2788 sgd_solver.cpp:106] Iteration 5050, lr = 0.01
I0701 14:01:13.866412  2788 solver.cpp:236] Iteration 5060, loss = 0.693261
I0701 14:01:13.866456  2788 solver.cpp:252]     Train net output #0: loss = 0.69294 (* 1 = 0.69294 loss)
I0701 14:01:13.866469  2788 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0701 14:01:20.669047  2788 solver.cpp:236] Iteration 5070, loss = 0.693351
I0701 14:01:20.669106  2788 solver.cpp:252]     Train net output #0: loss = 0.695169 (* 1 = 0.695169 loss)
I0701 14:01:20.669127  2788 sgd_solver.cpp:106] Iteration 5070, lr = 0.01
I0701 14:01:27.476285  2788 solver.cpp:236] Iteration 5080, loss = 0.693466
I0701 14:01:27.476474  2788 solver.cpp:252]     Train net output #0: loss = 0.69356 (* 1 = 0.69356 loss)
I0701 14:01:27.476512  2788 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0701 14:01:34.293545  2788 solver.cpp:236] Iteration 5090, loss = 0.693376
I0701 14:01:34.293586  2788 solver.cpp:252]     Train net output #0: loss = 0.692665 (* 1 = 0.692665 loss)
I0701 14:01:34.293599  2788 sgd_solver.cpp:106] Iteration 5090, lr = 0.01
I0701 14:01:41.095111  2788 solver.cpp:236] Iteration 5100, loss = 0.693545
I0701 14:01:41.095165  2788 solver.cpp:252]     Train net output #0: loss = 0.692347 (* 1 = 0.692347 loss)
I0701 14:01:41.095178  2788 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0701 14:01:47.906577  2788 solver.cpp:236] Iteration 5110, loss = 0.693551
I0701 14:01:47.906637  2788 solver.cpp:252]     Train net output #0: loss = 0.693006 (* 1 = 0.693006 loss)
I0701 14:01:47.906651  2788 sgd_solver.cpp:106] Iteration 5110, lr = 0.01
I0701 14:01:54.722378  2788 solver.cpp:236] Iteration 5120, loss = 0.693467
I0701 14:01:54.722419  2788 solver.cpp:252]     Train net output #0: loss = 0.693317 (* 1 = 0.693317 loss)
I0701 14:01:54.722432  2788 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0701 14:02:01.543094  2788 solver.cpp:236] Iteration 5130, loss = 0.693368
I0701 14:02:01.543212  2788 solver.cpp:252]     Train net output #0: loss = 0.694325 (* 1 = 0.694325 loss)
I0701 14:02:01.543228  2788 sgd_solver.cpp:106] Iteration 5130, lr = 0.01
I0701 14:02:08.347072  2788 solver.cpp:236] Iteration 5140, loss = 0.693442
I0701 14:02:08.347137  2788 solver.cpp:252]     Train net output #0: loss = 0.696321 (* 1 = 0.696321 loss)
I0701 14:02:08.347151  2788 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0701 14:02:15.169930  2788 solver.cpp:236] Iteration 5150, loss = 0.693271
I0701 14:02:15.169973  2788 solver.cpp:252]     Train net output #0: loss = 0.692965 (* 1 = 0.692965 loss)
I0701 14:02:15.169986  2788 sgd_solver.cpp:106] Iteration 5150, lr = 0.01
I0701 14:02:21.993005  2788 solver.cpp:236] Iteration 5160, loss = 0.693252
I0701 14:02:21.993046  2788 solver.cpp:252]     Train net output #0: loss = 0.692317 (* 1 = 0.692317 loss)
I0701 14:02:21.993058  2788 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0701 14:02:28.801081  2788 solver.cpp:236] Iteration 5170, loss = 0.693282
I0701 14:02:28.801126  2788 solver.cpp:252]     Train net output #0: loss = 0.69308 (* 1 = 0.69308 loss)
I0701 14:02:28.801137  2788 sgd_solver.cpp:106] Iteration 5170, lr = 0.01
I0701 14:02:35.612097  2788 solver.cpp:236] Iteration 5180, loss = 0.693308
I0701 14:02:35.616492  2788 solver.cpp:252]     Train net output #0: loss = 0.692962 (* 1 = 0.692962 loss)
I0701 14:02:35.616518  2788 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0701 14:02:42.412258  2788 solver.cpp:236] Iteration 5190, loss = 0.693296
I0701 14:02:42.412310  2788 solver.cpp:252]     Train net output #0: loss = 0.693138 (* 1 = 0.693138 loss)
I0701 14:02:42.412325  2788 sgd_solver.cpp:106] Iteration 5190, lr = 0.01
I0701 14:02:49.227347  2788 solver.cpp:236] Iteration 5200, loss = 0.693327
I0701 14:02:49.227399  2788 solver.cpp:252]     Train net output #0: loss = 0.692828 (* 1 = 0.692828 loss)
I0701 14:02:49.227413  2788 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0701 14:02:56.062800  2788 solver.cpp:236] Iteration 5210, loss = 0.693363
I0701 14:02:56.062844  2788 solver.cpp:252]     Train net output #0: loss = 0.693428 (* 1 = 0.693428 loss)
I0701 14:02:56.062857  2788 sgd_solver.cpp:106] Iteration 5210, lr = 0.01
I0701 14:03:02.864740  2788 solver.cpp:236] Iteration 5220, loss = 0.693268
I0701 14:03:02.864790  2788 solver.cpp:252]     Train net output #0: loss = 0.692224 (* 1 = 0.692224 loss)
I0701 14:03:02.864804  2788 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0701 14:03:09.681435  2788 solver.cpp:236] Iteration 5230, loss = 0.693112
I0701 14:03:09.681604  2788 solver.cpp:252]     Train net output #0: loss = 0.695317 (* 1 = 0.695317 loss)
I0701 14:03:09.681640  2788 sgd_solver.cpp:106] Iteration 5230, lr = 0.01
I0701 14:03:16.493680  2788 solver.cpp:236] Iteration 5240, loss = 0.69286
I0701 14:03:16.493736  2788 solver.cpp:252]     Train net output #0: loss = 0.696992 (* 1 = 0.696992 loss)
I0701 14:03:16.493753  2788 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0701 14:03:22.636934  2788 solver.cpp:340] Iteration 5250, Testing net (#0)
I0701 14:03:34.279003  2788 solver.cpp:408]     Test net output #0: accuracy = 0.497813
I0701 14:03:34.279049  2788 solver.cpp:408]     Test net output #1: loss = 0.694283 (* 1 = 0.694283 loss)
I0701 14:03:34.453560  2788 solver.cpp:236] Iteration 5250, loss = 0.692956
I0701 14:03:34.453600  2788 solver.cpp:252]     Train net output #0: loss = 0.695452 (* 1 = 0.695452 loss)
I0701 14:03:34.453619  2788 sgd_solver.cpp:106] Iteration 5250, lr = 0.01
I0701 14:03:41.242614  2788 solver.cpp:236] Iteration 5260, loss = 0.693182
I0701 14:03:41.242738  2788 solver.cpp:252]     Train net output #0: loss = 0.694138 (* 1 = 0.694138 loss)
I0701 14:03:41.242751  2788 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0701 14:03:48.045089  2788 solver.cpp:236] Iteration 5270, loss = 0.693362
I0701 14:03:48.045127  2788 solver.cpp:252]     Train net output #0: loss = 0.70128 (* 1 = 0.70128 loss)
I0701 14:03:48.045140  2788 sgd_solver.cpp:106] Iteration 5270, lr = 0.01
I0701 14:03:54.840450  2788 solver.cpp:236] Iteration 5280, loss = 0.693576
I0701 14:03:54.840529  2788 solver.cpp:252]     Train net output #0: loss = 0.69531 (* 1 = 0.69531 loss)
I0701 14:03:54.840545  2788 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0701 14:04:01.648120  2788 solver.cpp:236] Iteration 5290, loss = 0.693997
I0701 14:04:01.648162  2788 solver.cpp:252]     Train net output #0: loss = 0.693246 (* 1 = 0.693246 loss)
I0701 14:04:01.648175  2788 sgd_solver.cpp:106] Iteration 5290, lr = 0.01
I0701 14:04:08.442451  2788 solver.cpp:236] Iteration 5300, loss = 0.693859
I0701 14:04:08.442502  2788 solver.cpp:252]     Train net output #0: loss = 0.692979 (* 1 = 0.692979 loss)
I0701 14:04:08.442528  2788 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0701 14:04:15.235826  2788 solver.cpp:236] Iteration 5310, loss = 0.693553
I0701 14:04:15.235934  2788 solver.cpp:252]     Train net output #0: loss = 0.691752 (* 1 = 0.691752 loss)
I0701 14:04:15.235949  2788 sgd_solver.cpp:106] Iteration 5310, lr = 0.01
I0701 14:04:22.046890  2788 solver.cpp:236] Iteration 5320, loss = 0.693544
I0701 14:04:22.046941  2788 solver.cpp:252]     Train net output #0: loss = 0.69273 (* 1 = 0.69273 loss)
I0701 14:04:22.046955  2788 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0701 14:04:28.871984  2788 solver.cpp:236] Iteration 5330, loss = 0.693489
I0701 14:04:28.872025  2788 solver.cpp:252]     Train net output #0: loss = 0.692713 (* 1 = 0.692713 loss)
I0701 14:04:28.872040  2788 sgd_solver.cpp:106] Iteration 5330, lr = 0.01
I0701 14:04:35.676718  2788 solver.cpp:236] Iteration 5340, loss = 0.693279
I0701 14:04:35.676764  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 14:04:35.676776  2788 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0701 14:04:42.485110  2788 solver.cpp:236] Iteration 5350, loss = 0.693234
I0701 14:04:42.485157  2788 solver.cpp:252]     Train net output #0: loss = 0.692839 (* 1 = 0.692839 loss)
I0701 14:04:42.485172  2788 sgd_solver.cpp:106] Iteration 5350, lr = 0.01
I0701 14:04:49.290493  2788 solver.cpp:236] Iteration 5360, loss = 0.693376
I0701 14:04:49.290606  2788 solver.cpp:252]     Train net output #0: loss = 0.692204 (* 1 = 0.692204 loss)
I0701 14:04:49.290640  2788 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0701 14:04:56.107764  2788 solver.cpp:236] Iteration 5370, loss = 0.693227
I0701 14:04:56.107815  2788 solver.cpp:252]     Train net output #0: loss = 0.694826 (* 1 = 0.694826 loss)
I0701 14:04:56.107831  2788 sgd_solver.cpp:106] Iteration 5370, lr = 0.01
I0701 14:05:02.897110  2788 solver.cpp:236] Iteration 5380, loss = 0.693215
I0701 14:05:02.897150  2788 solver.cpp:252]     Train net output #0: loss = 0.692878 (* 1 = 0.692878 loss)
I0701 14:05:02.897163  2788 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0701 14:05:09.724141  2788 solver.cpp:236] Iteration 5390, loss = 0.693204
I0701 14:05:09.724189  2788 solver.cpp:252]     Train net output #0: loss = 0.694259 (* 1 = 0.694259 loss)
I0701 14:05:09.724203  2788 sgd_solver.cpp:106] Iteration 5390, lr = 0.01
I0701 14:05:16.539151  2788 solver.cpp:236] Iteration 5400, loss = 0.693271
I0701 14:05:16.539196  2788 solver.cpp:252]     Train net output #0: loss = 0.692909 (* 1 = 0.692909 loss)
I0701 14:05:16.539209  2788 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0701 14:05:23.361826  2788 solver.cpp:236] Iteration 5410, loss = 0.69317
I0701 14:05:23.362002  2788 solver.cpp:252]     Train net output #0: loss = 0.693704 (* 1 = 0.693704 loss)
I0701 14:05:23.362017  2788 sgd_solver.cpp:106] Iteration 5410, lr = 0.01
I0701 14:05:30.163193  2788 solver.cpp:236] Iteration 5420, loss = 0.693172
I0701 14:05:30.163242  2788 solver.cpp:252]     Train net output #0: loss = 0.691673 (* 1 = 0.691673 loss)
I0701 14:05:30.163255  2788 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0701 14:05:36.959650  2788 solver.cpp:236] Iteration 5430, loss = 0.693262
I0701 14:05:36.959700  2788 solver.cpp:252]     Train net output #0: loss = 0.693035 (* 1 = 0.693035 loss)
I0701 14:05:36.959713  2788 sgd_solver.cpp:106] Iteration 5430, lr = 0.01
I0701 14:05:43.783226  2788 solver.cpp:236] Iteration 5440, loss = 0.693393
I0701 14:05:43.783272  2788 solver.cpp:252]     Train net output #0: loss = 0.694373 (* 1 = 0.694373 loss)
I0701 14:05:43.783284  2788 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0701 14:05:50.586354  2788 solver.cpp:236] Iteration 5450, loss = 0.693381
I0701 14:05:50.586412  2788 solver.cpp:252]     Train net output #0: loss = 0.693315 (* 1 = 0.693315 loss)
I0701 14:05:50.586426  2788 sgd_solver.cpp:106] Iteration 5450, lr = 0.01
I0701 14:05:57.390485  2788 solver.cpp:236] Iteration 5460, loss = 0.693414
I0701 14:05:57.390588  2788 solver.cpp:252]     Train net output #0: loss = 0.692806 (* 1 = 0.692806 loss)
I0701 14:05:57.390604  2788 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0701 14:06:04.202224  2788 solver.cpp:236] Iteration 5470, loss = 0.693426
I0701 14:06:04.202271  2788 solver.cpp:252]     Train net output #0: loss = 0.691361 (* 1 = 0.691361 loss)
I0701 14:06:04.202285  2788 sgd_solver.cpp:106] Iteration 5470, lr = 0.01
I0701 14:06:11.010483  2788 solver.cpp:236] Iteration 5480, loss = 0.693381
I0701 14:06:11.010545  2788 solver.cpp:252]     Train net output #0: loss = 0.692772 (* 1 = 0.692772 loss)
I0701 14:06:11.010565  2788 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0701 14:06:17.830317  2788 solver.cpp:236] Iteration 5490, loss = 0.693272
I0701 14:06:17.830380  2788 solver.cpp:252]     Train net output #0: loss = 0.693057 (* 1 = 0.693057 loss)
I0701 14:06:17.830395  2788 sgd_solver.cpp:106] Iteration 5490, lr = 0.01
I0701 14:06:23.940716  2788 solver.cpp:340] Iteration 5500, Testing net (#0)
I0701 14:06:35.338985  2788 solver.cpp:408]     Test net output #0: accuracy = 0.4825
I0701 14:06:35.339108  2788 solver.cpp:408]     Test net output #1: loss = 0.693709 (* 1 = 0.693709 loss)
I0701 14:06:35.516463  2788 solver.cpp:236] Iteration 5500, loss = 0.693301
I0701 14:06:35.516508  2788 solver.cpp:252]     Train net output #0: loss = 0.692817 (* 1 = 0.692817 loss)
I0701 14:06:35.516523  2788 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0701 14:06:42.297842  2788 solver.cpp:236] Iteration 5510, loss = 0.693355
I0701 14:06:42.297905  2788 solver.cpp:252]     Train net output #0: loss = 0.693357 (* 1 = 0.693357 loss)
I0701 14:06:42.297919  2788 sgd_solver.cpp:106] Iteration 5510, lr = 0.01
I0701 14:06:49.101693  2788 solver.cpp:236] Iteration 5520, loss = 0.693385
I0701 14:06:49.101740  2788 solver.cpp:252]     Train net output #0: loss = 0.692894 (* 1 = 0.692894 loss)
I0701 14:06:49.101753  2788 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0701 14:06:55.886399  2788 solver.cpp:236] Iteration 5530, loss = 0.693316
I0701 14:06:55.886447  2788 solver.cpp:252]     Train net output #0: loss = 0.693078 (* 1 = 0.693078 loss)
I0701 14:06:55.886461  2788 sgd_solver.cpp:106] Iteration 5530, lr = 0.01
I0701 14:07:02.686120  2788 solver.cpp:236] Iteration 5540, loss = 0.693206
I0701 14:07:02.686162  2788 solver.cpp:252]     Train net output #0: loss = 0.690718 (* 1 = 0.690718 loss)
I0701 14:07:02.686175  2788 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0701 14:07:09.500216  2788 solver.cpp:236] Iteration 5550, loss = 0.693362
I0701 14:07:09.500386  2788 solver.cpp:252]     Train net output #0: loss = 0.694046 (* 1 = 0.694046 loss)
I0701 14:07:09.500403  2788 sgd_solver.cpp:106] Iteration 5550, lr = 0.01
I0701 14:07:16.286567  2788 solver.cpp:236] Iteration 5560, loss = 0.693313
I0701 14:07:16.286614  2788 solver.cpp:252]     Train net output #0: loss = 0.693335 (* 1 = 0.693335 loss)
I0701 14:07:16.286629  2788 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0701 14:07:23.088990  2788 solver.cpp:236] Iteration 5570, loss = 0.693113
I0701 14:07:23.089038  2788 solver.cpp:252]     Train net output #0: loss = 0.694097 (* 1 = 0.694097 loss)
I0701 14:07:23.089051  2788 sgd_solver.cpp:106] Iteration 5570, lr = 0.01
I0701 14:07:29.894539  2788 solver.cpp:236] Iteration 5580, loss = 0.693367
I0701 14:07:29.894590  2788 solver.cpp:252]     Train net output #0: loss = 0.692684 (* 1 = 0.692684 loss)
I0701 14:07:29.894604  2788 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0701 14:07:36.698823  2788 solver.cpp:236] Iteration 5590, loss = 0.693689
I0701 14:07:36.698874  2788 solver.cpp:252]     Train net output #0: loss = 0.693343 (* 1 = 0.693343 loss)
I0701 14:07:36.698889  2788 sgd_solver.cpp:106] Iteration 5590, lr = 0.01
I0701 14:07:43.504945  2788 solver.cpp:236] Iteration 5600, loss = 0.693553
I0701 14:07:43.505070  2788 solver.cpp:252]     Train net output #0: loss = 0.693524 (* 1 = 0.693524 loss)
I0701 14:07:43.505086  2788 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0701 14:07:50.314061  2788 solver.cpp:236] Iteration 5610, loss = 0.693587
I0701 14:07:50.314108  2788 solver.cpp:252]     Train net output #0: loss = 0.693221 (* 1 = 0.693221 loss)
I0701 14:07:50.314121  2788 sgd_solver.cpp:106] Iteration 5610, lr = 0.01
I0701 14:07:57.126307  2788 solver.cpp:236] Iteration 5620, loss = 0.693799
I0701 14:07:57.126356  2788 solver.cpp:252]     Train net output #0: loss = 0.693185 (* 1 = 0.693185 loss)
I0701 14:07:57.126369  2788 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0701 14:08:03.931850  2788 solver.cpp:236] Iteration 5630, loss = 0.693551
I0701 14:08:03.931908  2788 solver.cpp:252]     Train net output #0: loss = 0.693034 (* 1 = 0.693034 loss)
I0701 14:08:03.931928  2788 sgd_solver.cpp:106] Iteration 5630, lr = 0.01
I0701 14:08:10.741366  2788 solver.cpp:236] Iteration 5640, loss = 0.693304
I0701 14:08:10.741431  2788 solver.cpp:252]     Train net output #0: loss = 0.69172 (* 1 = 0.69172 loss)
I0701 14:08:10.741457  2788 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0701 14:08:17.558459  2788 solver.cpp:236] Iteration 5650, loss = 0.693286
I0701 14:08:17.558573  2788 solver.cpp:252]     Train net output #0: loss = 0.692364 (* 1 = 0.692364 loss)
I0701 14:08:17.558588  2788 sgd_solver.cpp:106] Iteration 5650, lr = 0.01
I0701 14:08:24.369943  2788 solver.cpp:236] Iteration 5660, loss = 0.693321
I0701 14:08:24.369988  2788 solver.cpp:252]     Train net output #0: loss = 0.693485 (* 1 = 0.693485 loss)
I0701 14:08:24.370002  2788 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0701 14:08:31.182857  2788 solver.cpp:236] Iteration 5670, loss = 0.693453
I0701 14:08:31.182917  2788 solver.cpp:252]     Train net output #0: loss = 0.69404 (* 1 = 0.69404 loss)
I0701 14:08:31.182930  2788 sgd_solver.cpp:106] Iteration 5670, lr = 0.01
I0701 14:08:37.999269  2788 solver.cpp:236] Iteration 5680, loss = 0.69352
I0701 14:08:37.999325  2788 solver.cpp:252]     Train net output #0: loss = 0.693042 (* 1 = 0.693042 loss)
I0701 14:08:37.999339  2788 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0701 14:08:44.806102  2788 solver.cpp:236] Iteration 5690, loss = 0.693632
I0701 14:08:44.806164  2788 solver.cpp:252]     Train net output #0: loss = 0.694506 (* 1 = 0.694506 loss)
I0701 14:08:44.806183  2788 sgd_solver.cpp:106] Iteration 5690, lr = 0.01
I0701 14:08:51.614994  2788 solver.cpp:236] Iteration 5700, loss = 0.693576
I0701 14:08:51.615171  2788 solver.cpp:252]     Train net output #0: loss = 0.693055 (* 1 = 0.693055 loss)
I0701 14:08:51.615195  2788 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0701 14:08:58.419132  2788 solver.cpp:236] Iteration 5710, loss = 0.693538
I0701 14:08:58.419186  2788 solver.cpp:252]     Train net output #0: loss = 0.693062 (* 1 = 0.693062 loss)
I0701 14:08:58.419199  2788 sgd_solver.cpp:106] Iteration 5710, lr = 0.01
I0701 14:09:05.244057  2788 solver.cpp:236] Iteration 5720, loss = 0.693385
I0701 14:09:05.244104  2788 solver.cpp:252]     Train net output #0: loss = 0.693303 (* 1 = 0.693303 loss)
I0701 14:09:05.244122  2788 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0701 14:09:12.054733  2788 solver.cpp:236] Iteration 5730, loss = 0.693352
I0701 14:09:12.054792  2788 solver.cpp:252]     Train net output #0: loss = 0.693424 (* 1 = 0.693424 loss)
I0701 14:09:12.054807  2788 sgd_solver.cpp:106] Iteration 5730, lr = 0.01
I0701 14:09:18.857549  2788 solver.cpp:236] Iteration 5740, loss = 0.693276
I0701 14:09:18.857600  2788 solver.cpp:252]     Train net output #0: loss = 0.693145 (* 1 = 0.693145 loss)
I0701 14:09:18.857614  2788 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0701 14:09:24.999183  2788 solver.cpp:340] Iteration 5750, Testing net (#0)
I0701 14:09:36.643965  2788 solver.cpp:408]     Test net output #0: accuracy = 0.48625
I0701 14:09:36.644033  2788 solver.cpp:408]     Test net output #1: loss = 0.693273 (* 1 = 0.693273 loss)
I0701 14:09:36.820637  2788 solver.cpp:236] Iteration 5750, loss = 0.693288
I0701 14:09:36.820688  2788 solver.cpp:252]     Train net output #0: loss = 0.693356 (* 1 = 0.693356 loss)
I0701 14:09:36.820708  2788 sgd_solver.cpp:106] Iteration 5750, lr = 0.01
I0701 14:09:43.596024  2788 solver.cpp:236] Iteration 5760, loss = 0.693274
I0701 14:09:43.596072  2788 solver.cpp:252]     Train net output #0: loss = 0.69318 (* 1 = 0.69318 loss)
I0701 14:09:43.596089  2788 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0701 14:09:50.394316  2788 solver.cpp:236] Iteration 5770, loss = 0.693242
I0701 14:09:50.394381  2788 solver.cpp:252]     Train net output #0: loss = 0.692661 (* 1 = 0.692661 loss)
I0701 14:09:50.394400  2788 sgd_solver.cpp:106] Iteration 5770, lr = 0.01
I0701 14:09:57.194731  2788 solver.cpp:236] Iteration 5780, loss = 0.693208
I0701 14:09:57.194864  2788 solver.cpp:252]     Train net output #0: loss = 0.692294 (* 1 = 0.692294 loss)
I0701 14:09:57.194895  2788 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0701 14:10:03.982192  2788 solver.cpp:236] Iteration 5790, loss = 0.693105
I0701 14:10:03.982234  2788 solver.cpp:252]     Train net output #0: loss = 0.695843 (* 1 = 0.695843 loss)
I0701 14:10:03.982246  2788 sgd_solver.cpp:106] Iteration 5790, lr = 0.01
I0701 14:10:10.781911  2788 solver.cpp:236] Iteration 5800, loss = 0.69294
I0701 14:10:10.781967  2788 solver.cpp:252]     Train net output #0: loss = 0.688634 (* 1 = 0.688634 loss)
I0701 14:10:10.781982  2788 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0701 14:10:17.574410  2788 solver.cpp:236] Iteration 5810, loss = 0.69306
I0701 14:10:17.574481  2788 solver.cpp:252]     Train net output #0: loss = 0.693143 (* 1 = 0.693143 loss)
I0701 14:10:17.574501  2788 sgd_solver.cpp:106] Iteration 5810, lr = 0.01
I0701 14:10:24.374142  2788 solver.cpp:236] Iteration 5820, loss = 0.692976
I0701 14:10:24.374207  2788 solver.cpp:252]     Train net output #0: loss = 0.691838 (* 1 = 0.691838 loss)
I0701 14:10:24.374223  2788 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0701 14:10:31.176540  2788 solver.cpp:236] Iteration 5830, loss = 0.692783
I0701 14:10:31.176761  2788 solver.cpp:252]     Train net output #0: loss = 0.689773 (* 1 = 0.689773 loss)
I0701 14:10:31.176791  2788 sgd_solver.cpp:106] Iteration 5830, lr = 0.01
I0701 14:10:37.967227  2788 solver.cpp:236] Iteration 5840, loss = 0.692929
I0701 14:10:37.967275  2788 solver.cpp:252]     Train net output #0: loss = 0.692712 (* 1 = 0.692712 loss)
I0701 14:10:37.967293  2788 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0701 14:10:44.762833  2788 solver.cpp:236] Iteration 5850, loss = 0.693246
I0701 14:10:44.762887  2788 solver.cpp:252]     Train net output #0: loss = 0.695309 (* 1 = 0.695309 loss)
I0701 14:10:44.762902  2788 sgd_solver.cpp:106] Iteration 5850, lr = 0.01
I0701 14:10:51.548622  2788 solver.cpp:236] Iteration 5860, loss = 0.693015
I0701 14:10:51.548691  2788 solver.cpp:252]     Train net output #0: loss = 0.694763 (* 1 = 0.694763 loss)
I0701 14:10:51.548712  2788 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0701 14:10:58.347440  2788 solver.cpp:236] Iteration 5870, loss = 0.693128
I0701 14:10:58.347501  2788 solver.cpp:252]     Train net output #0: loss = 0.693447 (* 1 = 0.693447 loss)
I0701 14:10:58.347518  2788 sgd_solver.cpp:106] Iteration 5870, lr = 0.01
I0701 14:11:05.147806  2788 solver.cpp:236] Iteration 5880, loss = 0.693329
I0701 14:11:05.147910  2788 solver.cpp:252]     Train net output #0: loss = 0.693029 (* 1 = 0.693029 loss)
I0701 14:11:05.147943  2788 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0701 14:11:11.922349  2788 solver.cpp:236] Iteration 5890, loss = 0.693198
I0701 14:11:11.922405  2788 solver.cpp:252]     Train net output #0: loss = 0.691203 (* 1 = 0.691203 loss)
I0701 14:11:11.922420  2788 sgd_solver.cpp:106] Iteration 5890, lr = 0.01
I0701 14:11:18.723394  2788 solver.cpp:236] Iteration 5900, loss = 0.692909
I0701 14:11:18.723443  2788 solver.cpp:252]     Train net output #0: loss = 0.695251 (* 1 = 0.695251 loss)
I0701 14:11:18.723461  2788 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0701 14:11:25.514123  2788 solver.cpp:236] Iteration 5910, loss = 0.693162
I0701 14:11:25.514183  2788 solver.cpp:252]     Train net output #0: loss = 0.691141 (* 1 = 0.691141 loss)
I0701 14:11:25.514204  2788 sgd_solver.cpp:106] Iteration 5910, lr = 0.01
I0701 14:11:32.300863  2788 solver.cpp:236] Iteration 5920, loss = 0.693268
I0701 14:11:32.300911  2788 solver.cpp:252]     Train net output #0: loss = 0.694825 (* 1 = 0.694825 loss)
I0701 14:11:32.300926  2788 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0701 14:11:39.102038  2788 solver.cpp:236] Iteration 5930, loss = 0.69325
I0701 14:11:39.102154  2788 solver.cpp:252]     Train net output #0: loss = 0.692836 (* 1 = 0.692836 loss)
I0701 14:11:39.102169  2788 sgd_solver.cpp:106] Iteration 5930, lr = 0.01
I0701 14:11:45.882083  2788 solver.cpp:236] Iteration 5940, loss = 0.693375
I0701 14:11:45.882133  2788 solver.cpp:252]     Train net output #0: loss = 0.695089 (* 1 = 0.695089 loss)
I0701 14:11:45.882148  2788 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0701 14:11:52.689872  2788 solver.cpp:236] Iteration 5950, loss = 0.693404
I0701 14:11:52.689911  2788 solver.cpp:252]     Train net output #0: loss = 0.693548 (* 1 = 0.693548 loss)
I0701 14:11:52.689925  2788 sgd_solver.cpp:106] Iteration 5950, lr = 0.01
I0701 14:11:59.498611  2788 solver.cpp:236] Iteration 5960, loss = 0.693196
I0701 14:11:59.498667  2788 solver.cpp:252]     Train net output #0: loss = 0.69902 (* 1 = 0.69902 loss)
I0701 14:11:59.498693  2788 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0701 14:12:06.282199  2788 solver.cpp:236] Iteration 5970, loss = 0.693316
I0701 14:12:06.282249  2788 solver.cpp:252]     Train net output #0: loss = 0.696743 (* 1 = 0.696743 loss)
I0701 14:12:06.282268  2788 sgd_solver.cpp:106] Iteration 5970, lr = 0.01
I0701 14:12:13.080229  2788 solver.cpp:236] Iteration 5980, loss = 0.693199
I0701 14:12:13.080328  2788 solver.cpp:252]     Train net output #0: loss = 0.692767 (* 1 = 0.692767 loss)
I0701 14:12:13.080344  2788 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0701 14:12:19.887332  2788 solver.cpp:236] Iteration 5990, loss = 0.693489
I0701 14:12:19.887401  2788 solver.cpp:252]     Train net output #0: loss = 0.690325 (* 1 = 0.690325 loss)
I0701 14:12:19.887418  2788 sgd_solver.cpp:106] Iteration 5990, lr = 0.01
I0701 14:12:26.004839  2788 solver.cpp:340] Iteration 6000, Testing net (#0)
I0701 14:12:38.142005  2788 solver.cpp:408]     Test net output #0: accuracy = 0.484062
I0701 14:12:38.142056  2788 solver.cpp:408]     Test net output #1: loss = 0.69418 (* 1 = 0.69418 loss)
I0701 14:12:38.323539  2788 solver.cpp:236] Iteration 6000, loss = 0.693939
I0701 14:12:38.323583  2788 solver.cpp:252]     Train net output #0: loss = 0.692688 (* 1 = 0.692688 loss)
I0701 14:12:38.323598  2788 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0701 14:12:45.111744  2788 solver.cpp:236] Iteration 6010, loss = 0.693998
I0701 14:12:45.111937  2788 solver.cpp:252]     Train net output #0: loss = 0.692174 (* 1 = 0.692174 loss)
I0701 14:12:45.111975  2788 sgd_solver.cpp:106] Iteration 6010, lr = 0.01
I0701 14:12:51.910660  2788 solver.cpp:236] Iteration 6020, loss = 0.693626
I0701 14:12:51.910714  2788 solver.cpp:252]     Train net output #0: loss = 0.691597 (* 1 = 0.691597 loss)
I0701 14:12:51.910729  2788 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0701 14:12:58.703121  2788 solver.cpp:236] Iteration 6030, loss = 0.693979
I0701 14:12:58.703171  2788 solver.cpp:252]     Train net output #0: loss = 0.693044 (* 1 = 0.693044 loss)
I0701 14:12:58.703186  2788 sgd_solver.cpp:106] Iteration 6030, lr = 0.01
I0701 14:13:05.502223  2788 solver.cpp:236] Iteration 6040, loss = 0.693677
I0701 14:13:05.502277  2788 solver.cpp:252]     Train net output #0: loss = 0.693029 (* 1 = 0.693029 loss)
I0701 14:13:05.502291  2788 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0701 14:13:12.292104  2788 solver.cpp:236] Iteration 6050, loss = 0.693256
I0701 14:13:12.292150  2788 solver.cpp:252]     Train net output #0: loss = 0.694117 (* 1 = 0.694117 loss)
I0701 14:13:12.292163  2788 sgd_solver.cpp:106] Iteration 6050, lr = 0.01
I0701 14:13:19.099809  2788 solver.cpp:236] Iteration 6060, loss = 0.693236
I0701 14:13:19.099948  2788 solver.cpp:252]     Train net output #0: loss = 0.691588 (* 1 = 0.691588 loss)
I0701 14:13:19.099977  2788 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0701 14:13:25.903205  2788 solver.cpp:236] Iteration 6070, loss = 0.693406
I0701 14:13:25.903267  2788 solver.cpp:252]     Train net output #0: loss = 0.693288 (* 1 = 0.693288 loss)
I0701 14:13:25.903281  2788 sgd_solver.cpp:106] Iteration 6070, lr = 0.01
I0701 14:13:32.698747  2788 solver.cpp:236] Iteration 6080, loss = 0.693239
I0701 14:13:32.698791  2788 solver.cpp:252]     Train net output #0: loss = 0.693191 (* 1 = 0.693191 loss)
I0701 14:13:32.698806  2788 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0701 14:13:39.519132  2788 solver.cpp:236] Iteration 6090, loss = 0.693207
I0701 14:13:39.519186  2788 solver.cpp:252]     Train net output #0: loss = 0.692904 (* 1 = 0.692904 loss)
I0701 14:13:39.519201  2788 sgd_solver.cpp:106] Iteration 6090, lr = 0.01
I0701 14:13:46.334252  2788 solver.cpp:236] Iteration 6100, loss = 0.693262
I0701 14:13:46.334300  2788 solver.cpp:252]     Train net output #0: loss = 0.692986 (* 1 = 0.692986 loss)
I0701 14:13:46.334313  2788 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0701 14:13:53.128619  2788 solver.cpp:236] Iteration 6110, loss = 0.693166
I0701 14:13:53.128768  2788 solver.cpp:252]     Train net output #0: loss = 0.694034 (* 1 = 0.694034 loss)
I0701 14:13:53.128788  2788 sgd_solver.cpp:106] Iteration 6110, lr = 0.01
I0701 14:13:59.945051  2788 solver.cpp:236] Iteration 6120, loss = 0.693387
I0701 14:13:59.945106  2788 solver.cpp:252]     Train net output #0: loss = 0.692667 (* 1 = 0.692667 loss)
I0701 14:13:59.945122  2788 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0701 14:14:06.743552  2788 solver.cpp:236] Iteration 6130, loss = 0.693315
I0701 14:14:06.743607  2788 solver.cpp:252]     Train net output #0: loss = 0.693067 (* 1 = 0.693067 loss)
I0701 14:14:06.743619  2788 sgd_solver.cpp:106] Iteration 6130, lr = 0.01
I0701 14:14:13.564432  2788 solver.cpp:236] Iteration 6140, loss = 0.693303
I0701 14:14:13.564489  2788 solver.cpp:252]     Train net output #0: loss = 0.693048 (* 1 = 0.693048 loss)
I0701 14:14:13.564514  2788 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0701 14:14:20.381047  2788 solver.cpp:236] Iteration 6150, loss = 0.693226
I0701 14:14:20.381098  2788 solver.cpp:252]     Train net output #0: loss = 0.69444 (* 1 = 0.69444 loss)
I0701 14:14:20.381113  2788 sgd_solver.cpp:106] Iteration 6150, lr = 0.01
I0701 14:14:27.185293  2788 solver.cpp:236] Iteration 6160, loss = 0.693463
I0701 14:14:27.185477  2788 solver.cpp:252]     Train net output #0: loss = 0.698261 (* 1 = 0.698261 loss)
I0701 14:14:27.185504  2788 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0701 14:14:33.994513  2788 solver.cpp:236] Iteration 6170, loss = 0.693116
I0701 14:14:33.994562  2788 solver.cpp:252]     Train net output #0: loss = 0.69241 (* 1 = 0.69241 loss)
I0701 14:14:33.994576  2788 sgd_solver.cpp:106] Iteration 6170, lr = 0.01
I0701 14:14:40.796818  2788 solver.cpp:236] Iteration 6180, loss = 0.693231
I0701 14:14:40.796870  2788 solver.cpp:252]     Train net output #0: loss = 0.692686 (* 1 = 0.692686 loss)
I0701 14:14:40.796885  2788 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0701 14:14:47.619882  2788 solver.cpp:236] Iteration 6190, loss = 0.693154
I0701 14:14:47.619927  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 14:14:47.619940  2788 sgd_solver.cpp:106] Iteration 6190, lr = 0.01
I0701 14:14:54.430570  2788 solver.cpp:236] Iteration 6200, loss = 0.693337
I0701 14:14:54.430634  2788 solver.cpp:252]     Train net output #0: loss = 0.697117 (* 1 = 0.697117 loss)
I0701 14:14:54.430647  2788 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0701 14:15:01.235644  2788 solver.cpp:236] Iteration 6210, loss = 0.693066
I0701 14:15:01.235746  2788 solver.cpp:252]     Train net output #0: loss = 0.691282 (* 1 = 0.691282 loss)
I0701 14:15:01.235760  2788 sgd_solver.cpp:106] Iteration 6210, lr = 0.01
I0701 14:15:08.045960  2788 solver.cpp:236] Iteration 6220, loss = 0.693279
I0701 14:15:08.046003  2788 solver.cpp:252]     Train net output #0: loss = 0.693132 (* 1 = 0.693132 loss)
I0701 14:15:08.046017  2788 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0701 14:15:14.856569  2788 solver.cpp:236] Iteration 6230, loss = 0.693275
I0701 14:15:14.856621  2788 solver.cpp:252]     Train net output #0: loss = 0.693387 (* 1 = 0.693387 loss)
I0701 14:15:14.856637  2788 sgd_solver.cpp:106] Iteration 6230, lr = 0.01
I0701 14:15:21.665151  2788 solver.cpp:236] Iteration 6240, loss = 0.693495
I0701 14:15:21.665206  2788 solver.cpp:252]     Train net output #0: loss = 0.69321 (* 1 = 0.69321 loss)
I0701 14:15:21.665220  2788 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0701 14:15:27.775602  2788 solver.cpp:340] Iteration 6250, Testing net (#0)
I0701 14:15:38.603655  2788 solver.cpp:408]     Test net output #0: accuracy = 0.49625
I0701 14:15:38.603803  2788 solver.cpp:408]     Test net output #1: loss = 0.693325 (* 1 = 0.693325 loss)
I0701 14:15:38.779371  2788 solver.cpp:236] Iteration 6250, loss = 0.693401
I0701 14:15:38.779418  2788 solver.cpp:252]     Train net output #0: loss = 0.692029 (* 1 = 0.692029 loss)
I0701 14:15:38.779434  2788 sgd_solver.cpp:106] Iteration 6250, lr = 0.01
I0701 14:15:45.555351  2788 solver.cpp:236] Iteration 6260, loss = 0.693662
I0701 14:15:45.555399  2788 solver.cpp:252]     Train net output #0: loss = 0.691382 (* 1 = 0.691382 loss)
I0701 14:15:45.555413  2788 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0701 14:15:52.347298  2788 solver.cpp:236] Iteration 6270, loss = 0.69361
I0701 14:15:52.347352  2788 solver.cpp:252]     Train net output #0: loss = 0.69356 (* 1 = 0.69356 loss)
I0701 14:15:52.347365  2788 sgd_solver.cpp:106] Iteration 6270, lr = 0.01
I0701 14:15:59.150610  2788 solver.cpp:236] Iteration 6280, loss = 0.693536
I0701 14:15:59.150660  2788 solver.cpp:252]     Train net output #0: loss = 0.693406 (* 1 = 0.693406 loss)
I0701 14:15:59.150673  2788 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0701 14:16:05.919221  2788 solver.cpp:236] Iteration 6290, loss = 0.693414
I0701 14:16:05.919272  2788 solver.cpp:252]     Train net output #0: loss = 0.693341 (* 1 = 0.693341 loss)
I0701 14:16:05.919286  2788 sgd_solver.cpp:106] Iteration 6290, lr = 0.01
I0701 14:16:12.711961  2788 solver.cpp:236] Iteration 6300, loss = 0.693422
I0701 14:16:12.712119  2788 solver.cpp:252]     Train net output #0: loss = 0.693184 (* 1 = 0.693184 loss)
I0701 14:16:12.712136  2788 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0701 14:16:19.488831  2788 solver.cpp:236] Iteration 6310, loss = 0.693288
I0701 14:16:19.488876  2788 solver.cpp:252]     Train net output #0: loss = 0.693159 (* 1 = 0.693159 loss)
I0701 14:16:19.488886  2788 sgd_solver.cpp:106] Iteration 6310, lr = 0.01
I0701 14:16:26.269546  2788 solver.cpp:236] Iteration 6320, loss = 0.693127
I0701 14:16:26.269593  2788 solver.cpp:252]     Train net output #0: loss = 0.693319 (* 1 = 0.693319 loss)
I0701 14:16:26.269606  2788 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0701 14:16:33.068562  2788 solver.cpp:236] Iteration 6330, loss = 0.69325
I0701 14:16:33.068617  2788 solver.cpp:252]     Train net output #0: loss = 0.699511 (* 1 = 0.699511 loss)
I0701 14:16:33.068634  2788 sgd_solver.cpp:106] Iteration 6330, lr = 0.01
I0701 14:16:39.849159  2788 solver.cpp:236] Iteration 6340, loss = 0.693381
I0701 14:16:39.849215  2788 solver.cpp:252]     Train net output #0: loss = 0.692915 (* 1 = 0.692915 loss)
I0701 14:16:39.849230  2788 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0701 14:16:46.647985  2788 solver.cpp:236] Iteration 6350, loss = 0.69337
I0701 14:16:46.648114  2788 solver.cpp:252]     Train net output #0: loss = 0.693079 (* 1 = 0.693079 loss)
I0701 14:16:46.648138  2788 sgd_solver.cpp:106] Iteration 6350, lr = 0.01
I0701 14:16:53.420682  2788 solver.cpp:236] Iteration 6360, loss = 0.693402
I0701 14:16:53.420747  2788 solver.cpp:252]     Train net output #0: loss = 0.693395 (* 1 = 0.693395 loss)
I0701 14:16:53.420763  2788 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0701 14:17:00.213456  2788 solver.cpp:236] Iteration 6370, loss = 0.69354
I0701 14:17:00.213511  2788 solver.cpp:252]     Train net output #0: loss = 0.694835 (* 1 = 0.694835 loss)
I0701 14:17:00.213527  2788 sgd_solver.cpp:106] Iteration 6370, lr = 0.01
I0701 14:17:07.017654  2788 solver.cpp:236] Iteration 6380, loss = 0.693464
I0701 14:17:07.017709  2788 solver.cpp:252]     Train net output #0: loss = 0.693245 (* 1 = 0.693245 loss)
I0701 14:17:07.017721  2788 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0701 14:17:13.797941  2788 solver.cpp:236] Iteration 6390, loss = 0.693342
I0701 14:17:13.797991  2788 solver.cpp:252]     Train net output #0: loss = 0.693271 (* 1 = 0.693271 loss)
I0701 14:17:13.798007  2788 sgd_solver.cpp:106] Iteration 6390, lr = 0.01
I0701 14:17:20.599490  2788 solver.cpp:236] Iteration 6400, loss = 0.693392
I0701 14:17:20.599620  2788 solver.cpp:252]     Train net output #0: loss = 0.693027 (* 1 = 0.693027 loss)
I0701 14:17:20.599637  2788 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0701 14:17:27.379451  2788 solver.cpp:236] Iteration 6410, loss = 0.693326
I0701 14:17:27.379508  2788 solver.cpp:252]     Train net output #0: loss = 0.695208 (* 1 = 0.695208 loss)
I0701 14:17:27.379526  2788 sgd_solver.cpp:106] Iteration 6410, lr = 0.01
I0701 14:17:34.166604  2788 solver.cpp:236] Iteration 6420, loss = 0.693341
I0701 14:17:34.166654  2788 solver.cpp:252]     Train net output #0: loss = 0.694747 (* 1 = 0.694747 loss)
I0701 14:17:34.166668  2788 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0701 14:17:40.979789  2788 solver.cpp:236] Iteration 6430, loss = 0.693292
I0701 14:17:40.979835  2788 solver.cpp:252]     Train net output #0: loss = 0.692677 (* 1 = 0.692677 loss)
I0701 14:17:40.979852  2788 sgd_solver.cpp:106] Iteration 6430, lr = 0.01
I0701 14:17:47.754300  2788 solver.cpp:236] Iteration 6440, loss = 0.693244
I0701 14:17:47.754348  2788 solver.cpp:252]     Train net output #0: loss = 0.691924 (* 1 = 0.691924 loss)
I0701 14:17:47.754364  2788 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0701 14:17:54.552047  2788 solver.cpp:236] Iteration 6450, loss = 0.693331
I0701 14:17:54.552235  2788 solver.cpp:252]     Train net output #0: loss = 0.693278 (* 1 = 0.693278 loss)
I0701 14:17:54.552253  2788 sgd_solver.cpp:106] Iteration 6450, lr = 0.01
I0701 14:18:01.340490  2788 solver.cpp:236] Iteration 6460, loss = 0.693407
I0701 14:18:01.340545  2788 solver.cpp:252]     Train net output #0: loss = 0.694393 (* 1 = 0.694393 loss)
I0701 14:18:01.340559  2788 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0701 14:18:08.125766  2788 solver.cpp:236] Iteration 6470, loss = 0.693396
I0701 14:18:08.125810  2788 solver.cpp:252]     Train net output #0: loss = 0.695465 (* 1 = 0.695465 loss)
I0701 14:18:08.125828  2788 sgd_solver.cpp:106] Iteration 6470, lr = 0.01
I0701 14:18:14.935858  2788 solver.cpp:236] Iteration 6480, loss = 0.693406
I0701 14:18:14.935909  2788 solver.cpp:252]     Train net output #0: loss = 0.691818 (* 1 = 0.691818 loss)
I0701 14:18:14.935923  2788 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0701 14:18:21.713523  2788 solver.cpp:236] Iteration 6490, loss = 0.693491
I0701 14:18:21.713568  2788 solver.cpp:252]     Train net output #0: loss = 0.693526 (* 1 = 0.693526 loss)
I0701 14:18:21.713577  2788 sgd_solver.cpp:106] Iteration 6490, lr = 0.01
I0701 14:18:27.834112  2788 solver.cpp:340] Iteration 6500, Testing net (#0)
I0701 14:18:39.191014  2788 solver.cpp:408]     Test net output #0: accuracy = 0.51
I0701 14:18:39.191069  2788 solver.cpp:408]     Test net output #1: loss = 0.692996 (* 1 = 0.692996 loss)
I0701 14:18:39.366734  2788 solver.cpp:236] Iteration 6500, loss = 0.693388
I0701 14:18:39.366782  2788 solver.cpp:252]     Train net output #0: loss = 0.693515 (* 1 = 0.693515 loss)
I0701 14:18:39.366799  2788 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0701 14:18:46.163395  2788 solver.cpp:236] Iteration 6510, loss = 0.693363
I0701 14:18:46.163446  2788 solver.cpp:252]     Train net output #0: loss = 0.693784 (* 1 = 0.693784 loss)
I0701 14:18:46.163460  2788 sgd_solver.cpp:106] Iteration 6510, lr = 0.01
I0701 14:18:52.961256  2788 solver.cpp:236] Iteration 6520, loss = 0.693284
I0701 14:18:52.961304  2788 solver.cpp:252]     Train net output #0: loss = 0.691882 (* 1 = 0.691882 loss)
I0701 14:18:52.961319  2788 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0701 14:18:59.757755  2788 solver.cpp:236] Iteration 6530, loss = 0.693393
I0701 14:18:59.757879  2788 solver.cpp:252]     Train net output #0: loss = 0.694689 (* 1 = 0.694689 loss)
I0701 14:18:59.757894  2788 sgd_solver.cpp:106] Iteration 6530, lr = 0.01
I0701 14:19:06.562522  2788 solver.cpp:236] Iteration 6540, loss = 0.693316
I0701 14:19:06.562582  2788 solver.cpp:252]     Train net output #0: loss = 0.693151 (* 1 = 0.693151 loss)
I0701 14:19:06.562595  2788 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0701 14:19:13.349275  2788 solver.cpp:236] Iteration 6550, loss = 0.693293
I0701 14:19:13.349321  2788 solver.cpp:252]     Train net output #0: loss = 0.692769 (* 1 = 0.692769 loss)
I0701 14:19:13.349334  2788 sgd_solver.cpp:106] Iteration 6550, lr = 0.01
I0701 14:19:20.147299  2788 solver.cpp:236] Iteration 6560, loss = 0.693167
I0701 14:19:20.147354  2788 solver.cpp:252]     Train net output #0: loss = 0.689239 (* 1 = 0.689239 loss)
I0701 14:19:20.147369  2788 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0701 14:19:26.951131  2788 solver.cpp:236] Iteration 6570, loss = 0.693402
I0701 14:19:26.951189  2788 solver.cpp:252]     Train net output #0: loss = 0.692605 (* 1 = 0.692605 loss)
I0701 14:19:26.951202  2788 sgd_solver.cpp:106] Iteration 6570, lr = 0.01
I0701 14:19:33.748600  2788 solver.cpp:236] Iteration 6580, loss = 0.693114
I0701 14:19:33.748726  2788 solver.cpp:252]     Train net output #0: loss = 0.691845 (* 1 = 0.691845 loss)
I0701 14:19:33.748754  2788 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0701 14:19:40.531103  2788 solver.cpp:236] Iteration 6590, loss = 0.693274
I0701 14:19:40.531158  2788 solver.cpp:252]     Train net output #0: loss = 0.692683 (* 1 = 0.692683 loss)
I0701 14:19:40.531172  2788 sgd_solver.cpp:106] Iteration 6590, lr = 0.01
I0701 14:19:47.348765  2788 solver.cpp:236] Iteration 6600, loss = 0.693278
I0701 14:19:47.348819  2788 solver.cpp:252]     Train net output #0: loss = 0.692792 (* 1 = 0.692792 loss)
I0701 14:19:47.348831  2788 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0701 14:19:54.145565  2788 solver.cpp:236] Iteration 6610, loss = 0.69337
I0701 14:19:54.145623  2788 solver.cpp:252]     Train net output #0: loss = 0.692829 (* 1 = 0.692829 loss)
I0701 14:19:54.145637  2788 sgd_solver.cpp:106] Iteration 6610, lr = 0.01
I0701 14:20:00.949120  2788 solver.cpp:236] Iteration 6620, loss = 0.693066
I0701 14:20:00.949168  2788 solver.cpp:252]     Train net output #0: loss = 0.694543 (* 1 = 0.694543 loss)
I0701 14:20:00.949182  2788 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0701 14:20:07.756208  2788 solver.cpp:236] Iteration 6630, loss = 0.693117
I0701 14:20:07.756402  2788 solver.cpp:252]     Train net output #0: loss = 0.693158 (* 1 = 0.693158 loss)
I0701 14:20:07.756445  2788 sgd_solver.cpp:106] Iteration 6630, lr = 0.01
I0701 14:20:14.554488  2788 solver.cpp:236] Iteration 6640, loss = 0.692971
I0701 14:20:14.554538  2788 solver.cpp:252]     Train net output #0: loss = 0.697785 (* 1 = 0.697785 loss)
I0701 14:20:14.554553  2788 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0701 14:20:21.354039  2788 solver.cpp:236] Iteration 6650, loss = 0.693099
I0701 14:20:21.354094  2788 solver.cpp:252]     Train net output #0: loss = 0.693782 (* 1 = 0.693782 loss)
I0701 14:20:21.354110  2788 sgd_solver.cpp:106] Iteration 6650, lr = 0.01
I0701 14:20:28.167095  2788 solver.cpp:236] Iteration 6660, loss = 0.693104
I0701 14:20:28.167136  2788 solver.cpp:252]     Train net output #0: loss = 0.693135 (* 1 = 0.693135 loss)
I0701 14:20:28.167145  2788 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0701 14:20:34.954689  2788 solver.cpp:236] Iteration 6670, loss = 0.693208
I0701 14:20:34.954743  2788 solver.cpp:252]     Train net output #0: loss = 0.693456 (* 1 = 0.693456 loss)
I0701 14:20:34.954757  2788 sgd_solver.cpp:106] Iteration 6670, lr = 0.01
I0701 14:20:41.752550  2788 solver.cpp:236] Iteration 6680, loss = 0.693342
I0701 14:20:41.752676  2788 solver.cpp:252]     Train net output #0: loss = 0.692766 (* 1 = 0.692766 loss)
I0701 14:20:41.752702  2788 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0701 14:20:48.568019  2788 solver.cpp:236] Iteration 6690, loss = 0.693541
I0701 14:20:48.568070  2788 solver.cpp:252]     Train net output #0: loss = 0.694631 (* 1 = 0.694631 loss)
I0701 14:20:48.568083  2788 sgd_solver.cpp:106] Iteration 6690, lr = 0.01
I0701 14:20:55.364557  2788 solver.cpp:236] Iteration 6700, loss = 0.69349
I0701 14:20:55.364609  2788 solver.cpp:252]     Train net output #0: loss = 0.692712 (* 1 = 0.692712 loss)
I0701 14:20:55.364624  2788 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0701 14:21:02.171171  2788 solver.cpp:236] Iteration 6710, loss = 0.693502
I0701 14:21:02.171219  2788 solver.cpp:252]     Train net output #0: loss = 0.693855 (* 1 = 0.693855 loss)
I0701 14:21:02.171236  2788 sgd_solver.cpp:106] Iteration 6710, lr = 0.01
I0701 14:21:08.976052  2788 solver.cpp:236] Iteration 6720, loss = 0.693411
I0701 14:21:08.976106  2788 solver.cpp:252]     Train net output #0: loss = 0.693703 (* 1 = 0.693703 loss)
I0701 14:21:08.976120  2788 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0701 14:21:15.766877  2788 solver.cpp:236] Iteration 6730, loss = 0.693405
I0701 14:21:15.767074  2788 solver.cpp:252]     Train net output #0: loss = 0.693833 (* 1 = 0.693833 loss)
I0701 14:21:15.767107  2788 sgd_solver.cpp:106] Iteration 6730, lr = 0.01
I0701 14:21:22.580937  2788 solver.cpp:236] Iteration 6740, loss = 0.693235
I0701 14:21:22.580987  2788 solver.cpp:252]     Train net output #0: loss = 0.696398 (* 1 = 0.696398 loss)
I0701 14:21:22.581001  2788 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0701 14:21:28.699506  2788 solver.cpp:340] Iteration 6750, Testing net (#0)
I0701 14:21:40.711565  2788 solver.cpp:408]     Test net output #0: accuracy = 0.5025
I0701 14:21:40.711621  2788 solver.cpp:408]     Test net output #1: loss = 0.693137 (* 1 = 0.693137 loss)
I0701 14:21:40.891124  2788 solver.cpp:236] Iteration 6750, loss = 0.693179
I0701 14:21:40.891175  2788 solver.cpp:252]     Train net output #0: loss = 0.693401 (* 1 = 0.693401 loss)
I0701 14:21:40.891193  2788 sgd_solver.cpp:106] Iteration 6750, lr = 0.01
I0701 14:21:47.669679  2788 solver.cpp:236] Iteration 6760, loss = 0.693259
I0701 14:21:47.669867  2788 solver.cpp:252]     Train net output #0: loss = 0.691694 (* 1 = 0.691694 loss)
I0701 14:21:47.669888  2788 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0701 14:21:54.466526  2788 solver.cpp:236] Iteration 6770, loss = 0.693466
I0701 14:21:54.466572  2788 solver.cpp:252]     Train net output #0: loss = 0.693938 (* 1 = 0.693938 loss)
I0701 14:21:54.466588  2788 sgd_solver.cpp:106] Iteration 6770, lr = 0.01
I0701 14:22:01.233618  2788 solver.cpp:236] Iteration 6780, loss = 0.693469
I0701 14:22:01.233660  2788 solver.cpp:252]     Train net output #0: loss = 0.693226 (* 1 = 0.693226 loss)
I0701 14:22:01.233672  2788 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0701 14:22:08.033010  2788 solver.cpp:236] Iteration 6790, loss = 0.693482
I0701 14:22:08.033057  2788 solver.cpp:252]     Train net output #0: loss = 0.692707 (* 1 = 0.692707 loss)
I0701 14:22:08.033072  2788 sgd_solver.cpp:106] Iteration 6790, lr = 0.01
I0701 14:22:14.845329  2788 solver.cpp:236] Iteration 6800, loss = 0.693626
I0701 14:22:14.845373  2788 solver.cpp:252]     Train net output #0: loss = 0.696515 (* 1 = 0.696515 loss)
I0701 14:22:14.845386  2788 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0701 14:22:21.618424  2788 solver.cpp:236] Iteration 6810, loss = 0.693678
I0701 14:22:21.618577  2788 solver.cpp:252]     Train net output #0: loss = 0.692173 (* 1 = 0.692173 loss)
I0701 14:22:21.618624  2788 sgd_solver.cpp:106] Iteration 6810, lr = 0.01
I0701 14:22:28.429378  2788 solver.cpp:236] Iteration 6820, loss = 0.69351
I0701 14:22:28.429430  2788 solver.cpp:252]     Train net output #0: loss = 0.692274 (* 1 = 0.692274 loss)
I0701 14:22:28.429443  2788 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0701 14:22:35.231451  2788 solver.cpp:236] Iteration 6830, loss = 0.693514
I0701 14:22:35.231505  2788 solver.cpp:252]     Train net output #0: loss = 0.692612 (* 1 = 0.692612 loss)
I0701 14:22:35.231519  2788 sgd_solver.cpp:106] Iteration 6830, lr = 0.01
I0701 14:22:42.029455  2788 solver.cpp:236] Iteration 6840, loss = 0.693498
I0701 14:22:42.029510  2788 solver.cpp:252]     Train net output #0: loss = 0.693109 (* 1 = 0.693109 loss)
I0701 14:22:42.029523  2788 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0701 14:22:48.831346  2788 solver.cpp:236] Iteration 6850, loss = 0.693359
I0701 14:22:48.831394  2788 solver.cpp:252]     Train net output #0: loss = 0.693386 (* 1 = 0.693386 loss)
I0701 14:22:48.831409  2788 sgd_solver.cpp:106] Iteration 6850, lr = 0.01
I0701 14:22:55.631710  2788 solver.cpp:236] Iteration 6860, loss = 0.693216
I0701 14:22:55.631865  2788 solver.cpp:252]     Train net output #0: loss = 0.69296 (* 1 = 0.69296 loss)
I0701 14:22:55.631907  2788 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0701 14:23:02.441604  2788 solver.cpp:236] Iteration 6870, loss = 0.693328
I0701 14:23:02.441661  2788 solver.cpp:252]     Train net output #0: loss = 0.693553 (* 1 = 0.693553 loss)
I0701 14:23:02.441678  2788 sgd_solver.cpp:106] Iteration 6870, lr = 0.01
I0701 14:23:09.235450  2788 solver.cpp:236] Iteration 6880, loss = 0.693231
I0701 14:23:09.235498  2788 solver.cpp:252]     Train net output #0: loss = 0.694376 (* 1 = 0.694376 loss)
I0701 14:23:09.235512  2788 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0701 14:23:16.055645  2788 solver.cpp:236] Iteration 6890, loss = 0.693392
I0701 14:23:16.055699  2788 solver.cpp:252]     Train net output #0: loss = 0.697987 (* 1 = 0.697987 loss)
I0701 14:23:16.055712  2788 sgd_solver.cpp:106] Iteration 6890, lr = 0.01
I0701 14:23:22.863103  2788 solver.cpp:236] Iteration 6900, loss = 0.69344
I0701 14:23:22.863149  2788 solver.cpp:252]     Train net output #0: loss = 0.692921 (* 1 = 0.692921 loss)
I0701 14:23:22.863163  2788 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0701 14:23:29.676229  2788 solver.cpp:236] Iteration 6910, loss = 0.693531
I0701 14:23:29.680491  2788 solver.cpp:252]     Train net output #0: loss = 0.693057 (* 1 = 0.693057 loss)
I0701 14:23:29.680510  2788 sgd_solver.cpp:106] Iteration 6910, lr = 0.01
I0701 14:23:36.478996  2788 solver.cpp:236] Iteration 6920, loss = 0.693341
I0701 14:23:36.479048  2788 solver.cpp:252]     Train net output #0: loss = 0.688888 (* 1 = 0.688888 loss)
I0701 14:23:36.479063  2788 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0701 14:23:43.266562  2788 solver.cpp:236] Iteration 6930, loss = 0.693311
I0701 14:23:43.266610  2788 solver.cpp:252]     Train net output #0: loss = 0.690936 (* 1 = 0.690936 loss)
I0701 14:23:43.266623  2788 sgd_solver.cpp:106] Iteration 6930, lr = 0.01
I0701 14:23:50.073087  2788 solver.cpp:236] Iteration 6940, loss = 0.693367
I0701 14:23:50.073143  2788 solver.cpp:252]     Train net output #0: loss = 0.701643 (* 1 = 0.701643 loss)
I0701 14:23:50.073156  2788 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0701 14:23:56.872150  2788 solver.cpp:236] Iteration 6950, loss = 0.693195
I0701 14:23:56.872196  2788 solver.cpp:252]     Train net output #0: loss = 0.690989 (* 1 = 0.690989 loss)
I0701 14:23:56.872210  2788 sgd_solver.cpp:106] Iteration 6950, lr = 0.01
I0701 14:24:03.668833  2788 solver.cpp:236] Iteration 6960, loss = 0.693244
I0701 14:24:03.669040  2788 solver.cpp:252]     Train net output #0: loss = 0.69324 (* 1 = 0.69324 loss)
I0701 14:24:03.669059  2788 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0701 14:24:10.466609  2788 solver.cpp:236] Iteration 6970, loss = 0.693372
I0701 14:24:10.466656  2788 solver.cpp:252]     Train net output #0: loss = 0.693798 (* 1 = 0.693798 loss)
I0701 14:24:10.466670  2788 sgd_solver.cpp:106] Iteration 6970, lr = 0.01
I0701 14:24:17.276105  2788 solver.cpp:236] Iteration 6980, loss = 0.693469
I0701 14:24:17.276154  2788 solver.cpp:252]     Train net output #0: loss = 0.692148 (* 1 = 0.692148 loss)
I0701 14:24:17.276167  2788 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0701 14:24:24.061693  2788 solver.cpp:236] Iteration 6990, loss = 0.693414
I0701 14:24:24.061739  2788 solver.cpp:252]     Train net output #0: loss = 0.695681 (* 1 = 0.695681 loss)
I0701 14:24:24.061755  2788 sgd_solver.cpp:106] Iteration 6990, lr = 0.01
I0701 14:24:30.179136  2788 solver.cpp:340] Iteration 7000, Testing net (#0)
I0701 14:24:41.927825  2788 solver.cpp:408]     Test net output #0: accuracy = 0.502187
I0701 14:24:41.928108  2788 solver.cpp:408]     Test net output #1: loss = 0.69324 (* 1 = 0.69324 loss)
I0701 14:24:42.106243  2788 solver.cpp:236] Iteration 7000, loss = 0.693622
I0701 14:24:42.106292  2788 solver.cpp:252]     Train net output #0: loss = 0.692153 (* 1 = 0.692153 loss)
I0701 14:24:42.106308  2788 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0701 14:24:48.892920  2788 solver.cpp:236] Iteration 7010, loss = 0.693535
I0701 14:24:48.892982  2788 solver.cpp:252]     Train net output #0: loss = 0.693343 (* 1 = 0.693343 loss)
I0701 14:24:48.892995  2788 sgd_solver.cpp:106] Iteration 7010, lr = 0.01
I0701 14:24:55.700059  2788 solver.cpp:236] Iteration 7020, loss = 0.693569
I0701 14:24:55.700104  2788 solver.cpp:252]     Train net output #0: loss = 0.695348 (* 1 = 0.695348 loss)
I0701 14:24:55.700119  2788 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0701 14:25:02.491559  2788 solver.cpp:236] Iteration 7030, loss = 0.693633
I0701 14:25:02.491606  2788 solver.cpp:252]     Train net output #0: loss = 0.692899 (* 1 = 0.692899 loss)
I0701 14:25:02.491621  2788 sgd_solver.cpp:106] Iteration 7030, lr = 0.01
I0701 14:25:09.290710  2788 solver.cpp:236] Iteration 7040, loss = 0.693365
I0701 14:25:09.290760  2788 solver.cpp:252]     Train net output #0: loss = 0.692391 (* 1 = 0.692391 loss)
I0701 14:25:09.290774  2788 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0701 14:25:16.103762  2788 solver.cpp:236] Iteration 7050, loss = 0.693481
I0701 14:25:16.103963  2788 solver.cpp:252]     Train net output #0: loss = 0.692677 (* 1 = 0.692677 loss)
I0701 14:25:16.103979  2788 sgd_solver.cpp:106] Iteration 7050, lr = 0.01
I0701 14:25:22.907974  2788 solver.cpp:236] Iteration 7060, loss = 0.693252
I0701 14:25:22.908015  2788 solver.cpp:252]     Train net output #0: loss = 0.691594 (* 1 = 0.691594 loss)
I0701 14:25:22.908028  2788 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0701 14:25:29.709928  2788 solver.cpp:236] Iteration 7070, loss = 0.692908
I0701 14:25:29.709993  2788 solver.cpp:252]     Train net output #0: loss = 0.689982 (* 1 = 0.689982 loss)
I0701 14:25:29.710013  2788 sgd_solver.cpp:106] Iteration 7070, lr = 0.01
I0701 14:25:36.526217  2788 solver.cpp:236] Iteration 7080, loss = 0.693378
I0701 14:25:36.526291  2788 solver.cpp:252]     Train net output #0: loss = 0.698382 (* 1 = 0.698382 loss)
I0701 14:25:36.526312  2788 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0701 14:25:43.327821  2788 solver.cpp:236] Iteration 7090, loss = 0.693431
I0701 14:25:43.327884  2788 solver.cpp:252]     Train net output #0: loss = 0.692694 (* 1 = 0.692694 loss)
I0701 14:25:43.327904  2788 sgd_solver.cpp:106] Iteration 7090, lr = 0.01
I0701 14:25:50.134150  2788 solver.cpp:236] Iteration 7100, loss = 0.693099
I0701 14:25:50.140489  2788 solver.cpp:252]     Train net output #0: loss = 0.692068 (* 1 = 0.692068 loss)
I0701 14:25:50.140511  2788 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0701 14:25:56.951761  2788 solver.cpp:236] Iteration 7110, loss = 0.692655
I0701 14:25:56.951822  2788 solver.cpp:252]     Train net output #0: loss = 0.686706 (* 1 = 0.686706 loss)
I0701 14:25:56.951840  2788 sgd_solver.cpp:106] Iteration 7110, lr = 0.01
I0701 14:26:03.754314  2788 solver.cpp:236] Iteration 7120, loss = 0.692815
I0701 14:26:03.754364  2788 solver.cpp:252]     Train net output #0: loss = 0.700453 (* 1 = 0.700453 loss)
I0701 14:26:03.754376  2788 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0701 14:26:10.566566  2788 solver.cpp:236] Iteration 7130, loss = 0.692872
I0701 14:26:10.566614  2788 solver.cpp:252]     Train net output #0: loss = 0.692053 (* 1 = 0.692053 loss)
I0701 14:26:10.566628  2788 sgd_solver.cpp:106] Iteration 7130, lr = 0.01
I0701 14:26:17.371469  2788 solver.cpp:236] Iteration 7140, loss = 0.692842
I0701 14:26:17.371525  2788 solver.cpp:252]     Train net output #0: loss = 0.696246 (* 1 = 0.696246 loss)
I0701 14:26:17.371541  2788 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0701 14:26:24.180663  2788 solver.cpp:236] Iteration 7150, loss = 0.692961
I0701 14:26:24.180891  2788 solver.cpp:252]     Train net output #0: loss = 0.693927 (* 1 = 0.693927 loss)
I0701 14:26:24.180908  2788 sgd_solver.cpp:106] Iteration 7150, lr = 0.01
I0701 14:26:30.996316  2788 solver.cpp:236] Iteration 7160, loss = 0.693613
I0701 14:26:30.996362  2788 solver.cpp:252]     Train net output #0: loss = 0.692632 (* 1 = 0.692632 loss)
I0701 14:26:30.996376  2788 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0701 14:26:37.803114  2788 solver.cpp:236] Iteration 7170, loss = 0.693809
I0701 14:26:37.803171  2788 solver.cpp:252]     Train net output #0: loss = 0.692893 (* 1 = 0.692893 loss)
I0701 14:26:37.803184  2788 sgd_solver.cpp:106] Iteration 7170, lr = 0.01
I0701 14:26:44.612398  2788 solver.cpp:236] Iteration 7180, loss = 0.693271
I0701 14:26:44.612471  2788 solver.cpp:252]     Train net output #0: loss = 0.695643 (* 1 = 0.695643 loss)
I0701 14:26:44.612486  2788 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0701 14:26:51.431792  2788 solver.cpp:236] Iteration 7190, loss = 0.693438
I0701 14:26:51.431846  2788 solver.cpp:252]     Train net output #0: loss = 0.69333 (* 1 = 0.69333 loss)
I0701 14:26:51.431861  2788 sgd_solver.cpp:106] Iteration 7190, lr = 0.01
I0701 14:26:58.247860  2788 solver.cpp:236] Iteration 7200, loss = 0.693383
I0701 14:26:58.248077  2788 solver.cpp:252]     Train net output #0: loss = 0.693706 (* 1 = 0.693706 loss)
I0701 14:26:58.248092  2788 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0701 14:27:05.051214  2788 solver.cpp:236] Iteration 7210, loss = 0.69333
I0701 14:27:05.051262  2788 solver.cpp:252]     Train net output #0: loss = 0.694132 (* 1 = 0.694132 loss)
I0701 14:27:05.051276  2788 sgd_solver.cpp:106] Iteration 7210, lr = 0.01
I0701 14:27:11.854974  2788 solver.cpp:236] Iteration 7220, loss = 0.693082
I0701 14:27:11.855026  2788 solver.cpp:252]     Train net output #0: loss = 0.692063 (* 1 = 0.692063 loss)
I0701 14:27:11.855039  2788 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0701 14:27:18.675782  2788 solver.cpp:236] Iteration 7230, loss = 0.693349
I0701 14:27:18.675858  2788 solver.cpp:252]     Train net output #0: loss = 0.69357 (* 1 = 0.69357 loss)
I0701 14:27:18.675876  2788 sgd_solver.cpp:106] Iteration 7230, lr = 0.01
I0701 14:27:25.480816  2788 solver.cpp:236] Iteration 7240, loss = 0.693295
I0701 14:27:25.480868  2788 solver.cpp:252]     Train net output #0: loss = 0.691815 (* 1 = 0.691815 loss)
I0701 14:27:25.480885  2788 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0701 14:27:31.604949  2788 solver.cpp:340] Iteration 7250, Testing net (#0)
I0701 14:27:34.014001  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 14:27:43.203873  2788 solver.cpp:408]     Test net output #0: accuracy = 0.491875
I0701 14:27:43.203930  2788 solver.cpp:408]     Test net output #1: loss = 0.693848 (* 1 = 0.693848 loss)
I0701 14:27:43.380704  2788 solver.cpp:236] Iteration 7250, loss = 0.693482
I0701 14:27:43.380758  2788 solver.cpp:252]     Train net output #0: loss = 0.698439 (* 1 = 0.698439 loss)
I0701 14:27:43.380771  2788 sgd_solver.cpp:106] Iteration 7250, lr = 0.01
I0701 14:27:50.177979  2788 solver.cpp:236] Iteration 7260, loss = 0.69349
I0701 14:27:50.178026  2788 solver.cpp:252]     Train net output #0: loss = 0.693725 (* 1 = 0.693725 loss)
I0701 14:27:50.178040  2788 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0701 14:27:56.963910  2788 solver.cpp:236] Iteration 7270, loss = 0.693694
I0701 14:27:56.963963  2788 solver.cpp:252]     Train net output #0: loss = 0.696414 (* 1 = 0.696414 loss)
I0701 14:27:56.963978  2788 sgd_solver.cpp:106] Iteration 7270, lr = 0.01
I0701 14:28:03.748498  2788 solver.cpp:236] Iteration 7280, loss = 0.693372
I0701 14:28:03.748672  2788 solver.cpp:252]     Train net output #0: loss = 0.693596 (* 1 = 0.693596 loss)
I0701 14:28:03.748687  2788 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0701 14:28:10.544592  2788 solver.cpp:236] Iteration 7290, loss = 0.693317
I0701 14:28:10.544637  2788 solver.cpp:252]     Train net output #0: loss = 0.693386 (* 1 = 0.693386 loss)
I0701 14:28:10.544651  2788 sgd_solver.cpp:106] Iteration 7290, lr = 0.01
I0701 14:28:17.329680  2788 solver.cpp:236] Iteration 7300, loss = 0.693125
I0701 14:28:17.329738  2788 solver.cpp:252]     Train net output #0: loss = 0.692289 (* 1 = 0.692289 loss)
I0701 14:28:17.329752  2788 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0701 14:28:24.127111  2788 solver.cpp:236] Iteration 7310, loss = 0.69321
I0701 14:28:24.127169  2788 solver.cpp:252]     Train net output #0: loss = 0.692185 (* 1 = 0.692185 loss)
I0701 14:28:24.127183  2788 sgd_solver.cpp:106] Iteration 7310, lr = 0.01
I0701 14:28:30.911854  2788 solver.cpp:236] Iteration 7320, loss = 0.693213
I0701 14:28:30.911907  2788 solver.cpp:252]     Train net output #0: loss = 0.693189 (* 1 = 0.693189 loss)
I0701 14:28:30.911921  2788 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0701 14:28:37.719429  2788 solver.cpp:236] Iteration 7330, loss = 0.693237
I0701 14:28:37.719740  2788 solver.cpp:252]     Train net output #0: loss = 0.693005 (* 1 = 0.693005 loss)
I0701 14:28:37.719758  2788 sgd_solver.cpp:106] Iteration 7330, lr = 0.01
I0701 14:28:44.525454  2788 solver.cpp:236] Iteration 7340, loss = 0.693244
I0701 14:28:44.525509  2788 solver.cpp:252]     Train net output #0: loss = 0.694724 (* 1 = 0.694724 loss)
I0701 14:28:44.525524  2788 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0701 14:28:51.340538  2788 solver.cpp:236] Iteration 7350, loss = 0.693165
I0701 14:28:51.340601  2788 solver.cpp:252]     Train net output #0: loss = 0.695114 (* 1 = 0.695114 loss)
I0701 14:28:51.340617  2788 sgd_solver.cpp:106] Iteration 7350, lr = 0.01
I0701 14:28:58.156914  2788 solver.cpp:236] Iteration 7360, loss = 0.693356
I0701 14:28:58.156966  2788 solver.cpp:252]     Train net output #0: loss = 0.693625 (* 1 = 0.693625 loss)
I0701 14:28:58.156980  2788 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0701 14:29:04.943984  2788 solver.cpp:236] Iteration 7370, loss = 0.693347
I0701 14:29:04.944025  2788 solver.cpp:252]     Train net output #0: loss = 0.693351 (* 1 = 0.693351 loss)
I0701 14:29:04.944038  2788 sgd_solver.cpp:106] Iteration 7370, lr = 0.01
I0701 14:29:11.757627  2788 solver.cpp:236] Iteration 7380, loss = 0.693418
I0701 14:29:11.757812  2788 solver.cpp:252]     Train net output #0: loss = 0.693691 (* 1 = 0.693691 loss)
I0701 14:29:11.757828  2788 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0701 14:29:18.566489  2788 solver.cpp:236] Iteration 7390, loss = 0.693506
I0701 14:29:18.566550  2788 solver.cpp:252]     Train net output #0: loss = 0.693543 (* 1 = 0.693543 loss)
I0701 14:29:18.566565  2788 sgd_solver.cpp:106] Iteration 7390, lr = 0.01
I0701 14:29:25.369823  2788 solver.cpp:236] Iteration 7400, loss = 0.69359
I0701 14:29:25.369871  2788 solver.cpp:252]     Train net output #0: loss = 0.695474 (* 1 = 0.695474 loss)
I0701 14:29:25.369884  2788 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0701 14:29:32.173558  2788 solver.cpp:236] Iteration 7410, loss = 0.693532
I0701 14:29:32.173617  2788 solver.cpp:252]     Train net output #0: loss = 0.692827 (* 1 = 0.692827 loss)
I0701 14:29:32.173631  2788 sgd_solver.cpp:106] Iteration 7410, lr = 0.01
I0701 14:29:38.993271  2788 solver.cpp:236] Iteration 7420, loss = 0.693588
I0701 14:29:38.993324  2788 solver.cpp:252]     Train net output #0: loss = 0.692883 (* 1 = 0.692883 loss)
I0701 14:29:38.993337  2788 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0701 14:29:45.806550  2788 solver.cpp:236] Iteration 7430, loss = 0.693205
I0701 14:29:45.806752  2788 solver.cpp:252]     Train net output #0: loss = 0.691195 (* 1 = 0.691195 loss)
I0701 14:29:45.806772  2788 sgd_solver.cpp:106] Iteration 7430, lr = 0.01
I0701 14:29:52.620384  2788 solver.cpp:236] Iteration 7440, loss = 0.693407
I0701 14:29:52.620479  2788 solver.cpp:252]     Train net output #0: loss = 0.695484 (* 1 = 0.695484 loss)
I0701 14:29:52.620497  2788 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0701 14:29:59.425899  2788 solver.cpp:236] Iteration 7450, loss = 0.693679
I0701 14:29:59.425976  2788 solver.cpp:252]     Train net output #0: loss = 0.693168 (* 1 = 0.693168 loss)
I0701 14:29:59.425998  2788 sgd_solver.cpp:106] Iteration 7450, lr = 0.01
I0701 14:30:06.258430  2788 solver.cpp:236] Iteration 7460, loss = 0.693572
I0701 14:30:06.258496  2788 solver.cpp:252]     Train net output #0: loss = 0.692771 (* 1 = 0.692771 loss)
I0701 14:30:06.258514  2788 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0701 14:30:13.072505  2788 solver.cpp:236] Iteration 7470, loss = 0.693468
I0701 14:30:13.072569  2788 solver.cpp:252]     Train net output #0: loss = 0.692002 (* 1 = 0.692002 loss)
I0701 14:30:13.072584  2788 sgd_solver.cpp:106] Iteration 7470, lr = 0.01
I0701 14:30:19.887671  2788 solver.cpp:236] Iteration 7480, loss = 0.69374
I0701 14:30:19.887827  2788 solver.cpp:252]     Train net output #0: loss = 0.693531 (* 1 = 0.693531 loss)
I0701 14:30:19.887843  2788 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0701 14:30:26.703300  2788 solver.cpp:236] Iteration 7490, loss = 0.693629
I0701 14:30:26.703346  2788 solver.cpp:252]     Train net output #0: loss = 0.69398 (* 1 = 0.69398 loss)
I0701 14:30:26.703359  2788 sgd_solver.cpp:106] Iteration 7490, lr = 0.01
I0701 14:30:32.835005  2788 solver.cpp:340] Iteration 7500, Testing net (#0)
I0701 14:30:44.438956  2788 solver.cpp:408]     Test net output #0: accuracy = 0.501875
I0701 14:30:44.439013  2788 solver.cpp:408]     Test net output #1: loss = 0.693154 (* 1 = 0.693154 loss)
I0701 14:30:44.619024  2788 solver.cpp:236] Iteration 7500, loss = 0.693398
I0701 14:30:44.619069  2788 solver.cpp:252]     Train net output #0: loss = 0.691916 (* 1 = 0.691916 loss)
I0701 14:30:44.619083  2788 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0701 14:30:51.413538  2788 solver.cpp:236] Iteration 7510, loss = 0.693352
I0701 14:30:51.413807  2788 solver.cpp:252]     Train net output #0: loss = 0.693167 (* 1 = 0.693167 loss)
I0701 14:30:51.413828  2788 sgd_solver.cpp:106] Iteration 7510, lr = 0.01
I0701 14:30:58.217087  2788 solver.cpp:236] Iteration 7520, loss = 0.693434
I0701 14:30:58.217150  2788 solver.cpp:252]     Train net output #0: loss = 0.694434 (* 1 = 0.694434 loss)
I0701 14:30:58.217165  2788 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0701 14:31:05.006791  2788 solver.cpp:236] Iteration 7530, loss = 0.693435
I0701 14:31:05.006861  2788 solver.cpp:252]     Train net output #0: loss = 0.691863 (* 1 = 0.691863 loss)
I0701 14:31:05.006876  2788 sgd_solver.cpp:106] Iteration 7530, lr = 0.01
I0701 14:31:11.821126  2788 solver.cpp:236] Iteration 7540, loss = 0.693274
I0701 14:31:11.821182  2788 solver.cpp:252]     Train net output #0: loss = 0.693416 (* 1 = 0.693416 loss)
I0701 14:31:11.821197  2788 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0701 14:31:18.634948  2788 solver.cpp:236] Iteration 7550, loss = 0.693226
I0701 14:31:18.635009  2788 solver.cpp:252]     Train net output #0: loss = 0.692485 (* 1 = 0.692485 loss)
I0701 14:31:18.635023  2788 sgd_solver.cpp:106] Iteration 7550, lr = 0.01
I0701 14:31:25.448765  2788 solver.cpp:236] Iteration 7560, loss = 0.693153
I0701 14:31:25.448993  2788 solver.cpp:252]     Train net output #0: loss = 0.697197 (* 1 = 0.697197 loss)
I0701 14:31:25.449012  2788 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0701 14:31:32.266055  2788 solver.cpp:236] Iteration 7570, loss = 0.693401
I0701 14:31:32.266113  2788 solver.cpp:252]     Train net output #0: loss = 0.694047 (* 1 = 0.694047 loss)
I0701 14:31:32.266127  2788 sgd_solver.cpp:106] Iteration 7570, lr = 0.01
I0701 14:31:39.068145  2788 solver.cpp:236] Iteration 7580, loss = 0.69347
I0701 14:31:39.068214  2788 solver.cpp:252]     Train net output #0: loss = 0.692313 (* 1 = 0.692313 loss)
I0701 14:31:39.068230  2788 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0701 14:31:45.897816  2788 solver.cpp:236] Iteration 7590, loss = 0.693698
I0701 14:31:45.897881  2788 solver.cpp:252]     Train net output #0: loss = 0.699456 (* 1 = 0.699456 loss)
I0701 14:31:45.897897  2788 sgd_solver.cpp:106] Iteration 7590, lr = 0.01
I0701 14:31:52.714979  2788 solver.cpp:236] Iteration 7600, loss = 0.693891
I0701 14:31:52.715050  2788 solver.cpp:252]     Train net output #0: loss = 0.693742 (* 1 = 0.693742 loss)
I0701 14:31:52.715073  2788 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0701 14:31:59.522589  2788 solver.cpp:236] Iteration 7610, loss = 0.693866
I0701 14:31:59.522815  2788 solver.cpp:252]     Train net output #0: loss = 0.69151 (* 1 = 0.69151 loss)
I0701 14:31:59.522838  2788 sgd_solver.cpp:106] Iteration 7610, lr = 0.01
I0701 14:32:06.334123  2788 solver.cpp:236] Iteration 7620, loss = 0.693562
I0701 14:32:06.334204  2788 solver.cpp:252]     Train net output #0: loss = 0.701321 (* 1 = 0.701321 loss)
I0701 14:32:06.334224  2788 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0701 14:32:13.140771  2788 solver.cpp:236] Iteration 7630, loss = 0.693561
I0701 14:32:13.140867  2788 solver.cpp:252]     Train net output #0: loss = 0.69513 (* 1 = 0.69513 loss)
I0701 14:32:13.140885  2788 sgd_solver.cpp:106] Iteration 7630, lr = 0.01
I0701 14:32:19.951692  2788 solver.cpp:236] Iteration 7640, loss = 0.693316
I0701 14:32:19.951756  2788 solver.cpp:252]     Train net output #0: loss = 0.69211 (* 1 = 0.69211 loss)
I0701 14:32:19.951771  2788 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0701 14:32:26.761077  2788 solver.cpp:236] Iteration 7650, loss = 0.693252
I0701 14:32:26.761135  2788 solver.cpp:252]     Train net output #0: loss = 0.693119 (* 1 = 0.693119 loss)
I0701 14:32:26.761149  2788 sgd_solver.cpp:106] Iteration 7650, lr = 0.01
I0701 14:32:33.580909  2788 solver.cpp:236] Iteration 7660, loss = 0.693349
I0701 14:32:33.581051  2788 solver.cpp:252]     Train net output #0: loss = 0.6954 (* 1 = 0.6954 loss)
I0701 14:32:33.581068  2788 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0701 14:32:40.400338  2788 solver.cpp:236] Iteration 7670, loss = 0.693448
I0701 14:32:40.400399  2788 solver.cpp:252]     Train net output #0: loss = 0.693461 (* 1 = 0.693461 loss)
I0701 14:32:40.400414  2788 sgd_solver.cpp:106] Iteration 7670, lr = 0.01
I0701 14:32:47.207625  2788 solver.cpp:236] Iteration 7680, loss = 0.69334
I0701 14:32:47.207686  2788 solver.cpp:252]     Train net output #0: loss = 0.694149 (* 1 = 0.694149 loss)
I0701 14:32:47.207700  2788 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0701 14:32:54.015745  2788 solver.cpp:236] Iteration 7690, loss = 0.693712
I0701 14:32:54.015811  2788 solver.cpp:252]     Train net output #0: loss = 0.699237 (* 1 = 0.699237 loss)
I0701 14:32:54.015825  2788 sgd_solver.cpp:106] Iteration 7690, lr = 0.01
I0701 14:33:00.828418  2788 solver.cpp:236] Iteration 7700, loss = 0.693484
I0701 14:33:00.828486  2788 solver.cpp:252]     Train net output #0: loss = 0.692518 (* 1 = 0.692518 loss)
I0701 14:33:00.828500  2788 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0701 14:33:07.643314  2788 solver.cpp:236] Iteration 7710, loss = 0.693529
I0701 14:33:07.643599  2788 solver.cpp:252]     Train net output #0: loss = 0.693337 (* 1 = 0.693337 loss)
I0701 14:33:07.643616  2788 sgd_solver.cpp:106] Iteration 7710, lr = 0.01
I0701 14:33:14.455440  2788 solver.cpp:236] Iteration 7720, loss = 0.693478
I0701 14:33:14.455489  2788 solver.cpp:252]     Train net output #0: loss = 0.694593 (* 1 = 0.694593 loss)
I0701 14:33:14.455503  2788 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0701 14:33:21.245010  2788 solver.cpp:236] Iteration 7730, loss = 0.693526
I0701 14:33:21.245075  2788 solver.cpp:252]     Train net output #0: loss = 0.693805 (* 1 = 0.693805 loss)
I0701 14:33:21.245090  2788 sgd_solver.cpp:106] Iteration 7730, lr = 0.01
I0701 14:33:28.049729  2788 solver.cpp:236] Iteration 7740, loss = 0.693164
I0701 14:33:28.049794  2788 solver.cpp:252]     Train net output #0: loss = 0.693193 (* 1 = 0.693193 loss)
I0701 14:33:28.049809  2788 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0701 14:33:34.191540  2788 solver.cpp:340] Iteration 7750, Testing net (#0)
I0701 14:33:45.862726  2788 solver.cpp:408]     Test net output #0: accuracy = 0.525937
I0701 14:33:45.862912  2788 solver.cpp:408]     Test net output #1: loss = 0.692858 (* 1 = 0.692858 loss)
I0701 14:33:46.042240  2788 solver.cpp:236] Iteration 7750, loss = 0.693306
I0701 14:33:46.042309  2788 solver.cpp:252]     Train net output #0: loss = 0.693165 (* 1 = 0.693165 loss)
I0701 14:33:46.042327  2788 sgd_solver.cpp:106] Iteration 7750, lr = 0.01
I0701 14:33:52.826557  2788 solver.cpp:236] Iteration 7760, loss = 0.693238
I0701 14:33:52.826613  2788 solver.cpp:252]     Train net output #0: loss = 0.693518 (* 1 = 0.693518 loss)
I0701 14:33:52.826627  2788 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0701 14:33:59.584974  2788 solver.cpp:236] Iteration 7770, loss = 0.69319
I0701 14:33:59.585036  2788 solver.cpp:252]     Train net output #0: loss = 0.692464 (* 1 = 0.692464 loss)
I0701 14:33:59.585049  2788 sgd_solver.cpp:106] Iteration 7770, lr = 0.01
I0701 14:34:06.378938  2788 solver.cpp:236] Iteration 7780, loss = 0.693201
I0701 14:34:06.378999  2788 solver.cpp:252]     Train net output #0: loss = 0.692081 (* 1 = 0.692081 loss)
I0701 14:34:06.379014  2788 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0701 14:34:13.167800  2788 solver.cpp:236] Iteration 7790, loss = 0.693264
I0701 14:34:13.167879  2788 solver.cpp:252]     Train net output #0: loss = 0.693621 (* 1 = 0.693621 loss)
I0701 14:34:13.167902  2788 sgd_solver.cpp:106] Iteration 7790, lr = 0.01
I0701 14:34:19.957615  2788 solver.cpp:236] Iteration 7800, loss = 0.693259
I0701 14:34:19.957795  2788 solver.cpp:252]     Train net output #0: loss = 0.693937 (* 1 = 0.693937 loss)
I0701 14:34:19.957818  2788 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0701 14:34:26.764922  2788 solver.cpp:236] Iteration 7810, loss = 0.693365
I0701 14:34:26.764967  2788 solver.cpp:252]     Train net output #0: loss = 0.694466 (* 1 = 0.694466 loss)
I0701 14:34:26.764981  2788 sgd_solver.cpp:106] Iteration 7810, lr = 0.01
I0701 14:34:33.546564  2788 solver.cpp:236] Iteration 7820, loss = 0.693355
I0701 14:34:33.546613  2788 solver.cpp:252]     Train net output #0: loss = 0.692938 (* 1 = 0.692938 loss)
I0701 14:34:33.546627  2788 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0701 14:34:40.324905  2788 solver.cpp:236] Iteration 7830, loss = 0.69317
I0701 14:34:40.324954  2788 solver.cpp:252]     Train net output #0: loss = 0.690011 (* 1 = 0.690011 loss)
I0701 14:34:40.324968  2788 sgd_solver.cpp:106] Iteration 7830, lr = 0.01
I0701 14:34:47.100158  2788 solver.cpp:236] Iteration 7840, loss = 0.693029
I0701 14:34:47.100210  2788 solver.cpp:252]     Train net output #0: loss = 0.692062 (* 1 = 0.692062 loss)
I0701 14:34:47.100224  2788 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0701 14:34:53.883447  2788 solver.cpp:236] Iteration 7850, loss = 0.693263
I0701 14:34:53.883625  2788 solver.cpp:252]     Train net output #0: loss = 0.693853 (* 1 = 0.693853 loss)
I0701 14:34:53.883651  2788 sgd_solver.cpp:106] Iteration 7850, lr = 0.01
I0701 14:35:00.688522  2788 solver.cpp:236] Iteration 7860, loss = 0.693271
I0701 14:35:00.688577  2788 solver.cpp:252]     Train net output #0: loss = 0.693527 (* 1 = 0.693527 loss)
I0701 14:35:00.688593  2788 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0701 14:35:07.469336  2788 solver.cpp:236] Iteration 7870, loss = 0.693209
I0701 14:35:07.469384  2788 solver.cpp:252]     Train net output #0: loss = 0.689801 (* 1 = 0.689801 loss)
I0701 14:35:07.469399  2788 sgd_solver.cpp:106] Iteration 7870, lr = 0.01
I0701 14:35:14.269758  2788 solver.cpp:236] Iteration 7880, loss = 0.693526
I0701 14:35:14.269806  2788 solver.cpp:252]     Train net output #0: loss = 0.697416 (* 1 = 0.697416 loss)
I0701 14:35:14.269820  2788 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0701 14:35:21.055882  2788 solver.cpp:236] Iteration 7890, loss = 0.693764
I0701 14:35:21.055945  2788 solver.cpp:252]     Train net output #0: loss = 0.693275 (* 1 = 0.693275 loss)
I0701 14:35:21.055959  2788 sgd_solver.cpp:106] Iteration 7890, lr = 0.01
I0701 14:35:27.834079  2788 solver.cpp:236] Iteration 7900, loss = 0.693492
I0701 14:35:27.834223  2788 solver.cpp:252]     Train net output #0: loss = 0.691562 (* 1 = 0.691562 loss)
I0701 14:35:27.834249  2788 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0701 14:35:34.647817  2788 solver.cpp:236] Iteration 7910, loss = 0.693453
I0701 14:35:34.647876  2788 solver.cpp:252]     Train net output #0: loss = 0.694861 (* 1 = 0.694861 loss)
I0701 14:35:34.647891  2788 sgd_solver.cpp:106] Iteration 7910, lr = 0.01
I0701 14:35:41.451318  2788 solver.cpp:236] Iteration 7920, loss = 0.693684
I0701 14:35:41.451382  2788 solver.cpp:252]     Train net output #0: loss = 0.692097 (* 1 = 0.692097 loss)
I0701 14:35:41.451396  2788 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0701 14:35:48.251965  2788 solver.cpp:236] Iteration 7930, loss = 0.693492
I0701 14:35:48.252012  2788 solver.cpp:252]     Train net output #0: loss = 0.692749 (* 1 = 0.692749 loss)
I0701 14:35:48.252022  2788 sgd_solver.cpp:106] Iteration 7930, lr = 0.01
I0701 14:35:55.056463  2788 solver.cpp:236] Iteration 7940, loss = 0.693422
I0701 14:35:55.056526  2788 solver.cpp:252]     Train net output #0: loss = 0.695028 (* 1 = 0.695028 loss)
I0701 14:35:55.056540  2788 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0701 14:36:01.858093  2788 solver.cpp:236] Iteration 7950, loss = 0.693611
I0701 14:36:01.858284  2788 solver.cpp:252]     Train net output #0: loss = 0.693774 (* 1 = 0.693774 loss)
I0701 14:36:01.858310  2788 sgd_solver.cpp:106] Iteration 7950, lr = 0.01
I0701 14:36:08.661803  2788 solver.cpp:236] Iteration 7960, loss = 0.6935
I0701 14:36:08.661864  2788 solver.cpp:252]     Train net output #0: loss = 0.692141 (* 1 = 0.692141 loss)
I0701 14:36:08.661880  2788 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0701 14:36:15.458063  2788 solver.cpp:236] Iteration 7970, loss = 0.693475
I0701 14:36:15.458127  2788 solver.cpp:252]     Train net output #0: loss = 0.694488 (* 1 = 0.694488 loss)
I0701 14:36:15.458140  2788 sgd_solver.cpp:106] Iteration 7970, lr = 0.01
I0701 14:36:22.278349  2788 solver.cpp:236] Iteration 7980, loss = 0.693628
I0701 14:36:22.278417  2788 solver.cpp:252]     Train net output #0: loss = 0.694476 (* 1 = 0.694476 loss)
I0701 14:36:22.278434  2788 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0701 14:36:29.066558  2788 solver.cpp:236] Iteration 7990, loss = 0.693477
I0701 14:36:29.066613  2788 solver.cpp:252]     Train net output #0: loss = 0.691838 (* 1 = 0.691838 loss)
I0701 14:36:29.066627  2788 sgd_solver.cpp:106] Iteration 7990, lr = 0.01
I0701 14:36:35.188148  2788 solver.cpp:340] Iteration 8000, Testing net (#0)
I0701 14:36:46.449373  2788 solver.cpp:408]     Test net output #0: accuracy = 0.508125
I0701 14:36:46.449434  2788 solver.cpp:408]     Test net output #1: loss = 0.693411 (* 1 = 0.693411 loss)
I0701 14:36:46.617844  2788 solver.cpp:236] Iteration 8000, loss = 0.693298
I0701 14:36:46.617902  2788 solver.cpp:252]     Train net output #0: loss = 0.694827 (* 1 = 0.694827 loss)
I0701 14:36:46.617915  2788 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0701 14:36:53.416203  2788 solver.cpp:236] Iteration 8010, loss = 0.693385
I0701 14:36:53.416272  2788 solver.cpp:252]     Train net output #0: loss = 0.697605 (* 1 = 0.697605 loss)
I0701 14:36:53.416286  2788 sgd_solver.cpp:106] Iteration 8010, lr = 0.01
I0701 14:37:00.216795  2788 solver.cpp:236] Iteration 8020, loss = 0.693342
I0701 14:37:00.216856  2788 solver.cpp:252]     Train net output #0: loss = 0.692607 (* 1 = 0.692607 loss)
I0701 14:37:00.216871  2788 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0701 14:37:07.000660  2788 solver.cpp:236] Iteration 8030, loss = 0.693216
I0701 14:37:07.000777  2788 solver.cpp:252]     Train net output #0: loss = 0.693268 (* 1 = 0.693268 loss)
I0701 14:37:07.000790  2788 sgd_solver.cpp:106] Iteration 8030, lr = 0.01
I0701 14:37:13.810051  2788 solver.cpp:236] Iteration 8040, loss = 0.693269
I0701 14:37:13.810132  2788 solver.cpp:252]     Train net output #0: loss = 0.695433 (* 1 = 0.695433 loss)
I0701 14:37:13.810145  2788 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0701 14:37:20.610954  2788 solver.cpp:236] Iteration 8050, loss = 0.693356
I0701 14:37:20.611019  2788 solver.cpp:252]     Train net output #0: loss = 0.697293 (* 1 = 0.697293 loss)
I0701 14:37:20.611033  2788 sgd_solver.cpp:106] Iteration 8050, lr = 0.01
I0701 14:37:27.401928  2788 solver.cpp:236] Iteration 8060, loss = 0.693353
I0701 14:37:27.401986  2788 solver.cpp:252]     Train net output #0: loss = 0.693694 (* 1 = 0.693694 loss)
I0701 14:37:27.402000  2788 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0701 14:37:34.215658  2788 solver.cpp:236] Iteration 8070, loss = 0.69337
I0701 14:37:34.215718  2788 solver.cpp:252]     Train net output #0: loss = 0.692907 (* 1 = 0.692907 loss)
I0701 14:37:34.215733  2788 sgd_solver.cpp:106] Iteration 8070, lr = 0.01
I0701 14:37:41.015887  2788 solver.cpp:236] Iteration 8080, loss = 0.693403
I0701 14:37:41.016054  2788 solver.cpp:252]     Train net output #0: loss = 0.693235 (* 1 = 0.693235 loss)
I0701 14:37:41.016085  2788 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0701 14:37:47.828014  2788 solver.cpp:236] Iteration 8090, loss = 0.693396
I0701 14:37:47.828074  2788 solver.cpp:252]     Train net output #0: loss = 0.693079 (* 1 = 0.693079 loss)
I0701 14:37:47.828088  2788 sgd_solver.cpp:106] Iteration 8090, lr = 0.01
I0701 14:37:54.632670  2788 solver.cpp:236] Iteration 8100, loss = 0.693414
I0701 14:37:54.632735  2788 solver.cpp:252]     Train net output #0: loss = 0.695801 (* 1 = 0.695801 loss)
I0701 14:37:54.632750  2788 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0701 14:38:01.437409  2788 solver.cpp:236] Iteration 8110, loss = 0.693341
I0701 14:38:01.437469  2788 solver.cpp:252]     Train net output #0: loss = 0.694408 (* 1 = 0.694408 loss)
I0701 14:38:01.437482  2788 sgd_solver.cpp:106] Iteration 8110, lr = 0.01
I0701 14:38:08.243016  2788 solver.cpp:236] Iteration 8120, loss = 0.693231
I0701 14:38:08.243086  2788 solver.cpp:252]     Train net output #0: loss = 0.693402 (* 1 = 0.693402 loss)
I0701 14:38:08.243103  2788 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0701 14:38:15.034433  2788 solver.cpp:236] Iteration 8130, loss = 0.693226
I0701 14:38:15.034692  2788 solver.cpp:252]     Train net output #0: loss = 0.694126 (* 1 = 0.694126 loss)
I0701 14:38:15.034724  2788 sgd_solver.cpp:106] Iteration 8130, lr = 0.01
I0701 14:38:21.848949  2788 solver.cpp:236] Iteration 8140, loss = 0.693131
I0701 14:38:21.849020  2788 solver.cpp:252]     Train net output #0: loss = 0.690582 (* 1 = 0.690582 loss)
I0701 14:38:21.849035  2788 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0701 14:38:28.642238  2788 solver.cpp:236] Iteration 8150, loss = 0.693194
I0701 14:38:28.642300  2788 solver.cpp:252]     Train net output #0: loss = 0.695004 (* 1 = 0.695004 loss)
I0701 14:38:28.642313  2788 sgd_solver.cpp:106] Iteration 8150, lr = 0.01
I0701 14:38:35.443086  2788 solver.cpp:236] Iteration 8160, loss = 0.693146
I0701 14:38:35.443137  2788 solver.cpp:252]     Train net output #0: loss = 0.691239 (* 1 = 0.691239 loss)
I0701 14:38:35.443152  2788 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0701 14:38:42.264271  2788 solver.cpp:236] Iteration 8170, loss = 0.693132
I0701 14:38:42.264333  2788 solver.cpp:252]     Train net output #0: loss = 0.695495 (* 1 = 0.695495 loss)
I0701 14:38:42.264345  2788 sgd_solver.cpp:106] Iteration 8170, lr = 0.01
I0701 14:38:49.062021  2788 solver.cpp:236] Iteration 8180, loss = 0.693408
I0701 14:38:49.062170  2788 solver.cpp:252]     Train net output #0: loss = 0.69408 (* 1 = 0.69408 loss)
I0701 14:38:49.062198  2788 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0701 14:38:55.881274  2788 solver.cpp:236] Iteration 8190, loss = 0.693481
I0701 14:38:55.881319  2788 solver.cpp:252]     Train net output #0: loss = 0.694755 (* 1 = 0.694755 loss)
I0701 14:38:55.881333  2788 sgd_solver.cpp:106] Iteration 8190, lr = 0.01
I0701 14:39:02.678648  2788 solver.cpp:236] Iteration 8200, loss = 0.693524
I0701 14:39:02.678697  2788 solver.cpp:252]     Train net output #0: loss = 0.696453 (* 1 = 0.696453 loss)
I0701 14:39:02.678710  2788 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0701 14:39:09.487932  2788 solver.cpp:236] Iteration 8210, loss = 0.693757
I0701 14:39:09.487990  2788 solver.cpp:252]     Train net output #0: loss = 0.692556 (* 1 = 0.692556 loss)
I0701 14:39:09.488011  2788 sgd_solver.cpp:106] Iteration 8210, lr = 0.01
I0701 14:39:16.293490  2788 solver.cpp:236] Iteration 8220, loss = 0.693843
I0701 14:39:16.293540  2788 solver.cpp:252]     Train net output #0: loss = 0.69463 (* 1 = 0.69463 loss)
I0701 14:39:16.293555  2788 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0701 14:39:23.091684  2788 solver.cpp:236] Iteration 8230, loss = 0.693549
I0701 14:39:23.091840  2788 solver.cpp:252]     Train net output #0: loss = 0.692273 (* 1 = 0.692273 loss)
I0701 14:39:23.091856  2788 sgd_solver.cpp:106] Iteration 8230, lr = 0.01
I0701 14:39:29.903437  2788 solver.cpp:236] Iteration 8240, loss = 0.693503
I0701 14:39:29.903481  2788 solver.cpp:252]     Train net output #0: loss = 0.69267 (* 1 = 0.69267 loss)
I0701 14:39:29.903496  2788 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0701 14:39:36.010912  2788 solver.cpp:340] Iteration 8250, Testing net (#0)
I0701 14:39:47.826761  2788 solver.cpp:408]     Test net output #0: accuracy = 0.491562
I0701 14:39:47.826808  2788 solver.cpp:408]     Test net output #1: loss = 0.693594 (* 1 = 0.693594 loss)
I0701 14:39:48.001358  2788 solver.cpp:236] Iteration 8250, loss = 0.693396
I0701 14:39:48.001408  2788 solver.cpp:252]     Train net output #0: loss = 0.694936 (* 1 = 0.694936 loss)
I0701 14:39:48.001422  2788 sgd_solver.cpp:106] Iteration 8250, lr = 0.01
I0701 14:39:54.789882  2788 solver.cpp:236] Iteration 8260, loss = 0.69333
I0701 14:39:54.790088  2788 solver.cpp:252]     Train net output #0: loss = 0.693457 (* 1 = 0.693457 loss)
I0701 14:39:54.790103  2788 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0701 14:40:01.585083  2788 solver.cpp:236] Iteration 8270, loss = 0.693343
I0701 14:40:01.585136  2788 solver.cpp:252]     Train net output #0: loss = 0.692884 (* 1 = 0.692884 loss)
I0701 14:40:01.585156  2788 sgd_solver.cpp:106] Iteration 8270, lr = 0.01
I0701 14:40:08.387624  2788 solver.cpp:236] Iteration 8280, loss = 0.693347
I0701 14:40:08.387677  2788 solver.cpp:252]     Train net output #0: loss = 0.692917 (* 1 = 0.692917 loss)
I0701 14:40:08.387697  2788 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0701 14:40:15.176368  2788 solver.cpp:236] Iteration 8290, loss = 0.693257
I0701 14:40:15.176419  2788 solver.cpp:252]     Train net output #0: loss = 0.689537 (* 1 = 0.689537 loss)
I0701 14:40:15.176460  2788 sgd_solver.cpp:106] Iteration 8290, lr = 0.01
I0701 14:40:21.975364  2788 solver.cpp:236] Iteration 8300, loss = 0.693394
I0701 14:40:21.975427  2788 solver.cpp:252]     Train net output #0: loss = 0.69266 (* 1 = 0.69266 loss)
I0701 14:40:21.975446  2788 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0701 14:40:28.774019  2788 solver.cpp:236] Iteration 8310, loss = 0.69329
I0701 14:40:28.774293  2788 solver.cpp:252]     Train net output #0: loss = 0.693557 (* 1 = 0.693557 loss)
I0701 14:40:28.774313  2788 sgd_solver.cpp:106] Iteration 8310, lr = 0.01
I0701 14:40:35.570085  2788 solver.cpp:236] Iteration 8320, loss = 0.693255
I0701 14:40:35.570142  2788 solver.cpp:252]     Train net output #0: loss = 0.693177 (* 1 = 0.693177 loss)
I0701 14:40:35.570160  2788 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0701 14:40:42.353992  2788 solver.cpp:236] Iteration 8330, loss = 0.693274
I0701 14:40:42.354044  2788 solver.cpp:252]     Train net output #0: loss = 0.693991 (* 1 = 0.693991 loss)
I0701 14:40:42.354058  2788 sgd_solver.cpp:106] Iteration 8330, lr = 0.01
I0701 14:40:49.157500  2788 solver.cpp:236] Iteration 8340, loss = 0.693468
I0701 14:40:49.157565  2788 solver.cpp:252]     Train net output #0: loss = 0.693931 (* 1 = 0.693931 loss)
I0701 14:40:49.157582  2788 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0701 14:40:55.974704  2788 solver.cpp:236] Iteration 8350, loss = 0.693194
I0701 14:40:55.974761  2788 solver.cpp:252]     Train net output #0: loss = 0.695069 (* 1 = 0.695069 loss)
I0701 14:40:55.974776  2788 sgd_solver.cpp:106] Iteration 8350, lr = 0.01
I0701 14:41:02.764869  2788 solver.cpp:236] Iteration 8360, loss = 0.693145
I0701 14:41:02.765064  2788 solver.cpp:252]     Train net output #0: loss = 0.691017 (* 1 = 0.691017 loss)
I0701 14:41:02.765084  2788 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0701 14:41:09.578815  2788 solver.cpp:236] Iteration 8370, loss = 0.69301
I0701 14:41:09.578881  2788 solver.cpp:252]     Train net output #0: loss = 0.688383 (* 1 = 0.688383 loss)
I0701 14:41:09.578896  2788 sgd_solver.cpp:106] Iteration 8370, lr = 0.01
I0701 14:41:16.386852  2788 solver.cpp:236] Iteration 8380, loss = 0.693194
I0701 14:41:16.386903  2788 solver.cpp:252]     Train net output #0: loss = 0.693341 (* 1 = 0.693341 loss)
I0701 14:41:16.386917  2788 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0701 14:41:23.192114  2788 solver.cpp:236] Iteration 8390, loss = 0.693004
I0701 14:41:23.192157  2788 solver.cpp:252]     Train net output #0: loss = 0.692076 (* 1 = 0.692076 loss)
I0701 14:41:23.192172  2788 sgd_solver.cpp:106] Iteration 8390, lr = 0.01
I0701 14:41:30.023155  2788 solver.cpp:236] Iteration 8400, loss = 0.693111
I0701 14:41:30.023211  2788 solver.cpp:252]     Train net output #0: loss = 0.693248 (* 1 = 0.693248 loss)
I0701 14:41:30.023226  2788 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0701 14:41:36.816736  2788 solver.cpp:236] Iteration 8410, loss = 0.693197
I0701 14:41:36.817001  2788 solver.cpp:252]     Train net output #0: loss = 0.693059 (* 1 = 0.693059 loss)
I0701 14:41:36.817020  2788 sgd_solver.cpp:106] Iteration 8410, lr = 0.01
I0701 14:41:43.626404  2788 solver.cpp:236] Iteration 8420, loss = 0.693332
I0701 14:41:43.626467  2788 solver.cpp:252]     Train net output #0: loss = 0.69358 (* 1 = 0.69358 loss)
I0701 14:41:43.626487  2788 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0701 14:41:50.456912  2788 solver.cpp:236] Iteration 8430, loss = 0.693189
I0701 14:41:50.456979  2788 solver.cpp:252]     Train net output #0: loss = 0.694345 (* 1 = 0.694345 loss)
I0701 14:41:50.456998  2788 sgd_solver.cpp:106] Iteration 8430, lr = 0.01
I0701 14:41:57.287430  2788 solver.cpp:236] Iteration 8440, loss = 0.693368
I0701 14:41:57.287499  2788 solver.cpp:252]     Train net output #0: loss = 0.694157 (* 1 = 0.694157 loss)
I0701 14:41:57.287519  2788 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0701 14:42:04.110098  2788 solver.cpp:236] Iteration 8450, loss = 0.693356
I0701 14:42:04.110165  2788 solver.cpp:252]     Train net output #0: loss = 0.694036 (* 1 = 0.694036 loss)
I0701 14:42:04.110186  2788 sgd_solver.cpp:106] Iteration 8450, lr = 0.01
I0701 14:42:10.921253  2788 solver.cpp:236] Iteration 8460, loss = 0.693278
I0701 14:42:10.921447  2788 solver.cpp:252]     Train net output #0: loss = 0.6928 (* 1 = 0.6928 loss)
I0701 14:42:10.921461  2788 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0701 14:42:17.736747  2788 solver.cpp:236] Iteration 8470, loss = 0.693274
I0701 14:42:17.736807  2788 solver.cpp:252]     Train net output #0: loss = 0.693385 (* 1 = 0.693385 loss)
I0701 14:42:17.736821  2788 sgd_solver.cpp:106] Iteration 8470, lr = 0.01
I0701 14:42:24.549242  2788 solver.cpp:236] Iteration 8480, loss = 0.693255
I0701 14:42:24.549300  2788 solver.cpp:252]     Train net output #0: loss = 0.694745 (* 1 = 0.694745 loss)
I0701 14:42:24.549315  2788 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0701 14:42:31.373219  2788 solver.cpp:236] Iteration 8490, loss = 0.69327
I0701 14:42:31.373280  2788 solver.cpp:252]     Train net output #0: loss = 0.693159 (* 1 = 0.693159 loss)
I0701 14:42:31.373294  2788 sgd_solver.cpp:106] Iteration 8490, lr = 0.01
I0701 14:42:37.515705  2788 solver.cpp:340] Iteration 8500, Testing net (#0)
I0701 14:42:49.316144  2788 solver.cpp:408]     Test net output #0: accuracy = 0.504375
I0701 14:42:49.316323  2788 solver.cpp:408]     Test net output #1: loss = 0.693119 (* 1 = 0.693119 loss)
I0701 14:42:49.492887  2788 solver.cpp:236] Iteration 8500, loss = 0.693238
I0701 14:42:49.492936  2788 solver.cpp:252]     Train net output #0: loss = 0.693224 (* 1 = 0.693224 loss)
I0701 14:42:49.492956  2788 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0701 14:42:56.274138  2788 solver.cpp:236] Iteration 8510, loss = 0.693318
I0701 14:42:56.274214  2788 solver.cpp:252]     Train net output #0: loss = 0.693646 (* 1 = 0.693646 loss)
I0701 14:42:56.274230  2788 sgd_solver.cpp:106] Iteration 8510, lr = 0.01
I0701 14:43:03.087882  2788 solver.cpp:236] Iteration 8520, loss = 0.693312
I0701 14:43:03.087939  2788 solver.cpp:252]     Train net output #0: loss = 0.693399 (* 1 = 0.693399 loss)
I0701 14:43:03.087959  2788 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0701 14:43:09.875499  2788 solver.cpp:236] Iteration 8530, loss = 0.693263
I0701 14:43:09.875552  2788 solver.cpp:252]     Train net output #0: loss = 0.693063 (* 1 = 0.693063 loss)
I0701 14:43:09.875576  2788 sgd_solver.cpp:106] Iteration 8530, lr = 0.01
I0701 14:43:16.669308  2788 solver.cpp:236] Iteration 8540, loss = 0.693277
I0701 14:43:16.669353  2788 solver.cpp:252]     Train net output #0: loss = 0.69369 (* 1 = 0.69369 loss)
I0701 14:43:16.669371  2788 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0701 14:43:23.455534  2788 solver.cpp:236] Iteration 8550, loss = 0.693245
I0701 14:43:23.455755  2788 solver.cpp:252]     Train net output #0: loss = 0.692418 (* 1 = 0.692418 loss)
I0701 14:43:23.455780  2788 sgd_solver.cpp:106] Iteration 8550, lr = 0.01
I0701 14:43:30.254727  2788 solver.cpp:236] Iteration 8560, loss = 0.693136
I0701 14:43:30.254789  2788 solver.cpp:252]     Train net output #0: loss = 0.693374 (* 1 = 0.693374 loss)
I0701 14:43:30.254804  2788 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0701 14:43:37.062450  2788 solver.cpp:236] Iteration 8570, loss = 0.693366
I0701 14:43:37.062505  2788 solver.cpp:252]     Train net output #0: loss = 0.6932 (* 1 = 0.6932 loss)
I0701 14:43:37.062520  2788 sgd_solver.cpp:106] Iteration 8570, lr = 0.01
I0701 14:43:43.869470  2788 solver.cpp:236] Iteration 8580, loss = 0.693427
I0701 14:43:43.869523  2788 solver.cpp:252]     Train net output #0: loss = 0.694116 (* 1 = 0.694116 loss)
I0701 14:43:43.869536  2788 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0701 14:43:50.654032  2788 solver.cpp:236] Iteration 8590, loss = 0.693462
I0701 14:43:50.654096  2788 solver.cpp:252]     Train net output #0: loss = 0.693179 (* 1 = 0.693179 loss)
I0701 14:43:50.654111  2788 sgd_solver.cpp:106] Iteration 8590, lr = 0.01
I0701 14:43:57.449815  2788 solver.cpp:236] Iteration 8600, loss = 0.693563
I0701 14:43:57.456485  2788 solver.cpp:252]     Train net output #0: loss = 0.694311 (* 1 = 0.694311 loss)
I0701 14:43:57.456501  2788 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0701 14:44:04.262915  2788 solver.cpp:236] Iteration 8610, loss = 0.693635
I0701 14:44:04.262981  2788 solver.cpp:252]     Train net output #0: loss = 0.693687 (* 1 = 0.693687 loss)
I0701 14:44:04.262996  2788 sgd_solver.cpp:106] Iteration 8610, lr = 0.01
I0701 14:44:11.079948  2788 solver.cpp:236] Iteration 8620, loss = 0.693309
I0701 14:44:11.080009  2788 solver.cpp:252]     Train net output #0: loss = 0.695644 (* 1 = 0.695644 loss)
I0701 14:44:11.080024  2788 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0701 14:44:17.896232  2788 solver.cpp:236] Iteration 8630, loss = 0.693077
I0701 14:44:17.896286  2788 solver.cpp:252]     Train net output #0: loss = 0.685981 (* 1 = 0.685981 loss)
I0701 14:44:17.896299  2788 sgd_solver.cpp:106] Iteration 8630, lr = 0.01
I0701 14:44:24.705715  2788 solver.cpp:236] Iteration 8640, loss = 0.693172
I0701 14:44:24.705775  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 14:44:24.705790  2788 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0701 14:44:31.523583  2788 solver.cpp:236] Iteration 8650, loss = 0.693013
I0701 14:44:31.523777  2788 solver.cpp:252]     Train net output #0: loss = 0.693421 (* 1 = 0.693421 loss)
I0701 14:44:31.523795  2788 sgd_solver.cpp:106] Iteration 8650, lr = 0.01
I0701 14:44:38.337524  2788 solver.cpp:236] Iteration 8660, loss = 0.693084
I0701 14:44:38.337584  2788 solver.cpp:252]     Train net output #0: loss = 0.693075 (* 1 = 0.693075 loss)
I0701 14:44:38.337599  2788 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0701 14:44:45.144922  2788 solver.cpp:236] Iteration 8670, loss = 0.693169
I0701 14:44:45.144982  2788 solver.cpp:252]     Train net output #0: loss = 0.693301 (* 1 = 0.693301 loss)
I0701 14:44:45.144997  2788 sgd_solver.cpp:106] Iteration 8670, lr = 0.01
I0701 14:44:51.967527  2788 solver.cpp:236] Iteration 8680, loss = 0.693357
I0701 14:44:51.967573  2788 solver.cpp:252]     Train net output #0: loss = 0.693301 (* 1 = 0.693301 loss)
I0701 14:44:51.967588  2788 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0701 14:44:58.780711  2788 solver.cpp:236] Iteration 8690, loss = 0.693153
I0701 14:44:58.780771  2788 solver.cpp:252]     Train net output #0: loss = 0.6903 (* 1 = 0.6903 loss)
I0701 14:44:58.780784  2788 sgd_solver.cpp:106] Iteration 8690, lr = 0.01
I0701 14:45:05.583118  2788 solver.cpp:236] Iteration 8700, loss = 0.693325
I0701 14:45:05.583256  2788 solver.cpp:252]     Train net output #0: loss = 0.693914 (* 1 = 0.693914 loss)
I0701 14:45:05.583276  2788 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0701 14:45:12.388506  2788 solver.cpp:236] Iteration 8710, loss = 0.69324
I0701 14:45:12.388558  2788 solver.cpp:252]     Train net output #0: loss = 0.693032 (* 1 = 0.693032 loss)
I0701 14:45:12.388573  2788 sgd_solver.cpp:106] Iteration 8710, lr = 0.01
I0701 14:45:19.203214  2788 solver.cpp:236] Iteration 8720, loss = 0.693214
I0701 14:45:19.203274  2788 solver.cpp:252]     Train net output #0: loss = 0.691786 (* 1 = 0.691786 loss)
I0701 14:45:19.203289  2788 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0701 14:45:26.016342  2788 solver.cpp:236] Iteration 8730, loss = 0.693249
I0701 14:45:26.016398  2788 solver.cpp:252]     Train net output #0: loss = 0.691887 (* 1 = 0.691887 loss)
I0701 14:45:26.016412  2788 sgd_solver.cpp:106] Iteration 8730, lr = 0.01
I0701 14:45:32.808204  2788 solver.cpp:236] Iteration 8740, loss = 0.693302
I0701 14:45:32.808275  2788 solver.cpp:252]     Train net output #0: loss = 0.694047 (* 1 = 0.694047 loss)
I0701 14:45:32.808291  2788 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0701 14:45:38.938148  2788 solver.cpp:340] Iteration 8750, Testing net (#0)
I0701 14:45:50.714216  2788 solver.cpp:408]     Test net output #0: accuracy = 0.506562
I0701 14:45:50.714274  2788 solver.cpp:408]     Test net output #1: loss = 0.693095 (* 1 = 0.693095 loss)
I0701 14:45:50.896893  2788 solver.cpp:236] Iteration 8750, loss = 0.693146
I0701 14:45:50.896981  2788 solver.cpp:252]     Train net output #0: loss = 0.696705 (* 1 = 0.696705 loss)
I0701 14:45:50.897027  2788 sgd_solver.cpp:106] Iteration 8750, lr = 0.01
I0701 14:45:57.690994  2788 solver.cpp:236] Iteration 8760, loss = 0.692742
I0701 14:45:57.691050  2788 solver.cpp:252]     Train net output #0: loss = 0.689833 (* 1 = 0.689833 loss)
I0701 14:45:57.691062  2788 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0701 14:46:04.503311  2788 solver.cpp:236] Iteration 8770, loss = 0.692857
I0701 14:46:04.503387  2788 solver.cpp:252]     Train net output #0: loss = 0.695604 (* 1 = 0.695604 loss)
I0701 14:46:04.503403  2788 sgd_solver.cpp:106] Iteration 8770, lr = 0.01
I0701 14:46:11.300357  2788 solver.cpp:236] Iteration 8780, loss = 0.692804
I0701 14:46:11.300532  2788 solver.cpp:252]     Train net output #0: loss = 0.695734 (* 1 = 0.695734 loss)
I0701 14:46:11.300560  2788 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0701 14:46:18.105731  2788 solver.cpp:236] Iteration 8790, loss = 0.692729
I0701 14:46:18.105782  2788 solver.cpp:252]     Train net output #0: loss = 0.696519 (* 1 = 0.696519 loss)
I0701 14:46:18.105798  2788 sgd_solver.cpp:106] Iteration 8790, lr = 0.01
I0701 14:46:24.921429  2788 solver.cpp:236] Iteration 8800, loss = 0.692992
I0701 14:46:24.921475  2788 solver.cpp:252]     Train net output #0: loss = 0.692946 (* 1 = 0.692946 loss)
I0701 14:46:24.921489  2788 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0701 14:46:31.726361  2788 solver.cpp:236] Iteration 8810, loss = 0.693404
I0701 14:46:31.726409  2788 solver.cpp:252]     Train net output #0: loss = 0.699284 (* 1 = 0.699284 loss)
I0701 14:46:31.726423  2788 sgd_solver.cpp:106] Iteration 8810, lr = 0.01
I0701 14:46:38.519722  2788 solver.cpp:236] Iteration 8820, loss = 0.693443
I0701 14:46:38.519775  2788 solver.cpp:252]     Train net output #0: loss = 0.689795 (* 1 = 0.689795 loss)
I0701 14:46:38.519796  2788 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0701 14:46:45.322814  2788 solver.cpp:236] Iteration 8830, loss = 0.693347
I0701 14:46:45.323076  2788 solver.cpp:252]     Train net output #0: loss = 0.689828 (* 1 = 0.689828 loss)
I0701 14:46:45.323113  2788 sgd_solver.cpp:106] Iteration 8830, lr = 0.01
I0701 14:46:52.128517  2788 solver.cpp:236] Iteration 8840, loss = 0.693291
I0701 14:46:52.128619  2788 solver.cpp:252]     Train net output #0: loss = 0.692213 (* 1 = 0.692213 loss)
I0701 14:46:52.128643  2788 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0701 14:46:58.913642  2788 solver.cpp:236] Iteration 8850, loss = 0.693071
I0701 14:46:58.913702  2788 solver.cpp:252]     Train net output #0: loss = 0.696085 (* 1 = 0.696085 loss)
I0701 14:46:58.913733  2788 sgd_solver.cpp:106] Iteration 8850, lr = 0.01
I0701 14:47:05.729321  2788 solver.cpp:236] Iteration 8860, loss = 0.693014
I0701 14:47:05.729398  2788 solver.cpp:252]     Train net output #0: loss = 0.696734 (* 1 = 0.696734 loss)
I0701 14:47:05.729418  2788 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0701 14:47:12.540479  2788 solver.cpp:236] Iteration 8870, loss = 0.693031
I0701 14:47:12.540573  2788 solver.cpp:252]     Train net output #0: loss = 0.693064 (* 1 = 0.693064 loss)
I0701 14:47:12.540597  2788 sgd_solver.cpp:106] Iteration 8870, lr = 0.01
I0701 14:47:19.333690  2788 solver.cpp:236] Iteration 8880, loss = 0.693194
I0701 14:47:19.333822  2788 solver.cpp:252]     Train net output #0: loss = 0.693162 (* 1 = 0.693162 loss)
I0701 14:47:19.333837  2788 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0701 14:47:26.141906  2788 solver.cpp:236] Iteration 8890, loss = 0.693283
I0701 14:47:26.141968  2788 solver.cpp:252]     Train net output #0: loss = 0.693498 (* 1 = 0.693498 loss)
I0701 14:47:26.141983  2788 sgd_solver.cpp:106] Iteration 8890, lr = 0.01
I0701 14:47:32.960311  2788 solver.cpp:236] Iteration 8900, loss = 0.693341
I0701 14:47:32.960378  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 14:47:32.960400  2788 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0701 14:47:39.782969  2788 solver.cpp:236] Iteration 8910, loss = 0.693339
I0701 14:47:39.783011  2788 solver.cpp:252]     Train net output #0: loss = 0.693752 (* 1 = 0.693752 loss)
I0701 14:47:39.783025  2788 sgd_solver.cpp:106] Iteration 8910, lr = 0.01
I0701 14:47:46.579254  2788 solver.cpp:236] Iteration 8920, loss = 0.693181
I0701 14:47:46.579303  2788 solver.cpp:252]     Train net output #0: loss = 0.690819 (* 1 = 0.690819 loss)
I0701 14:47:46.579316  2788 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0701 14:47:53.381731  2788 solver.cpp:236] Iteration 8930, loss = 0.693289
I0701 14:47:53.382041  2788 solver.cpp:252]     Train net output #0: loss = 0.693723 (* 1 = 0.693723 loss)
I0701 14:47:53.382064  2788 sgd_solver.cpp:106] Iteration 8930, lr = 0.01
I0701 14:48:00.211074  2788 solver.cpp:236] Iteration 8940, loss = 0.693332
I0701 14:48:00.211122  2788 solver.cpp:252]     Train net output #0: loss = 0.696829 (* 1 = 0.696829 loss)
I0701 14:48:00.211140  2788 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0701 14:48:07.007449  2788 solver.cpp:236] Iteration 8950, loss = 0.69375
I0701 14:48:07.007509  2788 solver.cpp:252]     Train net output #0: loss = 0.691103 (* 1 = 0.691103 loss)
I0701 14:48:07.007529  2788 sgd_solver.cpp:106] Iteration 8950, lr = 0.01
I0701 14:48:13.826515  2788 solver.cpp:236] Iteration 8960, loss = 0.693741
I0701 14:48:13.826565  2788 solver.cpp:252]     Train net output #0: loss = 0.691361 (* 1 = 0.691361 loss)
I0701 14:48:13.826584  2788 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0701 14:48:20.639210  2788 solver.cpp:236] Iteration 8970, loss = 0.693824
I0701 14:48:20.639269  2788 solver.cpp:252]     Train net output #0: loss = 0.693126 (* 1 = 0.693126 loss)
I0701 14:48:20.639288  2788 sgd_solver.cpp:106] Iteration 8970, lr = 0.01
I0701 14:48:27.445690  2788 solver.cpp:236] Iteration 8980, loss = 0.693625
I0701 14:48:27.445881  2788 solver.cpp:252]     Train net output #0: loss = 0.692495 (* 1 = 0.692495 loss)
I0701 14:48:27.445905  2788 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0701 14:48:34.257606  2788 solver.cpp:236] Iteration 8990, loss = 0.693651
I0701 14:48:34.257660  2788 solver.cpp:252]     Train net output #0: loss = 0.694315 (* 1 = 0.694315 loss)
I0701 14:48:34.257674  2788 sgd_solver.cpp:106] Iteration 8990, lr = 0.01
I0701 14:48:40.391127  2788 solver.cpp:340] Iteration 9000, Testing net (#0)
I0701 14:48:52.095693  2788 solver.cpp:408]     Test net output #0: accuracy = 0.49875
I0701 14:48:52.095746  2788 solver.cpp:408]     Test net output #1: loss = 0.693168 (* 1 = 0.693168 loss)
I0701 14:48:52.270004  2788 solver.cpp:236] Iteration 9000, loss = 0.693311
I0701 14:48:52.270053  2788 solver.cpp:252]     Train net output #0: loss = 0.693437 (* 1 = 0.693437 loss)
I0701 14:48:52.270069  2788 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0701 14:48:59.050511  2788 solver.cpp:236] Iteration 9010, loss = 0.693347
I0701 14:48:59.050704  2788 solver.cpp:252]     Train net output #0: loss = 0.692735 (* 1 = 0.692735 loss)
I0701 14:48:59.050720  2788 sgd_solver.cpp:106] Iteration 9010, lr = 0.01
I0701 14:49:05.859601  2788 solver.cpp:236] Iteration 9020, loss = 0.693378
I0701 14:49:05.859671  2788 solver.cpp:252]     Train net output #0: loss = 0.69497 (* 1 = 0.69497 loss)
I0701 14:49:05.859688  2788 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0701 14:49:12.652500  2788 solver.cpp:236] Iteration 9030, loss = 0.693398
I0701 14:49:12.652550  2788 solver.cpp:252]     Train net output #0: loss = 0.692515 (* 1 = 0.692515 loss)
I0701 14:49:12.652565  2788 sgd_solver.cpp:106] Iteration 9030, lr = 0.01
I0701 14:49:19.446445  2788 solver.cpp:236] Iteration 9040, loss = 0.693486
I0701 14:49:19.446549  2788 solver.cpp:252]     Train net output #0: loss = 0.69539 (* 1 = 0.69539 loss)
I0701 14:49:19.446573  2788 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0701 14:49:26.253732  2788 solver.cpp:236] Iteration 9050, loss = 0.69339
I0701 14:49:26.253803  2788 solver.cpp:252]     Train net output #0: loss = 0.693496 (* 1 = 0.693496 loss)
I0701 14:49:26.253821  2788 sgd_solver.cpp:106] Iteration 9050, lr = 0.01
I0701 14:49:33.054292  2788 solver.cpp:236] Iteration 9060, loss = 0.693399
I0701 14:49:33.054513  2788 solver.cpp:252]     Train net output #0: loss = 0.69269 (* 1 = 0.69269 loss)
I0701 14:49:33.054532  2788 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0701 14:49:39.866056  2788 solver.cpp:236] Iteration 9070, loss = 0.693363
I0701 14:49:39.866111  2788 solver.cpp:252]     Train net output #0: loss = 0.694632 (* 1 = 0.694632 loss)
I0701 14:49:39.866130  2788 sgd_solver.cpp:106] Iteration 9070, lr = 0.01
I0701 14:49:46.654060  2788 solver.cpp:236] Iteration 9080, loss = 0.69347
I0701 14:49:46.654112  2788 solver.cpp:252]     Train net output #0: loss = 0.694039 (* 1 = 0.694039 loss)
I0701 14:49:46.654129  2788 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0701 14:49:53.460541  2788 solver.cpp:236] Iteration 9090, loss = 0.693255
I0701 14:49:53.460593  2788 solver.cpp:252]     Train net output #0: loss = 0.69408 (* 1 = 0.69408 loss)
I0701 14:49:53.460608  2788 sgd_solver.cpp:106] Iteration 9090, lr = 0.01
I0701 14:50:00.252655  2788 solver.cpp:236] Iteration 9100, loss = 0.693186
I0701 14:50:00.252709  2788 solver.cpp:252]     Train net output #0: loss = 0.696999 (* 1 = 0.696999 loss)
I0701 14:50:00.252724  2788 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0701 14:50:07.031174  2788 solver.cpp:236] Iteration 9110, loss = 0.693307
I0701 14:50:07.031417  2788 solver.cpp:252]     Train net output #0: loss = 0.695751 (* 1 = 0.695751 loss)
I0701 14:50:07.031435  2788 sgd_solver.cpp:106] Iteration 9110, lr = 0.01
I0701 14:50:13.827416  2788 solver.cpp:236] Iteration 9120, loss = 0.693164
I0701 14:50:13.827474  2788 solver.cpp:252]     Train net output #0: loss = 0.69283 (* 1 = 0.69283 loss)
I0701 14:50:13.827489  2788 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0701 14:50:20.626590  2788 solver.cpp:236] Iteration 9130, loss = 0.693148
I0701 14:50:20.626641  2788 solver.cpp:252]     Train net output #0: loss = 0.693285 (* 1 = 0.693285 loss)
I0701 14:50:20.626655  2788 sgd_solver.cpp:106] Iteration 9130, lr = 0.01
I0701 14:50:27.426453  2788 solver.cpp:236] Iteration 9140, loss = 0.693289
I0701 14:50:27.426506  2788 solver.cpp:252]     Train net output #0: loss = 0.693174 (* 1 = 0.693174 loss)
I0701 14:50:27.426519  2788 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0701 14:50:34.243134  2788 solver.cpp:236] Iteration 9150, loss = 0.693356
I0701 14:50:34.243183  2788 solver.cpp:252]     Train net output #0: loss = 0.693571 (* 1 = 0.693571 loss)
I0701 14:50:34.243197  2788 sgd_solver.cpp:106] Iteration 9150, lr = 0.01
I0701 14:50:41.020335  2788 solver.cpp:236] Iteration 9160, loss = 0.693273
I0701 14:50:41.020612  2788 solver.cpp:252]     Train net output #0: loss = 0.692892 (* 1 = 0.692892 loss)
I0701 14:50:41.020632  2788 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0701 14:50:47.827975  2788 solver.cpp:236] Iteration 9170, loss = 0.693342
I0701 14:50:47.828038  2788 solver.cpp:252]     Train net output #0: loss = 0.693262 (* 1 = 0.693262 loss)
I0701 14:50:47.828053  2788 sgd_solver.cpp:106] Iteration 9170, lr = 0.01
I0701 14:50:54.629528  2788 solver.cpp:236] Iteration 9180, loss = 0.69317
I0701 14:50:54.629590  2788 solver.cpp:252]     Train net output #0: loss = 0.69545 (* 1 = 0.69545 loss)
I0701 14:50:54.629602  2788 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0701 14:51:01.438225  2788 solver.cpp:236] Iteration 9190, loss = 0.69311
I0701 14:51:01.438292  2788 solver.cpp:252]     Train net output #0: loss = 0.692115 (* 1 = 0.692115 loss)
I0701 14:51:01.438307  2788 sgd_solver.cpp:106] Iteration 9190, lr = 0.01
I0701 14:51:08.255170  2788 solver.cpp:236] Iteration 9200, loss = 0.693078
I0701 14:51:08.255244  2788 solver.cpp:252]     Train net output #0: loss = 0.693911 (* 1 = 0.693911 loss)
I0701 14:51:08.255261  2788 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0701 14:51:15.066778  2788 solver.cpp:236] Iteration 9210, loss = 0.693259
I0701 14:51:15.067057  2788 solver.cpp:252]     Train net output #0: loss = 0.69277 (* 1 = 0.69277 loss)
I0701 14:51:15.067073  2788 sgd_solver.cpp:106] Iteration 9210, lr = 0.01
I0701 14:51:21.873108  2788 solver.cpp:236] Iteration 9220, loss = 0.69324
I0701 14:51:21.873159  2788 solver.cpp:252]     Train net output #0: loss = 0.6866 (* 1 = 0.6866 loss)
I0701 14:51:21.873174  2788 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0701 14:51:28.656811  2788 solver.cpp:236] Iteration 9230, loss = 0.693043
I0701 14:51:28.656888  2788 solver.cpp:252]     Train net output #0: loss = 0.687897 (* 1 = 0.687897 loss)
I0701 14:51:28.656924  2788 sgd_solver.cpp:106] Iteration 9230, lr = 0.01
I0701 14:51:35.450767  2788 solver.cpp:236] Iteration 9240, loss = 0.693015
I0701 14:51:35.450846  2788 solver.cpp:252]     Train net output #0: loss = 0.698364 (* 1 = 0.698364 loss)
I0701 14:51:35.450865  2788 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0701 14:51:41.586407  2788 solver.cpp:340] Iteration 9250, Testing net (#0)
I0701 14:51:53.341163  2788 solver.cpp:408]     Test net output #0: accuracy = 0.500938
I0701 14:51:53.341418  2788 solver.cpp:408]     Test net output #1: loss = 0.693468 (* 1 = 0.693468 loss)
I0701 14:51:53.525218  2788 solver.cpp:236] Iteration 9250, loss = 0.693284
I0701 14:51:53.525281  2788 solver.cpp:252]     Train net output #0: loss = 0.689684 (* 1 = 0.689684 loss)
I0701 14:51:53.525298  2788 sgd_solver.cpp:106] Iteration 9250, lr = 0.01
I0701 14:52:00.304275  2788 solver.cpp:236] Iteration 9260, loss = 0.693039
I0701 14:52:00.304335  2788 solver.cpp:252]     Train net output #0: loss = 0.693894 (* 1 = 0.693894 loss)
I0701 14:52:00.304350  2788 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0701 14:52:07.092103  2788 solver.cpp:236] Iteration 9270, loss = 0.693045
I0701 14:52:07.092180  2788 solver.cpp:252]     Train net output #0: loss = 0.693401 (* 1 = 0.693401 loss)
I0701 14:52:07.092202  2788 sgd_solver.cpp:106] Iteration 9270, lr = 0.01
I0701 14:52:13.891073  2788 solver.cpp:236] Iteration 9280, loss = 0.693258
I0701 14:52:13.891207  2788 solver.cpp:252]     Train net output #0: loss = 0.694131 (* 1 = 0.694131 loss)
I0701 14:52:13.891232  2788 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0701 14:52:20.669842  2788 solver.cpp:236] Iteration 9290, loss = 0.69334
I0701 14:52:20.669917  2788 solver.cpp:252]     Train net output #0: loss = 0.693545 (* 1 = 0.693545 loss)
I0701 14:52:20.669937  2788 sgd_solver.cpp:106] Iteration 9290, lr = 0.01
I0701 14:52:27.471421  2788 solver.cpp:236] Iteration 9300, loss = 0.693143
I0701 14:52:27.471575  2788 solver.cpp:252]     Train net output #0: loss = 0.693172 (* 1 = 0.693172 loss)
I0701 14:52:27.471597  2788 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0701 14:52:34.272265  2788 solver.cpp:236] Iteration 9310, loss = 0.69317
I0701 14:52:34.272325  2788 solver.cpp:252]     Train net output #0: loss = 0.695155 (* 1 = 0.695155 loss)
I0701 14:52:34.272339  2788 sgd_solver.cpp:106] Iteration 9310, lr = 0.01
I0701 14:52:41.080188  2788 solver.cpp:236] Iteration 9320, loss = 0.693176
I0701 14:52:41.080236  2788 solver.cpp:252]     Train net output #0: loss = 0.690889 (* 1 = 0.690889 loss)
I0701 14:52:41.080251  2788 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0701 14:52:47.890048  2788 solver.cpp:236] Iteration 9330, loss = 0.693424
I0701 14:52:47.890089  2788 solver.cpp:252]     Train net output #0: loss = 0.693621 (* 1 = 0.693621 loss)
I0701 14:52:47.890102  2788 sgd_solver.cpp:106] Iteration 9330, lr = 0.01
I0701 14:52:54.689831  2788 solver.cpp:236] Iteration 9340, loss = 0.693338
I0701 14:52:54.689888  2788 solver.cpp:252]     Train net output #0: loss = 0.693203 (* 1 = 0.693203 loss)
I0701 14:52:54.689901  2788 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0701 14:53:01.500859  2788 solver.cpp:236] Iteration 9350, loss = 0.693189
I0701 14:53:01.504487  2788 solver.cpp:252]     Train net output #0: loss = 0.691305 (* 1 = 0.691305 loss)
I0701 14:53:01.504520  2788 sgd_solver.cpp:106] Iteration 9350, lr = 0.01
I0701 14:53:08.302824  2788 solver.cpp:236] Iteration 9360, loss = 0.693217
I0701 14:53:08.302884  2788 solver.cpp:252]     Train net output #0: loss = 0.693663 (* 1 = 0.693663 loss)
I0701 14:53:08.302901  2788 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0701 14:53:15.117868  2788 solver.cpp:236] Iteration 9370, loss = 0.693148
I0701 14:53:15.117910  2788 solver.cpp:252]     Train net output #0: loss = 0.692102 (* 1 = 0.692102 loss)
I0701 14:53:15.117924  2788 sgd_solver.cpp:106] Iteration 9370, lr = 0.01
I0701 14:53:21.929316  2788 solver.cpp:236] Iteration 9380, loss = 0.692938
I0701 14:53:21.929370  2788 solver.cpp:252]     Train net output #0: loss = 0.691288 (* 1 = 0.691288 loss)
I0701 14:53:21.929385  2788 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0701 14:53:28.726131  2788 solver.cpp:236] Iteration 9390, loss = 0.693101
I0701 14:53:28.726191  2788 solver.cpp:252]     Train net output #0: loss = 0.694621 (* 1 = 0.694621 loss)
I0701 14:53:28.726205  2788 sgd_solver.cpp:106] Iteration 9390, lr = 0.01
I0701 14:53:35.526769  2788 solver.cpp:236] Iteration 9400, loss = 0.693266
I0701 14:53:35.532487  2788 solver.cpp:252]     Train net output #0: loss = 0.693683 (* 1 = 0.693683 loss)
I0701 14:53:35.532505  2788 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0701 14:53:42.336680  2788 solver.cpp:236] Iteration 9410, loss = 0.693295
I0701 14:53:42.336755  2788 solver.cpp:252]     Train net output #0: loss = 0.693092 (* 1 = 0.693092 loss)
I0701 14:53:42.336773  2788 sgd_solver.cpp:106] Iteration 9410, lr = 0.01
I0701 14:53:49.122453  2788 solver.cpp:236] Iteration 9420, loss = 0.693364
I0701 14:53:49.122527  2788 solver.cpp:252]     Train net output #0: loss = 0.692659 (* 1 = 0.692659 loss)
I0701 14:53:49.122542  2788 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0701 14:53:55.926810  2788 solver.cpp:236] Iteration 9430, loss = 0.693381
I0701 14:53:55.926869  2788 solver.cpp:252]     Train net output #0: loss = 0.692289 (* 1 = 0.692289 loss)
I0701 14:53:55.926884  2788 sgd_solver.cpp:106] Iteration 9430, lr = 0.01
I0701 14:54:02.727419  2788 solver.cpp:236] Iteration 9440, loss = 0.693333
I0701 14:54:02.727471  2788 solver.cpp:252]     Train net output #0: loss = 0.692392 (* 1 = 0.692392 loss)
I0701 14:54:02.727484  2788 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0701 14:54:09.510293  2788 solver.cpp:236] Iteration 9450, loss = 0.693398
I0701 14:54:09.510484  2788 solver.cpp:252]     Train net output #0: loss = 0.693168 (* 1 = 0.693168 loss)
I0701 14:54:09.510500  2788 sgd_solver.cpp:106] Iteration 9450, lr = 0.01
I0701 14:54:16.320906  2788 solver.cpp:236] Iteration 9460, loss = 0.693443
I0701 14:54:16.320956  2788 solver.cpp:252]     Train net output #0: loss = 0.69552 (* 1 = 0.69552 loss)
I0701 14:54:16.320971  2788 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0701 14:54:23.129215  2788 solver.cpp:236] Iteration 9470, loss = 0.693483
I0701 14:54:23.129266  2788 solver.cpp:252]     Train net output #0: loss = 0.693196 (* 1 = 0.693196 loss)
I0701 14:54:23.129281  2788 sgd_solver.cpp:106] Iteration 9470, lr = 0.01
I0701 14:54:29.930580  2788 solver.cpp:236] Iteration 9480, loss = 0.693536
I0701 14:54:29.930642  2788 solver.cpp:252]     Train net output #0: loss = 0.693132 (* 1 = 0.693132 loss)
I0701 14:54:29.930658  2788 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0701 14:54:36.742177  2788 solver.cpp:236] Iteration 9490, loss = 0.693447
I0701 14:54:36.742239  2788 solver.cpp:252]     Train net output #0: loss = 0.693127 (* 1 = 0.693127 loss)
I0701 14:54:36.742254  2788 sgd_solver.cpp:106] Iteration 9490, lr = 0.01
I0701 14:54:42.868641  2788 solver.cpp:340] Iteration 9500, Testing net (#0)
I0701 14:54:54.621399  2788 solver.cpp:408]     Test net output #0: accuracy = 0.50375
I0701 14:54:54.621461  2788 solver.cpp:408]     Test net output #1: loss = 0.693145 (* 1 = 0.693145 loss)
I0701 14:54:54.794018  2788 solver.cpp:236] Iteration 9500, loss = 0.693429
I0701 14:54:54.794071  2788 solver.cpp:252]     Train net output #0: loss = 0.694636 (* 1 = 0.694636 loss)
I0701 14:54:54.794088  2788 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0701 14:55:01.589958  2788 solver.cpp:236] Iteration 9510, loss = 0.693274
I0701 14:55:01.590006  2788 solver.cpp:252]     Train net output #0: loss = 0.692861 (* 1 = 0.692861 loss)
I0701 14:55:01.590020  2788 sgd_solver.cpp:106] Iteration 9510, lr = 0.01
I0701 14:55:08.369565  2788 solver.cpp:236] Iteration 9520, loss = 0.693211
I0701 14:55:08.369612  2788 solver.cpp:252]     Train net output #0: loss = 0.694406 (* 1 = 0.694406 loss)
I0701 14:55:08.369627  2788 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0701 14:55:15.165627  2788 solver.cpp:236] Iteration 9530, loss = 0.693285
I0701 14:55:15.165912  2788 solver.cpp:252]     Train net output #0: loss = 0.697325 (* 1 = 0.697325 loss)
I0701 14:55:15.165931  2788 sgd_solver.cpp:106] Iteration 9530, lr = 0.01
I0701 14:55:21.959395  2788 solver.cpp:236] Iteration 9540, loss = 0.693178
I0701 14:55:21.959448  2788 solver.cpp:252]     Train net output #0: loss = 0.694252 (* 1 = 0.694252 loss)
I0701 14:55:21.959463  2788 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0701 14:55:28.753798  2788 solver.cpp:236] Iteration 9550, loss = 0.69294
I0701 14:55:28.753854  2788 solver.cpp:252]     Train net output #0: loss = 0.696606 (* 1 = 0.696606 loss)
I0701 14:55:28.753867  2788 sgd_solver.cpp:106] Iteration 9550, lr = 0.01
I0701 14:55:35.553416  2788 solver.cpp:236] Iteration 9560, loss = 0.693119
I0701 14:55:35.553474  2788 solver.cpp:252]     Train net output #0: loss = 0.696926 (* 1 = 0.696926 loss)
I0701 14:55:35.553489  2788 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0701 14:55:42.366741  2788 solver.cpp:236] Iteration 9570, loss = 0.693064
I0701 14:55:42.366791  2788 solver.cpp:252]     Train net output #0: loss = 0.693029 (* 1 = 0.693029 loss)
I0701 14:55:42.366806  2788 sgd_solver.cpp:106] Iteration 9570, lr = 0.01
I0701 14:55:49.153167  2788 solver.cpp:236] Iteration 9580, loss = 0.693066
I0701 14:55:49.153389  2788 solver.cpp:252]     Train net output #0: loss = 0.694001 (* 1 = 0.694001 loss)
I0701 14:55:49.153409  2788 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0701 14:55:55.965575  2788 solver.cpp:236] Iteration 9590, loss = 0.693188
I0701 14:55:55.965626  2788 solver.cpp:252]     Train net output #0: loss = 0.693262 (* 1 = 0.693262 loss)
I0701 14:55:55.965641  2788 sgd_solver.cpp:106] Iteration 9590, lr = 0.01
I0701 14:56:02.768070  2788 solver.cpp:236] Iteration 9600, loss = 0.693281
I0701 14:56:02.768126  2788 solver.cpp:252]     Train net output #0: loss = 0.692158 (* 1 = 0.692158 loss)
I0701 14:56:02.768142  2788 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0701 14:56:09.564087  2788 solver.cpp:236] Iteration 9610, loss = 0.693502
I0701 14:56:09.564134  2788 solver.cpp:252]     Train net output #0: loss = 0.693213 (* 1 = 0.693213 loss)
I0701 14:56:09.564147  2788 sgd_solver.cpp:106] Iteration 9610, lr = 0.01
I0701 14:56:16.367951  2788 solver.cpp:236] Iteration 9620, loss = 0.693823
I0701 14:56:16.368000  2788 solver.cpp:252]     Train net output #0: loss = 0.695583 (* 1 = 0.695583 loss)
I0701 14:56:16.368015  2788 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0701 14:56:23.158414  2788 solver.cpp:236] Iteration 9630, loss = 0.693732
I0701 14:56:23.160212  2788 solver.cpp:252]     Train net output #0: loss = 0.693795 (* 1 = 0.693795 loss)
I0701 14:56:23.160229  2788 sgd_solver.cpp:106] Iteration 9630, lr = 0.01
I0701 14:56:29.981972  2788 solver.cpp:236] Iteration 9640, loss = 0.693725
I0701 14:56:29.982038  2788 solver.cpp:252]     Train net output #0: loss = 0.693558 (* 1 = 0.693558 loss)
I0701 14:56:29.982053  2788 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0701 14:56:36.778162  2788 solver.cpp:236] Iteration 9650, loss = 0.693829
I0701 14:56:36.778223  2788 solver.cpp:252]     Train net output #0: loss = 0.693648 (* 1 = 0.693648 loss)
I0701 14:56:36.778237  2788 sgd_solver.cpp:106] Iteration 9650, lr = 0.01
I0701 14:56:43.591428  2788 solver.cpp:236] Iteration 9660, loss = 0.693544
I0701 14:56:43.591492  2788 solver.cpp:252]     Train net output #0: loss = 0.693211 (* 1 = 0.693211 loss)
I0701 14:56:43.591518  2788 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0701 14:56:50.402688  2788 solver.cpp:236] Iteration 9670, loss = 0.693311
I0701 14:56:50.402740  2788 solver.cpp:252]     Train net output #0: loss = 0.69273 (* 1 = 0.69273 loss)
I0701 14:56:50.402755  2788 sgd_solver.cpp:106] Iteration 9670, lr = 0.01
I0701 14:56:57.209704  2788 solver.cpp:236] Iteration 9680, loss = 0.693296
I0701 14:56:57.210055  2788 solver.cpp:252]     Train net output #0: loss = 0.694892 (* 1 = 0.694892 loss)
I0701 14:56:57.210077  2788 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0701 14:57:04.021262  2788 solver.cpp:236] Iteration 9690, loss = 0.69336
I0701 14:57:04.021311  2788 solver.cpp:252]     Train net output #0: loss = 0.692804 (* 1 = 0.692804 loss)
I0701 14:57:04.021324  2788 sgd_solver.cpp:106] Iteration 9690, lr = 0.01
I0701 14:57:10.836272  2788 solver.cpp:236] Iteration 9700, loss = 0.693276
I0701 14:57:10.836329  2788 solver.cpp:252]     Train net output #0: loss = 0.69311 (* 1 = 0.69311 loss)
I0701 14:57:10.836344  2788 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0701 14:57:17.644284  2788 solver.cpp:236] Iteration 9710, loss = 0.693265
I0701 14:57:17.644332  2788 solver.cpp:252]     Train net output #0: loss = 0.694726 (* 1 = 0.694726 loss)
I0701 14:57:17.644350  2788 sgd_solver.cpp:106] Iteration 9710, lr = 0.01
I0701 14:57:24.457209  2788 solver.cpp:236] Iteration 9720, loss = 0.693271
I0701 14:57:24.457252  2788 solver.cpp:252]     Train net output #0: loss = 0.693074 (* 1 = 0.693074 loss)
I0701 14:57:24.457267  2788 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0701 14:57:31.274212  2788 solver.cpp:236] Iteration 9730, loss = 0.693385
I0701 14:57:31.274379  2788 solver.cpp:252]     Train net output #0: loss = 0.695214 (* 1 = 0.695214 loss)
I0701 14:57:31.274394  2788 sgd_solver.cpp:106] Iteration 9730, lr = 0.01
I0701 14:57:38.088558  2788 solver.cpp:236] Iteration 9740, loss = 0.693303
I0701 14:57:38.088613  2788 solver.cpp:252]     Train net output #0: loss = 0.693341 (* 1 = 0.693341 loss)
I0701 14:57:38.088627  2788 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0701 14:57:44.220229  2788 solver.cpp:340] Iteration 9750, Testing net (#0)
I0701 14:57:50.204046  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 14:57:55.995992  2788 solver.cpp:408]     Test net output #0: accuracy = 0.494687
I0701 14:57:55.996055  2788 solver.cpp:408]     Test net output #1: loss = 0.693216 (* 1 = 0.693216 loss)
I0701 14:57:56.172724  2788 solver.cpp:236] Iteration 9750, loss = 0.693317
I0701 14:57:56.172778  2788 solver.cpp:252]     Train net output #0: loss = 0.693242 (* 1 = 0.693242 loss)
I0701 14:57:56.172793  2788 sgd_solver.cpp:106] Iteration 9750, lr = 0.01
I0701 14:58:02.955593  2788 solver.cpp:236] Iteration 9760, loss = 0.693289
I0701 14:58:02.960490  2788 solver.cpp:252]     Train net output #0: loss = 0.692954 (* 1 = 0.692954 loss)
I0701 14:58:02.960507  2788 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0701 14:58:09.739379  2788 solver.cpp:236] Iteration 9770, loss = 0.693299
I0701 14:58:09.739434  2788 solver.cpp:252]     Train net output #0: loss = 0.693059 (* 1 = 0.693059 loss)
I0701 14:58:09.739447  2788 sgd_solver.cpp:106] Iteration 9770, lr = 0.01
I0701 14:58:16.520560  2788 solver.cpp:236] Iteration 9780, loss = 0.693165
I0701 14:58:16.520612  2788 solver.cpp:252]     Train net output #0: loss = 0.692755 (* 1 = 0.692755 loss)
I0701 14:58:16.520627  2788 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0701 14:58:23.304332  2788 solver.cpp:236] Iteration 9790, loss = 0.693222
I0701 14:58:23.304383  2788 solver.cpp:252]     Train net output #0: loss = 0.692773 (* 1 = 0.692773 loss)
I0701 14:58:23.304399  2788 sgd_solver.cpp:106] Iteration 9790, lr = 0.01
I0701 14:58:30.102808  2788 solver.cpp:236] Iteration 9800, loss = 0.69324
I0701 14:58:30.102867  2788 solver.cpp:252]     Train net output #0: loss = 0.693565 (* 1 = 0.693565 loss)
I0701 14:58:30.102882  2788 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0701 14:58:36.874745  2788 solver.cpp:236] Iteration 9810, loss = 0.693244
I0701 14:58:36.875017  2788 solver.cpp:252]     Train net output #0: loss = 0.693078 (* 1 = 0.693078 loss)
I0701 14:58:36.875042  2788 sgd_solver.cpp:106] Iteration 9810, lr = 0.01
I0701 14:58:43.675734  2788 solver.cpp:236] Iteration 9820, loss = 0.693234
I0701 14:58:43.675779  2788 solver.cpp:252]     Train net output #0: loss = 0.693104 (* 1 = 0.693104 loss)
I0701 14:58:43.675793  2788 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0701 14:58:50.459926  2788 solver.cpp:236] Iteration 9830, loss = 0.693353
I0701 14:58:50.459980  2788 solver.cpp:252]     Train net output #0: loss = 0.69212 (* 1 = 0.69212 loss)
I0701 14:58:50.459995  2788 sgd_solver.cpp:106] Iteration 9830, lr = 0.01
I0701 14:58:57.249042  2788 solver.cpp:236] Iteration 9840, loss = 0.693247
I0701 14:58:57.249109  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 14:58:57.249124  2788 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0701 14:59:04.071410  2788 solver.cpp:236] Iteration 9850, loss = 0.693159
I0701 14:59:04.071461  2788 solver.cpp:252]     Train net output #0: loss = 0.692802 (* 1 = 0.692802 loss)
I0701 14:59:04.071476  2788 sgd_solver.cpp:106] Iteration 9850, lr = 0.01
I0701 14:59:10.854957  2788 solver.cpp:236] Iteration 9860, loss = 0.693065
I0701 14:59:10.855164  2788 solver.cpp:252]     Train net output #0: loss = 0.692059 (* 1 = 0.692059 loss)
I0701 14:59:10.855178  2788 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0701 14:59:17.650315  2788 solver.cpp:236] Iteration 9870, loss = 0.693387
I0701 14:59:17.650408  2788 solver.cpp:252]     Train net output #0: loss = 0.69374 (* 1 = 0.69374 loss)
I0701 14:59:17.650421  2788 sgd_solver.cpp:106] Iteration 9870, lr = 0.01
I0701 14:59:24.451274  2788 solver.cpp:236] Iteration 9880, loss = 0.693468
I0701 14:59:24.451336  2788 solver.cpp:252]     Train net output #0: loss = 0.694299 (* 1 = 0.694299 loss)
I0701 14:59:24.451351  2788 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0701 14:59:31.246155  2788 solver.cpp:236] Iteration 9890, loss = 0.693706
I0701 14:59:31.246206  2788 solver.cpp:252]     Train net output #0: loss = 0.692907 (* 1 = 0.692907 loss)
I0701 14:59:31.246220  2788 sgd_solver.cpp:106] Iteration 9890, lr = 0.01
I0701 14:59:38.050685  2788 solver.cpp:236] Iteration 9900, loss = 0.693708
I0701 14:59:38.050745  2788 solver.cpp:252]     Train net output #0: loss = 0.694953 (* 1 = 0.694953 loss)
I0701 14:59:38.050758  2788 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0701 14:59:44.854655  2788 solver.cpp:236] Iteration 9910, loss = 0.694217
I0701 14:59:44.854908  2788 solver.cpp:252]     Train net output #0: loss = 0.694758 (* 1 = 0.694758 loss)
I0701 14:59:44.854929  2788 sgd_solver.cpp:106] Iteration 9910, lr = 0.01
I0701 14:59:51.656818  2788 solver.cpp:236] Iteration 9920, loss = 0.693901
I0701 14:59:51.656882  2788 solver.cpp:252]     Train net output #0: loss = 0.693398 (* 1 = 0.693398 loss)
I0701 14:59:51.656908  2788 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0701 14:59:58.458696  2788 solver.cpp:236] Iteration 9930, loss = 0.69374
I0701 14:59:58.458753  2788 solver.cpp:252]     Train net output #0: loss = 0.695053 (* 1 = 0.695053 loss)
I0701 14:59:58.458767  2788 sgd_solver.cpp:106] Iteration 9930, lr = 0.01
I0701 15:00:05.272899  2788 solver.cpp:236] Iteration 9940, loss = 0.6935
I0701 15:00:05.272944  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 15:00:05.272958  2788 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0701 15:00:12.093015  2788 solver.cpp:236] Iteration 9950, loss = 0.693743
I0701 15:00:12.093070  2788 solver.cpp:252]     Train net output #0: loss = 0.693975 (* 1 = 0.693975 loss)
I0701 15:00:12.093083  2788 sgd_solver.cpp:106] Iteration 9950, lr = 0.01
I0701 15:00:18.896601  2788 solver.cpp:236] Iteration 9960, loss = 0.693347
I0701 15:00:18.896905  2788 solver.cpp:252]     Train net output #0: loss = 0.693088 (* 1 = 0.693088 loss)
I0701 15:00:18.896926  2788 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0701 15:00:25.703145  2788 solver.cpp:236] Iteration 9970, loss = 0.693343
I0701 15:00:25.703207  2788 solver.cpp:252]     Train net output #0: loss = 0.693006 (* 1 = 0.693006 loss)
I0701 15:00:25.703222  2788 sgd_solver.cpp:106] Iteration 9970, lr = 0.01
I0701 15:00:32.508720  2788 solver.cpp:236] Iteration 9980, loss = 0.693381
I0701 15:00:32.508772  2788 solver.cpp:252]     Train net output #0: loss = 0.69318 (* 1 = 0.69318 loss)
I0701 15:00:32.508787  2788 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0701 15:00:39.306215  2788 solver.cpp:236] Iteration 9990, loss = 0.693456
I0701 15:00:39.306262  2788 solver.cpp:252]     Train net output #0: loss = 0.693489 (* 1 = 0.693489 loss)
I0701 15:00:39.306277  2788 sgd_solver.cpp:106] Iteration 9990, lr = 0.01
I0701 15:00:45.436831  2788 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_10000.caffemodel
I0701 15:00:46.073312  2788 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_10000.solverstate
I0701 15:00:46.116211  2788 solver.cpp:340] Iteration 10000, Testing net (#0)
I0701 15:00:57.252091  2788 solver.cpp:408]     Test net output #0: accuracy = 0.499375
I0701 15:00:57.252272  2788 solver.cpp:408]     Test net output #1: loss = 0.693164 (* 1 = 0.693164 loss)
I0701 15:00:57.432411  2788 solver.cpp:236] Iteration 10000, loss = 0.69328
I0701 15:00:57.432472  2788 solver.cpp:252]     Train net output #0: loss = 0.692937 (* 1 = 0.692937 loss)
I0701 15:00:57.432489  2788 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0701 15:01:04.230183  2788 solver.cpp:236] Iteration 10010, loss = 0.693271
I0701 15:01:04.230242  2788 solver.cpp:252]     Train net output #0: loss = 0.693516 (* 1 = 0.693516 loss)
I0701 15:01:04.230257  2788 sgd_solver.cpp:106] Iteration 10010, lr = 0.01
I0701 15:01:11.035883  2788 solver.cpp:236] Iteration 10020, loss = 0.693248
I0701 15:01:11.035938  2788 solver.cpp:252]     Train net output #0: loss = 0.692615 (* 1 = 0.692615 loss)
I0701 15:01:11.035951  2788 sgd_solver.cpp:106] Iteration 10020, lr = 0.01
I0701 15:01:17.844002  2788 solver.cpp:236] Iteration 10030, loss = 0.693151
I0701 15:01:17.844092  2788 solver.cpp:252]     Train net output #0: loss = 0.696155 (* 1 = 0.696155 loss)
I0701 15:01:17.844108  2788 sgd_solver.cpp:106] Iteration 10030, lr = 0.01
I0701 15:01:24.643546  2788 solver.cpp:236] Iteration 10040, loss = 0.693347
I0701 15:01:24.643595  2788 solver.cpp:252]     Train net output #0: loss = 0.693511 (* 1 = 0.693511 loss)
I0701 15:01:24.643610  2788 sgd_solver.cpp:106] Iteration 10040, lr = 0.01
I0701 15:01:31.444850  2788 solver.cpp:236] Iteration 10050, loss = 0.693343
I0701 15:01:31.445101  2788 solver.cpp:252]     Train net output #0: loss = 0.693209 (* 1 = 0.693209 loss)
I0701 15:01:31.445121  2788 sgd_solver.cpp:106] Iteration 10050, lr = 0.01
I0701 15:01:38.248980  2788 solver.cpp:236] Iteration 10060, loss = 0.693332
I0701 15:01:38.249032  2788 solver.cpp:252]     Train net output #0: loss = 0.694176 (* 1 = 0.694176 loss)
I0701 15:01:38.249045  2788 sgd_solver.cpp:106] Iteration 10060, lr = 0.01
I0701 15:01:45.040269  2788 solver.cpp:236] Iteration 10070, loss = 0.693617
I0701 15:01:45.040343  2788 solver.cpp:252]     Train net output #0: loss = 0.69436 (* 1 = 0.69436 loss)
I0701 15:01:45.040366  2788 sgd_solver.cpp:106] Iteration 10070, lr = 0.01
I0701 15:01:51.843982  2788 solver.cpp:236] Iteration 10080, loss = 0.693821
I0701 15:01:51.844038  2788 solver.cpp:252]     Train net output #0: loss = 0.698773 (* 1 = 0.698773 loss)
I0701 15:01:51.844051  2788 sgd_solver.cpp:106] Iteration 10080, lr = 0.01
I0701 15:01:58.652760  2788 solver.cpp:236] Iteration 10090, loss = 0.693852
I0701 15:01:58.652817  2788 solver.cpp:252]     Train net output #0: loss = 0.691147 (* 1 = 0.691147 loss)
I0701 15:01:58.652832  2788 sgd_solver.cpp:106] Iteration 10090, lr = 0.01
I0701 15:02:05.461220  2788 solver.cpp:236] Iteration 10100, loss = 0.693951
I0701 15:02:05.461467  2788 solver.cpp:252]     Train net output #0: loss = 0.692963 (* 1 = 0.692963 loss)
I0701 15:02:05.461483  2788 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0701 15:02:12.291954  2788 solver.cpp:236] Iteration 10110, loss = 0.693927
I0701 15:02:12.292018  2788 solver.cpp:252]     Train net output #0: loss = 0.692217 (* 1 = 0.692217 loss)
I0701 15:02:12.292039  2788 sgd_solver.cpp:106] Iteration 10110, lr = 0.01
I0701 15:02:19.094437  2788 solver.cpp:236] Iteration 10120, loss = 0.693649
I0701 15:02:19.094511  2788 solver.cpp:252]     Train net output #0: loss = 0.690938 (* 1 = 0.690938 loss)
I0701 15:02:19.094537  2788 sgd_solver.cpp:106] Iteration 10120, lr = 0.01
I0701 15:02:25.897821  2788 solver.cpp:236] Iteration 10130, loss = 0.693432
I0701 15:02:25.897868  2788 solver.cpp:252]     Train net output #0: loss = 0.696262 (* 1 = 0.696262 loss)
I0701 15:02:25.897886  2788 sgd_solver.cpp:106] Iteration 10130, lr = 0.01
I0701 15:02:32.712296  2788 solver.cpp:236] Iteration 10140, loss = 0.693226
I0701 15:02:32.712357  2788 solver.cpp:252]     Train net output #0: loss = 0.690272 (* 1 = 0.690272 loss)
I0701 15:02:32.712383  2788 sgd_solver.cpp:106] Iteration 10140, lr = 0.01
I0701 15:02:39.519711  2788 solver.cpp:236] Iteration 10150, loss = 0.693152
I0701 15:02:39.524487  2788 solver.cpp:252]     Train net output #0: loss = 0.693432 (* 1 = 0.693432 loss)
I0701 15:02:39.524504  2788 sgd_solver.cpp:106] Iteration 10150, lr = 0.01
I0701 15:02:46.309727  2788 solver.cpp:236] Iteration 10160, loss = 0.693111
I0701 15:02:46.309789  2788 solver.cpp:252]     Train net output #0: loss = 0.691829 (* 1 = 0.691829 loss)
I0701 15:02:46.309803  2788 sgd_solver.cpp:106] Iteration 10160, lr = 0.01
I0701 15:02:53.126315  2788 solver.cpp:236] Iteration 10170, loss = 0.693038
I0701 15:02:53.126363  2788 solver.cpp:252]     Train net output #0: loss = 0.694316 (* 1 = 0.694316 loss)
I0701 15:02:53.126381  2788 sgd_solver.cpp:106] Iteration 10170, lr = 0.01
I0701 15:02:59.942767  2788 solver.cpp:236] Iteration 10180, loss = 0.693303
I0701 15:02:59.942809  2788 solver.cpp:252]     Train net output #0: loss = 0.696692 (* 1 = 0.696692 loss)
I0701 15:02:59.942821  2788 sgd_solver.cpp:106] Iteration 10180, lr = 0.01
I0701 15:03:06.734897  2788 solver.cpp:236] Iteration 10190, loss = 0.693322
I0701 15:03:06.734949  2788 solver.cpp:252]     Train net output #0: loss = 0.692753 (* 1 = 0.692753 loss)
I0701 15:03:06.734964  2788 sgd_solver.cpp:106] Iteration 10190, lr = 0.01
I0701 15:03:13.526144  2788 solver.cpp:236] Iteration 10200, loss = 0.69337
I0701 15:03:13.532480  2788 solver.cpp:252]     Train net output #0: loss = 0.692474 (* 1 = 0.692474 loss)
I0701 15:03:13.532497  2788 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0701 15:03:20.330374  2788 solver.cpp:236] Iteration 10210, loss = 0.69346
I0701 15:03:20.330435  2788 solver.cpp:252]     Train net output #0: loss = 0.694515 (* 1 = 0.694515 loss)
I0701 15:03:20.330448  2788 sgd_solver.cpp:106] Iteration 10210, lr = 0.01
I0701 15:03:27.156932  2788 solver.cpp:236] Iteration 10220, loss = 0.693419
I0701 15:03:27.156991  2788 solver.cpp:252]     Train net output #0: loss = 0.689591 (* 1 = 0.689591 loss)
I0701 15:03:27.157006  2788 sgd_solver.cpp:106] Iteration 10220, lr = 0.01
I0701 15:03:33.979634  2788 solver.cpp:236] Iteration 10230, loss = 0.693415
I0701 15:03:33.979686  2788 solver.cpp:252]     Train net output #0: loss = 0.693026 (* 1 = 0.693026 loss)
I0701 15:03:33.979699  2788 sgd_solver.cpp:106] Iteration 10230, lr = 0.01
I0701 15:03:40.790544  2788 solver.cpp:236] Iteration 10240, loss = 0.693294
I0701 15:03:40.790601  2788 solver.cpp:252]     Train net output #0: loss = 0.692319 (* 1 = 0.692319 loss)
I0701 15:03:40.790614  2788 sgd_solver.cpp:106] Iteration 10240, lr = 0.01
I0701 15:03:46.932442  2788 solver.cpp:340] Iteration 10250, Testing net (#0)
I0701 15:03:58.687557  2788 solver.cpp:408]     Test net output #0: accuracy = 0.484062
I0701 15:03:58.687615  2788 solver.cpp:408]     Test net output #1: loss = 0.693429 (* 1 = 0.693429 loss)
I0701 15:03:58.872485  2788 solver.cpp:236] Iteration 10250, loss = 0.693223
I0701 15:03:58.872547  2788 solver.cpp:252]     Train net output #0: loss = 0.692441 (* 1 = 0.692441 loss)
I0701 15:03:58.872561  2788 sgd_solver.cpp:106] Iteration 10250, lr = 0.01
I0701 15:04:05.658823  2788 solver.cpp:236] Iteration 10260, loss = 0.693172
I0701 15:04:05.658871  2788 solver.cpp:252]     Train net output #0: loss = 0.693554 (* 1 = 0.693554 loss)
I0701 15:04:05.658885  2788 sgd_solver.cpp:106] Iteration 10260, lr = 0.01
I0701 15:04:12.430974  2788 solver.cpp:236] Iteration 10270, loss = 0.693328
I0701 15:04:12.431026  2788 solver.cpp:252]     Train net output #0: loss = 0.693166 (* 1 = 0.693166 loss)
I0701 15:04:12.431041  2788 sgd_solver.cpp:106] Iteration 10270, lr = 0.01
I0701 15:04:19.230952  2788 solver.cpp:236] Iteration 10280, loss = 0.693128
I0701 15:04:19.231199  2788 solver.cpp:252]     Train net output #0: loss = 0.693088 (* 1 = 0.693088 loss)
I0701 15:04:19.231216  2788 sgd_solver.cpp:106] Iteration 10280, lr = 0.01
I0701 15:04:26.038346  2788 solver.cpp:236] Iteration 10290, loss = 0.693204
I0701 15:04:26.038398  2788 solver.cpp:252]     Train net output #0: loss = 0.69336 (* 1 = 0.69336 loss)
I0701 15:04:26.038413  2788 sgd_solver.cpp:106] Iteration 10290, lr = 0.01
I0701 15:04:32.829272  2788 solver.cpp:236] Iteration 10300, loss = 0.693195
I0701 15:04:32.829316  2788 solver.cpp:252]     Train net output #0: loss = 0.692528 (* 1 = 0.692528 loss)
I0701 15:04:32.829329  2788 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0701 15:04:39.628247  2788 solver.cpp:236] Iteration 10310, loss = 0.693266
I0701 15:04:39.628299  2788 solver.cpp:252]     Train net output #0: loss = 0.692656 (* 1 = 0.692656 loss)
I0701 15:04:39.628314  2788 sgd_solver.cpp:106] Iteration 10310, lr = 0.01
I0701 15:04:46.416272  2788 solver.cpp:236] Iteration 10320, loss = 0.693251
I0701 15:04:46.416322  2788 solver.cpp:252]     Train net output #0: loss = 0.693967 (* 1 = 0.693967 loss)
I0701 15:04:46.416335  2788 sgd_solver.cpp:106] Iteration 10320, lr = 0.01
I0701 15:04:53.221429  2788 solver.cpp:236] Iteration 10330, loss = 0.693238
I0701 15:04:53.221683  2788 solver.cpp:252]     Train net output #0: loss = 0.693076 (* 1 = 0.693076 loss)
I0701 15:04:53.221711  2788 sgd_solver.cpp:106] Iteration 10330, lr = 0.01
I0701 15:05:00.032920  2788 solver.cpp:236] Iteration 10340, loss = 0.693174
I0701 15:05:00.032984  2788 solver.cpp:252]     Train net output #0: loss = 0.697364 (* 1 = 0.697364 loss)
I0701 15:05:00.032999  2788 sgd_solver.cpp:106] Iteration 10340, lr = 0.01
I0701 15:05:06.829746  2788 solver.cpp:236] Iteration 10350, loss = 0.693551
I0701 15:05:06.829802  2788 solver.cpp:252]     Train net output #0: loss = 0.693155 (* 1 = 0.693155 loss)
I0701 15:05:06.829816  2788 sgd_solver.cpp:106] Iteration 10350, lr = 0.01
I0701 15:05:13.638203  2788 solver.cpp:236] Iteration 10360, loss = 0.693452
I0701 15:05:13.638254  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 15:05:13.638268  2788 sgd_solver.cpp:106] Iteration 10360, lr = 0.01
I0701 15:05:20.452189  2788 solver.cpp:236] Iteration 10370, loss = 0.693296
I0701 15:05:20.452261  2788 solver.cpp:252]     Train net output #0: loss = 0.693724 (* 1 = 0.693724 loss)
I0701 15:05:20.452281  2788 sgd_solver.cpp:106] Iteration 10370, lr = 0.01
I0701 15:05:27.237869  2788 solver.cpp:236] Iteration 10380, loss = 0.693914
I0701 15:05:27.238065  2788 solver.cpp:252]     Train net output #0: loss = 0.693776 (* 1 = 0.693776 loss)
I0701 15:05:27.238112  2788 sgd_solver.cpp:106] Iteration 10380, lr = 0.01
I0701 15:05:34.040904  2788 solver.cpp:236] Iteration 10390, loss = 0.694014
I0701 15:05:34.040964  2788 solver.cpp:252]     Train net output #0: loss = 0.694703 (* 1 = 0.694703 loss)
I0701 15:05:34.040985  2788 sgd_solver.cpp:106] Iteration 10390, lr = 0.01
I0701 15:05:40.844203  2788 solver.cpp:236] Iteration 10400, loss = 0.69361
I0701 15:05:40.844257  2788 solver.cpp:252]     Train net output #0: loss = 0.693444 (* 1 = 0.693444 loss)
I0701 15:05:40.844276  2788 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0701 15:05:47.648418  2788 solver.cpp:236] Iteration 10410, loss = 0.693817
I0701 15:05:47.648483  2788 solver.cpp:252]     Train net output #0: loss = 0.692631 (* 1 = 0.692631 loss)
I0701 15:05:47.648496  2788 sgd_solver.cpp:106] Iteration 10410, lr = 0.01
I0701 15:05:54.446892  2788 solver.cpp:236] Iteration 10420, loss = 0.693967
I0701 15:05:54.446943  2788 solver.cpp:252]     Train net output #0: loss = 0.693813 (* 1 = 0.693813 loss)
I0701 15:05:54.446956  2788 sgd_solver.cpp:106] Iteration 10420, lr = 0.01
I0701 15:06:01.235373  2788 solver.cpp:236] Iteration 10430, loss = 0.693201
I0701 15:06:01.235631  2788 solver.cpp:252]     Train net output #0: loss = 0.692208 (* 1 = 0.692208 loss)
I0701 15:06:01.235647  2788 sgd_solver.cpp:106] Iteration 10430, lr = 0.01
I0701 15:06:08.035142  2788 solver.cpp:236] Iteration 10440, loss = 0.693212
I0701 15:06:08.035188  2788 solver.cpp:252]     Train net output #0: loss = 0.693196 (* 1 = 0.693196 loss)
I0701 15:06:08.035202  2788 sgd_solver.cpp:106] Iteration 10440, lr = 0.01
I0701 15:06:14.836580  2788 solver.cpp:236] Iteration 10450, loss = 0.693331
I0701 15:06:14.836642  2788 solver.cpp:252]     Train net output #0: loss = 0.694199 (* 1 = 0.694199 loss)
I0701 15:06:14.836657  2788 sgd_solver.cpp:106] Iteration 10450, lr = 0.01
I0701 15:06:21.635753  2788 solver.cpp:236] Iteration 10460, loss = 0.693172
I0701 15:06:21.635807  2788 solver.cpp:252]     Train net output #0: loss = 0.6931 (* 1 = 0.6931 loss)
I0701 15:06:21.635828  2788 sgd_solver.cpp:106] Iteration 10460, lr = 0.01
I0701 15:06:28.436583  2788 solver.cpp:236] Iteration 10470, loss = 0.693125
I0701 15:06:28.436630  2788 solver.cpp:252]     Train net output #0: loss = 0.692062 (* 1 = 0.692062 loss)
I0701 15:06:28.436643  2788 sgd_solver.cpp:106] Iteration 10470, lr = 0.01
I0701 15:06:35.233085  2788 solver.cpp:236] Iteration 10480, loss = 0.693246
I0701 15:06:35.233317  2788 solver.cpp:252]     Train net output #0: loss = 0.691216 (* 1 = 0.691216 loss)
I0701 15:06:35.233335  2788 sgd_solver.cpp:106] Iteration 10480, lr = 0.01
I0701 15:06:42.046303  2788 solver.cpp:236] Iteration 10490, loss = 0.693214
I0701 15:06:42.046356  2788 solver.cpp:252]     Train net output #0: loss = 0.692487 (* 1 = 0.692487 loss)
I0701 15:06:42.046371  2788 sgd_solver.cpp:106] Iteration 10490, lr = 0.01
I0701 15:06:48.141891  2788 solver.cpp:340] Iteration 10500, Testing net (#0)
I0701 15:06:59.841995  2788 solver.cpp:408]     Test net output #0: accuracy = 0.496563
I0701 15:06:59.842044  2788 solver.cpp:408]     Test net output #1: loss = 0.693562 (* 1 = 0.693562 loss)
I0701 15:07:00.012285  2788 solver.cpp:236] Iteration 10500, loss = 0.693219
I0701 15:07:00.012331  2788 solver.cpp:252]     Train net output #0: loss = 0.693405 (* 1 = 0.693405 loss)
I0701 15:07:00.012348  2788 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0701 15:07:06.793823  2788 solver.cpp:236] Iteration 10510, loss = 0.693163
I0701 15:07:06.793987  2788 solver.cpp:252]     Train net output #0: loss = 0.692324 (* 1 = 0.692324 loss)
I0701 15:07:06.794001  2788 sgd_solver.cpp:106] Iteration 10510, lr = 0.01
I0701 15:07:13.579507  2788 solver.cpp:236] Iteration 10520, loss = 0.693291
I0701 15:07:13.579550  2788 solver.cpp:252]     Train net output #0: loss = 0.693255 (* 1 = 0.693255 loss)
I0701 15:07:13.579562  2788 sgd_solver.cpp:106] Iteration 10520, lr = 0.01
I0701 15:07:20.367790  2788 solver.cpp:236] Iteration 10530, loss = 0.693374
I0701 15:07:20.367844  2788 solver.cpp:252]     Train net output #0: loss = 0.691758 (* 1 = 0.691758 loss)
I0701 15:07:20.367858  2788 sgd_solver.cpp:106] Iteration 10530, lr = 0.01
I0701 15:07:27.188141  2788 solver.cpp:236] Iteration 10540, loss = 0.693421
I0701 15:07:27.188199  2788 solver.cpp:252]     Train net output #0: loss = 0.692049 (* 1 = 0.692049 loss)
I0701 15:07:27.188212  2788 sgd_solver.cpp:106] Iteration 10540, lr = 0.01
I0701 15:07:33.997913  2788 solver.cpp:236] Iteration 10550, loss = 0.69355
I0701 15:07:33.997964  2788 solver.cpp:252]     Train net output #0: loss = 0.693145 (* 1 = 0.693145 loss)
I0701 15:07:33.997978  2788 sgd_solver.cpp:106] Iteration 10550, lr = 0.01
I0701 15:07:40.798203  2788 solver.cpp:236] Iteration 10560, loss = 0.693653
I0701 15:07:40.798375  2788 solver.cpp:252]     Train net output #0: loss = 0.693076 (* 1 = 0.693076 loss)
I0701 15:07:40.798393  2788 sgd_solver.cpp:106] Iteration 10560, lr = 0.01
I0701 15:07:47.599104  2788 solver.cpp:236] Iteration 10570, loss = 0.693711
I0701 15:07:47.599162  2788 solver.cpp:252]     Train net output #0: loss = 0.696562 (* 1 = 0.696562 loss)
I0701 15:07:47.599176  2788 sgd_solver.cpp:106] Iteration 10570, lr = 0.01
I0701 15:07:54.417551  2788 solver.cpp:236] Iteration 10580, loss = 0.693634
I0701 15:07:54.417604  2788 solver.cpp:252]     Train net output #0: loss = 0.69306 (* 1 = 0.69306 loss)
I0701 15:07:54.417619  2788 sgd_solver.cpp:106] Iteration 10580, lr = 0.01
I0701 15:08:01.212893  2788 solver.cpp:236] Iteration 10590, loss = 0.693531
I0701 15:08:01.212939  2788 solver.cpp:252]     Train net output #0: loss = 0.691321 (* 1 = 0.691321 loss)
I0701 15:08:01.212952  2788 sgd_solver.cpp:106] Iteration 10590, lr = 0.01
I0701 15:08:08.014935  2788 solver.cpp:236] Iteration 10600, loss = 0.693415
I0701 15:08:08.014979  2788 solver.cpp:252]     Train net output #0: loss = 0.693741 (* 1 = 0.693741 loss)
I0701 15:08:08.014993  2788 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0701 15:08:14.829607  2788 solver.cpp:236] Iteration 10610, loss = 0.693407
I0701 15:08:14.829856  2788 solver.cpp:252]     Train net output #0: loss = 0.69255 (* 1 = 0.69255 loss)
I0701 15:08:14.829874  2788 sgd_solver.cpp:106] Iteration 10610, lr = 0.01
I0701 15:08:21.638913  2788 solver.cpp:236] Iteration 10620, loss = 0.692958
I0701 15:08:21.638960  2788 solver.cpp:252]     Train net output #0: loss = 0.685918 (* 1 = 0.685918 loss)
I0701 15:08:21.638977  2788 sgd_solver.cpp:106] Iteration 10620, lr = 0.01
I0701 15:08:28.432632  2788 solver.cpp:236] Iteration 10630, loss = 0.693251
I0701 15:08:28.432674  2788 solver.cpp:252]     Train net output #0: loss = 0.688586 (* 1 = 0.688586 loss)
I0701 15:08:28.432684  2788 sgd_solver.cpp:106] Iteration 10630, lr = 0.01
I0701 15:08:35.223809  2788 solver.cpp:236] Iteration 10640, loss = 0.693508
I0701 15:08:35.223875  2788 solver.cpp:252]     Train net output #0: loss = 0.692974 (* 1 = 0.692974 loss)
I0701 15:08:35.223896  2788 sgd_solver.cpp:106] Iteration 10640, lr = 0.01
I0701 15:08:42.048132  2788 solver.cpp:236] Iteration 10650, loss = 0.693407
I0701 15:08:42.048187  2788 solver.cpp:252]     Train net output #0: loss = 0.693513 (* 1 = 0.693513 loss)
I0701 15:08:42.048200  2788 sgd_solver.cpp:106] Iteration 10650, lr = 0.01
I0701 15:08:48.834455  2788 solver.cpp:236] Iteration 10660, loss = 0.693425
I0701 15:08:48.834631  2788 solver.cpp:252]     Train net output #0: loss = 0.692825 (* 1 = 0.692825 loss)
I0701 15:08:48.834647  2788 sgd_solver.cpp:106] Iteration 10660, lr = 0.01
I0701 15:08:55.645879  2788 solver.cpp:236] Iteration 10670, loss = 0.693673
I0701 15:08:55.645936  2788 solver.cpp:252]     Train net output #0: loss = 0.69232 (* 1 = 0.69232 loss)
I0701 15:08:55.645951  2788 sgd_solver.cpp:106] Iteration 10670, lr = 0.01
I0701 15:09:02.450225  2788 solver.cpp:236] Iteration 10680, loss = 0.693525
I0701 15:09:02.450275  2788 solver.cpp:252]     Train net output #0: loss = 0.694307 (* 1 = 0.694307 loss)
I0701 15:09:02.450290  2788 sgd_solver.cpp:106] Iteration 10680, lr = 0.01
I0701 15:09:09.249094  2788 solver.cpp:236] Iteration 10690, loss = 0.693323
I0701 15:09:09.249143  2788 solver.cpp:252]     Train net output #0: loss = 0.69343 (* 1 = 0.69343 loss)
I0701 15:09:09.249158  2788 sgd_solver.cpp:106] Iteration 10690, lr = 0.01
I0701 15:09:16.059943  2788 solver.cpp:236] Iteration 10700, loss = 0.69329
I0701 15:09:16.060034  2788 solver.cpp:252]     Train net output #0: loss = 0.693612 (* 1 = 0.693612 loss)
I0701 15:09:16.060057  2788 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0701 15:09:22.861804  2788 solver.cpp:236] Iteration 10710, loss = 0.69327
I0701 15:09:22.862020  2788 solver.cpp:252]     Train net output #0: loss = 0.692643 (* 1 = 0.692643 loss)
I0701 15:09:22.862036  2788 sgd_solver.cpp:106] Iteration 10710, lr = 0.01
I0701 15:09:29.679908  2788 solver.cpp:236] Iteration 10720, loss = 0.69337
I0701 15:09:29.679970  2788 solver.cpp:252]     Train net output #0: loss = 0.693092 (* 1 = 0.693092 loss)
I0701 15:09:29.679985  2788 sgd_solver.cpp:106] Iteration 10720, lr = 0.01
I0701 15:09:36.492331  2788 solver.cpp:236] Iteration 10730, loss = 0.6933
I0701 15:09:36.492394  2788 solver.cpp:252]     Train net output #0: loss = 0.692563 (* 1 = 0.692563 loss)
I0701 15:09:36.492408  2788 sgd_solver.cpp:106] Iteration 10730, lr = 0.01
I0701 15:09:43.298957  2788 solver.cpp:236] Iteration 10740, loss = 0.693234
I0701 15:09:43.298996  2788 solver.cpp:252]     Train net output #0: loss = 0.694171 (* 1 = 0.694171 loss)
I0701 15:09:43.299010  2788 sgd_solver.cpp:106] Iteration 10740, lr = 0.01
I0701 15:09:49.456019  2788 solver.cpp:340] Iteration 10750, Testing net (#0)
I0701 15:10:01.563673  2788 solver.cpp:408]     Test net output #0: accuracy = 0.49875
I0701 15:10:01.563943  2788 solver.cpp:408]     Test net output #1: loss = 0.693259 (* 1 = 0.693259 loss)
I0701 15:10:01.746274  2788 solver.cpp:236] Iteration 10750, loss = 0.693298
I0701 15:10:01.746323  2788 solver.cpp:252]     Train net output #0: loss = 0.69204 (* 1 = 0.69204 loss)
I0701 15:10:01.746340  2788 sgd_solver.cpp:106] Iteration 10750, lr = 0.01
I0701 15:10:08.542143  2788 solver.cpp:236] Iteration 10760, loss = 0.693302
I0701 15:10:08.542191  2788 solver.cpp:252]     Train net output #0: loss = 0.693108 (* 1 = 0.693108 loss)
I0701 15:10:08.542206  2788 sgd_solver.cpp:106] Iteration 10760, lr = 0.01
I0701 15:10:15.328377  2788 solver.cpp:236] Iteration 10770, loss = 0.693225
I0701 15:10:15.328434  2788 solver.cpp:252]     Train net output #0: loss = 0.693818 (* 1 = 0.693818 loss)
I0701 15:10:15.328454  2788 sgd_solver.cpp:106] Iteration 10770, lr = 0.01
I0701 15:10:22.137524  2788 solver.cpp:236] Iteration 10780, loss = 0.693268
I0701 15:10:22.137576  2788 solver.cpp:252]     Train net output #0: loss = 0.693032 (* 1 = 0.693032 loss)
I0701 15:10:22.137590  2788 sgd_solver.cpp:106] Iteration 10780, lr = 0.01
I0701 15:10:28.930896  2788 solver.cpp:236] Iteration 10790, loss = 0.693351
I0701 15:10:28.930946  2788 solver.cpp:252]     Train net output #0: loss = 0.69637 (* 1 = 0.69637 loss)
I0701 15:10:28.930960  2788 sgd_solver.cpp:106] Iteration 10790, lr = 0.01
I0701 15:10:35.744175  2788 solver.cpp:236] Iteration 10800, loss = 0.693345
I0701 15:10:35.748505  2788 solver.cpp:252]     Train net output #0: loss = 0.69389 (* 1 = 0.69389 loss)
I0701 15:10:35.748525  2788 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0701 15:10:42.549088  2788 solver.cpp:236] Iteration 10810, loss = 0.69357
I0701 15:10:42.549136  2788 solver.cpp:252]     Train net output #0: loss = 0.69408 (* 1 = 0.69408 loss)
I0701 15:10:42.549150  2788 sgd_solver.cpp:106] Iteration 10810, lr = 0.01
I0701 15:10:49.364226  2788 solver.cpp:236] Iteration 10820, loss = 0.693689
I0701 15:10:49.364284  2788 solver.cpp:252]     Train net output #0: loss = 0.691915 (* 1 = 0.691915 loss)
I0701 15:10:49.364298  2788 sgd_solver.cpp:106] Iteration 10820, lr = 0.01
I0701 15:10:56.173458  2788 solver.cpp:236] Iteration 10830, loss = 0.69363
I0701 15:10:56.173504  2788 solver.cpp:252]     Train net output #0: loss = 0.692723 (* 1 = 0.692723 loss)
I0701 15:10:56.173521  2788 sgd_solver.cpp:106] Iteration 10830, lr = 0.01
I0701 15:11:02.961042  2788 solver.cpp:236] Iteration 10840, loss = 0.693632
I0701 15:11:02.961105  2788 solver.cpp:252]     Train net output #0: loss = 0.69334 (* 1 = 0.69334 loss)
I0701 15:11:02.961125  2788 sgd_solver.cpp:106] Iteration 10840, lr = 0.01
I0701 15:11:09.763730  2788 solver.cpp:236] Iteration 10850, loss = 0.693606
I0701 15:11:09.763903  2788 solver.cpp:252]     Train net output #0: loss = 0.693282 (* 1 = 0.693282 loss)
I0701 15:11:09.763932  2788 sgd_solver.cpp:106] Iteration 10850, lr = 0.01
I0701 15:11:16.579836  2788 solver.cpp:236] Iteration 10860, loss = 0.693345
I0701 15:11:16.579905  2788 solver.cpp:252]     Train net output #0: loss = 0.693027 (* 1 = 0.693027 loss)
I0701 15:11:16.579927  2788 sgd_solver.cpp:106] Iteration 10860, lr = 0.01
I0701 15:11:23.379837  2788 solver.cpp:236] Iteration 10870, loss = 0.693189
I0701 15:11:23.379889  2788 solver.cpp:252]     Train net output #0: loss = 0.69654 (* 1 = 0.69654 loss)
I0701 15:11:23.379904  2788 sgd_solver.cpp:106] Iteration 10870, lr = 0.01
I0701 15:11:30.194232  2788 solver.cpp:236] Iteration 10880, loss = 0.693021
I0701 15:11:30.194283  2788 solver.cpp:252]     Train net output #0: loss = 0.6895 (* 1 = 0.6895 loss)
I0701 15:11:30.194299  2788 sgd_solver.cpp:106] Iteration 10880, lr = 0.01
I0701 15:11:36.999192  2788 solver.cpp:236] Iteration 10890, loss = 0.693075
I0701 15:11:36.999250  2788 solver.cpp:252]     Train net output #0: loss = 0.692659 (* 1 = 0.692659 loss)
I0701 15:11:36.999264  2788 sgd_solver.cpp:106] Iteration 10890, lr = 0.01
I0701 15:11:43.805858  2788 solver.cpp:236] Iteration 10900, loss = 0.693315
I0701 15:11:43.806186  2788 solver.cpp:252]     Train net output #0: loss = 0.693471 (* 1 = 0.693471 loss)
I0701 15:11:43.806205  2788 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0701 15:11:50.597375  2788 solver.cpp:236] Iteration 10910, loss = 0.693419
I0701 15:11:50.597422  2788 solver.cpp:252]     Train net output #0: loss = 0.694393 (* 1 = 0.694393 loss)
I0701 15:11:50.597436  2788 sgd_solver.cpp:106] Iteration 10910, lr = 0.01
I0701 15:11:57.406489  2788 solver.cpp:236] Iteration 10920, loss = 0.693521
I0701 15:11:57.406548  2788 solver.cpp:252]     Train net output #0: loss = 0.692828 (* 1 = 0.692828 loss)
I0701 15:11:57.406563  2788 sgd_solver.cpp:106] Iteration 10920, lr = 0.01
I0701 15:12:04.239784  2788 solver.cpp:236] Iteration 10930, loss = 0.693792
I0701 15:12:04.239835  2788 solver.cpp:252]     Train net output #0: loss = 0.693295 (* 1 = 0.693295 loss)
I0701 15:12:04.239848  2788 sgd_solver.cpp:106] Iteration 10930, lr = 0.01
I0701 15:12:11.045292  2788 solver.cpp:236] Iteration 10940, loss = 0.693715
I0701 15:12:11.045341  2788 solver.cpp:252]     Train net output #0: loss = 0.693113 (* 1 = 0.693113 loss)
I0701 15:12:11.045356  2788 sgd_solver.cpp:106] Iteration 10940, lr = 0.01
I0701 15:12:17.851403  2788 solver.cpp:236] Iteration 10950, loss = 0.693487
I0701 15:12:17.851611  2788 solver.cpp:252]     Train net output #0: loss = 0.693325 (* 1 = 0.693325 loss)
I0701 15:12:17.851626  2788 sgd_solver.cpp:106] Iteration 10950, lr = 0.01
I0701 15:12:24.665256  2788 solver.cpp:236] Iteration 10960, loss = 0.69338
I0701 15:12:24.665313  2788 solver.cpp:252]     Train net output #0: loss = 0.692952 (* 1 = 0.692952 loss)
I0701 15:12:24.665328  2788 sgd_solver.cpp:106] Iteration 10960, lr = 0.01
I0701 15:12:31.473803  2788 solver.cpp:236] Iteration 10970, loss = 0.693413
I0701 15:12:31.473857  2788 solver.cpp:252]     Train net output #0: loss = 0.693551 (* 1 = 0.693551 loss)
I0701 15:12:31.473871  2788 sgd_solver.cpp:106] Iteration 10970, lr = 0.01
I0701 15:12:38.280876  2788 solver.cpp:236] Iteration 10980, loss = 0.693301
I0701 15:12:38.280927  2788 solver.cpp:252]     Train net output #0: loss = 0.693246 (* 1 = 0.693246 loss)
I0701 15:12:38.280941  2788 sgd_solver.cpp:106] Iteration 10980, lr = 0.01
I0701 15:12:45.084926  2788 solver.cpp:236] Iteration 10990, loss = 0.693268
I0701 15:12:45.084974  2788 solver.cpp:252]     Train net output #0: loss = 0.692813 (* 1 = 0.692813 loss)
I0701 15:12:45.084987  2788 sgd_solver.cpp:106] Iteration 10990, lr = 0.01
I0701 15:12:51.226171  2788 solver.cpp:340] Iteration 11000, Testing net (#0)
I0701 15:13:03.097668  2788 solver.cpp:408]     Test net output #0: accuracy = 0.487812
I0701 15:13:03.097721  2788 solver.cpp:408]     Test net output #1: loss = 0.693553 (* 1 = 0.693553 loss)
I0701 15:13:03.276357  2788 solver.cpp:236] Iteration 11000, loss = 0.693291
I0701 15:13:03.276412  2788 solver.cpp:252]     Train net output #0: loss = 0.694053 (* 1 = 0.694053 loss)
I0701 15:13:03.276432  2788 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0701 15:13:10.061930  2788 solver.cpp:236] Iteration 11010, loss = 0.693303
I0701 15:13:10.061980  2788 solver.cpp:252]     Train net output #0: loss = 0.694224 (* 1 = 0.694224 loss)
I0701 15:13:10.061995  2788 sgd_solver.cpp:106] Iteration 11010, lr = 0.01
I0701 15:13:16.850889  2788 solver.cpp:236] Iteration 11020, loss = 0.693256
I0701 15:13:16.850944  2788 solver.cpp:252]     Train net output #0: loss = 0.693461 (* 1 = 0.693461 loss)
I0701 15:13:16.850958  2788 sgd_solver.cpp:106] Iteration 11020, lr = 0.01
I0701 15:13:23.633033  2788 solver.cpp:236] Iteration 11030, loss = 0.693177
I0701 15:13:23.633292  2788 solver.cpp:252]     Train net output #0: loss = 0.692002 (* 1 = 0.692002 loss)
I0701 15:13:23.633309  2788 sgd_solver.cpp:106] Iteration 11030, lr = 0.01
I0701 15:13:30.428827  2788 solver.cpp:236] Iteration 11040, loss = 0.693334
I0701 15:13:30.428885  2788 solver.cpp:252]     Train net output #0: loss = 0.693022 (* 1 = 0.693022 loss)
I0701 15:13:30.428900  2788 sgd_solver.cpp:106] Iteration 11040, lr = 0.01
I0701 15:13:37.228647  2788 solver.cpp:236] Iteration 11050, loss = 0.693345
I0701 15:13:37.228695  2788 solver.cpp:252]     Train net output #0: loss = 0.693034 (* 1 = 0.693034 loss)
I0701 15:13:37.228708  2788 sgd_solver.cpp:106] Iteration 11050, lr = 0.01
I0701 15:13:44.016070  2788 solver.cpp:236] Iteration 11060, loss = 0.69337
I0701 15:13:44.016121  2788 solver.cpp:252]     Train net output #0: loss = 0.693511 (* 1 = 0.693511 loss)
I0701 15:13:44.016135  2788 sgd_solver.cpp:106] Iteration 11060, lr = 0.01
I0701 15:13:50.812137  2788 solver.cpp:236] Iteration 11070, loss = 0.693385
I0701 15:13:50.812187  2788 solver.cpp:252]     Train net output #0: loss = 0.693406 (* 1 = 0.693406 loss)
I0701 15:13:50.812202  2788 sgd_solver.cpp:106] Iteration 11070, lr = 0.01
I0701 15:13:57.612581  2788 solver.cpp:236] Iteration 11080, loss = 0.693479
I0701 15:13:57.612776  2788 solver.cpp:252]     Train net output #0: loss = 0.692766 (* 1 = 0.692766 loss)
I0701 15:13:57.612793  2788 sgd_solver.cpp:106] Iteration 11080, lr = 0.01
I0701 15:14:04.410177  2788 solver.cpp:236] Iteration 11090, loss = 0.69342
I0701 15:14:04.410251  2788 solver.cpp:252]     Train net output #0: loss = 0.694311 (* 1 = 0.694311 loss)
I0701 15:14:04.410275  2788 sgd_solver.cpp:106] Iteration 11090, lr = 0.01
I0701 15:14:11.205103  2788 solver.cpp:236] Iteration 11100, loss = 0.693379
I0701 15:14:11.205160  2788 solver.cpp:252]     Train net output #0: loss = 0.692274 (* 1 = 0.692274 loss)
I0701 15:14:11.205174  2788 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0701 15:14:18.008208  2788 solver.cpp:236] Iteration 11110, loss = 0.693131
I0701 15:14:18.008268  2788 solver.cpp:252]     Train net output #0: loss = 0.697134 (* 1 = 0.697134 loss)
I0701 15:14:18.008282  2788 sgd_solver.cpp:106] Iteration 11110, lr = 0.01
I0701 15:14:24.796088  2788 solver.cpp:236] Iteration 11120, loss = 0.693114
I0701 15:14:24.796147  2788 solver.cpp:252]     Train net output #0: loss = 0.694762 (* 1 = 0.694762 loss)
I0701 15:14:24.796162  2788 sgd_solver.cpp:106] Iteration 11120, lr = 0.01
I0701 15:14:31.592775  2788 solver.cpp:236] Iteration 11130, loss = 0.693382
I0701 15:14:31.592965  2788 solver.cpp:252]     Train net output #0: loss = 0.693661 (* 1 = 0.693661 loss)
I0701 15:14:31.592984  2788 sgd_solver.cpp:106] Iteration 11130, lr = 0.01
I0701 15:14:38.399233  2788 solver.cpp:236] Iteration 11140, loss = 0.693369
I0701 15:14:38.399283  2788 solver.cpp:252]     Train net output #0: loss = 0.693327 (* 1 = 0.693327 loss)
I0701 15:14:38.399297  2788 sgd_solver.cpp:106] Iteration 11140, lr = 0.01
I0701 15:14:45.177930  2788 solver.cpp:236] Iteration 11150, loss = 0.693263
I0701 15:14:45.177986  2788 solver.cpp:252]     Train net output #0: loss = 0.691086 (* 1 = 0.691086 loss)
I0701 15:14:45.178000  2788 sgd_solver.cpp:106] Iteration 11150, lr = 0.01
I0701 15:14:51.983167  2788 solver.cpp:236] Iteration 11160, loss = 0.69352
I0701 15:14:51.983230  2788 solver.cpp:252]     Train net output #0: loss = 0.697949 (* 1 = 0.697949 loss)
I0701 15:14:51.983245  2788 sgd_solver.cpp:106] Iteration 11160, lr = 0.01
I0701 15:14:58.788079  2788 solver.cpp:236] Iteration 11170, loss = 0.693529
I0701 15:14:58.788133  2788 solver.cpp:252]     Train net output #0: loss = 0.68885 (* 1 = 0.68885 loss)
I0701 15:14:58.788147  2788 sgd_solver.cpp:106] Iteration 11170, lr = 0.01
I0701 15:15:05.578536  2788 solver.cpp:236] Iteration 11180, loss = 0.69334
I0701 15:15:05.578708  2788 solver.cpp:252]     Train net output #0: loss = 0.694009 (* 1 = 0.694009 loss)
I0701 15:15:05.578737  2788 sgd_solver.cpp:106] Iteration 11180, lr = 0.01
I0701 15:15:12.384997  2788 solver.cpp:236] Iteration 11190, loss = 0.693301
I0701 15:15:12.385042  2788 solver.cpp:252]     Train net output #0: loss = 0.695926 (* 1 = 0.695926 loss)
I0701 15:15:12.385056  2788 sgd_solver.cpp:106] Iteration 11190, lr = 0.01
I0701 15:15:19.182714  2788 solver.cpp:236] Iteration 11200, loss = 0.69329
I0701 15:15:19.182773  2788 solver.cpp:252]     Train net output #0: loss = 0.687818 (* 1 = 0.687818 loss)
I0701 15:15:19.182788  2788 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0701 15:15:25.983853  2788 solver.cpp:236] Iteration 11210, loss = 0.693262
I0701 15:15:25.983902  2788 solver.cpp:252]     Train net output #0: loss = 0.692659 (* 1 = 0.692659 loss)
I0701 15:15:25.983916  2788 sgd_solver.cpp:106] Iteration 11210, lr = 0.01
I0701 15:15:32.779889  2788 solver.cpp:236] Iteration 11220, loss = 0.69331
I0701 15:15:32.779939  2788 solver.cpp:252]     Train net output #0: loss = 0.690502 (* 1 = 0.690502 loss)
I0701 15:15:32.779953  2788 sgd_solver.cpp:106] Iteration 11220, lr = 0.01
I0701 15:15:39.572269  2788 solver.cpp:236] Iteration 11230, loss = 0.693252
I0701 15:15:39.572389  2788 solver.cpp:252]     Train net output #0: loss = 0.693262 (* 1 = 0.693262 loss)
I0701 15:15:39.572415  2788 sgd_solver.cpp:106] Iteration 11230, lr = 0.01
I0701 15:15:46.371310  2788 solver.cpp:236] Iteration 11240, loss = 0.693202
I0701 15:15:46.371357  2788 solver.cpp:252]     Train net output #0: loss = 0.692584 (* 1 = 0.692584 loss)
I0701 15:15:46.371371  2788 sgd_solver.cpp:106] Iteration 11240, lr = 0.01
I0701 15:15:52.504609  2788 solver.cpp:340] Iteration 11250, Testing net (#0)
I0701 15:16:04.287868  2788 solver.cpp:408]     Test net output #0: accuracy = 0.50125
I0701 15:16:04.287925  2788 solver.cpp:408]     Test net output #1: loss = 0.693392 (* 1 = 0.693392 loss)
I0701 15:16:04.463037  2788 solver.cpp:236] Iteration 11250, loss = 0.693311
I0701 15:16:04.463105  2788 solver.cpp:252]     Train net output #0: loss = 0.693453 (* 1 = 0.693453 loss)
I0701 15:16:04.463127  2788 sgd_solver.cpp:106] Iteration 11250, lr = 0.01
I0701 15:16:11.246088  2788 solver.cpp:236] Iteration 11260, loss = 0.693138
I0701 15:16:11.246258  2788 solver.cpp:252]     Train net output #0: loss = 0.691186 (* 1 = 0.691186 loss)
I0701 15:16:11.246271  2788 sgd_solver.cpp:106] Iteration 11260, lr = 0.01
I0701 15:16:18.016152  2788 solver.cpp:236] Iteration 11270, loss = 0.693362
I0701 15:16:18.016207  2788 solver.cpp:252]     Train net output #0: loss = 0.694192 (* 1 = 0.694192 loss)
I0701 15:16:18.016222  2788 sgd_solver.cpp:106] Iteration 11270, lr = 0.01
I0701 15:16:24.803581  2788 solver.cpp:236] Iteration 11280, loss = 0.693359
I0701 15:16:24.803637  2788 solver.cpp:252]     Train net output #0: loss = 0.691436 (* 1 = 0.691436 loss)
I0701 15:16:24.803652  2788 sgd_solver.cpp:106] Iteration 11280, lr = 0.01
I0701 15:16:31.608814  2788 solver.cpp:236] Iteration 11290, loss = 0.693494
I0701 15:16:31.608855  2788 solver.cpp:252]     Train net output #0: loss = 0.695888 (* 1 = 0.695888 loss)
I0701 15:16:31.608868  2788 sgd_solver.cpp:106] Iteration 11290, lr = 0.01
I0701 15:16:38.407073  2788 solver.cpp:236] Iteration 11300, loss = 0.693606
I0701 15:16:38.407124  2788 solver.cpp:252]     Train net output #0: loss = 0.694504 (* 1 = 0.694504 loss)
I0701 15:16:38.407137  2788 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0701 15:16:45.200412  2788 solver.cpp:236] Iteration 11310, loss = 0.693913
I0701 15:16:45.200637  2788 solver.cpp:252]     Train net output #0: loss = 0.698313 (* 1 = 0.698313 loss)
I0701 15:16:45.200656  2788 sgd_solver.cpp:106] Iteration 11310, lr = 0.01
I0701 15:16:52.001796  2788 solver.cpp:236] Iteration 11320, loss = 0.693681
I0701 15:16:52.001857  2788 solver.cpp:252]     Train net output #0: loss = 0.696038 (* 1 = 0.696038 loss)
I0701 15:16:52.001870  2788 sgd_solver.cpp:106] Iteration 11320, lr = 0.01
I0701 15:16:58.801188  2788 solver.cpp:236] Iteration 11330, loss = 0.693576
I0701 15:16:58.801235  2788 solver.cpp:252]     Train net output #0: loss = 0.693026 (* 1 = 0.693026 loss)
I0701 15:16:58.801250  2788 sgd_solver.cpp:106] Iteration 11330, lr = 0.01
I0701 15:17:05.587993  2788 solver.cpp:236] Iteration 11340, loss = 0.69346
I0701 15:17:05.588044  2788 solver.cpp:252]     Train net output #0: loss = 0.692918 (* 1 = 0.692918 loss)
I0701 15:17:05.588058  2788 sgd_solver.cpp:106] Iteration 11340, lr = 0.01
I0701 15:17:12.391402  2788 solver.cpp:236] Iteration 11350, loss = 0.693366
I0701 15:17:12.391472  2788 solver.cpp:252]     Train net output #0: loss = 0.69254 (* 1 = 0.69254 loss)
I0701 15:17:12.391494  2788 sgd_solver.cpp:106] Iteration 11350, lr = 0.01
I0701 15:17:19.169692  2788 solver.cpp:236] Iteration 11360, loss = 0.693316
I0701 15:17:19.169955  2788 solver.cpp:252]     Train net output #0: loss = 0.697285 (* 1 = 0.697285 loss)
I0701 15:17:19.169975  2788 sgd_solver.cpp:106] Iteration 11360, lr = 0.01
I0701 15:17:25.983376  2788 solver.cpp:236] Iteration 11370, loss = 0.693114
I0701 15:17:25.983433  2788 solver.cpp:252]     Train net output #0: loss = 0.693451 (* 1 = 0.693451 loss)
I0701 15:17:25.983448  2788 sgd_solver.cpp:106] Iteration 11370, lr = 0.01
I0701 15:17:32.768059  2788 solver.cpp:236] Iteration 11380, loss = 0.693253
I0701 15:17:32.768113  2788 solver.cpp:252]     Train net output #0: loss = 0.691339 (* 1 = 0.691339 loss)
I0701 15:17:32.768127  2788 sgd_solver.cpp:106] Iteration 11380, lr = 0.01
I0701 15:17:39.576429  2788 solver.cpp:236] Iteration 11390, loss = 0.693122
I0701 15:17:39.576514  2788 solver.cpp:252]     Train net output #0: loss = 0.692221 (* 1 = 0.692221 loss)
I0701 15:17:39.576534  2788 sgd_solver.cpp:106] Iteration 11390, lr = 0.01
I0701 15:17:46.387126  2788 solver.cpp:236] Iteration 11400, loss = 0.692954
I0701 15:17:46.387189  2788 solver.cpp:252]     Train net output #0: loss = 0.695638 (* 1 = 0.695638 loss)
I0701 15:17:46.387210  2788 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0701 15:17:53.186319  2788 solver.cpp:236] Iteration 11410, loss = 0.693176
I0701 15:17:53.186523  2788 solver.cpp:252]     Train net output #0: loss = 0.692374 (* 1 = 0.692374 loss)
I0701 15:17:53.186542  2788 sgd_solver.cpp:106] Iteration 11410, lr = 0.01
I0701 15:17:59.993258  2788 solver.cpp:236] Iteration 11420, loss = 0.693303
I0701 15:17:59.993314  2788 solver.cpp:252]     Train net output #0: loss = 0.693854 (* 1 = 0.693854 loss)
I0701 15:17:59.993330  2788 sgd_solver.cpp:106] Iteration 11420, lr = 0.01
I0701 15:18:06.796223  2788 solver.cpp:236] Iteration 11430, loss = 0.69325
I0701 15:18:06.796280  2788 solver.cpp:252]     Train net output #0: loss = 0.694443 (* 1 = 0.694443 loss)
I0701 15:18:06.796294  2788 sgd_solver.cpp:106] Iteration 11430, lr = 0.01
I0701 15:18:13.612182  2788 solver.cpp:236] Iteration 11440, loss = 0.693458
I0701 15:18:13.612237  2788 solver.cpp:252]     Train net output #0: loss = 0.693361 (* 1 = 0.693361 loss)
I0701 15:18:13.612256  2788 sgd_solver.cpp:106] Iteration 11440, lr = 0.01
I0701 15:18:20.413029  2788 solver.cpp:236] Iteration 11450, loss = 0.693635
I0701 15:18:20.413130  2788 solver.cpp:252]     Train net output #0: loss = 0.695461 (* 1 = 0.695461 loss)
I0701 15:18:20.413178  2788 sgd_solver.cpp:106] Iteration 11450, lr = 0.01
I0701 15:18:27.222667  2788 solver.cpp:236] Iteration 11460, loss = 0.693374
I0701 15:18:27.222861  2788 solver.cpp:252]     Train net output #0: loss = 0.693197 (* 1 = 0.693197 loss)
I0701 15:18:27.222887  2788 sgd_solver.cpp:106] Iteration 11460, lr = 0.01
I0701 15:18:34.025459  2788 solver.cpp:236] Iteration 11470, loss = 0.693371
I0701 15:18:34.025523  2788 solver.cpp:252]     Train net output #0: loss = 0.693267 (* 1 = 0.693267 loss)
I0701 15:18:34.025548  2788 sgd_solver.cpp:106] Iteration 11470, lr = 0.01
I0701 15:18:40.811576  2788 solver.cpp:236] Iteration 11480, loss = 0.693327
I0701 15:18:40.811619  2788 solver.cpp:252]     Train net output #0: loss = 0.69223 (* 1 = 0.69223 loss)
I0701 15:18:40.811633  2788 sgd_solver.cpp:106] Iteration 11480, lr = 0.01
I0701 15:18:47.604159  2788 solver.cpp:236] Iteration 11490, loss = 0.693197
I0701 15:18:47.604213  2788 solver.cpp:252]     Train net output #0: loss = 0.693816 (* 1 = 0.693816 loss)
I0701 15:18:47.604233  2788 sgd_solver.cpp:106] Iteration 11490, lr = 0.01
I0701 15:18:53.734405  2788 solver.cpp:340] Iteration 11500, Testing net (#0)
I0701 15:19:05.367254  2788 solver.cpp:408]     Test net output #0: accuracy = 0.501562
I0701 15:19:05.367439  2788 solver.cpp:408]     Test net output #1: loss = 0.693156 (* 1 = 0.693156 loss)
I0701 15:19:05.539682  2788 solver.cpp:236] Iteration 11500, loss = 0.693243
I0701 15:19:05.539726  2788 solver.cpp:252]     Train net output #0: loss = 0.692141 (* 1 = 0.692141 loss)
I0701 15:19:05.539741  2788 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0701 15:19:12.330464  2788 solver.cpp:236] Iteration 11510, loss = 0.69322
I0701 15:19:12.330520  2788 solver.cpp:252]     Train net output #0: loss = 0.693507 (* 1 = 0.693507 loss)
I0701 15:19:12.330540  2788 sgd_solver.cpp:106] Iteration 11510, lr = 0.01
I0701 15:19:19.108784  2788 solver.cpp:236] Iteration 11520, loss = 0.693243
I0701 15:19:19.108844  2788 solver.cpp:252]     Train net output #0: loss = 0.693256 (* 1 = 0.693256 loss)
I0701 15:19:19.108860  2788 sgd_solver.cpp:106] Iteration 11520, lr = 0.01
I0701 15:19:25.897279  2788 solver.cpp:236] Iteration 11530, loss = 0.693455
I0701 15:19:25.897325  2788 solver.cpp:252]     Train net output #0: loss = 0.695595 (* 1 = 0.695595 loss)
I0701 15:19:25.897338  2788 sgd_solver.cpp:106] Iteration 11530, lr = 0.01
I0701 15:19:32.697139  2788 solver.cpp:236] Iteration 11540, loss = 0.693555
I0701 15:19:32.697188  2788 solver.cpp:252]     Train net output #0: loss = 0.690444 (* 1 = 0.690444 loss)
I0701 15:19:32.697203  2788 sgd_solver.cpp:106] Iteration 11540, lr = 0.01
I0701 15:19:39.471573  2788 solver.cpp:236] Iteration 11550, loss = 0.69368
I0701 15:19:39.471788  2788 solver.cpp:252]     Train net output #0: loss = 0.692064 (* 1 = 0.692064 loss)
I0701 15:19:39.471807  2788 sgd_solver.cpp:106] Iteration 11550, lr = 0.01
I0701 15:19:46.271824  2788 solver.cpp:236] Iteration 11560, loss = 0.69382
I0701 15:19:46.271878  2788 solver.cpp:252]     Train net output #0: loss = 0.693743 (* 1 = 0.693743 loss)
I0701 15:19:46.271893  2788 sgd_solver.cpp:106] Iteration 11560, lr = 0.01
I0701 15:19:53.047968  2788 solver.cpp:236] Iteration 11570, loss = 0.693892
I0701 15:19:53.048022  2788 solver.cpp:252]     Train net output #0: loss = 0.69433 (* 1 = 0.69433 loss)
I0701 15:19:53.048038  2788 sgd_solver.cpp:106] Iteration 11570, lr = 0.01
I0701 15:19:59.828902  2788 solver.cpp:236] Iteration 11580, loss = 0.693768
I0701 15:19:59.828946  2788 solver.cpp:252]     Train net output #0: loss = 0.692693 (* 1 = 0.692693 loss)
I0701 15:19:59.828963  2788 sgd_solver.cpp:106] Iteration 11580, lr = 0.01
I0701 15:20:06.621698  2788 solver.cpp:236] Iteration 11590, loss = 0.693779
I0701 15:20:06.621747  2788 solver.cpp:252]     Train net output #0: loss = 0.693098 (* 1 = 0.693098 loss)
I0701 15:20:06.621764  2788 sgd_solver.cpp:106] Iteration 11590, lr = 0.01
I0701 15:20:13.412721  2788 solver.cpp:236] Iteration 11600, loss = 0.693647
I0701 15:20:13.412894  2788 solver.cpp:252]     Train net output #0: loss = 0.694198 (* 1 = 0.694198 loss)
I0701 15:20:13.412925  2788 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0701 15:20:20.224587  2788 solver.cpp:236] Iteration 11610, loss = 0.693509
I0701 15:20:20.224638  2788 solver.cpp:252]     Train net output #0: loss = 0.693978 (* 1 = 0.693978 loss)
I0701 15:20:20.224653  2788 sgd_solver.cpp:106] Iteration 11610, lr = 0.01
I0701 15:20:27.008844  2788 solver.cpp:236] Iteration 11620, loss = 0.693321
I0701 15:20:27.008900  2788 solver.cpp:252]     Train net output #0: loss = 0.692293 (* 1 = 0.692293 loss)
I0701 15:20:27.008916  2788 sgd_solver.cpp:106] Iteration 11620, lr = 0.01
I0701 15:20:33.806183  2788 solver.cpp:236] Iteration 11630, loss = 0.693394
I0701 15:20:33.806247  2788 solver.cpp:252]     Train net output #0: loss = 0.694905 (* 1 = 0.694905 loss)
I0701 15:20:33.806262  2788 sgd_solver.cpp:106] Iteration 11630, lr = 0.01
I0701 15:20:40.608229  2788 solver.cpp:236] Iteration 11640, loss = 0.693349
I0701 15:20:40.608273  2788 solver.cpp:252]     Train net output #0: loss = 0.692941 (* 1 = 0.692941 loss)
I0701 15:20:40.608288  2788 sgd_solver.cpp:106] Iteration 11640, lr = 0.01
I0701 15:20:47.396265  2788 solver.cpp:236] Iteration 11650, loss = 0.693268
I0701 15:20:47.396492  2788 solver.cpp:252]     Train net output #0: loss = 0.693607 (* 1 = 0.693607 loss)
I0701 15:20:47.396507  2788 sgd_solver.cpp:106] Iteration 11650, lr = 0.01
I0701 15:20:54.184020  2788 solver.cpp:236] Iteration 11660, loss = 0.69337
I0701 15:20:54.184079  2788 solver.cpp:252]     Train net output #0: loss = 0.692753 (* 1 = 0.692753 loss)
I0701 15:20:54.184094  2788 sgd_solver.cpp:106] Iteration 11660, lr = 0.01
I0701 15:21:00.973462  2788 solver.cpp:236] Iteration 11670, loss = 0.693471
I0701 15:21:00.973567  2788 solver.cpp:252]     Train net output #0: loss = 0.693155 (* 1 = 0.693155 loss)
I0701 15:21:00.973587  2788 sgd_solver.cpp:106] Iteration 11670, lr = 0.01
I0701 15:21:07.762792  2788 solver.cpp:236] Iteration 11680, loss = 0.693286
I0701 15:21:07.762840  2788 solver.cpp:252]     Train net output #0: loss = 0.69211 (* 1 = 0.69211 loss)
I0701 15:21:07.762857  2788 sgd_solver.cpp:106] Iteration 11680, lr = 0.01
I0701 15:21:14.560796  2788 solver.cpp:236] Iteration 11690, loss = 0.693315
I0701 15:21:14.560844  2788 solver.cpp:252]     Train net output #0: loss = 0.693042 (* 1 = 0.693042 loss)
I0701 15:21:14.560860  2788 sgd_solver.cpp:106] Iteration 11690, lr = 0.01
I0701 15:21:21.363312  2788 solver.cpp:236] Iteration 11700, loss = 0.693358
I0701 15:21:21.363577  2788 solver.cpp:252]     Train net output #0: loss = 0.694721 (* 1 = 0.694721 loss)
I0701 15:21:21.363595  2788 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0701 15:21:28.147845  2788 solver.cpp:236] Iteration 11710, loss = 0.693301
I0701 15:21:28.147897  2788 solver.cpp:252]     Train net output #0: loss = 0.693027 (* 1 = 0.693027 loss)
I0701 15:21:28.147912  2788 sgd_solver.cpp:106] Iteration 11710, lr = 0.01
I0701 15:21:34.940217  2788 solver.cpp:236] Iteration 11720, loss = 0.693346
I0701 15:21:34.940269  2788 solver.cpp:252]     Train net output #0: loss = 0.692913 (* 1 = 0.692913 loss)
I0701 15:21:34.940287  2788 sgd_solver.cpp:106] Iteration 11720, lr = 0.01
I0701 15:21:41.747246  2788 solver.cpp:236] Iteration 11730, loss = 0.693401
I0701 15:21:41.747294  2788 solver.cpp:252]     Train net output #0: loss = 0.693643 (* 1 = 0.693643 loss)
I0701 15:21:41.747308  2788 sgd_solver.cpp:106] Iteration 11730, lr = 0.01
I0701 15:21:48.535459  2788 solver.cpp:236] Iteration 11740, loss = 0.693341
I0701 15:21:48.535517  2788 solver.cpp:252]     Train net output #0: loss = 0.693768 (* 1 = 0.693768 loss)
I0701 15:21:48.535532  2788 sgd_solver.cpp:106] Iteration 11740, lr = 0.01
I0701 15:21:54.672014  2788 solver.cpp:340] Iteration 11750, Testing net (#0)
I0701 15:22:06.394527  2788 solver.cpp:408]     Test net output #0: accuracy = 0.50375
I0701 15:22:06.394575  2788 solver.cpp:408]     Test net output #1: loss = 0.693121 (* 1 = 0.693121 loss)
I0701 15:22:06.570340  2788 solver.cpp:236] Iteration 11750, loss = 0.693336
I0701 15:22:06.570385  2788 solver.cpp:252]     Train net output #0: loss = 0.693339 (* 1 = 0.693339 loss)
I0701 15:22:06.570407  2788 sgd_solver.cpp:106] Iteration 11750, lr = 0.01
I0701 15:22:13.346320  2788 solver.cpp:236] Iteration 11760, loss = 0.693261
I0701 15:22:13.346369  2788 solver.cpp:252]     Train net output #0: loss = 0.693189 (* 1 = 0.693189 loss)
I0701 15:22:13.346384  2788 sgd_solver.cpp:106] Iteration 11760, lr = 0.01
I0701 15:22:20.117741  2788 solver.cpp:236] Iteration 11770, loss = 0.693229
I0701 15:22:20.117801  2788 solver.cpp:252]     Train net output #0: loss = 0.692297 (* 1 = 0.692297 loss)
I0701 15:22:20.117815  2788 sgd_solver.cpp:106] Iteration 11770, lr = 0.01
I0701 15:22:26.913537  2788 solver.cpp:236] Iteration 11780, loss = 0.693257
I0701 15:22:26.913774  2788 solver.cpp:252]     Train net output #0: loss = 0.692908 (* 1 = 0.692908 loss)
I0701 15:22:26.913784  2788 sgd_solver.cpp:106] Iteration 11780, lr = 0.01
I0701 15:22:33.692795  2788 solver.cpp:236] Iteration 11790, loss = 0.693346
I0701 15:22:33.692852  2788 solver.cpp:252]     Train net output #0: loss = 0.691436 (* 1 = 0.691436 loss)
I0701 15:22:33.692865  2788 sgd_solver.cpp:106] Iteration 11790, lr = 0.01
I0701 15:22:40.489390  2788 solver.cpp:236] Iteration 11800, loss = 0.69334
I0701 15:22:40.489436  2788 solver.cpp:252]     Train net output #0: loss = 0.693223 (* 1 = 0.693223 loss)
I0701 15:22:40.489450  2788 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0701 15:22:47.271028  2788 solver.cpp:236] Iteration 11810, loss = 0.693378
I0701 15:22:47.271097  2788 solver.cpp:252]     Train net output #0: loss = 0.693777 (* 1 = 0.693777 loss)
I0701 15:22:47.271114  2788 sgd_solver.cpp:106] Iteration 11810, lr = 0.01
I0701 15:22:54.062773  2788 solver.cpp:236] Iteration 11820, loss = 0.693368
I0701 15:22:54.062829  2788 solver.cpp:252]     Train net output #0: loss = 0.693126 (* 1 = 0.693126 loss)
I0701 15:22:54.062842  2788 sgd_solver.cpp:106] Iteration 11820, lr = 0.01
I0701 15:23:00.860180  2788 solver.cpp:236] Iteration 11830, loss = 0.693342
I0701 15:23:00.860427  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 15:23:00.860456  2788 sgd_solver.cpp:106] Iteration 11830, lr = 0.01
I0701 15:23:07.644704  2788 solver.cpp:236] Iteration 11840, loss = 0.693246
I0701 15:23:07.644759  2788 solver.cpp:252]     Train net output #0: loss = 0.694472 (* 1 = 0.694472 loss)
I0701 15:23:07.644773  2788 sgd_solver.cpp:106] Iteration 11840, lr = 0.01
I0701 15:23:14.462493  2788 solver.cpp:236] Iteration 11850, loss = 0.693277
I0701 15:23:14.462543  2788 solver.cpp:252]     Train net output #0: loss = 0.693646 (* 1 = 0.693646 loss)
I0701 15:23:14.462559  2788 sgd_solver.cpp:106] Iteration 11850, lr = 0.01
I0701 15:23:21.263131  2788 solver.cpp:236] Iteration 11860, loss = 0.693235
I0701 15:23:21.263185  2788 solver.cpp:252]     Train net output #0: loss = 0.692424 (* 1 = 0.692424 loss)
I0701 15:23:21.263198  2788 sgd_solver.cpp:106] Iteration 11860, lr = 0.01
I0701 15:23:28.040936  2788 solver.cpp:236] Iteration 11870, loss = 0.693457
I0701 15:23:28.040982  2788 solver.cpp:252]     Train net output #0: loss = 0.693316 (* 1 = 0.693316 loss)
I0701 15:23:28.040997  2788 sgd_solver.cpp:106] Iteration 11870, lr = 0.01
I0701 15:23:34.847079  2788 solver.cpp:236] Iteration 11880, loss = 0.6935
I0701 15:23:34.852500  2788 solver.cpp:252]     Train net output #0: loss = 0.693545 (* 1 = 0.693545 loss)
I0701 15:23:34.852517  2788 sgd_solver.cpp:106] Iteration 11880, lr = 0.01
I0701 15:23:41.645767  2788 solver.cpp:236] Iteration 11890, loss = 0.693826
I0701 15:23:41.645824  2788 solver.cpp:252]     Train net output #0: loss = 0.693494 (* 1 = 0.693494 loss)
I0701 15:23:41.645840  2788 sgd_solver.cpp:106] Iteration 11890, lr = 0.01
I0701 15:23:48.434721  2788 solver.cpp:236] Iteration 11900, loss = 0.693911
I0701 15:23:48.434782  2788 solver.cpp:252]     Train net output #0: loss = 0.695035 (* 1 = 0.695035 loss)
I0701 15:23:48.434795  2788 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0701 15:23:55.236583  2788 solver.cpp:236] Iteration 11910, loss = 0.693884
I0701 15:23:55.236629  2788 solver.cpp:252]     Train net output #0: loss = 0.693364 (* 1 = 0.693364 loss)
I0701 15:23:55.236644  2788 sgd_solver.cpp:106] Iteration 11910, lr = 0.01
I0701 15:24:02.031287  2788 solver.cpp:236] Iteration 11920, loss = 0.69363
I0701 15:24:02.031334  2788 solver.cpp:252]     Train net output #0: loss = 0.69276 (* 1 = 0.69276 loss)
I0701 15:24:02.031348  2788 sgd_solver.cpp:106] Iteration 11920, lr = 0.01
I0701 15:24:08.820593  2788 solver.cpp:236] Iteration 11930, loss = 0.693657
I0701 15:24:08.824491  2788 solver.cpp:252]     Train net output #0: loss = 0.692061 (* 1 = 0.692061 loss)
I0701 15:24:08.824504  2788 sgd_solver.cpp:106] Iteration 11930, lr = 0.01
I0701 15:24:15.639302  2788 solver.cpp:236] Iteration 11940, loss = 0.693424
I0701 15:24:15.639363  2788 solver.cpp:252]     Train net output #0: loss = 0.692917 (* 1 = 0.692917 loss)
I0701 15:24:15.639376  2788 sgd_solver.cpp:106] Iteration 11940, lr = 0.01
I0701 15:24:22.416687  2788 solver.cpp:236] Iteration 11950, loss = 0.693097
I0701 15:24:22.416735  2788 solver.cpp:252]     Train net output #0: loss = 0.695611 (* 1 = 0.695611 loss)
I0701 15:24:22.416750  2788 sgd_solver.cpp:106] Iteration 11950, lr = 0.01
I0701 15:24:29.212481  2788 solver.cpp:236] Iteration 11960, loss = 0.693711
I0701 15:24:29.212527  2788 solver.cpp:252]     Train net output #0: loss = 0.696949 (* 1 = 0.696949 loss)
I0701 15:24:29.212539  2788 sgd_solver.cpp:106] Iteration 11960, lr = 0.01
I0701 15:24:36.011080  2788 solver.cpp:236] Iteration 11970, loss = 0.693765
I0701 15:24:36.011129  2788 solver.cpp:252]     Train net output #0: loss = 0.693333 (* 1 = 0.693333 loss)
I0701 15:24:36.011144  2788 sgd_solver.cpp:106] Iteration 11970, lr = 0.01
I0701 15:24:42.798363  2788 solver.cpp:236] Iteration 11980, loss = 0.693718
I0701 15:24:42.798557  2788 solver.cpp:252]     Train net output #0: loss = 0.69233 (* 1 = 0.69233 loss)
I0701 15:24:42.798576  2788 sgd_solver.cpp:106] Iteration 11980, lr = 0.01
I0701 15:24:49.611626  2788 solver.cpp:236] Iteration 11990, loss = 0.693632
I0701 15:24:49.611706  2788 solver.cpp:252]     Train net output #0: loss = 0.693626 (* 1 = 0.693626 loss)
I0701 15:24:49.611723  2788 sgd_solver.cpp:106] Iteration 11990, lr = 0.01
I0701 15:24:55.729727  2788 solver.cpp:340] Iteration 12000, Testing net (#0)
I0701 15:25:07.655783  2788 solver.cpp:408]     Test net output #0: accuracy = 0.505313
I0701 15:25:07.655845  2788 solver.cpp:408]     Test net output #1: loss = 0.693108 (* 1 = 0.693108 loss)
I0701 15:25:07.841663  2788 solver.cpp:236] Iteration 12000, loss = 0.693854
I0701 15:25:07.841723  2788 solver.cpp:252]     Train net output #0: loss = 0.693523 (* 1 = 0.693523 loss)
I0701 15:25:07.841739  2788 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0701 15:25:14.621181  2788 solver.cpp:236] Iteration 12010, loss = 0.693215
I0701 15:25:14.624490  2788 solver.cpp:252]     Train net output #0: loss = 0.692403 (* 1 = 0.692403 loss)
I0701 15:25:14.624503  2788 sgd_solver.cpp:106] Iteration 12010, lr = 0.01
I0701 15:25:21.406445  2788 solver.cpp:236] Iteration 12020, loss = 0.693301
I0701 15:25:21.406491  2788 solver.cpp:252]     Train net output #0: loss = 0.693041 (* 1 = 0.693041 loss)
I0701 15:25:21.406505  2788 sgd_solver.cpp:106] Iteration 12020, lr = 0.01
I0701 15:25:28.209776  2788 solver.cpp:236] Iteration 12030, loss = 0.693272
I0701 15:25:28.209831  2788 solver.cpp:252]     Train net output #0: loss = 0.693779 (* 1 = 0.693779 loss)
I0701 15:25:28.209846  2788 sgd_solver.cpp:106] Iteration 12030, lr = 0.01
I0701 15:25:35.004060  2788 solver.cpp:236] Iteration 12040, loss = 0.693275
I0701 15:25:35.004109  2788 solver.cpp:252]     Train net output #0: loss = 0.693113 (* 1 = 0.693113 loss)
I0701 15:25:35.004122  2788 sgd_solver.cpp:106] Iteration 12040, lr = 0.01
I0701 15:25:41.806733  2788 solver.cpp:236] Iteration 12050, loss = 0.693242
I0701 15:25:41.806793  2788 solver.cpp:252]     Train net output #0: loss = 0.692632 (* 1 = 0.692632 loss)
I0701 15:25:41.806807  2788 sgd_solver.cpp:106] Iteration 12050, lr = 0.01
I0701 15:25:48.608184  2788 solver.cpp:236] Iteration 12060, loss = 0.693329
I0701 15:25:48.608387  2788 solver.cpp:252]     Train net output #0: loss = 0.693277 (* 1 = 0.693277 loss)
I0701 15:25:48.608403  2788 sgd_solver.cpp:106] Iteration 12060, lr = 0.01
I0701 15:25:55.402760  2788 solver.cpp:236] Iteration 12070, loss = 0.693254
I0701 15:25:55.402804  2788 solver.cpp:252]     Train net output #0: loss = 0.692895 (* 1 = 0.692895 loss)
I0701 15:25:55.402817  2788 sgd_solver.cpp:106] Iteration 12070, lr = 0.01
I0701 15:26:02.206833  2788 solver.cpp:236] Iteration 12080, loss = 0.69328
I0701 15:26:02.206885  2788 solver.cpp:252]     Train net output #0: loss = 0.693834 (* 1 = 0.693834 loss)
I0701 15:26:02.206900  2788 sgd_solver.cpp:106] Iteration 12080, lr = 0.01
I0701 15:26:09.008465  2788 solver.cpp:236] Iteration 12090, loss = 0.69333
I0701 15:26:09.008518  2788 solver.cpp:252]     Train net output #0: loss = 0.694006 (* 1 = 0.694006 loss)
I0701 15:26:09.008538  2788 sgd_solver.cpp:106] Iteration 12090, lr = 0.01
I0701 15:26:15.792425  2788 solver.cpp:236] Iteration 12100, loss = 0.693252
I0701 15:26:15.792479  2788 solver.cpp:252]     Train net output #0: loss = 0.691458 (* 1 = 0.691458 loss)
I0701 15:26:15.792496  2788 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0701 15:26:22.585278  2788 solver.cpp:236] Iteration 12110, loss = 0.693269
I0701 15:26:22.585614  2788 solver.cpp:252]     Train net output #0: loss = 0.695252 (* 1 = 0.695252 loss)
I0701 15:26:22.585633  2788 sgd_solver.cpp:106] Iteration 12110, lr = 0.01
I0701 15:26:29.380812  2788 solver.cpp:236] Iteration 12120, loss = 0.693341
I0701 15:26:29.380867  2788 solver.cpp:252]     Train net output #0: loss = 0.693437 (* 1 = 0.693437 loss)
I0701 15:26:29.380882  2788 sgd_solver.cpp:106] Iteration 12120, lr = 0.01
I0701 15:26:36.156625  2788 solver.cpp:236] Iteration 12130, loss = 0.693316
I0701 15:26:36.156672  2788 solver.cpp:252]     Train net output #0: loss = 0.692662 (* 1 = 0.692662 loss)
I0701 15:26:36.156685  2788 sgd_solver.cpp:106] Iteration 12130, lr = 0.01
I0701 15:26:42.957396  2788 solver.cpp:236] Iteration 12140, loss = 0.693386
I0701 15:26:42.957444  2788 solver.cpp:252]     Train net output #0: loss = 0.691866 (* 1 = 0.691866 loss)
I0701 15:26:42.957458  2788 sgd_solver.cpp:106] Iteration 12140, lr = 0.01
I0701 15:26:49.752614  2788 solver.cpp:236] Iteration 12150, loss = 0.693544
I0701 15:26:49.752676  2788 solver.cpp:252]     Train net output #0: loss = 0.693176 (* 1 = 0.693176 loss)
I0701 15:26:49.752703  2788 sgd_solver.cpp:106] Iteration 12150, lr = 0.01
I0701 15:26:56.532907  2788 solver.cpp:236] Iteration 12160, loss = 0.693475
I0701 15:26:56.533097  2788 solver.cpp:252]     Train net output #0: loss = 0.693966 (* 1 = 0.693966 loss)
I0701 15:26:56.533116  2788 sgd_solver.cpp:106] Iteration 12160, lr = 0.01
I0701 15:27:03.329169  2788 solver.cpp:236] Iteration 12170, loss = 0.693429
I0701 15:27:03.329228  2788 solver.cpp:252]     Train net output #0: loss = 0.700599 (* 1 = 0.700599 loss)
I0701 15:27:03.329242  2788 sgd_solver.cpp:106] Iteration 12170, lr = 0.01
I0701 15:27:10.101686  2788 solver.cpp:236] Iteration 12180, loss = 0.69338
I0701 15:27:10.101739  2788 solver.cpp:252]     Train net output #0: loss = 0.692698 (* 1 = 0.692698 loss)
I0701 15:27:10.101753  2788 sgd_solver.cpp:106] Iteration 12180, lr = 0.01
I0701 15:27:16.891906  2788 solver.cpp:236] Iteration 12190, loss = 0.693271
I0701 15:27:16.891965  2788 solver.cpp:252]     Train net output #0: loss = 0.692398 (* 1 = 0.692398 loss)
I0701 15:27:16.891979  2788 sgd_solver.cpp:106] Iteration 12190, lr = 0.01
I0701 15:27:23.703367  2788 solver.cpp:236] Iteration 12200, loss = 0.693191
I0701 15:27:23.703429  2788 solver.cpp:252]     Train net output #0: loss = 0.692606 (* 1 = 0.692606 loss)
I0701 15:27:23.703444  2788 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0701 15:27:30.491334  2788 solver.cpp:236] Iteration 12210, loss = 0.6933
I0701 15:27:30.496517  2788 solver.cpp:252]     Train net output #0: loss = 0.693149 (* 1 = 0.693149 loss)
I0701 15:27:30.496553  2788 sgd_solver.cpp:106] Iteration 12210, lr = 0.01
I0701 15:27:37.304891  2788 solver.cpp:236] Iteration 12220, loss = 0.693237
I0701 15:27:37.304944  2788 solver.cpp:252]     Train net output #0: loss = 0.693127 (* 1 = 0.693127 loss)
I0701 15:27:37.304957  2788 sgd_solver.cpp:106] Iteration 12220, lr = 0.01
I0701 15:27:44.089210  2788 solver.cpp:236] Iteration 12230, loss = 0.693261
I0701 15:27:44.089264  2788 solver.cpp:252]     Train net output #0: loss = 0.692843 (* 1 = 0.692843 loss)
I0701 15:27:44.089278  2788 sgd_solver.cpp:106] Iteration 12230, lr = 0.01
I0701 15:27:50.888123  2788 solver.cpp:236] Iteration 12240, loss = 0.693247
I0701 15:27:50.888175  2788 solver.cpp:252]     Train net output #0: loss = 0.691815 (* 1 = 0.691815 loss)
I0701 15:27:50.888187  2788 sgd_solver.cpp:106] Iteration 12240, lr = 0.01
I0701 15:27:57.015576  2788 solver.cpp:340] Iteration 12250, Testing net (#0)
I0701 15:28:05.425948  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 15:28:08.731350  2788 solver.cpp:408]     Test net output #0: accuracy = 0.50625
I0701 15:28:08.731407  2788 solver.cpp:408]     Test net output #1: loss = 0.693069 (* 1 = 0.693069 loss)
I0701 15:28:08.907292  2788 solver.cpp:236] Iteration 12250, loss = 0.693269
I0701 15:28:08.907356  2788 solver.cpp:252]     Train net output #0: loss = 0.693028 (* 1 = 0.693028 loss)
I0701 15:28:08.907377  2788 sgd_solver.cpp:106] Iteration 12250, lr = 0.01
I0701 15:28:15.688551  2788 solver.cpp:236] Iteration 12260, loss = 0.693179
I0701 15:28:15.688607  2788 solver.cpp:252]     Train net output #0: loss = 0.69377 (* 1 = 0.69377 loss)
I0701 15:28:15.688621  2788 sgd_solver.cpp:106] Iteration 12260, lr = 0.01
I0701 15:28:22.486582  2788 solver.cpp:236] Iteration 12270, loss = 0.69321
I0701 15:28:22.486634  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 15:28:22.486649  2788 sgd_solver.cpp:106] Iteration 12270, lr = 0.01
I0701 15:28:29.285447  2788 solver.cpp:236] Iteration 12280, loss = 0.693126
I0701 15:28:29.285496  2788 solver.cpp:252]     Train net output #0: loss = 0.696235 (* 1 = 0.696235 loss)
I0701 15:28:29.285511  2788 sgd_solver.cpp:106] Iteration 12280, lr = 0.01
I0701 15:28:36.066253  2788 solver.cpp:236] Iteration 12290, loss = 0.693264
I0701 15:28:36.066484  2788 solver.cpp:252]     Train net output #0: loss = 0.694483 (* 1 = 0.694483 loss)
I0701 15:28:36.066499  2788 sgd_solver.cpp:106] Iteration 12290, lr = 0.01
I0701 15:28:42.853811  2788 solver.cpp:236] Iteration 12300, loss = 0.693213
I0701 15:28:42.853858  2788 solver.cpp:252]     Train net output #0: loss = 0.696657 (* 1 = 0.696657 loss)
I0701 15:28:42.853873  2788 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0701 15:28:49.661053  2788 solver.cpp:236] Iteration 12310, loss = 0.693037
I0701 15:28:49.661109  2788 solver.cpp:252]     Train net output #0: loss = 0.691867 (* 1 = 0.691867 loss)
I0701 15:28:49.661124  2788 sgd_solver.cpp:106] Iteration 12310, lr = 0.01
I0701 15:28:56.444245  2788 solver.cpp:236] Iteration 12320, loss = 0.693173
I0701 15:28:56.444296  2788 solver.cpp:252]     Train net output #0: loss = 0.69378 (* 1 = 0.69378 loss)
I0701 15:28:56.444310  2788 sgd_solver.cpp:106] Iteration 12320, lr = 0.01
I0701 15:29:03.253763  2788 solver.cpp:236] Iteration 12330, loss = 0.69327
I0701 15:29:03.253818  2788 solver.cpp:252]     Train net output #0: loss = 0.692254 (* 1 = 0.692254 loss)
I0701 15:29:03.253834  2788 sgd_solver.cpp:106] Iteration 12330, lr = 0.01
I0701 15:29:10.061368  2788 solver.cpp:236] Iteration 12340, loss = 0.693133
I0701 15:29:10.061625  2788 solver.cpp:252]     Train net output #0: loss = 0.694026 (* 1 = 0.694026 loss)
I0701 15:29:10.061643  2788 sgd_solver.cpp:106] Iteration 12340, lr = 0.01
I0701 15:29:16.852790  2788 solver.cpp:236] Iteration 12350, loss = 0.693191
I0701 15:29:16.852839  2788 solver.cpp:252]     Train net output #0: loss = 0.691793 (* 1 = 0.691793 loss)
I0701 15:29:16.852856  2788 sgd_solver.cpp:106] Iteration 12350, lr = 0.01
I0701 15:29:23.654012  2788 solver.cpp:236] Iteration 12360, loss = 0.693508
I0701 15:29:23.654068  2788 solver.cpp:252]     Train net output #0: loss = 0.69327 (* 1 = 0.69327 loss)
I0701 15:29:23.654083  2788 sgd_solver.cpp:106] Iteration 12360, lr = 0.01
I0701 15:29:30.458806  2788 solver.cpp:236] Iteration 12370, loss = 0.693164
I0701 15:29:30.458863  2788 solver.cpp:252]     Train net output #0: loss = 0.691742 (* 1 = 0.691742 loss)
I0701 15:29:30.458880  2788 sgd_solver.cpp:106] Iteration 12370, lr = 0.01
I0701 15:29:37.243865  2788 solver.cpp:236] Iteration 12380, loss = 0.693393
I0701 15:29:37.243913  2788 solver.cpp:252]     Train net output #0: loss = 0.694462 (* 1 = 0.694462 loss)
I0701 15:29:37.243927  2788 sgd_solver.cpp:106] Iteration 12380, lr = 0.01
I0701 15:29:44.054182  2788 solver.cpp:236] Iteration 12390, loss = 0.693576
I0701 15:29:44.054409  2788 solver.cpp:252]     Train net output #0: loss = 0.694266 (* 1 = 0.694266 loss)
I0701 15:29:44.054426  2788 sgd_solver.cpp:106] Iteration 12390, lr = 0.01
I0701 15:29:50.853505  2788 solver.cpp:236] Iteration 12400, loss = 0.693512
I0701 15:29:50.853564  2788 solver.cpp:252]     Train net output #0: loss = 0.693602 (* 1 = 0.693602 loss)
I0701 15:29:50.853579  2788 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0701 15:29:57.654954  2788 solver.cpp:236] Iteration 12410, loss = 0.693382
I0701 15:29:57.655004  2788 solver.cpp:252]     Train net output #0: loss = 0.692303 (* 1 = 0.692303 loss)
I0701 15:29:57.655019  2788 sgd_solver.cpp:106] Iteration 12410, lr = 0.01
I0701 15:30:04.460964  2788 solver.cpp:236] Iteration 12420, loss = 0.693558
I0701 15:30:04.461019  2788 solver.cpp:252]     Train net output #0: loss = 0.693196 (* 1 = 0.693196 loss)
I0701 15:30:04.461035  2788 sgd_solver.cpp:106] Iteration 12420, lr = 0.01
I0701 15:30:11.277007  2788 solver.cpp:236] Iteration 12430, loss = 0.693298
I0701 15:30:11.277055  2788 solver.cpp:252]     Train net output #0: loss = 0.693035 (* 1 = 0.693035 loss)
I0701 15:30:11.277068  2788 sgd_solver.cpp:106] Iteration 12430, lr = 0.01
I0701 15:30:18.082294  2788 solver.cpp:236] Iteration 12440, loss = 0.693145
I0701 15:30:18.082535  2788 solver.cpp:252]     Train net output #0: loss = 0.693418 (* 1 = 0.693418 loss)
I0701 15:30:18.082552  2788 sgd_solver.cpp:106] Iteration 12440, lr = 0.01
I0701 15:30:24.869386  2788 solver.cpp:236] Iteration 12450, loss = 0.693215
I0701 15:30:24.869437  2788 solver.cpp:252]     Train net output #0: loss = 0.693805 (* 1 = 0.693805 loss)
I0701 15:30:24.869451  2788 sgd_solver.cpp:106] Iteration 12450, lr = 0.01
I0701 15:30:31.679319  2788 solver.cpp:236] Iteration 12460, loss = 0.693161
I0701 15:30:31.679443  2788 solver.cpp:252]     Train net output #0: loss = 0.694045 (* 1 = 0.694045 loss)
I0701 15:30:31.679466  2788 sgd_solver.cpp:106] Iteration 12460, lr = 0.01
I0701 15:30:38.487535  2788 solver.cpp:236] Iteration 12470, loss = 0.69314
I0701 15:30:38.487594  2788 solver.cpp:252]     Train net output #0: loss = 0.694838 (* 1 = 0.694838 loss)
I0701 15:30:38.487609  2788 sgd_solver.cpp:106] Iteration 12470, lr = 0.01
I0701 15:30:45.280205  2788 solver.cpp:236] Iteration 12480, loss = 0.693361
I0701 15:30:45.280254  2788 solver.cpp:252]     Train net output #0: loss = 0.692852 (* 1 = 0.692852 loss)
I0701 15:30:45.280268  2788 sgd_solver.cpp:106] Iteration 12480, lr = 0.01
I0701 15:30:52.091769  2788 solver.cpp:236] Iteration 12490, loss = 0.693335
I0701 15:30:52.096518  2788 solver.cpp:252]     Train net output #0: loss = 0.693214 (* 1 = 0.693214 loss)
I0701 15:30:52.096547  2788 sgd_solver.cpp:106] Iteration 12490, lr = 0.01
I0701 15:30:58.223299  2788 solver.cpp:340] Iteration 12500, Testing net (#0)
I0701 15:31:09.928755  2788 solver.cpp:408]     Test net output #0: accuracy = 0.502187
I0701 15:31:09.928812  2788 solver.cpp:408]     Test net output #1: loss = 0.693138 (* 1 = 0.693138 loss)
I0701 15:31:10.107106  2788 solver.cpp:236] Iteration 12500, loss = 0.693318
I0701 15:31:10.107157  2788 solver.cpp:252]     Train net output #0: loss = 0.692934 (* 1 = 0.692934 loss)
I0701 15:31:10.107174  2788 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0701 15:31:16.880941  2788 solver.cpp:236] Iteration 12510, loss = 0.693324
I0701 15:31:16.881000  2788 solver.cpp:252]     Train net output #0: loss = 0.693029 (* 1 = 0.693029 loss)
I0701 15:31:16.881014  2788 sgd_solver.cpp:106] Iteration 12510, lr = 0.01
I0701 15:31:23.661572  2788 solver.cpp:236] Iteration 12520, loss = 0.69341
I0701 15:31:23.664504  2788 solver.cpp:252]     Train net output #0: loss = 0.692552 (* 1 = 0.692552 loss)
I0701 15:31:23.664520  2788 sgd_solver.cpp:106] Iteration 12520, lr = 0.01
I0701 15:31:30.441396  2788 solver.cpp:236] Iteration 12530, loss = 0.693156
I0701 15:31:30.441438  2788 solver.cpp:252]     Train net output #0: loss = 0.692398 (* 1 = 0.692398 loss)
I0701 15:31:30.441455  2788 sgd_solver.cpp:106] Iteration 12530, lr = 0.01
I0701 15:31:37.236209  2788 solver.cpp:236] Iteration 12540, loss = 0.693266
I0701 15:31:37.236264  2788 solver.cpp:252]     Train net output #0: loss = 0.696804 (* 1 = 0.696804 loss)
I0701 15:31:37.236279  2788 sgd_solver.cpp:106] Iteration 12540, lr = 0.01
I0701 15:31:44.027333  2788 solver.cpp:236] Iteration 12550, loss = 0.693253
I0701 15:31:44.027379  2788 solver.cpp:252]     Train net output #0: loss = 0.697824 (* 1 = 0.697824 loss)
I0701 15:31:44.027397  2788 sgd_solver.cpp:106] Iteration 12550, lr = 0.01
I0701 15:31:50.823016  2788 solver.cpp:236] Iteration 12560, loss = 0.693264
I0701 15:31:50.823076  2788 solver.cpp:252]     Train net output #0: loss = 0.69559 (* 1 = 0.69559 loss)
I0701 15:31:50.823092  2788 sgd_solver.cpp:106] Iteration 12560, lr = 0.01
I0701 15:31:57.635782  2788 solver.cpp:236] Iteration 12570, loss = 0.693253
I0701 15:31:57.636152  2788 solver.cpp:252]     Train net output #0: loss = 0.693062 (* 1 = 0.693062 loss)
I0701 15:31:57.636170  2788 sgd_solver.cpp:106] Iteration 12570, lr = 0.01
I0701 15:32:04.451373  2788 solver.cpp:236] Iteration 12580, loss = 0.693295
I0701 15:32:04.451455  2788 solver.cpp:252]     Train net output #0: loss = 0.692296 (* 1 = 0.692296 loss)
I0701 15:32:04.451472  2788 sgd_solver.cpp:106] Iteration 12580, lr = 0.01
I0701 15:32:11.247402  2788 solver.cpp:236] Iteration 12590, loss = 0.693243
I0701 15:32:11.247454  2788 solver.cpp:252]     Train net output #0: loss = 0.696174 (* 1 = 0.696174 loss)
I0701 15:32:11.247469  2788 sgd_solver.cpp:106] Iteration 12590, lr = 0.01
I0701 15:32:18.071966  2788 solver.cpp:236] Iteration 12600, loss = 0.693356
I0701 15:32:18.072026  2788 solver.cpp:252]     Train net output #0: loss = 0.693151 (* 1 = 0.693151 loss)
I0701 15:32:18.072046  2788 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0701 15:32:24.882141  2788 solver.cpp:236] Iteration 12610, loss = 0.693373
I0701 15:32:24.882208  2788 solver.cpp:252]     Train net output #0: loss = 0.694077 (* 1 = 0.694077 loss)
I0701 15:32:24.882230  2788 sgd_solver.cpp:106] Iteration 12610, lr = 0.01
I0701 15:32:31.702303  2788 solver.cpp:236] Iteration 12620, loss = 0.693344
I0701 15:32:31.702538  2788 solver.cpp:252]     Train net output #0: loss = 0.692796 (* 1 = 0.692796 loss)
I0701 15:32:31.702556  2788 sgd_solver.cpp:106] Iteration 12620, lr = 0.01
I0701 15:32:38.504642  2788 solver.cpp:236] Iteration 12630, loss = 0.693182
I0701 15:32:38.504691  2788 solver.cpp:252]     Train net output #0: loss = 0.693777 (* 1 = 0.693777 loss)
I0701 15:32:38.504706  2788 sgd_solver.cpp:106] Iteration 12630, lr = 0.01
I0701 15:32:45.315500  2788 solver.cpp:236] Iteration 12640, loss = 0.6933
I0701 15:32:45.315552  2788 solver.cpp:252]     Train net output #0: loss = 0.696206 (* 1 = 0.696206 loss)
I0701 15:32:45.315567  2788 sgd_solver.cpp:106] Iteration 12640, lr = 0.01
I0701 15:32:52.125301  2788 solver.cpp:236] Iteration 12650, loss = 0.693441
I0701 15:32:52.125350  2788 solver.cpp:252]     Train net output #0: loss = 0.693748 (* 1 = 0.693748 loss)
I0701 15:32:52.125365  2788 sgd_solver.cpp:106] Iteration 12650, lr = 0.01
I0701 15:32:58.935495  2788 solver.cpp:236] Iteration 12660, loss = 0.693498
I0701 15:32:58.935544  2788 solver.cpp:252]     Train net output #0: loss = 0.693912 (* 1 = 0.693912 loss)
I0701 15:32:58.935559  2788 sgd_solver.cpp:106] Iteration 12660, lr = 0.01
I0701 15:33:05.765393  2788 solver.cpp:236] Iteration 12670, loss = 0.693473
I0701 15:33:05.765599  2788 solver.cpp:252]     Train net output #0: loss = 0.693241 (* 1 = 0.693241 loss)
I0701 15:33:05.765616  2788 sgd_solver.cpp:106] Iteration 12670, lr = 0.01
I0701 15:33:12.573143  2788 solver.cpp:236] Iteration 12680, loss = 0.693711
I0701 15:33:12.573197  2788 solver.cpp:252]     Train net output #0: loss = 0.693163 (* 1 = 0.693163 loss)
I0701 15:33:12.573212  2788 sgd_solver.cpp:106] Iteration 12680, lr = 0.01
I0701 15:33:19.400068  2788 solver.cpp:236] Iteration 12690, loss = 0.693539
I0701 15:33:19.400115  2788 solver.cpp:252]     Train net output #0: loss = 0.693354 (* 1 = 0.693354 loss)
I0701 15:33:19.400130  2788 sgd_solver.cpp:106] Iteration 12690, lr = 0.01
I0701 15:33:26.223726  2788 solver.cpp:236] Iteration 12700, loss = 0.69329
I0701 15:33:26.223783  2788 solver.cpp:252]     Train net output #0: loss = 0.693418 (* 1 = 0.693418 loss)
I0701 15:33:26.223798  2788 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0701 15:33:33.044245  2788 solver.cpp:236] Iteration 12710, loss = 0.693232
I0701 15:33:33.044302  2788 solver.cpp:252]     Train net output #0: loss = 0.693155 (* 1 = 0.693155 loss)
I0701 15:33:33.044317  2788 sgd_solver.cpp:106] Iteration 12710, lr = 0.01
I0701 15:33:39.839154  2788 solver.cpp:236] Iteration 12720, loss = 0.693222
I0701 15:33:39.848480  2788 solver.cpp:252]     Train net output #0: loss = 0.693969 (* 1 = 0.693969 loss)
I0701 15:33:39.848498  2788 sgd_solver.cpp:106] Iteration 12720, lr = 0.01
I0701 15:33:46.659790  2788 solver.cpp:236] Iteration 12730, loss = 0.693321
I0701 15:33:46.659842  2788 solver.cpp:252]     Train net output #0: loss = 0.693442 (* 1 = 0.693442 loss)
I0701 15:33:46.659857  2788 sgd_solver.cpp:106] Iteration 12730, lr = 0.01
I0701 15:33:53.475375  2788 solver.cpp:236] Iteration 12740, loss = 0.69332
I0701 15:33:53.475422  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 15:33:53.475440  2788 sgd_solver.cpp:106] Iteration 12740, lr = 0.01
I0701 15:33:59.616803  2788 solver.cpp:340] Iteration 12750, Testing net (#0)
I0701 15:34:11.458196  2788 solver.cpp:408]     Test net output #0: accuracy = 0.488438
I0701 15:34:11.458390  2788 solver.cpp:408]     Test net output #1: loss = 0.693276 (* 1 = 0.693276 loss)
I0701 15:34:11.632910  2788 solver.cpp:236] Iteration 12750, loss = 0.693476
I0701 15:34:11.632958  2788 solver.cpp:252]     Train net output #0: loss = 0.693317 (* 1 = 0.693317 loss)
I0701 15:34:11.632975  2788 sgd_solver.cpp:106] Iteration 12750, lr = 0.01
I0701 15:34:18.422443  2788 solver.cpp:236] Iteration 12760, loss = 0.69348
I0701 15:34:18.422497  2788 solver.cpp:252]     Train net output #0: loss = 0.693834 (* 1 = 0.693834 loss)
I0701 15:34:18.422513  2788 sgd_solver.cpp:106] Iteration 12760, lr = 0.01
I0701 15:34:25.233230  2788 solver.cpp:236] Iteration 12770, loss = 0.693451
I0701 15:34:25.233281  2788 solver.cpp:252]     Train net output #0: loss = 0.692174 (* 1 = 0.692174 loss)
I0701 15:34:25.233297  2788 sgd_solver.cpp:106] Iteration 12770, lr = 0.01
I0701 15:34:32.034723  2788 solver.cpp:236] Iteration 12780, loss = 0.693391
I0701 15:34:32.034778  2788 solver.cpp:252]     Train net output #0: loss = 0.695229 (* 1 = 0.695229 loss)
I0701 15:34:32.034795  2788 sgd_solver.cpp:106] Iteration 12780, lr = 0.01
I0701 15:34:38.850914  2788 solver.cpp:236] Iteration 12790, loss = 0.693341
I0701 15:34:38.850962  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 15:34:38.850978  2788 sgd_solver.cpp:106] Iteration 12790, lr = 0.01
I0701 15:34:45.669808  2788 solver.cpp:236] Iteration 12800, loss = 0.693099
I0701 15:34:45.670012  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 15:34:45.670030  2788 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0701 15:34:52.470362  2788 solver.cpp:236] Iteration 12810, loss = 0.693183
I0701 15:34:52.470410  2788 solver.cpp:252]     Train net output #0: loss = 0.691161 (* 1 = 0.691161 loss)
I0701 15:34:52.470424  2788 sgd_solver.cpp:106] Iteration 12810, lr = 0.01
I0701 15:34:59.269807  2788 solver.cpp:236] Iteration 12820, loss = 0.69326
I0701 15:34:59.269861  2788 solver.cpp:252]     Train net output #0: loss = 0.692854 (* 1 = 0.692854 loss)
I0701 15:34:59.269876  2788 sgd_solver.cpp:106] Iteration 12820, lr = 0.01
I0701 15:35:06.093976  2788 solver.cpp:236] Iteration 12830, loss = 0.693299
I0701 15:35:06.094038  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 15:35:06.094053  2788 sgd_solver.cpp:106] Iteration 12830, lr = 0.01
I0701 15:35:12.919886  2788 solver.cpp:236] Iteration 12840, loss = 0.693366
I0701 15:35:12.919944  2788 solver.cpp:252]     Train net output #0: loss = 0.693598 (* 1 = 0.693598 loss)
I0701 15:35:12.919957  2788 sgd_solver.cpp:106] Iteration 12840, lr = 0.01
I0701 15:35:19.738210  2788 solver.cpp:236] Iteration 12850, loss = 0.693421
I0701 15:35:19.738569  2788 solver.cpp:252]     Train net output #0: loss = 0.691569 (* 1 = 0.691569 loss)
I0701 15:35:19.738596  2788 sgd_solver.cpp:106] Iteration 12850, lr = 0.01
I0701 15:35:26.536474  2788 solver.cpp:236] Iteration 12860, loss = 0.692992
I0701 15:35:26.536523  2788 solver.cpp:252]     Train net output #0: loss = 0.685602 (* 1 = 0.685602 loss)
I0701 15:35:26.536538  2788 sgd_solver.cpp:106] Iteration 12860, lr = 0.01
I0701 15:35:33.352308  2788 solver.cpp:236] Iteration 12870, loss = 0.693225
I0701 15:35:33.352368  2788 solver.cpp:252]     Train net output #0: loss = 0.691433 (* 1 = 0.691433 loss)
I0701 15:35:33.352385  2788 sgd_solver.cpp:106] Iteration 12870, lr = 0.01
I0701 15:35:40.174880  2788 solver.cpp:236] Iteration 12880, loss = 0.693078
I0701 15:35:40.174938  2788 solver.cpp:252]     Train net output #0: loss = 0.692329 (* 1 = 0.692329 loss)
I0701 15:35:40.174955  2788 sgd_solver.cpp:106] Iteration 12880, lr = 0.01
I0701 15:35:46.997582  2788 solver.cpp:236] Iteration 12890, loss = 0.693009
I0701 15:35:46.997637  2788 solver.cpp:252]     Train net output #0: loss = 0.693686 (* 1 = 0.693686 loss)
I0701 15:35:46.997650  2788 sgd_solver.cpp:106] Iteration 12890, lr = 0.01
I0701 15:35:53.808598  2788 solver.cpp:236] Iteration 12900, loss = 0.693056
I0701 15:35:53.808871  2788 solver.cpp:252]     Train net output #0: loss = 0.693493 (* 1 = 0.693493 loss)
I0701 15:35:53.808887  2788 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0701 15:36:00.609455  2788 solver.cpp:236] Iteration 12910, loss = 0.693448
I0701 15:36:00.609505  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 15:36:00.609520  2788 sgd_solver.cpp:106] Iteration 12910, lr = 0.01
I0701 15:36:07.443822  2788 solver.cpp:236] Iteration 12920, loss = 0.693177
I0701 15:36:07.443887  2788 solver.cpp:252]     Train net output #0: loss = 0.695769 (* 1 = 0.695769 loss)
I0701 15:36:07.443902  2788 sgd_solver.cpp:106] Iteration 12920, lr = 0.01
I0701 15:36:14.254791  2788 solver.cpp:236] Iteration 12930, loss = 0.69332
I0701 15:36:14.254837  2788 solver.cpp:252]     Train net output #0: loss = 0.693336 (* 1 = 0.693336 loss)
I0701 15:36:14.254851  2788 sgd_solver.cpp:106] Iteration 12930, lr = 0.01
I0701 15:36:21.055516  2788 solver.cpp:236] Iteration 12940, loss = 0.693412
I0701 15:36:21.055569  2788 solver.cpp:252]     Train net output #0: loss = 0.692508 (* 1 = 0.692508 loss)
I0701 15:36:21.055583  2788 sgd_solver.cpp:106] Iteration 12940, lr = 0.01
I0701 15:36:27.873342  2788 solver.cpp:236] Iteration 12950, loss = 0.69357
I0701 15:36:27.873503  2788 solver.cpp:252]     Train net output #0: loss = 0.691809 (* 1 = 0.691809 loss)
I0701 15:36:27.873538  2788 sgd_solver.cpp:106] Iteration 12950, lr = 0.01
I0701 15:36:34.666893  2788 solver.cpp:236] Iteration 12960, loss = 0.693665
I0701 15:36:34.666941  2788 solver.cpp:252]     Train net output #0: loss = 0.691393 (* 1 = 0.691393 loss)
I0701 15:36:34.666951  2788 sgd_solver.cpp:106] Iteration 12960, lr = 0.01
I0701 15:36:41.496642  2788 solver.cpp:236] Iteration 12970, loss = 0.693678
I0701 15:36:41.496697  2788 solver.cpp:252]     Train net output #0: loss = 0.69445 (* 1 = 0.69445 loss)
I0701 15:36:41.496714  2788 sgd_solver.cpp:106] Iteration 12970, lr = 0.01
I0701 15:36:48.324190  2788 solver.cpp:236] Iteration 12980, loss = 0.693713
I0701 15:36:48.324254  2788 solver.cpp:252]     Train net output #0: loss = 0.699463 (* 1 = 0.699463 loss)
I0701 15:36:48.324268  2788 sgd_solver.cpp:106] Iteration 12980, lr = 0.01
I0701 15:36:55.142427  2788 solver.cpp:236] Iteration 12990, loss = 0.693748
I0701 15:36:55.142494  2788 solver.cpp:252]     Train net output #0: loss = 0.694428 (* 1 = 0.694428 loss)
I0701 15:36:55.142511  2788 sgd_solver.cpp:106] Iteration 12990, lr = 0.01
I0701 15:37:01.279825  2788 solver.cpp:340] Iteration 13000, Testing net (#0)
I0701 15:37:13.037209  2788 solver.cpp:408]     Test net output #0: accuracy = 0.4925
I0701 15:37:13.037264  2788 solver.cpp:408]     Test net output #1: loss = 0.694528 (* 1 = 0.694528 loss)
I0701 15:37:13.210480  2788 solver.cpp:236] Iteration 13000, loss = 0.693609
I0701 15:37:13.210538  2788 solver.cpp:252]     Train net output #0: loss = 0.696412 (* 1 = 0.696412 loss)
I0701 15:37:13.210556  2788 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0701 15:37:20.014302  2788 solver.cpp:236] Iteration 13010, loss = 0.693653
I0701 15:37:20.014359  2788 solver.cpp:252]     Train net output #0: loss = 0.695464 (* 1 = 0.695464 loss)
I0701 15:37:20.014374  2788 sgd_solver.cpp:106] Iteration 13010, lr = 0.01
I0701 15:37:26.812019  2788 solver.cpp:236] Iteration 13020, loss = 0.693833
I0701 15:37:26.812073  2788 solver.cpp:252]     Train net output #0: loss = 0.694891 (* 1 = 0.694891 loss)
I0701 15:37:26.812088  2788 sgd_solver.cpp:106] Iteration 13020, lr = 0.01
I0701 15:37:33.606026  2788 solver.cpp:236] Iteration 13030, loss = 0.693698
I0701 15:37:33.606225  2788 solver.cpp:252]     Train net output #0: loss = 0.692831 (* 1 = 0.692831 loss)
I0701 15:37:33.606241  2788 sgd_solver.cpp:106] Iteration 13030, lr = 0.01
I0701 15:37:40.408704  2788 solver.cpp:236] Iteration 13040, loss = 0.693644
I0701 15:37:40.408749  2788 solver.cpp:252]     Train net output #0: loss = 0.694377 (* 1 = 0.694377 loss)
I0701 15:37:40.408763  2788 sgd_solver.cpp:106] Iteration 13040, lr = 0.01
I0701 15:37:47.213125  2788 solver.cpp:236] Iteration 13050, loss = 0.693552
I0701 15:37:47.213187  2788 solver.cpp:252]     Train net output #0: loss = 0.692623 (* 1 = 0.692623 loss)
I0701 15:37:47.213201  2788 sgd_solver.cpp:106] Iteration 13050, lr = 0.01
I0701 15:37:54.003047  2788 solver.cpp:236] Iteration 13060, loss = 0.693318
I0701 15:37:54.003096  2788 solver.cpp:252]     Train net output #0: loss = 0.691158 (* 1 = 0.691158 loss)
I0701 15:37:54.003111  2788 sgd_solver.cpp:106] Iteration 13060, lr = 0.01
I0701 15:38:00.806269  2788 solver.cpp:236] Iteration 13070, loss = 0.693288
I0701 15:38:00.806329  2788 solver.cpp:252]     Train net output #0: loss = 0.692797 (* 1 = 0.692797 loss)
I0701 15:38:00.806342  2788 sgd_solver.cpp:106] Iteration 13070, lr = 0.01
I0701 15:38:07.616838  2788 solver.cpp:236] Iteration 13080, loss = 0.69324
I0701 15:38:07.617081  2788 solver.cpp:252]     Train net output #0: loss = 0.693136 (* 1 = 0.693136 loss)
I0701 15:38:07.617100  2788 sgd_solver.cpp:106] Iteration 13080, lr = 0.01
I0701 15:38:14.416833  2788 solver.cpp:236] Iteration 13090, loss = 0.693248
I0701 15:38:14.416888  2788 solver.cpp:252]     Train net output #0: loss = 0.69431 (* 1 = 0.69431 loss)
I0701 15:38:14.416903  2788 sgd_solver.cpp:106] Iteration 13090, lr = 0.01
I0701 15:38:21.227892  2788 solver.cpp:236] Iteration 13100, loss = 0.693294
I0701 15:38:21.227947  2788 solver.cpp:252]     Train net output #0: loss = 0.69304 (* 1 = 0.69304 loss)
I0701 15:38:21.227962  2788 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0701 15:38:28.034203  2788 solver.cpp:236] Iteration 13110, loss = 0.69328
I0701 15:38:28.034253  2788 solver.cpp:252]     Train net output #0: loss = 0.68915 (* 1 = 0.68915 loss)
I0701 15:38:28.034266  2788 sgd_solver.cpp:106] Iteration 13110, lr = 0.01
I0701 15:38:34.832618  2788 solver.cpp:236] Iteration 13120, loss = 0.693284
I0701 15:38:34.832682  2788 solver.cpp:252]     Train net output #0: loss = 0.694036 (* 1 = 0.694036 loss)
I0701 15:38:34.832698  2788 sgd_solver.cpp:106] Iteration 13120, lr = 0.01
I0701 15:38:41.648535  2788 solver.cpp:236] Iteration 13130, loss = 0.693384
I0701 15:38:41.648764  2788 solver.cpp:252]     Train net output #0: loss = 0.691158 (* 1 = 0.691158 loss)
I0701 15:38:41.648782  2788 sgd_solver.cpp:106] Iteration 13130, lr = 0.01
I0701 15:38:48.445361  2788 solver.cpp:236] Iteration 13140, loss = 0.693524
I0701 15:38:48.445417  2788 solver.cpp:252]     Train net output #0: loss = 0.700552 (* 1 = 0.700552 loss)
I0701 15:38:48.445432  2788 sgd_solver.cpp:106] Iteration 13140, lr = 0.01
I0701 15:38:55.248061  2788 solver.cpp:236] Iteration 13150, loss = 0.693746
I0701 15:38:55.248119  2788 solver.cpp:252]     Train net output #0: loss = 0.692365 (* 1 = 0.692365 loss)
I0701 15:38:55.248133  2788 sgd_solver.cpp:106] Iteration 13150, lr = 0.01
I0701 15:39:02.068878  2788 solver.cpp:236] Iteration 13160, loss = 0.693804
I0701 15:39:02.068928  2788 solver.cpp:252]     Train net output #0: loss = 0.692896 (* 1 = 0.692896 loss)
I0701 15:39:02.068943  2788 sgd_solver.cpp:106] Iteration 13160, lr = 0.01
I0701 15:39:08.880862  2788 solver.cpp:236] Iteration 13170, loss = 0.693491
I0701 15:39:08.880911  2788 solver.cpp:252]     Train net output #0: loss = 0.691944 (* 1 = 0.691944 loss)
I0701 15:39:08.880928  2788 sgd_solver.cpp:106] Iteration 13170, lr = 0.01
I0701 15:39:15.701095  2788 solver.cpp:236] Iteration 13180, loss = 0.693429
I0701 15:39:15.701397  2788 solver.cpp:252]     Train net output #0: loss = 0.695965 (* 1 = 0.695965 loss)
I0701 15:39:15.701414  2788 sgd_solver.cpp:106] Iteration 13180, lr = 0.01
I0701 15:39:22.504586  2788 solver.cpp:236] Iteration 13190, loss = 0.693015
I0701 15:39:22.504643  2788 solver.cpp:252]     Train net output #0: loss = 0.694363 (* 1 = 0.694363 loss)
I0701 15:39:22.504657  2788 sgd_solver.cpp:106] Iteration 13190, lr = 0.01
I0701 15:39:29.296571  2788 solver.cpp:236] Iteration 13200, loss = 0.693091
I0701 15:39:29.296627  2788 solver.cpp:252]     Train net output #0: loss = 0.691845 (* 1 = 0.691845 loss)
I0701 15:39:29.296645  2788 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0701 15:39:36.111250  2788 solver.cpp:236] Iteration 13210, loss = 0.69313
I0701 15:39:36.111306  2788 solver.cpp:252]     Train net output #0: loss = 0.69269 (* 1 = 0.69269 loss)
I0701 15:39:36.111326  2788 sgd_solver.cpp:106] Iteration 13210, lr = 0.01
I0701 15:39:42.902849  2788 solver.cpp:236] Iteration 13220, loss = 0.693248
I0701 15:39:42.902909  2788 solver.cpp:252]     Train net output #0: loss = 0.697544 (* 1 = 0.697544 loss)
I0701 15:39:42.902922  2788 sgd_solver.cpp:106] Iteration 13220, lr = 0.01
I0701 15:39:49.704730  2788 solver.cpp:236] Iteration 13230, loss = 0.693374
I0701 15:39:49.704963  2788 solver.cpp:252]     Train net output #0: loss = 0.697163 (* 1 = 0.697163 loss)
I0701 15:39:49.704978  2788 sgd_solver.cpp:106] Iteration 13230, lr = 0.01
I0701 15:39:56.527588  2788 solver.cpp:236] Iteration 13240, loss = 0.69367
I0701 15:39:56.527648  2788 solver.cpp:252]     Train net output #0: loss = 0.69239 (* 1 = 0.69239 loss)
I0701 15:39:56.527663  2788 sgd_solver.cpp:106] Iteration 13240, lr = 0.01
I0701 15:40:02.630666  2788 solver.cpp:340] Iteration 13250, Testing net (#0)
I0701 15:40:14.382663  2788 solver.cpp:408]     Test net output #0: accuracy = 0.514063
I0701 15:40:14.382721  2788 solver.cpp:408]     Test net output #1: loss = 0.693018 (* 1 = 0.693018 loss)
I0701 15:40:14.568368  2788 solver.cpp:236] Iteration 13250, loss = 0.693397
I0701 15:40:14.568429  2788 solver.cpp:252]     Train net output #0: loss = 0.693553 (* 1 = 0.693553 loss)
I0701 15:40:14.568447  2788 sgd_solver.cpp:106] Iteration 13250, lr = 0.01
I0701 15:40:21.342978  2788 solver.cpp:236] Iteration 13260, loss = 0.693374
I0701 15:40:21.348500  2788 solver.cpp:252]     Train net output #0: loss = 0.693162 (* 1 = 0.693162 loss)
I0701 15:40:21.348513  2788 sgd_solver.cpp:106] Iteration 13260, lr = 0.01
I0701 15:40:28.133654  2788 solver.cpp:236] Iteration 13270, loss = 0.693416
I0701 15:40:28.133728  2788 solver.cpp:252]     Train net output #0: loss = 0.693727 (* 1 = 0.693727 loss)
I0701 15:40:28.133746  2788 sgd_solver.cpp:106] Iteration 13270, lr = 0.01
I0701 15:40:34.913545  2788 solver.cpp:236] Iteration 13280, loss = 0.693296
I0701 15:40:34.913596  2788 solver.cpp:252]     Train net output #0: loss = 0.693461 (* 1 = 0.693461 loss)
I0701 15:40:34.913611  2788 sgd_solver.cpp:106] Iteration 13280, lr = 0.01
I0701 15:40:41.697628  2788 solver.cpp:236] Iteration 13290, loss = 0.693231
I0701 15:40:41.697675  2788 solver.cpp:252]     Train net output #0: loss = 0.692535 (* 1 = 0.692535 loss)
I0701 15:40:41.697695  2788 sgd_solver.cpp:106] Iteration 13290, lr = 0.01
I0701 15:40:48.490614  2788 solver.cpp:236] Iteration 13300, loss = 0.693187
I0701 15:40:48.490703  2788 solver.cpp:252]     Train net output #0: loss = 0.694732 (* 1 = 0.694732 loss)
I0701 15:40:48.490726  2788 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0701 15:40:55.270177  2788 solver.cpp:236] Iteration 13310, loss = 0.693302
I0701 15:40:55.270427  2788 solver.cpp:252]     Train net output #0: loss = 0.692552 (* 1 = 0.692552 loss)
I0701 15:40:55.270450  2788 sgd_solver.cpp:106] Iteration 13310, lr = 0.01
I0701 15:41:02.079277  2788 solver.cpp:236] Iteration 13320, loss = 0.693271
I0701 15:41:02.079326  2788 solver.cpp:252]     Train net output #0: loss = 0.692676 (* 1 = 0.692676 loss)
I0701 15:41:02.079340  2788 sgd_solver.cpp:106] Iteration 13320, lr = 0.01
I0701 15:41:08.870070  2788 solver.cpp:236] Iteration 13330, loss = 0.693332
I0701 15:41:08.870121  2788 solver.cpp:252]     Train net output #0: loss = 0.692776 (* 1 = 0.692776 loss)
I0701 15:41:08.870136  2788 sgd_solver.cpp:106] Iteration 13330, lr = 0.01
I0701 15:41:15.654659  2788 solver.cpp:236] Iteration 13340, loss = 0.693369
I0701 15:41:15.654727  2788 solver.cpp:252]     Train net output #0: loss = 0.691047 (* 1 = 0.691047 loss)
I0701 15:41:15.654742  2788 sgd_solver.cpp:106] Iteration 13340, lr = 0.01
I0701 15:41:22.472137  2788 solver.cpp:236] Iteration 13350, loss = 0.693568
I0701 15:41:22.472187  2788 solver.cpp:252]     Train net output #0: loss = 0.69409 (* 1 = 0.69409 loss)
I0701 15:41:22.472201  2788 sgd_solver.cpp:106] Iteration 13350, lr = 0.01
I0701 15:41:29.263043  2788 solver.cpp:236] Iteration 13360, loss = 0.6935
I0701 15:41:29.263329  2788 solver.cpp:252]     Train net output #0: loss = 0.693198 (* 1 = 0.693198 loss)
I0701 15:41:29.263346  2788 sgd_solver.cpp:106] Iteration 13360, lr = 0.01
I0701 15:41:36.056309  2788 solver.cpp:236] Iteration 13370, loss = 0.693474
I0701 15:41:36.056359  2788 solver.cpp:252]     Train net output #0: loss = 0.692823 (* 1 = 0.692823 loss)
I0701 15:41:36.056373  2788 sgd_solver.cpp:106] Iteration 13370, lr = 0.01
I0701 15:41:42.851192  2788 solver.cpp:236] Iteration 13380, loss = 0.693484
I0701 15:41:42.851239  2788 solver.cpp:252]     Train net output #0: loss = 0.693274 (* 1 = 0.693274 loss)
I0701 15:41:42.851253  2788 sgd_solver.cpp:106] Iteration 13380, lr = 0.01
I0701 15:41:49.643882  2788 solver.cpp:236] Iteration 13390, loss = 0.693468
I0701 15:41:49.643936  2788 solver.cpp:252]     Train net output #0: loss = 0.693323 (* 1 = 0.693323 loss)
I0701 15:41:49.643951  2788 sgd_solver.cpp:106] Iteration 13390, lr = 0.01
I0701 15:41:56.439550  2788 solver.cpp:236] Iteration 13400, loss = 0.693212
I0701 15:41:56.439599  2788 solver.cpp:252]     Train net output #0: loss = 0.691757 (* 1 = 0.691757 loss)
I0701 15:41:56.439616  2788 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0701 15:42:03.242738  2788 solver.cpp:236] Iteration 13410, loss = 0.69342
I0701 15:42:03.242940  2788 solver.cpp:252]     Train net output #0: loss = 0.697349 (* 1 = 0.697349 loss)
I0701 15:42:03.242957  2788 sgd_solver.cpp:106] Iteration 13410, lr = 0.01
I0701 15:42:10.045706  2788 solver.cpp:236] Iteration 13420, loss = 0.693399
I0701 15:42:10.045753  2788 solver.cpp:252]     Train net output #0: loss = 0.69198 (* 1 = 0.69198 loss)
I0701 15:42:10.045768  2788 sgd_solver.cpp:106] Iteration 13420, lr = 0.01
I0701 15:42:16.849319  2788 solver.cpp:236] Iteration 13430, loss = 0.693329
I0701 15:42:16.849372  2788 solver.cpp:252]     Train net output #0: loss = 0.693069 (* 1 = 0.693069 loss)
I0701 15:42:16.849386  2788 sgd_solver.cpp:106] Iteration 13430, lr = 0.01
I0701 15:42:23.644911  2788 solver.cpp:236] Iteration 13440, loss = 0.693368
I0701 15:42:23.644958  2788 solver.cpp:252]     Train net output #0: loss = 0.693227 (* 1 = 0.693227 loss)
I0701 15:42:23.644975  2788 sgd_solver.cpp:106] Iteration 13440, lr = 0.01
I0701 15:42:30.412284  2788 solver.cpp:236] Iteration 13450, loss = 0.693457
I0701 15:42:30.412333  2788 solver.cpp:252]     Train net output #0: loss = 0.69302 (* 1 = 0.69302 loss)
I0701 15:42:30.412348  2788 sgd_solver.cpp:106] Iteration 13450, lr = 0.01
I0701 15:42:37.212410  2788 solver.cpp:236] Iteration 13460, loss = 0.693199
I0701 15:42:37.212661  2788 solver.cpp:252]     Train net output #0: loss = 0.693097 (* 1 = 0.693097 loss)
I0701 15:42:37.212677  2788 sgd_solver.cpp:106] Iteration 13460, lr = 0.01
I0701 15:42:44.026530  2788 solver.cpp:236] Iteration 13470, loss = 0.693335
I0701 15:42:44.026583  2788 solver.cpp:252]     Train net output #0: loss = 0.694561 (* 1 = 0.694561 loss)
I0701 15:42:44.026597  2788 sgd_solver.cpp:106] Iteration 13470, lr = 0.01
I0701 15:42:50.807868  2788 solver.cpp:236] Iteration 13480, loss = 0.693302
I0701 15:42:50.807930  2788 solver.cpp:252]     Train net output #0: loss = 0.692517 (* 1 = 0.692517 loss)
I0701 15:42:50.807945  2788 sgd_solver.cpp:106] Iteration 13480, lr = 0.01
I0701 15:42:57.608865  2788 solver.cpp:236] Iteration 13490, loss = 0.693281
I0701 15:42:57.608922  2788 solver.cpp:252]     Train net output #0: loss = 0.692637 (* 1 = 0.692637 loss)
I0701 15:42:57.608935  2788 sgd_solver.cpp:106] Iteration 13490, lr = 0.01
I0701 15:43:03.711020  2788 solver.cpp:340] Iteration 13500, Testing net (#0)
I0701 15:43:16.759047  2788 solver.cpp:408]     Test net output #0: accuracy = 0.503125
I0701 15:43:16.759223  2788 solver.cpp:408]     Test net output #1: loss = 0.693139 (* 1 = 0.693139 loss)
I0701 15:43:16.942446  2788 solver.cpp:236] Iteration 13500, loss = 0.693315
I0701 15:43:16.942507  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 15:43:16.942523  2788 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0701 15:43:23.726618  2788 solver.cpp:236] Iteration 13510, loss = 0.693306
I0701 15:43:23.726663  2788 solver.cpp:252]     Train net output #0: loss = 0.69498 (* 1 = 0.69498 loss)
I0701 15:43:23.726677  2788 sgd_solver.cpp:106] Iteration 13510, lr = 0.01
I0701 15:43:30.511132  2788 solver.cpp:236] Iteration 13520, loss = 0.693271
I0701 15:43:30.511185  2788 solver.cpp:252]     Train net output #0: loss = 0.692963 (* 1 = 0.692963 loss)
I0701 15:43:30.511199  2788 sgd_solver.cpp:106] Iteration 13520, lr = 0.01
I0701 15:43:37.282974  2788 solver.cpp:236] Iteration 13530, loss = 0.693305
I0701 15:43:37.283032  2788 solver.cpp:252]     Train net output #0: loss = 0.692722 (* 1 = 0.692722 loss)
I0701 15:43:37.283046  2788 sgd_solver.cpp:106] Iteration 13530, lr = 0.01
I0701 15:43:44.090045  2788 solver.cpp:236] Iteration 13540, loss = 0.693235
I0701 15:43:44.090092  2788 solver.cpp:252]     Train net output #0: loss = 0.692209 (* 1 = 0.692209 loss)
I0701 15:43:44.090106  2788 sgd_solver.cpp:106] Iteration 13540, lr = 0.01
I0701 15:43:50.891559  2788 solver.cpp:236] Iteration 13550, loss = 0.693165
I0701 15:43:50.891685  2788 solver.cpp:252]     Train net output #0: loss = 0.695101 (* 1 = 0.695101 loss)
I0701 15:43:50.891713  2788 sgd_solver.cpp:106] Iteration 13550, lr = 0.01
I0701 15:43:57.684078  2788 solver.cpp:236] Iteration 13560, loss = 0.693231
I0701 15:43:57.684125  2788 solver.cpp:252]     Train net output #0: loss = 0.693598 (* 1 = 0.693598 loss)
I0701 15:43:57.684139  2788 sgd_solver.cpp:106] Iteration 13560, lr = 0.01
I0701 15:44:04.485613  2788 solver.cpp:236] Iteration 13570, loss = 0.693235
I0701 15:44:04.485663  2788 solver.cpp:252]     Train net output #0: loss = 0.694192 (* 1 = 0.694192 loss)
I0701 15:44:04.485677  2788 sgd_solver.cpp:106] Iteration 13570, lr = 0.01
I0701 15:44:11.291609  2788 solver.cpp:236] Iteration 13580, loss = 0.693258
I0701 15:44:11.291666  2788 solver.cpp:252]     Train net output #0: loss = 0.692437 (* 1 = 0.692437 loss)
I0701 15:44:11.291682  2788 sgd_solver.cpp:106] Iteration 13580, lr = 0.01
I0701 15:44:18.083860  2788 solver.cpp:236] Iteration 13590, loss = 0.693375
I0701 15:44:18.083914  2788 solver.cpp:252]     Train net output #0: loss = 0.693341 (* 1 = 0.693341 loss)
I0701 15:44:18.083926  2788 sgd_solver.cpp:106] Iteration 13590, lr = 0.01
I0701 15:44:24.900152  2788 solver.cpp:236] Iteration 13600, loss = 0.693449
I0701 15:44:24.900390  2788 solver.cpp:252]     Train net output #0: loss = 0.693214 (* 1 = 0.693214 loss)
I0701 15:44:24.900408  2788 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0701 15:44:31.691054  2788 solver.cpp:236] Iteration 13610, loss = 0.693363
I0701 15:44:31.691134  2788 solver.cpp:252]     Train net output #0: loss = 0.695753 (* 1 = 0.695753 loss)
I0701 15:44:31.691155  2788 sgd_solver.cpp:106] Iteration 13610, lr = 0.01
I0701 15:44:38.491358  2788 solver.cpp:236] Iteration 13620, loss = 0.693282
I0701 15:44:38.491412  2788 solver.cpp:252]     Train net output #0: loss = 0.693869 (* 1 = 0.693869 loss)
I0701 15:44:38.491427  2788 sgd_solver.cpp:106] Iteration 13620, lr = 0.01
I0701 15:44:45.308446  2788 solver.cpp:236] Iteration 13630, loss = 0.693303
I0701 15:44:45.308500  2788 solver.cpp:252]     Train net output #0: loss = 0.693041 (* 1 = 0.693041 loss)
I0701 15:44:45.308514  2788 sgd_solver.cpp:106] Iteration 13630, lr = 0.01
I0701 15:44:52.102953  2788 solver.cpp:236] Iteration 13640, loss = 0.693222
I0701 15:44:52.103003  2788 solver.cpp:252]     Train net output #0: loss = 0.693604 (* 1 = 0.693604 loss)
I0701 15:44:52.103018  2788 sgd_solver.cpp:106] Iteration 13640, lr = 0.01
I0701 15:44:58.921576  2788 solver.cpp:236] Iteration 13650, loss = 0.693272
I0701 15:44:58.921847  2788 solver.cpp:252]     Train net output #0: loss = 0.693381 (* 1 = 0.693381 loss)
I0701 15:44:58.921869  2788 sgd_solver.cpp:106] Iteration 13650, lr = 0.01
I0701 15:45:05.728235  2788 solver.cpp:236] Iteration 13660, loss = 0.69324
I0701 15:45:05.728292  2788 solver.cpp:252]     Train net output #0: loss = 0.693382 (* 1 = 0.693382 loss)
I0701 15:45:05.728312  2788 sgd_solver.cpp:106] Iteration 13660, lr = 0.01
I0701 15:45:12.544849  2788 solver.cpp:236] Iteration 13670, loss = 0.693408
I0701 15:45:12.544975  2788 solver.cpp:252]     Train net output #0: loss = 0.692583 (* 1 = 0.692583 loss)
I0701 15:45:12.545001  2788 sgd_solver.cpp:106] Iteration 13670, lr = 0.01
I0701 15:45:19.356807  2788 solver.cpp:236] Iteration 13680, loss = 0.693376
I0701 15:45:19.356879  2788 solver.cpp:252]     Train net output #0: loss = 0.693416 (* 1 = 0.693416 loss)
I0701 15:45:19.356932  2788 sgd_solver.cpp:106] Iteration 13680, lr = 0.01
I0701 15:45:26.151245  2788 solver.cpp:236] Iteration 13690, loss = 0.693348
I0701 15:45:26.151293  2788 solver.cpp:252]     Train net output #0: loss = 0.692697 (* 1 = 0.692697 loss)
I0701 15:45:26.151307  2788 sgd_solver.cpp:106] Iteration 13690, lr = 0.01
I0701 15:45:32.970387  2788 solver.cpp:236] Iteration 13700, loss = 0.693227
I0701 15:45:32.970595  2788 solver.cpp:252]     Train net output #0: loss = 0.691246 (* 1 = 0.691246 loss)
I0701 15:45:32.970618  2788 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0701 15:45:39.762476  2788 solver.cpp:236] Iteration 13710, loss = 0.693563
I0701 15:45:39.762542  2788 solver.cpp:252]     Train net output #0: loss = 0.692276 (* 1 = 0.692276 loss)
I0701 15:45:39.762560  2788 sgd_solver.cpp:106] Iteration 13710, lr = 0.01
I0701 15:45:46.548152  2788 solver.cpp:236] Iteration 13720, loss = 0.69358
I0701 15:45:46.548207  2788 solver.cpp:252]     Train net output #0: loss = 0.694514 (* 1 = 0.694514 loss)
I0701 15:45:46.548224  2788 sgd_solver.cpp:106] Iteration 13720, lr = 0.01
I0701 15:45:53.355973  2788 solver.cpp:236] Iteration 13730, loss = 0.693526
I0701 15:45:53.356037  2788 solver.cpp:252]     Train net output #0: loss = 0.694067 (* 1 = 0.694067 loss)
I0701 15:45:53.356056  2788 sgd_solver.cpp:106] Iteration 13730, lr = 0.01
I0701 15:46:00.157647  2788 solver.cpp:236] Iteration 13740, loss = 0.693535
I0701 15:46:00.157696  2788 solver.cpp:252]     Train net output #0: loss = 0.695115 (* 1 = 0.695115 loss)
I0701 15:46:00.157711  2788 sgd_solver.cpp:106] Iteration 13740, lr = 0.01
I0701 15:46:06.283156  2788 solver.cpp:340] Iteration 13750, Testing net (#0)
I0701 15:46:18.092695  2788 solver.cpp:408]     Test net output #0: accuracy = 0.50375
I0701 15:46:18.092751  2788 solver.cpp:408]     Test net output #1: loss = 0.693132 (* 1 = 0.693132 loss)
I0701 15:46:18.275424  2788 solver.cpp:236] Iteration 13750, loss = 0.693671
I0701 15:46:18.275485  2788 solver.cpp:252]     Train net output #0: loss = 0.694796 (* 1 = 0.694796 loss)
I0701 15:46:18.275503  2788 sgd_solver.cpp:106] Iteration 13750, lr = 0.01
I0701 15:46:25.070118  2788 solver.cpp:236] Iteration 13760, loss = 0.693315
I0701 15:46:25.070174  2788 solver.cpp:252]     Train net output #0: loss = 0.69205 (* 1 = 0.69205 loss)
I0701 15:46:25.070188  2788 sgd_solver.cpp:106] Iteration 13760, lr = 0.01
I0701 15:46:31.847335  2788 solver.cpp:236] Iteration 13770, loss = 0.693286
I0701 15:46:31.847383  2788 solver.cpp:252]     Train net output #0: loss = 0.692856 (* 1 = 0.692856 loss)
I0701 15:46:31.847398  2788 sgd_solver.cpp:106] Iteration 13770, lr = 0.01
I0701 15:46:38.652026  2788 solver.cpp:236] Iteration 13780, loss = 0.693302
I0701 15:46:38.652166  2788 solver.cpp:252]     Train net output #0: loss = 0.693248 (* 1 = 0.693248 loss)
I0701 15:46:38.652204  2788 sgd_solver.cpp:106] Iteration 13780, lr = 0.01
I0701 15:46:45.439280  2788 solver.cpp:236] Iteration 13790, loss = 0.693343
I0701 15:46:45.439338  2788 solver.cpp:252]     Train net output #0: loss = 0.693504 (* 1 = 0.693504 loss)
I0701 15:46:45.439354  2788 sgd_solver.cpp:106] Iteration 13790, lr = 0.01
I0701 15:46:52.231621  2788 solver.cpp:236] Iteration 13800, loss = 0.693263
I0701 15:46:52.231670  2788 solver.cpp:252]     Train net output #0: loss = 0.693937 (* 1 = 0.693937 loss)
I0701 15:46:52.231684  2788 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0701 15:46:59.033449  2788 solver.cpp:236] Iteration 13810, loss = 0.693353
I0701 15:46:59.033494  2788 solver.cpp:252]     Train net output #0: loss = 0.693156 (* 1 = 0.693156 loss)
I0701 15:46:59.033507  2788 sgd_solver.cpp:106] Iteration 13810, lr = 0.01
I0701 15:47:05.810243  2788 solver.cpp:236] Iteration 13820, loss = 0.69328
I0701 15:47:05.810297  2788 solver.cpp:252]     Train net output #0: loss = 0.694233 (* 1 = 0.694233 loss)
I0701 15:47:05.810312  2788 sgd_solver.cpp:106] Iteration 13820, lr = 0.01
I0701 15:47:12.616606  2788 solver.cpp:236] Iteration 13830, loss = 0.693286
I0701 15:47:12.616755  2788 solver.cpp:252]     Train net output #0: loss = 0.693078 (* 1 = 0.693078 loss)
I0701 15:47:12.616770  2788 sgd_solver.cpp:106] Iteration 13830, lr = 0.01
I0701 15:47:19.402063  2788 solver.cpp:236] Iteration 13840, loss = 0.693279
I0701 15:47:19.402124  2788 solver.cpp:252]     Train net output #0: loss = 0.693007 (* 1 = 0.693007 loss)
I0701 15:47:19.402142  2788 sgd_solver.cpp:106] Iteration 13840, lr = 0.01
I0701 15:47:26.200561  2788 solver.cpp:236] Iteration 13850, loss = 0.693275
I0701 15:47:26.200624  2788 solver.cpp:252]     Train net output #0: loss = 0.69308 (* 1 = 0.69308 loss)
I0701 15:47:26.200651  2788 sgd_solver.cpp:106] Iteration 13850, lr = 0.01
I0701 15:47:33.022142  2788 solver.cpp:236] Iteration 13860, loss = 0.693213
I0701 15:47:33.022202  2788 solver.cpp:252]     Train net output #0: loss = 0.693263 (* 1 = 0.693263 loss)
I0701 15:47:33.022222  2788 sgd_solver.cpp:106] Iteration 13860, lr = 0.01
I0701 15:47:39.802856  2788 solver.cpp:236] Iteration 13870, loss = 0.693185
I0701 15:47:39.802916  2788 solver.cpp:252]     Train net output #0: loss = 0.692019 (* 1 = 0.692019 loss)
I0701 15:47:39.802934  2788 sgd_solver.cpp:106] Iteration 13870, lr = 0.01
I0701 15:47:46.609163  2788 solver.cpp:236] Iteration 13880, loss = 0.693199
I0701 15:47:46.609349  2788 solver.cpp:252]     Train net output #0: loss = 0.692423 (* 1 = 0.692423 loss)
I0701 15:47:46.609374  2788 sgd_solver.cpp:106] Iteration 13880, lr = 0.01
I0701 15:47:53.428490  2788 solver.cpp:236] Iteration 13890, loss = 0.693313
I0701 15:47:53.428558  2788 solver.cpp:252]     Train net output #0: loss = 0.692936 (* 1 = 0.692936 loss)
I0701 15:47:53.428572  2788 sgd_solver.cpp:106] Iteration 13890, lr = 0.01
I0701 15:48:00.246726  2788 solver.cpp:236] Iteration 13900, loss = 0.69334
I0701 15:48:00.246780  2788 solver.cpp:252]     Train net output #0: loss = 0.693857 (* 1 = 0.693857 loss)
I0701 15:48:00.246794  2788 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0701 15:48:07.054196  2788 solver.cpp:236] Iteration 13910, loss = 0.693372
I0701 15:48:07.054245  2788 solver.cpp:252]     Train net output #0: loss = 0.693451 (* 1 = 0.693451 loss)
I0701 15:48:07.054260  2788 sgd_solver.cpp:106] Iteration 13910, lr = 0.01
I0701 15:48:13.867174  2788 solver.cpp:236] Iteration 13920, loss = 0.693385
I0701 15:48:13.867223  2788 solver.cpp:252]     Train net output #0: loss = 0.69182 (* 1 = 0.69182 loss)
I0701 15:48:13.867238  2788 sgd_solver.cpp:106] Iteration 13920, lr = 0.01
I0701 15:48:20.691011  2788 solver.cpp:236] Iteration 13930, loss = 0.693211
I0701 15:48:20.691227  2788 solver.cpp:252]     Train net output #0: loss = 0.690952 (* 1 = 0.690952 loss)
I0701 15:48:20.691251  2788 sgd_solver.cpp:106] Iteration 13930, lr = 0.01
I0701 15:48:27.519774  2788 solver.cpp:236] Iteration 13940, loss = 0.693259
I0701 15:48:27.519860  2788 solver.cpp:252]     Train net output #0: loss = 0.694134 (* 1 = 0.694134 loss)
I0701 15:48:27.519881  2788 sgd_solver.cpp:106] Iteration 13940, lr = 0.01
I0701 15:48:35.151185  2788 solver.cpp:236] Iteration 13950, loss = 0.693255
I0701 15:48:35.151242  2788 solver.cpp:252]     Train net output #0: loss = 0.693139 (* 1 = 0.693139 loss)
I0701 15:48:35.151269  2788 sgd_solver.cpp:106] Iteration 13950, lr = 0.01
I0701 15:49:04.331063  2788 solver.cpp:236] Iteration 13960, loss = 0.693229
I0701 15:49:04.351466  2788 solver.cpp:252]     Train net output #0: loss = 0.695516 (* 1 = 0.695516 loss)
I0701 15:49:04.351493  2788 sgd_solver.cpp:106] Iteration 13960, lr = 0.01
I0701 15:49:28.571436  2788 solver.cpp:236] Iteration 13970, loss = 0.693328
I0701 15:49:28.571503  2788 solver.cpp:252]     Train net output #0: loss = 0.691908 (* 1 = 0.691908 loss)
I0701 15:49:28.571522  2788 sgd_solver.cpp:106] Iteration 13970, lr = 0.01
I0701 15:49:50.253948  2788 solver.cpp:236] Iteration 13980, loss = 0.693332
I0701 15:49:50.254304  2788 solver.cpp:252]     Train net output #0: loss = 0.696526 (* 1 = 0.696526 loss)
I0701 15:49:50.254320  2788 sgd_solver.cpp:106] Iteration 13980, lr = 0.01
I0701 15:50:06.686206  2788 solver.cpp:236] Iteration 13990, loss = 0.693004
I0701 15:50:06.686259  2788 solver.cpp:252]     Train net output #0: loss = 0.68925 (* 1 = 0.68925 loss)
I0701 15:50:06.686274  2788 sgd_solver.cpp:106] Iteration 13990, lr = 0.01
I0701 15:50:20.091384  2788 solver.cpp:340] Iteration 14000, Testing net (#0)
I0701 15:50:48.789480  2788 solver.cpp:408]     Test net output #0: accuracy = 0.49125
I0701 15:50:48.789643  2788 solver.cpp:408]     Test net output #1: loss = 0.694198 (* 1 = 0.694198 loss)
I0701 15:50:49.028311  2788 solver.cpp:236] Iteration 14000, loss = 0.692856
I0701 15:50:49.028380  2788 solver.cpp:252]     Train net output #0: loss = 0.692165 (* 1 = 0.692165 loss)
I0701 15:50:49.028403  2788 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0701 15:50:59.759197  2788 solver.cpp:236] Iteration 14010, loss = 0.692585
I0701 15:50:59.759249  2788 solver.cpp:252]     Train net output #0: loss = 0.693508 (* 1 = 0.693508 loss)
I0701 15:50:59.759263  2788 sgd_solver.cpp:106] Iteration 14010, lr = 0.01
I0701 15:51:13.224896  2788 solver.cpp:236] Iteration 14020, loss = 0.692479
I0701 15:51:13.224946  2788 solver.cpp:252]     Train net output #0: loss = 0.695843 (* 1 = 0.695843 loss)
I0701 15:51:13.224959  2788 sgd_solver.cpp:106] Iteration 14020, lr = 0.01
I0701 15:51:25.994267  2788 solver.cpp:236] Iteration 14030, loss = 0.692842
I0701 15:51:25.994473  2788 solver.cpp:252]     Train net output #0: loss = 0.69725 (* 1 = 0.69725 loss)
I0701 15:51:25.994498  2788 sgd_solver.cpp:106] Iteration 14030, lr = 0.01
I0701 15:51:39.067212  2788 solver.cpp:236] Iteration 14040, loss = 0.692919
I0701 15:51:39.067266  2788 solver.cpp:252]     Train net output #0: loss = 0.69477 (* 1 = 0.69477 loss)
I0701 15:51:39.067281  2788 sgd_solver.cpp:106] Iteration 14040, lr = 0.01
I0701 15:51:51.734927  2788 solver.cpp:236] Iteration 14050, loss = 0.692934
I0701 15:51:51.734998  2788 solver.cpp:252]     Train net output #0: loss = 0.693565 (* 1 = 0.693565 loss)
I0701 15:51:51.735013  2788 sgd_solver.cpp:106] Iteration 14050, lr = 0.01
I0701 15:52:04.690153  2788 solver.cpp:236] Iteration 14060, loss = 0.693288
I0701 15:52:04.690471  2788 solver.cpp:252]     Train net output #0: loss = 0.693608 (* 1 = 0.693608 loss)
I0701 15:52:04.690495  2788 sgd_solver.cpp:106] Iteration 14060, lr = 0.01
I0701 15:52:17.854586  2788 solver.cpp:236] Iteration 14070, loss = 0.693316
I0701 15:52:17.854631  2788 solver.cpp:252]     Train net output #0: loss = 0.691869 (* 1 = 0.691869 loss)
I0701 15:52:17.854645  2788 sgd_solver.cpp:106] Iteration 14070, lr = 0.01
I0701 15:52:30.985973  2788 solver.cpp:236] Iteration 14080, loss = 0.693056
I0701 15:52:30.986048  2788 solver.cpp:252]     Train net output #0: loss = 0.692724 (* 1 = 0.692724 loss)
I0701 15:52:30.986063  2788 sgd_solver.cpp:106] Iteration 14080, lr = 0.01
I0701 15:52:43.845692  2788 solver.cpp:236] Iteration 14090, loss = 0.693249
I0701 15:52:43.845839  2788 solver.cpp:252]     Train net output #0: loss = 0.693954 (* 1 = 0.693954 loss)
I0701 15:52:43.845865  2788 sgd_solver.cpp:106] Iteration 14090, lr = 0.01
I0701 15:52:56.798032  2788 solver.cpp:236] Iteration 14100, loss = 0.693232
I0701 15:52:56.798089  2788 solver.cpp:252]     Train net output #0: loss = 0.690898 (* 1 = 0.690898 loss)
I0701 15:52:56.798105  2788 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0701 15:53:09.840620  2788 solver.cpp:236] Iteration 14110, loss = 0.693206
I0701 15:53:09.840678  2788 solver.cpp:252]     Train net output #0: loss = 0.697483 (* 1 = 0.697483 loss)
I0701 15:53:09.840693  2788 sgd_solver.cpp:106] Iteration 14110, lr = 0.01
I0701 15:53:22.924125  2788 solver.cpp:236] Iteration 14120, loss = 0.69286
I0701 15:53:22.924314  2788 solver.cpp:252]     Train net output #0: loss = 0.699002 (* 1 = 0.699002 loss)
I0701 15:53:22.924341  2788 sgd_solver.cpp:106] Iteration 14120, lr = 0.01
I0701 15:53:35.595531  2788 solver.cpp:236] Iteration 14130, loss = 0.693086
I0701 15:53:35.595624  2788 solver.cpp:252]     Train net output #0: loss = 0.693309 (* 1 = 0.693309 loss)
I0701 15:53:35.595643  2788 sgd_solver.cpp:106] Iteration 14130, lr = 0.01
I0701 15:53:48.948441  2788 solver.cpp:236] Iteration 14140, loss = 0.693143
I0701 15:53:48.948490  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 15:53:48.948504  2788 sgd_solver.cpp:106] Iteration 14140, lr = 0.01
I0701 15:54:02.729648  2788 solver.cpp:236] Iteration 14150, loss = 0.693292
I0701 15:54:02.729828  2788 solver.cpp:252]     Train net output #0: loss = 0.699499 (* 1 = 0.699499 loss)
I0701 15:54:02.729853  2788 sgd_solver.cpp:106] Iteration 14150, lr = 0.01
I0701 15:54:16.518399  2788 solver.cpp:236] Iteration 14160, loss = 0.693218
I0701 15:54:16.518450  2788 solver.cpp:252]     Train net output #0: loss = 0.693136 (* 1 = 0.693136 loss)
I0701 15:54:16.518463  2788 sgd_solver.cpp:106] Iteration 14160, lr = 0.01
I0701 15:54:30.007704  2788 solver.cpp:236] Iteration 14170, loss = 0.693335
I0701 15:54:30.007768  2788 solver.cpp:252]     Train net output #0: loss = 0.693259 (* 1 = 0.693259 loss)
I0701 15:54:30.007784  2788 sgd_solver.cpp:106] Iteration 14170, lr = 0.01
I0701 15:54:43.218029  2788 solver.cpp:236] Iteration 14180, loss = 0.693408
I0701 15:54:43.218191  2788 solver.cpp:252]     Train net output #0: loss = 0.703993 (* 1 = 0.703993 loss)
I0701 15:54:43.218215  2788 sgd_solver.cpp:106] Iteration 14180, lr = 0.01
I0701 15:54:56.344868  2788 solver.cpp:236] Iteration 14190, loss = 0.693331
I0701 15:54:56.344925  2788 solver.cpp:252]     Train net output #0: loss = 0.69301 (* 1 = 0.69301 loss)
I0701 15:54:56.344940  2788 sgd_solver.cpp:106] Iteration 14190, lr = 0.01
I0701 15:55:09.853886  2788 solver.cpp:236] Iteration 14200, loss = 0.693306
I0701 15:55:09.853947  2788 solver.cpp:252]     Train net output #0: loss = 0.693934 (* 1 = 0.693934 loss)
I0701 15:55:09.853961  2788 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0701 15:55:23.119621  2788 solver.cpp:236] Iteration 14210, loss = 0.693373
I0701 15:55:23.119797  2788 solver.cpp:252]     Train net output #0: loss = 0.693192 (* 1 = 0.693192 loss)
I0701 15:55:23.119835  2788 sgd_solver.cpp:106] Iteration 14210, lr = 0.01
I0701 15:55:36.385085  2788 solver.cpp:236] Iteration 14220, loss = 0.693573
I0701 15:55:36.385170  2788 solver.cpp:252]     Train net output #0: loss = 0.693438 (* 1 = 0.693438 loss)
I0701 15:55:36.385185  2788 sgd_solver.cpp:106] Iteration 14220, lr = 0.01
I0701 15:55:49.340397  2788 solver.cpp:236] Iteration 14230, loss = 0.693346
I0701 15:55:49.340479  2788 solver.cpp:252]     Train net output #0: loss = 0.693445 (* 1 = 0.693445 loss)
I0701 15:55:49.340497  2788 sgd_solver.cpp:106] Iteration 14230, lr = 0.01
I0701 15:56:01.265019  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 15:56:02.591542  2788 solver.cpp:236] Iteration 14240, loss = 0.693334
I0701 15:56:02.591591  2788 solver.cpp:252]     Train net output #0: loss = 0.692784 (* 1 = 0.692784 loss)
I0701 15:56:02.591605  2788 sgd_solver.cpp:106] Iteration 14240, lr = 0.01
I0701 15:56:14.009831  2788 solver.cpp:340] Iteration 14250, Testing net (#0)
I0701 15:56:42.141441  2788 solver.cpp:408]     Test net output #0: accuracy = 0.508438
I0701 15:56:42.141697  2788 solver.cpp:408]     Test net output #1: loss = 0.693006 (* 1 = 0.693006 loss)
I0701 15:56:42.372526  2788 solver.cpp:236] Iteration 14250, loss = 0.693451
I0701 15:56:42.372586  2788 solver.cpp:252]     Train net output #0: loss = 0.694164 (* 1 = 0.694164 loss)
I0701 15:56:42.372603  2788 sgd_solver.cpp:106] Iteration 14250, lr = 0.01
I0701 15:56:53.252363  2788 solver.cpp:236] Iteration 14260, loss = 0.693483
I0701 15:56:53.252418  2788 solver.cpp:252]     Train net output #0: loss = 0.693866 (* 1 = 0.693866 loss)
I0701 15:56:53.252449  2788 sgd_solver.cpp:106] Iteration 14260, lr = 0.01
I0701 15:57:07.049996  2788 solver.cpp:236] Iteration 14270, loss = 0.693503
I0701 15:57:07.050061  2788 solver.cpp:252]     Train net output #0: loss = 0.692434 (* 1 = 0.692434 loss)
I0701 15:57:07.050077  2788 sgd_solver.cpp:106] Iteration 14270, lr = 0.01
I0701 15:57:20.692589  2788 solver.cpp:236] Iteration 14280, loss = 0.693504
I0701 15:57:20.692842  2788 solver.cpp:252]     Train net output #0: loss = 0.693356 (* 1 = 0.693356 loss)
I0701 15:57:20.692859  2788 sgd_solver.cpp:106] Iteration 14280, lr = 0.01
I0701 15:57:34.315223  2788 solver.cpp:236] Iteration 14290, loss = 0.693427
I0701 15:57:34.315279  2788 solver.cpp:252]     Train net output #0: loss = 0.693759 (* 1 = 0.693759 loss)
I0701 15:57:34.315294  2788 sgd_solver.cpp:106] Iteration 14290, lr = 0.01
I0701 15:57:48.607547  2788 solver.cpp:236] Iteration 14300, loss = 0.693308
I0701 15:57:48.607617  2788 solver.cpp:252]     Train net output #0: loss = 0.693261 (* 1 = 0.693261 loss)
I0701 15:57:48.607640  2788 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0701 15:58:01.747125  2788 solver.cpp:236] Iteration 14310, loss = 0.693106
I0701 15:58:01.747344  2788 solver.cpp:252]     Train net output #0: loss = 0.688542 (* 1 = 0.688542 loss)
I0701 15:58:01.747359  2788 sgd_solver.cpp:106] Iteration 14310, lr = 0.01
I0701 15:58:15.651167  2788 solver.cpp:236] Iteration 14320, loss = 0.6934
I0701 15:58:15.651224  2788 solver.cpp:252]     Train net output #0: loss = 0.696607 (* 1 = 0.696607 loss)
I0701 15:58:15.651239  2788 sgd_solver.cpp:106] Iteration 14320, lr = 0.01
I0701 15:58:29.173569  2788 solver.cpp:236] Iteration 14330, loss = 0.693424
I0701 15:58:29.173619  2788 solver.cpp:252]     Train net output #0: loss = 0.692214 (* 1 = 0.692214 loss)
I0701 15:58:29.173632  2788 sgd_solver.cpp:106] Iteration 14330, lr = 0.01
I0701 15:58:43.305860  2788 solver.cpp:236] Iteration 14340, loss = 0.693366
I0701 15:58:43.306041  2788 solver.cpp:252]     Train net output #0: loss = 0.691357 (* 1 = 0.691357 loss)
I0701 15:58:43.306064  2788 sgd_solver.cpp:106] Iteration 14340, lr = 0.01
I0701 15:58:57.124239  2788 solver.cpp:236] Iteration 14350, loss = 0.693459
I0701 15:58:57.124290  2788 solver.cpp:252]     Train net output #0: loss = 0.693226 (* 1 = 0.693226 loss)
I0701 15:58:57.124310  2788 sgd_solver.cpp:106] Iteration 14350, lr = 0.01
I0701 15:59:11.003123  2788 solver.cpp:236] Iteration 14360, loss = 0.693635
I0701 15:59:11.003198  2788 solver.cpp:252]     Train net output #0: loss = 0.695218 (* 1 = 0.695218 loss)
I0701 15:59:11.003218  2788 sgd_solver.cpp:106] Iteration 14360, lr = 0.01
I0701 15:59:25.497735  2788 solver.cpp:236] Iteration 14370, loss = 0.693129
I0701 15:59:25.497957  2788 solver.cpp:252]     Train net output #0: loss = 0.691396 (* 1 = 0.691396 loss)
I0701 15:59:25.497973  2788 sgd_solver.cpp:106] Iteration 14370, lr = 0.01
I0701 15:59:38.601104  2788 solver.cpp:236] Iteration 14380, loss = 0.69317
I0701 15:59:38.601192  2788 solver.cpp:252]     Train net output #0: loss = 0.696644 (* 1 = 0.696644 loss)
I0701 15:59:38.601222  2788 sgd_solver.cpp:106] Iteration 14380, lr = 0.01
I0701 15:59:52.263520  2788 solver.cpp:236] Iteration 14390, loss = 0.693246
I0701 15:59:52.263581  2788 solver.cpp:252]     Train net output #0: loss = 0.692723 (* 1 = 0.692723 loss)
I0701 15:59:52.263597  2788 sgd_solver.cpp:106] Iteration 14390, lr = 0.01
I0701 16:00:06.857213  2788 solver.cpp:236] Iteration 14400, loss = 0.693139
I0701 16:00:06.857580  2788 solver.cpp:252]     Train net output #0: loss = 0.693154 (* 1 = 0.693154 loss)
I0701 16:00:06.857599  2788 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0701 16:00:20.874307  2788 solver.cpp:236] Iteration 14410, loss = 0.693078
I0701 16:00:20.874377  2788 solver.cpp:252]     Train net output #0: loss = 0.69266 (* 1 = 0.69266 loss)
I0701 16:00:20.874400  2788 sgd_solver.cpp:106] Iteration 14410, lr = 0.01
I0701 16:00:35.037729  2788 solver.cpp:236] Iteration 14420, loss = 0.693146
I0701 16:00:35.037791  2788 solver.cpp:252]     Train net output #0: loss = 0.693516 (* 1 = 0.693516 loss)
I0701 16:00:35.037806  2788 sgd_solver.cpp:106] Iteration 14420, lr = 0.01
I0701 16:00:48.857728  2788 solver.cpp:236] Iteration 14430, loss = 0.693111
I0701 16:00:48.857888  2788 solver.cpp:252]     Train net output #0: loss = 0.695846 (* 1 = 0.695846 loss)
I0701 16:00:48.857918  2788 sgd_solver.cpp:106] Iteration 14430, lr = 0.01
I0701 16:01:02.254140  2788 solver.cpp:236] Iteration 14440, loss = 0.693093
I0701 16:01:02.254192  2788 solver.cpp:252]     Train net output #0: loss = 0.69573 (* 1 = 0.69573 loss)
I0701 16:01:02.254206  2788 sgd_solver.cpp:106] Iteration 14440, lr = 0.01
I0701 16:01:16.564640  2788 solver.cpp:236] Iteration 14450, loss = 0.693182
I0701 16:01:16.564694  2788 solver.cpp:252]     Train net output #0: loss = 0.692242 (* 1 = 0.692242 loss)
I0701 16:01:16.564708  2788 sgd_solver.cpp:106] Iteration 14450, lr = 0.01
I0701 16:01:30.824751  2788 solver.cpp:236] Iteration 14460, loss = 0.693429
I0701 16:01:30.824931  2788 solver.cpp:252]     Train net output #0: loss = 0.696609 (* 1 = 0.696609 loss)
I0701 16:01:30.824960  2788 sgd_solver.cpp:106] Iteration 14460, lr = 0.01
I0701 16:01:47.631868  2788 solver.cpp:236] Iteration 14470, loss = 0.693609
I0701 16:01:47.631927  2788 solver.cpp:252]     Train net output #0: loss = 0.692029 (* 1 = 0.692029 loss)
I0701 16:01:47.631943  2788 sgd_solver.cpp:106] Iteration 14470, lr = 0.01
I0701 16:02:10.082981  2788 solver.cpp:236] Iteration 14480, loss = 0.693528
I0701 16:02:10.083161  2788 solver.cpp:252]     Train net output #0: loss = 0.693185 (* 1 = 0.693185 loss)
I0701 16:02:10.083180  2788 sgd_solver.cpp:106] Iteration 14480, lr = 0.01
I0701 16:02:33.285605  2788 solver.cpp:236] Iteration 14490, loss = 0.693489
I0701 16:02:33.285658  2788 solver.cpp:252]     Train net output #0: loss = 0.692076 (* 1 = 0.692076 loss)
I0701 16:02:33.285673  2788 sgd_solver.cpp:106] Iteration 14490, lr = 0.01
I0701 16:02:46.121681  2788 solver.cpp:340] Iteration 14500, Testing net (#0)
I0701 16:03:18.928393  2788 solver.cpp:408]     Test net output #0: accuracy = 0.497813
I0701 16:03:18.928603  2788 solver.cpp:408]     Test net output #1: loss = 0.693408 (* 1 = 0.693408 loss)
I0701 16:03:19.163816  2788 solver.cpp:236] Iteration 14500, loss = 0.69346
I0701 16:03:19.163851  2788 solver.cpp:252]     Train net output #0: loss = 0.693326 (* 1 = 0.693326 loss)
I0701 16:03:19.163864  2788 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0701 16:03:30.235172  2788 solver.cpp:236] Iteration 14510, loss = 0.69319
I0701 16:03:30.235224  2788 solver.cpp:252]     Train net output #0: loss = 0.694287 (* 1 = 0.694287 loss)
I0701 16:03:30.235237  2788 sgd_solver.cpp:106] Iteration 14510, lr = 0.01
I0701 16:03:44.054118  2788 solver.cpp:236] Iteration 14520, loss = 0.693205
I0701 16:03:44.054174  2788 solver.cpp:252]     Train net output #0: loss = 0.6931 (* 1 = 0.6931 loss)
I0701 16:03:44.054189  2788 sgd_solver.cpp:106] Iteration 14520, lr = 0.01
I0701 16:03:58.672888  2788 solver.cpp:236] Iteration 14530, loss = 0.693292
I0701 16:03:58.673235  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 16:03:58.673269  2788 sgd_solver.cpp:106] Iteration 14530, lr = 0.01
I0701 16:04:12.775974  2788 solver.cpp:236] Iteration 14540, loss = 0.69336
I0701 16:04:12.776036  2788 solver.cpp:252]     Train net output #0: loss = 0.694017 (* 1 = 0.694017 loss)
I0701 16:04:12.776051  2788 sgd_solver.cpp:106] Iteration 14540, lr = 0.01
I0701 16:04:26.360494  2788 solver.cpp:236] Iteration 14550, loss = 0.693326
I0701 16:04:26.360558  2788 solver.cpp:252]     Train net output #0: loss = 0.692471 (* 1 = 0.692471 loss)
I0701 16:04:26.360574  2788 sgd_solver.cpp:106] Iteration 14550, lr = 0.01
I0701 16:04:40.843562  2788 solver.cpp:236] Iteration 14560, loss = 0.693449
I0701 16:04:40.843780  2788 solver.cpp:252]     Train net output #0: loss = 0.692728 (* 1 = 0.692728 loss)
I0701 16:04:40.843796  2788 sgd_solver.cpp:106] Iteration 14560, lr = 0.01
I0701 16:04:54.607249  2788 solver.cpp:236] Iteration 14570, loss = 0.693353
I0701 16:04:54.607311  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 16:04:54.607326  2788 sgd_solver.cpp:106] Iteration 14570, lr = 0.01
I0701 16:05:08.573668  2788 solver.cpp:236] Iteration 14580, loss = 0.693299
I0701 16:05:08.573721  2788 solver.cpp:252]     Train net output #0: loss = 0.693539 (* 1 = 0.693539 loss)
I0701 16:05:08.573736  2788 sgd_solver.cpp:106] Iteration 14580, lr = 0.01
I0701 16:05:22.594156  2788 solver.cpp:236] Iteration 14590, loss = 0.69324
I0701 16:05:22.594391  2788 solver.cpp:252]     Train net output #0: loss = 0.692154 (* 1 = 0.692154 loss)
I0701 16:05:22.594415  2788 sgd_solver.cpp:106] Iteration 14590, lr = 0.01
I0701 16:05:36.623175  2788 solver.cpp:236] Iteration 14600, loss = 0.693219
I0701 16:05:36.623241  2788 solver.cpp:252]     Train net output #0: loss = 0.694603 (* 1 = 0.694603 loss)
I0701 16:05:36.623256  2788 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0701 16:05:50.914654  2788 solver.cpp:236] Iteration 14610, loss = 0.693243
I0701 16:05:50.914712  2788 solver.cpp:252]     Train net output #0: loss = 0.692924 (* 1 = 0.692924 loss)
I0701 16:05:50.914727  2788 sgd_solver.cpp:106] Iteration 14610, lr = 0.01
I0701 16:06:05.759992  2788 solver.cpp:236] Iteration 14620, loss = 0.693239
I0701 16:06:05.768569  2788 solver.cpp:252]     Train net output #0: loss = 0.693472 (* 1 = 0.693472 loss)
I0701 16:06:05.768590  2788 sgd_solver.cpp:106] Iteration 14620, lr = 0.01
I0701 16:06:19.426537  2788 solver.cpp:236] Iteration 14630, loss = 0.693263
I0701 16:06:19.426596  2788 solver.cpp:252]     Train net output #0: loss = 0.695053 (* 1 = 0.695053 loss)
I0701 16:06:19.426611  2788 sgd_solver.cpp:106] Iteration 14630, lr = 0.01
I0701 16:06:33.530067  2788 solver.cpp:236] Iteration 14640, loss = 0.693294
I0701 16:06:33.530120  2788 solver.cpp:252]     Train net output #0: loss = 0.693332 (* 1 = 0.693332 loss)
I0701 16:06:33.530133  2788 sgd_solver.cpp:106] Iteration 14640, lr = 0.01
I0701 16:06:47.493579  2788 solver.cpp:236] Iteration 14650, loss = 0.693312
I0701 16:06:47.493824  2788 solver.cpp:252]     Train net output #0: loss = 0.692989 (* 1 = 0.692989 loss)
I0701 16:06:47.493840  2788 sgd_solver.cpp:106] Iteration 14650, lr = 0.01
I0701 16:07:01.622100  2788 solver.cpp:236] Iteration 14660, loss = 0.693286
I0701 16:07:01.622148  2788 solver.cpp:252]     Train net output #0: loss = 0.694041 (* 1 = 0.694041 loss)
I0701 16:07:01.622160  2788 sgd_solver.cpp:106] Iteration 14660, lr = 0.01
I0701 16:07:15.737355  2788 solver.cpp:236] Iteration 14670, loss = 0.693263
I0701 16:07:15.737419  2788 solver.cpp:252]     Train net output #0: loss = 0.692733 (* 1 = 0.692733 loss)
I0701 16:07:15.737435  2788 sgd_solver.cpp:106] Iteration 14670, lr = 0.01
I0701 16:07:29.792212  2788 solver.cpp:236] Iteration 14680, loss = 0.693094
I0701 16:07:29.792524  2788 solver.cpp:252]     Train net output #0: loss = 0.693136 (* 1 = 0.693136 loss)
I0701 16:07:29.792541  2788 sgd_solver.cpp:106] Iteration 14680, lr = 0.01
I0701 16:07:43.980387  2788 solver.cpp:236] Iteration 14690, loss = 0.693257
I0701 16:07:43.980454  2788 solver.cpp:252]     Train net output #0: loss = 0.694529 (* 1 = 0.694529 loss)
I0701 16:07:43.980470  2788 sgd_solver.cpp:106] Iteration 14690, lr = 0.01
I0701 16:07:58.201808  2788 solver.cpp:236] Iteration 14700, loss = 0.693263
I0701 16:07:58.201895  2788 solver.cpp:252]     Train net output #0: loss = 0.6933 (* 1 = 0.6933 loss)
I0701 16:07:58.201912  2788 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0701 16:08:12.472914  2788 solver.cpp:236] Iteration 14710, loss = 0.693201
I0701 16:08:12.473067  2788 solver.cpp:252]     Train net output #0: loss = 0.691482 (* 1 = 0.691482 loss)
I0701 16:08:12.473089  2788 sgd_solver.cpp:106] Iteration 14710, lr = 0.01
I0701 16:08:27.161922  2788 solver.cpp:236] Iteration 14720, loss = 0.693177
I0701 16:08:27.161983  2788 solver.cpp:252]     Train net output #0: loss = 0.69357 (* 1 = 0.69357 loss)
I0701 16:08:27.161998  2788 sgd_solver.cpp:106] Iteration 14720, lr = 0.01
I0701 16:08:41.463798  2788 solver.cpp:236] Iteration 14730, loss = 0.693286
I0701 16:08:41.463855  2788 solver.cpp:252]     Train net output #0: loss = 0.69316 (* 1 = 0.69316 loss)
I0701 16:08:41.463868  2788 sgd_solver.cpp:106] Iteration 14730, lr = 0.01
I0701 16:08:55.799720  2788 solver.cpp:236] Iteration 14740, loss = 0.693303
I0701 16:08:55.799901  2788 solver.cpp:252]     Train net output #0: loss = 0.693414 (* 1 = 0.693414 loss)
I0701 16:08:55.799917  2788 sgd_solver.cpp:106] Iteration 14740, lr = 0.01
I0701 16:09:08.435925  2788 solver.cpp:340] Iteration 14750, Testing net (#0)
I0701 16:09:39.899979  2788 solver.cpp:408]     Test net output #0: accuracy = 0.4975
I0701 16:09:39.900264  2788 solver.cpp:408]     Test net output #1: loss = 0.693301 (* 1 = 0.693301 loss)
I0701 16:09:40.132889  2788 solver.cpp:236] Iteration 14750, loss = 0.693252
I0701 16:09:40.132942  2788 solver.cpp:252]     Train net output #0: loss = 0.692821 (* 1 = 0.692821 loss)
I0701 16:09:40.132959  2788 sgd_solver.cpp:106] Iteration 14750, lr = 0.01
I0701 16:09:52.424397  2788 solver.cpp:236] Iteration 14760, loss = 0.693389
I0701 16:09:52.424469  2788 solver.cpp:252]     Train net output #0: loss = 0.692445 (* 1 = 0.692445 loss)
I0701 16:09:52.424484  2788 sgd_solver.cpp:106] Iteration 14760, lr = 0.01
I0701 16:10:07.037788  2788 solver.cpp:236] Iteration 14770, loss = 0.693426
I0701 16:10:07.037844  2788 solver.cpp:252]     Train net output #0: loss = 0.694921 (* 1 = 0.694921 loss)
I0701 16:10:07.037861  2788 sgd_solver.cpp:106] Iteration 14770, lr = 0.01
I0701 16:10:22.022114  2788 solver.cpp:236] Iteration 14780, loss = 0.693464
I0701 16:10:22.022275  2788 solver.cpp:252]     Train net output #0: loss = 0.693024 (* 1 = 0.693024 loss)
I0701 16:10:22.022315  2788 sgd_solver.cpp:106] Iteration 14780, lr = 0.01
I0701 16:10:37.182159  2788 solver.cpp:236] Iteration 14790, loss = 0.693307
I0701 16:10:37.182224  2788 solver.cpp:252]     Train net output #0: loss = 0.69328 (* 1 = 0.69328 loss)
I0701 16:10:37.182240  2788 sgd_solver.cpp:106] Iteration 14790, lr = 0.01
I0701 16:10:51.461689  2788 solver.cpp:236] Iteration 14800, loss = 0.693458
I0701 16:10:51.461741  2788 solver.cpp:252]     Train net output #0: loss = 0.693167 (* 1 = 0.693167 loss)
I0701 16:10:51.461756  2788 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0701 16:11:06.176239  2788 solver.cpp:236] Iteration 14810, loss = 0.693316
I0701 16:11:06.176569  2788 solver.cpp:252]     Train net output #0: loss = 0.692227 (* 1 = 0.692227 loss)
I0701 16:11:06.176589  2788 sgd_solver.cpp:106] Iteration 14810, lr = 0.01
I0701 16:11:21.028597  2788 solver.cpp:236] Iteration 14820, loss = 0.693378
I0701 16:11:21.028648  2788 solver.cpp:252]     Train net output #0: loss = 0.693163 (* 1 = 0.693163 loss)
I0701 16:11:21.028662  2788 sgd_solver.cpp:106] Iteration 14820, lr = 0.01
I0701 16:11:36.223951  2788 solver.cpp:236] Iteration 14830, loss = 0.693347
I0701 16:11:36.224073  2788 solver.cpp:252]     Train net output #0: loss = 0.693703 (* 1 = 0.693703 loss)
I0701 16:11:36.224090  2788 sgd_solver.cpp:106] Iteration 14830, lr = 0.01
I0701 16:11:50.748286  2788 solver.cpp:236] Iteration 14840, loss = 0.693348
I0701 16:11:50.748353  2788 solver.cpp:252]     Train net output #0: loss = 0.69425 (* 1 = 0.69425 loss)
I0701 16:11:50.748366  2788 sgd_solver.cpp:106] Iteration 14840, lr = 0.01
I0701 16:12:05.339026  2788 solver.cpp:236] Iteration 14850, loss = 0.693296
I0701 16:12:05.339081  2788 solver.cpp:252]     Train net output #0: loss = 0.694318 (* 1 = 0.694318 loss)
I0701 16:12:05.339095  2788 sgd_solver.cpp:106] Iteration 14850, lr = 0.01
I0701 16:12:20.485651  2788 solver.cpp:236] Iteration 14860, loss = 0.693395
I0701 16:12:20.485864  2788 solver.cpp:252]     Train net output #0: loss = 0.695177 (* 1 = 0.695177 loss)
I0701 16:12:20.485882  2788 sgd_solver.cpp:106] Iteration 14860, lr = 0.01
I0701 16:12:35.939307  2788 solver.cpp:236] Iteration 14870, loss = 0.693444
I0701 16:12:35.939363  2788 solver.cpp:252]     Train net output #0: loss = 0.69385 (* 1 = 0.69385 loss)
I0701 16:12:35.939378  2788 sgd_solver.cpp:106] Iteration 14870, lr = 0.01
I0701 16:12:51.140878  2788 solver.cpp:236] Iteration 14880, loss = 0.69349
I0701 16:12:51.141151  2788 solver.cpp:252]     Train net output #0: loss = 0.692775 (* 1 = 0.692775 loss)
I0701 16:12:51.141171  2788 sgd_solver.cpp:106] Iteration 14880, lr = 0.01
I0701 16:13:01.836277  2788 solver.cpp:236] Iteration 14890, loss = 0.693496
I0701 16:13:01.836328  2788 solver.cpp:252]     Train net output #0: loss = 0.694279 (* 1 = 0.694279 loss)
I0701 16:13:01.836341  2788 sgd_solver.cpp:106] Iteration 14890, lr = 0.01
I0701 16:13:10.774762  2788 solver.cpp:236] Iteration 14900, loss = 0.693476
I0701 16:13:10.774821  2788 solver.cpp:252]     Train net output #0: loss = 0.692036 (* 1 = 0.692036 loss)
I0701 16:13:10.774835  2788 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0701 16:13:20.174727  2788 solver.cpp:236] Iteration 14910, loss = 0.693434
I0701 16:13:20.174777  2788 solver.cpp:252]     Train net output #0: loss = 0.695193 (* 1 = 0.695193 loss)
I0701 16:13:20.174795  2788 sgd_solver.cpp:106] Iteration 14910, lr = 0.01
I0701 16:13:29.510103  2788 solver.cpp:236] Iteration 14920, loss = 0.693406
I0701 16:13:29.510351  2788 solver.cpp:252]     Train net output #0: loss = 0.692097 (* 1 = 0.692097 loss)
I0701 16:13:29.510370  2788 sgd_solver.cpp:106] Iteration 14920, lr = 0.01
I0701 16:13:38.480451  2788 solver.cpp:236] Iteration 14930, loss = 0.693325
I0701 16:13:38.480533  2788 solver.cpp:252]     Train net output #0: loss = 0.691493 (* 1 = 0.691493 loss)
I0701 16:13:38.480556  2788 sgd_solver.cpp:106] Iteration 14930, lr = 0.01
I0701 16:13:47.417946  2788 solver.cpp:236] Iteration 14940, loss = 0.693379
I0701 16:13:47.417999  2788 solver.cpp:252]     Train net output #0: loss = 0.692242 (* 1 = 0.692242 loss)
I0701 16:13:47.418014  2788 sgd_solver.cpp:106] Iteration 14940, lr = 0.01
I0701 16:13:56.695195  2788 solver.cpp:236] Iteration 14950, loss = 0.693365
I0701 16:13:56.695248  2788 solver.cpp:252]     Train net output #0: loss = 0.693052 (* 1 = 0.693052 loss)
I0701 16:13:56.695263  2788 sgd_solver.cpp:106] Iteration 14950, lr = 0.01
I0701 16:14:04.478879  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 16:14:05.403439  2788 solver.cpp:236] Iteration 14960, loss = 0.693386
I0701 16:14:05.403491  2788 solver.cpp:252]     Train net output #0: loss = 0.697341 (* 1 = 0.697341 loss)
I0701 16:14:05.403506  2788 sgd_solver.cpp:106] Iteration 14960, lr = 0.01
I0701 16:14:14.533951  2788 solver.cpp:236] Iteration 14970, loss = 0.69332
I0701 16:14:14.534013  2788 solver.cpp:252]     Train net output #0: loss = 0.6923 (* 1 = 0.6923 loss)
I0701 16:14:14.534026  2788 sgd_solver.cpp:106] Iteration 14970, lr = 0.01
I0701 16:14:24.418599  2788 solver.cpp:236] Iteration 14980, loss = 0.693379
I0701 16:14:24.418644  2788 solver.cpp:252]     Train net output #0: loss = 0.69292 (* 1 = 0.69292 loss)
I0701 16:14:24.418658  2788 sgd_solver.cpp:106] Iteration 14980, lr = 0.01
I0701 16:14:33.155910  2788 solver.cpp:236] Iteration 14990, loss = 0.693365
I0701 16:14:33.155962  2788 solver.cpp:252]     Train net output #0: loss = 0.693428 (* 1 = 0.693428 loss)
I0701 16:14:33.155977  2788 sgd_solver.cpp:106] Iteration 14990, lr = 0.01
I0701 16:14:41.429226  2788 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_15000.caffemodel
I0701 16:14:42.093399  2788 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_15000.solverstate
I0701 16:14:42.138749  2788 solver.cpp:340] Iteration 15000, Testing net (#0)
I0701 16:15:04.423713  2788 solver.cpp:408]     Test net output #0: accuracy = 0.510938
I0701 16:15:04.423763  2788 solver.cpp:408]     Test net output #1: loss = 0.69293 (* 1 = 0.69293 loss)
I0701 16:15:04.657632  2788 solver.cpp:236] Iteration 15000, loss = 0.693459
I0701 16:15:04.657690  2788 solver.cpp:252]     Train net output #0: loss = 0.697564 (* 1 = 0.697564 loss)
I0701 16:15:04.657706  2788 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0701 16:15:12.619299  2788 solver.cpp:236] Iteration 15010, loss = 0.693425
I0701 16:15:12.619464  2788 solver.cpp:252]     Train net output #0: loss = 0.693828 (* 1 = 0.693828 loss)
I0701 16:15:12.619484  2788 sgd_solver.cpp:106] Iteration 15010, lr = 0.01
I0701 16:15:22.168479  2788 solver.cpp:236] Iteration 15020, loss = 0.693435
I0701 16:15:22.168545  2788 solver.cpp:252]     Train net output #0: loss = 0.693062 (* 1 = 0.693062 loss)
I0701 16:15:22.168565  2788 sgd_solver.cpp:106] Iteration 15020, lr = 0.01
I0701 16:15:31.613047  2788 solver.cpp:236] Iteration 15030, loss = 0.69344
I0701 16:15:31.613100  2788 solver.cpp:252]     Train net output #0: loss = 0.693385 (* 1 = 0.693385 loss)
I0701 16:15:31.613114  2788 sgd_solver.cpp:106] Iteration 15030, lr = 0.01
I0701 16:15:40.690668  2788 solver.cpp:236] Iteration 15040, loss = 0.693287
I0701 16:15:40.690721  2788 solver.cpp:252]     Train net output #0: loss = 0.691612 (* 1 = 0.691612 loss)
I0701 16:15:40.690735  2788 sgd_solver.cpp:106] Iteration 15040, lr = 0.01
I0701 16:15:50.177654  2788 solver.cpp:236] Iteration 15050, loss = 0.693414
I0701 16:15:50.177845  2788 solver.cpp:252]     Train net output #0: loss = 0.691179 (* 1 = 0.691179 loss)
I0701 16:15:50.177861  2788 sgd_solver.cpp:106] Iteration 15050, lr = 0.01
I0701 16:15:59.956058  2788 solver.cpp:236] Iteration 15060, loss = 0.693398
I0701 16:15:59.956112  2788 solver.cpp:252]     Train net output #0: loss = 0.693206 (* 1 = 0.693206 loss)
I0701 16:15:59.956127  2788 sgd_solver.cpp:106] Iteration 15060, lr = 0.01
I0701 16:16:08.989691  2788 solver.cpp:236] Iteration 15070, loss = 0.693428
I0701 16:16:08.989747  2788 solver.cpp:252]     Train net output #0: loss = 0.695575 (* 1 = 0.695575 loss)
I0701 16:16:08.989759  2788 sgd_solver.cpp:106] Iteration 15070, lr = 0.01
I0701 16:16:18.018069  2788 solver.cpp:236] Iteration 15080, loss = 0.693532
I0701 16:16:18.018122  2788 solver.cpp:252]     Train net output #0: loss = 0.694141 (* 1 = 0.694141 loss)
I0701 16:16:18.018137  2788 sgd_solver.cpp:106] Iteration 15080, lr = 0.01
I0701 16:16:27.533531  2788 solver.cpp:236] Iteration 15090, loss = 0.693665
I0701 16:16:27.533789  2788 solver.cpp:252]     Train net output #0: loss = 0.693513 (* 1 = 0.693513 loss)
I0701 16:16:27.533807  2788 sgd_solver.cpp:106] Iteration 15090, lr = 0.01
I0701 16:16:37.382097  2788 solver.cpp:236] Iteration 15100, loss = 0.693416
I0701 16:16:37.382163  2788 solver.cpp:252]     Train net output #0: loss = 0.693032 (* 1 = 0.693032 loss)
I0701 16:16:37.382182  2788 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0701 16:16:46.404281  2788 solver.cpp:236] Iteration 15110, loss = 0.693419
I0701 16:16:46.404330  2788 solver.cpp:252]     Train net output #0: loss = 0.693757 (* 1 = 0.693757 loss)
I0701 16:16:46.404341  2788 sgd_solver.cpp:106] Iteration 15110, lr = 0.01
I0701 16:16:55.322813  2788 solver.cpp:236] Iteration 15120, loss = 0.693428
I0701 16:16:55.322867  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 16:16:55.322883  2788 sgd_solver.cpp:106] Iteration 15120, lr = 0.01
I0701 16:17:04.928174  2788 solver.cpp:236] Iteration 15130, loss = 0.693297
I0701 16:17:04.928392  2788 solver.cpp:252]     Train net output #0: loss = 0.691611 (* 1 = 0.691611 loss)
I0701 16:17:04.928416  2788 sgd_solver.cpp:106] Iteration 15130, lr = 0.01
I0701 16:17:14.356217  2788 solver.cpp:236] Iteration 15140, loss = 0.693376
I0701 16:17:14.356267  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 16:17:14.356282  2788 sgd_solver.cpp:106] Iteration 15140, lr = 0.01
I0701 16:17:23.862442  2788 solver.cpp:236] Iteration 15150, loss = 0.693626
I0701 16:17:23.862490  2788 solver.cpp:252]     Train net output #0: loss = 0.694866 (* 1 = 0.694866 loss)
I0701 16:17:23.862504  2788 sgd_solver.cpp:106] Iteration 15150, lr = 0.01
I0701 16:17:33.286182  2788 solver.cpp:236] Iteration 15160, loss = 0.693716
I0701 16:17:33.286243  2788 solver.cpp:252]     Train net output #0: loss = 0.694613 (* 1 = 0.694613 loss)
I0701 16:17:33.286259  2788 sgd_solver.cpp:106] Iteration 15160, lr = 0.01
I0701 16:17:42.953658  2788 solver.cpp:236] Iteration 15170, loss = 0.693626
I0701 16:17:42.953837  2788 solver.cpp:252]     Train net output #0: loss = 0.693686 (* 1 = 0.693686 loss)
I0701 16:17:42.953858  2788 sgd_solver.cpp:106] Iteration 15170, lr = 0.01
I0701 16:17:52.253669  2788 solver.cpp:236] Iteration 15180, loss = 0.693618
I0701 16:17:52.253759  2788 solver.cpp:252]     Train net output #0: loss = 0.693963 (* 1 = 0.693963 loss)
I0701 16:17:52.253787  2788 sgd_solver.cpp:106] Iteration 15180, lr = 0.01
I0701 16:18:01.452630  2788 solver.cpp:236] Iteration 15190, loss = 0.693534
I0701 16:18:01.452680  2788 solver.cpp:252]     Train net output #0: loss = 0.695106 (* 1 = 0.695106 loss)
I0701 16:18:01.452693  2788 sgd_solver.cpp:106] Iteration 15190, lr = 0.01
I0701 16:18:11.206450  2788 solver.cpp:236] Iteration 15200, loss = 0.693244
I0701 16:18:11.206517  2788 solver.cpp:252]     Train net output #0: loss = 0.693045 (* 1 = 0.693045 loss)
I0701 16:18:11.206533  2788 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0701 16:18:20.301380  2788 solver.cpp:236] Iteration 15210, loss = 0.693125
I0701 16:18:20.301650  2788 solver.cpp:252]     Train net output #0: loss = 0.692397 (* 1 = 0.692397 loss)
I0701 16:18:20.301667  2788 sgd_solver.cpp:106] Iteration 15210, lr = 0.01
I0701 16:18:29.414176  2788 solver.cpp:236] Iteration 15220, loss = 0.693164
I0701 16:18:29.414237  2788 solver.cpp:252]     Train net output #0: loss = 0.693287 (* 1 = 0.693287 loss)
I0701 16:18:29.414250  2788 sgd_solver.cpp:106] Iteration 15220, lr = 0.01
I0701 16:18:39.409248  2788 solver.cpp:236] Iteration 15230, loss = 0.693147
I0701 16:18:39.409302  2788 solver.cpp:252]     Train net output #0: loss = 0.691527 (* 1 = 0.691527 loss)
I0701 16:18:39.409317  2788 sgd_solver.cpp:106] Iteration 15230, lr = 0.01
I0701 16:18:48.473597  2788 solver.cpp:236] Iteration 15240, loss = 0.693156
I0701 16:18:48.473680  2788 solver.cpp:252]     Train net output #0: loss = 0.692643 (* 1 = 0.692643 loss)
I0701 16:18:48.473701  2788 sgd_solver.cpp:106] Iteration 15240, lr = 0.01
I0701 16:18:57.257990  2788 solver.cpp:340] Iteration 15250, Testing net (#0)
I0701 16:19:22.748081  2788 solver.cpp:408]     Test net output #0: accuracy = 0.510312
I0701 16:19:22.748137  2788 solver.cpp:408]     Test net output #1: loss = 0.692998 (* 1 = 0.692998 loss)
I0701 16:19:22.981482  2788 solver.cpp:236] Iteration 15250, loss = 0.693295
I0701 16:19:22.981528  2788 solver.cpp:252]     Train net output #0: loss = 0.694645 (* 1 = 0.694645 loss)
I0701 16:19:22.981544  2788 sgd_solver.cpp:106] Iteration 15250, lr = 0.01
I0701 16:19:31.159703  2788 solver.cpp:236] Iteration 15260, loss = 0.693202
I0701 16:19:31.159939  2788 solver.cpp:252]     Train net output #0: loss = 0.690872 (* 1 = 0.690872 loss)
I0701 16:19:31.159955  2788 sgd_solver.cpp:106] Iteration 15260, lr = 0.01
I0701 16:19:40.966970  2788 solver.cpp:236] Iteration 15270, loss = 0.693263
I0701 16:19:40.967031  2788 solver.cpp:252]     Train net output #0: loss = 0.692667 (* 1 = 0.692667 loss)
I0701 16:19:40.967044  2788 sgd_solver.cpp:106] Iteration 15270, lr = 0.01
I0701 16:19:50.315830  2788 solver.cpp:236] Iteration 15280, loss = 0.693599
I0701 16:19:50.315893  2788 solver.cpp:252]     Train net output #0: loss = 0.693325 (* 1 = 0.693325 loss)
I0701 16:19:50.315907  2788 sgd_solver.cpp:106] Iteration 15280, lr = 0.01
I0701 16:20:00.441077  2788 solver.cpp:236] Iteration 15290, loss = 0.693615
I0701 16:20:00.441124  2788 solver.cpp:252]     Train net output #0: loss = 0.694609 (* 1 = 0.694609 loss)
I0701 16:20:00.441138  2788 sgd_solver.cpp:106] Iteration 15290, lr = 0.01
I0701 16:20:10.323994  2788 solver.cpp:236] Iteration 15300, loss = 0.693509
I0701 16:20:10.324209  2788 solver.cpp:252]     Train net output #0: loss = 0.695234 (* 1 = 0.695234 loss)
I0701 16:20:10.324224  2788 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0701 16:20:19.926426  2788 solver.cpp:236] Iteration 15310, loss = 0.693717
I0701 16:20:19.926488  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 16:20:19.926506  2788 sgd_solver.cpp:106] Iteration 15310, lr = 0.01
I0701 16:20:29.535934  2788 solver.cpp:236] Iteration 15320, loss = 0.693708
I0701 16:20:29.535980  2788 solver.cpp:252]     Train net output #0: loss = 0.694754 (* 1 = 0.694754 loss)
I0701 16:20:29.535995  2788 sgd_solver.cpp:106] Iteration 15320, lr = 0.01
I0701 16:20:39.564911  2788 solver.cpp:236] Iteration 15330, loss = 0.693516
I0701 16:20:39.565002  2788 solver.cpp:252]     Train net output #0: loss = 0.692641 (* 1 = 0.692641 loss)
I0701 16:20:39.565035  2788 sgd_solver.cpp:106] Iteration 15330, lr = 0.01
I0701 16:20:49.303238  2788 solver.cpp:236] Iteration 15340, loss = 0.693476
I0701 16:20:49.303912  2788 solver.cpp:252]     Train net output #0: loss = 0.693157 (* 1 = 0.693157 loss)
I0701 16:20:49.303930  2788 sgd_solver.cpp:106] Iteration 15340, lr = 0.01
I0701 16:20:59.160370  2788 solver.cpp:236] Iteration 15350, loss = 0.693567
I0701 16:20:59.160431  2788 solver.cpp:252]     Train net output #0: loss = 0.693655 (* 1 = 0.693655 loss)
I0701 16:20:59.160449  2788 sgd_solver.cpp:106] Iteration 15350, lr = 0.01
I0701 16:21:08.510061  2788 solver.cpp:236] Iteration 15360, loss = 0.693564
I0701 16:21:08.510120  2788 solver.cpp:252]     Train net output #0: loss = 0.698973 (* 1 = 0.698973 loss)
I0701 16:21:08.510134  2788 sgd_solver.cpp:106] Iteration 15360, lr = 0.01
I0701 16:21:18.375640  2788 solver.cpp:236] Iteration 15370, loss = 0.693504
I0701 16:21:18.375692  2788 solver.cpp:252]     Train net output #0: loss = 0.693367 (* 1 = 0.693367 loss)
I0701 16:21:18.375708  2788 sgd_solver.cpp:106] Iteration 15370, lr = 0.01
I0701 16:21:28.026280  2788 solver.cpp:236] Iteration 15380, loss = 0.693533
I0701 16:21:28.026504  2788 solver.cpp:252]     Train net output #0: loss = 0.693828 (* 1 = 0.693828 loss)
I0701 16:21:28.026518  2788 sgd_solver.cpp:106] Iteration 15380, lr = 0.01
I0701 16:21:37.289901  2788 solver.cpp:236] Iteration 15390, loss = 0.693346
I0701 16:21:37.289957  2788 solver.cpp:252]     Train net output #0: loss = 0.693691 (* 1 = 0.693691 loss)
I0701 16:21:37.289971  2788 sgd_solver.cpp:106] Iteration 15390, lr = 0.01
I0701 16:21:47.140301  2788 solver.cpp:236] Iteration 15400, loss = 0.693398
I0701 16:21:47.140352  2788 solver.cpp:252]     Train net output #0: loss = 0.696588 (* 1 = 0.696588 loss)
I0701 16:21:47.140367  2788 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0701 16:21:56.693646  2788 solver.cpp:236] Iteration 15410, loss = 0.69335
I0701 16:21:56.693699  2788 solver.cpp:252]     Train net output #0: loss = 0.694039 (* 1 = 0.694039 loss)
I0701 16:21:56.693717  2788 sgd_solver.cpp:106] Iteration 15410, lr = 0.01
I0701 16:22:06.190337  2788 solver.cpp:236] Iteration 15420, loss = 0.693349
I0701 16:22:06.190750  2788 solver.cpp:252]     Train net output #0: loss = 0.697038 (* 1 = 0.697038 loss)
I0701 16:22:06.190770  2788 sgd_solver.cpp:106] Iteration 15420, lr = 0.01
I0701 16:22:15.547511  2788 solver.cpp:236] Iteration 15430, loss = 0.693506
I0701 16:22:15.547561  2788 solver.cpp:252]     Train net output #0: loss = 0.694876 (* 1 = 0.694876 loss)
I0701 16:22:15.547580  2788 sgd_solver.cpp:106] Iteration 15430, lr = 0.01
I0701 16:22:25.197623  2788 solver.cpp:236] Iteration 15440, loss = 0.693774
I0701 16:22:25.197675  2788 solver.cpp:252]     Train net output #0: loss = 0.692765 (* 1 = 0.692765 loss)
I0701 16:22:25.197690  2788 sgd_solver.cpp:106] Iteration 15440, lr = 0.01
I0701 16:22:34.644898  2788 solver.cpp:236] Iteration 15450, loss = 0.6936
I0701 16:22:34.644953  2788 solver.cpp:252]     Train net output #0: loss = 0.693744 (* 1 = 0.693744 loss)
I0701 16:22:34.644968  2788 sgd_solver.cpp:106] Iteration 15450, lr = 0.01
I0701 16:22:44.184468  2788 solver.cpp:236] Iteration 15460, loss = 0.693583
I0701 16:22:44.184746  2788 solver.cpp:252]     Train net output #0: loss = 0.690871 (* 1 = 0.690871 loss)
I0701 16:22:44.184763  2788 sgd_solver.cpp:106] Iteration 15460, lr = 0.01
I0701 16:22:54.023995  2788 solver.cpp:236] Iteration 15470, loss = 0.693541
I0701 16:22:54.024052  2788 solver.cpp:252]     Train net output #0: loss = 0.69378 (* 1 = 0.69378 loss)
I0701 16:22:54.024067  2788 sgd_solver.cpp:106] Iteration 15470, lr = 0.01
I0701 16:23:03.840750  2788 solver.cpp:236] Iteration 15480, loss = 0.693292
I0701 16:23:03.840806  2788 solver.cpp:252]     Train net output #0: loss = 0.694035 (* 1 = 0.694035 loss)
I0701 16:23:03.840821  2788 sgd_solver.cpp:106] Iteration 15480, lr = 0.01
I0701 16:23:13.848532  2788 solver.cpp:236] Iteration 15490, loss = 0.692966
I0701 16:23:13.848580  2788 solver.cpp:252]     Train net output #0: loss = 0.690068 (* 1 = 0.690068 loss)
I0701 16:23:13.848593  2788 sgd_solver.cpp:106] Iteration 15490, lr = 0.01
I0701 16:23:22.188258  2788 solver.cpp:340] Iteration 15500, Testing net (#0)
I0701 16:23:47.905654  2788 solver.cpp:408]     Test net output #0: accuracy = 0.51875
I0701 16:23:47.905725  2788 solver.cpp:408]     Test net output #1: loss = 0.692507 (* 1 = 0.692507 loss)
I0701 16:23:48.141243  2788 solver.cpp:236] Iteration 15500, loss = 0.693289
I0701 16:23:48.141294  2788 solver.cpp:252]     Train net output #0: loss = 0.695139 (* 1 = 0.695139 loss)
I0701 16:23:48.141309  2788 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0701 16:23:56.528817  2788 solver.cpp:236] Iteration 15510, loss = 0.693133
I0701 16:23:56.529057  2788 solver.cpp:252]     Train net output #0: loss = 0.694145 (* 1 = 0.694145 loss)
I0701 16:23:56.529073  2788 sgd_solver.cpp:106] Iteration 15510, lr = 0.01
I0701 16:24:06.000448  2788 solver.cpp:236] Iteration 15520, loss = 0.693195
I0701 16:24:06.000504  2788 solver.cpp:252]     Train net output #0: loss = 0.693478 (* 1 = 0.693478 loss)
I0701 16:24:06.000520  2788 sgd_solver.cpp:106] Iteration 15520, lr = 0.01
I0701 16:24:15.890067  2788 solver.cpp:236] Iteration 15530, loss = 0.693179
I0701 16:24:15.890133  2788 solver.cpp:252]     Train net output #0: loss = 0.693072 (* 1 = 0.693072 loss)
I0701 16:24:15.890153  2788 sgd_solver.cpp:106] Iteration 15530, lr = 0.01
I0701 16:24:26.186712  2788 solver.cpp:236] Iteration 15540, loss = 0.693379
I0701 16:24:26.186800  2788 solver.cpp:252]     Train net output #0: loss = 0.692898 (* 1 = 0.692898 loss)
I0701 16:24:26.186849  2788 sgd_solver.cpp:106] Iteration 15540, lr = 0.01
I0701 16:24:35.941310  2788 solver.cpp:236] Iteration 15550, loss = 0.692994
I0701 16:24:35.941539  2788 solver.cpp:252]     Train net output #0: loss = 0.6896 (* 1 = 0.6896 loss)
I0701 16:24:35.941556  2788 sgd_solver.cpp:106] Iteration 15550, lr = 0.01
I0701 16:24:45.618818  2788 solver.cpp:236] Iteration 15560, loss = 0.692975
I0701 16:24:45.618877  2788 solver.cpp:252]     Train net output #0: loss = 0.697464 (* 1 = 0.697464 loss)
I0701 16:24:45.618892  2788 sgd_solver.cpp:106] Iteration 15560, lr = 0.01
I0701 16:24:55.523115  2788 solver.cpp:236] Iteration 15570, loss = 0.693142
I0701 16:24:55.523171  2788 solver.cpp:252]     Train net output #0: loss = 0.693132 (* 1 = 0.693132 loss)
I0701 16:24:55.523187  2788 sgd_solver.cpp:106] Iteration 15570, lr = 0.01
I0701 16:25:05.547848  2788 solver.cpp:236] Iteration 15580, loss = 0.693185
I0701 16:25:05.547901  2788 solver.cpp:252]     Train net output #0: loss = 0.695869 (* 1 = 0.695869 loss)
I0701 16:25:05.547916  2788 sgd_solver.cpp:106] Iteration 15580, lr = 0.01
I0701 16:25:15.190686  2788 solver.cpp:236] Iteration 15590, loss = 0.693183
I0701 16:25:15.190987  2788 solver.cpp:252]     Train net output #0: loss = 0.693546 (* 1 = 0.693546 loss)
I0701 16:25:15.191005  2788 sgd_solver.cpp:106] Iteration 15590, lr = 0.01
I0701 16:25:24.991387  2788 solver.cpp:236] Iteration 15600, loss = 0.693255
I0701 16:25:24.991443  2788 solver.cpp:252]     Train net output #0: loss = 0.693079 (* 1 = 0.693079 loss)
I0701 16:25:24.991458  2788 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0701 16:25:34.816151  2788 solver.cpp:236] Iteration 15610, loss = 0.693395
I0701 16:25:34.816212  2788 solver.cpp:252]     Train net output #0: loss = 0.693548 (* 1 = 0.693548 loss)
I0701 16:25:34.816227  2788 sgd_solver.cpp:106] Iteration 15610, lr = 0.01
I0701 16:25:44.668081  2788 solver.cpp:236] Iteration 15620, loss = 0.693182
I0701 16:25:44.668138  2788 solver.cpp:252]     Train net output #0: loss = 0.692261 (* 1 = 0.692261 loss)
I0701 16:25:44.668153  2788 sgd_solver.cpp:106] Iteration 15620, lr = 0.01
I0701 16:25:54.446609  2788 solver.cpp:236] Iteration 15630, loss = 0.693232
I0701 16:25:54.446827  2788 solver.cpp:252]     Train net output #0: loss = 0.693969 (* 1 = 0.693969 loss)
I0701 16:25:54.446843  2788 sgd_solver.cpp:106] Iteration 15630, lr = 0.01
I0701 16:26:04.270694  2788 solver.cpp:236] Iteration 15640, loss = 0.693236
I0701 16:26:04.270735  2788 solver.cpp:252]     Train net output #0: loss = 0.690121 (* 1 = 0.690121 loss)
I0701 16:26:04.270748  2788 sgd_solver.cpp:106] Iteration 15640, lr = 0.01
I0701 16:26:14.212980  2788 solver.cpp:236] Iteration 15650, loss = 0.693462
I0701 16:26:14.213027  2788 solver.cpp:252]     Train net output #0: loss = 0.695751 (* 1 = 0.695751 loss)
I0701 16:26:14.213043  2788 sgd_solver.cpp:106] Iteration 15650, lr = 0.01
I0701 16:26:24.354923  2788 solver.cpp:236] Iteration 15660, loss = 0.693423
I0701 16:26:24.354981  2788 solver.cpp:252]     Train net output #0: loss = 0.6927 (* 1 = 0.6927 loss)
I0701 16:26:24.354996  2788 sgd_solver.cpp:106] Iteration 15660, lr = 0.01
I0701 16:26:34.414454  2788 solver.cpp:236] Iteration 15670, loss = 0.693445
I0701 16:26:34.414657  2788 solver.cpp:252]     Train net output #0: loss = 0.692343 (* 1 = 0.692343 loss)
I0701 16:26:34.414675  2788 sgd_solver.cpp:106] Iteration 15670, lr = 0.01
I0701 16:26:44.788208  2788 solver.cpp:236] Iteration 15680, loss = 0.693096
I0701 16:26:44.788255  2788 solver.cpp:252]     Train net output #0: loss = 0.692151 (* 1 = 0.692151 loss)
I0701 16:26:44.788269  2788 sgd_solver.cpp:106] Iteration 15680, lr = 0.01
I0701 16:26:44.788836  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 16:26:54.916016  2788 solver.cpp:236] Iteration 15690, loss = 0.693294
I0701 16:26:54.916072  2788 solver.cpp:252]     Train net output #0: loss = 0.691535 (* 1 = 0.691535 loss)
I0701 16:26:54.916088  2788 sgd_solver.cpp:106] Iteration 15690, lr = 0.01
I0701 16:27:04.843821  2788 solver.cpp:236] Iteration 15700, loss = 0.693102
I0701 16:27:04.843991  2788 solver.cpp:252]     Train net output #0: loss = 0.692278 (* 1 = 0.692278 loss)
I0701 16:27:04.844007  2788 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0701 16:27:15.122324  2788 solver.cpp:236] Iteration 15710, loss = 0.693176
I0701 16:27:15.122372  2788 solver.cpp:252]     Train net output #0: loss = 0.693157 (* 1 = 0.693157 loss)
I0701 16:27:15.122387  2788 sgd_solver.cpp:106] Iteration 15710, lr = 0.01
I0701 16:27:25.692205  2788 solver.cpp:236] Iteration 15720, loss = 0.6932
I0701 16:27:25.692265  2788 solver.cpp:252]     Train net output #0: loss = 0.693682 (* 1 = 0.693682 loss)
I0701 16:27:25.692283  2788 sgd_solver.cpp:106] Iteration 15720, lr = 0.01
I0701 16:27:35.702041  2788 solver.cpp:236] Iteration 15730, loss = 0.693422
I0701 16:27:35.702193  2788 solver.cpp:252]     Train net output #0: loss = 0.691387 (* 1 = 0.691387 loss)
I0701 16:27:35.702222  2788 sgd_solver.cpp:106] Iteration 15730, lr = 0.01
I0701 16:27:45.757529  2788 solver.cpp:236] Iteration 15740, loss = 0.692976
I0701 16:27:45.757577  2788 solver.cpp:252]     Train net output #0: loss = 0.693936 (* 1 = 0.693936 loss)
I0701 16:27:45.757591  2788 sgd_solver.cpp:106] Iteration 15740, lr = 0.01
I0701 16:27:54.668866  2788 solver.cpp:340] Iteration 15750, Testing net (#0)
I0701 16:28:21.067039  2788 solver.cpp:408]     Test net output #0: accuracy = 0.504375
I0701 16:28:21.067291  2788 solver.cpp:408]     Test net output #1: loss = 0.693627 (* 1 = 0.693627 loss)
I0701 16:28:21.306991  2788 solver.cpp:236] Iteration 15750, loss = 0.693187
I0701 16:28:21.307044  2788 solver.cpp:252]     Train net output #0: loss = 0.695906 (* 1 = 0.695906 loss)
I0701 16:28:21.307059  2788 sgd_solver.cpp:106] Iteration 15750, lr = 0.01
I0701 16:28:30.569751  2788 solver.cpp:236] Iteration 15760, loss = 0.693201
I0701 16:28:30.569810  2788 solver.cpp:252]     Train net output #0: loss = 0.693948 (* 1 = 0.693948 loss)
I0701 16:28:30.569830  2788 sgd_solver.cpp:106] Iteration 15760, lr = 0.01
I0701 16:28:41.332561  2788 solver.cpp:236] Iteration 15770, loss = 0.693263
I0701 16:28:41.332612  2788 solver.cpp:252]     Train net output #0: loss = 0.695792 (* 1 = 0.695792 loss)
I0701 16:28:41.332626  2788 sgd_solver.cpp:106] Iteration 15770, lr = 0.01
I0701 16:28:51.776154  2788 solver.cpp:236] Iteration 15780, loss = 0.693382
I0701 16:28:51.776363  2788 solver.cpp:252]     Train net output #0: loss = 0.695075 (* 1 = 0.695075 loss)
I0701 16:28:51.776387  2788 sgd_solver.cpp:106] Iteration 15780, lr = 0.01
I0701 16:29:02.014349  2788 solver.cpp:236] Iteration 15790, loss = 0.693651
I0701 16:29:02.014415  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 16:29:02.014430  2788 sgd_solver.cpp:106] Iteration 15790, lr = 0.01
I0701 16:29:12.155684  2788 solver.cpp:236] Iteration 15800, loss = 0.693422
I0701 16:29:12.155735  2788 solver.cpp:252]     Train net output #0: loss = 0.693155 (* 1 = 0.693155 loss)
I0701 16:29:12.155753  2788 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0701 16:29:22.192533  2788 solver.cpp:236] Iteration 15810, loss = 0.69341
I0701 16:29:22.192802  2788 solver.cpp:252]     Train net output #0: loss = 0.693132 (* 1 = 0.693132 loss)
I0701 16:29:22.192821  2788 sgd_solver.cpp:106] Iteration 15810, lr = 0.01
I0701 16:29:32.386009  2788 solver.cpp:236] Iteration 15820, loss = 0.693357
I0701 16:29:32.386096  2788 solver.cpp:252]     Train net output #0: loss = 0.693169 (* 1 = 0.693169 loss)
I0701 16:29:32.386122  2788 sgd_solver.cpp:106] Iteration 15820, lr = 0.01
I0701 16:29:42.334769  2788 solver.cpp:236] Iteration 15830, loss = 0.69329
I0701 16:29:42.334821  2788 solver.cpp:252]     Train net output #0: loss = 0.694095 (* 1 = 0.694095 loss)
I0701 16:29:42.334838  2788 sgd_solver.cpp:106] Iteration 15830, lr = 0.01
I0701 16:29:53.378247  2788 solver.cpp:236] Iteration 15840, loss = 0.693299
I0701 16:29:53.378445  2788 solver.cpp:252]     Train net output #0: loss = 0.693295 (* 1 = 0.693295 loss)
I0701 16:29:53.378463  2788 sgd_solver.cpp:106] Iteration 15840, lr = 0.01
I0701 16:30:03.649672  2788 solver.cpp:236] Iteration 15850, loss = 0.693301
I0701 16:30:03.649731  2788 solver.cpp:252]     Train net output #0: loss = 0.693044 (* 1 = 0.693044 loss)
I0701 16:30:03.649746  2788 sgd_solver.cpp:106] Iteration 15850, lr = 0.01
I0701 16:30:14.178176  2788 solver.cpp:236] Iteration 15860, loss = 0.693285
I0701 16:30:14.178232  2788 solver.cpp:252]     Train net output #0: loss = 0.693161 (* 1 = 0.693161 loss)
I0701 16:30:14.178247  2788 sgd_solver.cpp:106] Iteration 15860, lr = 0.01
I0701 16:30:25.106211  2788 solver.cpp:236] Iteration 15870, loss = 0.693257
I0701 16:30:25.106384  2788 solver.cpp:252]     Train net output #0: loss = 0.692817 (* 1 = 0.692817 loss)
I0701 16:30:25.106426  2788 sgd_solver.cpp:106] Iteration 15870, lr = 0.01
I0701 16:30:35.380197  2788 solver.cpp:236] Iteration 15880, loss = 0.693309
I0701 16:30:35.380296  2788 solver.cpp:252]     Train net output #0: loss = 0.692703 (* 1 = 0.692703 loss)
I0701 16:30:35.380312  2788 sgd_solver.cpp:106] Iteration 15880, lr = 0.01
I0701 16:30:45.479470  2788 solver.cpp:236] Iteration 15890, loss = 0.693465
I0701 16:30:45.479522  2788 solver.cpp:252]     Train net output #0: loss = 0.693338 (* 1 = 0.693338 loss)
I0701 16:30:45.479537  2788 sgd_solver.cpp:106] Iteration 15890, lr = 0.01
I0701 16:30:55.889564  2788 solver.cpp:236] Iteration 15900, loss = 0.693532
I0701 16:30:55.889811  2788 solver.cpp:252]     Train net output #0: loss = 0.693181 (* 1 = 0.693181 loss)
I0701 16:30:55.889832  2788 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0701 16:31:06.401608  2788 solver.cpp:236] Iteration 15910, loss = 0.693381
I0701 16:31:06.401669  2788 solver.cpp:252]     Train net output #0: loss = 0.690131 (* 1 = 0.690131 loss)
I0701 16:31:06.401685  2788 sgd_solver.cpp:106] Iteration 15910, lr = 0.01
I0701 16:31:17.113675  2788 solver.cpp:236] Iteration 15920, loss = 0.693638
I0701 16:31:17.113729  2788 solver.cpp:252]     Train net output #0: loss = 0.696269 (* 1 = 0.696269 loss)
I0701 16:31:17.113744  2788 sgd_solver.cpp:106] Iteration 15920, lr = 0.01
I0701 16:31:28.089174  2788 solver.cpp:236] Iteration 15930, loss = 0.693674
I0701 16:31:28.089443  2788 solver.cpp:252]     Train net output #0: loss = 0.693264 (* 1 = 0.693264 loss)
I0701 16:31:28.089463  2788 sgd_solver.cpp:106] Iteration 15930, lr = 0.01
I0701 16:31:38.592231  2788 solver.cpp:236] Iteration 15940, loss = 0.6935
I0701 16:31:38.592301  2788 solver.cpp:252]     Train net output #0: loss = 0.692405 (* 1 = 0.692405 loss)
I0701 16:31:38.592320  2788 sgd_solver.cpp:106] Iteration 15940, lr = 0.01
I0701 16:31:49.056246  2788 solver.cpp:236] Iteration 15950, loss = 0.693397
I0701 16:31:49.056291  2788 solver.cpp:252]     Train net output #0: loss = 0.693288 (* 1 = 0.693288 loss)
I0701 16:31:49.056308  2788 sgd_solver.cpp:106] Iteration 15950, lr = 0.01
I0701 16:31:59.146630  2788 solver.cpp:236] Iteration 15960, loss = 0.6936
I0701 16:31:59.146807  2788 solver.cpp:252]     Train net output #0: loss = 0.695647 (* 1 = 0.695647 loss)
I0701 16:31:59.146836  2788 sgd_solver.cpp:106] Iteration 15960, lr = 0.01
I0701 16:32:09.417492  2788 solver.cpp:236] Iteration 15970, loss = 0.69343
I0701 16:32:09.417547  2788 solver.cpp:252]     Train net output #0: loss = 0.693019 (* 1 = 0.693019 loss)
I0701 16:32:09.417562  2788 sgd_solver.cpp:106] Iteration 15970, lr = 0.01
I0701 16:32:20.089675  2788 solver.cpp:236] Iteration 15980, loss = 0.693277
I0701 16:32:20.089731  2788 solver.cpp:252]     Train net output #0: loss = 0.6911 (* 1 = 0.6911 loss)
I0701 16:32:20.089745  2788 sgd_solver.cpp:106] Iteration 15980, lr = 0.01
I0701 16:32:30.738317  2788 solver.cpp:236] Iteration 15990, loss = 0.693264
I0701 16:32:30.738593  2788 solver.cpp:252]     Train net output #0: loss = 0.687631 (* 1 = 0.687631 loss)
I0701 16:32:30.738625  2788 sgd_solver.cpp:106] Iteration 15990, lr = 0.01
I0701 16:32:40.202370  2788 solver.cpp:340] Iteration 16000, Testing net (#0)
I0701 16:33:06.582053  2788 solver.cpp:408]     Test net output #0: accuracy = 0.5
I0701 16:33:06.582201  2788 solver.cpp:408]     Test net output #1: loss = 0.693322 (* 1 = 0.693322 loss)
I0701 16:33:06.812043  2788 solver.cpp:236] Iteration 16000, loss = 0.693745
I0701 16:33:06.812096  2788 solver.cpp:252]     Train net output #0: loss = 0.691859 (* 1 = 0.691859 loss)
I0701 16:33:06.812113  2788 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0701 16:33:15.838760  2788 solver.cpp:236] Iteration 16010, loss = 0.694258
I0701 16:33:15.838809  2788 solver.cpp:252]     Train net output #0: loss = 0.694618 (* 1 = 0.694618 loss)
I0701 16:33:15.838822  2788 sgd_solver.cpp:106] Iteration 16010, lr = 0.01
I0701 16:33:26.997702  2788 solver.cpp:236] Iteration 16020, loss = 0.694427
I0701 16:33:26.997757  2788 solver.cpp:252]     Train net output #0: loss = 0.692651 (* 1 = 0.692651 loss)
I0701 16:33:26.997772  2788 sgd_solver.cpp:106] Iteration 16020, lr = 0.01
I0701 16:33:37.291904  2788 solver.cpp:236] Iteration 16030, loss = 0.694396
I0701 16:33:37.292179  2788 solver.cpp:252]     Train net output #0: loss = 0.700642 (* 1 = 0.700642 loss)
I0701 16:33:37.292197  2788 sgd_solver.cpp:106] Iteration 16030, lr = 0.01
I0701 16:33:47.795819  2788 solver.cpp:236] Iteration 16040, loss = 0.694749
I0701 16:33:47.795877  2788 solver.cpp:252]     Train net output #0: loss = 0.690758 (* 1 = 0.690758 loss)
I0701 16:33:47.795892  2788 sgd_solver.cpp:106] Iteration 16040, lr = 0.01
I0701 16:33:58.207969  2788 solver.cpp:236] Iteration 16050, loss = 0.694383
I0701 16:33:58.208021  2788 solver.cpp:252]     Train net output #0: loss = 0.695229 (* 1 = 0.695229 loss)
I0701 16:33:58.208034  2788 sgd_solver.cpp:106] Iteration 16050, lr = 0.01
I0701 16:34:08.534360  2788 solver.cpp:236] Iteration 16060, loss = 0.693672
I0701 16:34:08.534579  2788 solver.cpp:252]     Train net output #0: loss = 0.692203 (* 1 = 0.692203 loss)
I0701 16:34:08.534605  2788 sgd_solver.cpp:106] Iteration 16060, lr = 0.01
I0701 16:34:19.417747  2788 solver.cpp:236] Iteration 16070, loss = 0.693607
I0701 16:34:19.417796  2788 solver.cpp:252]     Train net output #0: loss = 0.690165 (* 1 = 0.690165 loss)
I0701 16:34:19.417810  2788 sgd_solver.cpp:106] Iteration 16070, lr = 0.01
I0701 16:34:30.521760  2788 solver.cpp:236] Iteration 16080, loss = 0.693817
I0701 16:34:30.521809  2788 solver.cpp:252]     Train net output #0: loss = 0.69335 (* 1 = 0.69335 loss)
I0701 16:34:30.521824  2788 sgd_solver.cpp:106] Iteration 16080, lr = 0.01
I0701 16:34:40.873463  2788 solver.cpp:236] Iteration 16090, loss = 0.693452
I0701 16:34:40.873636  2788 solver.cpp:252]     Train net output #0: loss = 0.692864 (* 1 = 0.692864 loss)
I0701 16:34:40.873675  2788 sgd_solver.cpp:106] Iteration 16090, lr = 0.01
I0701 16:34:51.477648  2788 solver.cpp:236] Iteration 16100, loss = 0.693477
I0701 16:34:51.477720  2788 solver.cpp:252]     Train net output #0: loss = 0.69441 (* 1 = 0.69441 loss)
I0701 16:34:51.477740  2788 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0701 16:35:02.661574  2788 solver.cpp:236] Iteration 16110, loss = 0.693565
I0701 16:35:02.661620  2788 solver.cpp:252]     Train net output #0: loss = 0.692159 (* 1 = 0.692159 loss)
I0701 16:35:02.661633  2788 sgd_solver.cpp:106] Iteration 16110, lr = 0.01
I0701 16:35:13.142863  2788 solver.cpp:236] Iteration 16120, loss = 0.693364
I0701 16:35:13.143069  2788 solver.cpp:252]     Train net output #0: loss = 0.693247 (* 1 = 0.693247 loss)
I0701 16:35:13.143090  2788 sgd_solver.cpp:106] Iteration 16120, lr = 0.01
I0701 16:35:23.761343  2788 solver.cpp:236] Iteration 16130, loss = 0.693155
I0701 16:35:23.761401  2788 solver.cpp:252]     Train net output #0: loss = 0.6931 (* 1 = 0.6931 loss)
I0701 16:35:23.761415  2788 sgd_solver.cpp:106] Iteration 16130, lr = 0.01
I0701 16:35:33.772156  2788 solver.cpp:236] Iteration 16140, loss = 0.69317
I0701 16:35:33.772215  2788 solver.cpp:252]     Train net output #0: loss = 0.692709 (* 1 = 0.692709 loss)
I0701 16:35:33.772230  2788 sgd_solver.cpp:106] Iteration 16140, lr = 0.01
I0701 16:35:44.392843  2788 solver.cpp:236] Iteration 16150, loss = 0.693075
I0701 16:35:44.393081  2788 solver.cpp:252]     Train net output #0: loss = 0.692755 (* 1 = 0.692755 loss)
I0701 16:35:44.393100  2788 sgd_solver.cpp:106] Iteration 16150, lr = 0.01
I0701 16:35:56.204082  2788 solver.cpp:236] Iteration 16160, loss = 0.693123
I0701 16:35:56.204141  2788 solver.cpp:252]     Train net output #0: loss = 0.692989 (* 1 = 0.692989 loss)
I0701 16:35:56.204155  2788 sgd_solver.cpp:106] Iteration 16160, lr = 0.01
I0701 16:36:06.706948  2788 solver.cpp:236] Iteration 16170, loss = 0.693141
I0701 16:36:06.706998  2788 solver.cpp:252]     Train net output #0: loss = 0.693118 (* 1 = 0.693118 loss)
I0701 16:36:06.707013  2788 sgd_solver.cpp:106] Iteration 16170, lr = 0.01
I0701 16:36:17.657371  2788 solver.cpp:236] Iteration 16180, loss = 0.693208
I0701 16:36:17.659536  2788 solver.cpp:252]     Train net output #0: loss = 0.691757 (* 1 = 0.691757 loss)
I0701 16:36:17.659554  2788 sgd_solver.cpp:106] Iteration 16180, lr = 0.01
I0701 16:36:28.255008  2788 solver.cpp:236] Iteration 16190, loss = 0.693138
I0701 16:36:28.255066  2788 solver.cpp:252]     Train net output #0: loss = 0.6911 (* 1 = 0.6911 loss)
I0701 16:36:28.255080  2788 sgd_solver.cpp:106] Iteration 16190, lr = 0.01
I0701 16:36:39.017942  2788 solver.cpp:236] Iteration 16200, loss = 0.693337
I0701 16:36:39.017989  2788 solver.cpp:252]     Train net output #0: loss = 0.692899 (* 1 = 0.692899 loss)
I0701 16:36:39.018002  2788 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0701 16:36:50.828158  2788 solver.cpp:236] Iteration 16210, loss = 0.693295
I0701 16:36:50.828517  2788 solver.cpp:252]     Train net output #0: loss = 0.692546 (* 1 = 0.692546 loss)
I0701 16:36:50.828557  2788 sgd_solver.cpp:106] Iteration 16210, lr = 0.01
I0701 16:37:02.222461  2788 solver.cpp:236] Iteration 16220, loss = 0.693291
I0701 16:37:02.222519  2788 solver.cpp:252]     Train net output #0: loss = 0.69346 (* 1 = 0.69346 loss)
I0701 16:37:02.222535  2788 sgd_solver.cpp:106] Iteration 16220, lr = 0.01
I0701 16:37:13.285187  2788 solver.cpp:236] Iteration 16230, loss = 0.693415
I0701 16:37:13.285264  2788 solver.cpp:252]     Train net output #0: loss = 0.69585 (* 1 = 0.69585 loss)
I0701 16:37:13.285285  2788 sgd_solver.cpp:106] Iteration 16230, lr = 0.01
I0701 16:37:24.344893  2788 solver.cpp:236] Iteration 16240, loss = 0.693452
I0701 16:37:24.345144  2788 solver.cpp:252]     Train net output #0: loss = 0.693997 (* 1 = 0.693997 loss)
I0701 16:37:24.345165  2788 sgd_solver.cpp:106] Iteration 16240, lr = 0.01
I0701 16:37:34.105717  2788 solver.cpp:340] Iteration 16250, Testing net (#0)
I0701 16:38:01.849406  2788 solver.cpp:408]     Test net output #0: accuracy = 0.496563
I0701 16:38:01.849603  2788 solver.cpp:408]     Test net output #1: loss = 0.693424 (* 1 = 0.693424 loss)
I0701 16:38:02.079223  2788 solver.cpp:236] Iteration 16250, loss = 0.693283
I0701 16:38:02.079275  2788 solver.cpp:252]     Train net output #0: loss = 0.696057 (* 1 = 0.696057 loss)
I0701 16:38:02.079293  2788 sgd_solver.cpp:106] Iteration 16250, lr = 0.01
I0701 16:38:11.295307  2788 solver.cpp:236] Iteration 16260, loss = 0.693349
I0701 16:38:11.295363  2788 solver.cpp:252]     Train net output #0: loss = 0.695973 (* 1 = 0.695973 loss)
I0701 16:38:11.295377  2788 sgd_solver.cpp:106] Iteration 16260, lr = 0.01
I0701 16:38:22.189003  2788 solver.cpp:236] Iteration 16270, loss = 0.693376
I0701 16:38:22.189048  2788 solver.cpp:252]     Train net output #0: loss = 0.69383 (* 1 = 0.69383 loss)
I0701 16:38:22.189064  2788 sgd_solver.cpp:106] Iteration 16270, lr = 0.01
I0701 16:38:33.344045  2788 solver.cpp:236] Iteration 16280, loss = 0.693284
I0701 16:38:33.345695  2788 solver.cpp:252]     Train net output #0: loss = 0.696804 (* 1 = 0.696804 loss)
I0701 16:38:33.345729  2788 sgd_solver.cpp:106] Iteration 16280, lr = 0.01
I0701 16:38:44.094846  2788 solver.cpp:236] Iteration 16290, loss = 0.693349
I0701 16:38:44.094899  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 16:38:44.094914  2788 sgd_solver.cpp:106] Iteration 16290, lr = 0.01
I0701 16:38:54.713130  2788 solver.cpp:236] Iteration 16300, loss = 0.693324
I0701 16:38:54.713197  2788 solver.cpp:252]     Train net output #0: loss = 0.693928 (* 1 = 0.693928 loss)
I0701 16:38:54.713212  2788 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0701 16:39:05.676651  2788 solver.cpp:236] Iteration 16310, loss = 0.693316
I0701 16:39:05.676923  2788 solver.cpp:252]     Train net output #0: loss = 0.696005 (* 1 = 0.696005 loss)
I0701 16:39:05.676950  2788 sgd_solver.cpp:106] Iteration 16310, lr = 0.01
I0701 16:39:16.737627  2788 solver.cpp:236] Iteration 16320, loss = 0.693645
I0701 16:39:16.737676  2788 solver.cpp:252]     Train net output #0: loss = 0.693216 (* 1 = 0.693216 loss)
I0701 16:39:16.737694  2788 sgd_solver.cpp:106] Iteration 16320, lr = 0.01
I0701 16:39:27.738818  2788 solver.cpp:236] Iteration 16330, loss = 0.693687
I0701 16:39:27.738893  2788 solver.cpp:252]     Train net output #0: loss = 0.692739 (* 1 = 0.692739 loss)
I0701 16:39:27.738909  2788 sgd_solver.cpp:106] Iteration 16330, lr = 0.01
I0701 16:39:38.417080  2788 solver.cpp:236] Iteration 16340, loss = 0.693641
I0701 16:39:38.417317  2788 solver.cpp:252]     Train net output #0: loss = 0.692617 (* 1 = 0.692617 loss)
I0701 16:39:38.417335  2788 sgd_solver.cpp:106] Iteration 16340, lr = 0.01
I0701 16:39:49.845603  2788 solver.cpp:236] Iteration 16350, loss = 0.693638
I0701 16:39:49.845660  2788 solver.cpp:252]     Train net output #0: loss = 0.695091 (* 1 = 0.695091 loss)
I0701 16:39:49.845675  2788 sgd_solver.cpp:106] Iteration 16350, lr = 0.01
I0701 16:40:00.906754  2788 solver.cpp:236] Iteration 16360, loss = 0.693615
I0701 16:40:00.906834  2788 solver.cpp:252]     Train net output #0: loss = 0.693365 (* 1 = 0.693365 loss)
I0701 16:40:00.906850  2788 sgd_solver.cpp:106] Iteration 16360, lr = 0.01
I0701 16:40:11.733191  2788 solver.cpp:236] Iteration 16370, loss = 0.693286
I0701 16:40:11.733399  2788 solver.cpp:252]     Train net output #0: loss = 0.693278 (* 1 = 0.693278 loss)
I0701 16:40:11.733414  2788 sgd_solver.cpp:106] Iteration 16370, lr = 0.01
I0701 16:40:23.224140  2788 solver.cpp:236] Iteration 16380, loss = 0.693216
I0701 16:40:23.224210  2788 solver.cpp:252]     Train net output #0: loss = 0.693649 (* 1 = 0.693649 loss)
I0701 16:40:23.224230  2788 sgd_solver.cpp:106] Iteration 16380, lr = 0.01
I0701 16:40:34.695744  2788 solver.cpp:236] Iteration 16390, loss = 0.693258
I0701 16:40:34.695792  2788 solver.cpp:252]     Train net output #0: loss = 0.692619 (* 1 = 0.692619 loss)
I0701 16:40:34.695806  2788 sgd_solver.cpp:106] Iteration 16390, lr = 0.01
I0701 16:40:45.944088  2788 solver.cpp:236] Iteration 16400, loss = 0.693266
I0701 16:40:45.944303  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 16:40:45.944321  2788 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0701 16:40:47.013079  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 16:40:57.344470  2788 solver.cpp:236] Iteration 16410, loss = 0.693248
I0701 16:40:57.344532  2788 solver.cpp:252]     Train net output #0: loss = 0.693046 (* 1 = 0.693046 loss)
I0701 16:40:57.344552  2788 sgd_solver.cpp:106] Iteration 16410, lr = 0.01
I0701 16:41:09.001725  2788 solver.cpp:236] Iteration 16420, loss = 0.693293
I0701 16:41:09.001780  2788 solver.cpp:252]     Train net output #0: loss = 0.694886 (* 1 = 0.694886 loss)
I0701 16:41:09.001793  2788 sgd_solver.cpp:106] Iteration 16420, lr = 0.01
I0701 16:41:20.113358  2788 solver.cpp:236] Iteration 16430, loss = 0.693284
I0701 16:41:20.113579  2788 solver.cpp:252]     Train net output #0: loss = 0.69306 (* 1 = 0.69306 loss)
I0701 16:41:20.113607  2788 sgd_solver.cpp:106] Iteration 16430, lr = 0.01
I0701 16:41:31.563511  2788 solver.cpp:236] Iteration 16440, loss = 0.692833
I0701 16:41:31.563561  2788 solver.cpp:252]     Train net output #0: loss = 0.684955 (* 1 = 0.684955 loss)
I0701 16:41:31.563576  2788 sgd_solver.cpp:106] Iteration 16440, lr = 0.01
I0701 16:41:42.857836  2788 solver.cpp:236] Iteration 16450, loss = 0.693133
I0701 16:41:42.857890  2788 solver.cpp:252]     Train net output #0: loss = 0.696958 (* 1 = 0.696958 loss)
I0701 16:41:42.857904  2788 sgd_solver.cpp:106] Iteration 16450, lr = 0.01
I0701 16:41:54.078402  2788 solver.cpp:236] Iteration 16460, loss = 0.693828
I0701 16:41:54.078692  2788 solver.cpp:252]     Train net output #0: loss = 0.693057 (* 1 = 0.693057 loss)
I0701 16:41:54.078719  2788 sgd_solver.cpp:106] Iteration 16460, lr = 0.01
I0701 16:42:05.826297  2788 solver.cpp:236] Iteration 16470, loss = 0.693743
I0701 16:42:05.826347  2788 solver.cpp:252]     Train net output #0: loss = 0.694856 (* 1 = 0.694856 loss)
I0701 16:42:05.826362  2788 sgd_solver.cpp:106] Iteration 16470, lr = 0.01
I0701 16:42:16.954144  2788 solver.cpp:236] Iteration 16480, loss = 0.69379
I0701 16:42:16.954190  2788 solver.cpp:252]     Train net output #0: loss = 0.691513 (* 1 = 0.691513 loss)
I0701 16:42:16.954203  2788 sgd_solver.cpp:106] Iteration 16480, lr = 0.01
I0701 16:42:28.772248  2788 solver.cpp:236] Iteration 16490, loss = 0.694188
I0701 16:42:28.772593  2788 solver.cpp:252]     Train net output #0: loss = 0.692169 (* 1 = 0.692169 loss)
I0701 16:42:28.772611  2788 sgd_solver.cpp:106] Iteration 16490, lr = 0.01
I0701 16:42:38.898440  2788 solver.cpp:340] Iteration 16500, Testing net (#0)
I0701 16:43:06.599393  2788 solver.cpp:408]     Test net output #0: accuracy = 0.477812
I0701 16:43:06.599598  2788 solver.cpp:408]     Test net output #1: loss = 0.693781 (* 1 = 0.693781 loss)
I0701 16:43:06.834348  2788 solver.cpp:236] Iteration 16500, loss = 0.693917
I0701 16:43:06.834403  2788 solver.cpp:252]     Train net output #0: loss = 0.693616 (* 1 = 0.693616 loss)
I0701 16:43:06.834419  2788 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0701 16:43:16.385426  2788 solver.cpp:236] Iteration 16510, loss = 0.693264
I0701 16:43:16.385468  2788 solver.cpp:252]     Train net output #0: loss = 0.692941 (* 1 = 0.692941 loss)
I0701 16:43:16.385479  2788 sgd_solver.cpp:106] Iteration 16510, lr = 0.01
I0701 16:43:27.617847  2788 solver.cpp:236] Iteration 16520, loss = 0.693214
I0701 16:43:27.617895  2788 solver.cpp:252]     Train net output #0: loss = 0.692664 (* 1 = 0.692664 loss)
I0701 16:43:27.617905  2788 sgd_solver.cpp:106] Iteration 16520, lr = 0.01
I0701 16:43:39.668529  2788 solver.cpp:236] Iteration 16530, loss = 0.693181
I0701 16:43:39.668655  2788 solver.cpp:252]     Train net output #0: loss = 0.693788 (* 1 = 0.693788 loss)
I0701 16:43:39.668670  2788 sgd_solver.cpp:106] Iteration 16530, lr = 0.01
I0701 16:43:49.506796  2788 solver.cpp:236] Iteration 16540, loss = 0.693545
I0701 16:43:49.506855  2788 solver.cpp:252]     Train net output #0: loss = 0.693129 (* 1 = 0.693129 loss)
I0701 16:43:49.506870  2788 sgd_solver.cpp:106] Iteration 16540, lr = 0.01
I0701 16:43:56.281239  2788 solver.cpp:236] Iteration 16550, loss = 0.693475
I0701 16:43:56.281301  2788 solver.cpp:252]     Train net output #0: loss = 0.691009 (* 1 = 0.691009 loss)
I0701 16:43:56.281316  2788 sgd_solver.cpp:106] Iteration 16550, lr = 0.01
I0701 16:44:03.078529  2788 solver.cpp:236] Iteration 16560, loss = 0.693586
I0701 16:44:03.078579  2788 solver.cpp:252]     Train net output #0: loss = 0.693288 (* 1 = 0.693288 loss)
I0701 16:44:03.078595  2788 sgd_solver.cpp:106] Iteration 16560, lr = 0.01
I0701 16:44:09.875594  2788 solver.cpp:236] Iteration 16570, loss = 0.693666
I0701 16:44:09.879032  2788 solver.cpp:252]     Train net output #0: loss = 0.697545 (* 1 = 0.697545 loss)
I0701 16:44:09.879056  2788 sgd_solver.cpp:106] Iteration 16570, lr = 0.01
I0701 16:44:16.689765  2788 solver.cpp:236] Iteration 16580, loss = 0.693722
I0701 16:44:16.689806  2788 solver.cpp:252]     Train net output #0: loss = 0.698609 (* 1 = 0.698609 loss)
I0701 16:44:16.689820  2788 sgd_solver.cpp:106] Iteration 16580, lr = 0.01
I0701 16:44:23.496546  2788 solver.cpp:236] Iteration 16590, loss = 0.693537
I0701 16:44:23.496601  2788 solver.cpp:252]     Train net output #0: loss = 0.69265 (* 1 = 0.69265 loss)
I0701 16:44:23.496614  2788 sgd_solver.cpp:106] Iteration 16590, lr = 0.01
I0701 16:44:30.324968  2788 solver.cpp:236] Iteration 16600, loss = 0.693576
I0701 16:44:30.325031  2788 solver.cpp:252]     Train net output #0: loss = 0.693115 (* 1 = 0.693115 loss)
I0701 16:44:30.325045  2788 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0701 16:44:37.146555  2788 solver.cpp:236] Iteration 16610, loss = 0.693451
I0701 16:44:37.146617  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 16:44:37.146631  2788 sgd_solver.cpp:106] Iteration 16610, lr = 0.01
I0701 16:44:43.948751  2788 solver.cpp:236] Iteration 16620, loss = 0.693438
I0701 16:44:43.952500  2788 solver.cpp:252]     Train net output #0: loss = 0.69401 (* 1 = 0.69401 loss)
I0701 16:44:43.952519  2788 sgd_solver.cpp:106] Iteration 16620, lr = 0.01
I0701 16:44:50.783418  2788 solver.cpp:236] Iteration 16630, loss = 0.693262
I0701 16:44:50.783468  2788 solver.cpp:252]     Train net output #0: loss = 0.693448 (* 1 = 0.693448 loss)
I0701 16:44:50.783481  2788 sgd_solver.cpp:106] Iteration 16630, lr = 0.01
I0701 16:44:57.610512  2788 solver.cpp:236] Iteration 16640, loss = 0.693116
I0701 16:44:57.610569  2788 solver.cpp:252]     Train net output #0: loss = 0.690375 (* 1 = 0.690375 loss)
I0701 16:44:57.610584  2788 sgd_solver.cpp:106] Iteration 16640, lr = 0.01
I0701 16:45:04.435925  2788 solver.cpp:236] Iteration 16650, loss = 0.693171
I0701 16:45:04.435977  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 16:45:04.435992  2788 sgd_solver.cpp:106] Iteration 16650, lr = 0.01
I0701 16:45:11.249701  2788 solver.cpp:236] Iteration 16660, loss = 0.693141
I0701 16:45:11.249758  2788 solver.cpp:252]     Train net output #0: loss = 0.692487 (* 1 = 0.692487 loss)
I0701 16:45:11.249773  2788 sgd_solver.cpp:106] Iteration 16660, lr = 0.01
I0701 16:45:18.080525  2788 solver.cpp:236] Iteration 16670, loss = 0.693163
I0701 16:45:18.080760  2788 solver.cpp:252]     Train net output #0: loss = 0.693272 (* 1 = 0.693272 loss)
I0701 16:45:18.080781  2788 sgd_solver.cpp:106] Iteration 16670, lr = 0.01
I0701 16:45:24.914333  2788 solver.cpp:236] Iteration 16680, loss = 0.693153
I0701 16:45:24.914391  2788 solver.cpp:252]     Train net output #0: loss = 0.694295 (* 1 = 0.694295 loss)
I0701 16:45:24.914407  2788 sgd_solver.cpp:106] Iteration 16680, lr = 0.01
I0701 16:45:31.738903  2788 solver.cpp:236] Iteration 16690, loss = 0.692923
I0701 16:45:31.738981  2788 solver.cpp:252]     Train net output #0: loss = 0.694816 (* 1 = 0.694816 loss)
I0701 16:45:31.738998  2788 sgd_solver.cpp:106] Iteration 16690, lr = 0.01
I0701 16:45:38.586966  2788 solver.cpp:236] Iteration 16700, loss = 0.693087
I0701 16:45:38.587016  2788 solver.cpp:252]     Train net output #0: loss = 0.693771 (* 1 = 0.693771 loss)
I0701 16:45:38.587030  2788 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0701 16:45:45.417413  2788 solver.cpp:236] Iteration 16710, loss = 0.693206
I0701 16:45:45.417464  2788 solver.cpp:252]     Train net output #0: loss = 0.694183 (* 1 = 0.694183 loss)
I0701 16:45:45.417477  2788 sgd_solver.cpp:106] Iteration 16710, lr = 0.01
I0701 16:45:52.257493  2788 solver.cpp:236] Iteration 16720, loss = 0.693402
I0701 16:45:52.257648  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 16:45:52.257670  2788 sgd_solver.cpp:106] Iteration 16720, lr = 0.01
I0701 16:45:59.111892  2788 solver.cpp:236] Iteration 16730, loss = 0.693544
I0701 16:45:59.111955  2788 solver.cpp:252]     Train net output #0: loss = 0.693244 (* 1 = 0.693244 loss)
I0701 16:45:59.111969  2788 sgd_solver.cpp:106] Iteration 16730, lr = 0.01
I0701 16:46:05.945243  2788 solver.cpp:236] Iteration 16740, loss = 0.693797
I0701 16:46:05.945291  2788 solver.cpp:252]     Train net output #0: loss = 0.693088 (* 1 = 0.693088 loss)
I0701 16:46:05.945304  2788 sgd_solver.cpp:106] Iteration 16740, lr = 0.01
I0701 16:46:12.105890  2788 solver.cpp:340] Iteration 16750, Testing net (#0)
I0701 16:46:26.309083  2788 solver.cpp:408]     Test net output #0: accuracy = 0.504687
I0701 16:46:26.309347  2788 solver.cpp:408]     Test net output #1: loss = 0.693104 (* 1 = 0.693104 loss)
I0701 16:46:26.497793  2788 solver.cpp:236] Iteration 16750, loss = 0.693527
I0701 16:46:26.497856  2788 solver.cpp:252]     Train net output #0: loss = 0.691633 (* 1 = 0.691633 loss)
I0701 16:46:26.497879  2788 sgd_solver.cpp:106] Iteration 16750, lr = 0.01
I0701 16:46:33.303416  2788 solver.cpp:236] Iteration 16760, loss = 0.6934
I0701 16:46:33.303475  2788 solver.cpp:252]     Train net output #0: loss = 0.695418 (* 1 = 0.695418 loss)
I0701 16:46:33.303489  2788 sgd_solver.cpp:106] Iteration 16760, lr = 0.01
I0701 16:46:40.123257  2788 solver.cpp:236] Iteration 16770, loss = 0.693273
I0701 16:46:40.123307  2788 solver.cpp:252]     Train net output #0: loss = 0.696199 (* 1 = 0.696199 loss)
I0701 16:46:40.123322  2788 sgd_solver.cpp:106] Iteration 16770, lr = 0.01
I0701 16:46:46.939769  2788 solver.cpp:236] Iteration 16780, loss = 0.693147
I0701 16:46:46.939813  2788 solver.cpp:252]     Train net output #0: loss = 0.694224 (* 1 = 0.694224 loss)
I0701 16:46:46.939826  2788 sgd_solver.cpp:106] Iteration 16780, lr = 0.01
I0701 16:46:53.763725  2788 solver.cpp:236] Iteration 16790, loss = 0.692953
I0701 16:46:53.763779  2788 solver.cpp:252]     Train net output #0: loss = 0.692662 (* 1 = 0.692662 loss)
I0701 16:46:53.763795  2788 sgd_solver.cpp:106] Iteration 16790, lr = 0.01
I0701 16:47:00.598104  2788 solver.cpp:236] Iteration 16800, loss = 0.693045
I0701 16:47:00.598332  2788 solver.cpp:252]     Train net output #0: loss = 0.696066 (* 1 = 0.696066 loss)
I0701 16:47:00.598350  2788 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0701 16:47:07.429061  2788 solver.cpp:236] Iteration 16810, loss = 0.693058
I0701 16:47:07.429110  2788 solver.cpp:252]     Train net output #0: loss = 0.695545 (* 1 = 0.695545 loss)
I0701 16:47:07.429124  2788 sgd_solver.cpp:106] Iteration 16810, lr = 0.01
I0701 16:47:14.241518  2788 solver.cpp:236] Iteration 16820, loss = 0.693066
I0701 16:47:14.241581  2788 solver.cpp:252]     Train net output #0: loss = 0.693286 (* 1 = 0.693286 loss)
I0701 16:47:14.241596  2788 sgd_solver.cpp:106] Iteration 16820, lr = 0.01
I0701 16:47:21.071024  2788 solver.cpp:236] Iteration 16830, loss = 0.693178
I0701 16:47:21.071069  2788 solver.cpp:252]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0701 16:47:21.071084  2788 sgd_solver.cpp:106] Iteration 16830, lr = 0.01
I0701 16:47:27.905134  2788 solver.cpp:236] Iteration 16840, loss = 0.693358
I0701 16:47:27.905197  2788 solver.cpp:252]     Train net output #0: loss = 0.693549 (* 1 = 0.693549 loss)
I0701 16:47:27.905213  2788 sgd_solver.cpp:106] Iteration 16840, lr = 0.01
I0701 16:47:34.736982  2788 solver.cpp:236] Iteration 16850, loss = 0.693321
I0701 16:47:34.740474  2788 solver.cpp:252]     Train net output #0: loss = 0.693495 (* 1 = 0.693495 loss)
I0701 16:47:34.740492  2788 sgd_solver.cpp:106] Iteration 16850, lr = 0.01
I0701 16:47:41.566334  2788 solver.cpp:236] Iteration 16860, loss = 0.693259
I0701 16:47:41.566382  2788 solver.cpp:252]     Train net output #0: loss = 0.692793 (* 1 = 0.692793 loss)
I0701 16:47:41.566396  2788 sgd_solver.cpp:106] Iteration 16860, lr = 0.01
I0701 16:47:48.387737  2788 solver.cpp:236] Iteration 16870, loss = 0.693063
I0701 16:47:48.387786  2788 solver.cpp:252]     Train net output #0: loss = 0.690128 (* 1 = 0.690128 loss)
I0701 16:47:48.387806  2788 sgd_solver.cpp:106] Iteration 16870, lr = 0.01
I0701 16:47:55.211469  2788 solver.cpp:236] Iteration 16880, loss = 0.69312
I0701 16:47:55.211525  2788 solver.cpp:252]     Train net output #0: loss = 0.692197 (* 1 = 0.692197 loss)
I0701 16:47:55.211539  2788 sgd_solver.cpp:106] Iteration 16880, lr = 0.01
I0701 16:48:02.048285  2788 solver.cpp:236] Iteration 16890, loss = 0.69328
I0701 16:48:02.048338  2788 solver.cpp:252]     Train net output #0: loss = 0.692872 (* 1 = 0.692872 loss)
I0701 16:48:02.048352  2788 sgd_solver.cpp:106] Iteration 16890, lr = 0.01
I0701 16:48:08.864887  2788 solver.cpp:236] Iteration 16900, loss = 0.693257
I0701 16:48:08.865128  2788 solver.cpp:252]     Train net output #0: loss = 0.695233 (* 1 = 0.695233 loss)
I0701 16:48:08.865145  2788 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0701 16:48:15.709389  2788 solver.cpp:236] Iteration 16910, loss = 0.693318
I0701 16:48:15.709447  2788 solver.cpp:252]     Train net output #0: loss = 0.692241 (* 1 = 0.692241 loss)
I0701 16:48:15.709462  2788 sgd_solver.cpp:106] Iteration 16910, lr = 0.01
I0701 16:48:22.545552  2788 solver.cpp:236] Iteration 16920, loss = 0.693401
I0701 16:48:22.545598  2788 solver.cpp:252]     Train net output #0: loss = 0.693638 (* 1 = 0.693638 loss)
I0701 16:48:22.545614  2788 sgd_solver.cpp:106] Iteration 16920, lr = 0.01
I0701 16:48:29.367766  2788 solver.cpp:236] Iteration 16930, loss = 0.693441
I0701 16:48:29.367820  2788 solver.cpp:252]     Train net output #0: loss = 0.693869 (* 1 = 0.693869 loss)
I0701 16:48:29.367835  2788 sgd_solver.cpp:106] Iteration 16930, lr = 0.01
I0701 16:48:36.187636  2788 solver.cpp:236] Iteration 16940, loss = 0.693262
I0701 16:48:36.187687  2788 solver.cpp:252]     Train net output #0: loss = 0.694249 (* 1 = 0.694249 loss)
I0701 16:48:36.187702  2788 sgd_solver.cpp:106] Iteration 16940, lr = 0.01
I0701 16:48:43.021651  2788 solver.cpp:236] Iteration 16950, loss = 0.693263
I0701 16:48:43.028491  2788 solver.cpp:252]     Train net output #0: loss = 0.692774 (* 1 = 0.692774 loss)
I0701 16:48:43.028511  2788 sgd_solver.cpp:106] Iteration 16950, lr = 0.01
I0701 16:48:49.858242  2788 solver.cpp:236] Iteration 16960, loss = 0.69337
I0701 16:48:49.858289  2788 solver.cpp:252]     Train net output #0: loss = 0.693429 (* 1 = 0.693429 loss)
I0701 16:48:49.858304  2788 sgd_solver.cpp:106] Iteration 16960, lr = 0.01
I0701 16:48:56.684496  2788 solver.cpp:236] Iteration 16970, loss = 0.693432
I0701 16:48:56.684553  2788 solver.cpp:252]     Train net output #0: loss = 0.693734 (* 1 = 0.693734 loss)
I0701 16:48:56.684567  2788 sgd_solver.cpp:106] Iteration 16970, lr = 0.01
I0701 16:49:03.522101  2788 solver.cpp:236] Iteration 16980, loss = 0.693301
I0701 16:49:03.522163  2788 solver.cpp:252]     Train net output #0: loss = 0.69713 (* 1 = 0.69713 loss)
I0701 16:49:03.522179  2788 sgd_solver.cpp:106] Iteration 16980, lr = 0.01
I0701 16:49:10.353337  2788 solver.cpp:236] Iteration 16990, loss = 0.69338
I0701 16:49:10.353382  2788 solver.cpp:252]     Train net output #0: loss = 0.692671 (* 1 = 0.692671 loss)
I0701 16:49:10.353397  2788 sgd_solver.cpp:106] Iteration 16990, lr = 0.01
I0701 16:49:16.493803  2788 solver.cpp:340] Iteration 17000, Testing net (#0)
I0701 16:49:28.993696  2788 solver.cpp:408]     Test net output #0: accuracy = 0.491562
I0701 16:49:28.993747  2788 solver.cpp:408]     Test net output #1: loss = 0.69366 (* 1 = 0.69366 loss)
I0701 16:49:29.172026  2788 solver.cpp:236] Iteration 17000, loss = 0.693406
I0701 16:49:29.172077  2788 solver.cpp:252]     Train net output #0: loss = 0.693334 (* 1 = 0.693334 loss)
I0701 16:49:29.172092  2788 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0701 16:49:35.988545  2788 solver.cpp:236] Iteration 17010, loss = 0.693373
I0701 16:49:35.988603  2788 solver.cpp:252]     Train net output #0: loss = 0.692877 (* 1 = 0.692877 loss)
I0701 16:49:35.988618  2788 sgd_solver.cpp:106] Iteration 17010, lr = 0.01
I0701 16:49:42.824007  2788 solver.cpp:236] Iteration 17020, loss = 0.693304
I0701 16:49:42.824062  2788 solver.cpp:252]     Train net output #0: loss = 0.692453 (* 1 = 0.692453 loss)
I0701 16:49:42.824076  2788 sgd_solver.cpp:106] Iteration 17020, lr = 0.01
I0701 16:49:49.635038  2788 solver.cpp:236] Iteration 17030, loss = 0.693233
I0701 16:49:49.635288  2788 solver.cpp:252]     Train net output #0: loss = 0.692678 (* 1 = 0.692678 loss)
I0701 16:49:49.635308  2788 sgd_solver.cpp:106] Iteration 17030, lr = 0.01
I0701 16:49:56.470331  2788 solver.cpp:236] Iteration 17040, loss = 0.693308
I0701 16:49:56.470383  2788 solver.cpp:252]     Train net output #0: loss = 0.694802 (* 1 = 0.694802 loss)
I0701 16:49:56.470398  2788 sgd_solver.cpp:106] Iteration 17040, lr = 0.01
I0701 16:50:03.288720  2788 solver.cpp:236] Iteration 17050, loss = 0.693367
I0701 16:50:03.288763  2788 solver.cpp:252]     Train net output #0: loss = 0.693024 (* 1 = 0.693024 loss)
I0701 16:50:03.288776  2788 sgd_solver.cpp:106] Iteration 17050, lr = 0.01
I0701 16:50:10.119282  2788 solver.cpp:236] Iteration 17060, loss = 0.69335
I0701 16:50:10.119335  2788 solver.cpp:252]     Train net output #0: loss = 0.693047 (* 1 = 0.693047 loss)
I0701 16:50:10.119352  2788 sgd_solver.cpp:106] Iteration 17060, lr = 0.01
I0701 16:50:16.956557  2788 solver.cpp:236] Iteration 17070, loss = 0.693388
I0701 16:50:16.956646  2788 solver.cpp:252]     Train net output #0: loss = 0.69314 (* 1 = 0.69314 loss)
I0701 16:50:16.956676  2788 sgd_solver.cpp:106] Iteration 17070, lr = 0.01
I0701 16:50:23.780256  2788 solver.cpp:236] Iteration 17080, loss = 0.693473
I0701 16:50:23.780637  2788 solver.cpp:252]     Train net output #0: loss = 0.692634 (* 1 = 0.692634 loss)
I0701 16:50:23.780655  2788 sgd_solver.cpp:106] Iteration 17080, lr = 0.01
I0701 16:50:30.598346  2788 solver.cpp:236] Iteration 17090, loss = 0.693384
I0701 16:50:30.598403  2788 solver.cpp:252]     Train net output #0: loss = 0.693068 (* 1 = 0.693068 loss)
I0701 16:50:30.598417  2788 sgd_solver.cpp:106] Iteration 17090, lr = 0.01
I0701 16:50:37.399129  2788 solver.cpp:236] Iteration 17100, loss = 0.693261
I0701 16:50:37.399173  2788 solver.cpp:252]     Train net output #0: loss = 0.69129 (* 1 = 0.69129 loss)
I0701 16:50:37.399186  2788 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0701 16:50:44.236546  2788 solver.cpp:236] Iteration 17110, loss = 0.693192
I0701 16:50:44.236605  2788 solver.cpp:252]     Train net output #0: loss = 0.689742 (* 1 = 0.689742 loss)
I0701 16:50:44.236619  2788 sgd_solver.cpp:106] Iteration 17110, lr = 0.01
I0701 16:50:51.070963  2788 solver.cpp:236] Iteration 17120, loss = 0.693325
I0701 16:50:51.071035  2788 solver.cpp:252]     Train net output #0: loss = 0.695782 (* 1 = 0.695782 loss)
I0701 16:50:51.071060  2788 sgd_solver.cpp:106] Iteration 17120, lr = 0.01
I0701 16:50:57.912214  2788 solver.cpp:236] Iteration 17130, loss = 0.693292
I0701 16:50:57.912446  2788 solver.cpp:252]     Train net output #0: loss = 0.692689 (* 1 = 0.692689 loss)
I0701 16:50:57.912461  2788 sgd_solver.cpp:106] Iteration 17130, lr = 0.01
I0701 16:51:04.766135  2788 solver.cpp:236] Iteration 17140, loss = 0.693292
I0701 16:51:04.766196  2788 solver.cpp:252]     Train net output #0: loss = 0.693614 (* 1 = 0.693614 loss)
I0701 16:51:04.766211  2788 sgd_solver.cpp:106] Iteration 17140, lr = 0.01
I0701 16:51:11.601547  2788 solver.cpp:236] Iteration 17150, loss = 0.693309
I0701 16:51:11.601629  2788 solver.cpp:252]     Train net output #0: loss = 0.696365 (* 1 = 0.696365 loss)
I0701 16:51:11.601649  2788 sgd_solver.cpp:106] Iteration 17150, lr = 0.01
I0701 16:51:18.437703  2788 solver.cpp:236] Iteration 17160, loss = 0.693658
I0701 16:51:18.437778  2788 solver.cpp:252]     Train net output #0: loss = 0.694913 (* 1 = 0.694913 loss)
I0701 16:51:18.437795  2788 sgd_solver.cpp:106] Iteration 17160, lr = 0.01
I0701 16:51:25.282605  2788 solver.cpp:236] Iteration 17170, loss = 0.693474
I0701 16:51:25.282670  2788 solver.cpp:252]     Train net output #0: loss = 0.694625 (* 1 = 0.694625 loss)
I0701 16:51:25.282691  2788 sgd_solver.cpp:106] Iteration 17170, lr = 0.01
I0701 16:51:32.128186  2788 solver.cpp:236] Iteration 17180, loss = 0.693503
I0701 16:51:32.128327  2788 solver.cpp:252]     Train net output #0: loss = 0.692359 (* 1 = 0.692359 loss)
I0701 16:51:32.128343  2788 sgd_solver.cpp:106] Iteration 17180, lr = 0.01
I0701 16:51:38.957072  2788 solver.cpp:236] Iteration 17190, loss = 0.693432
I0701 16:51:38.957134  2788 solver.cpp:252]     Train net output #0: loss = 0.690088 (* 1 = 0.690088 loss)
I0701 16:51:38.957149  2788 sgd_solver.cpp:106] Iteration 17190, lr = 0.01
I0701 16:51:45.790899  2788 solver.cpp:236] Iteration 17200, loss = 0.693409
I0701 16:51:45.790951  2788 solver.cpp:252]     Train net output #0: loss = 0.693043 (* 1 = 0.693043 loss)
I0701 16:51:45.790969  2788 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0701 16:51:52.626296  2788 solver.cpp:236] Iteration 17210, loss = 0.693042
I0701 16:51:52.626345  2788 solver.cpp:252]     Train net output #0: loss = 0.694792 (* 1 = 0.694792 loss)
I0701 16:51:52.626359  2788 sgd_solver.cpp:106] Iteration 17210, lr = 0.01
I0701 16:51:59.467183  2788 solver.cpp:236] Iteration 17220, loss = 0.693208
I0701 16:51:59.467249  2788 solver.cpp:252]     Train net output #0: loss = 0.69489 (* 1 = 0.69489 loss)
I0701 16:51:59.467263  2788 sgd_solver.cpp:106] Iteration 17220, lr = 0.01
I0701 16:52:06.303272  2788 solver.cpp:236] Iteration 17230, loss = 0.693235
I0701 16:52:06.303582  2788 solver.cpp:252]     Train net output #0: loss = 0.6929 (* 1 = 0.6929 loss)
I0701 16:52:06.303601  2788 sgd_solver.cpp:106] Iteration 17230, lr = 0.01
I0701 16:52:13.155258  2788 solver.cpp:236] Iteration 17240, loss = 0.693258
I0701 16:52:13.155318  2788 solver.cpp:252]     Train net output #0: loss = 0.692947 (* 1 = 0.692947 loss)
I0701 16:52:13.155331  2788 sgd_solver.cpp:106] Iteration 17240, lr = 0.01
I0701 16:52:19.297009  2788 solver.cpp:340] Iteration 17250, Testing net (#0)
I0701 16:52:31.610687  2788 solver.cpp:408]     Test net output #0: accuracy = 0.503125
I0701 16:52:31.610748  2788 solver.cpp:408]     Test net output #1: loss = 0.693161 (* 1 = 0.693161 loss)
I0701 16:52:31.785846  2788 solver.cpp:236] Iteration 17250, loss = 0.693294
I0701 16:52:31.785913  2788 solver.cpp:252]     Train net output #0: loss = 0.693477 (* 1 = 0.693477 loss)
I0701 16:52:31.785951  2788 sgd_solver.cpp:106] Iteration 17250, lr = 0.01
I0701 16:52:38.589304  2788 solver.cpp:236] Iteration 17260, loss = 0.693355
I0701 16:52:38.589435  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 16:52:38.589452  2788 sgd_solver.cpp:106] Iteration 17260, lr = 0.01
I0701 16:52:45.398457  2788 solver.cpp:236] Iteration 17270, loss = 0.693142
I0701 16:52:45.398505  2788 solver.cpp:252]     Train net output #0: loss = 0.690692 (* 1 = 0.690692 loss)
I0701 16:52:45.398519  2788 sgd_solver.cpp:106] Iteration 17270, lr = 0.01
I0701 16:52:52.209260  2788 solver.cpp:236] Iteration 17280, loss = 0.693223
I0701 16:52:52.209318  2788 solver.cpp:252]     Train net output #0: loss = 0.692091 (* 1 = 0.692091 loss)
I0701 16:52:52.209333  2788 sgd_solver.cpp:106] Iteration 17280, lr = 0.01
I0701 16:52:59.020068  2788 solver.cpp:236] Iteration 17290, loss = 0.69322
I0701 16:52:59.020122  2788 solver.cpp:252]     Train net output #0: loss = 0.693151 (* 1 = 0.693151 loss)
I0701 16:52:59.020136  2788 sgd_solver.cpp:106] Iteration 17290, lr = 0.01
I0701 16:53:05.845774  2788 solver.cpp:236] Iteration 17300, loss = 0.693291
I0701 16:53:05.845831  2788 solver.cpp:252]     Train net output #0: loss = 0.694192 (* 1 = 0.694192 loss)
I0701 16:53:05.845845  2788 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0701 16:53:12.656456  2788 solver.cpp:236] Iteration 17310, loss = 0.693289
I0701 16:53:12.656689  2788 solver.cpp:252]     Train net output #0: loss = 0.694008 (* 1 = 0.694008 loss)
I0701 16:53:12.656708  2788 sgd_solver.cpp:106] Iteration 17310, lr = 0.01
I0701 16:53:19.456744  2788 solver.cpp:236] Iteration 17320, loss = 0.693406
I0701 16:53:19.456799  2788 solver.cpp:252]     Train net output #0: loss = 0.693316 (* 1 = 0.693316 loss)
I0701 16:53:19.456815  2788 sgd_solver.cpp:106] Iteration 17320, lr = 0.01
I0701 16:53:26.275094  2788 solver.cpp:236] Iteration 17330, loss = 0.693232
I0701 16:53:26.275152  2788 solver.cpp:252]     Train net output #0: loss = 0.692546 (* 1 = 0.692546 loss)
I0701 16:53:26.275166  2788 sgd_solver.cpp:106] Iteration 17330, lr = 0.01
I0701 16:53:33.088354  2788 solver.cpp:236] Iteration 17340, loss = 0.693345
I0701 16:53:33.088404  2788 solver.cpp:252]     Train net output #0: loss = 0.692664 (* 1 = 0.692664 loss)
I0701 16:53:33.088418  2788 sgd_solver.cpp:106] Iteration 17340, lr = 0.01
I0701 16:53:39.932304  2788 solver.cpp:236] Iteration 17350, loss = 0.69341
I0701 16:53:39.932363  2788 solver.cpp:252]     Train net output #0: loss = 0.692886 (* 1 = 0.692886 loss)
I0701 16:53:39.932376  2788 sgd_solver.cpp:106] Iteration 17350, lr = 0.01
I0701 16:53:46.743367  2788 solver.cpp:236] Iteration 17360, loss = 0.693378
I0701 16:53:46.743507  2788 solver.cpp:252]     Train net output #0: loss = 0.693057 (* 1 = 0.693057 loss)
I0701 16:53:46.743522  2788 sgd_solver.cpp:106] Iteration 17360, lr = 0.01
I0701 16:53:53.555577  2788 solver.cpp:236] Iteration 17370, loss = 0.693288
I0701 16:53:53.555644  2788 solver.cpp:252]     Train net output #0: loss = 0.693379 (* 1 = 0.693379 loss)
I0701 16:53:53.555660  2788 sgd_solver.cpp:106] Iteration 17370, lr = 0.01
I0701 16:54:00.373255  2788 solver.cpp:236] Iteration 17380, loss = 0.693063
I0701 16:54:00.373306  2788 solver.cpp:252]     Train net output #0: loss = 0.69079 (* 1 = 0.69079 loss)
I0701 16:54:00.373322  2788 sgd_solver.cpp:106] Iteration 17380, lr = 0.01
I0701 16:54:07.202996  2788 solver.cpp:236] Iteration 17390, loss = 0.693417
I0701 16:54:07.203059  2788 solver.cpp:252]     Train net output #0: loss = 0.692201 (* 1 = 0.692201 loss)
I0701 16:54:07.203074  2788 sgd_solver.cpp:106] Iteration 17390, lr = 0.01
I0701 16:54:14.028139  2788 solver.cpp:236] Iteration 17400, loss = 0.693324
I0701 16:54:14.028201  2788 solver.cpp:252]     Train net output #0: loss = 0.693671 (* 1 = 0.693671 loss)
I0701 16:54:14.028216  2788 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0701 16:54:20.847244  2788 solver.cpp:236] Iteration 17410, loss = 0.693305
I0701 16:54:20.847528  2788 solver.cpp:252]     Train net output #0: loss = 0.692463 (* 1 = 0.692463 loss)
I0701 16:54:20.847545  2788 sgd_solver.cpp:106] Iteration 17410, lr = 0.01
I0701 16:54:27.670512  2788 solver.cpp:236] Iteration 17420, loss = 0.693386
I0701 16:54:27.670565  2788 solver.cpp:252]     Train net output #0: loss = 0.693623 (* 1 = 0.693623 loss)
I0701 16:54:27.670579  2788 sgd_solver.cpp:106] Iteration 17420, lr = 0.01
I0701 16:54:34.488049  2788 solver.cpp:236] Iteration 17430, loss = 0.693733
I0701 16:54:34.488107  2788 solver.cpp:252]     Train net output #0: loss = 0.693089 (* 1 = 0.693089 loss)
I0701 16:54:34.488122  2788 sgd_solver.cpp:106] Iteration 17430, lr = 0.01
I0701 16:54:41.316308  2788 solver.cpp:236] Iteration 17440, loss = 0.693277
I0701 16:54:41.316364  2788 solver.cpp:252]     Train net output #0: loss = 0.693406 (* 1 = 0.693406 loss)
I0701 16:54:41.316378  2788 sgd_solver.cpp:106] Iteration 17440, lr = 0.01
I0701 16:54:48.151527  2788 solver.cpp:236] Iteration 17450, loss = 0.693272
I0701 16:54:48.151582  2788 solver.cpp:252]     Train net output #0: loss = 0.694008 (* 1 = 0.694008 loss)
I0701 16:54:48.151597  2788 sgd_solver.cpp:106] Iteration 17450, lr = 0.01
I0701 16:54:54.976917  2788 solver.cpp:236] Iteration 17460, loss = 0.693294
I0701 16:54:54.977133  2788 solver.cpp:252]     Train net output #0: loss = 0.691944 (* 1 = 0.691944 loss)
I0701 16:54:54.977157  2788 sgd_solver.cpp:106] Iteration 17460, lr = 0.01
I0701 16:55:01.804752  2788 solver.cpp:236] Iteration 17470, loss = 0.69331
I0701 16:55:01.804816  2788 solver.cpp:252]     Train net output #0: loss = 0.694171 (* 1 = 0.694171 loss)
I0701 16:55:01.804831  2788 sgd_solver.cpp:106] Iteration 17470, lr = 0.01
I0701 16:55:08.649210  2788 solver.cpp:236] Iteration 17480, loss = 0.69327
I0701 16:55:08.649261  2788 solver.cpp:252]     Train net output #0: loss = 0.693206 (* 1 = 0.693206 loss)
I0701 16:55:08.649276  2788 sgd_solver.cpp:106] Iteration 17480, lr = 0.01
I0701 16:55:15.471498  2788 solver.cpp:236] Iteration 17490, loss = 0.693197
I0701 16:55:15.471570  2788 solver.cpp:252]     Train net output #0: loss = 0.693052 (* 1 = 0.693052 loss)
I0701 16:55:15.471590  2788 sgd_solver.cpp:106] Iteration 17490, lr = 0.01
I0701 16:55:21.621953  2788 solver.cpp:340] Iteration 17500, Testing net (#0)
I0701 16:55:34.487906  2788 solver.cpp:408]     Test net output #0: accuracy = 0.499375
I0701 16:55:34.488070  2788 solver.cpp:408]     Test net output #1: loss = 0.694229 (* 1 = 0.694229 loss)
I0701 16:55:34.674306  2788 solver.cpp:236] Iteration 17500, loss = 0.692964
I0701 16:55:34.674381  2788 solver.cpp:252]     Train net output #0: loss = 0.694172 (* 1 = 0.694172 loss)
I0701 16:55:34.674401  2788 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0701 16:55:41.478534  2788 solver.cpp:236] Iteration 17510, loss = 0.693639
I0701 16:55:41.478592  2788 solver.cpp:252]     Train net output #0: loss = 0.697157 (* 1 = 0.697157 loss)
I0701 16:55:41.478606  2788 sgd_solver.cpp:106] Iteration 17510, lr = 0.01
I0701 16:55:48.276909  2788 solver.cpp:236] Iteration 17520, loss = 0.693644
I0701 16:55:48.276967  2788 solver.cpp:252]     Train net output #0: loss = 0.694965 (* 1 = 0.694965 loss)
I0701 16:55:48.276983  2788 sgd_solver.cpp:106] Iteration 17520, lr = 0.01
I0701 16:55:55.099452  2788 solver.cpp:236] Iteration 17530, loss = 0.693805
I0701 16:55:55.099509  2788 solver.cpp:252]     Train net output #0: loss = 0.695619 (* 1 = 0.695619 loss)
I0701 16:55:55.099529  2788 sgd_solver.cpp:106] Iteration 17530, lr = 0.01
I0701 16:56:01.915053  2788 solver.cpp:236] Iteration 17540, loss = 0.693662
I0701 16:56:01.915112  2788 solver.cpp:252]     Train net output #0: loss = 0.690538 (* 1 = 0.690538 loss)
I0701 16:56:01.915127  2788 sgd_solver.cpp:106] Iteration 17540, lr = 0.01
I0701 16:56:08.735870  2788 solver.cpp:236] Iteration 17550, loss = 0.694108
I0701 16:56:08.736088  2788 solver.cpp:252]     Train net output #0: loss = 0.694808 (* 1 = 0.694808 loss)
I0701 16:56:08.736104  2788 sgd_solver.cpp:106] Iteration 17550, lr = 0.01
I0701 16:56:15.559062  2788 solver.cpp:236] Iteration 17560, loss = 0.693443
I0701 16:56:15.559123  2788 solver.cpp:252]     Train net output #0: loss = 0.693287 (* 1 = 0.693287 loss)
I0701 16:56:15.559139  2788 sgd_solver.cpp:106] Iteration 17560, lr = 0.01
I0701 16:56:22.358921  2788 solver.cpp:236] Iteration 17570, loss = 0.693421
I0701 16:56:22.358979  2788 solver.cpp:252]     Train net output #0: loss = 0.693173 (* 1 = 0.693173 loss)
I0701 16:56:22.358994  2788 sgd_solver.cpp:106] Iteration 17570, lr = 0.01
I0701 16:56:29.189729  2788 solver.cpp:236] Iteration 17580, loss = 0.693232
I0701 16:56:29.189791  2788 solver.cpp:252]     Train net output #0: loss = 0.692378 (* 1 = 0.692378 loss)
I0701 16:56:29.189806  2788 sgd_solver.cpp:106] Iteration 17580, lr = 0.01
I0701 16:56:36.011528  2788 solver.cpp:236] Iteration 17590, loss = 0.69347
I0701 16:56:36.011590  2788 solver.cpp:252]     Train net output #0: loss = 0.692907 (* 1 = 0.692907 loss)
I0701 16:56:36.011603  2788 sgd_solver.cpp:106] Iteration 17590, lr = 0.01
I0701 16:56:42.845702  2788 solver.cpp:236] Iteration 17600, loss = 0.693345
I0701 16:56:42.848525  2788 solver.cpp:252]     Train net output #0: loss = 0.693923 (* 1 = 0.693923 loss)
I0701 16:56:42.848562  2788 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0701 16:56:49.674264  2788 solver.cpp:236] Iteration 17610, loss = 0.693325
I0701 16:56:49.674324  2788 solver.cpp:252]     Train net output #0: loss = 0.691875 (* 1 = 0.691875 loss)
I0701 16:56:49.674337  2788 sgd_solver.cpp:106] Iteration 17610, lr = 0.01
I0701 16:56:56.492977  2788 solver.cpp:236] Iteration 17620, loss = 0.693401
I0701 16:56:56.493027  2788 solver.cpp:252]     Train net output #0: loss = 0.693091 (* 1 = 0.693091 loss)
I0701 16:56:56.493042  2788 sgd_solver.cpp:106] Iteration 17620, lr = 0.01
I0701 16:57:03.341646  2788 solver.cpp:236] Iteration 17630, loss = 0.69355
I0701 16:57:03.341702  2788 solver.cpp:252]     Train net output #0: loss = 0.692639 (* 1 = 0.692639 loss)
I0701 16:57:03.341717  2788 sgd_solver.cpp:106] Iteration 17630, lr = 0.01
I0701 16:57:10.172987  2788 solver.cpp:236] Iteration 17640, loss = 0.693529
I0701 16:57:10.173045  2788 solver.cpp:252]     Train net output #0: loss = 0.694945 (* 1 = 0.694945 loss)
I0701 16:57:10.173059  2788 sgd_solver.cpp:106] Iteration 17640, lr = 0.01
I0701 16:57:16.999876  2788 solver.cpp:236] Iteration 17650, loss = 0.693555
I0701 16:57:17.000032  2788 solver.cpp:252]     Train net output #0: loss = 0.693143 (* 1 = 0.693143 loss)
I0701 16:57:17.000047  2788 sgd_solver.cpp:106] Iteration 17650, lr = 0.01
I0701 16:57:23.842859  2788 solver.cpp:236] Iteration 17660, loss = 0.693579
I0701 16:57:23.842937  2788 solver.cpp:252]     Train net output #0: loss = 0.693247 (* 1 = 0.693247 loss)
I0701 16:57:23.842960  2788 sgd_solver.cpp:106] Iteration 17660, lr = 0.01
I0701 16:57:30.667641  2788 solver.cpp:236] Iteration 17670, loss = 0.693477
I0701 16:57:30.667707  2788 solver.cpp:252]     Train net output #0: loss = 0.693735 (* 1 = 0.693735 loss)
I0701 16:57:30.667722  2788 sgd_solver.cpp:106] Iteration 17670, lr = 0.01
I0701 16:57:37.498864  2788 solver.cpp:236] Iteration 17680, loss = 0.693234
I0701 16:57:37.498924  2788 solver.cpp:252]     Train net output #0: loss = 0.689089 (* 1 = 0.689089 loss)
I0701 16:57:37.498939  2788 sgd_solver.cpp:106] Iteration 17680, lr = 0.01
I0701 16:57:44.325454  2788 solver.cpp:236] Iteration 17690, loss = 0.693504
I0701 16:57:44.325508  2788 solver.cpp:252]     Train net output #0: loss = 0.692906 (* 1 = 0.692906 loss)
I0701 16:57:44.325523  2788 sgd_solver.cpp:106] Iteration 17690, lr = 0.01
I0701 16:57:51.154291  2788 solver.cpp:236] Iteration 17700, loss = 0.693338
I0701 16:57:51.154500  2788 solver.cpp:252]     Train net output #0: loss = 0.694109 (* 1 = 0.694109 loss)
I0701 16:57:51.154518  2788 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0701 16:57:57.994796  2788 solver.cpp:236] Iteration 17710, loss = 0.693318
I0701 16:57:57.994868  2788 solver.cpp:252]     Train net output #0: loss = 0.693676 (* 1 = 0.693676 loss)
I0701 16:57:57.994882  2788 sgd_solver.cpp:106] Iteration 17710, lr = 0.01
I0701 16:58:04.836113  2788 solver.cpp:236] Iteration 17720, loss = 0.693258
I0701 16:58:04.836158  2788 solver.cpp:252]     Train net output #0: loss = 0.689945 (* 1 = 0.689945 loss)
I0701 16:58:04.836172  2788 sgd_solver.cpp:106] Iteration 17720, lr = 0.01
I0701 16:58:11.669590  2788 solver.cpp:236] Iteration 17730, loss = 0.693656
I0701 16:58:11.669654  2788 solver.cpp:252]     Train net output #0: loss = 0.693156 (* 1 = 0.693156 loss)
I0701 16:58:11.669668  2788 sgd_solver.cpp:106] Iteration 17730, lr = 0.01
I0701 16:58:18.489351  2788 solver.cpp:236] Iteration 17740, loss = 0.693239
I0701 16:58:18.489398  2788 solver.cpp:252]     Train net output #0: loss = 0.689248 (* 1 = 0.689248 loss)
I0701 16:58:18.489413  2788 sgd_solver.cpp:106] Iteration 17740, lr = 0.01
I0701 16:58:24.639194  2788 solver.cpp:340] Iteration 17750, Testing net (#0)
I0701 16:58:37.661279  2788 solver.cpp:408]     Test net output #0: accuracy = 0.4975
I0701 16:58:37.661347  2788 solver.cpp:408]     Test net output #1: loss = 0.693944 (* 1 = 0.693944 loss)
I0701 16:58:37.835811  2788 solver.cpp:236] Iteration 17750, loss = 0.693858
I0701 16:58:37.835886  2788 solver.cpp:252]     Train net output #0: loss = 0.695418 (* 1 = 0.695418 loss)
I0701 16:58:37.835907  2788 sgd_solver.cpp:106] Iteration 17750, lr = 0.01
I0701 16:58:44.631753  2788 solver.cpp:236] Iteration 17760, loss = 0.694156
I0701 16:58:44.631844  2788 solver.cpp:252]     Train net output #0: loss = 0.699224 (* 1 = 0.699224 loss)
I0701 16:58:44.631867  2788 sgd_solver.cpp:106] Iteration 17760, lr = 0.01
I0701 16:58:51.440372  2788 solver.cpp:236] Iteration 17770, loss = 0.694169
I0701 16:58:51.440441  2788 solver.cpp:252]     Train net output #0: loss = 0.686525 (* 1 = 0.686525 loss)
I0701 16:58:51.440457  2788 sgd_solver.cpp:106] Iteration 17770, lr = 0.01
I0701 16:58:58.259675  2788 solver.cpp:236] Iteration 17780, loss = 0.693993
I0701 16:58:58.259941  2788 solver.cpp:252]     Train net output #0: loss = 0.693166 (* 1 = 0.693166 loss)
I0701 16:58:58.259954  2788 sgd_solver.cpp:106] Iteration 17780, lr = 0.01
I0701 16:59:05.064023  2788 solver.cpp:236] Iteration 17790, loss = 0.694016
I0701 16:59:05.064098  2788 solver.cpp:252]     Train net output #0: loss = 0.692098 (* 1 = 0.692098 loss)
I0701 16:59:05.064113  2788 sgd_solver.cpp:106] Iteration 17790, lr = 0.01
I0701 16:59:11.884063  2788 solver.cpp:236] Iteration 17800, loss = 0.693489
I0701 16:59:11.884126  2788 solver.cpp:252]     Train net output #0: loss = 0.693081 (* 1 = 0.693081 loss)
I0701 16:59:11.884148  2788 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0701 16:59:18.718925  2788 solver.cpp:236] Iteration 17810, loss = 0.693226
I0701 16:59:18.718996  2788 solver.cpp:252]     Train net output #0: loss = 0.693375 (* 1 = 0.693375 loss)
I0701 16:59:18.719017  2788 sgd_solver.cpp:106] Iteration 17810, lr = 0.01
I0701 16:59:25.533629  2788 solver.cpp:236] Iteration 17820, loss = 0.693243
I0701 16:59:25.533689  2788 solver.cpp:252]     Train net output #0: loss = 0.692856 (* 1 = 0.692856 loss)
I0701 16:59:25.533704  2788 sgd_solver.cpp:106] Iteration 17820, lr = 0.01
I0701 16:59:32.350370  2788 solver.cpp:236] Iteration 17830, loss = 0.693194
I0701 16:59:32.350631  2788 solver.cpp:252]     Train net output #0: loss = 0.694635 (* 1 = 0.694635 loss)
I0701 16:59:32.350647  2788 sgd_solver.cpp:106] Iteration 17830, lr = 0.01
I0701 16:59:39.166158  2788 solver.cpp:236] Iteration 17840, loss = 0.693295
I0701 16:59:39.166236  2788 solver.cpp:252]     Train net output #0: loss = 0.693183 (* 1 = 0.693183 loss)
I0701 16:59:39.166251  2788 sgd_solver.cpp:106] Iteration 17840, lr = 0.01
I0701 16:59:45.977188  2788 solver.cpp:236] Iteration 17850, loss = 0.693211
I0701 16:59:45.977278  2788 solver.cpp:252]     Train net output #0: loss = 0.691538 (* 1 = 0.691538 loss)
I0701 16:59:45.977303  2788 sgd_solver.cpp:106] Iteration 17850, lr = 0.01
I0701 16:59:52.806474  2788 solver.cpp:236] Iteration 17860, loss = 0.693086
I0701 16:59:52.806526  2788 solver.cpp:252]     Train net output #0: loss = 0.696498 (* 1 = 0.696498 loss)
I0701 16:59:52.806540  2788 sgd_solver.cpp:106] Iteration 17860, lr = 0.01
I0701 16:59:59.619509  2788 solver.cpp:236] Iteration 17870, loss = 0.693104
I0701 16:59:59.619573  2788 solver.cpp:252]     Train net output #0: loss = 0.693272 (* 1 = 0.693272 loss)
I0701 16:59:59.619588  2788 sgd_solver.cpp:106] Iteration 17870, lr = 0.01
I0701 17:00:06.438994  2788 solver.cpp:236] Iteration 17880, loss = 0.693143
I0701 17:00:06.439218  2788 solver.cpp:252]     Train net output #0: loss = 0.691766 (* 1 = 0.691766 loss)
I0701 17:00:06.439234  2788 sgd_solver.cpp:106] Iteration 17880, lr = 0.01
I0701 17:00:13.242317  2788 solver.cpp:236] Iteration 17890, loss = 0.693198
I0701 17:00:13.242384  2788 solver.cpp:252]     Train net output #0: loss = 0.693036 (* 1 = 0.693036 loss)
I0701 17:00:13.242399  2788 sgd_solver.cpp:106] Iteration 17890, lr = 0.01
I0701 17:00:20.059887  2788 solver.cpp:236] Iteration 17900, loss = 0.692982
I0701 17:00:20.059937  2788 solver.cpp:252]     Train net output #0: loss = 0.694082 (* 1 = 0.694082 loss)
I0701 17:00:20.059952  2788 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0701 17:00:26.886450  2788 solver.cpp:236] Iteration 17910, loss = 0.692983
I0701 17:00:26.886512  2788 solver.cpp:252]     Train net output #0: loss = 0.693603 (* 1 = 0.693603 loss)
I0701 17:00:26.886526  2788 sgd_solver.cpp:106] Iteration 17910, lr = 0.01
I0701 17:00:33.715190  2788 solver.cpp:236] Iteration 17920, loss = 0.693606
I0701 17:00:33.715240  2788 solver.cpp:252]     Train net output #0: loss = 0.698214 (* 1 = 0.698214 loss)
I0701 17:00:33.715253  2788 sgd_solver.cpp:106] Iteration 17920, lr = 0.01
I0701 17:00:40.539257  2788 solver.cpp:236] Iteration 17930, loss = 0.693787
I0701 17:00:40.539444  2788 solver.cpp:252]     Train net output #0: loss = 0.694929 (* 1 = 0.694929 loss)
I0701 17:00:40.539463  2788 sgd_solver.cpp:106] Iteration 17930, lr = 0.01
I0701 17:00:47.357707  2788 solver.cpp:236] Iteration 17940, loss = 0.693734
I0701 17:00:47.357772  2788 solver.cpp:252]     Train net output #0: loss = 0.697685 (* 1 = 0.697685 loss)
I0701 17:00:47.357785  2788 sgd_solver.cpp:106] Iteration 17940, lr = 0.01
I0701 17:00:54.179883  2788 solver.cpp:236] Iteration 17950, loss = 0.694024
I0701 17:00:54.179934  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 17:00:54.179950  2788 sgd_solver.cpp:106] Iteration 17950, lr = 0.01
I0701 17:01:01.006037  2788 solver.cpp:236] Iteration 17960, loss = 0.69411
I0701 17:01:01.006108  2788 solver.cpp:252]     Train net output #0: loss = 0.693222 (* 1 = 0.693222 loss)
I0701 17:01:01.006122  2788 sgd_solver.cpp:106] Iteration 17960, lr = 0.01
I0701 17:01:07.801455  2788 solver.cpp:236] Iteration 17970, loss = 0.693528
I0701 17:01:07.801520  2788 solver.cpp:252]     Train net output #0: loss = 0.693374 (* 1 = 0.693374 loss)
I0701 17:01:07.801539  2788 sgd_solver.cpp:106] Iteration 17970, lr = 0.01
I0701 17:01:14.631819  2788 solver.cpp:236] Iteration 17980, loss = 0.693269
I0701 17:01:14.631952  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 17:01:14.631973  2788 sgd_solver.cpp:106] Iteration 17980, lr = 0.01
I0701 17:01:21.454890  2788 solver.cpp:236] Iteration 17990, loss = 0.693257
I0701 17:01:21.454952  2788 solver.cpp:252]     Train net output #0: loss = 0.693432 (* 1 = 0.693432 loss)
I0701 17:01:21.454967  2788 sgd_solver.cpp:106] Iteration 17990, lr = 0.01
I0701 17:01:27.608985  2788 solver.cpp:340] Iteration 18000, Testing net (#0)
I0701 17:01:40.282320  2788 solver.cpp:408]     Test net output #0: accuracy = 0.514375
I0701 17:01:40.282397  2788 solver.cpp:408]     Test net output #1: loss = 0.692824 (* 1 = 0.692824 loss)
I0701 17:01:40.472599  2788 solver.cpp:236] Iteration 18000, loss = 0.693251
I0701 17:01:40.472667  2788 solver.cpp:252]     Train net output #0: loss = 0.693743 (* 1 = 0.693743 loss)
I0701 17:01:40.472692  2788 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0701 17:01:47.262557  2788 solver.cpp:236] Iteration 18010, loss = 0.69335
I0701 17:01:47.268496  2788 solver.cpp:252]     Train net output #0: loss = 0.701752 (* 1 = 0.701752 loss)
I0701 17:01:47.268513  2788 sgd_solver.cpp:106] Iteration 18010, lr = 0.01
I0701 17:01:54.065261  2788 solver.cpp:236] Iteration 18020, loss = 0.693549
I0701 17:01:54.065320  2788 solver.cpp:252]     Train net output #0: loss = 0.699164 (* 1 = 0.699164 loss)
I0701 17:01:54.065335  2788 sgd_solver.cpp:106] Iteration 18020, lr = 0.01
I0701 17:02:00.870841  2788 solver.cpp:236] Iteration 18030, loss = 0.693644
I0701 17:02:00.870898  2788 solver.cpp:252]     Train net output #0: loss = 0.688146 (* 1 = 0.688146 loss)
I0701 17:02:00.870916  2788 sgd_solver.cpp:106] Iteration 18030, lr = 0.01
I0701 17:02:07.668656  2788 solver.cpp:236] Iteration 18040, loss = 0.693508
I0701 17:02:07.668707  2788 solver.cpp:252]     Train net output #0: loss = 0.689983 (* 1 = 0.689983 loss)
I0701 17:02:07.668727  2788 sgd_solver.cpp:106] Iteration 18040, lr = 0.01
I0701 17:02:14.466215  2788 solver.cpp:236] Iteration 18050, loss = 0.693585
I0701 17:02:14.466272  2788 solver.cpp:252]     Train net output #0: loss = 0.693174 (* 1 = 0.693174 loss)
I0701 17:02:14.466292  2788 sgd_solver.cpp:106] Iteration 18050, lr = 0.01
I0701 17:02:21.276840  2788 solver.cpp:236] Iteration 18060, loss = 0.693482
I0701 17:02:21.277055  2788 solver.cpp:252]     Train net output #0: loss = 0.692931 (* 1 = 0.692931 loss)
I0701 17:02:21.277073  2788 sgd_solver.cpp:106] Iteration 18060, lr = 0.01
I0701 17:02:28.097090  2788 solver.cpp:236] Iteration 18070, loss = 0.693302
I0701 17:02:28.097141  2788 solver.cpp:252]     Train net output #0: loss = 0.693128 (* 1 = 0.693128 loss)
I0701 17:02:28.097154  2788 sgd_solver.cpp:106] Iteration 18070, lr = 0.01
I0701 17:02:34.906473  2788 solver.cpp:236] Iteration 18080, loss = 0.693186
I0701 17:02:34.906538  2788 solver.cpp:252]     Train net output #0: loss = 0.693187 (* 1 = 0.693187 loss)
I0701 17:02:34.906556  2788 sgd_solver.cpp:106] Iteration 18080, lr = 0.01
I0701 17:02:41.731709  2788 solver.cpp:236] Iteration 18090, loss = 0.693296
I0701 17:02:41.731772  2788 solver.cpp:252]     Train net output #0: loss = 0.692829 (* 1 = 0.692829 loss)
I0701 17:02:41.731786  2788 sgd_solver.cpp:106] Iteration 18090, lr = 0.01
I0701 17:02:48.555362  2788 solver.cpp:236] Iteration 18100, loss = 0.693294
I0701 17:02:48.555434  2788 solver.cpp:252]     Train net output #0: loss = 0.693129 (* 1 = 0.693129 loss)
I0701 17:02:48.555449  2788 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0701 17:02:55.355866  2788 solver.cpp:236] Iteration 18110, loss = 0.693348
I0701 17:02:55.356043  2788 solver.cpp:252]     Train net output #0: loss = 0.693962 (* 1 = 0.693962 loss)
I0701 17:02:55.356060  2788 sgd_solver.cpp:106] Iteration 18110, lr = 0.01
I0701 17:03:02.176970  2788 solver.cpp:236] Iteration 18120, loss = 0.693338
I0701 17:03:02.177044  2788 solver.cpp:252]     Train net output #0: loss = 0.696588 (* 1 = 0.696588 loss)
I0701 17:03:02.177059  2788 sgd_solver.cpp:106] Iteration 18120, lr = 0.01
I0701 17:03:09.004040  2788 solver.cpp:236] Iteration 18130, loss = 0.693351
I0701 17:03:09.004115  2788 solver.cpp:252]     Train net output #0: loss = 0.692786 (* 1 = 0.692786 loss)
I0701 17:03:09.004132  2788 sgd_solver.cpp:106] Iteration 18130, lr = 0.01
I0701 17:03:15.827869  2788 solver.cpp:236] Iteration 18140, loss = 0.693456
I0701 17:03:15.827934  2788 solver.cpp:252]     Train net output #0: loss = 0.698288 (* 1 = 0.698288 loss)
I0701 17:03:15.827949  2788 sgd_solver.cpp:106] Iteration 18140, lr = 0.01
I0701 17:03:22.644455  2788 solver.cpp:236] Iteration 18150, loss = 0.693241
I0701 17:03:22.644542  2788 solver.cpp:252]     Train net output #0: loss = 0.695364 (* 1 = 0.695364 loss)
I0701 17:03:22.644563  2788 sgd_solver.cpp:106] Iteration 18150, lr = 0.01
I0701 17:03:29.444026  2788 solver.cpp:236] Iteration 18160, loss = 0.69297
I0701 17:03:29.444283  2788 solver.cpp:252]     Train net output #0: loss = 0.689876 (* 1 = 0.689876 loss)
I0701 17:03:29.444300  2788 sgd_solver.cpp:106] Iteration 18160, lr = 0.01
I0701 17:03:36.262835  2788 solver.cpp:236] Iteration 18170, loss = 0.693127
I0701 17:03:36.262892  2788 solver.cpp:252]     Train net output #0: loss = 0.693992 (* 1 = 0.693992 loss)
I0701 17:03:36.262907  2788 sgd_solver.cpp:106] Iteration 18170, lr = 0.01
I0701 17:03:43.062862  2788 solver.cpp:236] Iteration 18180, loss = 0.693118
I0701 17:03:43.062938  2788 solver.cpp:252]     Train net output #0: loss = 0.692991 (* 1 = 0.692991 loss)
I0701 17:03:43.062959  2788 sgd_solver.cpp:106] Iteration 18180, lr = 0.01
I0701 17:03:49.878728  2788 solver.cpp:236] Iteration 18190, loss = 0.693075
I0701 17:03:49.878805  2788 solver.cpp:252]     Train net output #0: loss = 0.693816 (* 1 = 0.693816 loss)
I0701 17:03:49.878825  2788 sgd_solver.cpp:106] Iteration 18190, lr = 0.01
I0701 17:03:56.689913  2788 solver.cpp:236] Iteration 18200, loss = 0.69315
I0701 17:03:56.689993  2788 solver.cpp:252]     Train net output #0: loss = 0.69421 (* 1 = 0.69421 loss)
I0701 17:03:56.690028  2788 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0701 17:04:03.500404  2788 solver.cpp:236] Iteration 18210, loss = 0.693411
I0701 17:04:03.500672  2788 solver.cpp:252]     Train net output #0: loss = 0.69304 (* 1 = 0.69304 loss)
I0701 17:04:03.500692  2788 sgd_solver.cpp:106] Iteration 18210, lr = 0.01
I0701 17:04:10.321329  2788 solver.cpp:236] Iteration 18220, loss = 0.693322
I0701 17:04:10.321398  2788 solver.cpp:252]     Train net output #0: loss = 0.696394 (* 1 = 0.696394 loss)
I0701 17:04:10.321413  2788 sgd_solver.cpp:106] Iteration 18220, lr = 0.01
I0701 17:04:17.131438  2788 solver.cpp:236] Iteration 18230, loss = 0.693319
I0701 17:04:17.131505  2788 solver.cpp:252]     Train net output #0: loss = 0.693959 (* 1 = 0.693959 loss)
I0701 17:04:17.131520  2788 sgd_solver.cpp:106] Iteration 18230, lr = 0.01
I0701 17:04:23.929111  2788 solver.cpp:236] Iteration 18240, loss = 0.693315
I0701 17:04:23.929199  2788 solver.cpp:252]     Train net output #0: loss = 0.693141 (* 1 = 0.693141 loss)
I0701 17:04:23.929215  2788 sgd_solver.cpp:106] Iteration 18240, lr = 0.01
I0701 17:04:30.057891  2788 solver.cpp:340] Iteration 18250, Testing net (#0)
I0701 17:04:42.551931  2788 solver.cpp:408]     Test net output #0: accuracy = 0.5
I0701 17:04:42.552168  2788 solver.cpp:408]     Test net output #1: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 17:04:42.735947  2788 solver.cpp:236] Iteration 18250, loss = 0.693325
I0701 17:04:42.735997  2788 solver.cpp:252]     Train net output #0: loss = 0.69322 (* 1 = 0.69322 loss)
I0701 17:04:42.736013  2788 sgd_solver.cpp:106] Iteration 18250, lr = 0.01
I0701 17:04:49.492890  2788 solver.cpp:236] Iteration 18260, loss = 0.693304
I0701 17:04:49.492944  2788 solver.cpp:252]     Train net output #0: loss = 0.6933 (* 1 = 0.6933 loss)
I0701 17:04:49.492964  2788 sgd_solver.cpp:106] Iteration 18260, lr = 0.01
I0701 17:04:56.279906  2788 solver.cpp:236] Iteration 18270, loss = 0.693219
I0701 17:04:56.279949  2788 solver.cpp:252]     Train net output #0: loss = 0.692008 (* 1 = 0.692008 loss)
I0701 17:04:56.279969  2788 sgd_solver.cpp:106] Iteration 18270, lr = 0.01
I0701 17:05:03.053117  2788 solver.cpp:236] Iteration 18280, loss = 0.693142
I0701 17:05:03.053169  2788 solver.cpp:252]     Train net output #0: loss = 0.694699 (* 1 = 0.694699 loss)
I0701 17:05:03.053184  2788 sgd_solver.cpp:106] Iteration 18280, lr = 0.01
I0701 17:05:09.846416  2788 solver.cpp:236] Iteration 18290, loss = 0.69337
I0701 17:05:09.846487  2788 solver.cpp:252]     Train net output #0: loss = 0.69636 (* 1 = 0.69636 loss)
I0701 17:05:09.846505  2788 sgd_solver.cpp:106] Iteration 18290, lr = 0.01
I0701 17:05:16.643697  2788 solver.cpp:236] Iteration 18300, loss = 0.693363
I0701 17:05:16.643949  2788 solver.cpp:252]     Train net output #0: loss = 0.697479 (* 1 = 0.697479 loss)
I0701 17:05:16.643965  2788 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0701 17:05:23.424418  2788 solver.cpp:236] Iteration 18310, loss = 0.693634
I0701 17:05:23.424484  2788 solver.cpp:252]     Train net output #0: loss = 0.696934 (* 1 = 0.696934 loss)
I0701 17:05:23.424497  2788 sgd_solver.cpp:106] Iteration 18310, lr = 0.01
I0701 17:05:30.222177  2788 solver.cpp:236] Iteration 18320, loss = 0.693693
I0701 17:05:30.222236  2788 solver.cpp:252]     Train net output #0: loss = 0.693664 (* 1 = 0.693664 loss)
I0701 17:05:30.222254  2788 sgd_solver.cpp:106] Iteration 18320, lr = 0.01
I0701 17:05:37.012065  2788 solver.cpp:236] Iteration 18330, loss = 0.69378
I0701 17:05:37.012135  2788 solver.cpp:252]     Train net output #0: loss = 0.69483 (* 1 = 0.69483 loss)
I0701 17:05:37.012151  2788 sgd_solver.cpp:106] Iteration 18330, lr = 0.01
I0701 17:05:43.809432  2788 solver.cpp:236] Iteration 18340, loss = 0.693487
I0701 17:05:43.809499  2788 solver.cpp:252]     Train net output #0: loss = 0.692445 (* 1 = 0.692445 loss)
I0701 17:05:43.809514  2788 sgd_solver.cpp:106] Iteration 18340, lr = 0.01
I0701 17:05:50.600661  2788 solver.cpp:236] Iteration 18350, loss = 0.693372
I0701 17:05:50.600987  2788 solver.cpp:252]     Train net output #0: loss = 0.695354 (* 1 = 0.695354 loss)
I0701 17:05:50.601022  2788 sgd_solver.cpp:106] Iteration 18350, lr = 0.01
I0701 17:05:57.380280  2788 solver.cpp:236] Iteration 18360, loss = 0.693328
I0701 17:05:57.380329  2788 solver.cpp:252]     Train net output #0: loss = 0.696063 (* 1 = 0.696063 loss)
I0701 17:05:57.380344  2788 sgd_solver.cpp:106] Iteration 18360, lr = 0.01
I0701 17:06:04.203469  2788 solver.cpp:236] Iteration 18370, loss = 0.693268
I0701 17:06:04.203521  2788 solver.cpp:252]     Train net output #0: loss = 0.693071 (* 1 = 0.693071 loss)
I0701 17:06:04.203534  2788 sgd_solver.cpp:106] Iteration 18370, lr = 0.01
I0701 17:06:10.978138  2788 solver.cpp:236] Iteration 18380, loss = 0.693202
I0701 17:06:10.978201  2788 solver.cpp:252]     Train net output #0: loss = 0.692676 (* 1 = 0.692676 loss)
I0701 17:06:10.978216  2788 sgd_solver.cpp:106] Iteration 18380, lr = 0.01
I0701 17:06:17.775185  2788 solver.cpp:236] Iteration 18390, loss = 0.6934
I0701 17:06:17.775240  2788 solver.cpp:252]     Train net output #0: loss = 0.693526 (* 1 = 0.693526 loss)
I0701 17:06:17.775254  2788 sgd_solver.cpp:106] Iteration 18390, lr = 0.01
I0701 17:06:17.775843  2788 blocking_queue.cpp:50] Data layer prefetch queue empty
I0701 17:06:24.585400  2788 solver.cpp:236] Iteration 18400, loss = 0.693505
I0701 17:06:24.588487  2788 solver.cpp:252]     Train net output #0: loss = 0.694409 (* 1 = 0.694409 loss)
I0701 17:06:24.588511  2788 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0701 17:06:31.392803  2788 solver.cpp:236] Iteration 18410, loss = 0.69339
I0701 17:06:31.392896  2788 solver.cpp:252]     Train net output #0: loss = 0.696395 (* 1 = 0.696395 loss)
I0701 17:06:31.392921  2788 sgd_solver.cpp:106] Iteration 18410, lr = 0.01
I0701 17:06:38.199878  2788 solver.cpp:236] Iteration 18420, loss = 0.69361
I0701 17:06:38.199952  2788 solver.cpp:252]     Train net output #0: loss = 0.693516 (* 1 = 0.693516 loss)
I0701 17:06:38.199970  2788 sgd_solver.cpp:106] Iteration 18420, lr = 0.01
I0701 17:06:45.007457  2788 solver.cpp:236] Iteration 18430, loss = 0.693639
I0701 17:06:45.007524  2788 solver.cpp:252]     Train net output #0: loss = 0.694627 (* 1 = 0.694627 loss)
I0701 17:06:45.007539  2788 sgd_solver.cpp:106] Iteration 18430, lr = 0.01
I0701 17:06:51.821100  2788 solver.cpp:236] Iteration 18440, loss = 0.69346
I0701 17:06:51.821153  2788 solver.cpp:252]     Train net output #0: loss = 0.693203 (* 1 = 0.693203 loss)
I0701 17:06:51.821169  2788 sgd_solver.cpp:106] Iteration 18440, lr = 0.01
I0701 17:06:58.619316  2788 solver.cpp:236] Iteration 18450, loss = 0.693612
I0701 17:06:58.619539  2788 solver.cpp:252]     Train net output #0: loss = 0.693131 (* 1 = 0.693131 loss)
I0701 17:06:58.619554  2788 sgd_solver.cpp:106] Iteration 18450, lr = 0.01
I0701 17:07:05.418372  2788 solver.cpp:236] Iteration 18460, loss = 0.693459
I0701 17:07:05.418440  2788 solver.cpp:252]     Train net output #0: loss = 0.694468 (* 1 = 0.694468 loss)
I0701 17:07:05.418457  2788 sgd_solver.cpp:106] Iteration 18460, lr = 0.01
I0701 17:07:12.227529  2788 solver.cpp:236] Iteration 18470, loss = 0.693464
I0701 17:07:12.227569  2788 solver.cpp:252]     Train net output #0: loss = 0.691241 (* 1 = 0.691241 loss)
I0701 17:07:12.227579  2788 sgd_solver.cpp:106] Iteration 18470, lr = 0.01
I0701 17:07:19.018936  2788 solver.cpp:236] Iteration 18480, loss = 0.693545
I0701 17:07:19.018998  2788 solver.cpp:252]     Train net output #0: loss = 0.693741 (* 1 = 0.693741 loss)
I0701 17:07:19.019013  2788 sgd_solver.cpp:106] Iteration 18480, lr = 0.01
I0701 17:07:25.819514  2788 solver.cpp:236] Iteration 18490, loss = 0.693577
I0701 17:07:25.819563  2788 solver.cpp:252]     Train net output #0: loss = 0.693035 (* 1 = 0.693035 loss)
I0701 17:07:25.819578  2788 sgd_solver.cpp:106] Iteration 18490, lr = 0.01
I0701 17:07:31.948673  2788 solver.cpp:340] Iteration 18500, Testing net (#0)
I0701 17:07:44.025200  2788 solver.cpp:408]     Test net output #0: accuracy = 0.487188
I0701 17:07:44.025256  2788 solver.cpp:408]     Test net output #1: loss = 0.695019 (* 1 = 0.695019 loss)
I0701 17:07:44.206138  2788 solver.cpp:236] Iteration 18500, loss = 0.693488
I0701 17:07:44.206190  2788 solver.cpp:252]     Train net output #0: loss = 0.698428 (* 1 = 0.698428 loss)
I0701 17:07:44.206204  2788 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0701 17:07:51.004484  2788 solver.cpp:236] Iteration 18510, loss = 0.693801
I0701 17:07:51.004544  2788 solver.cpp:252]     Train net output #0: loss = 0.693094 (* 1 = 0.693094 loss)
I0701 17:07:51.004556  2788 sgd_solver.cpp:106] Iteration 18510, lr = 0.01
I0701 17:07:57.794162  2788 solver.cpp:236] Iteration 18520, loss = 0.693453
I0701 17:07:57.794214  2788 solver.cpp:252]     Train net output #0: loss = 0.690689 (* 1 = 0.690689 loss)
I0701 17:07:57.794231  2788 sgd_solver.cpp:106] Iteration 18520, lr = 0.01
I0701 17:08:04.588843  2788 solver.cpp:236] Iteration 18530, loss = 0.693688
I0701 17:08:04.589099  2788 solver.cpp:252]     Train net output #0: loss = 0.69146 (* 1 = 0.69146 loss)
I0701 17:08:04.589125  2788 sgd_solver.cpp:106] Iteration 18530, lr = 0.01
I0701 17:08:11.381743  2788 solver.cpp:236] Iteration 18540, loss = 0.693814
I0701 17:08:11.381790  2788 solver.cpp:252]     Train net output #0: loss = 0.694986 (* 1 = 0.694986 loss)
I0701 17:08:11.381800  2788 sgd_solver.cpp:106] Iteration 18540, lr = 0.01
I0701 17:08:18.173635  2788 solver.cpp:236] Iteration 18550, loss = 0.693781
I0701 17:08:18.173697  2788 solver.cpp:252]     Train net output #0: loss = 0.693247 (* 1 = 0.693247 loss)
I0701 17:08:18.173712  2788 sgd_solver.cpp:106] Iteration 18550, lr = 0.01
I0701 17:08:24.976639  2788 solver.cpp:236] Iteration 18560, loss = 0.693496
I0701 17:08:24.976697  2788 solver.cpp:252]     Train net output #0: loss = 0.693138 (* 1 = 0.693138 loss)
I0701 17:08:24.976711  2788 sgd_solver.cpp:106] Iteration 18560, lr = 0.01
I0701 17:08:31.772188  2788 solver.cpp:236] Iteration 18570, loss = 0.693607
I0701 17:08:31.772256  2788 solver.cpp:252]     Train net output #0: loss = 0.693354 (* 1 = 0.693354 loss)
I0701 17:08:31.772271  2788 sgd_solver.cpp:106] Iteration 18570, lr = 0.01
I0701 17:08:38.571559  2788 solver.cpp:236] Iteration 18580, loss = 0.693338
I0701 17:08:38.571866  2788 solver.cpp:252]     Train net output #0: loss = 0.693148 (* 1 = 0.693148 loss)
I0701 17:08:38.571888  2788 sgd_solver.cpp:106] Iteration 18580, lr = 0.01
I0701 17:08:45.381114  2788 solver.cpp:236] Iteration 18590, loss = 0.693161
I0701 17:08:45.381166  2788 solver.cpp:252]     Train net output #0: loss = 0.694486 (* 1 = 0.694486 loss)
I0701 17:08:45.381181  2788 sgd_solver.cpp:106] Iteration 18590, lr = 0.01
I0701 17:08:52.163475  2788 solver.cpp:236] Iteration 18600, loss = 0.69327
I0701 17:08:52.163522  2788 solver.cpp:252]     Train net output #0: loss = 0.698777 (* 1 = 0.698777 loss)
I0701 17:08:52.163535  2788 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0701 17:08:58.959517  2788 solver.cpp:236] Iteration 18610, loss = 0.693128
I0701 17:08:58.959568  2788 solver.cpp:252]     Train net output #0: loss = 0.692295 (* 1 = 0.692295 loss)
I0701 17:08:58.959583  2788 sgd_solver.cpp:106] Iteration 18610, lr = 0.01
I0701 17:09:05.745766  2788 solver.cpp:236] Iteration 18620, loss = 0.693163
I0701 17:09:05.745828  2788 solver.cpp:252]     Train net output #0: loss = 0.693992 (* 1 = 0.693992 loss)
I0701 17:09:05.745844  2788 sgd_solver.cpp:106] Iteration 18620, lr = 0.01
I0701 17:09:12.559387  2788 solver.cpp:236] Iteration 18630, loss = 0.693107
I0701 17:09:12.559612  2788 solver.cpp:252]     Train net output #0: loss = 0.693869 (* 1 = 0.693869 loss)
I0701 17:09:12.559633  2788 sgd_solver.cpp:106] Iteration 18630, lr = 0.01
I0701 17:09:19.351238  2788 solver.cpp:236] Iteration 18640, loss = 0.69318
I0701 17:09:19.351294  2788 solver.cpp:252]     Train net output #0: loss = 0.692831 (* 1 = 0.692831 loss)
I0701 17:09:19.351315  2788 sgd_solver.cpp:106] Iteration 18640, lr = 0.01
I0701 17:09:26.159519  2788 solver.cpp:236] Iteration 18650, loss = 0.693073
I0701 17:09:26.159569  2788 solver.cpp:252]     Train net output #0: loss = 0.69432 (* 1 = 0.69432 loss)
I0701 17:09:26.159584  2788 sgd_solver.cpp:106] Iteration 18650, lr = 0.01
I0701 17:09:32.964192  2788 solver.cpp:236] Iteration 18660, loss = 0.693203
I0701 17:09:32.964282  2788 solver.cpp:252]     Train net output #0: loss = 0.692863 (* 1 = 0.692863 loss)
I0701 17:09:32.964299  2788 sgd_solver.cpp:106] Iteration 18660, lr = 0.01
I0701 17:09:39.751174  2788 solver.cpp:236] Iteration 18670, loss = 0.693362
I0701 17:09:39.751248  2788 solver.cpp:252]     Train net output #0: loss = 0.693759 (* 1 = 0.693759 loss)
I0701 17:09:39.751267  2788 sgd_solver.cpp:106] Iteration 18670, lr = 0.01
I0701 17:09:46.562057  2788 solver.cpp:236] Iteration 18680, loss = 0.693399
I0701 17:09:46.562242  2788 solver.cpp:252]     Train net output #0: loss = 0.693739 (* 1 = 0.693739 loss)
I0701 17:09:46.562258  2788 sgd_solver.cpp:106] Iteration 18680, lr = 0.01
I0701 17:09:53.369771  2788 solver.cpp:236] Iteration 18690, loss = 0.693369
I0701 17:09:53.369871  2788 solver.cpp:252]     Train net output #0: loss = 0.694242 (* 1 = 0.694242 loss)
I0701 17:09:53.369887  2788 sgd_solver.cpp:106] Iteration 18690, lr = 0.01
I0701 17:10:00.182212  2788 solver.cpp:236] Iteration 18700, loss = 0.693329
I0701 17:10:00.182277  2788 solver.cpp:252]     Train net output #0: loss = 0.693025 (* 1 = 0.693025 loss)
I0701 17:10:00.182292  2788 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0701 17:10:06.987615  2788 solver.cpp:236] Iteration 18710, loss = 0.693305
I0701 17:10:06.987676  2788 solver.cpp:252]     Train net output #0: loss = 0.694231 (* 1 = 0.694231 loss)
I0701 17:10:06.987690  2788 sgd_solver.cpp:106] Iteration 18710, lr = 0.01
I0701 17:10:13.800040  2788 solver.cpp:236] Iteration 18720, loss = 0.693227
I0701 17:10:13.800092  2788 solver.cpp:252]     Train net output #0: loss = 0.693454 (* 1 = 0.693454 loss)
I0701 17:10:13.800107  2788 sgd_solver.cpp:106] Iteration 18720, lr = 0.01
I0701 17:10:20.610577  2788 solver.cpp:236] Iteration 18730, loss = 0.693187
I0701 17:10:20.616469  2788 solver.cpp:252]     Train net output #0: loss = 0.692798 (* 1 = 0.692798 loss)
I0701 17:10:20.616485  2788 sgd_solver.cpp:106] Iteration 18730, lr = 0.01
I0701 17:10:27.409312  2788 solver.cpp:236] Iteration 18740, loss = 0.693307
I0701 17:10:27.409361  2788 solver.cpp:252]     Train net output #0: loss = 0.694929 (* 1 = 0.694929 loss)
I0701 17:10:27.409378  2788 sgd_solver.cpp:106] Iteration 18740, lr = 0.01
I0701 17:10:33.534345  2788 solver.cpp:340] Iteration 18750, Testing net (#0)
I0701 17:10:45.186661  2788 solver.cpp:408]     Test net output #0: accuracy = 0.493437
I0701 17:10:45.186722  2788 solver.cpp:408]     Test net output #1: loss = 0.693284 (* 1 = 0.693284 loss)
I0701 17:10:45.362859  2788 solver.cpp:236] Iteration 18750, loss = 0.693372
I0701 17:10:45.362916  2788 solver.cpp:252]     Train net output #0: loss = 0.693553 (* 1 = 0.693553 loss)
I0701 17:10:45.362936  2788 sgd_solver.cpp:106] Iteration 18750, lr = 0.01
I0701 17:10:52.148134  2788 solver.cpp:236] Iteration 18760, loss = 0.693417
I0701 17:10:52.148299  2788 solver.cpp:252]     Train net output #0: loss = 0.694628 (* 1 = 0.694628 loss)
I0701 17:10:52.148314  2788 sgd_solver.cpp:106] Iteration 18760, lr = 0.01
I0701 17:10:58.957758  2788 solver.cpp:236] Iteration 18770, loss = 0.693336
I0701 17:10:58.957815  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 17:10:58.957831  2788 sgd_solver.cpp:106] Iteration 18770, lr = 0.01
I0701 17:11:05.758833  2788 solver.cpp:236] Iteration 18780, loss = 0.693386
I0701 17:11:05.758885  2788 solver.cpp:252]     Train net output #0: loss = 0.693134 (* 1 = 0.693134 loss)
I0701 17:11:05.758900  2788 sgd_solver.cpp:106] Iteration 18780, lr = 0.01
I0701 17:11:12.551611  2788 solver.cpp:236] Iteration 18790, loss = 0.693286
I0701 17:11:12.551686  2788 solver.cpp:252]     Train net output #0: loss = 0.693161 (* 1 = 0.693161 loss)
I0701 17:11:12.551728  2788 sgd_solver.cpp:106] Iteration 18790, lr = 0.01
I0701 17:11:19.359756  2788 solver.cpp:236] Iteration 18800, loss = 0.693165
I0701 17:11:19.359824  2788 solver.cpp:252]     Train net output #0: loss = 0.691109 (* 1 = 0.691109 loss)
I0701 17:11:19.359840  2788 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0701 17:11:26.163374  2788 solver.cpp:236] Iteration 18810, loss = 0.693405
I0701 17:11:26.163600  2788 solver.cpp:252]     Train net output #0: loss = 0.693466 (* 1 = 0.693466 loss)
I0701 17:11:26.163628  2788 sgd_solver.cpp:106] Iteration 18810, lr = 0.01
I0701 17:11:32.976011  2788 solver.cpp:236] Iteration 18820, loss = 0.693367
I0701 17:11:32.976059  2788 solver.cpp:252]     Train net output #0: loss = 0.69408 (* 1 = 0.69408 loss)
I0701 17:11:32.976079  2788 sgd_solver.cpp:106] Iteration 18820, lr = 0.01
I0701 17:11:39.784059  2788 solver.cpp:236] Iteration 18830, loss = 0.693534
I0701 17:11:39.784112  2788 solver.cpp:252]     Train net output #0: loss = 0.692132 (* 1 = 0.692132 loss)
I0701 17:11:39.784132  2788 sgd_solver.cpp:106] Iteration 18830, lr = 0.01
I0701 17:11:46.583119  2788 solver.cpp:236] Iteration 18840, loss = 0.693629
I0701 17:11:46.583176  2788 solver.cpp:252]     Train net output #0: loss = 0.694692 (* 1 = 0.694692 loss)
I0701 17:11:46.583202  2788 sgd_solver.cpp:106] Iteration 18840, lr = 0.01
I0701 17:11:53.378484  2788 solver.cpp:236] Iteration 18850, loss = 0.693807
I0701 17:11:53.378538  2788 solver.cpp:252]     Train net output #0: loss = 0.693851 (* 1 = 0.693851 loss)
I0701 17:11:53.378553  2788 sgd_solver.cpp:106] Iteration 18850, lr = 0.01
I0701 17:12:00.191776  2788 solver.cpp:236] Iteration 18860, loss = 0.69354
I0701 17:12:00.191962  2788 solver.cpp:252]     Train net output #0: loss = 0.691873 (* 1 = 0.691873 loss)
I0701 17:12:00.191982  2788 sgd_solver.cpp:106] Iteration 18860, lr = 0.01
I0701 17:12:07.000416  2788 solver.cpp:236] Iteration 18870, loss = 0.693671
I0701 17:12:07.000483  2788 solver.cpp:252]     Train net output #0: loss = 0.693545 (* 1 = 0.693545 loss)
I0701 17:12:07.000501  2788 sgd_solver.cpp:106] Iteration 18870, lr = 0.01
I0701 17:12:13.789386  2788 solver.cpp:236] Iteration 18880, loss = 0.693487
I0701 17:12:13.789438  2788 solver.cpp:252]     Train net output #0: loss = 0.694075 (* 1 = 0.694075 loss)
I0701 17:12:13.789451  2788 sgd_solver.cpp:106] Iteration 18880, lr = 0.01
I0701 17:12:20.607336  2788 solver.cpp:236] Iteration 18890, loss = 0.693398
I0701 17:12:20.607408  2788 solver.cpp:252]     Train net output #0: loss = 0.692422 (* 1 = 0.692422 loss)
I0701 17:12:20.607444  2788 sgd_solver.cpp:106] Iteration 18890, lr = 0.01
I0701 17:12:27.415966  2788 solver.cpp:236] Iteration 18900, loss = 0.693366
I0701 17:12:27.416023  2788 solver.cpp:252]     Train net output #0: loss = 0.693087 (* 1 = 0.693087 loss)
I0701 17:12:27.416038  2788 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0701 17:12:34.220616  2788 solver.cpp:236] Iteration 18910, loss = 0.693374
I0701 17:12:34.220847  2788 solver.cpp:252]     Train net output #0: loss = 0.694574 (* 1 = 0.694574 loss)
I0701 17:12:34.220868  2788 sgd_solver.cpp:106] Iteration 18910, lr = 0.01
I0701 17:12:41.047574  2788 solver.cpp:236] Iteration 18920, loss = 0.693202
I0701 17:12:41.047658  2788 solver.cpp:252]     Train net output #0: loss = 0.690562 (* 1 = 0.690562 loss)
I0701 17:12:41.047685  2788 sgd_solver.cpp:106] Iteration 18920, lr = 0.01
I0701 17:12:47.867125  2788 solver.cpp:236] Iteration 18930, loss = 0.693303
I0701 17:12:47.867195  2788 solver.cpp:252]     Train net output #0: loss = 0.694136 (* 1 = 0.694136 loss)
I0701 17:12:47.867215  2788 sgd_solver.cpp:106] Iteration 18930, lr = 0.01
I0701 17:12:54.681005  2788 solver.cpp:236] Iteration 18940, loss = 0.693323
I0701 17:12:54.681056  2788 solver.cpp:252]     Train net output #0: loss = 0.693083 (* 1 = 0.693083 loss)
I0701 17:12:54.681071  2788 sgd_solver.cpp:106] Iteration 18940, lr = 0.01
I0701 17:13:01.466020  2788 solver.cpp:236] Iteration 18950, loss = 0.693281
I0701 17:13:01.466075  2788 solver.cpp:252]     Train net output #0: loss = 0.693672 (* 1 = 0.693672 loss)
I0701 17:13:01.466090  2788 sgd_solver.cpp:106] Iteration 18950, lr = 0.01
I0701 17:13:08.283135  2788 solver.cpp:236] Iteration 18960, loss = 0.693302
I0701 17:13:08.283404  2788 solver.cpp:252]     Train net output #0: loss = 0.6932 (* 1 = 0.6932 loss)
I0701 17:13:08.283427  2788 sgd_solver.cpp:106] Iteration 18960, lr = 0.01
I0701 17:13:15.113652  2788 solver.cpp:236] Iteration 18970, loss = 0.693387
I0701 17:13:15.113708  2788 solver.cpp:252]     Train net output #0: loss = 0.693657 (* 1 = 0.693657 loss)
I0701 17:13:15.113723  2788 sgd_solver.cpp:106] Iteration 18970, lr = 0.01
I0701 17:13:21.937857  2788 solver.cpp:236] Iteration 18980, loss = 0.693286
I0701 17:13:21.937908  2788 solver.cpp:252]     Train net output #0: loss = 0.694583 (* 1 = 0.694583 loss)
I0701 17:13:21.937923  2788 sgd_solver.cpp:106] Iteration 18980, lr = 0.01
I0701 17:13:28.767542  2788 solver.cpp:236] Iteration 18990, loss = 0.693276
I0701 17:13:28.767602  2788 solver.cpp:252]     Train net output #0: loss = 0.696858 (* 1 = 0.696858 loss)
I0701 17:13:28.767617  2788 sgd_solver.cpp:106] Iteration 18990, lr = 0.01
I0701 17:13:34.914783  2788 solver.cpp:340] Iteration 19000, Testing net (#0)
I0701 17:13:46.646045  2788 solver.cpp:408]     Test net output #0: accuracy = 0.51125
I0701 17:13:46.646242  2788 solver.cpp:408]     Test net output #1: loss = 0.692894 (* 1 = 0.692894 loss)
I0701 17:13:46.824465  2788 solver.cpp:236] Iteration 19000, loss = 0.693216
I0701 17:13:46.824523  2788 solver.cpp:252]     Train net output #0: loss = 0.69128 (* 1 = 0.69128 loss)
I0701 17:13:46.824539  2788 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0701 17:13:53.620003  2788 solver.cpp:236] Iteration 19010, loss = 0.69321
I0701 17:13:53.620064  2788 solver.cpp:252]     Train net output #0: loss = 0.693428 (* 1 = 0.693428 loss)
I0701 17:13:53.620079  2788 sgd_solver.cpp:106] Iteration 19010, lr = 0.01
I0701 17:14:00.423952  2788 solver.cpp:236] Iteration 19020, loss = 0.693108
I0701 17:14:00.424001  2788 solver.cpp:252]     Train net output #0: loss = 0.693303 (* 1 = 0.693303 loss)
I0701 17:14:00.424016  2788 sgd_solver.cpp:106] Iteration 19020, lr = 0.01
I0701 17:14:07.231081  2788 solver.cpp:236] Iteration 19030, loss = 0.693178
I0701 17:14:07.231132  2788 solver.cpp:252]     Train net output #0: loss = 0.693037 (* 1 = 0.693037 loss)
I0701 17:14:07.231147  2788 sgd_solver.cpp:106] Iteration 19030, lr = 0.01
I0701 17:14:14.047744  2788 solver.cpp:236] Iteration 19040, loss = 0.693118
I0701 17:14:14.047802  2788 solver.cpp:252]     Train net output #0: loss = 0.692009 (* 1 = 0.692009 loss)
I0701 17:14:14.047817  2788 sgd_solver.cpp:106] Iteration 19040, lr = 0.01
I0701 17:14:20.853745  2788 solver.cpp:236] Iteration 19050, loss = 0.693196
I0701 17:14:20.854096  2788 solver.cpp:252]     Train net output #0: loss = 0.693515 (* 1 = 0.693515 loss)
I0701 17:14:20.854115  2788 sgd_solver.cpp:106] Iteration 19050, lr = 0.01
I0701 17:14:27.655995  2788 solver.cpp:236] Iteration 19060, loss = 0.693273
I0701 17:14:27.656052  2788 solver.cpp:252]     Train net output #0: loss = 0.693088 (* 1 = 0.693088 loss)
I0701 17:14:27.656069  2788 sgd_solver.cpp:106] Iteration 19060, lr = 0.01
I0701 17:14:34.459914  2788 solver.cpp:236] Iteration 19070, loss = 0.693274
I0701 17:14:34.459980  2788 solver.cpp:252]     Train net output #0: loss = 0.693031 (* 1 = 0.693031 loss)
I0701 17:14:34.459995  2788 sgd_solver.cpp:106] Iteration 19070, lr = 0.01
I0701 17:14:41.265485  2788 solver.cpp:236] Iteration 19080, loss = 0.692897
I0701 17:14:41.265553  2788 solver.cpp:252]     Train net output #0: loss = 0.689638 (* 1 = 0.689638 loss)
I0701 17:14:41.265566  2788 sgd_solver.cpp:106] Iteration 19080, lr = 0.01
I0701 17:14:48.079355  2788 solver.cpp:236] Iteration 19090, loss = 0.693442
I0701 17:14:48.079417  2788 solver.cpp:252]     Train net output #0: loss = 0.690609 (* 1 = 0.690609 loss)
I0701 17:14:48.079432  2788 sgd_solver.cpp:106] Iteration 19090, lr = 0.01
I0701 17:14:54.903903  2788 solver.cpp:236] Iteration 19100, loss = 0.693502
I0701 17:14:54.904146  2788 solver.cpp:252]     Train net output #0: loss = 0.693281 (* 1 = 0.693281 loss)
I0701 17:14:54.904168  2788 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0701 17:15:01.727980  2788 solver.cpp:236] Iteration 19110, loss = 0.693402
I0701 17:15:01.728046  2788 solver.cpp:252]     Train net output #0: loss = 0.692827 (* 1 = 0.692827 loss)
I0701 17:15:01.728061  2788 sgd_solver.cpp:106] Iteration 19110, lr = 0.01
I0701 17:15:08.539458  2788 solver.cpp:236] Iteration 19120, loss = 0.693299
I0701 17:15:08.539521  2788 solver.cpp:252]     Train net output #0: loss = 0.693143 (* 1 = 0.693143 loss)
I0701 17:15:08.539537  2788 sgd_solver.cpp:106] Iteration 19120, lr = 0.01
I0701 17:15:15.350791  2788 solver.cpp:236] Iteration 19130, loss = 0.693723
I0701 17:15:15.350859  2788 solver.cpp:252]     Train net output #0: loss = 0.690555 (* 1 = 0.690555 loss)
I0701 17:15:15.350874  2788 sgd_solver.cpp:106] Iteration 19130, lr = 0.01
I0701 17:15:22.157470  2788 solver.cpp:236] Iteration 19140, loss = 0.693448
I0701 17:15:22.157542  2788 solver.cpp:252]     Train net output #0: loss = 0.693239 (* 1 = 0.693239 loss)
I0701 17:15:22.157559  2788 sgd_solver.cpp:106] Iteration 19140, lr = 0.01
I0701 17:15:28.981019  2788 solver.cpp:236] Iteration 19150, loss = 0.693417
I0701 17:15:28.981215  2788 solver.cpp:252]     Train net output #0: loss = 0.696908 (* 1 = 0.696908 loss)
I0701 17:15:28.981228  2788 sgd_solver.cpp:106] Iteration 19150, lr = 0.01
I0701 17:15:35.787523  2788 solver.cpp:236] Iteration 19160, loss = 0.693378
I0701 17:15:35.787578  2788 solver.cpp:252]     Train net output #0: loss = 0.692397 (* 1 = 0.692397 loss)
I0701 17:15:35.787592  2788 sgd_solver.cpp:106] Iteration 19160, lr = 0.01
I0701 17:15:42.594422  2788 solver.cpp:236] Iteration 19170, loss = 0.693405
I0701 17:15:42.594473  2788 solver.cpp:252]     Train net output #0: loss = 0.6976 (* 1 = 0.6976 loss)
I0701 17:15:42.594488  2788 sgd_solver.cpp:106] Iteration 19170, lr = 0.01
I0701 17:15:49.407387  2788 solver.cpp:236] Iteration 19180, loss = 0.69356
I0701 17:15:49.407454  2788 solver.cpp:252]     Train net output #0: loss = 0.696967 (* 1 = 0.696967 loss)
I0701 17:15:49.407472  2788 sgd_solver.cpp:106] Iteration 19180, lr = 0.01
I0701 17:15:56.213088  2788 solver.cpp:236] Iteration 19190, loss = 0.693285
I0701 17:15:56.213155  2788 solver.cpp:252]     Train net output #0: loss = 0.692556 (* 1 = 0.692556 loss)
I0701 17:15:56.213176  2788 sgd_solver.cpp:106] Iteration 19190, lr = 0.01
I0701 17:16:03.017346  2788 solver.cpp:236] Iteration 19200, loss = 0.693624
I0701 17:16:03.017588  2788 solver.cpp:252]     Train net output #0: loss = 0.695698 (* 1 = 0.695698 loss)
I0701 17:16:03.017606  2788 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0701 17:16:09.827165  2788 solver.cpp:236] Iteration 19210, loss = 0.693641
I0701 17:16:09.827214  2788 solver.cpp:252]     Train net output #0: loss = 0.692797 (* 1 = 0.692797 loss)
I0701 17:16:09.827229  2788 sgd_solver.cpp:106] Iteration 19210, lr = 0.01
I0701 17:16:16.633524  2788 solver.cpp:236] Iteration 19220, loss = 0.693779
I0701 17:16:16.633582  2788 solver.cpp:252]     Train net output #0: loss = 0.693181 (* 1 = 0.693181 loss)
I0701 17:16:16.633596  2788 sgd_solver.cpp:106] Iteration 19220, lr = 0.01
I0701 17:16:23.441488  2788 solver.cpp:236] Iteration 19230, loss = 0.693551
I0701 17:16:23.441540  2788 solver.cpp:252]     Train net output #0: loss = 0.69315 (* 1 = 0.69315 loss)
I0701 17:16:23.441553  2788 sgd_solver.cpp:106] Iteration 19230, lr = 0.01
I0701 17:16:28.875267  2788 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_19239.caffemodel
I0701 17:16:29.493278  2788 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_19239.solverstate
I0701 17:16:29.532812  2788 solver.cpp:308] Optimization stopped early.
I0701 17:16:29.532861  2788 caffe.cpp:215] Optimization Done.
