Log file created at: 2016/07/07 10:10:21
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0707 10:10:21.058589 26359 caffe.cpp:184] Using GPUs 2
I0707 10:10:21.806255 26359 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 250
base_lr: 0.005
display: 100
max_iter: 360000
lr_policy: "fixed"
gamma: 0.1
momentum: 0.9
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/cnn10"
solver_mode: GPU
device_id: 2
net: "train_val.prototxt.full"
test_initialization: false
average_loss: 50
I0707 10:10:21.813344 26359 solver.cpp:90] Creating training net from net file: train_val.prototxt.full
I0707 10:10:21.835110 26359 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0707 10:10:21.835316 26359 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0707 10:10:21.835455 26359 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0707 10:10:21.835703 26359 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-train-L0.lst"
    batch_size: 128
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0707 10:10:21.837442 26359 layer_factory.hpp:76] Creating layer data
I0707 10:10:21.837702 26359 net.cpp:106] Creating Layer data
I0707 10:10:21.837739 26359 net.cpp:411] data -> data
I0707 10:10:21.837772 26359 net.cpp:411] data -> label
I0707 10:10:21.838383 26359 image_data_layer.cpp:36] Opening file ../lists/roi-train-L0.lst
I0707 10:10:22.291307 26359 image_data_layer.cpp:46] Shuffling data
I0707 10:10:22.353525 26359 image_data_layer.cpp:51] A total of 211680 images.
I0707 10:10:22.571612 26359 image_data_layer.cpp:78] output data size: 128,3,100,100
I0707 10:10:22.645884 26359 net.cpp:150] Setting up data
I0707 10:10:22.645977 26359 net.cpp:157] Top shape: 128 3 100 100 (3840000)
I0707 10:10:22.645989 26359 net.cpp:157] Top shape: 128 (128)
I0707 10:10:22.645998 26359 net.cpp:165] Memory required for data: 15360512
I0707 10:10:22.646016 26359 layer_factory.hpp:76] Creating layer label_data_1_split
I0707 10:10:22.646234 26359 net.cpp:106] Creating Layer label_data_1_split
I0707 10:10:22.646255 26359 net.cpp:454] label_data_1_split <- label
I0707 10:10:22.646275 26359 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0707 10:10:22.646303 26359 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0707 10:10:22.646375 26359 net.cpp:150] Setting up label_data_1_split
I0707 10:10:22.646390 26359 net.cpp:157] Top shape: 128 (128)
I0707 10:10:22.646399 26359 net.cpp:157] Top shape: 128 (128)
I0707 10:10:22.646407 26359 net.cpp:165] Memory required for data: 15361536
I0707 10:10:22.646415 26359 layer_factory.hpp:76] Creating layer conv11
I0707 10:10:22.646438 26359 net.cpp:106] Creating Layer conv11
I0707 10:10:22.646458 26359 net.cpp:454] conv11 <- data
I0707 10:10:22.646471 26359 net.cpp:411] conv11 -> conv11
I0707 10:10:23.015441 26359 net.cpp:150] Setting up conv11
I0707 10:10:23.015550 26359 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0707 10:10:23.015570 26359 net.cpp:165] Memory required for data: 179201536
I0707 10:10:23.015791 26359 layer_factory.hpp:76] Creating layer relu11
I0707 10:10:23.015874 26359 net.cpp:106] Creating Layer relu11
I0707 10:10:23.015897 26359 net.cpp:454] relu11 <- conv11
I0707 10:10:23.015923 26359 net.cpp:397] relu11 -> conv11 (in-place)
I0707 10:10:23.016216 26359 net.cpp:150] Setting up relu11
I0707 10:10:23.016247 26359 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0707 10:10:23.016260 26359 net.cpp:165] Memory required for data: 343041536
I0707 10:10:23.016273 26359 layer_factory.hpp:76] Creating layer conv12
I0707 10:10:23.016352 26359 net.cpp:106] Creating Layer conv12
I0707 10:10:23.016374 26359 net.cpp:454] conv12 <- conv11
I0707 10:10:23.016396 26359 net.cpp:411] conv12 -> conv12
I0707 10:10:23.017761 26359 net.cpp:150] Setting up conv12
I0707 10:10:23.017792 26359 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0707 10:10:23.017802 26359 net.cpp:165] Memory required for data: 506881536
I0707 10:10:23.017840 26359 layer_factory.hpp:76] Creating layer relu12
I0707 10:10:23.017897 26359 net.cpp:106] Creating Layer relu12
I0707 10:10:23.017907 26359 net.cpp:454] relu12 <- conv12
I0707 10:10:23.017917 26359 net.cpp:397] relu12 -> conv12 (in-place)
I0707 10:10:23.018270 26359 net.cpp:150] Setting up relu12
I0707 10:10:23.018302 26359 net.cpp:157] Top shape: 128 32 100 100 (40960000)
I0707 10:10:23.018311 26359 net.cpp:165] Memory required for data: 670721536
I0707 10:10:23.018321 26359 layer_factory.hpp:76] Creating layer pool1
I0707 10:10:23.018342 26359 net.cpp:106] Creating Layer pool1
I0707 10:10:23.018352 26359 net.cpp:454] pool1 <- conv12
I0707 10:10:23.018362 26359 net.cpp:411] pool1 -> pool1
I0707 10:10:23.018851 26359 net.cpp:150] Setting up pool1
I0707 10:10:23.018887 26359 net.cpp:157] Top shape: 128 32 50 50 (10240000)
I0707 10:10:23.018898 26359 net.cpp:165] Memory required for data: 711681536
I0707 10:10:23.018908 26359 layer_factory.hpp:76] Creating layer conv21
I0707 10:10:23.018937 26359 net.cpp:106] Creating Layer conv21
I0707 10:10:23.018947 26359 net.cpp:454] conv21 <- pool1
I0707 10:10:23.018960 26359 net.cpp:411] conv21 -> conv21
I0707 10:10:23.021361 26359 net.cpp:150] Setting up conv21
I0707 10:10:23.021404 26359 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0707 10:10:23.021414 26359 net.cpp:165] Memory required for data: 793601536
I0707 10:10:23.021432 26359 layer_factory.hpp:76] Creating layer relu21
I0707 10:10:23.021450 26359 net.cpp:106] Creating Layer relu21
I0707 10:10:23.021459 26359 net.cpp:454] relu21 <- conv21
I0707 10:10:23.021471 26359 net.cpp:397] relu21 -> conv21 (in-place)
I0707 10:10:23.021806 26359 net.cpp:150] Setting up relu21
I0707 10:10:23.021836 26359 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0707 10:10:23.021877 26359 net.cpp:165] Memory required for data: 875521536
I0707 10:10:23.021888 26359 layer_factory.hpp:76] Creating layer conv22
I0707 10:10:23.021919 26359 net.cpp:106] Creating Layer conv22
I0707 10:10:23.021931 26359 net.cpp:454] conv22 <- conv21
I0707 10:10:23.021944 26359 net.cpp:411] conv22 -> conv22
I0707 10:10:23.023304 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0707 10:10:23.023552 26359 net.cpp:150] Setting up conv22
I0707 10:10:23.023583 26359 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0707 10:10:23.023592 26359 net.cpp:165] Memory required for data: 957441536
I0707 10:10:23.023612 26359 layer_factory.hpp:76] Creating layer relu22
I0707 10:10:23.023627 26359 net.cpp:106] Creating Layer relu22
I0707 10:10:23.023635 26359 net.cpp:454] relu22 <- conv22
I0707 10:10:23.023648 26359 net.cpp:397] relu22 -> conv22 (in-place)
I0707 10:10:23.023993 26359 net.cpp:150] Setting up relu22
I0707 10:10:23.024027 26359 net.cpp:157] Top shape: 128 64 50 50 (20480000)
I0707 10:10:23.024045 26359 net.cpp:165] Memory required for data: 1039361536
I0707 10:10:23.024055 26359 layer_factory.hpp:76] Creating layer pool2
I0707 10:10:23.024068 26359 net.cpp:106] Creating Layer pool2
I0707 10:10:23.024076 26359 net.cpp:454] pool2 <- conv22
I0707 10:10:23.024098 26359 net.cpp:411] pool2 -> pool2
I0707 10:10:23.024395 26359 net.cpp:150] Setting up pool2
I0707 10:10:23.024431 26359 net.cpp:157] Top shape: 128 64 25 25 (5120000)
I0707 10:10:23.024451 26359 net.cpp:165] Memory required for data: 1059841536
I0707 10:10:23.024469 26359 layer_factory.hpp:76] Creating layer conv31
I0707 10:10:23.024489 26359 net.cpp:106] Creating Layer conv31
I0707 10:10:23.024503 26359 net.cpp:454] conv31 <- pool2
I0707 10:10:23.024518 26359 net.cpp:411] conv31 -> conv31
I0707 10:10:23.026037 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0707 10:10:23.026087 26359 net.cpp:150] Setting up conv31
I0707 10:10:23.026099 26359 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0707 10:10:23.026108 26359 net.cpp:165] Memory required for data: 1090561536
I0707 10:10:23.026124 26359 layer_factory.hpp:76] Creating layer relu31
I0707 10:10:23.026150 26359 net.cpp:106] Creating Layer relu31
I0707 10:10:23.026163 26359 net.cpp:454] relu31 <- conv31
I0707 10:10:23.026173 26359 net.cpp:397] relu31 -> conv31 (in-place)
I0707 10:10:23.026506 26359 net.cpp:150] Setting up relu31
I0707 10:10:23.026537 26359 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0707 10:10:23.026546 26359 net.cpp:165] Memory required for data: 1121281536
I0707 10:10:23.026564 26359 layer_factory.hpp:76] Creating layer conv32
I0707 10:10:23.026581 26359 net.cpp:106] Creating Layer conv32
I0707 10:10:23.026589 26359 net.cpp:454] conv32 <- conv31
I0707 10:10:23.026603 26359 net.cpp:411] conv32 -> conv32
I0707 10:10:23.029322 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0707 10:10:23.029379 26359 net.cpp:150] Setting up conv32
I0707 10:10:23.029393 26359 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0707 10:10:23.029403 26359 net.cpp:165] Memory required for data: 1152001536
I0707 10:10:23.029415 26359 layer_factory.hpp:76] Creating layer relu32
I0707 10:10:23.029428 26359 net.cpp:106] Creating Layer relu32
I0707 10:10:23.029438 26359 net.cpp:454] relu32 <- conv32
I0707 10:10:23.029450 26359 net.cpp:397] relu32 -> conv32 (in-place)
I0707 10:10:23.029644 26359 net.cpp:150] Setting up relu32
I0707 10:10:23.029671 26359 net.cpp:157] Top shape: 128 96 25 25 (7680000)
I0707 10:10:23.029680 26359 net.cpp:165] Memory required for data: 1182721536
I0707 10:10:23.029690 26359 layer_factory.hpp:76] Creating layer pool3
I0707 10:10:23.029718 26359 net.cpp:106] Creating Layer pool3
I0707 10:10:23.029729 26359 net.cpp:454] pool3 <- conv32
I0707 10:10:23.029742 26359 net.cpp:411] pool3 -> pool3
I0707 10:10:23.030278 26359 net.cpp:150] Setting up pool3
I0707 10:10:23.030314 26359 net.cpp:157] Top shape: 128 96 13 13 (2076672)
I0707 10:10:23.030323 26359 net.cpp:165] Memory required for data: 1191028224
I0707 10:10:23.030333 26359 layer_factory.hpp:76] Creating layer conv41
I0707 10:10:23.030388 26359 net.cpp:106] Creating Layer conv41
I0707 10:10:23.030401 26359 net.cpp:454] conv41 <- pool3
I0707 10:10:23.030412 26359 net.cpp:411] conv41 -> conv41
I0707 10:10:23.032147 26359 net.cpp:150] Setting up conv41
I0707 10:10:23.032181 26359 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0707 10:10:23.032191 26359 net.cpp:165] Memory required for data: 1202103808
I0707 10:10:23.032202 26359 layer_factory.hpp:76] Creating layer relu41
I0707 10:10:23.032214 26359 net.cpp:106] Creating Layer relu41
I0707 10:10:23.032223 26359 net.cpp:454] relu41 <- conv41
I0707 10:10:23.032235 26359 net.cpp:397] relu41 -> conv41 (in-place)
I0707 10:10:23.033407 26359 net.cpp:150] Setting up relu41
I0707 10:10:23.033438 26359 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0707 10:10:23.033447 26359 net.cpp:165] Memory required for data: 1213179392
I0707 10:10:23.033457 26359 layer_factory.hpp:76] Creating layer conv42
I0707 10:10:23.033473 26359 net.cpp:106] Creating Layer conv42
I0707 10:10:23.033484 26359 net.cpp:454] conv42 <- conv41
I0707 10:10:23.033498 26359 net.cpp:411] conv42 -> conv42
I0707 10:10:23.037822 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0707 10:10:23.037899 26359 net.cpp:150] Setting up conv42
I0707 10:10:23.037915 26359 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0707 10:10:23.037925 26359 net.cpp:165] Memory required for data: 1224254976
I0707 10:10:23.037940 26359 layer_factory.hpp:76] Creating layer relu42
I0707 10:10:23.037971 26359 net.cpp:106] Creating Layer relu42
I0707 10:10:23.037983 26359 net.cpp:454] relu42 <- conv42
I0707 10:10:23.038008 26359 net.cpp:397] relu42 -> conv42 (in-place)
I0707 10:10:23.038221 26359 net.cpp:150] Setting up relu42
I0707 10:10:23.038260 26359 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0707 10:10:23.038269 26359 net.cpp:165] Memory required for data: 1235330560
I0707 10:10:23.038277 26359 layer_factory.hpp:76] Creating layer pool4
I0707 10:10:23.038292 26359 net.cpp:106] Creating Layer pool4
I0707 10:10:23.038300 26359 net.cpp:454] pool4 <- conv42
I0707 10:10:23.038311 26359 net.cpp:411] pool4 -> pool4
I0707 10:10:23.038854 26359 net.cpp:150] Setting up pool4
I0707 10:10:23.038885 26359 net.cpp:157] Top shape: 128 128 7 7 (802816)
I0707 10:10:23.038894 26359 net.cpp:165] Memory required for data: 1238541824
I0707 10:10:23.038904 26359 layer_factory.hpp:76] Creating layer conv51
I0707 10:10:23.038924 26359 net.cpp:106] Creating Layer conv51
I0707 10:10:23.038933 26359 net.cpp:454] conv51 <- pool4
I0707 10:10:23.038944 26359 net.cpp:411] conv51 -> conv51
I0707 10:10:23.043277 26359 net.cpp:150] Setting up conv51
I0707 10:10:23.043326 26359 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0707 10:10:23.043336 26359 net.cpp:165] Memory required for data: 1244964352
I0707 10:10:23.043355 26359 layer_factory.hpp:76] Creating layer relu51
I0707 10:10:23.043370 26359 net.cpp:106] Creating Layer relu51
I0707 10:10:23.043380 26359 net.cpp:454] relu51 <- conv51
I0707 10:10:23.043390 26359 net.cpp:397] relu51 -> conv51 (in-place)
I0707 10:10:23.043612 26359 net.cpp:150] Setting up relu51
I0707 10:10:23.043640 26359 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0707 10:10:23.043648 26359 net.cpp:165] Memory required for data: 1251386880
I0707 10:10:23.043658 26359 layer_factory.hpp:76] Creating layer conv52
I0707 10:10:23.043678 26359 net.cpp:106] Creating Layer conv52
I0707 10:10:23.043687 26359 net.cpp:454] conv52 <- conv51
I0707 10:10:23.043700 26359 net.cpp:411] conv52 -> conv52
I0707 10:10:23.067407 26359 net.cpp:150] Setting up conv52
I0707 10:10:23.067438 26359 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0707 10:10:23.067443 26359 net.cpp:165] Memory required for data: 1257809408
I0707 10:10:23.067456 26359 layer_factory.hpp:76] Creating layer relu52
I0707 10:10:23.067471 26359 net.cpp:106] Creating Layer relu52
I0707 10:10:23.067477 26359 net.cpp:454] relu52 <- conv52
I0707 10:10:23.067487 26359 net.cpp:397] relu52 -> conv52 (in-place)
I0707 10:10:23.076014 26359 net.cpp:150] Setting up relu52
I0707 10:10:23.076066 26359 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0707 10:10:23.076071 26359 net.cpp:165] Memory required for data: 1264231936
I0707 10:10:23.076074 26359 layer_factory.hpp:76] Creating layer conv53
I0707 10:10:23.076088 26359 net.cpp:106] Creating Layer conv53
I0707 10:10:23.076093 26359 net.cpp:454] conv53 <- conv52
I0707 10:10:23.076102 26359 net.cpp:411] conv53 -> conv53
I0707 10:10:23.106709 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0707 10:10:23.106995 26359 net.cpp:150] Setting up conv53
I0707 10:10:23.107017 26359 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0707 10:10:23.107025 26359 net.cpp:165] Memory required for data: 1264363008
I0707 10:10:23.107040 26359 layer_factory.hpp:76] Creating layer relu53
I0707 10:10:23.107058 26359 net.cpp:106] Creating Layer relu53
I0707 10:10:23.107081 26359 net.cpp:454] relu53 <- conv53
I0707 10:10:23.107105 26359 net.cpp:397] relu53 -> conv53 (in-place)
I0707 10:10:23.107470 26359 net.cpp:150] Setting up relu53
I0707 10:10:23.107499 26359 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0707 10:10:23.107507 26359 net.cpp:165] Memory required for data: 1264494080
I0707 10:10:23.107516 26359 layer_factory.hpp:76] Creating layer drop6
I0707 10:10:23.107534 26359 net.cpp:106] Creating Layer drop6
I0707 10:10:23.107542 26359 net.cpp:454] drop6 <- conv53
I0707 10:10:23.107553 26359 net.cpp:411] drop6 -> drop6
I0707 10:10:23.107959 26359 net.cpp:150] Setting up drop6
I0707 10:10:23.107996 26359 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0707 10:10:23.108006 26359 net.cpp:165] Memory required for data: 1264625152
I0707 10:10:23.108014 26359 layer_factory.hpp:76] Creating layer conv54
I0707 10:10:23.108031 26359 net.cpp:106] Creating Layer conv54
I0707 10:10:23.108042 26359 net.cpp:454] conv54 <- drop6
I0707 10:10:23.108054 26359 net.cpp:411] conv54 -> conv54
I0707 10:10:23.109205 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0707 10:10:23.109484 26359 net.cpp:150] Setting up conv54
I0707 10:10:23.109513 26359 net.cpp:157] Top shape: 128 2 1 1 (256)
I0707 10:10:23.109522 26359 net.cpp:165] Memory required for data: 1264626176
I0707 10:10:23.109534 26359 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0707 10:10:23.109545 26359 net.cpp:106] Creating Layer conv54_conv54_0_split
I0707 10:10:23.109554 26359 net.cpp:454] conv54_conv54_0_split <- conv54
I0707 10:10:23.109566 26359 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0707 10:10:23.109577 26359 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0707 10:10:23.109642 26359 net.cpp:150] Setting up conv54_conv54_0_split
I0707 10:10:23.109655 26359 net.cpp:157] Top shape: 128 2 1 1 (256)
I0707 10:10:23.109663 26359 net.cpp:157] Top shape: 128 2 1 1 (256)
I0707 10:10:23.109671 26359 net.cpp:165] Memory required for data: 1264628224
I0707 10:10:23.109680 26359 layer_factory.hpp:76] Creating layer accuracy
I0707 10:10:23.109699 26359 net.cpp:106] Creating Layer accuracy
I0707 10:10:23.109720 26359 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0707 10:10:23.109730 26359 net.cpp:454] accuracy <- label_data_1_split_0
I0707 10:10:23.109740 26359 net.cpp:411] accuracy -> accuracy
I0707 10:10:23.109767 26359 net.cpp:150] Setting up accuracy
I0707 10:10:23.109794 26359 net.cpp:157] Top shape: (1)
I0707 10:10:23.109802 26359 net.cpp:165] Memory required for data: 1264628228
I0707 10:10:23.109822 26359 layer_factory.hpp:76] Creating layer loss
I0707 10:10:23.109853 26359 net.cpp:106] Creating Layer loss
I0707 10:10:23.109860 26359 net.cpp:454] loss <- conv54_conv54_0_split_1
I0707 10:10:23.109869 26359 net.cpp:454] loss <- label_data_1_split_1
I0707 10:10:23.109880 26359 net.cpp:411] loss -> loss
I0707 10:10:23.109915 26359 layer_factory.hpp:76] Creating layer loss
I0707 10:10:23.110390 26359 net.cpp:150] Setting up loss
I0707 10:10:23.110435 26359 net.cpp:157] Top shape: (1)
I0707 10:10:23.110443 26359 net.cpp:160]     with loss weight 1
I0707 10:10:23.110486 26359 net.cpp:165] Memory required for data: 1264628232
I0707 10:10:23.110551 26359 net.cpp:226] loss needs backward computation.
I0707 10:10:23.110563 26359 net.cpp:228] accuracy does not need backward computation.
I0707 10:10:23.110570 26359 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0707 10:10:23.110579 26359 net.cpp:226] conv54 needs backward computation.
I0707 10:10:23.110585 26359 net.cpp:226] drop6 needs backward computation.
I0707 10:10:23.110605 26359 net.cpp:226] relu53 needs backward computation.
I0707 10:10:23.110612 26359 net.cpp:226] conv53 needs backward computation.
I0707 10:10:23.110618 26359 net.cpp:226] relu52 needs backward computation.
I0707 10:10:23.110626 26359 net.cpp:226] conv52 needs backward computation.
I0707 10:10:23.110633 26359 net.cpp:226] relu51 needs backward computation.
I0707 10:10:23.110641 26359 net.cpp:226] conv51 needs backward computation.
I0707 10:10:23.110647 26359 net.cpp:226] pool4 needs backward computation.
I0707 10:10:23.110654 26359 net.cpp:226] relu42 needs backward computation.
I0707 10:10:23.110661 26359 net.cpp:226] conv42 needs backward computation.
I0707 10:10:23.110668 26359 net.cpp:226] relu41 needs backward computation.
I0707 10:10:23.110676 26359 net.cpp:226] conv41 needs backward computation.
I0707 10:10:23.110682 26359 net.cpp:226] pool3 needs backward computation.
I0707 10:10:23.110689 26359 net.cpp:226] relu32 needs backward computation.
I0707 10:10:23.110697 26359 net.cpp:226] conv32 needs backward computation.
I0707 10:10:23.110704 26359 net.cpp:226] relu31 needs backward computation.
I0707 10:10:23.110710 26359 net.cpp:226] conv31 needs backward computation.
I0707 10:10:23.110718 26359 net.cpp:226] pool2 needs backward computation.
I0707 10:10:23.110725 26359 net.cpp:226] relu22 needs backward computation.
I0707 10:10:23.110733 26359 net.cpp:226] conv22 needs backward computation.
I0707 10:10:23.110739 26359 net.cpp:226] relu21 needs backward computation.
I0707 10:10:23.110748 26359 net.cpp:226] conv21 needs backward computation.
I0707 10:10:23.110754 26359 net.cpp:226] pool1 needs backward computation.
I0707 10:10:23.110761 26359 net.cpp:226] relu12 needs backward computation.
I0707 10:10:23.110767 26359 net.cpp:226] conv12 needs backward computation.
I0707 10:10:23.110775 26359 net.cpp:226] relu11 needs backward computation.
I0707 10:10:23.110782 26359 net.cpp:226] conv11 needs backward computation.
I0707 10:10:23.110790 26359 net.cpp:228] label_data_1_split does not need backward computation.
I0707 10:10:23.110800 26359 net.cpp:228] data does not need backward computation.
I0707 10:10:23.110807 26359 net.cpp:270] This network produces output accuracy
I0707 10:10:23.110815 26359 net.cpp:270] This network produces output loss
I0707 10:10:23.110839 26359 net.cpp:283] Network initialization done.
I0707 10:10:23.113790 26359 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: train_val.prototxt.full
I0707 10:10:23.114253 26359 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0707 10:10:23.114301 26359 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt.full
I0707 10:10:23.114359 26359 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0707 10:10:23.115640 26359 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 100
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/roi-val-L0.lst"
    batch_size: 100
    shuffle: true
    new_height: 110
    new_width: 110
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv53"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "drop6"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv54"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv54"
  bottom: "label"
  top: "loss"
}
I0707 10:10:23.117409 26359 layer_factory.hpp:76] Creating layer data
I0707 10:10:23.117460 26359 net.cpp:106] Creating Layer data
I0707 10:10:23.117470 26359 net.cpp:411] data -> data
I0707 10:10:23.117483 26359 net.cpp:411] data -> label
I0707 10:10:23.117498 26359 image_data_layer.cpp:36] Opening file ../lists/roi-val-L0.lst
I0707 10:10:23.228946 26359 image_data_layer.cpp:46] Shuffling data
I0707 10:10:23.234114 26359 image_data_layer.cpp:51] A total of 23520 images.
I0707 10:10:23.290393 26359 image_data_layer.cpp:78] output data size: 100,3,100,100
I0707 10:10:23.349820 26359 net.cpp:150] Setting up data
I0707 10:10:23.349920 26359 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0707 10:10:23.349936 26359 net.cpp:157] Top shape: 100 (100)
I0707 10:10:23.349944 26359 net.cpp:165] Memory required for data: 12000400
I0707 10:10:23.349961 26359 layer_factory.hpp:76] Creating layer label_data_1_split
I0707 10:10:23.349982 26359 net.cpp:106] Creating Layer label_data_1_split
I0707 10:10:23.349992 26359 net.cpp:454] label_data_1_split <- label
I0707 10:10:23.350005 26359 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0707 10:10:23.350033 26359 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0707 10:10:23.350379 26359 net.cpp:150] Setting up label_data_1_split
I0707 10:10:23.350415 26359 net.cpp:157] Top shape: 100 (100)
I0707 10:10:23.350427 26359 net.cpp:157] Top shape: 100 (100)
I0707 10:10:23.350443 26359 net.cpp:165] Memory required for data: 12001200
I0707 10:10:23.350451 26359 layer_factory.hpp:76] Creating layer conv11
I0707 10:10:23.350476 26359 net.cpp:106] Creating Layer conv11
I0707 10:10:23.350487 26359 net.cpp:454] conv11 <- data
I0707 10:10:23.350512 26359 net.cpp:411] conv11 -> conv11
I0707 10:10:23.370574 26359 net.cpp:150] Setting up conv11
I0707 10:10:23.370622 26359 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0707 10:10:23.370628 26359 net.cpp:165] Memory required for data: 140001200
I0707 10:10:23.370657 26359 layer_factory.hpp:76] Creating layer relu11
I0707 10:10:23.370676 26359 net.cpp:106] Creating Layer relu11
I0707 10:10:23.370683 26359 net.cpp:454] relu11 <- conv11
I0707 10:10:23.370692 26359 net.cpp:397] relu11 -> conv11 (in-place)
I0707 10:10:23.389153 26359 net.cpp:150] Setting up relu11
I0707 10:10:23.389228 26359 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0707 10:10:23.389235 26359 net.cpp:165] Memory required for data: 268001200
I0707 10:10:23.389246 26359 layer_factory.hpp:76] Creating layer conv12
I0707 10:10:23.389281 26359 net.cpp:106] Creating Layer conv12
I0707 10:10:23.389287 26359 net.cpp:454] conv12 <- conv11
I0707 10:10:23.389297 26359 net.cpp:411] conv12 -> conv12
I0707 10:10:23.394395 26359 net.cpp:150] Setting up conv12
I0707 10:10:23.394438 26359 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0707 10:10:23.394454 26359 net.cpp:165] Memory required for data: 396001200
I0707 10:10:23.394491 26359 layer_factory.hpp:76] Creating layer relu12
I0707 10:10:23.394510 26359 net.cpp:106] Creating Layer relu12
I0707 10:10:23.394520 26359 net.cpp:454] relu12 <- conv12
I0707 10:10:23.394534 26359 net.cpp:397] relu12 -> conv12 (in-place)
I0707 10:10:23.396692 26359 net.cpp:150] Setting up relu12
I0707 10:10:23.396716 26359 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0707 10:10:23.396733 26359 net.cpp:165] Memory required for data: 524001200
I0707 10:10:23.396746 26359 layer_factory.hpp:76] Creating layer pool1
I0707 10:10:23.396775 26359 net.cpp:106] Creating Layer pool1
I0707 10:10:23.396787 26359 net.cpp:454] pool1 <- conv12
I0707 10:10:23.396798 26359 net.cpp:411] pool1 -> pool1
I0707 10:10:23.397816 26359 net.cpp:150] Setting up pool1
I0707 10:10:23.397841 26359 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0707 10:10:23.397858 26359 net.cpp:165] Memory required for data: 556001200
I0707 10:10:23.397874 26359 layer_factory.hpp:76] Creating layer conv21
I0707 10:10:23.397908 26359 net.cpp:106] Creating Layer conv21
I0707 10:10:23.397920 26359 net.cpp:454] conv21 <- pool1
I0707 10:10:23.397933 26359 net.cpp:411] conv21 -> conv21
I0707 10:10:23.402451 26359 net.cpp:150] Setting up conv21
I0707 10:10:23.402487 26359 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0707 10:10:23.402503 26359 net.cpp:165] Memory required for data: 620001200
I0707 10:10:23.402529 26359 layer_factory.hpp:76] Creating layer relu21
I0707 10:10:23.402549 26359 net.cpp:106] Creating Layer relu21
I0707 10:10:23.402562 26359 net.cpp:454] relu21 <- conv21
I0707 10:10:23.402583 26359 net.cpp:397] relu21 -> conv21 (in-place)
I0707 10:10:23.404733 26359 net.cpp:150] Setting up relu21
I0707 10:10:23.404762 26359 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0707 10:10:23.404777 26359 net.cpp:165] Memory required for data: 684001200
I0707 10:10:23.404793 26359 layer_factory.hpp:76] Creating layer conv22
I0707 10:10:23.404819 26359 net.cpp:106] Creating Layer conv22
I0707 10:10:23.404829 26359 net.cpp:454] conv22 <- conv21
I0707 10:10:23.404846 26359 net.cpp:411] conv22 -> conv22
I0707 10:10:23.409452 26359 net.cpp:150] Setting up conv22
I0707 10:10:23.409497 26359 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0707 10:10:23.409507 26359 net.cpp:165] Memory required for data: 748001200
I0707 10:10:23.409524 26359 layer_factory.hpp:76] Creating layer relu22
I0707 10:10:23.409546 26359 net.cpp:106] Creating Layer relu22
I0707 10:10:23.409570 26359 net.cpp:454] relu22 <- conv22
I0707 10:10:23.409591 26359 net.cpp:397] relu22 -> conv22 (in-place)
I0707 10:10:23.410522 26359 net.cpp:150] Setting up relu22
I0707 10:10:23.410557 26359 net.cpp:157] Top shape: 100 64 50 50 (16000000)
I0707 10:10:23.410572 26359 net.cpp:165] Memory required for data: 812001200
I0707 10:10:23.410588 26359 layer_factory.hpp:76] Creating layer pool2
I0707 10:10:23.410609 26359 net.cpp:106] Creating Layer pool2
I0707 10:10:23.410621 26359 net.cpp:454] pool2 <- conv22
I0707 10:10:23.410645 26359 net.cpp:411] pool2 -> pool2
I0707 10:10:23.413595 26359 net.cpp:150] Setting up pool2
I0707 10:10:23.413635 26359 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0707 10:10:23.413651 26359 net.cpp:165] Memory required for data: 828001200
I0707 10:10:23.413667 26359 layer_factory.hpp:76] Creating layer conv31
I0707 10:10:23.413697 26359 net.cpp:106] Creating Layer conv31
I0707 10:10:23.413712 26359 net.cpp:454] conv31 <- pool2
I0707 10:10:23.413723 26359 net.cpp:411] conv31 -> conv31
I0707 10:10:23.417930 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0707 10:10:23.417982 26359 net.cpp:150] Setting up conv31
I0707 10:10:23.417994 26359 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0707 10:10:23.418002 26359 net.cpp:165] Memory required for data: 852001200
I0707 10:10:23.418025 26359 layer_factory.hpp:76] Creating layer relu31
I0707 10:10:23.418051 26359 net.cpp:106] Creating Layer relu31
I0707 10:10:23.418061 26359 net.cpp:454] relu31 <- conv31
I0707 10:10:23.418071 26359 net.cpp:397] relu31 -> conv31 (in-place)
I0707 10:10:23.420100 26359 net.cpp:150] Setting up relu31
I0707 10:10:23.420140 26359 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0707 10:10:23.420156 26359 net.cpp:165] Memory required for data: 876001200
I0707 10:10:23.420169 26359 layer_factory.hpp:76] Creating layer conv32
I0707 10:10:23.420200 26359 net.cpp:106] Creating Layer conv32
I0707 10:10:23.420217 26359 net.cpp:454] conv32 <- conv31
I0707 10:10:23.420228 26359 net.cpp:411] conv32 -> conv32
I0707 10:10:23.425468 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0707 10:10:23.425542 26359 net.cpp:150] Setting up conv32
I0707 10:10:23.425575 26359 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0707 10:10:23.425590 26359 net.cpp:165] Memory required for data: 900001200
I0707 10:10:23.425621 26359 layer_factory.hpp:76] Creating layer relu32
I0707 10:10:23.425639 26359 net.cpp:106] Creating Layer relu32
I0707 10:10:23.425668 26359 net.cpp:454] relu32 <- conv32
I0707 10:10:23.425689 26359 net.cpp:397] relu32 -> conv32 (in-place)
I0707 10:10:23.426754 26359 net.cpp:150] Setting up relu32
I0707 10:10:23.426790 26359 net.cpp:157] Top shape: 100 96 25 25 (6000000)
I0707 10:10:23.426803 26359 net.cpp:165] Memory required for data: 924001200
I0707 10:10:23.426817 26359 layer_factory.hpp:76] Creating layer pool3
I0707 10:10:23.426859 26359 net.cpp:106] Creating Layer pool3
I0707 10:10:23.426874 26359 net.cpp:454] pool3 <- conv32
I0707 10:10:23.426900 26359 net.cpp:411] pool3 -> pool3
I0707 10:10:23.428275 26359 net.cpp:150] Setting up pool3
I0707 10:10:23.428313 26359 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I0707 10:10:23.428326 26359 net.cpp:165] Memory required for data: 930490800
I0707 10:10:23.428341 26359 layer_factory.hpp:76] Creating layer conv41
I0707 10:10:23.428369 26359 net.cpp:106] Creating Layer conv41
I0707 10:10:23.428385 26359 net.cpp:454] conv41 <- pool3
I0707 10:10:23.428419 26359 net.cpp:411] conv41 -> conv41
I0707 10:10:23.432541 26359 net.cpp:150] Setting up conv41
I0707 10:10:23.432592 26359 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0707 10:10:23.432607 26359 net.cpp:165] Memory required for data: 939143600
I0707 10:10:23.432627 26359 layer_factory.hpp:76] Creating layer relu41
I0707 10:10:23.432648 26359 net.cpp:106] Creating Layer relu41
I0707 10:10:23.432677 26359 net.cpp:454] relu41 <- conv41
I0707 10:10:23.432693 26359 net.cpp:397] relu41 -> conv41 (in-place)
I0707 10:10:23.433645 26359 net.cpp:150] Setting up relu41
I0707 10:10:23.433681 26359 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0707 10:10:23.433694 26359 net.cpp:165] Memory required for data: 947796400
I0707 10:10:23.433706 26359 layer_factory.hpp:76] Creating layer conv42
I0707 10:10:23.433732 26359 net.cpp:106] Creating Layer conv42
I0707 10:10:23.433760 26359 net.cpp:454] conv42 <- conv41
I0707 10:10:23.433781 26359 net.cpp:411] conv42 -> conv42
I0707 10:10:23.439934 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0707 10:10:23.440009 26359 net.cpp:150] Setting up conv42
I0707 10:10:23.440029 26359 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0707 10:10:23.440083 26359 net.cpp:165] Memory required for data: 956449200
I0707 10:10:23.440126 26359 layer_factory.hpp:76] Creating layer relu42
I0707 10:10:23.440161 26359 net.cpp:106] Creating Layer relu42
I0707 10:10:23.440176 26359 net.cpp:454] relu42 <- conv42
I0707 10:10:23.440212 26359 net.cpp:397] relu42 -> conv42 (in-place)
I0707 10:10:23.440976 26359 net.cpp:150] Setting up relu42
I0707 10:10:23.441066 26359 net.cpp:157] Top shape: 100 128 13 13 (2163200)
I0707 10:10:23.441081 26359 net.cpp:165] Memory required for data: 965102000
I0707 10:10:23.441094 26359 layer_factory.hpp:76] Creating layer pool4
I0707 10:10:23.441141 26359 net.cpp:106] Creating Layer pool4
I0707 10:10:23.441155 26359 net.cpp:454] pool4 <- conv42
I0707 10:10:23.441193 26359 net.cpp:411] pool4 -> pool4
I0707 10:10:23.443326 26359 net.cpp:150] Setting up pool4
I0707 10:10:23.443364 26359 net.cpp:157] Top shape: 100 128 7 7 (627200)
I0707 10:10:23.443377 26359 net.cpp:165] Memory required for data: 967610800
I0707 10:10:23.443390 26359 layer_factory.hpp:76] Creating layer conv51
I0707 10:10:23.443447 26359 net.cpp:106] Creating Layer conv51
I0707 10:10:23.443473 26359 net.cpp:454] conv51 <- pool4
I0707 10:10:23.443491 26359 net.cpp:411] conv51 -> conv51
I0707 10:10:23.449978 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0707 10:10:23.450044 26359 net.cpp:150] Setting up conv51
I0707 10:10:23.450065 26359 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0707 10:10:23.450093 26359 net.cpp:165] Memory required for data: 972628400
I0707 10:10:23.450151 26359 layer_factory.hpp:76] Creating layer relu51
I0707 10:10:23.450186 26359 net.cpp:106] Creating Layer relu51
I0707 10:10:23.450212 26359 net.cpp:454] relu51 <- conv51
I0707 10:10:23.450228 26359 net.cpp:397] relu51 -> conv51 (in-place)
I0707 10:10:23.451252 26359 net.cpp:150] Setting up relu51
I0707 10:10:23.451287 26359 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0707 10:10:23.451303 26359 net.cpp:165] Memory required for data: 977646000
I0707 10:10:23.451314 26359 layer_factory.hpp:76] Creating layer conv52
I0707 10:10:23.451339 26359 net.cpp:106] Creating Layer conv52
I0707 10:10:23.451367 26359 net.cpp:454] conv52 <- conv51
I0707 10:10:23.451403 26359 net.cpp:411] conv52 -> conv52
I0707 10:10:23.464648 26359 net.cpp:150] Setting up conv52
I0707 10:10:23.464716 26359 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0707 10:10:23.464732 26359 net.cpp:165] Memory required for data: 982663600
I0707 10:10:23.464758 26359 layer_factory.hpp:76] Creating layer relu52
I0707 10:10:23.464788 26359 net.cpp:106] Creating Layer relu52
I0707 10:10:23.464818 26359 net.cpp:454] relu52 <- conv52
I0707 10:10:23.464851 26359 net.cpp:397] relu52 -> conv52 (in-place)
I0707 10:10:23.465363 26359 net.cpp:150] Setting up relu52
I0707 10:10:23.465399 26359 net.cpp:157] Top shape: 100 256 7 7 (1254400)
I0707 10:10:23.465412 26359 net.cpp:165] Memory required for data: 987681200
I0707 10:10:23.465425 26359 layer_factory.hpp:76] Creating layer conv53
I0707 10:10:23.465458 26359 net.cpp:106] Creating Layer conv53
I0707 10:10:23.465486 26359 net.cpp:454] conv53 <- conv52
I0707 10:10:23.465508 26359 net.cpp:411] conv53 -> conv53
I0707 10:10:23.522505 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0707 10:10:23.522586 26359 net.cpp:150] Setting up conv53
I0707 10:10:23.522606 26359 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0707 10:10:23.522617 26359 net.cpp:165] Memory required for data: 987783600
I0707 10:10:23.522640 26359 layer_factory.hpp:76] Creating layer relu53
I0707 10:10:23.522668 26359 net.cpp:106] Creating Layer relu53
I0707 10:10:23.522681 26359 net.cpp:454] relu53 <- conv53
I0707 10:10:23.522696 26359 net.cpp:397] relu53 -> conv53 (in-place)
I0707 10:10:23.522976 26359 net.cpp:150] Setting up relu53
I0707 10:10:23.522994 26359 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0707 10:10:23.523002 26359 net.cpp:165] Memory required for data: 987886000
I0707 10:10:23.523010 26359 layer_factory.hpp:76] Creating layer drop6
I0707 10:10:23.523026 26359 net.cpp:106] Creating Layer drop6
I0707 10:10:23.523036 26359 net.cpp:454] drop6 <- conv53
I0707 10:10:23.523051 26359 net.cpp:411] drop6 -> drop6
I0707 10:10:23.523108 26359 net.cpp:150] Setting up drop6
I0707 10:10:23.523138 26359 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0707 10:10:23.523146 26359 net.cpp:165] Memory required for data: 987988400
I0707 10:10:23.523155 26359 layer_factory.hpp:76] Creating layer conv54
I0707 10:10:23.523211 26359 net.cpp:106] Creating Layer conv54
I0707 10:10:23.523223 26359 net.cpp:454] conv54 <- drop6
I0707 10:10:23.523234 26359 net.cpp:411] conv54 -> conv54
I0707 10:10:23.541052 26359 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0707 10:10:23.541147 26359 net.cpp:150] Setting up conv54
I0707 10:10:23.541175 26359 net.cpp:157] Top shape: 100 2 1 1 (200)
I0707 10:10:23.541195 26359 net.cpp:165] Memory required for data: 987989200
I0707 10:10:23.541214 26359 layer_factory.hpp:76] Creating layer conv54_conv54_0_split
I0707 10:10:23.541242 26359 net.cpp:106] Creating Layer conv54_conv54_0_split
I0707 10:10:23.541260 26359 net.cpp:454] conv54_conv54_0_split <- conv54
I0707 10:10:23.541275 26359 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_0
I0707 10:10:23.541296 26359 net.cpp:411] conv54_conv54_0_split -> conv54_conv54_0_split_1
I0707 10:10:23.541355 26359 net.cpp:150] Setting up conv54_conv54_0_split
I0707 10:10:23.541369 26359 net.cpp:157] Top shape: 100 2 1 1 (200)
I0707 10:10:23.541378 26359 net.cpp:157] Top shape: 100 2 1 1 (200)
I0707 10:10:23.541386 26359 net.cpp:165] Memory required for data: 987990800
I0707 10:10:23.541399 26359 layer_factory.hpp:76] Creating layer accuracy
I0707 10:10:23.541421 26359 net.cpp:106] Creating Layer accuracy
I0707 10:10:23.541435 26359 net.cpp:454] accuracy <- conv54_conv54_0_split_0
I0707 10:10:23.541443 26359 net.cpp:454] accuracy <- label_data_1_split_0
I0707 10:10:23.541455 26359 net.cpp:411] accuracy -> accuracy
I0707 10:10:23.541468 26359 net.cpp:150] Setting up accuracy
I0707 10:10:23.541478 26359 net.cpp:157] Top shape: (1)
I0707 10:10:23.541487 26359 net.cpp:165] Memory required for data: 987990804
I0707 10:10:23.541497 26359 layer_factory.hpp:76] Creating layer loss
I0707 10:10:23.541518 26359 net.cpp:106] Creating Layer loss
I0707 10:10:23.541528 26359 net.cpp:454] loss <- conv54_conv54_0_split_1
I0707 10:10:23.541538 26359 net.cpp:454] loss <- label_data_1_split_1
I0707 10:10:23.541548 26359 net.cpp:411] loss -> loss
I0707 10:10:23.541568 26359 layer_factory.hpp:76] Creating layer loss
I0707 10:10:23.542892 26359 net.cpp:150] Setting up loss
I0707 10:10:23.542927 26359 net.cpp:157] Top shape: (1)
I0707 10:10:23.542935 26359 net.cpp:160]     with loss weight 1
I0707 10:10:23.542954 26359 net.cpp:165] Memory required for data: 987990808
I0707 10:10:23.542963 26359 net.cpp:226] loss needs backward computation.
I0707 10:10:23.542973 26359 net.cpp:228] accuracy does not need backward computation.
I0707 10:10:23.542981 26359 net.cpp:226] conv54_conv54_0_split needs backward computation.
I0707 10:10:23.542989 26359 net.cpp:226] conv54 needs backward computation.
I0707 10:10:23.542999 26359 net.cpp:226] drop6 needs backward computation.
I0707 10:10:23.543010 26359 net.cpp:226] relu53 needs backward computation.
I0707 10:10:23.543018 26359 net.cpp:226] conv53 needs backward computation.
I0707 10:10:23.543026 26359 net.cpp:226] relu52 needs backward computation.
I0707 10:10:23.543040 26359 net.cpp:226] conv52 needs backward computation.
I0707 10:10:23.543051 26359 net.cpp:226] relu51 needs backward computation.
I0707 10:10:23.543061 26359 net.cpp:226] conv51 needs backward computation.
I0707 10:10:23.543069 26359 net.cpp:226] pool4 needs backward computation.
I0707 10:10:23.543078 26359 net.cpp:226] relu42 needs backward computation.
I0707 10:10:23.543088 26359 net.cpp:226] conv42 needs backward computation.
I0707 10:10:23.543097 26359 net.cpp:226] relu41 needs backward computation.
I0707 10:10:23.543105 26359 net.cpp:226] conv41 needs backward computation.
I0707 10:10:23.543113 26359 net.cpp:226] pool3 needs backward computation.
I0707 10:10:23.543121 26359 net.cpp:226] relu32 needs backward computation.
I0707 10:10:23.543129 26359 net.cpp:226] conv32 needs backward computation.
I0707 10:10:23.543138 26359 net.cpp:226] relu31 needs backward computation.
I0707 10:10:23.543145 26359 net.cpp:226] conv31 needs backward computation.
I0707 10:10:23.543154 26359 net.cpp:226] pool2 needs backward computation.
I0707 10:10:23.543198 26359 net.cpp:226] relu22 needs backward computation.
I0707 10:10:23.543208 26359 net.cpp:226] conv22 needs backward computation.
I0707 10:10:23.543216 26359 net.cpp:226] relu21 needs backward computation.
I0707 10:10:23.543225 26359 net.cpp:226] conv21 needs backward computation.
I0707 10:10:23.543233 26359 net.cpp:226] pool1 needs backward computation.
I0707 10:10:23.543241 26359 net.cpp:226] relu12 needs backward computation.
I0707 10:10:23.543251 26359 net.cpp:226] conv12 needs backward computation.
I0707 10:10:23.543259 26359 net.cpp:226] relu11 needs backward computation.
I0707 10:10:23.543267 26359 net.cpp:226] conv11 needs backward computation.
I0707 10:10:23.543275 26359 net.cpp:228] label_data_1_split does not need backward computation.
I0707 10:10:23.543284 26359 net.cpp:228] data does not need backward computation.
I0707 10:10:23.543294 26359 net.cpp:270] This network produces output accuracy
I0707 10:10:23.543303 26359 net.cpp:270] This network produces output loss
I0707 10:10:23.543329 26359 net.cpp:283] Network initialization done.
I0707 10:10:23.543560 26359 solver.cpp:59] Solver scaffolding done.
I0707 10:10:23.545143 26359 caffe.cpp:202] Resuming from models/cnn10_iter_201500.solverstate
I0707 10:10:25.035487 26359 sgd_solver.cpp:314] SGDSolver: restoring history
I0707 10:10:25.101492 26359 caffe.cpp:212] Starting Optimization
I0707 10:10:25.101579 26359 solver.cpp:287] Solving FaceNN
I0707 10:10:25.101593 26359 solver.cpp:288] Learning Rate Policy: fixed
I0707 10:10:25.103632 26359 solver.cpp:340] Iteration 201500, Testing net (#0)
I0707 10:10:25.131618 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 10:15:38.890818 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7867
I0707 10:15:38.921119 26359 solver.cpp:408]     Test net output #1: loss = 0.454262 (* 1 = 0.454262 loss)
I0707 10:15:39.203166 26359 solver.cpp:236] Iteration 201500, loss = 0.494897
I0707 10:15:39.203209 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 10:15:39.203227 26359 solver.cpp:252]     Train net output #1: loss = 0.494897 (* 1 = 0.494897 loss)
I0707 10:15:39.203241 26359 sgd_solver.cpp:106] Iteration 201500, lr = 0.005
I0707 10:22:08.387214 26359 solver.cpp:236] Iteration 201600, loss = 0.488382
I0707 10:22:08.448570 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 10:22:08.448598 26359 solver.cpp:252]     Train net output #1: loss = 0.431526 (* 1 = 0.431526 loss)
I0707 10:22:08.448604 26359 sgd_solver.cpp:106] Iteration 201600, lr = 0.005
I0707 10:28:24.081894 26359 solver.cpp:236] Iteration 201700, loss = 0.483318
I0707 10:28:24.124577 26359 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0707 10:28:24.124593 26359 solver.cpp:252]     Train net output #1: loss = 0.519826 (* 1 = 0.519826 loss)
I0707 10:28:24.124601 26359 sgd_solver.cpp:106] Iteration 201700, lr = 0.005
I0707 10:31:26.734045 26359 solver.cpp:340] Iteration 201750, Testing net (#0)
I0707 10:36:11.821113 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7869
I0707 10:36:11.870642 26359 solver.cpp:408]     Test net output #1: loss = 0.455344 (* 1 = 0.455344 loss)
I0707 10:39:18.008882 26359 solver.cpp:236] Iteration 201800, loss = 0.472142
I0707 10:39:18.042809 26359 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0707 10:39:18.042836 26359 solver.cpp:252]     Train net output #1: loss = 0.503177 (* 1 = 0.503177 loss)
I0707 10:39:18.042848 26359 sgd_solver.cpp:106] Iteration 201800, lr = 0.005
I0707 10:45:52.219137 26359 solver.cpp:236] Iteration 201900, loss = 0.466817
I0707 10:45:52.242837 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 10:45:52.242890 26359 solver.cpp:252]     Train net output #1: loss = 0.412568 (* 1 = 0.412568 loss)
I0707 10:45:52.242903 26359 sgd_solver.cpp:106] Iteration 201900, lr = 0.005
I0707 10:51:52.606240 26359 solver.cpp:340] Iteration 202000, Testing net (#0)
I0707 10:57:05.451643 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7863
I0707 10:57:05.451836 26359 solver.cpp:408]     Test net output #1: loss = 0.463089 (* 1 = 0.463089 loss)
I0707 10:57:05.587685 26359 solver.cpp:236] Iteration 202000, loss = 0.463846
I0707 10:57:05.587754 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 10:57:05.587782 26359 solver.cpp:252]     Train net output #1: loss = 0.451656 (* 1 = 0.451656 loss)
I0707 10:57:05.587806 26359 sgd_solver.cpp:106] Iteration 202000, lr = 0.005
I0707 11:03:29.132012 26359 solver.cpp:236] Iteration 202100, loss = 0.453743
I0707 11:03:29.132282 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 11:03:29.132320 26359 solver.cpp:252]     Train net output #1: loss = 0.486061 (* 1 = 0.486061 loss)
I0707 11:03:29.132344 26359 sgd_solver.cpp:106] Iteration 202100, lr = 0.005
I0707 11:10:46.247423 26359 solver.cpp:236] Iteration 202200, loss = 0.457584
I0707 11:10:46.247660 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 11:10:46.247694 26359 solver.cpp:252]     Train net output #1: loss = 0.498775 (* 1 = 0.498775 loss)
I0707 11:10:46.247722 26359 sgd_solver.cpp:106] Iteration 202200, lr = 0.005
I0707 11:11:54.527943 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 11:14:47.585172 26359 solver.cpp:340] Iteration 202250, Testing net (#0)
I0707 11:20:10.577520 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7539
I0707 11:20:10.577647 26359 solver.cpp:408]     Test net output #1: loss = 0.49528 (* 1 = 0.49528 loss)
I0707 11:22:35.603234 26359 solver.cpp:236] Iteration 202300, loss = 0.470197
I0707 11:22:35.603399 26359 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0707 11:22:35.603442 26359 solver.cpp:252]     Train net output #1: loss = 0.515308 (* 1 = 0.515308 loss)
I0707 11:22:35.603461 26359 sgd_solver.cpp:106] Iteration 202300, lr = 0.005
I0707 11:27:16.150115 26359 solver.cpp:236] Iteration 202400, loss = 0.456768
I0707 11:27:16.150336 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 11:27:16.150380 26359 solver.cpp:252]     Train net output #1: loss = 0.432293 (* 1 = 0.432293 loss)
I0707 11:27:16.150403 26359 sgd_solver.cpp:106] Iteration 202400, lr = 0.005
I0707 11:31:13.281276 26359 solver.cpp:340] Iteration 202500, Testing net (#0)
I0707 11:33:48.386950 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7778
I0707 11:33:48.387092 26359 solver.cpp:408]     Test net output #1: loss = 0.463139 (* 1 = 0.463139 loss)
I0707 11:33:48.599825 26359 solver.cpp:236] Iteration 202500, loss = 0.463291
I0707 11:33:48.599870 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 11:33:48.599886 26359 solver.cpp:252]     Train net output #1: loss = 0.467494 (* 1 = 0.467494 loss)
I0707 11:33:48.599897 26359 sgd_solver.cpp:106] Iteration 202500, lr = 0.005
I0707 11:37:21.422864 26359 solver.cpp:236] Iteration 202600, loss = 0.477518
I0707 11:37:21.423045 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 11:37:21.423064 26359 solver.cpp:252]     Train net output #1: loss = 0.487008 (* 1 = 0.487008 loss)
I0707 11:37:21.423079 26359 sgd_solver.cpp:106] Iteration 202600, lr = 0.005
I0707 11:41:03.279636 26359 solver.cpp:236] Iteration 202700, loss = 0.461337
I0707 11:41:03.279786 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 11:41:03.279804 26359 solver.cpp:252]     Train net output #1: loss = 0.470795 (* 1 = 0.470795 loss)
I0707 11:41:03.279815 26359 sgd_solver.cpp:106] Iteration 202700, lr = 0.005
I0707 11:42:52.319839 26359 solver.cpp:340] Iteration 202750, Testing net (#0)
I0707 11:46:12.821506 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7888
I0707 11:46:12.821657 26359 solver.cpp:408]     Test net output #1: loss = 0.455868 (* 1 = 0.455868 loss)
I0707 11:49:10.545372 26359 solver.cpp:236] Iteration 202800, loss = 0.460217
I0707 11:49:10.545572 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 11:49:10.545593 26359 solver.cpp:252]     Train net output #1: loss = 0.450774 (* 1 = 0.450774 loss)
I0707 11:49:10.545604 26359 sgd_solver.cpp:106] Iteration 202800, lr = 0.005
I0707 11:55:26.240574 26359 solver.cpp:236] Iteration 202900, loss = 0.460908
I0707 11:55:26.240777 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 11:55:26.240805 26359 solver.cpp:252]     Train net output #1: loss = 0.466291 (* 1 = 0.466291 loss)
I0707 11:55:26.240813 26359 sgd_solver.cpp:106] Iteration 202900, lr = 0.005
I0707 11:57:27.577311 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 12:01:38.565160 26359 solver.cpp:340] Iteration 203000, Testing net (#0)
I0707 12:06:18.226130 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7797
I0707 12:06:18.226265 26359 solver.cpp:408]     Test net output #1: loss = 0.472635 (* 1 = 0.472635 loss)
I0707 12:06:18.364841 26359 solver.cpp:236] Iteration 203000, loss = 0.478845
I0707 12:06:18.364886 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 12:06:18.364902 26359 solver.cpp:252]     Train net output #1: loss = 0.452981 (* 1 = 0.452981 loss)
I0707 12:06:18.364913 26359 sgd_solver.cpp:106] Iteration 203000, lr = 0.005
I0707 12:12:29.981292 26359 solver.cpp:236] Iteration 203100, loss = 0.464828
I0707 12:12:29.981595 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 12:12:29.981626 26359 solver.cpp:252]     Train net output #1: loss = 0.469999 (* 1 = 0.469999 loss)
I0707 12:12:29.981639 26359 sgd_solver.cpp:106] Iteration 203100, lr = 0.005
I0707 12:18:29.578744 26359 solver.cpp:236] Iteration 203200, loss = 0.463477
I0707 12:18:29.578896 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 12:18:29.578917 26359 solver.cpp:252]     Train net output #1: loss = 0.420011 (* 1 = 0.420011 loss)
I0707 12:18:29.578928 26359 sgd_solver.cpp:106] Iteration 203200, lr = 0.005
I0707 12:21:24.703178 26359 solver.cpp:340] Iteration 203250, Testing net (#0)
I0707 12:25:34.553133 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7493
I0707 12:25:34.553309 26359 solver.cpp:408]     Test net output #1: loss = 0.510586 (* 1 = 0.510586 loss)
I0707 12:28:28.495865 26359 solver.cpp:236] Iteration 203300, loss = 0.480257
I0707 12:28:28.496002 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 12:28:28.496034 26359 solver.cpp:252]     Train net output #1: loss = 0.44472 (* 1 = 0.44472 loss)
I0707 12:28:28.496062 26359 sgd_solver.cpp:106] Iteration 203300, lr = 0.005
I0707 12:34:36.071529 26359 solver.cpp:236] Iteration 203400, loss = 0.46896
I0707 12:34:36.071682 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 12:34:36.071715 26359 solver.cpp:252]     Train net output #1: loss = 0.448456 (* 1 = 0.448456 loss)
I0707 12:34:36.071738 26359 sgd_solver.cpp:106] Iteration 203400, lr = 0.005
I0707 12:40:48.816321 26359 solver.cpp:340] Iteration 203500, Testing net (#0)
I0707 12:45:07.047724 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7824
I0707 12:45:07.047878 26359 solver.cpp:408]     Test net output #1: loss = 0.465478 (* 1 = 0.465478 loss)
I0707 12:45:07.360646 26359 solver.cpp:236] Iteration 203500, loss = 0.491552
I0707 12:45:07.360707 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 12:45:07.360733 26359 solver.cpp:252]     Train net output #1: loss = 0.426926 (* 1 = 0.426926 loss)
I0707 12:45:07.360759 26359 sgd_solver.cpp:106] Iteration 203500, lr = 0.005
I0707 12:49:46.472836 26359 solver.cpp:236] Iteration 203600, loss = 0.480268
I0707 12:49:46.473011 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 12:49:46.473037 26359 solver.cpp:252]     Train net output #1: loss = 0.484095 (* 1 = 0.484095 loss)
I0707 12:49:46.473047 26359 sgd_solver.cpp:106] Iteration 203600, lr = 0.005
I0707 12:51:33.999069 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 12:53:19.635793 26359 solver.cpp:236] Iteration 203700, loss = 0.471217
I0707 12:53:19.635987 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 12:53:19.636005 26359 solver.cpp:252]     Train net output #1: loss = 0.525095 (* 1 = 0.525095 loss)
I0707 12:53:19.636015 26359 sgd_solver.cpp:106] Iteration 203700, lr = 0.005
I0707 12:55:02.118821 26359 solver.cpp:340] Iteration 203750, Testing net (#0)
I0707 12:57:21.952548 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7848
I0707 12:57:21.952713 26359 solver.cpp:408]     Test net output #1: loss = 0.455811 (* 1 = 0.455811 loss)
I0707 12:59:02.962829 26359 solver.cpp:236] Iteration 203800, loss = 0.458098
I0707 12:59:02.962998 26359 solver.cpp:252]     Train net output #0: accuracy = 0.890625
I0707 12:59:02.963048 26359 solver.cpp:252]     Train net output #1: loss = 0.357474 (* 1 = 0.357474 loss)
I0707 12:59:02.963086 26359 sgd_solver.cpp:106] Iteration 203800, lr = 0.005
I0707 13:02:33.172703 26359 solver.cpp:236] Iteration 203900, loss = 0.476134
I0707 13:02:33.172863 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 13:02:33.172895 26359 solver.cpp:252]     Train net output #1: loss = 0.474152 (* 1 = 0.474152 loss)
I0707 13:02:33.172914 26359 sgd_solver.cpp:106] Iteration 203900, lr = 0.005
I0707 13:06:01.819026 26359 solver.cpp:340] Iteration 204000, Testing net (#0)
I0707 13:08:31.173115 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7746
I0707 13:08:31.173321 26359 solver.cpp:408]     Test net output #1: loss = 0.477063 (* 1 = 0.477063 loss)
I0707 13:08:31.481897 26359 solver.cpp:236] Iteration 204000, loss = 0.492328
I0707 13:08:31.481943 26359 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0707 13:08:31.481961 26359 solver.cpp:252]     Train net output #1: loss = 0.540367 (* 1 = 0.540367 loss)
I0707 13:08:31.481972 26359 sgd_solver.cpp:106] Iteration 204000, lr = 0.005
I0707 13:12:07.112144 26359 solver.cpp:236] Iteration 204100, loss = 0.476831
I0707 13:12:07.112318 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 13:12:07.112347 26359 solver.cpp:252]     Train net output #1: loss = 0.475277 (* 1 = 0.475277 loss)
I0707 13:12:07.112370 26359 sgd_solver.cpp:106] Iteration 204100, lr = 0.005
I0707 13:15:56.227358 26359 solver.cpp:236] Iteration 204200, loss = 0.497233
I0707 13:15:56.227601 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 13:15:56.227627 26359 solver.cpp:252]     Train net output #1: loss = 0.469826 (* 1 = 0.469826 loss)
I0707 13:15:56.227640 26359 sgd_solver.cpp:106] Iteration 204200, lr = 0.005
I0707 13:17:48.408774 26359 solver.cpp:340] Iteration 204250, Testing net (#0)
I0707 13:20:14.712285 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7608
I0707 13:20:14.712517 26359 solver.cpp:408]     Test net output #1: loss = 0.490613 (* 1 = 0.490613 loss)
I0707 13:21:58.967279 26359 solver.cpp:236] Iteration 204300, loss = 0.476907
I0707 13:21:58.967433 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 13:21:58.967464 26359 solver.cpp:252]     Train net output #1: loss = 0.427312 (* 1 = 0.427312 loss)
I0707 13:21:58.967494 26359 sgd_solver.cpp:106] Iteration 204300, lr = 0.005
I0707 13:24:30.579100 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 13:25:36.325268 26359 solver.cpp:236] Iteration 204400, loss = 0.479593
I0707 13:25:36.325434 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 13:25:36.325453 26359 solver.cpp:252]     Train net output #1: loss = 0.437767 (* 1 = 0.437767 loss)
I0707 13:25:36.325467 26359 sgd_solver.cpp:106] Iteration 204400, lr = 0.005
I0707 13:29:08.361726 26359 solver.cpp:340] Iteration 204500, Testing net (#0)
I0707 13:30:50.312337 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7857
I0707 13:30:50.312533 26359 solver.cpp:408]     Test net output #1: loss = 0.461843 (* 1 = 0.461843 loss)
I0707 13:30:50.525524 26359 solver.cpp:236] Iteration 204500, loss = 0.478116
I0707 13:30:50.525565 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 13:30:50.525590 26359 solver.cpp:252]     Train net output #1: loss = 0.539375 (* 1 = 0.539375 loss)
I0707 13:30:50.525606 26359 sgd_solver.cpp:106] Iteration 204500, lr = 0.005
I0707 13:34:25.394791 26359 solver.cpp:236] Iteration 204600, loss = 0.50034
I0707 13:34:25.394953 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 13:34:25.394989 26359 solver.cpp:252]     Train net output #1: loss = 0.495157 (* 1 = 0.495157 loss)
I0707 13:34:25.395000 26359 sgd_solver.cpp:106] Iteration 204600, lr = 0.005
I0707 13:38:02.096930 26359 solver.cpp:236] Iteration 204700, loss = 0.467634
I0707 13:38:02.097064 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 13:38:02.097096 26359 solver.cpp:252]     Train net output #1: loss = 0.507171 (* 1 = 0.507171 loss)
I0707 13:38:02.097123 26359 sgd_solver.cpp:106] Iteration 204700, lr = 0.005
I0707 13:39:49.341045 26359 solver.cpp:340] Iteration 204750, Testing net (#0)
I0707 13:42:15.240303 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7741
I0707 13:42:15.240543 26359 solver.cpp:408]     Test net output #1: loss = 0.47135 (* 1 = 0.47135 loss)
I0707 13:44:01.863003 26359 solver.cpp:236] Iteration 204800, loss = 0.474523
I0707 13:44:01.863272 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 13:44:01.863318 26359 solver.cpp:252]     Train net output #1: loss = 0.457991 (* 1 = 0.457991 loss)
I0707 13:44:01.863330 26359 sgd_solver.cpp:106] Iteration 204800, lr = 0.005
I0707 13:46:54.153831 26359 solver.cpp:236] Iteration 204900, loss = 0.484502
I0707 13:46:54.154017 26359 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 13:46:54.154036 26359 solver.cpp:252]     Train net output #1: loss = 0.439341 (* 1 = 0.439341 loss)
I0707 13:46:54.154044 26359 sgd_solver.cpp:106] Iteration 204900, lr = 0.005
I0707 13:49:48.790763 26359 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_205000.caffemodel
I0707 13:49:49.575393 26359 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_205000.solverstate
I0707 13:49:49.605561 26359 solver.cpp:340] Iteration 205000, Testing net (#0)
I0707 13:50:58.193085 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7879
I0707 13:50:58.193245 26359 solver.cpp:408]     Test net output #1: loss = 0.456163 (* 1 = 0.456163 loss)
I0707 13:50:58.331400 26359 solver.cpp:236] Iteration 205000, loss = 0.482633
I0707 13:50:58.331456 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 13:50:58.331475 26359 solver.cpp:252]     Train net output #1: loss = 0.443187 (* 1 = 0.443187 loss)
I0707 13:50:58.331485 26359 sgd_solver.cpp:106] Iteration 205000, lr = 0.005
I0707 13:53:40.708073 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 13:54:01.618211 26359 solver.cpp:236] Iteration 205100, loss = 0.489453
I0707 13:54:01.618263 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 13:54:01.618279 26359 solver.cpp:252]     Train net output #1: loss = 0.481483 (* 1 = 0.481483 loss)
I0707 13:54:01.618290 26359 sgd_solver.cpp:106] Iteration 205100, lr = 0.005
I0707 13:57:10.788662 26359 solver.cpp:236] Iteration 205200, loss = 0.476285
I0707 13:57:10.788851 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 13:57:10.788882 26359 solver.cpp:252]     Train net output #1: loss = 0.426769 (* 1 = 0.426769 loss)
I0707 13:57:10.788889 26359 sgd_solver.cpp:106] Iteration 205200, lr = 0.005
I0707 13:58:46.075399 26359 solver.cpp:340] Iteration 205250, Testing net (#0)
I0707 14:00:23.897080 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7848
I0707 14:00:23.897218 26359 solver.cpp:408]     Test net output #1: loss = 0.462032 (* 1 = 0.462032 loss)
I0707 14:01:59.206614 26359 solver.cpp:236] Iteration 205300, loss = 0.485058
I0707 14:01:59.206775 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 14:01:59.206805 26359 solver.cpp:252]     Train net output #1: loss = 0.438184 (* 1 = 0.438184 loss)
I0707 14:01:59.206820 26359 sgd_solver.cpp:106] Iteration 205300, lr = 0.005
I0707 14:05:18.163836 26359 solver.cpp:236] Iteration 205400, loss = 0.479675
I0707 14:05:18.165909 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 14:05:18.165947 26359 solver.cpp:252]     Train net output #1: loss = 0.491353 (* 1 = 0.491353 loss)
I0707 14:05:18.165973 26359 sgd_solver.cpp:106] Iteration 205400, lr = 0.005
I0707 14:08:35.622078 26359 solver.cpp:340] Iteration 205500, Testing net (#0)
I0707 14:09:50.085880 26359 solver.cpp:408]     Test net output #0: accuracy = 0.788
I0707 14:09:50.086081 26359 solver.cpp:408]     Test net output #1: loss = 0.461557 (* 1 = 0.461557 loss)
I0707 14:09:50.408826 26359 solver.cpp:236] Iteration 205500, loss = 0.483487
I0707 14:09:50.408890 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 14:09:50.408915 26359 solver.cpp:252]     Train net output #1: loss = 0.468836 (* 1 = 0.468836 loss)
I0707 14:09:50.408932 26359 sgd_solver.cpp:106] Iteration 205500, lr = 0.005
I0707 14:13:17.069190 26359 solver.cpp:236] Iteration 205600, loss = 0.473887
I0707 14:13:17.069461 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 14:13:17.069501 26359 solver.cpp:252]     Train net output #1: loss = 0.458003 (* 1 = 0.458003 loss)
I0707 14:13:17.069524 26359 sgd_solver.cpp:106] Iteration 205600, lr = 0.005
I0707 14:16:49.528434 26359 solver.cpp:236] Iteration 205700, loss = 0.478567
I0707 14:16:49.528594 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 14:16:49.528628 26359 solver.cpp:252]     Train net output #1: loss = 0.539137 (* 1 = 0.539137 loss)
I0707 14:16:49.528657 26359 sgd_solver.cpp:106] Iteration 205700, lr = 0.005
I0707 14:18:33.335680 26359 solver.cpp:340] Iteration 205750, Testing net (#0)
I0707 14:19:36.912987 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7553
I0707 14:19:36.913156 26359 solver.cpp:408]     Test net output #1: loss = 0.498479 (* 1 = 0.498479 loss)
I0707 14:21:18.576889 26359 solver.cpp:236] Iteration 205800, loss = 0.474487
I0707 14:21:18.577036 26359 solver.cpp:252]     Train net output #0: accuracy = 0.671875
I0707 14:21:18.577054 26359 solver.cpp:252]     Train net output #1: loss = 0.668243 (* 1 = 0.668243 loss)
I0707 14:21:18.577061 26359 sgd_solver.cpp:106] Iteration 205800, lr = 0.005
I0707 14:21:35.713836 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 14:24:51.386054 26359 solver.cpp:236] Iteration 205900, loss = 0.482536
I0707 14:24:51.386204 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 14:24:51.386224 26359 solver.cpp:252]     Train net output #1: loss = 0.502598 (* 1 = 0.502598 loss)
I0707 14:24:51.386234 26359 sgd_solver.cpp:106] Iteration 205900, lr = 0.005
I0707 14:28:21.935256 26359 solver.cpp:340] Iteration 206000, Testing net (#0)
I0707 14:29:23.715400 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7823
I0707 14:29:23.715541 26359 solver.cpp:408]     Test net output #1: loss = 0.468572 (* 1 = 0.468572 loss)
I0707 14:29:24.038532 26359 solver.cpp:236] Iteration 206000, loss = 0.486997
I0707 14:29:24.038579 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 14:29:24.038595 26359 solver.cpp:252]     Train net output #1: loss = 0.514454 (* 1 = 0.514454 loss)
I0707 14:29:24.038606 26359 sgd_solver.cpp:106] Iteration 206000, lr = 0.005
I0707 14:32:53.448808 26359 solver.cpp:236] Iteration 206100, loss = 0.466631
I0707 14:32:53.449017 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 14:32:53.449069 26359 solver.cpp:252]     Train net output #1: loss = 0.498189 (* 1 = 0.498189 loss)
I0707 14:32:53.449112 26359 sgd_solver.cpp:106] Iteration 206100, lr = 0.005
I0707 14:36:26.091816 26359 solver.cpp:236] Iteration 206200, loss = 0.460219
I0707 14:36:26.091979 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 14:36:26.092011 26359 solver.cpp:252]     Train net output #1: loss = 0.439075 (* 1 = 0.439075 loss)
I0707 14:36:26.092022 26359 sgd_solver.cpp:106] Iteration 206200, lr = 0.005
I0707 14:38:12.424527 26359 solver.cpp:340] Iteration 206250, Testing net (#0)
I0707 14:39:12.100638 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7685
I0707 14:39:12.100829 26359 solver.cpp:408]     Test net output #1: loss = 0.481177 (* 1 = 0.481177 loss)
I0707 14:40:59.885537 26359 solver.cpp:236] Iteration 206300, loss = 0.480365
I0707 14:40:59.885735 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 14:40:59.885778 26359 solver.cpp:252]     Train net output #1: loss = 0.427846 (* 1 = 0.427846 loss)
I0707 14:40:59.885802 26359 sgd_solver.cpp:106] Iteration 206300, lr = 0.005
I0707 14:44:38.556614 26359 solver.cpp:236] Iteration 206400, loss = 0.462538
I0707 14:44:38.556764 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 14:44:38.556795 26359 solver.cpp:252]     Train net output #1: loss = 0.536008 (* 1 = 0.536008 loss)
I0707 14:44:38.556809 26359 sgd_solver.cpp:106] Iteration 206400, lr = 0.005
I0707 14:47:51.099092 26359 solver.cpp:340] Iteration 206500, Testing net (#0)
I0707 14:48:48.141979 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7849
I0707 14:48:48.142377 26359 solver.cpp:408]     Test net output #1: loss = 0.458159 (* 1 = 0.458159 loss)
I0707 14:48:48.377423 26359 solver.cpp:236] Iteration 206500, loss = 0.467564
I0707 14:48:48.377485 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 14:48:48.377503 26359 solver.cpp:252]     Train net output #1: loss = 0.482427 (* 1 = 0.482427 loss)
I0707 14:48:48.377523 26359 sgd_solver.cpp:106] Iteration 206500, lr = 0.005
I0707 14:49:35.221817 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 14:51:38.953686 26359 solver.cpp:236] Iteration 206600, loss = 0.480505
I0707 14:51:38.962611 26359 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0707 14:51:38.962653 26359 solver.cpp:252]     Train net output #1: loss = 0.531519 (* 1 = 0.531519 loss)
I0707 14:51:38.962673 26359 sgd_solver.cpp:106] Iteration 206600, lr = 0.005
I0707 14:54:41.096263 26359 solver.cpp:236] Iteration 206700, loss = 0.491725
I0707 14:54:41.096401 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 14:54:41.096436 26359 solver.cpp:252]     Train net output #1: loss = 0.501326 (* 1 = 0.501326 loss)
I0707 14:54:41.096448 26359 sgd_solver.cpp:106] Iteration 206700, lr = 0.005
I0707 14:56:12.144853 26359 solver.cpp:340] Iteration 206750, Testing net (#0)
I0707 14:57:06.358860 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7835
I0707 14:57:06.359030 26359 solver.cpp:408]     Test net output #1: loss = 0.460607 (* 1 = 0.460607 loss)
I0707 14:58:36.516765 26359 solver.cpp:236] Iteration 206800, loss = 0.462592
I0707 14:58:36.516887 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 14:58:36.516906 26359 solver.cpp:252]     Train net output #1: loss = 0.425367 (* 1 = 0.425367 loss)
I0707 14:58:36.516916 26359 sgd_solver.cpp:106] Iteration 206800, lr = 0.005
I0707 15:01:46.258097 26359 solver.cpp:236] Iteration 206900, loss = 0.472559
I0707 15:01:46.258240 26359 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 15:01:46.258260 26359 solver.cpp:252]     Train net output #1: loss = 0.418961 (* 1 = 0.418961 loss)
I0707 15:01:46.258270 26359 sgd_solver.cpp:106] Iteration 206900, lr = 0.005
I0707 15:04:57.869671 26359 solver.cpp:340] Iteration 207000, Testing net (#0)
I0707 15:05:55.808497 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7819
I0707 15:05:55.808634 26359 solver.cpp:408]     Test net output #1: loss = 0.466371 (* 1 = 0.466371 loss)
I0707 15:05:56.041870 26359 solver.cpp:236] Iteration 207000, loss = 0.490791
I0707 15:05:56.041952 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 15:05:56.041990 26359 solver.cpp:252]     Train net output #1: loss = 0.504772 (* 1 = 0.504772 loss)
I0707 15:05:56.042016 26359 sgd_solver.cpp:106] Iteration 207000, lr = 0.005
I0707 15:09:13.190426 26359 solver.cpp:236] Iteration 207100, loss = 0.476213
I0707 15:09:13.190582 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 15:09:13.190606 26359 solver.cpp:252]     Train net output #1: loss = 0.479233 (* 1 = 0.479233 loss)
I0707 15:09:13.190618 26359 sgd_solver.cpp:106] Iteration 207100, lr = 0.005
I0707 15:12:35.505038 26359 solver.cpp:236] Iteration 207200, loss = 0.4648
I0707 15:12:35.505193 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 15:12:35.505242 26359 solver.cpp:252]     Train net output #1: loss = 0.446128 (* 1 = 0.446128 loss)
I0707 15:12:35.505280 26359 sgd_solver.cpp:106] Iteration 207200, lr = 0.005
I0707 15:14:13.011283 26359 solver.cpp:340] Iteration 207250, Testing net (#0)
I0707 15:15:04.058331 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 15:15:06.067970 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7919
I0707 15:15:06.068032 26359 solver.cpp:408]     Test net output #1: loss = 0.448146 (* 1 = 0.448146 loss)
I0707 15:16:41.376011 26359 solver.cpp:236] Iteration 207300, loss = 0.47136
I0707 15:16:41.376134 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 15:16:41.376155 26359 solver.cpp:252]     Train net output #1: loss = 0.4468 (* 1 = 0.4468 loss)
I0707 15:16:41.376168 26359 sgd_solver.cpp:106] Iteration 207300, lr = 0.005
I0707 15:20:03.138356 26359 solver.cpp:236] Iteration 207400, loss = 0.471667
I0707 15:20:03.138510 26359 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0707 15:20:03.138530 26359 solver.cpp:252]     Train net output #1: loss = 0.55513 (* 1 = 0.55513 loss)
I0707 15:20:03.138541 26359 sgd_solver.cpp:106] Iteration 207400, lr = 0.005
I0707 15:23:22.182267 26359 solver.cpp:340] Iteration 207500, Testing net (#0)
I0707 15:24:17.140009 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7783
I0707 15:24:17.140192 26359 solver.cpp:408]     Test net output #1: loss = 0.473154 (* 1 = 0.473154 loss)
I0707 15:24:17.278192 26359 solver.cpp:236] Iteration 207500, loss = 0.473668
I0707 15:24:17.278249 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 15:24:17.278267 26359 solver.cpp:252]     Train net output #1: loss = 0.494388 (* 1 = 0.494388 loss)
I0707 15:24:17.278278 26359 sgd_solver.cpp:106] Iteration 207500, lr = 0.005
I0707 15:27:43.661484 26359 solver.cpp:236] Iteration 207600, loss = 0.464462
I0707 15:27:43.661664 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 15:27:43.661695 26359 solver.cpp:252]     Train net output #1: loss = 0.407309 (* 1 = 0.407309 loss)
I0707 15:27:43.661705 26359 sgd_solver.cpp:106] Iteration 207600, lr = 0.005
I0707 15:31:08.504199 26359 solver.cpp:236] Iteration 207700, loss = 0.484401
I0707 15:31:08.504364 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 15:31:08.504386 26359 solver.cpp:252]     Train net output #1: loss = 0.419671 (* 1 = 0.419671 loss)
I0707 15:31:08.504398 26359 sgd_solver.cpp:106] Iteration 207700, lr = 0.005
I0707 15:32:50.677995 26359 solver.cpp:340] Iteration 207750, Testing net (#0)
I0707 15:33:45.158620 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7345
I0707 15:33:45.158787 26359 solver.cpp:408]     Test net output #1: loss = 0.53571 (* 1 = 0.53571 loss)
I0707 15:35:35.668660 26359 solver.cpp:236] Iteration 207800, loss = 0.493259
I0707 15:35:35.668843 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 15:35:35.668861 26359 solver.cpp:252]     Train net output #1: loss = 0.502199 (* 1 = 0.502199 loss)
I0707 15:35:35.668879 26359 sgd_solver.cpp:106] Iteration 207800, lr = 0.005
I0707 15:39:26.381393 26359 solver.cpp:236] Iteration 207900, loss = 0.469471
I0707 15:39:26.381526 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 15:39:26.381546 26359 solver.cpp:252]     Train net output #1: loss = 0.445212 (* 1 = 0.445212 loss)
I0707 15:39:26.381561 26359 sgd_solver.cpp:106] Iteration 207900, lr = 0.005
I0707 15:44:49.985525 26359 solver.cpp:340] Iteration 208000, Testing net (#0)
I0707 15:45:40.024273 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 15:46:05.731674 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7926
I0707 15:46:05.731727 26359 solver.cpp:408]     Test net output #1: loss = 0.45116 (* 1 = 0.45116 loss)
I0707 15:46:05.941349 26359 solver.cpp:236] Iteration 208000, loss = 0.475228
I0707 15:46:05.941411 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 15:46:05.941426 26359 solver.cpp:252]     Train net output #1: loss = 0.442989 (* 1 = 0.442989 loss)
I0707 15:46:05.941437 26359 sgd_solver.cpp:106] Iteration 208000, lr = 0.005
I0707 15:52:17.560252 26359 solver.cpp:236] Iteration 208100, loss = 0.484584
I0707 15:52:17.560427 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 15:52:17.560456 26359 solver.cpp:252]     Train net output #1: loss = 0.460904 (* 1 = 0.460904 loss)
I0707 15:52:17.560483 26359 sgd_solver.cpp:106] Iteration 208100, lr = 0.005
I0707 15:57:53.358999 26359 solver.cpp:236] Iteration 208200, loss = 0.471981
I0707 15:57:53.359144 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 15:57:53.359165 26359 solver.cpp:252]     Train net output #1: loss = 0.501324 (* 1 = 0.501324 loss)
I0707 15:57:53.359177 26359 sgd_solver.cpp:106] Iteration 208200, lr = 0.005
I0707 16:00:39.188868 26359 solver.cpp:340] Iteration 208250, Testing net (#0)
I0707 16:02:25.960440 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7895
I0707 16:02:25.960603 26359 solver.cpp:408]     Test net output #1: loss = 0.454604 (* 1 = 0.454604 loss)
I0707 16:05:11.106746 26359 solver.cpp:236] Iteration 208300, loss = 0.452708
I0707 16:05:11.106899 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0707 16:05:11.106928 26359 solver.cpp:252]     Train net output #1: loss = 0.409753 (* 1 = 0.409753 loss)
I0707 16:05:11.106940 26359 sgd_solver.cpp:106] Iteration 208300, lr = 0.005
I0707 16:11:08.972998 26359 solver.cpp:236] Iteration 208400, loss = 0.467897
I0707 16:11:08.976521 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 16:11:08.976549 26359 solver.cpp:252]     Train net output #1: loss = 0.557671 (* 1 = 0.557671 loss)
I0707 16:11:08.976562 26359 sgd_solver.cpp:106] Iteration 208400, lr = 0.005
I0707 16:17:07.929659 26359 solver.cpp:340] Iteration 208500, Testing net (#0)
I0707 16:19:34.165905 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7771
I0707 16:19:34.166105 26359 solver.cpp:408]     Test net output #1: loss = 0.472643 (* 1 = 0.472643 loss)
I0707 16:19:34.369915 26359 solver.cpp:236] Iteration 208500, loss = 0.479438
I0707 16:19:34.369963 26359 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 16:19:34.369977 26359 solver.cpp:252]     Train net output #1: loss = 0.40344 (* 1 = 0.40344 loss)
I0707 16:19:34.369988 26359 sgd_solver.cpp:106] Iteration 208500, lr = 0.005
I0707 16:25:27.385967 26359 solver.cpp:236] Iteration 208600, loss = 0.481169
I0707 16:25:27.386114 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 16:25:27.386138 26359 solver.cpp:252]     Train net output #1: loss = 0.384636 (* 1 = 0.384636 loss)
I0707 16:25:27.386157 26359 sgd_solver.cpp:106] Iteration 208600, lr = 0.005
I0707 16:31:30.321029 26359 solver.cpp:236] Iteration 208700, loss = 0.470704
I0707 16:31:30.321162 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 16:31:30.321199 26359 solver.cpp:252]     Train net output #1: loss = 0.47143 (* 1 = 0.47143 loss)
I0707 16:31:30.321218 26359 sgd_solver.cpp:106] Iteration 208700, lr = 0.005
I0707 16:34:28.696735 26359 solver.cpp:340] Iteration 208750, Testing net (#0)
I0707 16:35:13.478420 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 16:36:53.082357 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7781
I0707 16:36:53.082564 26359 solver.cpp:408]     Test net output #1: loss = 0.464512 (* 1 = 0.464512 loss)
I0707 16:39:54.479553 26359 solver.cpp:236] Iteration 208800, loss = 0.480067
I0707 16:39:54.479718 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 16:39:54.479744 26359 solver.cpp:252]     Train net output #1: loss = 0.500834 (* 1 = 0.500834 loss)
I0707 16:39:54.479768 26359 sgd_solver.cpp:106] Iteration 208800, lr = 0.005
I0707 16:44:58.219370 26359 solver.cpp:236] Iteration 208900, loss = 0.462554
I0707 16:44:58.224509 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 16:44:58.224540 26359 solver.cpp:252]     Train net output #1: loss = 0.477896 (* 1 = 0.477896 loss)
I0707 16:44:58.224560 26359 sgd_solver.cpp:106] Iteration 208900, lr = 0.005
I0707 16:50:44.286523 26359 solver.cpp:340] Iteration 209000, Testing net (#0)
I0707 16:52:39.442639 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7841
I0707 16:52:39.442795 26359 solver.cpp:408]     Test net output #1: loss = 0.459143 (* 1 = 0.459143 loss)
I0707 16:52:39.818684 26359 solver.cpp:236] Iteration 209000, loss = 0.469613
I0707 16:52:39.818733 26359 solver.cpp:252]     Train net output #0: accuracy = 0.851562
I0707 16:52:39.818753 26359 solver.cpp:252]     Train net output #1: loss = 0.416533 (* 1 = 0.416533 loss)
I0707 16:52:39.818763 26359 sgd_solver.cpp:106] Iteration 209000, lr = 0.005
I0707 16:58:29.450542 26359 solver.cpp:236] Iteration 209100, loss = 0.473322
I0707 16:58:29.450669 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 16:58:29.450696 26359 solver.cpp:252]     Train net output #1: loss = 0.443336 (* 1 = 0.443336 loss)
I0707 16:58:29.450707 26359 sgd_solver.cpp:106] Iteration 209100, lr = 0.005
I0707 17:06:35.507616 26359 solver.cpp:236] Iteration 209200, loss = 0.468538
I0707 17:06:35.507881 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0707 17:06:35.507935 26359 solver.cpp:252]     Train net output #1: loss = 0.419856 (* 1 = 0.419856 loss)
I0707 17:06:35.507948 26359 sgd_solver.cpp:106] Iteration 209200, lr = 0.005
I0707 17:11:58.462579 26359 solver.cpp:340] Iteration 209250, Testing net (#0)
I0707 17:20:19.731744 26359 solver.cpp:408]     Test net output #0: accuracy = 0.781
I0707 17:20:19.731904 26359 solver.cpp:408]     Test net output #1: loss = 0.462531 (* 1 = 0.462531 loss)
I0707 17:25:47.225788 26359 solver.cpp:236] Iteration 209300, loss = 0.473832
I0707 17:25:47.225968 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 17:25:47.226006 26359 solver.cpp:252]     Train net output #1: loss = 0.488028 (* 1 = 0.488028 loss)
I0707 17:25:47.226033 26359 sgd_solver.cpp:106] Iteration 209300, lr = 0.005
I0707 17:36:30.698532 26359 solver.cpp:236] Iteration 209400, loss = 0.476308
I0707 17:36:30.698703 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 17:36:30.698724 26359 solver.cpp:252]     Train net output #1: loss = 0.478246 (* 1 = 0.478246 loss)
I0707 17:36:30.698736 26359 sgd_solver.cpp:106] Iteration 209400, lr = 0.005
I0707 17:48:53.929301 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 17:49:10.858602 26359 solver.cpp:340] Iteration 209500, Testing net (#0)
I0707 17:59:20.487566 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7851
I0707 17:59:20.502178 26359 solver.cpp:408]     Test net output #1: loss = 0.461466 (* 1 = 0.461466 loss)
I0707 17:59:20.760715 26359 solver.cpp:236] Iteration 209500, loss = 0.45813
I0707 17:59:20.760771 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 17:59:20.760787 26359 solver.cpp:252]     Train net output #1: loss = 0.458569 (* 1 = 0.458569 loss)
I0707 17:59:20.760798 26359 sgd_solver.cpp:106] Iteration 209500, lr = 0.005
I0707 18:16:00.809381 26359 solver.cpp:236] Iteration 209600, loss = 0.484414
I0707 18:16:00.886837 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 18:16:00.886880 26359 solver.cpp:252]     Train net output #1: loss = 0.520131 (* 1 = 0.520131 loss)
I0707 18:16:00.886888 26359 sgd_solver.cpp:106] Iteration 209600, lr = 0.005
I0707 18:29:38.314571 26359 solver.cpp:236] Iteration 209700, loss = 0.490297
I0707 18:29:38.321902 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 18:29:38.321941 26359 solver.cpp:252]     Train net output #1: loss = 0.613943 (* 1 = 0.613943 loss)
I0707 18:29:38.321952 26359 sgd_solver.cpp:106] Iteration 209700, lr = 0.005
I0707 18:37:37.627430 26359 solver.cpp:340] Iteration 209750, Testing net (#0)
I0707 18:48:44.245746 26359 solver.cpp:408]     Test net output #0: accuracy = 0.778
I0707 18:48:44.339781 26359 solver.cpp:408]     Test net output #1: loss = 0.467488 (* 1 = 0.467488 loss)
I0707 18:55:09.784018 26359 solver.cpp:236] Iteration 209800, loss = 0.467603
I0707 18:55:09.818956 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0707 18:55:09.867280 26359 solver.cpp:252]     Train net output #1: loss = 0.520511 (* 1 = 0.520511 loss)
I0707 18:55:09.867292 26359 sgd_solver.cpp:106] Iteration 209800, lr = 0.005
I0707 19:06:58.860587 26359 solver.cpp:236] Iteration 209900, loss = 0.481632
I0707 19:06:58.883769 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 19:06:58.883795 26359 solver.cpp:252]     Train net output #1: loss = 0.467737 (* 1 = 0.467737 loss)
I0707 19:06:58.883805 26359 sgd_solver.cpp:106] Iteration 209900, lr = 0.005
I0707 19:18:14.452004 26359 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_210000.caffemodel
I0707 19:18:15.653115 26359 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_210000.solverstate
I0707 19:18:15.688756 26359 solver.cpp:340] Iteration 210000, Testing net (#0)
I0707 19:27:00.744967 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7805
I0707 19:27:00.764859 26359 solver.cpp:408]     Test net output #1: loss = 0.463365 (* 1 = 0.463365 loss)
I0707 19:27:00.997089 26359 solver.cpp:236] Iteration 210000, loss = 0.474152
I0707 19:27:00.997134 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 19:27:00.997151 26359 solver.cpp:252]     Train net output #1: loss = 0.48776 (* 1 = 0.48776 loss)
I0707 19:27:00.997162 26359 sgd_solver.cpp:106] Iteration 210000, lr = 0.005
I0707 19:38:00.352713 26359 solver.cpp:236] Iteration 210100, loss = 0.483212
I0707 19:38:00.388034 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 19:38:00.388079 26359 solver.cpp:252]     Train net output #1: loss = 0.518328 (* 1 = 0.518328 loss)
I0707 19:38:00.388089 26359 sgd_solver.cpp:106] Iteration 210100, lr = 0.005
I0707 19:48:32.230871 26359 solver.cpp:236] Iteration 210200, loss = 0.472496
I0707 19:48:32.292058 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0707 19:48:32.292126 26359 solver.cpp:252]     Train net output #1: loss = 0.440133 (* 1 = 0.440133 loss)
I0707 19:48:32.292143 26359 sgd_solver.cpp:106] Iteration 210200, lr = 0.005
I0707 19:50:00.873443 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 19:53:25.101325 26359 solver.cpp:340] Iteration 210250, Testing net (#0)
I0707 20:00:35.107568 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7769
I0707 20:00:35.142597 26359 solver.cpp:408]     Test net output #1: loss = 0.472426 (* 1 = 0.472426 loss)
I0707 20:05:17.537540 26359 solver.cpp:236] Iteration 210300, loss = 0.469624
I0707 20:05:17.537716 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 20:05:17.537739 26359 solver.cpp:252]     Train net output #1: loss = 0.483773 (* 1 = 0.483773 loss)
I0707 20:05:17.537751 26359 sgd_solver.cpp:106] Iteration 210300, lr = 0.005
I0707 20:14:13.334048 26359 solver.cpp:236] Iteration 210400, loss = 0.484324
I0707 20:14:13.334179 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 20:14:13.334199 26359 solver.cpp:252]     Train net output #1: loss = 0.515749 (* 1 = 0.515749 loss)
I0707 20:14:13.334210 26359 sgd_solver.cpp:106] Iteration 210400, lr = 0.005
I0707 20:22:25.199339 26359 solver.cpp:340] Iteration 210500, Testing net (#0)
I0707 20:28:40.501222 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7836
I0707 20:28:40.501382 26359 solver.cpp:408]     Test net output #1: loss = 0.46385 (* 1 = 0.46385 loss)
I0707 20:28:40.896507 26359 solver.cpp:236] Iteration 210500, loss = 0.478279
I0707 20:28:40.896749 26359 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0707 20:28:40.896765 26359 solver.cpp:252]     Train net output #1: loss = 0.416487 (* 1 = 0.416487 loss)
I0707 20:28:40.916345 26359 sgd_solver.cpp:106] Iteration 210500, lr = 0.005
I0707 20:36:54.056092 26359 solver.cpp:236] Iteration 210600, loss = 0.480812
I0707 20:36:54.056221 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 20:36:54.056236 26359 solver.cpp:252]     Train net output #1: loss = 0.511413 (* 1 = 0.511413 loss)
I0707 20:36:54.056243 26359 sgd_solver.cpp:106] Iteration 210600, lr = 0.005
I0707 20:45:26.705896 26359 solver.cpp:236] Iteration 210700, loss = 0.475142
I0707 20:45:26.715700 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0707 20:45:26.715735 26359 solver.cpp:252]     Train net output #1: loss = 0.489496 (* 1 = 0.489496 loss)
I0707 20:45:26.715746 26359 sgd_solver.cpp:106] Iteration 210700, lr = 0.005
I0707 20:49:38.639556 26359 solver.cpp:340] Iteration 210750, Testing net (#0)
I0707 20:56:02.274279 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7887
I0707 20:56:02.274518 26359 solver.cpp:408]     Test net output #1: loss = 0.449528 (* 1 = 0.449528 loss)
I0707 20:59:56.583837 26359 solver.cpp:236] Iteration 210800, loss = 0.469759
I0707 20:59:56.583971 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 20:59:56.583989 26359 solver.cpp:252]     Train net output #1: loss = 0.524421 (* 1 = 0.524421 loss)
I0707 20:59:56.584000 26359 sgd_solver.cpp:106] Iteration 210800, lr = 0.005
I0707 21:08:25.760440 26359 solver.cpp:236] Iteration 210900, loss = 0.471764
I0707 21:08:25.760653 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 21:08:25.760680 26359 solver.cpp:252]     Train net output #1: loss = 0.480599 (* 1 = 0.480599 loss)
I0707 21:08:25.760694 26359 sgd_solver.cpp:106] Iteration 210900, lr = 0.005
I0707 21:11:15.384546 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 21:16:55.038746 26359 solver.cpp:340] Iteration 211000, Testing net (#0)
I0707 21:23:22.357345 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7851
I0707 21:23:22.357514 26359 solver.cpp:408]     Test net output #1: loss = 0.459262 (* 1 = 0.459262 loss)
I0707 21:23:22.708009 26359 solver.cpp:236] Iteration 211000, loss = 0.46423
I0707 21:23:22.708044 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 21:23:22.708055 26359 solver.cpp:252]     Train net output #1: loss = 0.441399 (* 1 = 0.441399 loss)
I0707 21:23:22.708061 26359 sgd_solver.cpp:106] Iteration 211000, lr = 0.005
I0707 21:31:41.981251 26359 solver.cpp:236] Iteration 211100, loss = 0.472416
I0707 21:31:41.981447 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0707 21:31:41.981482 26359 solver.cpp:252]     Train net output #1: loss = 0.499789 (* 1 = 0.499789 loss)
I0707 21:31:41.981494 26359 sgd_solver.cpp:106] Iteration 211100, lr = 0.005
I0707 21:40:07.467979 26359 solver.cpp:236] Iteration 211200, loss = 0.483288
I0707 21:40:07.468188 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0707 21:40:07.468216 26359 solver.cpp:252]     Train net output #1: loss = 0.507558 (* 1 = 0.507558 loss)
I0707 21:40:07.468236 26359 sgd_solver.cpp:106] Iteration 211200, lr = 0.005
I0707 21:44:13.787997 26359 solver.cpp:340] Iteration 211250, Testing net (#0)
I0707 21:50:33.522125 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7877
I0707 21:50:33.522321 26359 solver.cpp:408]     Test net output #1: loss = 0.458873 (* 1 = 0.458873 loss)
I0707 21:54:33.922683 26359 solver.cpp:236] Iteration 211300, loss = 0.490593
I0707 21:54:33.922943 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 21:54:33.922976 26359 solver.cpp:252]     Train net output #1: loss = 0.49846 (* 1 = 0.49846 loss)
I0707 21:54:33.922989 26359 sgd_solver.cpp:106] Iteration 211300, lr = 0.005
I0707 22:03:01.708279 26359 solver.cpp:236] Iteration 211400, loss = 0.477601
I0707 22:03:01.708686 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0707 22:03:01.708714 26359 solver.cpp:252]     Train net output #1: loss = 0.452597 (* 1 = 0.452597 loss)
I0707 22:03:01.708722 26359 sgd_solver.cpp:106] Iteration 211400, lr = 0.005
I0707 22:11:10.304031 26359 solver.cpp:340] Iteration 211500, Testing net (#0)
I0707 22:17:20.952795 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7767
I0707 22:17:20.964349 26359 solver.cpp:408]     Test net output #1: loss = 0.468779 (* 1 = 0.468779 loss)
I0707 22:17:21.324712 26359 solver.cpp:236] Iteration 211500, loss = 0.48453
I0707 22:17:21.324766 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 22:17:21.324784 26359 solver.cpp:252]     Train net output #1: loss = 0.535618 (* 1 = 0.535618 loss)
I0707 22:17:21.324795 26359 sgd_solver.cpp:106] Iteration 211500, lr = 0.005
I0707 22:25:21.949010 26359 solver.cpp:236] Iteration 211600, loss = 0.478197
I0707 22:25:21.961678 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 22:25:21.961731 26359 solver.cpp:252]     Train net output #1: loss = 0.431234 (* 1 = 0.431234 loss)
I0707 22:25:21.961746 26359 sgd_solver.cpp:106] Iteration 211600, lr = 0.005
I0707 22:29:36.091475 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 22:33:37.499032 26359 solver.cpp:236] Iteration 211700, loss = 0.474699
I0707 22:33:37.518198 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 22:33:37.518226 26359 solver.cpp:252]     Train net output #1: loss = 0.51169 (* 1 = 0.51169 loss)
I0707 22:33:37.518237 26359 sgd_solver.cpp:106] Iteration 211700, lr = 0.005
I0707 22:37:37.582026 26359 solver.cpp:340] Iteration 211750, Testing net (#0)
I0707 22:43:51.883062 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7861
I0707 22:43:51.897653 26359 solver.cpp:408]     Test net output #1: loss = 0.454896 (* 1 = 0.454896 loss)
I0707 22:47:48.653106 26359 solver.cpp:236] Iteration 211800, loss = 0.452956
I0707 22:47:48.664553 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0707 22:47:48.664594 26359 solver.cpp:252]     Train net output #1: loss = 0.452649 (* 1 = 0.452649 loss)
I0707 22:47:48.664608 26359 sgd_solver.cpp:106] Iteration 211800, lr = 0.005
I0707 22:56:04.319497 26359 solver.cpp:236] Iteration 211900, loss = 0.464038
I0707 22:56:04.319631 26359 solver.cpp:252]     Train net output #0: accuracy = 0.835938
I0707 22:56:04.319675 26359 solver.cpp:252]     Train net output #1: loss = 0.385365 (* 1 = 0.385365 loss)
I0707 22:56:04.319686 26359 sgd_solver.cpp:106] Iteration 211900, lr = 0.005
I0707 23:04:15.318857 26359 solver.cpp:340] Iteration 212000, Testing net (#0)
I0707 23:10:18.562693 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7829
I0707 23:10:18.562937 26359 solver.cpp:408]     Test net output #1: loss = 0.463919 (* 1 = 0.463919 loss)
I0707 23:10:18.799552 26359 solver.cpp:236] Iteration 212000, loss = 0.477645
I0707 23:10:18.799578 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 23:10:18.799593 26359 solver.cpp:252]     Train net output #1: loss = 0.491959 (* 1 = 0.491959 loss)
I0707 23:10:18.799602 26359 sgd_solver.cpp:106] Iteration 212000, lr = 0.005
I0707 23:18:18.994709 26359 solver.cpp:236] Iteration 212100, loss = 0.477886
I0707 23:18:18.994829 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0707 23:18:18.994849 26359 solver.cpp:252]     Train net output #1: loss = 0.479547 (* 1 = 0.479547 loss)
I0707 23:18:18.994860 26359 sgd_solver.cpp:106] Iteration 212100, lr = 0.005
I0707 23:26:38.376871 26359 solver.cpp:236] Iteration 212200, loss = 0.469864
I0707 23:26:38.377080 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0707 23:26:38.377109 26359 solver.cpp:252]     Train net output #1: loss = 0.443453 (* 1 = 0.443453 loss)
I0707 23:26:38.377116 26359 sgd_solver.cpp:106] Iteration 212200, lr = 0.005
I0707 23:30:41.976565 26359 solver.cpp:340] Iteration 212250, Testing net (#0)
I0707 23:36:55.801174 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7622
I0707 23:36:55.801321 26359 solver.cpp:408]     Test net output #1: loss = 0.489178 (* 1 = 0.489178 loss)
I0707 23:40:49.740777 26359 solver.cpp:236] Iteration 212300, loss = 0.480496
I0707 23:40:49.740926 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0707 23:40:49.740944 26359 solver.cpp:252]     Train net output #1: loss = 0.52312 (* 1 = 0.52312 loss)
I0707 23:40:49.740967 26359 sgd_solver.cpp:106] Iteration 212300, lr = 0.005
I0707 23:46:27.313406 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0707 23:49:02.746731 26359 solver.cpp:236] Iteration 212400, loss = 0.478437
I0707 23:49:02.761014 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0707 23:49:02.761036 26359 solver.cpp:252]     Train net output #1: loss = 0.575091 (* 1 = 0.575091 loss)
I0707 23:49:02.761047 26359 sgd_solver.cpp:106] Iteration 212400, lr = 0.005
I0707 23:57:03.721534 26359 solver.cpp:340] Iteration 212500, Testing net (#0)
I0708 00:03:06.337337 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7818
I0708 00:03:06.349171 26359 solver.cpp:408]     Test net output #1: loss = 0.466048 (* 1 = 0.466048 loss)
I0708 00:03:06.658293 26359 solver.cpp:236] Iteration 212500, loss = 0.471748
I0708 00:03:06.658344 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 00:03:06.658360 26359 solver.cpp:252]     Train net output #1: loss = 0.481655 (* 1 = 0.481655 loss)
I0708 00:03:06.658370 26359 sgd_solver.cpp:106] Iteration 212500, lr = 0.005
I0708 00:11:00.579912 26359 solver.cpp:236] Iteration 212600, loss = 0.468239
I0708 00:11:00.591645 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 00:11:00.591665 26359 solver.cpp:252]     Train net output #1: loss = 0.465691 (* 1 = 0.465691 loss)
I0708 00:11:00.591676 26359 sgd_solver.cpp:106] Iteration 212600, lr = 0.005
I0708 00:19:04.855020 26359 solver.cpp:236] Iteration 212700, loss = 0.460146
I0708 00:19:04.870465 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 00:19:04.870507 26359 solver.cpp:252]     Train net output #1: loss = 0.466133 (* 1 = 0.466133 loss)
I0708 00:19:04.870518 26359 sgd_solver.cpp:106] Iteration 212700, lr = 0.005
I0708 00:23:03.131310 26359 solver.cpp:340] Iteration 212750, Testing net (#0)
I0708 00:29:05.813719 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7841
I0708 00:29:05.840241 26359 solver.cpp:408]     Test net output #1: loss = 0.461811 (* 1 = 0.461811 loss)
I0708 00:32:54.689229 26359 solver.cpp:236] Iteration 212800, loss = 0.467603
I0708 00:32:54.715590 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0708 00:32:54.715636 26359 solver.cpp:252]     Train net output #1: loss = 0.475774 (* 1 = 0.475774 loss)
I0708 00:32:54.715646 26359 sgd_solver.cpp:106] Iteration 212800, lr = 0.005
I0708 00:41:01.814802 26359 solver.cpp:236] Iteration 212900, loss = 0.478107
I0708 00:41:01.826452 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 00:41:01.826484 26359 solver.cpp:252]     Train net output #1: loss = 0.484677 (* 1 = 0.484677 loss)
I0708 00:41:01.826508 26359 sgd_solver.cpp:106] Iteration 212900, lr = 0.005
I0708 00:49:04.578706 26359 solver.cpp:340] Iteration 213000, Testing net (#0)
I0708 00:55:12.804836 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7876
I0708 00:55:12.819205 26359 solver.cpp:408]     Test net output #1: loss = 0.460826 (* 1 = 0.460826 loss)
I0708 00:55:12.957262 26359 solver.cpp:236] Iteration 213000, loss = 0.468401
I0708 00:55:12.957301 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 00:55:12.957326 26359 solver.cpp:252]     Train net output #1: loss = 0.512697 (* 1 = 0.512697 loss)
I0708 00:55:12.957341 26359 sgd_solver.cpp:106] Iteration 213000, lr = 0.005
I0708 01:02:01.864354 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:03:05.128417 26359 solver.cpp:236] Iteration 213100, loss = 0.473527
I0708 01:03:05.129266 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0708 01:03:05.129287 26359 solver.cpp:252]     Train net output #1: loss = 0.519063 (* 1 = 0.519063 loss)
I0708 01:03:05.129297 26359 sgd_solver.cpp:106] Iteration 213100, lr = 0.005
I0708 01:11:03.113533 26359 solver.cpp:236] Iteration 213200, loss = 0.458245
I0708 01:11:03.113765 26359 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0708 01:11:03.113797 26359 solver.cpp:252]     Train net output #1: loss = 0.510498 (* 1 = 0.510498 loss)
I0708 01:11:03.113809 26359 sgd_solver.cpp:106] Iteration 213200, lr = 0.005
I0708 01:14:58.011036 26359 solver.cpp:340] Iteration 213250, Testing net (#0)
I0708 01:20:57.659298 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7714
I0708 01:20:57.667677 26359 solver.cpp:408]     Test net output #1: loss = 0.481107 (* 1 = 0.481107 loss)
I0708 01:24:47.242686 26359 solver.cpp:236] Iteration 213300, loss = 0.464856
I0708 01:24:47.259871 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 01:24:47.259903 26359 solver.cpp:252]     Train net output #1: loss = 0.449458 (* 1 = 0.449458 loss)
I0708 01:24:47.259915 26359 sgd_solver.cpp:106] Iteration 213300, lr = 0.005
I0708 01:32:46.702582 26359 solver.cpp:236] Iteration 213400, loss = 0.497911
I0708 01:32:46.715797 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0708 01:32:46.715828 26359 solver.cpp:252]     Train net output #1: loss = 0.491623 (* 1 = 0.491623 loss)
I0708 01:32:46.715837 26359 sgd_solver.cpp:106] Iteration 213400, lr = 0.005
I0708 01:40:45.067590 26359 solver.cpp:340] Iteration 213500, Testing net (#0)
I0708 01:46:51.108414 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7937
I0708 01:46:51.120136 26359 solver.cpp:408]     Test net output #1: loss = 0.446373 (* 1 = 0.446373 loss)
I0708 01:46:51.363046 26359 solver.cpp:236] Iteration 213500, loss = 0.454897
I0708 01:46:51.363086 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 01:46:51.363101 26359 solver.cpp:252]     Train net output #1: loss = 0.422889 (* 1 = 0.422889 loss)
I0708 01:46:51.363111 26359 sgd_solver.cpp:106] Iteration 213500, lr = 0.005
I0708 01:54:39.458258 26359 solver.cpp:236] Iteration 213600, loss = 0.464518
I0708 01:54:39.473815 26359 solver.cpp:252]     Train net output #0: accuracy = 0.679688
I0708 01:54:39.473832 26359 solver.cpp:252]     Train net output #1: loss = 0.601642 (* 1 = 0.601642 loss)
I0708 01:54:39.473839 26359 sgd_solver.cpp:106] Iteration 213600, lr = 0.005
I0708 02:02:41.277282 26359 solver.cpp:236] Iteration 213700, loss = 0.453662
I0708 02:02:41.304046 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0708 02:02:41.304087 26359 solver.cpp:252]     Train net output #1: loss = 0.476487 (* 1 = 0.476487 loss)
I0708 02:02:41.304098 26359 sgd_solver.cpp:106] Iteration 213700, lr = 0.005
I0708 02:06:35.003048 26359 solver.cpp:340] Iteration 213750, Testing net (#0)
I0708 02:12:30.549768 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7714
I0708 02:12:30.579722 26359 solver.cpp:408]     Test net output #1: loss = 0.480752 (* 1 = 0.480752 loss)
I0708 02:16:22.334857 26359 solver.cpp:236] Iteration 213800, loss = 0.461915
I0708 02:16:22.345340 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0708 02:16:22.345372 26359 solver.cpp:252]     Train net output #1: loss = 0.412498 (* 1 = 0.412498 loss)
I0708 02:16:22.345394 26359 sgd_solver.cpp:106] Iteration 213800, lr = 0.005
I0708 02:16:46.148216 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:24:20.016341 26359 solver.cpp:236] Iteration 213900, loss = 0.470537
I0708 02:24:20.027710 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0708 02:24:20.027755 26359 solver.cpp:252]     Train net output #1: loss = 0.509331 (* 1 = 0.509331 loss)
I0708 02:24:20.027766 26359 sgd_solver.cpp:106] Iteration 213900, lr = 0.005
I0708 02:32:13.926862 26359 solver.cpp:340] Iteration 214000, Testing net (#0)
I0708 02:38:18.542258 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7845
I0708 02:38:18.585144 26359 solver.cpp:408]     Test net output #1: loss = 0.462794 (* 1 = 0.462794 loss)
I0708 02:38:18.723578 26359 solver.cpp:236] Iteration 214000, loss = 0.46828
I0708 02:38:18.723646 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0708 02:38:18.723665 26359 solver.cpp:252]     Train net output #1: loss = 0.389993 (* 1 = 0.389993 loss)
I0708 02:38:18.723676 26359 sgd_solver.cpp:106] Iteration 214000, lr = 0.005
I0708 02:46:10.625109 26359 solver.cpp:236] Iteration 214100, loss = 0.478556
I0708 02:46:10.636925 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 02:46:10.636945 26359 solver.cpp:252]     Train net output #1: loss = 0.451078 (* 1 = 0.451078 loss)
I0708 02:46:10.636956 26359 sgd_solver.cpp:106] Iteration 214100, lr = 0.005
I0708 02:54:08.831357 26359 solver.cpp:236] Iteration 214200, loss = 0.474863
I0708 02:54:08.844063 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0708 02:54:08.844096 26359 solver.cpp:252]     Train net output #1: loss = 0.495342 (* 1 = 0.495342 loss)
I0708 02:54:08.844107 26359 sgd_solver.cpp:106] Iteration 214200, lr = 0.005
I0708 02:58:03.392007 26359 solver.cpp:340] Iteration 214250, Testing net (#0)
I0708 03:04:08.341236 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7528
I0708 03:04:08.341387 26359 solver.cpp:408]     Test net output #1: loss = 0.506033 (* 1 = 0.506033 loss)
I0708 03:08:00.154130 26359 solver.cpp:236] Iteration 214300, loss = 0.485217
I0708 03:08:00.154254 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0708 03:08:00.154285 26359 solver.cpp:252]     Train net output #1: loss = 0.482765 (* 1 = 0.482765 loss)
I0708 03:08:00.154296 26359 sgd_solver.cpp:106] Iteration 214300, lr = 0.005
I0708 03:16:02.712124 26359 solver.cpp:236] Iteration 214400, loss = 0.476734
I0708 03:16:02.712245 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 03:16:02.712268 26359 solver.cpp:252]     Train net output #1: loss = 0.51309 (* 1 = 0.51309 loss)
I0708 03:16:02.712298 26359 sgd_solver.cpp:106] Iteration 214400, lr = 0.005
I0708 03:24:02.383077 26359 solver.cpp:340] Iteration 214500, Testing net (#0)
I0708 03:30:03.265925 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7802
I0708 03:30:03.266082 26359 solver.cpp:408]     Test net output #1: loss = 0.473735 (* 1 = 0.473735 loss)
I0708 03:30:03.494105 26359 solver.cpp:236] Iteration 214500, loss = 0.480476
I0708 03:30:03.494177 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0708 03:30:03.494197 26359 solver.cpp:252]     Train net output #1: loss = 0.426363 (* 1 = 0.426363 loss)
I0708 03:30:03.494210 26359 sgd_solver.cpp:106] Iteration 214500, lr = 0.005
I0708 03:31:44.050946 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 03:37:59.185627 26359 solver.cpp:236] Iteration 214600, loss = 0.466817
I0708 03:37:59.189321 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0708 03:37:59.189354 26359 solver.cpp:252]     Train net output #1: loss = 0.463654 (* 1 = 0.463654 loss)
I0708 03:37:59.189366 26359 sgd_solver.cpp:106] Iteration 214600, lr = 0.005
I0708 03:45:58.238668 26359 solver.cpp:236] Iteration 214700, loss = 0.464136
I0708 03:45:58.238831 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 03:45:58.238859 26359 solver.cpp:252]     Train net output #1: loss = 0.475437 (* 1 = 0.475437 loss)
I0708 03:45:58.238870 26359 sgd_solver.cpp:106] Iteration 214700, lr = 0.005
I0708 03:49:51.279593 26359 solver.cpp:340] Iteration 214750, Testing net (#0)
I0708 03:55:56.381441 26359 solver.cpp:408]     Test net output #0: accuracy = 0.774
I0708 03:55:56.382278 26359 solver.cpp:408]     Test net output #1: loss = 0.474137 (* 1 = 0.474137 loss)
I0708 03:59:47.496726 26359 solver.cpp:236] Iteration 214800, loss = 0.47756
I0708 03:59:47.496882 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0708 03:59:47.496913 26359 solver.cpp:252]     Train net output #1: loss = 0.506118 (* 1 = 0.506118 loss)
I0708 03:59:47.496924 26359 sgd_solver.cpp:106] Iteration 214800, lr = 0.005
I0708 04:07:48.688856 26359 solver.cpp:236] Iteration 214900, loss = 0.50076
I0708 04:07:48.698773 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 04:07:48.698812 26359 solver.cpp:252]     Train net output #1: loss = 0.492219 (* 1 = 0.492219 loss)
I0708 04:07:48.698825 26359 sgd_solver.cpp:106] Iteration 214900, lr = 0.005
I0708 04:15:43.590833 26359 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_215000.caffemodel
I0708 04:15:44.276089 26359 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_215000.solverstate
I0708 04:15:44.308573 26359 solver.cpp:340] Iteration 215000, Testing net (#0)
I0708 04:21:42.363071 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7679
I0708 04:21:42.383586 26359 solver.cpp:408]     Test net output #1: loss = 0.48519 (* 1 = 0.48519 loss)
I0708 04:21:42.625843 26359 solver.cpp:236] Iteration 215000, loss = 0.472676
I0708 04:21:42.625881 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 04:21:42.625895 26359 solver.cpp:252]     Train net output #1: loss = 0.466285 (* 1 = 0.466285 loss)
I0708 04:21:42.625906 26359 sgd_solver.cpp:106] Iteration 215000, lr = 0.005
I0708 04:29:39.226650 26359 solver.cpp:236] Iteration 215100, loss = 0.462137
I0708 04:29:39.258034 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 04:29:39.258081 26359 solver.cpp:252]     Train net output #1: loss = 0.41162 (* 1 = 0.41162 loss)
I0708 04:29:39.258097 26359 sgd_solver.cpp:106] Iteration 215100, lr = 0.005
I0708 04:37:39.621923 26359 solver.cpp:236] Iteration 215200, loss = 0.466266
I0708 04:37:39.630558 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 04:37:39.630607 26359 solver.cpp:252]     Train net output #1: loss = 0.42175 (* 1 = 0.42175 loss)
I0708 04:37:39.630620 26359 sgd_solver.cpp:106] Iteration 215200, lr = 0.005
I0708 04:41:34.524349 26359 solver.cpp:340] Iteration 215250, Testing net (#0)
I0708 04:46:59.687783 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 04:47:40.937260 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7878
I0708 04:47:40.958408 26359 solver.cpp:408]     Test net output #1: loss = 0.453786 (* 1 = 0.453786 loss)
I0708 04:51:32.288203 26359 solver.cpp:236] Iteration 215300, loss = 0.46485
I0708 04:51:32.324110 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0708 04:51:32.324162 26359 solver.cpp:252]     Train net output #1: loss = 0.443826 (* 1 = 0.443826 loss)
I0708 04:51:32.324172 26359 sgd_solver.cpp:106] Iteration 215300, lr = 0.005
I0708 04:59:40.025436 26359 solver.cpp:236] Iteration 215400, loss = 0.464296
I0708 04:59:40.059671 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0708 04:59:40.059705 26359 solver.cpp:252]     Train net output #1: loss = 0.444246 (* 1 = 0.444246 loss)
I0708 04:59:40.059715 26359 sgd_solver.cpp:106] Iteration 215400, lr = 0.005
I0708 05:07:38.256676 26359 solver.cpp:340] Iteration 215500, Testing net (#0)
I0708 05:13:42.408911 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7819
I0708 05:13:42.423384 26359 solver.cpp:408]     Test net output #1: loss = 0.470707 (* 1 = 0.470707 loss)
I0708 05:13:42.770361 26359 solver.cpp:236] Iteration 215500, loss = 0.478
I0708 05:13:42.770411 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 05:13:42.770426 26359 solver.cpp:252]     Train net output #1: loss = 0.440126 (* 1 = 0.440126 loss)
I0708 05:13:42.770437 26359 sgd_solver.cpp:106] Iteration 215500, lr = 0.005
I0708 05:21:36.396919 26359 solver.cpp:236] Iteration 215600, loss = 0.467513
I0708 05:21:36.440906 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 05:21:36.440984 26359 solver.cpp:252]     Train net output #1: loss = 0.480917 (* 1 = 0.480917 loss)
I0708 05:21:36.441009 26359 sgd_solver.cpp:106] Iteration 215600, lr = 0.005
I0708 05:29:37.338279 26359 solver.cpp:236] Iteration 215700, loss = 0.48911
I0708 05:29:37.354933 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0708 05:29:37.354985 26359 solver.cpp:252]     Train net output #1: loss = 0.49011 (* 1 = 0.49011 loss)
I0708 05:29:37.354996 26359 sgd_solver.cpp:106] Iteration 215700, lr = 0.005
I0708 05:33:34.996950 26359 solver.cpp:340] Iteration 215750, Testing net (#0)
I0708 05:39:40.522222 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7771
I0708 05:39:40.540231 26359 solver.cpp:408]     Test net output #1: loss = 0.471261 (* 1 = 0.471261 loss)
I0708 05:43:30.639183 26359 solver.cpp:236] Iteration 215800, loss = 0.464838
I0708 05:43:30.658493 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0708 05:43:30.658524 26359 solver.cpp:252]     Train net output #1: loss = 0.432621 (* 1 = 0.432621 loss)
I0708 05:43:30.658535 26359 sgd_solver.cpp:106] Iteration 215800, lr = 0.005
I0708 05:51:32.678140 26359 solver.cpp:236] Iteration 215900, loss = 0.477097
I0708 05:51:32.695176 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 05:51:32.695219 26359 solver.cpp:252]     Train net output #1: loss = 0.532048 (* 1 = 0.532048 loss)
I0708 05:51:32.695227 26359 sgd_solver.cpp:106] Iteration 215900, lr = 0.005
I0708 05:59:30.732723 26359 solver.cpp:340] Iteration 216000, Testing net (#0)
I0708 06:02:53.057560 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 06:05:31.953368 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7821
I0708 06:05:31.953541 26359 solver.cpp:408]     Test net output #1: loss = 0.464767 (* 1 = 0.464767 loss)
I0708 06:05:32.161489 26359 solver.cpp:236] Iteration 216000, loss = 0.478931
I0708 06:05:32.161540 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 06:05:32.161556 26359 solver.cpp:252]     Train net output #1: loss = 0.472369 (* 1 = 0.472369 loss)
I0708 06:05:32.161566 26359 sgd_solver.cpp:106] Iteration 216000, lr = 0.005
I0708 06:13:23.355283 26359 solver.cpp:236] Iteration 216100, loss = 0.488595
I0708 06:13:23.355432 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0708 06:13:23.355466 26359 solver.cpp:252]     Train net output #1: loss = 0.527719 (* 1 = 0.527719 loss)
I0708 06:13:23.355487 26359 sgd_solver.cpp:106] Iteration 216100, lr = 0.005
I0708 06:21:29.026760 26359 solver.cpp:236] Iteration 216200, loss = 0.462817
I0708 06:21:29.026921 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 06:21:29.026944 26359 solver.cpp:252]     Train net output #1: loss = 0.440037 (* 1 = 0.440037 loss)
I0708 06:21:29.026955 26359 sgd_solver.cpp:106] Iteration 216200, lr = 0.005
I0708 06:25:27.735977 26359 solver.cpp:340] Iteration 216250, Testing net (#0)
I0708 06:31:30.380985 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7807
I0708 06:31:30.382302 26359 solver.cpp:408]     Test net output #1: loss = 0.463827 (* 1 = 0.463827 loss)
I0708 06:35:21.646180 26359 solver.cpp:236] Iteration 216300, loss = 0.477666
I0708 06:35:21.646314 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 06:35:21.646345 26359 solver.cpp:252]     Train net output #1: loss = 0.458711 (* 1 = 0.458711 loss)
I0708 06:35:21.646356 26359 sgd_solver.cpp:106] Iteration 216300, lr = 0.005
I0708 06:43:19.361259 26359 solver.cpp:236] Iteration 216400, loss = 0.481952
I0708 06:43:19.361398 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0708 06:43:19.361445 26359 solver.cpp:252]     Train net output #1: loss = 0.511319 (* 1 = 0.511319 loss)
I0708 06:43:19.361456 26359 sgd_solver.cpp:106] Iteration 216400, lr = 0.005
I0708 06:51:13.710714 26359 solver.cpp:340] Iteration 216500, Testing net (#0)
I0708 06:58:14.481717 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7865
I0708 06:58:14.481922 26359 solver.cpp:408]     Test net output #1: loss = 0.466856 (* 1 = 0.466856 loss)
I0708 06:58:14.764124 26359 solver.cpp:236] Iteration 216500, loss = 0.467821
I0708 06:58:14.764165 26359 solver.cpp:252]     Train net output #0: accuracy = 0.835938
I0708 06:58:14.764181 26359 solver.cpp:252]     Train net output #1: loss = 0.400917 (* 1 = 0.400917 loss)
I0708 06:58:14.764191 26359 sgd_solver.cpp:106] Iteration 216500, lr = 0.005
I0708 07:07:06.084336 26359 solver.cpp:236] Iteration 216600, loss = 0.483089
I0708 07:07:06.084496 26359 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0708 07:07:06.084529 26359 solver.cpp:252]     Train net output #1: loss = 0.567932 (* 1 = 0.567932 loss)
I0708 07:07:06.084552 26359 sgd_solver.cpp:106] Iteration 216600, lr = 0.005
I0708 07:16:03.716797 26359 solver.cpp:236] Iteration 216700, loss = 0.478434
I0708 07:16:03.717020 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0708 07:16:03.717061 26359 solver.cpp:252]     Train net output #1: loss = 0.44786 (* 1 = 0.44786 loss)
I0708 07:16:03.717072 26359 sgd_solver.cpp:106] Iteration 216700, lr = 0.005
I0708 07:20:25.381891 26359 solver.cpp:340] Iteration 216750, Testing net (#0)
I0708 07:21:54.390982 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 07:26:54.072329 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7854
I0708 07:26:54.072489 26359 solver.cpp:408]     Test net output #1: loss = 0.457696 (* 1 = 0.457696 loss)
I0708 07:30:59.378069 26359 solver.cpp:236] Iteration 216800, loss = 0.462673
I0708 07:30:59.378203 26359 solver.cpp:252]     Train net output #0: accuracy = 0.710938
I0708 07:30:59.378232 26359 solver.cpp:252]     Train net output #1: loss = 0.510181 (* 1 = 0.510181 loss)
I0708 07:30:59.378243 26359 sgd_solver.cpp:106] Iteration 216800, lr = 0.005
I0708 07:39:27.292032 26359 solver.cpp:236] Iteration 216900, loss = 0.475363
I0708 07:39:27.292191 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0708 07:39:27.292222 26359 solver.cpp:252]     Train net output #1: loss = 0.511661 (* 1 = 0.511661 loss)
I0708 07:39:27.292244 26359 sgd_solver.cpp:106] Iteration 216900, lr = 0.005
I0708 07:47:46.436636 26359 solver.cpp:340] Iteration 217000, Testing net (#0)
I0708 07:54:08.144187 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7743
I0708 07:54:08.144314 26359 solver.cpp:408]     Test net output #1: loss = 0.475205 (* 1 = 0.475205 loss)
I0708 07:54:08.442215 26359 solver.cpp:236] Iteration 217000, loss = 0.482143
I0708 07:54:08.442267 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0708 07:54:08.442284 26359 solver.cpp:252]     Train net output #1: loss = 0.486907 (* 1 = 0.486907 loss)
I0708 07:54:08.442294 26359 sgd_solver.cpp:106] Iteration 217000, lr = 0.005
I0708 08:02:13.824934 26359 solver.cpp:236] Iteration 217100, loss = 0.498818
I0708 08:02:13.825129 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 08:02:13.825156 26359 solver.cpp:252]     Train net output #1: loss = 0.457114 (* 1 = 0.457114 loss)
I0708 08:02:13.825165 26359 sgd_solver.cpp:106] Iteration 217100, lr = 0.005
I0708 08:10:29.911810 26359 solver.cpp:236] Iteration 217200, loss = 0.461057
I0708 08:10:29.911931 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0708 08:10:29.911960 26359 solver.cpp:252]     Train net output #1: loss = 0.502361 (* 1 = 0.502361 loss)
I0708 08:10:29.911970 26359 sgd_solver.cpp:106] Iteration 217200, lr = 0.005
I0708 08:14:33.292035 26359 solver.cpp:340] Iteration 217250, Testing net (#0)
I0708 08:20:47.135479 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7919
I0708 08:20:47.135607 26359 solver.cpp:408]     Test net output #1: loss = 0.447647 (* 1 = 0.447647 loss)
I0708 08:24:45.657830 26359 solver.cpp:236] Iteration 217300, loss = 0.467288
I0708 08:24:45.657970 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 08:24:45.657999 26359 solver.cpp:252]     Train net output #1: loss = 0.52698 (* 1 = 0.52698 loss)
I0708 08:24:45.658022 26359 sgd_solver.cpp:106] Iteration 217300, lr = 0.005
I0708 08:32:59.239374 26359 solver.cpp:236] Iteration 217400, loss = 0.468617
I0708 08:32:59.239519 26359 solver.cpp:252]     Train net output #0: accuracy = 0.703125
I0708 08:32:59.239567 26359 solver.cpp:252]     Train net output #1: loss = 0.572375 (* 1 = 0.572375 loss)
I0708 08:32:59.239578 26359 sgd_solver.cpp:106] Iteration 217400, lr = 0.005
I0708 08:40:17.136543 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 08:41:06.530633 26359 solver.cpp:340] Iteration 217500, Testing net (#0)
I0708 08:47:19.979542 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7677
I0708 08:47:19.979708 26359 solver.cpp:408]     Test net output #1: loss = 0.495034 (* 1 = 0.495034 loss)
I0708 08:47:20.194314 26359 solver.cpp:236] Iteration 217500, loss = 0.472375
I0708 08:47:20.194352 26359 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0708 08:47:20.194367 26359 solver.cpp:252]     Train net output #1: loss = 0.599052 (* 1 = 0.599052 loss)
I0708 08:47:20.194377 26359 sgd_solver.cpp:106] Iteration 217500, lr = 0.005
I0708 08:55:21.755316 26359 solver.cpp:236] Iteration 217600, loss = 0.469746
I0708 08:55:21.774987 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0708 08:55:21.775018 26359 solver.cpp:252]     Train net output #1: loss = 0.510619 (* 1 = 0.510619 loss)
I0708 08:55:21.775029 26359 sgd_solver.cpp:106] Iteration 217600, lr = 0.005
I0708 09:03:26.205454 26359 solver.cpp:236] Iteration 217700, loss = 0.493435
I0708 09:03:26.222334 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0708 09:03:26.222374 26359 solver.cpp:252]     Train net output #1: loss = 0.474679 (* 1 = 0.474679 loss)
I0708 09:03:26.222388 26359 sgd_solver.cpp:106] Iteration 217700, lr = 0.005
I0708 09:07:28.817011 26359 solver.cpp:340] Iteration 217750, Testing net (#0)
I0708 09:13:35.081250 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7829
I0708 09:13:35.098592 26359 solver.cpp:408]     Test net output #1: loss = 0.460837 (* 1 = 0.460837 loss)
I0708 09:17:27.140664 26359 solver.cpp:236] Iteration 217800, loss = 0.47384
I0708 09:17:27.164849 26359 solver.cpp:252]     Train net output #0: accuracy = 0.820312
I0708 09:17:27.164867 26359 solver.cpp:252]     Train net output #1: loss = 0.414334 (* 1 = 0.414334 loss)
I0708 09:17:27.164886 26359 sgd_solver.cpp:106] Iteration 217800, lr = 0.005
I0708 09:25:32.170377 26359 solver.cpp:236] Iteration 217900, loss = 0.473726
I0708 09:25:32.186908 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 09:25:32.186940 26359 solver.cpp:252]     Train net output #1: loss = 0.484883 (* 1 = 0.484883 loss)
I0708 09:25:32.186952 26359 sgd_solver.cpp:106] Iteration 217900, lr = 0.005
I0708 09:33:32.365223 26359 solver.cpp:340] Iteration 218000, Testing net (#0)
I0708 09:39:33.624119 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7857
I0708 09:39:33.637671 26359 solver.cpp:408]     Test net output #1: loss = 0.456916 (* 1 = 0.456916 loss)
I0708 09:39:33.969224 26359 solver.cpp:236] Iteration 218000, loss = 0.465155
I0708 09:39:33.969275 26359 solver.cpp:252]     Train net output #0: accuracy = 0.828125
I0708 09:39:33.969292 26359 solver.cpp:252]     Train net output #1: loss = 0.435117 (* 1 = 0.435117 loss)
I0708 09:39:33.969305 26359 sgd_solver.cpp:106] Iteration 218000, lr = 0.005
I0708 09:47:28.374759 26359 solver.cpp:236] Iteration 218100, loss = 0.473923
I0708 09:47:28.381541 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 09:47:28.381578 26359 solver.cpp:252]     Train net output #1: loss = 0.501907 (* 1 = 0.501907 loss)
I0708 09:47:28.381588 26359 sgd_solver.cpp:106] Iteration 218100, lr = 0.005
I0708 09:55:27.276960 26359 solver.cpp:236] Iteration 218200, loss = 0.468969
I0708 09:55:27.291858 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 09:55:27.291877 26359 solver.cpp:252]     Train net output #1: loss = 0.445064 (* 1 = 0.445064 loss)
I0708 09:55:27.291883 26359 sgd_solver.cpp:106] Iteration 218200, lr = 0.005
I0708 09:56:00.538792 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 09:59:19.936496 26359 solver.cpp:340] Iteration 218250, Testing net (#0)
I0708 10:05:29.211154 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7803
I0708 10:05:29.244788 26359 solver.cpp:408]     Test net output #1: loss = 0.466412 (* 1 = 0.466412 loss)
I0708 10:09:18.679554 26359 solver.cpp:236] Iteration 218300, loss = 0.473517
I0708 10:09:18.704074 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0708 10:09:18.704107 26359 solver.cpp:252]     Train net output #1: loss = 0.432543 (* 1 = 0.432543 loss)
I0708 10:09:18.704119 26359 sgd_solver.cpp:106] Iteration 218300, lr = 0.005
I0708 10:17:21.924108 26359 solver.cpp:236] Iteration 218400, loss = 0.464636
I0708 10:17:21.952059 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 10:17:21.952086 26359 solver.cpp:252]     Train net output #1: loss = 0.468391 (* 1 = 0.468391 loss)
I0708 10:17:21.952093 26359 sgd_solver.cpp:106] Iteration 218400, lr = 0.005
I0708 10:25:21.654808 26359 solver.cpp:340] Iteration 218500, Testing net (#0)
I0708 10:29:32.387305 26359 solver.cpp:408]     Test net output #0: accuracy = 0.781
I0708 10:29:32.387445 26359 solver.cpp:408]     Test net output #1: loss = 0.465324 (* 1 = 0.465324 loss)
I0708 10:29:32.613047 26359 solver.cpp:236] Iteration 218500, loss = 0.469753
I0708 10:29:32.613090 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0708 10:29:32.613106 26359 solver.cpp:252]     Train net output #1: loss = 0.519421 (* 1 = 0.519421 loss)
I0708 10:29:32.613116 26359 sgd_solver.cpp:106] Iteration 218500, lr = 0.005
I0708 10:33:05.944123 26359 solver.cpp:236] Iteration 218600, loss = 0.480766
I0708 10:33:05.944313 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0708 10:33:05.944351 26359 solver.cpp:252]     Train net output #1: loss = 0.458379 (* 1 = 0.458379 loss)
I0708 10:33:05.944362 26359 sgd_solver.cpp:106] Iteration 218600, lr = 0.005
I0708 10:36:41.211974 26359 solver.cpp:236] Iteration 218700, loss = 0.47112
I0708 10:36:41.212119 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0708 10:36:41.212153 26359 solver.cpp:252]     Train net output #1: loss = 0.472355 (* 1 = 0.472355 loss)
I0708 10:36:41.212175 26359 sgd_solver.cpp:106] Iteration 218700, lr = 0.005
I0708 10:38:27.446398 26359 solver.cpp:340] Iteration 218750, Testing net (#0)
I0708 10:41:12.268175 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7801
I0708 10:41:12.268342 26359 solver.cpp:408]     Test net output #1: loss = 0.46651 (* 1 = 0.46651 loss)
I0708 10:42:55.033571 26359 solver.cpp:236] Iteration 218800, loss = 0.482757
I0708 10:42:55.033756 26359 solver.cpp:252]     Train net output #0: accuracy = 0.757812
I0708 10:42:55.033785 26359 solver.cpp:252]     Train net output #1: loss = 0.517525 (* 1 = 0.517525 loss)
I0708 10:42:55.033795 26359 sgd_solver.cpp:106] Iteration 218800, lr = 0.005
I0708 10:46:39.580472 26359 solver.cpp:236] Iteration 218900, loss = 0.451935
I0708 10:46:39.580708 26359 solver.cpp:252]     Train net output #0: accuracy = 0.859375
I0708 10:46:39.580734 26359 solver.cpp:252]     Train net output #1: loss = 0.371829 (* 1 = 0.371829 loss)
I0708 10:46:39.580742 26359 sgd_solver.cpp:106] Iteration 218900, lr = 0.005
I0708 10:47:33.476735 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 10:50:14.005725 26359 solver.cpp:340] Iteration 219000, Testing net (#0)
I0708 10:52:24.272653 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7799
I0708 10:52:24.272785 26359 solver.cpp:408]     Test net output #1: loss = 0.471613 (* 1 = 0.471613 loss)
I0708 10:52:24.411166 26359 solver.cpp:236] Iteration 219000, loss = 0.464727
I0708 10:52:24.411191 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 10:52:24.411204 26359 solver.cpp:252]     Train net output #1: loss = 0.467832 (* 1 = 0.467832 loss)
I0708 10:52:24.411213 26359 sgd_solver.cpp:106] Iteration 219000, lr = 0.005
I0708 10:55:57.508579 26359 solver.cpp:236] Iteration 219100, loss = 0.481838
I0708 10:55:57.508713 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0708 10:55:57.508746 26359 solver.cpp:252]     Train net output #1: loss = 0.455105 (* 1 = 0.455105 loss)
I0708 10:55:57.508759 26359 sgd_solver.cpp:106] Iteration 219100, lr = 0.005
I0708 10:59:32.200417 26359 solver.cpp:236] Iteration 219200, loss = 0.46124
I0708 10:59:32.200636 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 10:59:32.200675 26359 solver.cpp:252]     Train net output #1: loss = 0.474134 (* 1 = 0.474134 loss)
I0708 10:59:32.200683 26359 sgd_solver.cpp:106] Iteration 219200, lr = 0.005
I0708 11:01:19.111757 26359 solver.cpp:340] Iteration 219250, Testing net (#0)
I0708 11:02:50.410953 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7369
I0708 11:02:50.411139 26359 solver.cpp:408]     Test net output #1: loss = 0.528532 (* 1 = 0.528532 loss)
I0708 11:04:37.928377 26359 solver.cpp:236] Iteration 219300, loss = 0.478109
I0708 11:04:37.944622 26359 solver.cpp:252]     Train net output #0: accuracy = 0.804688
I0708 11:04:37.944656 26359 solver.cpp:252]     Train net output #1: loss = 0.38193 (* 1 = 0.38193 loss)
I0708 11:04:37.944669 26359 sgd_solver.cpp:106] Iteration 219300, lr = 0.005
I0708 11:08:35.411669 26359 solver.cpp:236] Iteration 219400, loss = 0.473289
I0708 11:08:35.411854 26359 solver.cpp:252]     Train net output #0: accuracy = 0.84375
I0708 11:08:35.411875 26359 solver.cpp:252]     Train net output #1: loss = 0.414274 (* 1 = 0.414274 loss)
I0708 11:08:35.411886 26359 sgd_solver.cpp:106] Iteration 219400, lr = 0.005
I0708 11:13:21.280354 26359 solver.cpp:340] Iteration 219500, Testing net (#0)
I0708 11:17:15.780160 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7603
I0708 11:17:15.780364 26359 solver.cpp:408]     Test net output #1: loss = 0.490421 (* 1 = 0.490421 loss)
I0708 11:17:16.049757 26359 solver.cpp:236] Iteration 219500, loss = 0.490376
I0708 11:17:16.049804 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 11:17:16.049823 26359 solver.cpp:252]     Train net output #1: loss = 0.47417 (* 1 = 0.47417 loss)
I0708 11:17:16.049834 26359 sgd_solver.cpp:106] Iteration 219500, lr = 0.005
I0708 11:21:35.954740 26359 solver.cpp:236] Iteration 219600, loss = 0.478214
I0708 11:21:35.954996 26359 solver.cpp:252]     Train net output #0: accuracy = 0.71875
I0708 11:21:35.955039 26359 solver.cpp:252]     Train net output #1: loss = 0.545092 (* 1 = 0.545092 loss)
I0708 11:21:35.955059 26359 sgd_solver.cpp:106] Iteration 219600, lr = 0.005
I0708 11:23:12.902150 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 11:26:03.946790 26359 solver.cpp:236] Iteration 219700, loss = 0.470997
I0708 11:26:03.946957 26359 solver.cpp:252]     Train net output #0: accuracy = 0.796875
I0708 11:26:03.946991 26359 solver.cpp:252]     Train net output #1: loss = 0.417529 (* 1 = 0.417529 loss)
I0708 11:26:03.947013 26359 sgd_solver.cpp:106] Iteration 219700, lr = 0.005
I0708 11:28:43.093420 26359 solver.cpp:340] Iteration 219750, Testing net (#0)
I0708 11:31:18.742420 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7817
I0708 11:31:18.742610 26359 solver.cpp:408]     Test net output #1: loss = 0.462652 (* 1 = 0.462652 loss)
I0708 11:33:01.621768 26359 solver.cpp:236] Iteration 219800, loss = 0.47642
I0708 11:33:01.621912 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0708 11:33:01.621939 26359 solver.cpp:252]     Train net output #1: loss = 0.483249 (* 1 = 0.483249 loss)
I0708 11:33:01.621959 26359 sgd_solver.cpp:106] Iteration 219800, lr = 0.005
I0708 11:36:36.397894 26359 solver.cpp:236] Iteration 219900, loss = 0.475118
I0708 11:36:36.398078 26359 solver.cpp:252]     Train net output #0: accuracy = 0.734375
I0708 11:36:36.398107 26359 solver.cpp:252]     Train net output #1: loss = 0.555873 (* 1 = 0.555873 loss)
I0708 11:36:36.398118 26359 sgd_solver.cpp:106] Iteration 219900, lr = 0.005
I0708 11:40:09.112814 26359 solver.cpp:461] Snapshotting to binary proto file models/cnn10_iter_220000.caffemodel
I0708 11:40:09.720969 26359 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/cnn10_iter_220000.solverstate
I0708 11:40:09.756623 26359 solver.cpp:340] Iteration 220000, Testing net (#0)
I0708 11:42:50.635699 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7903
I0708 11:42:50.635872 26359 solver.cpp:408]     Test net output #1: loss = 0.455769 (* 1 = 0.455769 loss)
I0708 11:42:50.774070 26359 solver.cpp:236] Iteration 220000, loss = 0.476426
I0708 11:42:50.774127 26359 solver.cpp:252]     Train net output #0: accuracy = 0.84375
I0708 11:42:50.774149 26359 solver.cpp:252]     Train net output #1: loss = 0.410191 (* 1 = 0.410191 loss)
I0708 11:42:50.774163 26359 sgd_solver.cpp:106] Iteration 220000, lr = 0.005
I0708 11:46:20.585734 26359 solver.cpp:236] Iteration 220100, loss = 0.472733
I0708 11:46:20.585921 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 11:46:20.585952 26359 solver.cpp:252]     Train net output #1: loss = 0.435773 (* 1 = 0.435773 loss)
I0708 11:46:20.585963 26359 sgd_solver.cpp:106] Iteration 220100, lr = 0.005
I0708 11:49:57.618497 26359 solver.cpp:236] Iteration 220200, loss = 0.471322
I0708 11:49:57.618649 26359 solver.cpp:252]     Train net output #0: accuracy = 0.851562
I0708 11:49:57.618669 26359 solver.cpp:252]     Train net output #1: loss = 0.413094 (* 1 = 0.413094 loss)
I0708 11:49:57.618698 26359 sgd_solver.cpp:106] Iteration 220200, lr = 0.005
I0708 11:52:19.990442 26359 solver.cpp:340] Iteration 220250, Testing net (#0)
I0708 11:54:31.308138 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7845
I0708 11:54:31.308326 26359 solver.cpp:408]     Test net output #1: loss = 0.458024 (* 1 = 0.458024 loss)
I0708 11:56:32.186370 26359 solver.cpp:236] Iteration 220300, loss = 0.486408
I0708 11:56:32.186539 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 11:56:32.186583 26359 solver.cpp:252]     Train net output #1: loss = 0.458336 (* 1 = 0.458336 loss)
I0708 11:56:32.186596 26359 sgd_solver.cpp:106] Iteration 220300, lr = 0.005
I0708 11:59:51.352540 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 12:01:13.771473 26359 solver.cpp:236] Iteration 220400, loss = 0.463663
I0708 12:01:13.771612 26359 solver.cpp:252]     Train net output #0: accuracy = 0.773438
I0708 12:01:13.771632 26359 solver.cpp:252]     Train net output #1: loss = 0.446015 (* 1 = 0.446015 loss)
I0708 12:01:13.771652 26359 sgd_solver.cpp:106] Iteration 220400, lr = 0.005
I0708 12:04:42.819676 26359 solver.cpp:340] Iteration 220500, Testing net (#0)
I0708 12:07:01.677863 26359 solver.cpp:408]     Test net output #0: accuracy = 0.784
I0708 12:07:01.678058 26359 solver.cpp:408]     Test net output #1: loss = 0.461315 (* 1 = 0.461315 loss)
I0708 12:07:01.816577 26359 solver.cpp:236] Iteration 220500, loss = 0.468767
I0708 12:07:01.816643 26359 solver.cpp:252]     Train net output #0: accuracy = 0.789062
I0708 12:07:01.816668 26359 solver.cpp:252]     Train net output #1: loss = 0.465103 (* 1 = 0.465103 loss)
I0708 12:07:01.816691 26359 sgd_solver.cpp:106] Iteration 220500, lr = 0.005
I0708 12:10:32.186558 26359 solver.cpp:236] Iteration 220600, loss = 0.473488
I0708 12:10:32.186746 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 12:10:32.186769 26359 solver.cpp:252]     Train net output #1: loss = 0.451621 (* 1 = 0.451621 loss)
I0708 12:10:32.186781 26359 sgd_solver.cpp:106] Iteration 220600, lr = 0.005
I0708 12:14:11.453976 26359 solver.cpp:236] Iteration 220700, loss = 0.462526
I0708 12:14:11.454121 26359 solver.cpp:252]     Train net output #0: accuracy = 0.78125
I0708 12:14:11.454149 26359 solver.cpp:252]     Train net output #1: loss = 0.459369 (* 1 = 0.459369 loss)
I0708 12:14:11.454179 26359 sgd_solver.cpp:106] Iteration 220700, lr = 0.005
I0708 12:15:57.108328 26359 solver.cpp:340] Iteration 220750, Testing net (#0)
I0708 12:17:46.772656 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7826
I0708 12:17:46.772826 26359 solver.cpp:408]     Test net output #1: loss = 0.45678 (* 1 = 0.45678 loss)
I0708 12:19:30.974741 26359 solver.cpp:236] Iteration 220800, loss = 0.469298
I0708 12:19:30.974876 26359 solver.cpp:252]     Train net output #0: accuracy = 0.742188
I0708 12:19:30.974906 26359 solver.cpp:252]     Train net output #1: loss = 0.509178 (* 1 = 0.509178 loss)
I0708 12:19:30.974917 26359 sgd_solver.cpp:106] Iteration 220800, lr = 0.005
I0708 12:23:18.274040 26359 solver.cpp:236] Iteration 220900, loss = 0.480569
I0708 12:23:18.274173 26359 solver.cpp:252]     Train net output #0: accuracy = 0.765625
I0708 12:23:18.274193 26359 solver.cpp:252]     Train net output #1: loss = 0.495552 (* 1 = 0.495552 loss)
I0708 12:23:18.274224 26359 sgd_solver.cpp:106] Iteration 220900, lr = 0.005
I0708 12:27:15.168828 26359 solver.cpp:340] Iteration 221000, Testing net (#0)
I0708 12:28:29.413872 26359 solver.cpp:408]     Test net output #0: accuracy = 0.7821
I0708 12:28:29.414016 26359 solver.cpp:408]     Test net output #1: loss = 0.470479 (* 1 = 0.470479 loss)
I0708 12:28:29.552569 26359 solver.cpp:236] Iteration 221000, loss = 0.465751
I0708 12:28:29.552604 26359 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0708 12:28:29.552619 26359 solver.cpp:252]     Train net output #1: loss = 0.482707 (* 1 = 0.482707 loss)
I0708 12:28:29.552630 26359 sgd_solver.cpp:106] Iteration 221000, lr = 0.005
I0708 12:31:14.541447 26359 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 12:31:58.792775 26359 solver.cpp:236] Iteration 221100, loss = 0.467251
I0708 12:31:58.792912 26359 solver.cpp:252]     Train net output #0: accuracy = 0.726562
I0708 12:31:58.792930 26359 solver.cpp:252]     Train net output #1: loss = 0.523823 (* 1 = 0.523823 loss)
I0708 12:31:58.792963 26359 sgd_solver.cpp:106] Iteration 221100, lr = 0.005
I0708 12:35:31.001905 26359 solver.cpp:236] Iteration 221200, loss = 0.466876
I0708 12:35:31.002055 26359 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0708 12:35:31.002084 26359 solver.cpp:252]     Train net output #1: loss = 0.537398 (* 1 = 0.537398 loss)
I0708 12:35:31.002095 26359 sgd_solver.cpp:106] Iteration 221200, lr = 0.005
I0708 12:37:14.504899 26359 solver.cpp:340] Iteration 221250, Testing net (#0)
