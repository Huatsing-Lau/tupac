Log file created at: 2016/07/28 12:55:28
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0728 12:55:28.521129 118397 caffe.cpp:184] Using GPUs 3
I0728 12:55:28.912051 118397 solver.cpp:47] Initializing solver from parameters: 
test_iter: 10
test_interval: 500
base_lr: 0.01
display: 10
max_iter: 25000
lr_policy: "step"
gamma: 0.9
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 1000
snapshot_prefix: "models/fnet"
solver_mode: GPU
device_id: 3
net: "train_val.prototxt"
test_initialization: true
average_loss: 100
I0728 12:55:28.912295 118397 solver.cpp:90] Creating training net from net file: train_val.prototxt
I0728 12:55:28.912902 118397 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0728 12:55:28.912940 118397 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0728 12:55:28.913108 118397 net.cpp:49] Initializing net from parameters: 
name: "Net"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "mask_image_layer"
    layer: "random_patches_from_images_withlabel"
    param_str: "{\'root_folder\': \'/home/dywang/Proliferation/data/mitoses\', \'image_list\': \'/home/dywang/00exp_wdy/stage04_mitosisDetection/step02_train_mitosis_detecotor/heatmap_mc13_tr/all_image_withlabel_mc13_tr.lst\', \'seed\': 8899, \'mean\': (128, 128, 128), \'size\': 64, \'batch\': 128, \'scale\':0.1, \'colorn\':20, \'classes\':\'1:0 2:1 3:0\', \'DEBUG\': True}"
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_c"
  type: "Convolution"
  bottom: "conv4"
  top: "conv_c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv_c"
  bottom: "label"
  top: "loss"
}
I0728 12:55:28.914261 118397 layer_factory.hpp:76] Creating layer data
I0728 12:55:33.139036 118397 net.cpp:106] Creating Layer data
I0728 12:55:33.139127 118397 net.cpp:411] data -> data
I0728 12:55:33.139159 118397 net.cpp:411] data -> label
I0728 12:55:42.477097 118397 net.cpp:150] Setting up data
I0728 12:55:42.477176 118397 net.cpp:157] Top shape: 128 3 64 64 (1572864)
I0728 12:55:42.477190 118397 net.cpp:157] Top shape: 128 1 1 1 (128)
I0728 12:55:42.477200 118397 net.cpp:165] Memory required for data: 6291968
I0728 12:55:42.477218 118397 layer_factory.hpp:76] Creating layer conv11
I0728 12:55:42.477264 118397 net.cpp:106] Creating Layer conv11
I0728 12:55:42.477277 118397 net.cpp:454] conv11 <- data
I0728 12:55:42.477303 118397 net.cpp:411] conv11 -> conv11
I0728 12:55:42.681773 118397 net.cpp:150] Setting up conv11
I0728 12:55:42.681835 118397 net.cpp:157] Top shape: 128 32 62 62 (15745024)
I0728 12:55:42.681850 118397 net.cpp:165] Memory required for data: 69272064
I0728 12:55:42.681895 118397 layer_factory.hpp:76] Creating layer relu11
I0728 12:55:42.681926 118397 net.cpp:106] Creating Layer relu11
I0728 12:55:42.681943 118397 net.cpp:454] relu11 <- conv11
I0728 12:55:42.681960 118397 net.cpp:397] relu11 -> conv11 (in-place)
I0728 12:55:42.682199 118397 net.cpp:150] Setting up relu11
I0728 12:55:42.682221 118397 net.cpp:157] Top shape: 128 32 62 62 (15745024)
I0728 12:55:42.682236 118397 net.cpp:165] Memory required for data: 132252160
I0728 12:55:42.682250 118397 layer_factory.hpp:76] Creating layer conv12
I0728 12:55:42.682276 118397 net.cpp:106] Creating Layer conv12
I0728 12:55:42.682291 118397 net.cpp:454] conv12 <- conv11
I0728 12:55:42.682308 118397 net.cpp:411] conv12 -> conv12
I0728 12:55:42.684315 118397 net.cpp:150] Setting up conv12
I0728 12:55:42.684339 118397 net.cpp:157] Top shape: 128 32 60 60 (14745600)
I0728 12:55:42.684348 118397 net.cpp:165] Memory required for data: 191234560
I0728 12:55:42.684365 118397 layer_factory.hpp:76] Creating layer relu12
I0728 12:55:42.684381 118397 net.cpp:106] Creating Layer relu12
I0728 12:55:42.684391 118397 net.cpp:454] relu12 <- conv12
I0728 12:55:42.684402 118397 net.cpp:397] relu12 -> conv12 (in-place)
I0728 12:55:42.684721 118397 net.cpp:150] Setting up relu12
I0728 12:55:42.684741 118397 net.cpp:157] Top shape: 128 32 60 60 (14745600)
I0728 12:55:42.684749 118397 net.cpp:165] Memory required for data: 250216960
I0728 12:55:42.684792 118397 layer_factory.hpp:76] Creating layer pool1
I0728 12:55:42.684808 118397 net.cpp:106] Creating Layer pool1
I0728 12:55:42.684818 118397 net.cpp:454] pool1 <- conv12
I0728 12:55:42.684828 118397 net.cpp:411] pool1 -> pool1
I0728 12:55:42.685065 118397 net.cpp:150] Setting up pool1
I0728 12:55:42.685083 118397 net.cpp:157] Top shape: 128 32 30 30 (3686400)
I0728 12:55:42.685092 118397 net.cpp:165] Memory required for data: 264962560
I0728 12:55:42.685101 118397 layer_factory.hpp:76] Creating layer conv21
I0728 12:55:42.685118 118397 net.cpp:106] Creating Layer conv21
I0728 12:55:42.685128 118397 net.cpp:454] conv21 <- pool1
I0728 12:55:42.685139 118397 net.cpp:411] conv21 -> conv21
I0728 12:55:42.687338 118397 net.cpp:150] Setting up conv21
I0728 12:55:42.687362 118397 net.cpp:157] Top shape: 128 64 28 28 (6422528)
I0728 12:55:42.687372 118397 net.cpp:165] Memory required for data: 290652672
I0728 12:55:42.687387 118397 layer_factory.hpp:76] Creating layer relu21
I0728 12:55:42.687403 118397 net.cpp:106] Creating Layer relu21
I0728 12:55:42.687415 118397 net.cpp:454] relu21 <- conv21
I0728 12:55:42.687427 118397 net.cpp:397] relu21 -> conv21 (in-place)
I0728 12:55:42.687744 118397 net.cpp:150] Setting up relu21
I0728 12:55:42.687767 118397 net.cpp:157] Top shape: 128 64 28 28 (6422528)
I0728 12:55:42.687777 118397 net.cpp:165] Memory required for data: 316342784
I0728 12:55:42.687785 118397 layer_factory.hpp:76] Creating layer conv22
I0728 12:55:42.687808 118397 net.cpp:106] Creating Layer conv22
I0728 12:55:42.687819 118397 net.cpp:454] conv22 <- conv21
I0728 12:55:42.687834 118397 net.cpp:411] conv22 -> conv22
I0728 12:55:42.689906 118397 net.cpp:150] Setting up conv22
I0728 12:55:42.689929 118397 net.cpp:157] Top shape: 128 64 26 26 (5537792)
I0728 12:55:42.689939 118397 net.cpp:165] Memory required for data: 338493952
I0728 12:55:42.689951 118397 layer_factory.hpp:76] Creating layer relu22
I0728 12:55:42.689965 118397 net.cpp:106] Creating Layer relu22
I0728 12:55:42.689975 118397 net.cpp:454] relu22 <- conv22
I0728 12:55:42.689990 118397 net.cpp:397] relu22 -> conv22 (in-place)
I0728 12:55:42.690302 118397 net.cpp:150] Setting up relu22
I0728 12:55:42.690323 118397 net.cpp:157] Top shape: 128 64 26 26 (5537792)
I0728 12:55:42.690335 118397 net.cpp:165] Memory required for data: 360645120
I0728 12:55:42.690343 118397 layer_factory.hpp:76] Creating layer pool2
I0728 12:55:42.690356 118397 net.cpp:106] Creating Layer pool2
I0728 12:55:42.690366 118397 net.cpp:454] pool2 <- conv22
I0728 12:55:42.690378 118397 net.cpp:411] pool2 -> pool2
I0728 12:55:42.690582 118397 net.cpp:150] Setting up pool2
I0728 12:55:42.690600 118397 net.cpp:157] Top shape: 128 64 13 13 (1384448)
I0728 12:55:42.690609 118397 net.cpp:165] Memory required for data: 366182912
I0728 12:55:42.690619 118397 layer_factory.hpp:76] Creating layer conv31
I0728 12:55:42.690649 118397 net.cpp:106] Creating Layer conv31
I0728 12:55:42.690659 118397 net.cpp:454] conv31 <- pool2
I0728 12:55:42.690671 118397 net.cpp:411] conv31 -> conv31
I0728 12:55:42.694748 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0728 12:55:42.694969 118397 net.cpp:150] Setting up conv31
I0728 12:55:42.694990 118397 net.cpp:157] Top shape: 128 128 11 11 (1982464)
I0728 12:55:42.695000 118397 net.cpp:165] Memory required for data: 374112768
I0728 12:55:42.695015 118397 layer_factory.hpp:76] Creating layer relu31
I0728 12:55:42.695034 118397 net.cpp:106] Creating Layer relu31
I0728 12:55:42.695083 118397 net.cpp:454] relu31 <- conv31
I0728 12:55:42.695117 118397 net.cpp:397] relu31 -> conv31 (in-place)
I0728 12:55:42.695713 118397 net.cpp:150] Setting up relu31
I0728 12:55:42.695734 118397 net.cpp:157] Top shape: 128 128 11 11 (1982464)
I0728 12:55:42.695740 118397 net.cpp:165] Memory required for data: 382042624
I0728 12:55:42.695750 118397 layer_factory.hpp:76] Creating layer conv32
I0728 12:55:42.695772 118397 net.cpp:106] Creating Layer conv32
I0728 12:55:42.695780 118397 net.cpp:454] conv32 <- conv31
I0728 12:55:42.695791 118397 net.cpp:411] conv32 -> conv32
I0728 12:55:42.698580 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0728 12:55:42.698612 118397 net.cpp:150] Setting up conv32
I0728 12:55:42.698746 118397 net.cpp:157] Top shape: 128 128 9 9 (1327104)
I0728 12:55:42.698791 118397 net.cpp:165] Memory required for data: 387351040
I0728 12:55:42.698837 118397 layer_factory.hpp:76] Creating layer relu32
I0728 12:55:42.698879 118397 net.cpp:106] Creating Layer relu32
I0728 12:55:42.698916 118397 net.cpp:454] relu32 <- conv32
I0728 12:55:42.698954 118397 net.cpp:397] relu32 -> conv32 (in-place)
I0728 12:55:42.699220 118397 net.cpp:150] Setting up relu32
I0728 12:55:42.699268 118397 net.cpp:157] Top shape: 128 128 9 9 (1327104)
I0728 12:55:42.699304 118397 net.cpp:165] Memory required for data: 392659456
I0728 12:55:42.699340 118397 layer_factory.hpp:76] Creating layer pool3
I0728 12:55:42.699383 118397 net.cpp:106] Creating Layer pool3
I0728 12:55:42.699419 118397 net.cpp:454] pool3 <- conv32
I0728 12:55:42.699460 118397 net.cpp:411] pool3 -> pool3
I0728 12:55:42.699934 118397 net.cpp:150] Setting up pool3
I0728 12:55:42.699985 118397 net.cpp:157] Top shape: 128 128 3 3 (147456)
I0728 12:55:42.700021 118397 net.cpp:165] Memory required for data: 393249280
I0728 12:55:42.700063 118397 layer_factory.hpp:76] Creating layer conv4
I0728 12:55:42.700116 118397 net.cpp:106] Creating Layer conv4
I0728 12:55:42.700155 118397 net.cpp:454] conv4 <- pool3
I0728 12:55:42.700198 118397 net.cpp:411] conv4 -> conv4
I0728 12:55:42.714876 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1769472
I0728 12:55:42.715160 118397 net.cpp:150] Setting up conv4
I0728 12:55:42.715211 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:42.715248 118397 net.cpp:165] Memory required for data: 393380352
I0728 12:55:42.715292 118397 layer_factory.hpp:76] Creating layer relu4
I0728 12:55:42.715338 118397 net.cpp:106] Creating Layer relu4
I0728 12:55:42.715378 118397 net.cpp:454] relu4 <- conv4
I0728 12:55:42.715415 118397 net.cpp:397] relu4 -> conv4 (in-place)
I0728 12:55:42.715837 118397 net.cpp:150] Setting up relu4
I0728 12:55:42.715891 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:42.715929 118397 net.cpp:165] Memory required for data: 393511424
I0728 12:55:42.715967 118397 layer_factory.hpp:76] Creating layer drop
I0728 12:55:42.716014 118397 net.cpp:106] Creating Layer drop
I0728 12:55:42.716053 118397 net.cpp:454] drop <- conv4
I0728 12:55:42.716089 118397 net.cpp:397] drop -> conv4 (in-place)
I0728 12:55:42.716173 118397 net.cpp:150] Setting up drop
I0728 12:55:42.716215 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:42.716253 118397 net.cpp:165] Memory required for data: 393642496
I0728 12:55:42.716287 118397 layer_factory.hpp:76] Creating layer conv_c
I0728 12:55:42.716333 118397 net.cpp:106] Creating Layer conv_c
I0728 12:55:42.716368 118397 net.cpp:454] conv_c <- conv4
I0728 12:55:42.716411 118397 net.cpp:411] conv_c -> conv_c
I0728 12:55:42.720825 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0728 12:55:42.721109 118397 net.cpp:150] Setting up conv_c
I0728 12:55:42.721159 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:42.721199 118397 net.cpp:165] Memory required for data: 393773568
I0728 12:55:42.721245 118397 layer_factory.hpp:76] Creating layer loss
I0728 12:55:42.721292 118397 net.cpp:106] Creating Layer loss
I0728 12:55:42.721328 118397 net.cpp:454] loss <- conv_c
I0728 12:55:42.721375 118397 net.cpp:454] loss <- label
I0728 12:55:42.721416 118397 net.cpp:411] loss -> loss
I0728 12:55:42.721465 118397 layer_factory.hpp:76] Creating layer loss
I0728 12:55:42.721905 118397 net.cpp:150] Setting up loss
I0728 12:55:42.721930 118397 net.cpp:157] Top shape: (1)
I0728 12:55:42.721945 118397 net.cpp:160]     with loss weight 1
I0728 12:55:42.721983 118397 net.cpp:165] Memory required for data: 393773572
I0728 12:55:42.721999 118397 net.cpp:226] loss needs backward computation.
I0728 12:55:42.722013 118397 net.cpp:226] conv_c needs backward computation.
I0728 12:55:42.722046 118397 net.cpp:226] drop needs backward computation.
I0728 12:55:42.722069 118397 net.cpp:226] relu4 needs backward computation.
I0728 12:55:42.722081 118397 net.cpp:226] conv4 needs backward computation.
I0728 12:55:42.722095 118397 net.cpp:226] pool3 needs backward computation.
I0728 12:55:42.722110 118397 net.cpp:226] relu32 needs backward computation.
I0728 12:55:42.722121 118397 net.cpp:226] conv32 needs backward computation.
I0728 12:55:42.722136 118397 net.cpp:226] relu31 needs backward computation.
I0728 12:55:42.722148 118397 net.cpp:226] conv31 needs backward computation.
I0728 12:55:42.722162 118397 net.cpp:226] pool2 needs backward computation.
I0728 12:55:42.722175 118397 net.cpp:226] relu22 needs backward computation.
I0728 12:55:42.722189 118397 net.cpp:226] conv22 needs backward computation.
I0728 12:55:42.722203 118397 net.cpp:226] relu21 needs backward computation.
I0728 12:55:42.722223 118397 net.cpp:226] conv21 needs backward computation.
I0728 12:55:42.722237 118397 net.cpp:226] pool1 needs backward computation.
I0728 12:55:42.722257 118397 net.cpp:226] relu12 needs backward computation.
I0728 12:55:42.722273 118397 net.cpp:226] conv12 needs backward computation.
I0728 12:55:42.722286 118397 net.cpp:226] relu11 needs backward computation.
I0728 12:55:42.722301 118397 net.cpp:226] conv11 needs backward computation.
I0728 12:55:42.722314 118397 net.cpp:228] data does not need backward computation.
I0728 12:55:42.722327 118397 net.cpp:270] This network produces output loss
I0728 12:55:42.722358 118397 net.cpp:283] Network initialization done.
I0728 12:55:42.723155 118397 solver.cpp:180] Creating test net (#0) specified by net file: train_val.prototxt
I0728 12:55:42.723214 118397 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0728 12:55:42.723412 118397 net.cpp:49] Initializing net from parameters: 
name: "Net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "mask_image_layer"
    layer: "random_patches_from_images_withlabel"
    param_str: "{\'root_folder\': \'/home/dywang/Proliferation/data/mitoses\', \'image_list\': \'/home/dywang/00exp_wdy/stage04_mitosisDetection/step02_train_mitosis_detecotor/heatmap_mc13_tr/all_image_withlabel_mc13_tr.lst\', \'seed\': 8899, \'mean\': (128, 128, 128), \'size\': 64, \'batch\': 128, \'scale\':0.1, \'colorn\':20, \'classes\':\'1:0 2:1 3:0\', \'DEBUG\': True}"
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv_c"
  type: "Convolution"
  bottom: "conv4"
  top: "conv_c"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.04
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv_c"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv_c"
  bottom: "label"
  top: "loss"
}
I0728 12:55:42.725220 118397 layer_factory.hpp:76] Creating layer data
I0728 12:55:42.725373 118397 net.cpp:106] Creating Layer data
I0728 12:55:42.725394 118397 net.cpp:411] data -> data
I0728 12:55:42.725415 118397 net.cpp:411] data -> label
I0728 12:55:52.467892 118397 net.cpp:150] Setting up data
I0728 12:55:52.467964 118397 net.cpp:157] Top shape: 128 3 64 64 (1572864)
I0728 12:55:52.467978 118397 net.cpp:157] Top shape: 128 1 1 1 (128)
I0728 12:55:52.467986 118397 net.cpp:165] Memory required for data: 6291968
I0728 12:55:52.468003 118397 layer_factory.hpp:76] Creating layer label_data_1_split
I0728 12:55:52.468050 118397 net.cpp:106] Creating Layer label_data_1_split
I0728 12:55:52.468063 118397 net.cpp:454] label_data_1_split <- label
I0728 12:55:52.468081 118397 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0728 12:55:52.468099 118397 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0728 12:55:52.468150 118397 net.cpp:150] Setting up label_data_1_split
I0728 12:55:52.468176 118397 net.cpp:157] Top shape: 128 1 1 1 (128)
I0728 12:55:52.468197 118397 net.cpp:157] Top shape: 128 1 1 1 (128)
I0728 12:55:52.468206 118397 net.cpp:165] Memory required for data: 6292992
I0728 12:55:52.468245 118397 layer_factory.hpp:76] Creating layer conv11
I0728 12:55:52.468268 118397 net.cpp:106] Creating Layer conv11
I0728 12:55:52.468279 118397 net.cpp:454] conv11 <- data
I0728 12:55:52.468291 118397 net.cpp:411] conv11 -> conv11
I0728 12:55:52.469954 118397 net.cpp:150] Setting up conv11
I0728 12:55:52.469979 118397 net.cpp:157] Top shape: 128 32 62 62 (15745024)
I0728 12:55:52.469990 118397 net.cpp:165] Memory required for data: 69273088
I0728 12:55:52.470008 118397 layer_factory.hpp:76] Creating layer relu11
I0728 12:55:52.470027 118397 net.cpp:106] Creating Layer relu11
I0728 12:55:52.470038 118397 net.cpp:454] relu11 <- conv11
I0728 12:55:52.470051 118397 net.cpp:397] relu11 -> conv11 (in-place)
I0728 12:55:52.470371 118397 net.cpp:150] Setting up relu11
I0728 12:55:52.470391 118397 net.cpp:157] Top shape: 128 32 62 62 (15745024)
I0728 12:55:52.470402 118397 net.cpp:165] Memory required for data: 132253184
I0728 12:55:52.470412 118397 layer_factory.hpp:76] Creating layer conv12
I0728 12:55:52.470429 118397 net.cpp:106] Creating Layer conv12
I0728 12:55:52.470440 118397 net.cpp:454] conv12 <- conv11
I0728 12:55:52.470453 118397 net.cpp:411] conv12 -> conv12
I0728 12:55:52.471609 118397 net.cpp:150] Setting up conv12
I0728 12:55:52.471633 118397 net.cpp:157] Top shape: 128 32 60 60 (14745600)
I0728 12:55:52.471643 118397 net.cpp:165] Memory required for data: 191235584
I0728 12:55:52.471662 118397 layer_factory.hpp:76] Creating layer relu12
I0728 12:55:52.471678 118397 net.cpp:106] Creating Layer relu12
I0728 12:55:52.471688 118397 net.cpp:454] relu12 <- conv12
I0728 12:55:52.471699 118397 net.cpp:397] relu12 -> conv12 (in-place)
I0728 12:55:52.472015 118397 net.cpp:150] Setting up relu12
I0728 12:55:52.472036 118397 net.cpp:157] Top shape: 128 32 60 60 (14745600)
I0728 12:55:52.472046 118397 net.cpp:165] Memory required for data: 250217984
I0728 12:55:52.472057 118397 layer_factory.hpp:76] Creating layer pool1
I0728 12:55:52.472071 118397 net.cpp:106] Creating Layer pool1
I0728 12:55:52.472081 118397 net.cpp:454] pool1 <- conv12
I0728 12:55:52.472093 118397 net.cpp:411] pool1 -> pool1
I0728 12:55:52.472287 118397 net.cpp:150] Setting up pool1
I0728 12:55:52.472306 118397 net.cpp:157] Top shape: 128 32 30 30 (3686400)
I0728 12:55:52.472316 118397 net.cpp:165] Memory required for data: 264963584
I0728 12:55:52.472326 118397 layer_factory.hpp:76] Creating layer conv21
I0728 12:55:52.472340 118397 net.cpp:106] Creating Layer conv21
I0728 12:55:52.472350 118397 net.cpp:454] conv21 <- pool1
I0728 12:55:52.472363 118397 net.cpp:411] conv21 -> conv21
I0728 12:55:52.474040 118397 net.cpp:150] Setting up conv21
I0728 12:55:52.474061 118397 net.cpp:157] Top shape: 128 64 28 28 (6422528)
I0728 12:55:52.474072 118397 net.cpp:165] Memory required for data: 290653696
I0728 12:55:52.474089 118397 layer_factory.hpp:76] Creating layer relu21
I0728 12:55:52.474104 118397 net.cpp:106] Creating Layer relu21
I0728 12:55:52.474114 118397 net.cpp:454] relu21 <- conv21
I0728 12:55:52.474126 118397 net.cpp:397] relu21 -> conv21 (in-place)
I0728 12:55:52.474442 118397 net.cpp:150] Setting up relu21
I0728 12:55:52.474463 118397 net.cpp:157] Top shape: 128 64 28 28 (6422528)
I0728 12:55:52.474473 118397 net.cpp:165] Memory required for data: 316343808
I0728 12:55:52.474485 118397 layer_factory.hpp:76] Creating layer conv22
I0728 12:55:52.474500 118397 net.cpp:106] Creating Layer conv22
I0728 12:55:52.474510 118397 net.cpp:454] conv22 <- conv21
I0728 12:55:52.474524 118397 net.cpp:411] conv22 -> conv22
I0728 12:55:52.476725 118397 net.cpp:150] Setting up conv22
I0728 12:55:52.476749 118397 net.cpp:157] Top shape: 128 64 26 26 (5537792)
I0728 12:55:52.476760 118397 net.cpp:165] Memory required for data: 338494976
I0728 12:55:52.476774 118397 layer_factory.hpp:76] Creating layer relu22
I0728 12:55:52.476788 118397 net.cpp:106] Creating Layer relu22
I0728 12:55:52.476799 118397 net.cpp:454] relu22 <- conv22
I0728 12:55:52.476810 118397 net.cpp:397] relu22 -> conv22 (in-place)
I0728 12:55:52.476975 118397 net.cpp:150] Setting up relu22
I0728 12:55:52.477010 118397 net.cpp:157] Top shape: 128 64 26 26 (5537792)
I0728 12:55:52.477020 118397 net.cpp:165] Memory required for data: 360646144
I0728 12:55:52.477031 118397 layer_factory.hpp:76] Creating layer pool2
I0728 12:55:52.477046 118397 net.cpp:106] Creating Layer pool2
I0728 12:55:52.477056 118397 net.cpp:454] pool2 <- conv22
I0728 12:55:52.477066 118397 net.cpp:411] pool2 -> pool2
I0728 12:55:52.477406 118397 net.cpp:150] Setting up pool2
I0728 12:55:52.477427 118397 net.cpp:157] Top shape: 128 64 13 13 (1384448)
I0728 12:55:52.477437 118397 net.cpp:165] Memory required for data: 366183936
I0728 12:55:52.477447 118397 layer_factory.hpp:76] Creating layer conv31
I0728 12:55:52.477463 118397 net.cpp:106] Creating Layer conv31
I0728 12:55:52.477473 118397 net.cpp:454] conv31 <- pool2
I0728 12:55:52.477488 118397 net.cpp:411] conv31 -> conv31
I0728 12:55:52.481360 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0728 12:55:52.481422 118397 net.cpp:150] Setting up conv31
I0728 12:55:52.481438 118397 net.cpp:157] Top shape: 128 128 11 11 (1982464)
I0728 12:55:52.481448 118397 net.cpp:165] Memory required for data: 374113792
I0728 12:55:52.481465 118397 layer_factory.hpp:76] Creating layer relu31
I0728 12:55:52.481479 118397 net.cpp:106] Creating Layer relu31
I0728 12:55:52.481490 118397 net.cpp:454] relu31 <- conv31
I0728 12:55:52.481503 118397 net.cpp:397] relu31 -> conv31 (in-place)
I0728 12:55:52.481812 118397 net.cpp:150] Setting up relu31
I0728 12:55:52.481833 118397 net.cpp:157] Top shape: 128 128 11 11 (1982464)
I0728 12:55:52.481843 118397 net.cpp:165] Memory required for data: 382043648
I0728 12:55:52.481855 118397 layer_factory.hpp:76] Creating layer conv32
I0728 12:55:52.481873 118397 net.cpp:106] Creating Layer conv32
I0728 12:55:52.481884 118397 net.cpp:454] conv32 <- conv31
I0728 12:55:52.481897 118397 net.cpp:411] conv32 -> conv32
I0728 12:55:52.483966 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0728 12:55:52.484002 118397 net.cpp:150] Setting up conv32
I0728 12:55:52.484016 118397 net.cpp:157] Top shape: 128 128 9 9 (1327104)
I0728 12:55:52.484026 118397 net.cpp:165] Memory required for data: 387352064
I0728 12:55:52.484040 118397 layer_factory.hpp:76] Creating layer relu32
I0728 12:55:52.484053 118397 net.cpp:106] Creating Layer relu32
I0728 12:55:52.484064 118397 net.cpp:454] relu32 <- conv32
I0728 12:55:52.484076 118397 net.cpp:397] relu32 -> conv32 (in-place)
I0728 12:55:52.484244 118397 net.cpp:150] Setting up relu32
I0728 12:55:52.484261 118397 net.cpp:157] Top shape: 128 128 9 9 (1327104)
I0728 12:55:52.484272 118397 net.cpp:165] Memory required for data: 392660480
I0728 12:55:52.484283 118397 layer_factory.hpp:76] Creating layer pool3
I0728 12:55:52.484297 118397 net.cpp:106] Creating Layer pool3
I0728 12:55:52.484308 118397 net.cpp:454] pool3 <- conv32
I0728 12:55:52.484320 118397 net.cpp:411] pool3 -> pool3
I0728 12:55:52.484696 118397 net.cpp:150] Setting up pool3
I0728 12:55:52.484717 118397 net.cpp:157] Top shape: 128 128 3 3 (147456)
I0728 12:55:52.484727 118397 net.cpp:165] Memory required for data: 393250304
I0728 12:55:52.484738 118397 layer_factory.hpp:76] Creating layer conv4
I0728 12:55:52.484753 118397 net.cpp:106] Creating Layer conv4
I0728 12:55:52.484764 118397 net.cpp:454] conv4 <- pool3
I0728 12:55:52.484778 118397 net.cpp:411] conv4 -> conv4
I0728 12:55:52.496140 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1769472
I0728 12:55:52.496369 118397 net.cpp:150] Setting up conv4
I0728 12:55:52.496399 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:52.496409 118397 net.cpp:165] Memory required for data: 393381376
I0728 12:55:52.496423 118397 layer_factory.hpp:76] Creating layer relu4
I0728 12:55:52.496434 118397 net.cpp:106] Creating Layer relu4
I0728 12:55:52.496443 118397 net.cpp:454] relu4 <- conv4
I0728 12:55:52.496462 118397 net.cpp:397] relu4 -> conv4 (in-place)
I0728 12:55:52.496645 118397 net.cpp:150] Setting up relu4
I0728 12:55:52.496672 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:52.496696 118397 net.cpp:165] Memory required for data: 393512448
I0728 12:55:52.496706 118397 layer_factory.hpp:76] Creating layer drop
I0728 12:55:52.496728 118397 net.cpp:106] Creating Layer drop
I0728 12:55:52.496738 118397 net.cpp:454] drop <- conv4
I0728 12:55:52.496749 118397 net.cpp:397] drop -> conv4 (in-place)
I0728 12:55:52.496786 118397 net.cpp:150] Setting up drop
I0728 12:55:52.496800 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:52.496809 118397 net.cpp:165] Memory required for data: 393643520
I0728 12:55:52.496819 118397 layer_factory.hpp:76] Creating layer conv_c
I0728 12:55:52.496831 118397 net.cpp:106] Creating Layer conv_c
I0728 12:55:52.496841 118397 net.cpp:454] conv_c <- conv4
I0728 12:55:52.496852 118397 net.cpp:411] conv_c -> conv_c
I0728 12:55:52.500560 118397 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0728 12:55:52.500594 118397 net.cpp:150] Setting up conv_c
I0728 12:55:52.500608 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:52.500618 118397 net.cpp:165] Memory required for data: 393774592
I0728 12:55:52.500635 118397 layer_factory.hpp:76] Creating layer conv_c_conv_c_0_split
I0728 12:55:52.500649 118397 net.cpp:106] Creating Layer conv_c_conv_c_0_split
I0728 12:55:52.500660 118397 net.cpp:454] conv_c_conv_c_0_split <- conv_c
I0728 12:55:52.500674 118397 net.cpp:411] conv_c_conv_c_0_split -> conv_c_conv_c_0_split_0
I0728 12:55:52.500689 118397 net.cpp:411] conv_c_conv_c_0_split -> conv_c_conv_c_0_split_1
I0728 12:55:52.500735 118397 net.cpp:150] Setting up conv_c_conv_c_0_split
I0728 12:55:52.500749 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:52.500761 118397 net.cpp:157] Top shape: 128 256 1 1 (32768)
I0728 12:55:52.500771 118397 net.cpp:165] Memory required for data: 394036736
I0728 12:55:52.500779 118397 layer_factory.hpp:76] Creating layer accuracy
I0728 12:55:52.500798 118397 net.cpp:106] Creating Layer accuracy
I0728 12:55:52.500809 118397 net.cpp:454] accuracy <- conv_c_conv_c_0_split_0
I0728 12:55:52.500820 118397 net.cpp:454] accuracy <- label_data_1_split_0
I0728 12:55:52.500833 118397 net.cpp:411] accuracy -> accuracy
I0728 12:55:52.500851 118397 net.cpp:150] Setting up accuracy
I0728 12:55:52.500862 118397 net.cpp:157] Top shape: (1)
I0728 12:55:52.500872 118397 net.cpp:165] Memory required for data: 394036740
I0728 12:55:52.500882 118397 layer_factory.hpp:76] Creating layer loss
I0728 12:55:52.500897 118397 net.cpp:106] Creating Layer loss
I0728 12:55:52.500907 118397 net.cpp:454] loss <- conv_c_conv_c_0_split_1
I0728 12:55:52.500918 118397 net.cpp:454] loss <- label_data_1_split_1
I0728 12:55:52.500931 118397 net.cpp:411] loss -> loss
I0728 12:55:52.500946 118397 layer_factory.hpp:76] Creating layer loss
I0728 12:55:52.501363 118397 net.cpp:150] Setting up loss
I0728 12:55:52.501385 118397 net.cpp:157] Top shape: (1)
I0728 12:55:52.501395 118397 net.cpp:160]     with loss weight 1
I0728 12:55:52.501412 118397 net.cpp:165] Memory required for data: 394036744
I0728 12:55:52.501422 118397 net.cpp:226] loss needs backward computation.
I0728 12:55:52.501433 118397 net.cpp:228] accuracy does not need backward computation.
I0728 12:55:52.501444 118397 net.cpp:226] conv_c_conv_c_0_split needs backward computation.
I0728 12:55:52.501453 118397 net.cpp:226] conv_c needs backward computation.
I0728 12:55:52.501462 118397 net.cpp:226] drop needs backward computation.
I0728 12:55:52.501472 118397 net.cpp:226] relu4 needs backward computation.
I0728 12:55:52.501482 118397 net.cpp:226] conv4 needs backward computation.
I0728 12:55:52.501490 118397 net.cpp:226] pool3 needs backward computation.
I0728 12:55:52.501499 118397 net.cpp:226] relu32 needs backward computation.
I0728 12:55:52.501509 118397 net.cpp:226] conv32 needs backward computation.
I0728 12:55:52.501518 118397 net.cpp:226] relu31 needs backward computation.
I0728 12:55:52.501526 118397 net.cpp:226] conv31 needs backward computation.
I0728 12:55:52.501538 118397 net.cpp:226] pool2 needs backward computation.
I0728 12:55:52.501561 118397 net.cpp:226] relu22 needs backward computation.
I0728 12:55:52.501572 118397 net.cpp:226] conv22 needs backward computation.
I0728 12:55:52.501581 118397 net.cpp:226] relu21 needs backward computation.
I0728 12:55:52.501590 118397 net.cpp:226] conv21 needs backward computation.
I0728 12:55:52.501598 118397 net.cpp:226] pool1 needs backward computation.
I0728 12:55:52.501610 118397 net.cpp:226] relu12 needs backward computation.
I0728 12:55:52.501619 118397 net.cpp:226] conv12 needs backward computation.
I0728 12:55:52.501627 118397 net.cpp:226] relu11 needs backward computation.
I0728 12:55:52.501636 118397 net.cpp:226] conv11 needs backward computation.
I0728 12:55:52.501647 118397 net.cpp:228] label_data_1_split does not need backward computation.
I0728 12:55:52.501658 118397 net.cpp:228] data does not need backward computation.
I0728 12:55:52.501667 118397 net.cpp:270] This network produces output accuracy
I0728 12:55:52.501677 118397 net.cpp:270] This network produces output loss
I0728 12:55:52.501698 118397 net.cpp:283] Network initialization done.
I0728 12:55:52.501828 118397 solver.cpp:59] Solver scaffolding done.
I0728 12:55:52.502408 118397 caffe.cpp:212] Starting Optimization
I0728 12:55:52.502430 118397 solver.cpp:287] Solving Net
I0728 12:55:52.502440 118397 solver.cpp:288] Learning Rate Policy: step
I0728 12:55:52.503365 118397 solver.cpp:340] Iteration 0, Testing net (#0)
I0728 12:57:00.002507 118397 solver.cpp:408]     Test net output #0: accuracy = 0
I0728 12:57:00.002684 118397 solver.cpp:408]     Test net output #1: loss = 6.28074 (* 1 = 6.28074 loss)
I0728 12:57:05.670300 118397 solver.cpp:236] Iteration 0, loss = 6.64544
I0728 12:57:05.670393 118397 solver.cpp:252]     Train net output #0: loss = 6.64544 (* 1 = 6.64544 loss)
I0728 12:57:05.670425 118397 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0728 12:58:04.439895 118397 solver.cpp:236] Iteration 10, loss = 4.31321
I0728 12:58:04.440093 118397 solver.cpp:252]     Train net output #0: loss = 2.11923 (* 1 = 2.11923 loss)
I0728 12:58:04.440119 118397 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I0728 12:59:01.013818 118397 solver.cpp:236] Iteration 20, loss = 4.04114
I0728 12:59:01.014034 118397 solver.cpp:252]     Train net output #0: loss = 13.2045 (* 1 = 13.2045 loss)
I0728 12:59:01.014063 118397 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0728 12:59:57.299592 118397 solver.cpp:236] Iteration 30, loss = 3.99329
I0728 12:59:57.299829 118397 solver.cpp:252]     Train net output #0: loss = 1.76931 (* 1 = 1.76931 loss)
I0728 12:59:57.299862 118397 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I0728 13:01:06.766729 118397 solver.cpp:236] Iteration 40, loss = 3.28185
I0728 13:01:06.766921 118397 solver.cpp:252]     Train net output #0: loss = 1.13755 (* 1 = 1.13755 loss)
I0728 13:01:06.766947 118397 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0728 13:02:07.480384 118397 solver.cpp:236] Iteration 50, loss = 2.797
I0728 13:02:07.480597 118397 solver.cpp:252]     Train net output #0: loss = 0.683773 (* 1 = 0.683773 loss)
I0728 13:02:07.480628 118397 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I0728 13:03:01.155827 118397 solver.cpp:236] Iteration 60, loss = 2.45323
I0728 13:03:01.156047 118397 solver.cpp:252]     Train net output #0: loss = 0.754667 (* 1 = 0.754667 loss)
I0728 13:03:01.156074 118397 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0728 13:04:00.360951 118397 solver.cpp:236] Iteration 70, loss = 2.2056
I0728 13:04:00.361125 118397 solver.cpp:252]     Train net output #0: loss = 0.665376 (* 1 = 0.665376 loss)
I0728 13:04:00.361145 118397 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I0728 13:05:00.930666 118397 solver.cpp:236] Iteration 80, loss = 2.01042
I0728 13:05:00.930822 118397 solver.cpp:252]     Train net output #0: loss = 0.690546 (* 1 = 0.690546 loss)
I0728 13:05:00.930842 118397 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0728 13:05:58.991677 118397 solver.cpp:236] Iteration 90, loss = 1.86965
I0728 13:05:58.991852 118397 solver.cpp:252]     Train net output #0: loss = 0.72051 (* 1 = 0.72051 loss)
I0728 13:05:58.991871 118397 sgd_solver.cpp:106] Iteration 90, lr = 0.01
I0728 13:07:07.575605 118397 solver.cpp:236] Iteration 100, loss = 1.69817
I0728 13:07:07.575742 118397 solver.cpp:252]     Train net output #0: loss = 0.655106 (* 1 = 0.655106 loss)
I0728 13:07:07.575762 118397 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0728 13:08:12.551856 118397 solver.cpp:236] Iteration 110, loss = 1.3502
I0728 13:08:12.552047 118397 solver.cpp:252]     Train net output #0: loss = 0.760154 (* 1 = 0.760154 loss)
I0728 13:08:12.552065 118397 sgd_solver.cpp:106] Iteration 110, lr = 0.01
I0728 13:09:06.011924 118397 solver.cpp:236] Iteration 120, loss = 1.03876
I0728 13:09:06.012142 118397 solver.cpp:252]     Train net output #0: loss = 0.658372 (* 1 = 0.658372 loss)
I0728 13:09:06.012177 118397 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0728 13:10:00.247236 118397 solver.cpp:236] Iteration 130, loss = 0.709338
I0728 13:10:00.247448 118397 solver.cpp:252]     Train net output #0: loss = 0.734618 (* 1 = 0.734618 loss)
I0728 13:10:00.247474 118397 sgd_solver.cpp:106] Iteration 130, lr = 0.01
I0728 13:11:00.618535 118397 solver.cpp:236] Iteration 140, loss = 0.664208
I0728 13:11:00.618708 118397 solver.cpp:252]     Train net output #0: loss = 0.648658 (* 1 = 0.648658 loss)
I0728 13:11:00.618731 118397 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0728 13:12:13.711750 118397 solver.cpp:236] Iteration 150, loss = 0.645442
I0728 13:12:13.711926 118397 solver.cpp:252]     Train net output #0: loss = 0.657861 (* 1 = 0.657861 loss)
I0728 13:12:13.711951 118397 sgd_solver.cpp:106] Iteration 150, lr = 0.01
I0728 13:13:22.284077 118397 solver.cpp:236] Iteration 160, loss = 0.631944
I0728 13:13:22.284238 118397 solver.cpp:252]     Train net output #0: loss = 0.735418 (* 1 = 0.735418 loss)
I0728 13:13:22.284260 118397 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0728 13:14:28.372395 118397 solver.cpp:236] Iteration 170, loss = 0.628853
I0728 13:14:28.372586 118397 solver.cpp:252]     Train net output #0: loss = 0.629754 (* 1 = 0.629754 loss)
I0728 13:14:28.372623 118397 sgd_solver.cpp:106] Iteration 170, lr = 0.01
I0728 13:15:28.186455 118397 solver.cpp:236] Iteration 180, loss = 0.629305
I0728 13:15:28.186619 118397 solver.cpp:252]     Train net output #0: loss = 0.653633 (* 1 = 0.653633 loss)
I0728 13:15:28.186655 118397 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0728 13:16:34.641765 118397 solver.cpp:236] Iteration 190, loss = 0.621583
I0728 13:16:34.641942 118397 solver.cpp:252]     Train net output #0: loss = 0.708394 (* 1 = 0.708394 loss)
I0728 13:16:34.641966 118397 sgd_solver.cpp:106] Iteration 190, lr = 0.01
I0728 13:17:33.165021 118397 solver.cpp:236] Iteration 200, loss = 0.621734
I0728 13:17:33.165220 118397 solver.cpp:252]     Train net output #0: loss = 0.669142 (* 1 = 0.669142 loss)
I0728 13:17:33.165241 118397 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0728 13:18:37.469432 118397 solver.cpp:236] Iteration 210, loss = 0.62967
I0728 13:18:37.469605 118397 solver.cpp:252]     Train net output #0: loss = 0.662028 (* 1 = 0.662028 loss)
I0728 13:18:37.469631 118397 sgd_solver.cpp:106] Iteration 210, lr = 0.01
I0728 13:19:53.987156 118397 solver.cpp:236] Iteration 220, loss = 0.633735
I0728 13:19:53.987476 118397 solver.cpp:252]     Train net output #0: loss = 0.633826 (* 1 = 0.633826 loss)
I0728 13:19:53.987506 118397 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0728 13:21:13.823957 118397 solver.cpp:236] Iteration 230, loss = 0.637923
I0728 13:21:13.824142 118397 solver.cpp:252]     Train net output #0: loss = 0.615773 (* 1 = 0.615773 loss)
I0728 13:21:13.824168 118397 sgd_solver.cpp:106] Iteration 230, lr = 0.01
I0728 13:22:07.084533 118397 solver.cpp:236] Iteration 240, loss = 0.636424
I0728 13:22:07.084746 118397 solver.cpp:252]     Train net output #0: loss = 0.659141 (* 1 = 0.659141 loss)
I0728 13:22:07.084774 118397 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0728 13:23:18.560397 118397 solver.cpp:236] Iteration 250, loss = 0.642454
I0728 13:23:18.560636 118397 solver.cpp:252]     Train net output #0: loss = 0.640996 (* 1 = 0.640996 loss)
I0728 13:23:18.560659 118397 sgd_solver.cpp:106] Iteration 250, lr = 0.01
I0728 13:24:31.459600 118397 solver.cpp:236] Iteration 260, loss = 0.648607
I0728 13:24:31.459786 118397 solver.cpp:252]     Train net output #0: loss = 0.638444 (* 1 = 0.638444 loss)
I0728 13:24:31.459812 118397 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0728 13:25:35.031515 118397 solver.cpp:236] Iteration 270, loss = 0.64678
I0728 13:25:35.031698 118397 solver.cpp:252]     Train net output #0: loss = 0.688875 (* 1 = 0.688875 loss)
I0728 13:25:35.031720 118397 sgd_solver.cpp:106] Iteration 270, lr = 0.01
I0728 13:26:56.294240 118397 solver.cpp:236] Iteration 280, loss = 0.645084
I0728 13:26:56.294404 118397 solver.cpp:252]     Train net output #0: loss = 0.645637 (* 1 = 0.645637 loss)
I0728 13:26:56.294423 118397 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0728 13:28:06.067750 118397 solver.cpp:236] Iteration 290, loss = 0.643916
I0728 13:28:06.067950 118397 solver.cpp:252]     Train net output #0: loss = 0.624603 (* 1 = 0.624603 loss)
I0728 13:28:06.067986 118397 sgd_solver.cpp:106] Iteration 290, lr = 0.01
I0728 13:29:13.368229 118397 solver.cpp:236] Iteration 300, loss = 0.643148
I0728 13:29:13.368402 118397 solver.cpp:252]     Train net output #0: loss = 0.657126 (* 1 = 0.657126 loss)
I0728 13:29:13.368432 118397 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0728 13:30:16.117091 118397 solver.cpp:236] Iteration 310, loss = 0.641356
I0728 13:30:16.117264 118397 solver.cpp:252]     Train net output #0: loss = 0.641781 (* 1 = 0.641781 loss)
I0728 13:30:16.117295 118397 sgd_solver.cpp:106] Iteration 310, lr = 0.01
I0728 13:31:30.891849 118397 solver.cpp:236] Iteration 320, loss = 0.638998
I0728 13:31:30.892019 118397 solver.cpp:252]     Train net output #0: loss = 0.645715 (* 1 = 0.645715 loss)
I0728 13:31:30.892047 118397 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0728 13:32:30.385115 118397 solver.cpp:236] Iteration 330, loss = 0.638211
I0728 13:32:30.385326 118397 solver.cpp:252]     Train net output #0: loss = 0.689049 (* 1 = 0.689049 loss)
I0728 13:32:30.385356 118397 sgd_solver.cpp:106] Iteration 330, lr = 0.01
I0728 13:33:30.392439 118397 solver.cpp:236] Iteration 340, loss = 0.642681
I0728 13:33:30.392628 118397 solver.cpp:252]     Train net output #0: loss = 0.648813 (* 1 = 0.648813 loss)
I0728 13:33:30.392648 118397 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0728 13:34:44.584414 118397 solver.cpp:236] Iteration 350, loss = 0.636972
I0728 13:34:44.584600 118397 solver.cpp:252]     Train net output #0: loss = 0.64407 (* 1 = 0.64407 loss)
I0728 13:34:44.584619 118397 sgd_solver.cpp:106] Iteration 350, lr = 0.01
I0728 13:36:02.006925 118397 solver.cpp:236] Iteration 360, loss = 0.636344
I0728 13:36:02.007096 118397 solver.cpp:252]     Train net output #0: loss = 0.385847 (* 1 = 0.385847 loss)
I0728 13:36:02.007135 118397 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0728 13:37:06.600690 118397 solver.cpp:236] Iteration 370, loss = 0.634945
I0728 13:37:06.600836 118397 solver.cpp:252]     Train net output #0: loss = 0.640257 (* 1 = 0.640257 loss)
I0728 13:37:06.600857 118397 sgd_solver.cpp:106] Iteration 370, lr = 0.01
I0728 13:38:17.022987 118397 solver.cpp:236] Iteration 380, loss = 0.636419
I0728 13:38:17.023242 118397 solver.cpp:252]     Train net output #0: loss = 0.665967 (* 1 = 0.665967 loss)
I0728 13:38:17.023268 118397 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0728 13:39:37.706044 118397 solver.cpp:236] Iteration 390, loss = 0.635346
I0728 13:39:37.706233 118397 solver.cpp:252]     Train net output #0: loss = 0.649673 (* 1 = 0.649673 loss)
I0728 13:39:37.706269 118397 sgd_solver.cpp:106] Iteration 390, lr = 0.01
I0728 13:40:40.140521 118397 solver.cpp:236] Iteration 400, loss = 0.634972
I0728 13:40:40.140920 118397 solver.cpp:252]     Train net output #0: loss = 0.64001 (* 1 = 0.64001 loss)
I0728 13:40:40.140944 118397 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0728 13:41:36.651850 118397 solver.cpp:236] Iteration 410, loss = 0.630341
I0728 13:41:36.654728 118397 solver.cpp:252]     Train net output #0: loss = 0.341199 (* 1 = 0.341199 loss)
I0728 13:41:36.654754 118397 sgd_solver.cpp:106] Iteration 410, lr = 0.01
I0728 13:42:46.542184 118397 solver.cpp:236] Iteration 420, loss = 0.627575
I0728 13:42:46.542333 118397 solver.cpp:252]     Train net output #0: loss = 0.661621 (* 1 = 0.661621 loss)
I0728 13:42:46.542356 118397 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0728 13:43:48.917278 118397 solver.cpp:236] Iteration 430, loss = 0.623156
I0728 13:43:48.917438 118397 solver.cpp:252]     Train net output #0: loss = 0.642812 (* 1 = 0.642812 loss)
I0728 13:43:48.917456 118397 sgd_solver.cpp:106] Iteration 430, lr = 0.01
I0728 13:44:57.946187 118397 solver.cpp:236] Iteration 440, loss = 0.621432
I0728 13:44:57.946346 118397 solver.cpp:252]     Train net output #0: loss = 0.622324 (* 1 = 0.622324 loss)
I0728 13:44:57.946374 118397 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0728 13:45:57.645264 118397 solver.cpp:236] Iteration 450, loss = 0.620576
I0728 13:45:57.645437 118397 solver.cpp:252]     Train net output #0: loss = 0.649987 (* 1 = 0.649987 loss)
I0728 13:45:57.645455 118397 sgd_solver.cpp:106] Iteration 450, lr = 0.01
I0728 13:47:00.804877 118397 solver.cpp:236] Iteration 460, loss = 0.620594
I0728 13:47:00.805066 118397 solver.cpp:252]     Train net output #0: loss = 0.40393 (* 1 = 0.40393 loss)
I0728 13:47:00.805086 118397 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0728 13:48:06.070868 118397 solver.cpp:236] Iteration 470, loss = 0.623743
I0728 13:48:06.071084 118397 solver.cpp:252]     Train net output #0: loss = 0.647931 (* 1 = 0.647931 loss)
I0728 13:48:06.071105 118397 sgd_solver.cpp:106] Iteration 470, lr = 0.01
I0728 13:49:14.779755 118397 solver.cpp:236] Iteration 480, loss = 0.625751
I0728 13:49:14.779922 118397 solver.cpp:252]     Train net output #0: loss = 0.683513 (* 1 = 0.683513 loss)
I0728 13:49:14.779944 118397 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0728 13:50:20.411083 118397 solver.cpp:236] Iteration 490, loss = 0.625658
I0728 13:50:20.411283 118397 solver.cpp:252]     Train net output #0: loss = 0.638299 (* 1 = 0.638299 loss)
I0728 13:50:20.411303 118397 sgd_solver.cpp:106] Iteration 490, lr = 0.01
I0728 13:51:30.593653 118397 solver.cpp:340] Iteration 500, Testing net (#0)
I0728 13:52:25.523255 118397 solver.cpp:408]     Test net output #0: accuracy = 0.795313
I0728 13:52:25.523478 118397 solver.cpp:408]     Test net output #1: loss = 0.513932 (* 1 = 0.513932 loss)
I0728 13:52:32.352459 118397 solver.cpp:236] Iteration 500, loss = 0.625104
I0728 13:52:32.352525 118397 solver.cpp:252]     Train net output #0: loss = 0.654479 (* 1 = 0.654479 loss)
I0728 13:52:32.352545 118397 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0728 13:53:55.483402 118397 solver.cpp:236] Iteration 510, loss = 0.626112
I0728 13:53:55.483571 118397 solver.cpp:252]     Train net output #0: loss = 0.653823 (* 1 = 0.653823 loss)
I0728 13:53:55.483603 118397 sgd_solver.cpp:106] Iteration 510, lr = 0.01
I0728 13:54:57.217227 118397 solver.cpp:236] Iteration 520, loss = 0.627761
I0728 13:54:57.217420 118397 solver.cpp:252]     Train net output #0: loss = 0.637825 (* 1 = 0.637825 loss)
I0728 13:54:57.217439 118397 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0728 13:56:07.550159 118397 solver.cpp:236] Iteration 530, loss = 0.631557
I0728 13:56:07.550334 118397 solver.cpp:252]     Train net output #0: loss = 0.638977 (* 1 = 0.638977 loss)
I0728 13:56:07.550359 118397 sgd_solver.cpp:106] Iteration 530, lr = 0.01
I0728 13:56:53.667559 118397 solver.cpp:236] Iteration 540, loss = 0.629919
I0728 13:56:53.667999 118397 solver.cpp:252]     Train net output #0: loss = 0.627844 (* 1 = 0.627844 loss)
I0728 13:56:53.668016 118397 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0728 13:58:10.896530 118397 solver.cpp:236] Iteration 550, loss = 0.632452
I0728 13:58:10.896703 118397 solver.cpp:252]     Train net output #0: loss = 0.636452 (* 1 = 0.636452 loss)
I0728 13:58:10.896723 118397 sgd_solver.cpp:106] Iteration 550, lr = 0.01
I0728 13:59:10.401284 118397 solver.cpp:236] Iteration 560, loss = 0.633292
I0728 13:59:10.401543 118397 solver.cpp:252]     Train net output #0: loss = 0.635547 (* 1 = 0.635547 loss)
I0728 13:59:10.401568 118397 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0728 14:00:10.275501 118397 solver.cpp:236] Iteration 570, loss = 0.631273
I0728 14:00:10.275799 118397 solver.cpp:252]     Train net output #0: loss = 0.651406 (* 1 = 0.651406 loss)
I0728 14:00:10.275816 118397 sgd_solver.cpp:106] Iteration 570, lr = 0.01
I0728 14:00:56.806077 118397 solver.cpp:236] Iteration 580, loss = 0.629631
I0728 14:00:56.806233 118397 solver.cpp:252]     Train net output #0: loss = 0.685811 (* 1 = 0.685811 loss)
I0728 14:00:56.806253 118397 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0728 14:01:47.169916 118397 solver.cpp:236] Iteration 590, loss = 0.632849
I0728 14:01:47.170068 118397 solver.cpp:252]     Train net output #0: loss = 0.643103 (* 1 = 0.643103 loss)
I0728 14:01:47.170086 118397 sgd_solver.cpp:106] Iteration 590, lr = 0.01
I0728 14:02:40.220772 118397 solver.cpp:236] Iteration 600, loss = 0.633886
I0728 14:02:40.220953 118397 solver.cpp:252]     Train net output #0: loss = 0.728147 (* 1 = 0.728147 loss)
I0728 14:02:40.220979 118397 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0728 14:03:28.789933 118397 solver.cpp:236] Iteration 610, loss = 0.633757
I0728 14:03:28.790132 118397 solver.cpp:252]     Train net output #0: loss = 0.644018 (* 1 = 0.644018 loss)
I0728 14:03:28.790150 118397 sgd_solver.cpp:106] Iteration 610, lr = 0.01
I0728 14:04:16.119135 118397 solver.cpp:236] Iteration 620, loss = 0.630614
I0728 14:04:16.119343 118397 solver.cpp:252]     Train net output #0: loss = 0.701946 (* 1 = 0.701946 loss)
I0728 14:04:16.119362 118397 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0728 14:04:58.541051 118397 solver.cpp:236] Iteration 630, loss = 0.634125
I0728 14:04:58.543421 118397 solver.cpp:252]     Train net output #0: loss = 0.659904 (* 1 = 0.659904 loss)
I0728 14:04:58.543445 118397 sgd_solver.cpp:106] Iteration 630, lr = 0.01
I0728 14:05:45.459856 118397 solver.cpp:236] Iteration 640, loss = 0.631571
I0728 14:05:45.460117 118397 solver.cpp:252]     Train net output #0: loss = 0.228171 (* 1 = 0.228171 loss)
I0728 14:05:45.460146 118397 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0728 14:06:33.100335 118397 solver.cpp:236] Iteration 650, loss = 0.632716
I0728 14:06:33.100489 118397 solver.cpp:252]     Train net output #0: loss = 0.526254 (* 1 = 0.526254 loss)
I0728 14:06:33.100508 118397 sgd_solver.cpp:106] Iteration 650, lr = 0.01
I0728 14:07:26.115725 118397 solver.cpp:236] Iteration 660, loss = 0.628566
I0728 14:07:26.115881 118397 solver.cpp:252]     Train net output #0: loss = 0.705394 (* 1 = 0.705394 loss)
I0728 14:07:26.115900 118397 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0728 14:08:16.890136 118397 solver.cpp:236] Iteration 670, loss = 0.616359
I0728 14:08:16.890293 118397 solver.cpp:252]     Train net output #0: loss = 0.279676 (* 1 = 0.279676 loss)
I0728 14:08:16.890316 118397 sgd_solver.cpp:106] Iteration 670, lr = 0.01
I0728 14:09:09.226965 118397 solver.cpp:236] Iteration 680, loss = 0.612028
I0728 14:09:09.227145 118397 solver.cpp:252]     Train net output #0: loss = 0.657622 (* 1 = 0.657622 loss)
I0728 14:09:09.227170 118397 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0728 14:10:06.967938 118397 solver.cpp:236] Iteration 690, loss = 0.610345
I0728 14:10:06.968099 118397 solver.cpp:252]     Train net output #0: loss = 0.644379 (* 1 = 0.644379 loss)
I0728 14:10:06.968117 118397 sgd_solver.cpp:106] Iteration 690, lr = 0.01
I0728 14:11:07.200810 118397 solver.cpp:236] Iteration 700, loss = 0.608013
I0728 14:11:07.200979 118397 solver.cpp:252]     Train net output #0: loss = 0.658986 (* 1 = 0.658986 loss)
I0728 14:11:07.200999 118397 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0728 14:12:22.773952 118397 solver.cpp:236] Iteration 710, loss = 0.607566
I0728 14:12:22.774390 118397 solver.cpp:252]     Train net output #0: loss = 0.635898 (* 1 = 0.635898 loss)
I0728 14:12:22.774413 118397 sgd_solver.cpp:106] Iteration 710, lr = 0.01
I0728 14:13:24.987447 118397 solver.cpp:236] Iteration 720, loss = 0.609042
I0728 14:13:24.987834 118397 solver.cpp:252]     Train net output #0: loss = 0.642017 (* 1 = 0.642017 loss)
I0728 14:13:24.987856 118397 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0728 14:14:16.870332 118397 solver.cpp:236] Iteration 730, loss = 0.601734
I0728 14:14:16.870507 118397 solver.cpp:252]     Train net output #0: loss = 0.642363 (* 1 = 0.642363 loss)
I0728 14:14:16.870542 118397 sgd_solver.cpp:106] Iteration 730, lr = 0.01
I0728 14:15:15.273972 118397 solver.cpp:236] Iteration 740, loss = 0.604349
I0728 14:15:15.274221 118397 solver.cpp:252]     Train net output #0: loss = 0.645061 (* 1 = 0.645061 loss)
I0728 14:15:15.274247 118397 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0728 14:16:13.913203 118397 solver.cpp:236] Iteration 750, loss = 0.596026
I0728 14:16:13.913357 118397 solver.cpp:252]     Train net output #0: loss = 0.637113 (* 1 = 0.637113 loss)
I0728 14:16:13.913375 118397 sgd_solver.cpp:106] Iteration 750, lr = 0.01
I0728 14:17:20.860062 118397 solver.cpp:236] Iteration 760, loss = 0.598964
I0728 14:17:20.860294 118397 solver.cpp:252]     Train net output #0: loss = 0.629738 (* 1 = 0.629738 loss)
I0728 14:17:20.860327 118397 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0728 14:18:31.960110 118397 solver.cpp:236] Iteration 770, loss = 0.610658
I0728 14:18:31.960269 118397 solver.cpp:252]     Train net output #0: loss = 0.617583 (* 1 = 0.617583 loss)
I0728 14:18:31.960289 118397 sgd_solver.cpp:106] Iteration 770, lr = 0.01
I0728 14:19:39.594969 118397 solver.cpp:236] Iteration 780, loss = 0.614676
I0728 14:19:39.595187 118397 solver.cpp:252]     Train net output #0: loss = 0.667686 (* 1 = 0.667686 loss)
I0728 14:19:39.595219 118397 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0728 14:20:56.702843 118397 solver.cpp:236] Iteration 790, loss = 0.607451
I0728 14:20:56.703030 118397 solver.cpp:252]     Train net output #0: loss = 0.323568 (* 1 = 0.323568 loss)
I0728 14:20:56.703047 118397 sgd_solver.cpp:106] Iteration 790, lr = 0.01
I0728 14:22:06.019402 118397 solver.cpp:236] Iteration 800, loss = 0.612958
I0728 14:22:06.019556 118397 solver.cpp:252]     Train net output #0: loss = 0.645866 (* 1 = 0.645866 loss)
I0728 14:22:06.019578 118397 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0728 14:23:08.395303 118397 solver.cpp:236] Iteration 810, loss = 0.611258
I0728 14:23:08.395514 118397 solver.cpp:252]     Train net output #0: loss = 0.683072 (* 1 = 0.683072 loss)
I0728 14:23:08.395547 118397 sgd_solver.cpp:106] Iteration 810, lr = 0.01
I0728 14:24:08.167563 118397 solver.cpp:236] Iteration 820, loss = 0.612932
I0728 14:24:08.167711 118397 solver.cpp:252]     Train net output #0: loss = 0.637928 (* 1 = 0.637928 loss)
I0728 14:24:08.167731 118397 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0728 14:25:12.459348 118397 solver.cpp:236] Iteration 830, loss = 0.618987
I0728 14:25:12.459475 118397 solver.cpp:252]     Train net output #0: loss = 0.639268 (* 1 = 0.639268 loss)
I0728 14:25:12.459493 118397 sgd_solver.cpp:106] Iteration 830, lr = 0.01
I0728 14:26:15.687142 118397 solver.cpp:236] Iteration 840, loss = 0.615797
I0728 14:26:15.687399 118397 solver.cpp:252]     Train net output #0: loss = 0.286655 (* 1 = 0.286655 loss)
I0728 14:26:15.687427 118397 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0728 14:27:17.884420 118397 solver.cpp:236] Iteration 850, loss = 0.618001
I0728 14:27:17.884567 118397 solver.cpp:252]     Train net output #0: loss = 0.632783 (* 1 = 0.632783 loss)
I0728 14:27:17.884584 118397 sgd_solver.cpp:106] Iteration 850, lr = 0.01
I0728 14:28:19.873880 118397 solver.cpp:236] Iteration 860, loss = 0.620067
I0728 14:28:19.874068 118397 solver.cpp:252]     Train net output #0: loss = 0.633345 (* 1 = 0.633345 loss)
I0728 14:28:19.874096 118397 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0728 14:29:29.716835 118397 solver.cpp:236] Iteration 870, loss = 0.619933
I0728 14:29:29.717094 118397 solver.cpp:252]     Train net output #0: loss = 0.633265 (* 1 = 0.633265 loss)
I0728 14:29:29.717123 118397 sgd_solver.cpp:106] Iteration 870, lr = 0.01
I0728 14:30:38.827471 118397 solver.cpp:236] Iteration 880, loss = 0.620918
I0728 14:30:38.830693 118397 solver.cpp:252]     Train net output #0: loss = 0.643834 (* 1 = 0.643834 loss)
I0728 14:30:38.830720 118397 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0728 14:31:49.401099 118397 solver.cpp:236] Iteration 890, loss = 0.626047
I0728 14:31:49.401258 118397 solver.cpp:252]     Train net output #0: loss = 0.65043 (* 1 = 0.65043 loss)
I0728 14:31:49.401278 118397 sgd_solver.cpp:106] Iteration 890, lr = 0.01
I0728 14:32:58.861940 118397 solver.cpp:236] Iteration 900, loss = 0.620097
I0728 14:32:58.862112 118397 solver.cpp:252]     Train net output #0: loss = 0.652275 (* 1 = 0.652275 loss)
I0728 14:32:58.862129 118397 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0728 14:34:15.912961 118397 solver.cpp:236] Iteration 910, loss = 0.624266
I0728 14:34:15.913126 118397 solver.cpp:252]     Train net output #0: loss = 0.643662 (* 1 = 0.643662 loss)
I0728 14:34:15.913147 118397 sgd_solver.cpp:106] Iteration 910, lr = 0.01
I0728 14:35:26.617065 118397 solver.cpp:236] Iteration 920, loss = 0.621718
I0728 14:35:26.617241 118397 solver.cpp:252]     Train net output #0: loss = 0.354324 (* 1 = 0.354324 loss)
I0728 14:35:26.617266 118397 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0728 14:36:46.836906 118397 solver.cpp:236] Iteration 930, loss = 0.617048
I0728 14:36:46.837097 118397 solver.cpp:252]     Train net output #0: loss = 0.343517 (* 1 = 0.343517 loss)
I0728 14:36:46.837119 118397 sgd_solver.cpp:106] Iteration 930, lr = 0.01
I0728 14:38:18.777199 118397 solver.cpp:236] Iteration 940, loss = 0.621829
I0728 14:38:18.777381 118397 solver.cpp:252]     Train net output #0: loss = 0.64227 (* 1 = 0.64227 loss)
I0728 14:38:18.777400 118397 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0728 14:39:43.490875 118397 solver.cpp:236] Iteration 950, loss = 0.624727
I0728 14:39:43.491060 118397 solver.cpp:252]     Train net output #0: loss = 0.652911 (* 1 = 0.652911 loss)
I0728 14:39:43.491085 118397 sgd_solver.cpp:106] Iteration 950, lr = 0.01
I0728 14:40:37.762584 118397 solver.cpp:236] Iteration 960, loss = 0.616755
I0728 14:40:37.762774 118397 solver.cpp:252]     Train net output #0: loss = 0.656899 (* 1 = 0.656899 loss)
I0728 14:40:37.762796 118397 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0728 14:41:49.122512 118397 solver.cpp:236] Iteration 970, loss = 0.616991
I0728 14:41:49.122696 118397 solver.cpp:252]     Train net output #0: loss = 0.640712 (* 1 = 0.640712 loss)
I0728 14:41:49.122717 118397 sgd_solver.cpp:106] Iteration 970, lr = 0.01
I0728 14:43:05.899353 118397 solver.cpp:236] Iteration 980, loss = 0.618643
I0728 14:43:05.899518 118397 solver.cpp:252]     Train net output #0: loss = 0.636216 (* 1 = 0.636216 loss)
I0728 14:43:05.899544 118397 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0728 14:44:09.564761 118397 solver.cpp:236] Iteration 990, loss = 0.618315
I0728 14:44:09.564965 118397 solver.cpp:252]     Train net output #0: loss = 0.632853 (* 1 = 0.632853 loss)
I0728 14:44:09.564991 118397 sgd_solver.cpp:106] Iteration 990, lr = 0.01
I0728 14:45:12.941831 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_1000.caffemodel
I0728 14:45:13.059321 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_1000.solverstate
I0728 14:45:13.063660 118397 solver.cpp:340] Iteration 1000, Testing net (#0)
I0728 14:46:23.779955 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 14:46:23.780135 118397 solver.cpp:408]     Test net output #1: loss = 0.633981 (* 1 = 0.633981 loss)
I0728 14:46:26.896481 118397 solver.cpp:236] Iteration 1000, loss = 0.622111
I0728 14:46:26.896554 118397 solver.cpp:252]     Train net output #0: loss = 0.639027 (* 1 = 0.639027 loss)
I0728 14:46:26.896574 118397 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0728 14:47:25.822636 118397 solver.cpp:236] Iteration 1010, loss = 0.615573
I0728 14:47:25.822824 118397 solver.cpp:252]     Train net output #0: loss = 0.253234 (* 1 = 0.253234 loss)
I0728 14:47:25.822844 118397 sgd_solver.cpp:106] Iteration 1010, lr = 0.01
I0728 14:48:29.037412 118397 solver.cpp:236] Iteration 1020, loss = 0.614338
I0728 14:48:29.037575 118397 solver.cpp:252]     Train net output #0: loss = 0.646899 (* 1 = 0.646899 loss)
I0728 14:48:29.037595 118397 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0728 14:49:41.944077 118397 solver.cpp:236] Iteration 1030, loss = 0.617966
I0728 14:49:41.944231 118397 solver.cpp:252]     Train net output #0: loss = 0.642136 (* 1 = 0.642136 loss)
I0728 14:49:41.944250 118397 sgd_solver.cpp:106] Iteration 1030, lr = 0.01
I0728 14:50:50.758893 118397 solver.cpp:236] Iteration 1040, loss = 0.61286
I0728 14:50:50.759063 118397 solver.cpp:252]     Train net output #0: loss = 0.687149 (* 1 = 0.687149 loss)
I0728 14:50:50.759093 118397 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0728 14:51:53.324331 118397 solver.cpp:236] Iteration 1050, loss = 0.611036
I0728 14:51:53.324579 118397 solver.cpp:252]     Train net output #0: loss = 0.649312 (* 1 = 0.649312 loss)
I0728 14:51:53.324602 118397 sgd_solver.cpp:106] Iteration 1050, lr = 0.01
I0728 14:52:57.528946 118397 solver.cpp:236] Iteration 1060, loss = 0.61943
I0728 14:52:57.529103 118397 solver.cpp:252]     Train net output #0: loss = 0.638546 (* 1 = 0.638546 loss)
I0728 14:52:57.529129 118397 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0728 14:54:07.477397 118397 solver.cpp:236] Iteration 1070, loss = 0.613556
I0728 14:54:07.482735 118397 solver.cpp:252]     Train net output #0: loss = 0.252132 (* 1 = 0.252132 loss)
I0728 14:54:07.482764 118397 sgd_solver.cpp:106] Iteration 1070, lr = 0.01
I0728 14:55:02.844425 118397 solver.cpp:236] Iteration 1080, loss = 0.607541
I0728 14:55:02.844600 118397 solver.cpp:252]     Train net output #0: loss = 0.63993 (* 1 = 0.63993 loss)
I0728 14:55:02.844620 118397 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0728 14:56:04.254480 118397 solver.cpp:236] Iteration 1090, loss = 0.604434
I0728 14:56:04.254705 118397 solver.cpp:252]     Train net output #0: loss = 0.639919 (* 1 = 0.639919 loss)
I0728 14:56:04.254739 118397 sgd_solver.cpp:106] Iteration 1090, lr = 0.01
I0728 14:57:27.209496 118397 solver.cpp:236] Iteration 1100, loss = 0.601314
I0728 14:57:27.209679 118397 solver.cpp:252]     Train net output #0: loss = 0.678074 (* 1 = 0.678074 loss)
I0728 14:57:27.209707 118397 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0728 14:58:38.582373 118397 solver.cpp:236] Iteration 1110, loss = 0.606502
I0728 14:58:38.582566 118397 solver.cpp:252]     Train net output #0: loss = 0.651377 (* 1 = 0.651377 loss)
I0728 14:58:38.582587 118397 sgd_solver.cpp:106] Iteration 1110, lr = 0.01
I0728 14:59:45.104111 118397 solver.cpp:236] Iteration 1120, loss = 0.609725
I0728 14:59:45.104298 118397 solver.cpp:252]     Train net output #0: loss = 0.452675 (* 1 = 0.452675 loss)
I0728 14:59:45.104321 118397 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0728 15:00:50.379340 118397 solver.cpp:236] Iteration 1130, loss = 0.611647
I0728 15:00:50.379492 118397 solver.cpp:252]     Train net output #0: loss = 0.645814 (* 1 = 0.645814 loss)
I0728 15:00:50.379518 118397 sgd_solver.cpp:106] Iteration 1130, lr = 0.01
I0728 15:02:09.407058 118397 solver.cpp:236] Iteration 1140, loss = 0.617377
I0728 15:02:09.407284 118397 solver.cpp:252]     Train net output #0: loss = 0.648514 (* 1 = 0.648514 loss)
I0728 15:02:09.407313 118397 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0728 15:03:18.070722 118397 solver.cpp:236] Iteration 1150, loss = 0.619872
I0728 15:03:18.070914 118397 solver.cpp:252]     Train net output #0: loss = 0.656544 (* 1 = 0.656544 loss)
I0728 15:03:18.070947 118397 sgd_solver.cpp:106] Iteration 1150, lr = 0.01
I0728 15:04:34.068934 118397 solver.cpp:236] Iteration 1160, loss = 0.614906
I0728 15:04:34.069118 118397 solver.cpp:252]     Train net output #0: loss = 0.659546 (* 1 = 0.659546 loss)
I0728 15:04:34.069140 118397 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0728 15:05:38.841897 118397 solver.cpp:236] Iteration 1170, loss = 0.612532
I0728 15:05:38.842088 118397 solver.cpp:252]     Train net output #0: loss = 0.680128 (* 1 = 0.680128 loss)
I0728 15:05:38.842110 118397 sgd_solver.cpp:106] Iteration 1170, lr = 0.01
I0728 15:06:39.573729 118397 solver.cpp:236] Iteration 1180, loss = 0.614165
I0728 15:06:39.573974 118397 solver.cpp:252]     Train net output #0: loss = 0.635619 (* 1 = 0.635619 loss)
I0728 15:06:39.574000 118397 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0728 15:07:48.067183 118397 solver.cpp:236] Iteration 1190, loss = 0.617548
I0728 15:07:48.067348 118397 solver.cpp:252]     Train net output #0: loss = 0.655476 (* 1 = 0.655476 loss)
I0728 15:07:48.067374 118397 sgd_solver.cpp:106] Iteration 1190, lr = 0.01
I0728 15:08:53.146662 118397 solver.cpp:236] Iteration 1200, loss = 0.619783
I0728 15:08:53.146849 118397 solver.cpp:252]     Train net output #0: loss = 0.631481 (* 1 = 0.631481 loss)
I0728 15:08:53.146875 118397 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0728 15:09:49.140147 118397 solver.cpp:236] Iteration 1210, loss = 0.614295
I0728 15:09:49.140338 118397 solver.cpp:252]     Train net output #0: loss = 0.269528 (* 1 = 0.269528 loss)
I0728 15:09:49.140373 118397 sgd_solver.cpp:106] Iteration 1210, lr = 0.01
I0728 15:10:41.200980 118397 solver.cpp:236] Iteration 1220, loss = 0.616352
I0728 15:10:41.202716 118397 solver.cpp:252]     Train net output #0: loss = 0.642572 (* 1 = 0.642572 loss)
I0728 15:10:41.202741 118397 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0728 15:11:31.182282 118397 solver.cpp:236] Iteration 1230, loss = 0.612028
I0728 15:11:31.182492 118397 solver.cpp:252]     Train net output #0: loss = 0.638914 (* 1 = 0.638914 loss)
I0728 15:11:31.182517 118397 sgd_solver.cpp:106] Iteration 1230, lr = 0.01
I0728 15:12:34.129338 118397 solver.cpp:236] Iteration 1240, loss = 0.607189
I0728 15:12:34.129542 118397 solver.cpp:252]     Train net output #0: loss = 0.322247 (* 1 = 0.322247 loss)
I0728 15:12:34.129590 118397 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0728 15:13:20.650038 118397 solver.cpp:236] Iteration 1250, loss = 0.600337
I0728 15:13:20.650368 118397 solver.cpp:252]     Train net output #0: loss = 0.69301 (* 1 = 0.69301 loss)
I0728 15:13:20.650408 118397 sgd_solver.cpp:106] Iteration 1250, lr = 0.01
I0728 15:14:26.589745 118397 solver.cpp:236] Iteration 1260, loss = 0.600178
I0728 15:14:26.590699 118397 solver.cpp:252]     Train net output #0: loss = 0.652554 (* 1 = 0.652554 loss)
I0728 15:14:26.590726 118397 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0728 15:15:21.714622 118397 solver.cpp:236] Iteration 1270, loss = 0.607013
I0728 15:15:21.714821 118397 solver.cpp:252]     Train net output #0: loss = 0.630242 (* 1 = 0.630242 loss)
I0728 15:15:21.714851 118397 sgd_solver.cpp:106] Iteration 1270, lr = 0.01
I0728 15:15:57.313027 118397 solver.cpp:236] Iteration 1280, loss = 0.604449
I0728 15:15:57.313222 118397 solver.cpp:252]     Train net output #0: loss = 0.739041 (* 1 = 0.739041 loss)
I0728 15:15:57.313248 118397 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0728 15:16:36.619102 118397 solver.cpp:236] Iteration 1290, loss = 0.606061
I0728 15:16:36.619312 118397 solver.cpp:252]     Train net output #0: loss = 0.639512 (* 1 = 0.639512 loss)
I0728 15:16:36.619333 118397 sgd_solver.cpp:106] Iteration 1290, lr = 0.01
I0728 15:17:13.239224 118397 solver.cpp:236] Iteration 1300, loss = 0.606217
I0728 15:17:13.239389 118397 solver.cpp:252]     Train net output #0: loss = 0.654854 (* 1 = 0.654854 loss)
I0728 15:17:13.239423 118397 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0728 15:18:01.683583 118397 solver.cpp:236] Iteration 1310, loss = 0.61031
I0728 15:18:01.683785 118397 solver.cpp:252]     Train net output #0: loss = 0.635336 (* 1 = 0.635336 loss)
I0728 15:18:01.683810 118397 sgd_solver.cpp:106] Iteration 1310, lr = 0.01
I0728 15:18:54.657536 118397 solver.cpp:236] Iteration 1320, loss = 0.609379
I0728 15:18:54.657769 118397 solver.cpp:252]     Train net output #0: loss = 0.65193 (* 1 = 0.65193 loss)
I0728 15:18:54.657796 118397 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0728 15:19:28.374672 118397 solver.cpp:236] Iteration 1330, loss = 0.611695
I0728 15:19:28.375046 118397 solver.cpp:252]     Train net output #0: loss = 0.635246 (* 1 = 0.635246 loss)
I0728 15:19:28.375067 118397 sgd_solver.cpp:106] Iteration 1330, lr = 0.01
I0728 15:20:11.434036 118397 solver.cpp:236] Iteration 1340, loss = 0.616075
I0728 15:20:11.434257 118397 solver.cpp:252]     Train net output #0: loss = 0.63756 (* 1 = 0.63756 loss)
I0728 15:20:11.434274 118397 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0728 15:20:46.468194 118397 solver.cpp:236] Iteration 1350, loss = 0.621234
I0728 15:20:46.468367 118397 solver.cpp:252]     Train net output #0: loss = 0.648035 (* 1 = 0.648035 loss)
I0728 15:20:46.468392 118397 sgd_solver.cpp:106] Iteration 1350, lr = 0.01
I0728 15:21:21.304383 118397 solver.cpp:236] Iteration 1360, loss = 0.626507
I0728 15:21:21.304620 118397 solver.cpp:252]     Train net output #0: loss = 0.643363 (* 1 = 0.643363 loss)
I0728 15:21:21.304642 118397 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0728 15:21:53.028146 118397 solver.cpp:236] Iteration 1370, loss = 0.625768
I0728 15:21:53.028302 118397 solver.cpp:252]     Train net output #0: loss = 0.654561 (* 1 = 0.654561 loss)
I0728 15:21:53.028331 118397 sgd_solver.cpp:106] Iteration 1370, lr = 0.01
I0728 15:22:41.878391 118397 solver.cpp:236] Iteration 1380, loss = 0.632351
I0728 15:22:41.878612 118397 solver.cpp:252]     Train net output #0: loss = 0.65958 (* 1 = 0.65958 loss)
I0728 15:22:41.878649 118397 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0728 15:23:28.818660 118397 solver.cpp:236] Iteration 1390, loss = 0.630484
I0728 15:23:28.818835 118397 solver.cpp:252]     Train net output #0: loss = 0.713163 (* 1 = 0.713163 loss)
I0728 15:23:28.818859 118397 sgd_solver.cpp:106] Iteration 1390, lr = 0.01
I0728 15:24:10.755759 118397 solver.cpp:236] Iteration 1400, loss = 0.627694
I0728 15:24:10.755939 118397 solver.cpp:252]     Train net output #0: loss = 0.6417 (* 1 = 0.6417 loss)
I0728 15:24:10.755955 118397 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0728 15:24:55.597062 118397 solver.cpp:236] Iteration 1410, loss = 0.629717
I0728 15:24:55.597300 118397 solver.cpp:252]     Train net output #0: loss = 0.633402 (* 1 = 0.633402 loss)
I0728 15:24:55.597314 118397 sgd_solver.cpp:106] Iteration 1410, lr = 0.01
I0728 15:25:34.573326 118397 solver.cpp:236] Iteration 1420, loss = 0.627434
I0728 15:25:34.573503 118397 solver.cpp:252]     Train net output #0: loss = 0.658566 (* 1 = 0.658566 loss)
I0728 15:25:34.573534 118397 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0728 15:26:37.186532 118397 solver.cpp:236] Iteration 1430, loss = 0.624631
I0728 15:26:37.186772 118397 solver.cpp:252]     Train net output #0: loss = 0.647832 (* 1 = 0.647832 loss)
I0728 15:26:37.186789 118397 sgd_solver.cpp:106] Iteration 1430, lr = 0.01
I0728 15:27:34.933462 118397 solver.cpp:236] Iteration 1440, loss = 0.624233
I0728 15:27:34.933595 118397 solver.cpp:252]     Train net output #0: loss = 0.636713 (* 1 = 0.636713 loss)
I0728 15:27:34.933614 118397 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0728 15:28:24.690708 118397 solver.cpp:236] Iteration 1450, loss = 0.621948
I0728 15:28:24.690948 118397 solver.cpp:252]     Train net output #0: loss = 0.335228 (* 1 = 0.335228 loss)
I0728 15:28:24.690968 118397 sgd_solver.cpp:106] Iteration 1450, lr = 0.01
I0728 15:29:40.832409 118397 solver.cpp:236] Iteration 1460, loss = 0.624574
I0728 15:29:40.832628 118397 solver.cpp:252]     Train net output #0: loss = 0.648164 (* 1 = 0.648164 loss)
I0728 15:29:40.832662 118397 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0728 15:30:40.379801 118397 solver.cpp:236] Iteration 1470, loss = 0.627156
I0728 15:30:40.379969 118397 solver.cpp:252]     Train net output #0: loss = 0.638351 (* 1 = 0.638351 loss)
I0728 15:30:40.379987 118397 sgd_solver.cpp:106] Iteration 1470, lr = 0.01
I0728 15:31:44.319596 118397 solver.cpp:236] Iteration 1480, loss = 0.626177
I0728 15:31:44.319782 118397 solver.cpp:252]     Train net output #0: loss = 0.634347 (* 1 = 0.634347 loss)
I0728 15:31:44.319804 118397 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0728 15:32:44.260259 118397 solver.cpp:236] Iteration 1490, loss = 0.621382
I0728 15:32:44.270058 118397 solver.cpp:252]     Train net output #0: loss = 0.706335 (* 1 = 0.706335 loss)
I0728 15:32:44.270097 118397 sgd_solver.cpp:106] Iteration 1490, lr = 0.01
I0728 15:33:36.095870 118397 solver.cpp:340] Iteration 1500, Testing net (#0)
I0728 15:35:07.069257 118397 solver.cpp:408]     Test net output #0: accuracy = 0.7375
I0728 15:35:07.069404 118397 solver.cpp:408]     Test net output #1: loss = 0.575977 (* 1 = 0.575977 loss)
I0728 15:35:18.217305 118397 solver.cpp:236] Iteration 1500, loss = 0.620767
I0728 15:35:18.217371 118397 solver.cpp:252]     Train net output #0: loss = 0.649102 (* 1 = 0.649102 loss)
I0728 15:35:18.217388 118397 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0728 15:38:21.196166 118397 solver.cpp:236] Iteration 1510, loss = 0.621058
I0728 15:38:21.196351 118397 solver.cpp:252]     Train net output #0: loss = 0.643409 (* 1 = 0.643409 loss)
I0728 15:38:21.196380 118397 sgd_solver.cpp:106] Iteration 1510, lr = 0.01
I0728 15:41:40.558545 118397 solver.cpp:236] Iteration 1520, loss = 0.621736
I0728 15:41:40.558768 118397 solver.cpp:252]     Train net output #0: loss = 0.657706 (* 1 = 0.657706 loss)
I0728 15:41:40.558795 118397 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0728 15:44:08.656535 118397 solver.cpp:236] Iteration 1530, loss = 0.619939
I0728 15:44:08.656711 118397 solver.cpp:252]     Train net output #0: loss = 0.651166 (* 1 = 0.651166 loss)
I0728 15:44:08.656743 118397 sgd_solver.cpp:106] Iteration 1530, lr = 0.01
I0728 15:46:20.405158 118397 solver.cpp:236] Iteration 1540, loss = 0.614768
I0728 15:46:20.405366 118397 solver.cpp:252]     Train net output #0: loss = 0.376604 (* 1 = 0.376604 loss)
I0728 15:46:20.405396 118397 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0728 15:48:47.181201 118397 solver.cpp:236] Iteration 1550, loss = 0.617305
I0728 15:48:47.181406 118397 solver.cpp:252]     Train net output #0: loss = 0.642057 (* 1 = 0.642057 loss)
I0728 15:48:47.181435 118397 sgd_solver.cpp:106] Iteration 1550, lr = 0.01
I0728 15:51:09.519222 118397 solver.cpp:236] Iteration 1560, loss = 0.612545
I0728 15:51:09.519480 118397 solver.cpp:252]     Train net output #0: loss = 0.643292 (* 1 = 0.643292 loss)
I0728 15:51:09.519502 118397 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0728 15:53:09.474267 118397 solver.cpp:236] Iteration 1570, loss = 0.611146
I0728 15:53:09.474450 118397 solver.cpp:252]     Train net output #0: loss = 0.646624 (* 1 = 0.646624 loss)
I0728 15:53:09.474475 118397 sgd_solver.cpp:106] Iteration 1570, lr = 0.01
I0728 15:55:13.354472 118397 solver.cpp:236] Iteration 1580, loss = 0.609822
I0728 15:55:13.354650 118397 solver.cpp:252]     Train net output #0: loss = 0.63992 (* 1 = 0.63992 loss)
I0728 15:55:13.354691 118397 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0728 15:56:38.538678 118397 solver.cpp:236] Iteration 1590, loss = 0.615399
I0728 15:56:38.538933 118397 solver.cpp:252]     Train net output #0: loss = 0.633123 (* 1 = 0.633123 loss)
I0728 15:56:38.538959 118397 sgd_solver.cpp:106] Iteration 1590, lr = 0.01
I0728 15:58:27.765547 118397 solver.cpp:236] Iteration 1600, loss = 0.620627
I0728 15:58:27.765713 118397 solver.cpp:252]     Train net output #0: loss = 0.66536 (* 1 = 0.66536 loss)
I0728 15:58:27.765740 118397 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0728 16:00:20.205878 118397 solver.cpp:236] Iteration 1610, loss = 0.621299
I0728 16:00:20.206085 118397 solver.cpp:252]     Train net output #0: loss = 0.652263 (* 1 = 0.652263 loss)
I0728 16:00:20.206106 118397 sgd_solver.cpp:106] Iteration 1610, lr = 0.01
I0728 16:02:14.818029 118397 solver.cpp:236] Iteration 1620, loss = 0.62243
I0728 16:02:14.818199 118397 solver.cpp:252]     Train net output #0: loss = 0.648207 (* 1 = 0.648207 loss)
I0728 16:02:14.818217 118397 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0728 16:04:08.410306 118397 solver.cpp:236] Iteration 1630, loss = 0.625726
I0728 16:04:08.416252 118397 solver.cpp:252]     Train net output #0: loss = 0.633621 (* 1 = 0.633621 loss)
I0728 16:04:08.416280 118397 sgd_solver.cpp:106] Iteration 1630, lr = 0.01
I0728 16:05:58.599865 118397 solver.cpp:236] Iteration 1640, loss = 0.617479
I0728 16:05:58.600054 118397 solver.cpp:252]     Train net output #0: loss = 0.157746 (* 1 = 0.157746 loss)
I0728 16:05:58.600090 118397 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0728 16:07:47.698515 118397 solver.cpp:236] Iteration 1650, loss = 0.616485
I0728 16:07:47.698740 118397 solver.cpp:252]     Train net output #0: loss = 0.652561 (* 1 = 0.652561 loss)
I0728 16:07:47.698772 118397 sgd_solver.cpp:106] Iteration 1650, lr = 0.01
I0728 16:09:42.862433 118397 solver.cpp:236] Iteration 1660, loss = 0.617931
I0728 16:09:42.862601 118397 solver.cpp:252]     Train net output #0: loss = 0.642659 (* 1 = 0.642659 loss)
I0728 16:09:42.862635 118397 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0728 16:11:46.912490 118397 solver.cpp:236] Iteration 1670, loss = 0.619647
I0728 16:11:46.912750 118397 solver.cpp:252]     Train net output #0: loss = 0.634718 (* 1 = 0.634718 loss)
I0728 16:11:46.912775 118397 sgd_solver.cpp:106] Iteration 1670, lr = 0.01
I0728 16:13:52.018122 118397 solver.cpp:236] Iteration 1680, loss = 0.615481
I0728 16:13:52.018286 118397 solver.cpp:252]     Train net output #0: loss = 0.63155 (* 1 = 0.63155 loss)
I0728 16:13:52.018306 118397 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0728 16:16:02.086318 118397 solver.cpp:236] Iteration 1690, loss = 0.613702
I0728 16:16:02.086480 118397 solver.cpp:252]     Train net output #0: loss = 0.650074 (* 1 = 0.650074 loss)
I0728 16:16:02.086501 118397 sgd_solver.cpp:106] Iteration 1690, lr = 0.01
I0728 16:18:17.583433 118397 solver.cpp:236] Iteration 1700, loss = 0.605657
I0728 16:18:17.583649 118397 solver.cpp:252]     Train net output #0: loss = 0.468644 (* 1 = 0.468644 loss)
I0728 16:18:17.583695 118397 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0728 16:19:42.741474 118397 solver.cpp:236] Iteration 1710, loss = 0.606568
I0728 16:19:42.741608 118397 solver.cpp:252]     Train net output #0: loss = 0.644286 (* 1 = 0.644286 loss)
I0728 16:19:42.741636 118397 sgd_solver.cpp:106] Iteration 1710, lr = 0.01
I0728 16:20:34.116509 118397 solver.cpp:236] Iteration 1720, loss = 0.602185
I0728 16:20:34.116703 118397 solver.cpp:252]     Train net output #0: loss = 0.39122 (* 1 = 0.39122 loss)
I0728 16:20:34.116731 118397 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0728 16:21:17.806619 118397 solver.cpp:236] Iteration 1730, loss = 0.598317
I0728 16:21:17.806844 118397 solver.cpp:252]     Train net output #0: loss = 0.739899 (* 1 = 0.739899 loss)
I0728 16:21:17.806865 118397 sgd_solver.cpp:106] Iteration 1730, lr = 0.01
I0728 16:22:15.987263 118397 solver.cpp:236] Iteration 1740, loss = 0.609548
I0728 16:22:15.989856 118397 solver.cpp:252]     Train net output #0: loss = 0.648589 (* 1 = 0.648589 loss)
I0728 16:22:15.989886 118397 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0728 16:22:56.338619 118397 solver.cpp:236] Iteration 1750, loss = 0.612285
I0728 16:22:56.338804 118397 solver.cpp:252]     Train net output #0: loss = 0.40275 (* 1 = 0.40275 loss)
I0728 16:22:56.338837 118397 sgd_solver.cpp:106] Iteration 1750, lr = 0.01
I0728 16:23:50.768321 118397 solver.cpp:236] Iteration 1760, loss = 0.614404
I0728 16:23:50.771145 118397 solver.cpp:252]     Train net output #0: loss = 0.65583 (* 1 = 0.65583 loss)
I0728 16:23:50.771168 118397 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0728 16:24:37.163750 118397 solver.cpp:236] Iteration 1770, loss = 0.614009
I0728 16:24:37.163933 118397 solver.cpp:252]     Train net output #0: loss = 0.640742 (* 1 = 0.640742 loss)
I0728 16:24:37.163975 118397 sgd_solver.cpp:106] Iteration 1770, lr = 0.01
I0728 16:25:40.567371 118397 solver.cpp:236] Iteration 1780, loss = 0.619131
I0728 16:25:40.567533 118397 solver.cpp:252]     Train net output #0: loss = 0.641159 (* 1 = 0.641159 loss)
I0728 16:25:40.567553 118397 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0728 16:26:48.038533 118397 solver.cpp:236] Iteration 1790, loss = 0.620119
I0728 16:26:48.038743 118397 solver.cpp:252]     Train net output #0: loss = 0.641274 (* 1 = 0.641274 loss)
I0728 16:26:48.038784 118397 sgd_solver.cpp:106] Iteration 1790, lr = 0.01
I0728 16:27:36.935098 118397 solver.cpp:236] Iteration 1800, loss = 0.626834
I0728 16:27:36.935292 118397 solver.cpp:252]     Train net output #0: loss = 0.632658 (* 1 = 0.632658 loss)
I0728 16:27:36.935313 118397 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0728 16:29:58.548249 118397 solver.cpp:236] Iteration 1810, loss = 0.619688
I0728 16:29:58.548416 118397 solver.cpp:252]     Train net output #0: loss = 0.661657 (* 1 = 0.661657 loss)
I0728 16:29:58.548445 118397 sgd_solver.cpp:106] Iteration 1810, lr = 0.01
I0728 16:34:37.790040 118397 solver.cpp:236] Iteration 1820, loss = 0.626745
I0728 16:34:37.790210 118397 solver.cpp:252]     Train net output #0: loss = 0.641275 (* 1 = 0.641275 loss)
I0728 16:34:37.790228 118397 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0728 16:36:57.152793 118397 solver.cpp:236] Iteration 1830, loss = 0.629946
I0728 16:36:57.152988 118397 solver.cpp:252]     Train net output #0: loss = 0.686838 (* 1 = 0.686838 loss)
I0728 16:36:57.153007 118397 sgd_solver.cpp:106] Iteration 1830, lr = 0.01
I0728 16:37:39.745640 118397 solver.cpp:236] Iteration 1840, loss = 0.635311
I0728 16:37:39.745798 118397 solver.cpp:252]     Train net output #0: loss = 0.652732 (* 1 = 0.652732 loss)
I0728 16:37:39.745821 118397 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0728 16:40:10.355134 118397 solver.cpp:236] Iteration 1850, loss = 0.637126
I0728 16:40:10.355377 118397 solver.cpp:252]     Train net output #0: loss = 0.645431 (* 1 = 0.645431 loss)
I0728 16:40:10.355402 118397 sgd_solver.cpp:106] Iteration 1850, lr = 0.01
I0728 16:43:04.085690 118397 solver.cpp:236] Iteration 1860, loss = 0.632365
I0728 16:43:04.085855 118397 solver.cpp:252]     Train net output #0: loss = 0.642825 (* 1 = 0.642825 loss)
I0728 16:43:04.085875 118397 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0728 16:46:23.661239 118397 solver.cpp:236] Iteration 1870, loss = 0.632243
I0728 16:46:23.661406 118397 solver.cpp:252]     Train net output #0: loss = 0.639791 (* 1 = 0.639791 loss)
I0728 16:46:23.661430 118397 sgd_solver.cpp:106] Iteration 1870, lr = 0.01
I0728 16:48:28.501364 118397 solver.cpp:236] Iteration 1880, loss = 0.630941
I0728 16:48:28.501665 118397 solver.cpp:252]     Train net output #0: loss = 0.641056 (* 1 = 0.641056 loss)
I0728 16:48:28.501695 118397 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0728 16:50:48.064844 118397 solver.cpp:236] Iteration 1890, loss = 0.632875
I0728 16:50:48.065006 118397 solver.cpp:252]     Train net output #0: loss = 0.637959 (* 1 = 0.637959 loss)
I0728 16:50:48.065024 118397 sgd_solver.cpp:106] Iteration 1890, lr = 0.01
I0728 16:53:35.623466 118397 solver.cpp:236] Iteration 1900, loss = 0.633073
I0728 16:53:35.623646 118397 solver.cpp:252]     Train net output #0: loss = 0.635275 (* 1 = 0.635275 loss)
I0728 16:53:35.623667 118397 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0728 16:56:13.846575 118397 solver.cpp:236] Iteration 1910, loss = 0.638153
I0728 16:56:13.846856 118397 solver.cpp:252]     Train net output #0: loss = 0.63279 (* 1 = 0.63279 loss)
I0728 16:56:13.846909 118397 sgd_solver.cpp:106] Iteration 1910, lr = 0.01
I0728 16:58:42.232801 118397 solver.cpp:236] Iteration 1920, loss = 0.635331
I0728 16:58:42.242698 118397 solver.cpp:252]     Train net output #0: loss = 0.63258 (* 1 = 0.63258 loss)
I0728 16:58:42.242728 118397 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0728 17:00:58.285413 118397 solver.cpp:236] Iteration 1930, loss = 0.635451
I0728 17:00:58.285650 118397 solver.cpp:252]     Train net output #0: loss = 0.635826 (* 1 = 0.635826 loss)
I0728 17:00:58.285668 118397 sgd_solver.cpp:106] Iteration 1930, lr = 0.01
I0728 17:03:11.674490 118397 solver.cpp:236] Iteration 1940, loss = 0.632626
I0728 17:03:11.674659 118397 solver.cpp:252]     Train net output #0: loss = 0.63638 (* 1 = 0.63638 loss)
I0728 17:03:11.674684 118397 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0728 17:05:30.106135 118397 solver.cpp:236] Iteration 1950, loss = 0.62693
I0728 17:05:30.117985 118397 solver.cpp:252]     Train net output #0: loss = 0.670295 (* 1 = 0.670295 loss)
I0728 17:05:30.118016 118397 sgd_solver.cpp:106] Iteration 1950, lr = 0.01
I0728 17:07:47.164547 118397 solver.cpp:236] Iteration 1960, loss = 0.630372
I0728 17:07:47.164731 118397 solver.cpp:252]     Train net output #0: loss = 0.650594 (* 1 = 0.650594 loss)
I0728 17:07:47.164748 118397 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0728 17:09:59.888942 118397 solver.cpp:236] Iteration 1970, loss = 0.629211
I0728 17:09:59.889070 118397 solver.cpp:252]     Train net output #0: loss = 0.655558 (* 1 = 0.655558 loss)
I0728 17:09:59.889091 118397 sgd_solver.cpp:106] Iteration 1970, lr = 0.01
I0728 17:11:41.088237 118397 solver.cpp:236] Iteration 1980, loss = 0.625685
I0728 17:11:41.088402 118397 solver.cpp:252]     Train net output #0: loss = 0.365662 (* 1 = 0.365662 loss)
I0728 17:11:41.088449 118397 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0728 17:13:40.163910 118397 solver.cpp:236] Iteration 1990, loss = 0.624683
I0728 17:13:40.164041 118397 solver.cpp:252]     Train net output #0: loss = 0.650111 (* 1 = 0.650111 loss)
I0728 17:13:40.164070 118397 sgd_solver.cpp:106] Iteration 1990, lr = 0.01
I0728 17:15:11.047513 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_2000.caffemodel
I0728 17:15:11.169529 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_2000.solverstate
I0728 17:15:11.173677 118397 solver.cpp:340] Iteration 2000, Testing net (#0)
I0728 17:17:08.249269 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 17:17:08.249418 118397 solver.cpp:408]     Test net output #1: loss = 0.627655 (* 1 = 0.627655 loss)
I0728 17:17:16.775148 118397 solver.cpp:236] Iteration 2000, loss = 0.62532
I0728 17:17:16.775213 118397 solver.cpp:252]     Train net output #0: loss = 0.646107 (* 1 = 0.646107 loss)
I0728 17:17:16.775231 118397 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0728 17:19:23.379395 118397 solver.cpp:236] Iteration 2010, loss = 0.620284
I0728 17:19:23.379560 118397 solver.cpp:252]     Train net output #0: loss = 0.677215 (* 1 = 0.677215 loss)
I0728 17:19:23.379595 118397 sgd_solver.cpp:106] Iteration 2010, lr = 0.01
I0728 17:21:26.087429 118397 solver.cpp:236] Iteration 2020, loss = 0.622421
I0728 17:21:26.087595 118397 solver.cpp:252]     Train net output #0: loss = 0.635774 (* 1 = 0.635774 loss)
I0728 17:21:26.087630 118397 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0728 17:23:09.097935 118397 solver.cpp:236] Iteration 2030, loss = 0.622364
I0728 17:23:09.098084 118397 solver.cpp:252]     Train net output #0: loss = 0.392868 (* 1 = 0.392868 loss)
I0728 17:23:09.098101 118397 sgd_solver.cpp:106] Iteration 2030, lr = 0.01
I0728 17:24:59.136782 118397 solver.cpp:236] Iteration 2040, loss = 0.620447
I0728 17:24:59.139281 118397 solver.cpp:252]     Train net output #0: loss = 0.646315 (* 1 = 0.646315 loss)
I0728 17:24:59.139302 118397 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0728 17:27:02.314736 118397 solver.cpp:236] Iteration 2050, loss = 0.622853
I0728 17:27:02.314919 118397 solver.cpp:252]     Train net output #0: loss = 0.635393 (* 1 = 0.635393 loss)
I0728 17:27:02.314941 118397 sgd_solver.cpp:106] Iteration 2050, lr = 0.01
I0728 17:28:43.794646 118397 solver.cpp:236] Iteration 2060, loss = 0.619756
I0728 17:28:43.794812 118397 solver.cpp:252]     Train net output #0: loss = 0.63957 (* 1 = 0.63957 loss)
I0728 17:28:43.794837 118397 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0728 17:30:36.767997 118397 solver.cpp:236] Iteration 2070, loss = 0.618749
I0728 17:30:36.768195 118397 solver.cpp:252]     Train net output #0: loss = 0.636135 (* 1 = 0.636135 loss)
I0728 17:30:36.768227 118397 sgd_solver.cpp:106] Iteration 2070, lr = 0.01
I0728 17:32:06.097823 118397 solver.cpp:236] Iteration 2080, loss = 0.620037
I0728 17:32:06.097983 118397 solver.cpp:252]     Train net output #0: loss = 0.648615 (* 1 = 0.648615 loss)
I0728 17:32:06.098007 118397 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0728 17:33:42.971700 118397 solver.cpp:236] Iteration 2090, loss = 0.620537
I0728 17:33:42.972014 118397 solver.cpp:252]     Train net output #0: loss = 0.646053 (* 1 = 0.646053 loss)
I0728 17:33:42.972040 118397 sgd_solver.cpp:106] Iteration 2090, lr = 0.01
I0728 17:35:10.888123 118397 solver.cpp:236] Iteration 2100, loss = 0.615555
I0728 17:35:10.890955 118397 solver.cpp:252]     Train net output #0: loss = 0.645357 (* 1 = 0.645357 loss)
I0728 17:35:10.890974 118397 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0728 17:37:03.023335 118397 solver.cpp:236] Iteration 2110, loss = 0.615409
I0728 17:37:03.023497 118397 solver.cpp:252]     Train net output #0: loss = 0.295963 (* 1 = 0.295963 loss)
I0728 17:37:03.023514 118397 sgd_solver.cpp:106] Iteration 2110, lr = 0.01
I0728 17:38:29.588590 118397 solver.cpp:236] Iteration 2120, loss = 0.608608
I0728 17:38:29.588821 118397 solver.cpp:252]     Train net output #0: loss = 0.658756 (* 1 = 0.658756 loss)
I0728 17:38:29.588845 118397 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0728 17:39:52.820835 118397 solver.cpp:236] Iteration 2130, loss = 0.610932
I0728 17:39:52.821004 118397 solver.cpp:252]     Train net output #0: loss = 0.643386 (* 1 = 0.643386 loss)
I0728 17:39:52.821025 118397 sgd_solver.cpp:106] Iteration 2130, lr = 0.01
I0728 17:41:05.353009 118397 solver.cpp:236] Iteration 2140, loss = 0.611687
I0728 17:41:05.353204 118397 solver.cpp:252]     Train net output #0: loss = 0.652176 (* 1 = 0.652176 loss)
I0728 17:41:05.353235 118397 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0728 17:42:24.940318 118397 solver.cpp:236] Iteration 2150, loss = 0.612006
I0728 17:42:24.940531 118397 solver.cpp:252]     Train net output #0: loss = 0.632404 (* 1 = 0.632404 loss)
I0728 17:42:24.940554 118397 sgd_solver.cpp:106] Iteration 2150, lr = 0.01
I0728 17:43:44.449501 118397 solver.cpp:236] Iteration 2160, loss = 0.614941
I0728 17:43:44.449666 118397 solver.cpp:252]     Train net output #0: loss = 0.638148 (* 1 = 0.638148 loss)
I0728 17:43:44.449686 118397 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0728 17:45:03.136677 118397 solver.cpp:236] Iteration 2170, loss = 0.6168
I0728 17:45:03.136852 118397 solver.cpp:252]     Train net output #0: loss = 0.636895 (* 1 = 0.636895 loss)
I0728 17:45:03.136878 118397 sgd_solver.cpp:106] Iteration 2170, lr = 0.01
I0728 17:46:11.173195 118397 solver.cpp:236] Iteration 2180, loss = 0.614757
I0728 17:46:11.173363 118397 solver.cpp:252]     Train net output #0: loss = 0.693485 (* 1 = 0.693485 loss)
I0728 17:46:11.173398 118397 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0728 17:47:15.107473 118397 solver.cpp:236] Iteration 2190, loss = 0.61627
I0728 17:47:15.108360 118397 solver.cpp:252]     Train net output #0: loss = 0.658517 (* 1 = 0.658517 loss)
I0728 17:47:15.108382 118397 sgd_solver.cpp:106] Iteration 2190, lr = 0.01
I0728 17:48:19.980381 118397 solver.cpp:236] Iteration 2200, loss = 0.616767
I0728 17:48:19.980551 118397 solver.cpp:252]     Train net output #0: loss = 0.674251 (* 1 = 0.674251 loss)
I0728 17:48:19.980569 118397 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0728 17:49:27.203761 118397 solver.cpp:236] Iteration 2210, loss = 0.625343
I0728 17:49:27.203944 118397 solver.cpp:252]     Train net output #0: loss = 0.636436 (* 1 = 0.636436 loss)
I0728 17:49:27.203964 118397 sgd_solver.cpp:106] Iteration 2210, lr = 0.01
I0728 17:50:13.348278 118397 solver.cpp:236] Iteration 2220, loss = 0.628231
I0728 17:50:13.348502 118397 solver.cpp:252]     Train net output #0: loss = 0.63691 (* 1 = 0.63691 loss)
I0728 17:50:13.348521 118397 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0728 17:51:06.635512 118397 solver.cpp:236] Iteration 2230, loss = 0.619008
I0728 17:51:06.635720 118397 solver.cpp:252]     Train net output #0: loss = 0.25542 (* 1 = 0.25542 loss)
I0728 17:51:06.635756 118397 sgd_solver.cpp:106] Iteration 2230, lr = 0.01
I0728 17:51:43.979055 118397 solver.cpp:236] Iteration 2240, loss = 0.616236
I0728 17:51:43.979207 118397 solver.cpp:252]     Train net output #0: loss = 0.639321 (* 1 = 0.639321 loss)
I0728 17:51:43.979228 118397 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0728 17:52:22.995833 118397 solver.cpp:236] Iteration 2250, loss = 0.616352
I0728 17:52:22.996039 118397 solver.cpp:252]     Train net output #0: loss = 0.634136 (* 1 = 0.634136 loss)
I0728 17:52:22.996062 118397 sgd_solver.cpp:106] Iteration 2250, lr = 0.01
I0728 17:53:07.912263 118397 solver.cpp:236] Iteration 2260, loss = 0.616255
I0728 17:53:07.912468 118397 solver.cpp:252]     Train net output #0: loss = 0.635841 (* 1 = 0.635841 loss)
I0728 17:53:07.912492 118397 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0728 17:53:39.123044 118397 solver.cpp:236] Iteration 2270, loss = 0.616264
I0728 17:53:39.123275 118397 solver.cpp:252]     Train net output #0: loss = 0.63738 (* 1 = 0.63738 loss)
I0728 17:53:39.123317 118397 sgd_solver.cpp:106] Iteration 2270, lr = 0.01
I0728 17:54:10.615015 118397 solver.cpp:236] Iteration 2280, loss = 0.612232
I0728 17:54:10.615272 118397 solver.cpp:252]     Train net output #0: loss = 0.78177 (* 1 = 0.78177 loss)
I0728 17:54:10.615298 118397 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0728 17:54:40.941509 118397 solver.cpp:236] Iteration 2290, loss = 0.611619
I0728 17:54:40.950765 118397 solver.cpp:252]     Train net output #0: loss = 0.650119 (* 1 = 0.650119 loss)
I0728 17:54:40.950803 118397 sgd_solver.cpp:106] Iteration 2290, lr = 0.01
I0728 17:55:17.712182 118397 solver.cpp:236] Iteration 2300, loss = 0.616608
I0728 17:55:17.712363 118397 solver.cpp:252]     Train net output #0: loss = 0.644688 (* 1 = 0.644688 loss)
I0728 17:55:17.712388 118397 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0728 17:55:47.701742 118397 solver.cpp:236] Iteration 2310, loss = 0.609595
I0728 17:55:47.701822 118397 solver.cpp:252]     Train net output #0: loss = 0.722901 (* 1 = 0.722901 loss)
I0728 17:55:47.701840 118397 sgd_solver.cpp:106] Iteration 2310, lr = 0.01
I0728 17:56:23.308763 118397 solver.cpp:236] Iteration 2320, loss = 0.6145
I0728 17:56:23.308938 118397 solver.cpp:252]     Train net output #0: loss = 0.644147 (* 1 = 0.644147 loss)
I0728 17:56:23.308956 118397 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0728 17:56:54.770778 118397 solver.cpp:236] Iteration 2330, loss = 0.623481
I0728 17:56:54.770998 118397 solver.cpp:252]     Train net output #0: loss = 0.647836 (* 1 = 0.647836 loss)
I0728 17:56:54.771015 118397 sgd_solver.cpp:106] Iteration 2330, lr = 0.01
I0728 17:57:25.182103 118397 solver.cpp:236] Iteration 2340, loss = 0.622861
I0728 17:57:25.182345 118397 solver.cpp:252]     Train net output #0: loss = 0.65358 (* 1 = 0.65358 loss)
I0728 17:57:25.182371 118397 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0728 17:57:49.124932 118397 solver.cpp:236] Iteration 2350, loss = 0.621735
I0728 17:57:49.125017 118397 solver.cpp:252]     Train net output #0: loss = 0.637619 (* 1 = 0.637619 loss)
I0728 17:57:49.125036 118397 sgd_solver.cpp:106] Iteration 2350, lr = 0.01
I0728 17:58:23.266736 118397 solver.cpp:236] Iteration 2360, loss = 0.619071
I0728 17:58:23.266901 118397 solver.cpp:252]     Train net output #0: loss = 0.426231 (* 1 = 0.426231 loss)
I0728 17:58:23.266923 118397 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0728 17:58:57.576532 118397 solver.cpp:236] Iteration 2370, loss = 0.616204
I0728 17:58:57.577091 118397 solver.cpp:252]     Train net output #0: loss = 0.650221 (* 1 = 0.650221 loss)
I0728 17:58:57.577108 118397 sgd_solver.cpp:106] Iteration 2370, lr = 0.01
I0728 17:59:38.952625 118397 solver.cpp:236] Iteration 2380, loss = 0.626451
I0728 17:59:38.952788 118397 solver.cpp:252]     Train net output #0: loss = 0.647635 (* 1 = 0.647635 loss)
I0728 17:59:38.952816 118397 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0728 18:00:12.463845 118397 solver.cpp:236] Iteration 2390, loss = 0.622653
I0728 18:00:12.464115 118397 solver.cpp:252]     Train net output #0: loss = 0.678821 (* 1 = 0.678821 loss)
I0728 18:00:12.464138 118397 sgd_solver.cpp:106] Iteration 2390, lr = 0.01
I0728 18:00:42.657901 118397 solver.cpp:236] Iteration 2400, loss = 0.61933
I0728 18:00:42.658187 118397 solver.cpp:252]     Train net output #0: loss = 0.629728 (* 1 = 0.629728 loss)
I0728 18:00:42.658205 118397 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0728 18:01:18.534478 118397 solver.cpp:236] Iteration 2410, loss = 0.621334
I0728 18:01:18.534745 118397 solver.cpp:252]     Train net output #0: loss = 0.643037 (* 1 = 0.643037 loss)
I0728 18:01:18.534777 118397 sgd_solver.cpp:106] Iteration 2410, lr = 0.01
I0728 18:01:53.302417 118397 solver.cpp:236] Iteration 2420, loss = 0.617839
I0728 18:01:53.302625 118397 solver.cpp:252]     Train net output #0: loss = 0.653106 (* 1 = 0.653106 loss)
I0728 18:01:53.302662 118397 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0728 18:02:31.131810 118397 solver.cpp:236] Iteration 2430, loss = 0.618116
I0728 18:02:31.132056 118397 solver.cpp:252]     Train net output #0: loss = 0.650825 (* 1 = 0.650825 loss)
I0728 18:02:31.132074 118397 sgd_solver.cpp:106] Iteration 2430, lr = 0.01
I0728 18:03:05.869369 118397 solver.cpp:236] Iteration 2440, loss = 0.621071
I0728 18:03:05.869534 118397 solver.cpp:252]     Train net output #0: loss = 0.690515 (* 1 = 0.690515 loss)
I0728 18:03:05.869559 118397 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0728 18:03:42.474520 118397 solver.cpp:236] Iteration 2450, loss = 0.625527
I0728 18:03:42.474743 118397 solver.cpp:252]     Train net output #0: loss = 0.649072 (* 1 = 0.649072 loss)
I0728 18:03:42.474774 118397 sgd_solver.cpp:106] Iteration 2450, lr = 0.01
I0728 18:04:15.152519 118397 solver.cpp:236] Iteration 2460, loss = 0.628407
I0728 18:04:15.152675 118397 solver.cpp:252]     Train net output #0: loss = 0.634551 (* 1 = 0.634551 loss)
I0728 18:04:15.152694 118397 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0728 18:04:56.399294 118397 solver.cpp:236] Iteration 2470, loss = 0.629209
I0728 18:04:56.399530 118397 solver.cpp:252]     Train net output #0: loss = 0.654046 (* 1 = 0.654046 loss)
I0728 18:04:56.399550 118397 sgd_solver.cpp:106] Iteration 2470, lr = 0.01
I0728 18:05:31.725644 118397 solver.cpp:236] Iteration 2480, loss = 0.623252
I0728 18:05:31.725816 118397 solver.cpp:252]     Train net output #0: loss = 0.639505 (* 1 = 0.639505 loss)
I0728 18:05:31.725841 118397 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0728 18:05:59.807296 118397 solver.cpp:236] Iteration 2490, loss = 0.624182
I0728 18:05:59.807366 118397 solver.cpp:252]     Train net output #0: loss = 0.641107 (* 1 = 0.641107 loss)
I0728 18:05:59.807384 118397 sgd_solver.cpp:106] Iteration 2490, lr = 0.01
I0728 18:06:25.798276 118397 solver.cpp:340] Iteration 2500, Testing net (#0)
I0728 18:06:52.798435 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 18:06:52.798534 118397 solver.cpp:408]     Test net output #1: loss = 0.638675 (* 1 = 0.638675 loss)
I0728 18:06:56.022109 118397 solver.cpp:236] Iteration 2500, loss = 0.62204
I0728 18:06:56.022263 118397 solver.cpp:252]     Train net output #0: loss = 0.638154 (* 1 = 0.638154 loss)
I0728 18:06:56.022279 118397 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0728 18:07:24.645967 118397 solver.cpp:236] Iteration 2510, loss = 0.619147
I0728 18:07:24.646037 118397 solver.cpp:252]     Train net output #0: loss = 0.269273 (* 1 = 0.269273 loss)
I0728 18:07:24.646054 118397 sgd_solver.cpp:106] Iteration 2510, lr = 0.01
I0728 18:07:52.202451 118397 solver.cpp:236] Iteration 2520, loss = 0.620506
I0728 18:07:52.202937 118397 solver.cpp:252]     Train net output #0: loss = 0.642583 (* 1 = 0.642583 loss)
I0728 18:07:52.202966 118397 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0728 18:08:20.684574 118397 solver.cpp:236] Iteration 2530, loss = 0.618579
I0728 18:08:20.684646 118397 solver.cpp:252]     Train net output #0: loss = 0.641584 (* 1 = 0.641584 loss)
I0728 18:08:20.684662 118397 sgd_solver.cpp:106] Iteration 2530, lr = 0.01
I0728 18:08:49.610746 118397 solver.cpp:236] Iteration 2540, loss = 0.617613
I0728 18:08:49.610982 118397 solver.cpp:252]     Train net output #0: loss = 0.637341 (* 1 = 0.637341 loss)
I0728 18:08:49.611009 118397 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0728 18:09:19.051765 118397 solver.cpp:236] Iteration 2550, loss = 0.614161
I0728 18:09:19.051839 118397 solver.cpp:252]     Train net output #0: loss = 0.635405 (* 1 = 0.635405 loss)
I0728 18:09:19.051856 118397 sgd_solver.cpp:106] Iteration 2550, lr = 0.01
I0728 18:09:49.243139 118397 solver.cpp:236] Iteration 2560, loss = 0.611154
I0728 18:09:49.243443 118397 solver.cpp:252]     Train net output #0: loss = 0.643953 (* 1 = 0.643953 loss)
I0728 18:09:49.243460 118397 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0728 18:10:18.503306 118397 solver.cpp:236] Iteration 2570, loss = 0.610999
I0728 18:10:18.503373 118397 solver.cpp:252]     Train net output #0: loss = 0.637458 (* 1 = 0.637458 loss)
I0728 18:10:18.503389 118397 sgd_solver.cpp:106] Iteration 2570, lr = 0.01
I0728 18:10:47.845933 118397 solver.cpp:236] Iteration 2580, loss = 0.613916
I0728 18:10:47.846112 118397 solver.cpp:252]     Train net output #0: loss = 0.639785 (* 1 = 0.639785 loss)
I0728 18:10:47.846137 118397 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0728 18:11:16.793718 118397 solver.cpp:236] Iteration 2590, loss = 0.613798
I0728 18:11:16.793794 118397 solver.cpp:252]     Train net output #0: loss = 0.633705 (* 1 = 0.633705 loss)
I0728 18:11:16.793809 118397 sgd_solver.cpp:106] Iteration 2590, lr = 0.01
I0728 18:11:43.232192 118397 solver.cpp:236] Iteration 2600, loss = 0.609013
I0728 18:11:43.232342 118397 solver.cpp:252]     Train net output #0: loss = 0.671486 (* 1 = 0.671486 loss)
I0728 18:11:43.232372 118397 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0728 18:12:07.316050 118397 solver.cpp:236] Iteration 2610, loss = 0.600753
I0728 18:12:07.316119 118397 solver.cpp:252]     Train net output #0: loss = 0.737025 (* 1 = 0.737025 loss)
I0728 18:12:07.316135 118397 sgd_solver.cpp:106] Iteration 2610, lr = 0.01
I0728 18:12:33.847667 118397 solver.cpp:236] Iteration 2620, loss = 0.594876
I0728 18:12:33.847868 118397 solver.cpp:252]     Train net output #0: loss = 0.641455 (* 1 = 0.641455 loss)
I0728 18:12:33.847892 118397 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0728 18:13:06.773581 118397 solver.cpp:236] Iteration 2630, loss = 0.59491
I0728 18:13:06.773797 118397 solver.cpp:252]     Train net output #0: loss = 0.637065 (* 1 = 0.637065 loss)
I0728 18:13:06.773813 118397 sgd_solver.cpp:106] Iteration 2630, lr = 0.01
I0728 18:13:39.060469 118397 solver.cpp:236] Iteration 2640, loss = 0.594722
I0728 18:13:39.060695 118397 solver.cpp:252]     Train net output #0: loss = 0.64624 (* 1 = 0.64624 loss)
I0728 18:13:39.060712 118397 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0728 18:14:07.500579 118397 solver.cpp:236] Iteration 2650, loss = 0.594314
I0728 18:14:07.500653 118397 solver.cpp:252]     Train net output #0: loss = 0.63952 (* 1 = 0.63952 loss)
I0728 18:14:07.500669 118397 sgd_solver.cpp:106] Iteration 2650, lr = 0.01
I0728 18:14:34.031967 118397 solver.cpp:236] Iteration 2660, loss = 0.588054
I0728 18:14:34.032187 118397 solver.cpp:252]     Train net output #0: loss = 0.747018 (* 1 = 0.747018 loss)
I0728 18:14:34.032204 118397 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0728 18:15:05.462170 118397 solver.cpp:236] Iteration 2670, loss = 0.588908
I0728 18:15:05.462332 118397 solver.cpp:252]     Train net output #0: loss = 0.642643 (* 1 = 0.642643 loss)
I0728 18:15:05.462349 118397 sgd_solver.cpp:106] Iteration 2670, lr = 0.01
I0728 18:15:34.721974 118397 solver.cpp:236] Iteration 2680, loss = 0.588822
I0728 18:15:34.722035 118397 solver.cpp:252]     Train net output #0: loss = 0.643883 (* 1 = 0.643883 loss)
I0728 18:15:34.722046 118397 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0728 18:16:02.750061 118397 solver.cpp:236] Iteration 2690, loss = 0.592142
I0728 18:16:02.750310 118397 solver.cpp:252]     Train net output #0: loss = 0.647228 (* 1 = 0.647228 loss)
I0728 18:16:02.750325 118397 sgd_solver.cpp:106] Iteration 2690, lr = 0.01
I0728 18:16:33.527274 118397 solver.cpp:236] Iteration 2700, loss = 0.599033
I0728 18:16:33.527474 118397 solver.cpp:252]     Train net output #0: loss = 0.646475 (* 1 = 0.646475 loss)
I0728 18:16:33.527500 118397 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0728 18:17:07.888069 118397 solver.cpp:236] Iteration 2710, loss = 0.61103
I0728 18:17:07.888397 118397 solver.cpp:252]     Train net output #0: loss = 0.638751 (* 1 = 0.638751 loss)
I0728 18:17:07.888417 118397 sgd_solver.cpp:106] Iteration 2710, lr = 0.01
I0728 18:17:44.329413 118397 solver.cpp:236] Iteration 2720, loss = 0.613156
I0728 18:17:44.334036 118397 solver.cpp:252]     Train net output #0: loss = 0.642192 (* 1 = 0.642192 loss)
I0728 18:17:44.334056 118397 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0728 18:18:16.642489 118397 solver.cpp:236] Iteration 2730, loss = 0.615345
I0728 18:18:16.643143 118397 solver.cpp:252]     Train net output #0: loss = 0.659385 (* 1 = 0.659385 loss)
I0728 18:18:16.643168 118397 sgd_solver.cpp:106] Iteration 2730, lr = 0.01
I0728 18:18:41.751297 118397 solver.cpp:236] Iteration 2740, loss = 0.616809
I0728 18:18:41.751373 118397 solver.cpp:252]     Train net output #0: loss = 0.640706 (* 1 = 0.640706 loss)
I0728 18:18:41.751390 118397 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0728 18:19:09.548131 118397 solver.cpp:236] Iteration 2750, loss = 0.614049
I0728 18:19:09.548595 118397 solver.cpp:252]     Train net output #0: loss = 0.668506 (* 1 = 0.668506 loss)
I0728 18:19:09.548614 118397 sgd_solver.cpp:106] Iteration 2750, lr = 0.01
I0728 18:19:34.446038 118397 solver.cpp:236] Iteration 2760, loss = 0.618726
I0728 18:19:34.446106 118397 solver.cpp:252]     Train net output #0: loss = 0.649325 (* 1 = 0.649325 loss)
I0728 18:19:34.446121 118397 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0728 18:19:58.752441 118397 solver.cpp:236] Iteration 2770, loss = 0.614514
I0728 18:19:58.752708 118397 solver.cpp:252]     Train net output #0: loss = 0.640207 (* 1 = 0.640207 loss)
I0728 18:19:58.752733 118397 sgd_solver.cpp:106] Iteration 2770, lr = 0.01
I0728 18:20:24.574431 118397 solver.cpp:236] Iteration 2780, loss = 0.615035
I0728 18:20:24.574513 118397 solver.cpp:252]     Train net output #0: loss = 0.638916 (* 1 = 0.638916 loss)
I0728 18:20:24.574528 118397 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0728 18:20:53.721534 118397 solver.cpp:236] Iteration 2790, loss = 0.613902
I0728 18:20:53.721794 118397 solver.cpp:252]     Train net output #0: loss = 0.639863 (* 1 = 0.639863 loss)
I0728 18:20:53.721812 118397 sgd_solver.cpp:106] Iteration 2790, lr = 0.01
I0728 18:21:23.338114 118397 solver.cpp:236] Iteration 2800, loss = 0.614695
I0728 18:21:23.338183 118397 solver.cpp:252]     Train net output #0: loss = 0.642527 (* 1 = 0.642527 loss)
I0728 18:21:23.338201 118397 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0728 18:21:48.885036 118397 solver.cpp:236] Iteration 2810, loss = 0.607103
I0728 18:21:48.885206 118397 solver.cpp:252]     Train net output #0: loss = 0.663013 (* 1 = 0.663013 loss)
I0728 18:21:48.885242 118397 sgd_solver.cpp:106] Iteration 2810, lr = 0.01
I0728 18:22:22.453940 118397 solver.cpp:236] Iteration 2820, loss = 0.605405
I0728 18:22:22.454131 118397 solver.cpp:252]     Train net output #0: loss = 0.643949 (* 1 = 0.643949 loss)
I0728 18:22:22.454161 118397 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0728 18:22:59.846266 118397 solver.cpp:236] Iteration 2830, loss = 0.596029
I0728 18:22:59.846477 118397 solver.cpp:252]     Train net output #0: loss = 0.668508 (* 1 = 0.668508 loss)
I0728 18:22:59.846495 118397 sgd_solver.cpp:106] Iteration 2830, lr = 0.01
I0728 18:23:38.634469 118397 solver.cpp:236] Iteration 2840, loss = 0.597647
I0728 18:23:38.634601 118397 solver.cpp:252]     Train net output #0: loss = 0.647512 (* 1 = 0.647512 loss)
I0728 18:23:38.634623 118397 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0728 18:24:14.226244 118397 solver.cpp:236] Iteration 2850, loss = 0.603014
I0728 18:24:14.226495 118397 solver.cpp:252]     Train net output #0: loss = 0.637906 (* 1 = 0.637906 loss)
I0728 18:24:14.226527 118397 sgd_solver.cpp:106] Iteration 2850, lr = 0.01
I0728 18:24:44.737634 118397 solver.cpp:236] Iteration 2860, loss = 0.599571
I0728 18:24:44.737798 118397 solver.cpp:252]     Train net output #0: loss = 0.703112 (* 1 = 0.703112 loss)
I0728 18:24:44.737817 118397 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0728 18:25:43.640667 118397 solver.cpp:236] Iteration 2870, loss = 0.606862
I0728 18:25:43.640938 118397 solver.cpp:252]     Train net output #0: loss = 0.641107 (* 1 = 0.641107 loss)
I0728 18:25:43.640957 118397 sgd_solver.cpp:106] Iteration 2870, lr = 0.01
I0728 18:26:33.763748 118397 solver.cpp:236] Iteration 2880, loss = 0.603171
I0728 18:26:33.763962 118397 solver.cpp:252]     Train net output #0: loss = 0.30582 (* 1 = 0.30582 loss)
I0728 18:26:33.763979 118397 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0728 18:28:23.940248 118397 solver.cpp:236] Iteration 2890, loss = 0.603574
I0728 18:28:23.940397 118397 solver.cpp:252]     Train net output #0: loss = 0.310482 (* 1 = 0.310482 loss)
I0728 18:28:23.940435 118397 sgd_solver.cpp:106] Iteration 2890, lr = 0.01
I0728 18:30:39.175585 118397 solver.cpp:236] Iteration 2900, loss = 0.602502
I0728 18:30:39.175760 118397 solver.cpp:252]     Train net output #0: loss = 0.640701 (* 1 = 0.640701 loss)
I0728 18:30:39.175779 118397 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0728 18:32:37.229547 118397 solver.cpp:236] Iteration 2910, loss = 0.605803
I0728 18:32:37.229727 118397 solver.cpp:252]     Train net output #0: loss = 0.650193 (* 1 = 0.650193 loss)
I0728 18:32:37.229745 118397 sgd_solver.cpp:106] Iteration 2910, lr = 0.01
I0728 18:35:18.255729 118397 solver.cpp:236] Iteration 2920, loss = 0.611258
I0728 18:35:18.256024 118397 solver.cpp:252]     Train net output #0: loss = 0.64544 (* 1 = 0.64544 loss)
I0728 18:35:18.256093 118397 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0728 18:37:56.378854 118397 solver.cpp:236] Iteration 2930, loss = 0.609115
I0728 18:37:56.379060 118397 solver.cpp:252]     Train net output #0: loss = 0.706879 (* 1 = 0.706879 loss)
I0728 18:37:56.379083 118397 sgd_solver.cpp:106] Iteration 2930, lr = 0.01
I0728 18:41:28.705152 118397 solver.cpp:236] Iteration 2940, loss = 0.613267
I0728 18:41:29.321746 118397 solver.cpp:252]     Train net output #0: loss = 0.677832 (* 1 = 0.677832 loss)
I0728 18:41:29.321789 118397 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0728 18:44:26.234462 118397 solver.cpp:236] Iteration 2950, loss = 0.614457
I0728 18:44:26.234588 118397 solver.cpp:252]     Train net output #0: loss = 0.663046 (* 1 = 0.663046 loss)
I0728 18:44:26.234607 118397 sgd_solver.cpp:106] Iteration 2950, lr = 0.01
I0728 18:47:48.232977 118397 solver.cpp:236] Iteration 2960, loss = 0.616975
I0728 18:47:48.233204 118397 solver.cpp:252]     Train net output #0: loss = 0.688484 (* 1 = 0.688484 loss)
I0728 18:47:48.233224 118397 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0728 18:48:31.739308 118397 solver.cpp:236] Iteration 2970, loss = 0.611419
I0728 18:48:31.739522 118397 solver.cpp:252]     Train net output #0: loss = 0.669657 (* 1 = 0.669657 loss)
I0728 18:48:31.739542 118397 sgd_solver.cpp:106] Iteration 2970, lr = 0.01
I0728 18:49:02.397496 118397 solver.cpp:236] Iteration 2980, loss = 0.61804
I0728 18:49:02.397723 118397 solver.cpp:252]     Train net output #0: loss = 0.647806 (* 1 = 0.647806 loss)
I0728 18:49:02.397740 118397 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0728 18:49:30.325604 118397 solver.cpp:236] Iteration 2990, loss = 0.616331
I0728 18:49:30.325672 118397 solver.cpp:252]     Train net output #0: loss = 0.643011 (* 1 = 0.643011 loss)
I0728 18:49:30.325687 118397 sgd_solver.cpp:106] Iteration 2990, lr = 0.01
I0728 18:49:56.083750 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_3000.caffemodel
I0728 18:49:56.178719 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_3000.solverstate
I0728 18:49:56.182337 118397 solver.cpp:340] Iteration 3000, Testing net (#0)
I0728 18:50:27.750150 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 18:50:27.750344 118397 solver.cpp:408]     Test net output #1: loss = 0.649329 (* 1 = 0.649329 loss)
I0728 18:50:30.076073 118397 solver.cpp:236] Iteration 3000, loss = 0.617268
I0728 18:50:30.076134 118397 solver.cpp:252]     Train net output #0: loss = 0.655456 (* 1 = 0.655456 loss)
I0728 18:50:30.076153 118397 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0728 18:50:58.520623 118397 solver.cpp:236] Iteration 3010, loss = 0.616996
I0728 18:50:58.520890 118397 solver.cpp:252]     Train net output #0: loss = 0.637818 (* 1 = 0.637818 loss)
I0728 18:50:58.520912 118397 sgd_solver.cpp:106] Iteration 3010, lr = 0.01
I0728 18:51:22.539433 118397 solver.cpp:236] Iteration 3020, loss = 0.607581
I0728 18:51:22.539516 118397 solver.cpp:252]     Train net output #0: loss = 0.669598 (* 1 = 0.669598 loss)
I0728 18:51:22.539530 118397 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0728 18:51:54.712996 118397 solver.cpp:236] Iteration 3030, loss = 0.619326
I0728 18:51:54.713183 118397 solver.cpp:252]     Train net output #0: loss = 0.631558 (* 1 = 0.631558 loss)
I0728 18:51:54.713202 118397 sgd_solver.cpp:106] Iteration 3030, lr = 0.01
I0728 18:52:19.174191 118397 solver.cpp:236] Iteration 3040, loss = 0.610749
I0728 18:52:19.174262 118397 solver.cpp:252]     Train net output #0: loss = 0.659523 (* 1 = 0.659523 loss)
I0728 18:52:19.174278 118397 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0728 18:52:47.285956 118397 solver.cpp:236] Iteration 3050, loss = 0.608297
I0728 18:52:47.286099 118397 solver.cpp:252]     Train net output #0: loss = 0.438522 (* 1 = 0.438522 loss)
I0728 18:52:47.286119 118397 sgd_solver.cpp:106] Iteration 3050, lr = 0.01
I0728 18:53:13.942586 118397 solver.cpp:236] Iteration 3060, loss = 0.605156
I0728 18:53:13.942674 118397 solver.cpp:252]     Train net output #0: loss = 0.685868 (* 1 = 0.685868 loss)
I0728 18:53:13.942694 118397 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0728 18:53:42.004050 118397 solver.cpp:236] Iteration 3070, loss = 0.605348
I0728 18:53:42.004197 118397 solver.cpp:252]     Train net output #0: loss = 0.664839 (* 1 = 0.664839 loss)
I0728 18:53:42.004215 118397 sgd_solver.cpp:106] Iteration 3070, lr = 0.01
I0728 18:54:08.490885 118397 solver.cpp:236] Iteration 3080, loss = 0.605265
I0728 18:54:08.490952 118397 solver.cpp:252]     Train net output #0: loss = 0.65431 (* 1 = 0.65431 loss)
I0728 18:54:08.490968 118397 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0728 18:54:39.688074 118397 solver.cpp:236] Iteration 3090, loss = 0.605795
I0728 18:54:39.688314 118397 solver.cpp:252]     Train net output #0: loss = 0.659009 (* 1 = 0.659009 loss)
I0728 18:54:39.688335 118397 sgd_solver.cpp:106] Iteration 3090, lr = 0.01
I0728 18:55:16.164309 118397 solver.cpp:236] Iteration 3100, loss = 0.605757
I0728 18:55:16.164465 118397 solver.cpp:252]     Train net output #0: loss = 0.634893 (* 1 = 0.634893 loss)
I0728 18:55:16.164482 118397 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0728 18:55:45.685956 118397 solver.cpp:236] Iteration 3110, loss = 0.606672
I0728 18:55:45.686044 118397 solver.cpp:252]     Train net output #0: loss = 0.661523 (* 1 = 0.661523 loss)
I0728 18:55:45.686064 118397 sgd_solver.cpp:106] Iteration 3110, lr = 0.01
I0728 18:56:17.976372 118397 solver.cpp:236] Iteration 3120, loss = 0.610822
I0728 18:56:17.976634 118397 solver.cpp:252]     Train net output #0: loss = 0.378654 (* 1 = 0.378654 loss)
I0728 18:56:17.976649 118397 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0728 18:56:46.094524 118397 solver.cpp:236] Iteration 3130, loss = 0.608511
I0728 18:56:46.094600 118397 solver.cpp:252]     Train net output #0: loss = 0.653202 (* 1 = 0.653202 loss)
I0728 18:56:46.094615 118397 sgd_solver.cpp:106] Iteration 3130, lr = 0.01
I0728 18:57:12.886256 118397 solver.cpp:236] Iteration 3140, loss = 0.604219
I0728 18:57:12.886432 118397 solver.cpp:252]     Train net output #0: loss = 0.644172 (* 1 = 0.644172 loss)
I0728 18:57:12.886466 118397 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0728 18:57:39.297418 118397 solver.cpp:236] Iteration 3150, loss = 0.603103
I0728 18:57:39.297497 118397 solver.cpp:252]     Train net output #0: loss = 0.652305 (* 1 = 0.652305 loss)
I0728 18:57:39.297523 118397 sgd_solver.cpp:106] Iteration 3150, lr = 0.01
I0728 18:58:05.074266 118397 solver.cpp:236] Iteration 3160, loss = 0.608129
I0728 18:58:05.078210 118397 solver.cpp:252]     Train net output #0: loss = 0.63315 (* 1 = 0.63315 loss)
I0728 18:58:05.078238 118397 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0728 18:58:39.420058 118397 solver.cpp:236] Iteration 3170, loss = 0.609356
I0728 18:58:39.420215 118397 solver.cpp:252]     Train net output #0: loss = 0.63339 (* 1 = 0.63339 loss)
I0728 18:58:39.420243 118397 sgd_solver.cpp:106] Iteration 3170, lr = 0.01
I0728 18:59:09.430951 118397 solver.cpp:236] Iteration 3180, loss = 0.606246
I0728 18:59:09.431123 118397 solver.cpp:252]     Train net output #0: loss = 0.639762 (* 1 = 0.639762 loss)
I0728 18:59:09.431139 118397 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0728 18:59:34.763155 118397 solver.cpp:236] Iteration 3190, loss = 0.598112
I0728 18:59:34.763229 118397 solver.cpp:252]     Train net output #0: loss = 0.666536 (* 1 = 0.666536 loss)
I0728 18:59:34.763248 118397 sgd_solver.cpp:106] Iteration 3190, lr = 0.01
I0728 19:00:01.619354 118397 solver.cpp:236] Iteration 3200, loss = 0.598294
I0728 19:00:01.619592 118397 solver.cpp:252]     Train net output #0: loss = 0.645553 (* 1 = 0.645553 loss)
I0728 19:00:01.619612 118397 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0728 19:00:27.084750 118397 solver.cpp:236] Iteration 3210, loss = 0.595116
I0728 19:00:27.084822 118397 solver.cpp:252]     Train net output #0: loss = 0.650318 (* 1 = 0.650318 loss)
I0728 19:00:27.084839 118397 sgd_solver.cpp:106] Iteration 3210, lr = 0.01
I0728 19:00:52.367926 118397 solver.cpp:236] Iteration 3220, loss = 0.601738
I0728 19:00:52.368079 118397 solver.cpp:252]     Train net output #0: loss = 0.638896 (* 1 = 0.638896 loss)
I0728 19:00:52.368095 118397 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0728 19:01:21.403085 118397 solver.cpp:236] Iteration 3230, loss = 0.60172
I0728 19:01:21.403146 118397 solver.cpp:252]     Train net output #0: loss = 0.627185 (* 1 = 0.627185 loss)
I0728 19:01:21.403161 118397 sgd_solver.cpp:106] Iteration 3230, lr = 0.01
I0728 19:01:48.951156 118397 solver.cpp:236] Iteration 3240, loss = 0.608651
I0728 19:01:48.951326 118397 solver.cpp:252]     Train net output #0: loss = 0.658904 (* 1 = 0.658904 loss)
I0728 19:01:48.951349 118397 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0728 19:02:14.595114 118397 solver.cpp:236] Iteration 3250, loss = 0.601941
I0728 19:02:14.595177 118397 solver.cpp:252]     Train net output #0: loss = 0.641085 (* 1 = 0.641085 loss)
I0728 19:02:14.595192 118397 sgd_solver.cpp:106] Iteration 3250, lr = 0.01
I0728 19:02:43.537084 118397 solver.cpp:236] Iteration 3260, loss = 0.600063
I0728 19:02:43.537235 118397 solver.cpp:252]     Train net output #0: loss = 0.648098 (* 1 = 0.648098 loss)
I0728 19:02:43.537252 118397 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0728 19:03:12.058053 118397 solver.cpp:236] Iteration 3270, loss = 0.60032
I0728 19:03:12.058145 118397 solver.cpp:252]     Train net output #0: loss = 0.641336 (* 1 = 0.641336 loss)
I0728 19:03:12.058163 118397 sgd_solver.cpp:106] Iteration 3270, lr = 0.01
I0728 19:03:40.765525 118397 solver.cpp:236] Iteration 3280, loss = 0.60045
I0728 19:03:40.765733 118397 solver.cpp:252]     Train net output #0: loss = 0.636839 (* 1 = 0.636839 loss)
I0728 19:03:40.765753 118397 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0728 19:04:09.499115 118397 solver.cpp:236] Iteration 3290, loss = 0.608647
I0728 19:04:09.499183 118397 solver.cpp:252]     Train net output #0: loss = 0.646626 (* 1 = 0.646626 loss)
I0728 19:04:09.499198 118397 sgd_solver.cpp:106] Iteration 3290, lr = 0.01
I0728 19:04:39.488317 118397 solver.cpp:236] Iteration 3300, loss = 0.610298
I0728 19:04:39.488498 118397 solver.cpp:252]     Train net output #0: loss = 0.640857 (* 1 = 0.640857 loss)
I0728 19:04:39.488514 118397 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0728 19:05:08.595237 118397 solver.cpp:236] Iteration 3310, loss = 0.613619
I0728 19:05:08.595310 118397 solver.cpp:252]     Train net output #0: loss = 0.669309 (* 1 = 0.669309 loss)
I0728 19:05:08.595327 118397 sgd_solver.cpp:106] Iteration 3310, lr = 0.01
I0728 19:05:37.370751 118397 solver.cpp:236] Iteration 3320, loss = 0.60933
I0728 19:05:37.370925 118397 solver.cpp:252]     Train net output #0: loss = 0.639416 (* 1 = 0.639416 loss)
I0728 19:05:37.370954 118397 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0728 19:06:08.315899 118397 solver.cpp:236] Iteration 3330, loss = 0.610641
I0728 19:06:08.316143 118397 solver.cpp:252]     Train net output #0: loss = 0.635103 (* 1 = 0.635103 loss)
I0728 19:06:08.316164 118397 sgd_solver.cpp:106] Iteration 3330, lr = 0.01
I0728 19:06:42.988066 118397 solver.cpp:236] Iteration 3340, loss = 0.609363
I0728 19:06:42.988251 118397 solver.cpp:252]     Train net output #0: loss = 0.643311 (* 1 = 0.643311 loss)
I0728 19:06:42.988268 118397 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0728 19:07:08.658144 118397 solver.cpp:236] Iteration 3350, loss = 0.615837
I0728 19:07:08.658224 118397 solver.cpp:252]     Train net output #0: loss = 0.635943 (* 1 = 0.635943 loss)
I0728 19:07:08.658241 118397 sgd_solver.cpp:106] Iteration 3350, lr = 0.01
I0728 19:07:35.239323 118397 solver.cpp:236] Iteration 3360, loss = 0.616049
I0728 19:07:35.239550 118397 solver.cpp:252]     Train net output #0: loss = 0.649834 (* 1 = 0.649834 loss)
I0728 19:07:35.239572 118397 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0728 19:08:08.261026 118397 solver.cpp:236] Iteration 3370, loss = 0.618376
I0728 19:08:08.261193 118397 solver.cpp:252]     Train net output #0: loss = 0.632413 (* 1 = 0.632413 loss)
I0728 19:08:08.261211 118397 sgd_solver.cpp:106] Iteration 3370, lr = 0.01
I0728 19:08:34.669478 118397 solver.cpp:236] Iteration 3380, loss = 0.615707
I0728 19:08:34.669546 118397 solver.cpp:252]     Train net output #0: loss = 0.655821 (* 1 = 0.655821 loss)
I0728 19:08:34.669560 118397 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0728 19:09:06.752255 118397 solver.cpp:236] Iteration 3390, loss = 0.611198
I0728 19:09:06.752444 118397 solver.cpp:252]     Train net output #0: loss = 0.660397 (* 1 = 0.660397 loss)
I0728 19:09:06.752472 118397 sgd_solver.cpp:106] Iteration 3390, lr = 0.01
I0728 19:09:36.267976 118397 solver.cpp:236] Iteration 3400, loss = 0.611545
I0728 19:09:36.268046 118397 solver.cpp:252]     Train net output #0: loss = 0.639448 (* 1 = 0.639448 loss)
I0728 19:09:36.268062 118397 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0728 19:10:03.706173 118397 solver.cpp:236] Iteration 3410, loss = 0.616215
I0728 19:10:03.706323 118397 solver.cpp:252]     Train net output #0: loss = 0.636539 (* 1 = 0.636539 loss)
I0728 19:10:03.706341 118397 sgd_solver.cpp:106] Iteration 3410, lr = 0.01
I0728 19:10:30.876155 118397 solver.cpp:236] Iteration 3420, loss = 0.618523
I0728 19:10:30.876230 118397 solver.cpp:252]     Train net output #0: loss = 0.633221 (* 1 = 0.633221 loss)
I0728 19:10:30.876246 118397 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0728 19:11:02.179590 118397 solver.cpp:236] Iteration 3430, loss = 0.61846
I0728 19:11:02.179754 118397 solver.cpp:252]     Train net output #0: loss = 0.638825 (* 1 = 0.638825 loss)
I0728 19:11:02.179771 118397 sgd_solver.cpp:106] Iteration 3430, lr = 0.01
I0728 19:11:27.120070 118397 solver.cpp:236] Iteration 3440, loss = 0.618821
I0728 19:11:27.120152 118397 solver.cpp:252]     Train net output #0: loss = 0.648371 (* 1 = 0.648371 loss)
I0728 19:11:27.120167 118397 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0728 19:11:56.610003 118397 solver.cpp:236] Iteration 3450, loss = 0.61584
I0728 19:11:56.610178 118397 solver.cpp:252]     Train net output #0: loss = 0.646342 (* 1 = 0.646342 loss)
I0728 19:11:56.610195 118397 sgd_solver.cpp:106] Iteration 3450, lr = 0.01
I0728 19:12:25.596812 118397 solver.cpp:236] Iteration 3460, loss = 0.610979
I0728 19:12:25.596886 118397 solver.cpp:252]     Train net output #0: loss = 0.23684 (* 1 = 0.23684 loss)
I0728 19:12:25.596910 118397 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0728 19:12:53.489259 118397 solver.cpp:236] Iteration 3470, loss = 0.612069
I0728 19:12:53.489387 118397 solver.cpp:252]     Train net output #0: loss = 0.63767 (* 1 = 0.63767 loss)
I0728 19:12:53.489403 118397 sgd_solver.cpp:106] Iteration 3470, lr = 0.01
I0728 19:13:25.888298 118397 solver.cpp:236] Iteration 3480, loss = 0.61726
I0728 19:13:25.888473 118397 solver.cpp:252]     Train net output #0: loss = 0.638275 (* 1 = 0.638275 loss)
I0728 19:13:25.888490 118397 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0728 19:13:53.269079 118397 solver.cpp:236] Iteration 3490, loss = 0.622648
I0728 19:13:53.269148 118397 solver.cpp:252]     Train net output #0: loss = 0.633172 (* 1 = 0.633172 loss)
I0728 19:13:53.269165 118397 sgd_solver.cpp:106] Iteration 3490, lr = 0.01
I0728 19:14:17.931182 118397 solver.cpp:340] Iteration 3500, Testing net (#0)
I0728 19:14:48.012365 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 19:14:48.012536 118397 solver.cpp:408]     Test net output #1: loss = 0.691974 (* 1 = 0.691974 loss)
I0728 19:14:52.166226 118397 solver.cpp:236] Iteration 3500, loss = 0.615094
I0728 19:14:52.166309 118397 solver.cpp:252]     Train net output #0: loss = 0.699458 (* 1 = 0.699458 loss)
I0728 19:14:52.166328 118397 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0728 19:15:22.275954 118397 solver.cpp:236] Iteration 3510, loss = 0.616899
I0728 19:15:22.276124 118397 solver.cpp:252]     Train net output #0: loss = 0.641401 (* 1 = 0.641401 loss)
I0728 19:15:22.276145 118397 sgd_solver.cpp:106] Iteration 3510, lr = 0.01
I0728 19:15:48.846344 118397 solver.cpp:236] Iteration 3520, loss = 0.617592
I0728 19:15:48.846436 118397 solver.cpp:252]     Train net output #0: loss = 0.633376 (* 1 = 0.633376 loss)
I0728 19:15:48.846460 118397 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0728 19:16:20.506552 118397 solver.cpp:236] Iteration 3530, loss = 0.615799
I0728 19:16:20.506767 118397 solver.cpp:252]     Train net output #0: loss = 0.653173 (* 1 = 0.653173 loss)
I0728 19:16:20.506790 118397 sgd_solver.cpp:106] Iteration 3530, lr = 0.01
I0728 19:16:49.945284 118397 solver.cpp:236] Iteration 3540, loss = 0.618391
I0728 19:16:49.945374 118397 solver.cpp:252]     Train net output #0: loss = 0.649792 (* 1 = 0.649792 loss)
I0728 19:16:49.945395 118397 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0728 19:17:14.863140 118397 solver.cpp:236] Iteration 3550, loss = 0.619152
I0728 19:17:14.863301 118397 solver.cpp:252]     Train net output #0: loss = 0.654538 (* 1 = 0.654538 loss)
I0728 19:17:14.863322 118397 sgd_solver.cpp:106] Iteration 3550, lr = 0.01
I0728 19:17:43.883361 118397 solver.cpp:236] Iteration 3560, loss = 0.627604
I0728 19:17:43.883450 118397 solver.cpp:252]     Train net output #0: loss = 0.652835 (* 1 = 0.652835 loss)
I0728 19:17:43.883473 118397 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0728 19:18:10.802973 118397 solver.cpp:236] Iteration 3570, loss = 0.626565
I0728 19:18:10.803130 118397 solver.cpp:252]     Train net output #0: loss = 0.636017 (* 1 = 0.636017 loss)
I0728 19:18:10.803151 118397 sgd_solver.cpp:106] Iteration 3570, lr = 0.01
I0728 19:18:38.459494 118397 solver.cpp:236] Iteration 3580, loss = 0.626249
I0728 19:18:38.459564 118397 solver.cpp:252]     Train net output #0: loss = 0.633106 (* 1 = 0.633106 loss)
I0728 19:18:38.459579 118397 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0728 19:19:02.640522 118397 solver.cpp:236] Iteration 3590, loss = 0.621346
I0728 19:19:02.640718 118397 solver.cpp:252]     Train net output #0: loss = 0.662173 (* 1 = 0.662173 loss)
I0728 19:19:02.640734 118397 sgd_solver.cpp:106] Iteration 3590, lr = 0.01
I0728 19:19:31.843178 118397 solver.cpp:236] Iteration 3600, loss = 0.629031
I0728 19:19:31.843255 118397 solver.cpp:252]     Train net output #0: loss = 0.639476 (* 1 = 0.639476 loss)
I0728 19:19:31.843277 118397 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0728 19:19:58.471741 118397 solver.cpp:236] Iteration 3610, loss = 0.619472
I0728 19:19:58.471915 118397 solver.cpp:252]     Train net output #0: loss = 0.662158 (* 1 = 0.662158 loss)
I0728 19:19:58.471932 118397 sgd_solver.cpp:106] Iteration 3610, lr = 0.01
I0728 19:20:25.103880 118397 solver.cpp:236] Iteration 3620, loss = 0.621743
I0728 19:20:25.103951 118397 solver.cpp:252]     Train net output #0: loss = 0.634421 (* 1 = 0.634421 loss)
I0728 19:20:25.103968 118397 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0728 19:20:52.184558 118397 solver.cpp:236] Iteration 3630, loss = 0.62177
I0728 19:20:52.184818 118397 solver.cpp:252]     Train net output #0: loss = 0.639732 (* 1 = 0.639732 loss)
I0728 19:20:52.184840 118397 sgd_solver.cpp:106] Iteration 3630, lr = 0.01
I0728 19:21:23.269408 118397 solver.cpp:236] Iteration 3640, loss = 0.619196
I0728 19:21:23.269569 118397 solver.cpp:252]     Train net output #0: loss = 0.650936 (* 1 = 0.650936 loss)
I0728 19:21:23.269594 118397 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0728 19:21:50.755403 118397 solver.cpp:236] Iteration 3650, loss = 0.619043
I0728 19:21:50.755503 118397 solver.cpp:252]     Train net output #0: loss = 0.637033 (* 1 = 0.637033 loss)
I0728 19:21:50.755527 118397 sgd_solver.cpp:106] Iteration 3650, lr = 0.01
I0728 19:22:19.140466 118397 solver.cpp:236] Iteration 3660, loss = 0.618564
I0728 19:22:19.140653 118397 solver.cpp:252]     Train net output #0: loss = 0.650711 (* 1 = 0.650711 loss)
I0728 19:22:19.140676 118397 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0728 19:22:40.961233 118397 solver.cpp:236] Iteration 3670, loss = 0.609289
I0728 19:22:40.961307 118397 solver.cpp:252]     Train net output #0: loss = 0.645084 (* 1 = 0.645084 loss)
I0728 19:22:40.961323 118397 sgd_solver.cpp:106] Iteration 3670, lr = 0.01
I0728 19:23:03.672376 118397 solver.cpp:236] Iteration 3680, loss = 0.606526
I0728 19:23:03.672544 118397 solver.cpp:252]     Train net output #0: loss = 0.631463 (* 1 = 0.631463 loss)
I0728 19:23:03.672567 118397 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0728 19:23:30.878574 118397 solver.cpp:236] Iteration 3690, loss = 0.611699
I0728 19:23:30.878684 118397 solver.cpp:252]     Train net output #0: loss = 0.641149 (* 1 = 0.641149 loss)
I0728 19:23:30.878702 118397 sgd_solver.cpp:106] Iteration 3690, lr = 0.01
I0728 19:23:56.637785 118397 solver.cpp:236] Iteration 3700, loss = 0.606682
I0728 19:23:56.637961 118397 solver.cpp:252]     Train net output #0: loss = 0.682705 (* 1 = 0.682705 loss)
I0728 19:23:56.637984 118397 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0728 19:24:21.184769 118397 solver.cpp:236] Iteration 3710, loss = 0.613541
I0728 19:24:21.184847 118397 solver.cpp:252]     Train net output #0: loss = 0.636264 (* 1 = 0.636264 loss)
I0728 19:24:21.184864 118397 sgd_solver.cpp:106] Iteration 3710, lr = 0.01
I0728 19:24:51.678025 118397 solver.cpp:236] Iteration 3720, loss = 0.605818
I0728 19:24:51.678171 118397 solver.cpp:252]     Train net output #0: loss = 0.345876 (* 1 = 0.345876 loss)
I0728 19:24:51.678190 118397 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0728 19:25:18.279105 118397 solver.cpp:236] Iteration 3730, loss = 0.605439
I0728 19:25:18.279186 118397 solver.cpp:252]     Train net output #0: loss = 0.650152 (* 1 = 0.650152 loss)
I0728 19:25:18.279206 118397 sgd_solver.cpp:106] Iteration 3730, lr = 0.01
I0728 19:25:46.164044 118397 solver.cpp:236] Iteration 3740, loss = 0.598614
I0728 19:25:46.164242 118397 solver.cpp:252]     Train net output #0: loss = 0.647751 (* 1 = 0.647751 loss)
I0728 19:25:46.164271 118397 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0728 19:26:13.205837 118397 solver.cpp:236] Iteration 3750, loss = 0.597678
I0728 19:26:13.205912 118397 solver.cpp:252]     Train net output #0: loss = 0.660239 (* 1 = 0.660239 loss)
I0728 19:26:13.205926 118397 sgd_solver.cpp:106] Iteration 3750, lr = 0.01
I0728 19:26:43.280064 118397 solver.cpp:236] Iteration 3760, loss = 0.59412
I0728 19:26:43.283849 118397 solver.cpp:252]     Train net output #0: loss = 0.384745 (* 1 = 0.384745 loss)
I0728 19:26:43.283870 118397 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0728 19:27:10.619294 118397 solver.cpp:236] Iteration 3770, loss = 0.600442
I0728 19:27:10.619369 118397 solver.cpp:252]     Train net output #0: loss = 0.634923 (* 1 = 0.634923 loss)
I0728 19:27:10.619385 118397 sgd_solver.cpp:106] Iteration 3770, lr = 0.01
I0728 19:27:38.922617 118397 solver.cpp:236] Iteration 3780, loss = 0.600815
I0728 19:27:38.922787 118397 solver.cpp:252]     Train net output #0: loss = 0.63146 (* 1 = 0.63146 loss)
I0728 19:27:38.922804 118397 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0728 19:28:12.645881 118397 solver.cpp:236] Iteration 3790, loss = 0.598261
I0728 19:28:12.646064 118397 solver.cpp:252]     Train net output #0: loss = 0.643641 (* 1 = 0.643641 loss)
I0728 19:28:12.646095 118397 sgd_solver.cpp:106] Iteration 3790, lr = 0.01
I0728 19:28:41.048156 118397 solver.cpp:236] Iteration 3800, loss = 0.597576
I0728 19:28:41.048240 118397 solver.cpp:252]     Train net output #0: loss = 0.639764 (* 1 = 0.639764 loss)
I0728 19:28:41.048256 118397 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0728 19:29:11.674350 118397 solver.cpp:236] Iteration 3810, loss = 0.599294
I0728 19:29:11.674499 118397 solver.cpp:252]     Train net output #0: loss = 0.637971 (* 1 = 0.637971 loss)
I0728 19:29:11.674520 118397 sgd_solver.cpp:106] Iteration 3810, lr = 0.01
I0728 19:29:36.546408 118397 solver.cpp:236] Iteration 3820, loss = 0.600458
I0728 19:29:36.546490 118397 solver.cpp:252]     Train net output #0: loss = 0.638706 (* 1 = 0.638706 loss)
I0728 19:29:36.546506 118397 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0728 19:30:09.328701 118397 solver.cpp:236] Iteration 3830, loss = 0.601558
I0728 19:30:09.328840 118397 solver.cpp:252]     Train net output #0: loss = 0.659846 (* 1 = 0.659846 loss)
I0728 19:30:09.328861 118397 sgd_solver.cpp:106] Iteration 3830, lr = 0.01
I0728 19:30:37.999969 118397 solver.cpp:236] Iteration 3840, loss = 0.610995
I0728 19:30:38.000056 118397 solver.cpp:252]     Train net output #0: loss = 0.641787 (* 1 = 0.641787 loss)
I0728 19:30:38.000072 118397 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0728 19:31:16.245671 118397 solver.cpp:236] Iteration 3850, loss = 0.616719
I0728 19:31:16.245844 118397 solver.cpp:252]     Train net output #0: loss = 0.637264 (* 1 = 0.637264 loss)
I0728 19:31:16.245862 118397 sgd_solver.cpp:106] Iteration 3850, lr = 0.01
I0728 19:31:50.950742 118397 solver.cpp:236] Iteration 3860, loss = 0.621642
I0728 19:31:50.950937 118397 solver.cpp:252]     Train net output #0: loss = 0.631474 (* 1 = 0.631474 loss)
I0728 19:31:50.950959 118397 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0728 19:32:18.422762 118397 solver.cpp:236] Iteration 3870, loss = 0.619481
I0728 19:32:18.422835 118397 solver.cpp:252]     Train net output #0: loss = 0.636533 (* 1 = 0.636533 loss)
I0728 19:32:18.422852 118397 sgd_solver.cpp:106] Iteration 3870, lr = 0.01
I0728 19:32:52.020747 118397 solver.cpp:236] Iteration 3880, loss = 0.624275
I0728 19:32:52.020908 118397 solver.cpp:252]     Train net output #0: loss = 0.651694 (* 1 = 0.651694 loss)
I0728 19:32:52.020948 118397 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0728 19:33:20.674041 118397 solver.cpp:236] Iteration 3890, loss = 0.623625
I0728 19:33:20.674115 118397 solver.cpp:252]     Train net output #0: loss = 0.638813 (* 1 = 0.638813 loss)
I0728 19:33:20.674130 118397 sgd_solver.cpp:106] Iteration 3890, lr = 0.01
I0728 19:33:43.351446 118397 solver.cpp:236] Iteration 3900, loss = 0.626776
I0728 19:33:43.351647 118397 solver.cpp:252]     Train net output #0: loss = 0.652922 (* 1 = 0.652922 loss)
I0728 19:33:43.351670 118397 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0728 19:34:08.977843 118397 solver.cpp:236] Iteration 3910, loss = 0.617042
I0728 19:34:08.977908 118397 solver.cpp:252]     Train net output #0: loss = 0.271888 (* 1 = 0.271888 loss)
I0728 19:34:08.977924 118397 sgd_solver.cpp:106] Iteration 3910, lr = 0.01
I0728 19:34:33.773250 118397 solver.cpp:236] Iteration 3920, loss = 0.618732
I0728 19:34:33.773473 118397 solver.cpp:252]     Train net output #0: loss = 0.634475 (* 1 = 0.634475 loss)
I0728 19:34:33.773499 118397 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0728 19:34:59.002693 118397 solver.cpp:236] Iteration 3930, loss = 0.614695
I0728 19:34:59.002774 118397 solver.cpp:252]     Train net output #0: loss = 0.643893 (* 1 = 0.643893 loss)
I0728 19:34:59.002792 118397 sgd_solver.cpp:106] Iteration 3930, lr = 0.01
I0728 19:35:25.050518 118397 solver.cpp:236] Iteration 3940, loss = 0.609127
I0728 19:35:25.050737 118397 solver.cpp:252]     Train net output #0: loss = 0.657117 (* 1 = 0.657117 loss)
I0728 19:35:25.050765 118397 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0728 19:35:48.337280 118397 solver.cpp:236] Iteration 3950, loss = 0.609799
I0728 19:35:48.337352 118397 solver.cpp:252]     Train net output #0: loss = 0.634778 (* 1 = 0.634778 loss)
I0728 19:35:48.337368 118397 sgd_solver.cpp:106] Iteration 3950, lr = 0.01
I0728 19:36:12.784379 118397 solver.cpp:236] Iteration 3960, loss = 0.603875
I0728 19:36:12.784543 118397 solver.cpp:252]     Train net output #0: loss = 0.680773 (* 1 = 0.680773 loss)
I0728 19:36:12.784579 118397 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0728 19:36:37.150182 118397 solver.cpp:236] Iteration 3970, loss = 0.612646
I0728 19:36:37.150257 118397 solver.cpp:252]     Train net output #0: loss = 0.635614 (* 1 = 0.635614 loss)
I0728 19:36:37.150274 118397 sgd_solver.cpp:106] Iteration 3970, lr = 0.01
I0728 19:37:01.493458 118397 solver.cpp:236] Iteration 3980, loss = 0.606003
I0728 19:37:01.493661 118397 solver.cpp:252]     Train net output #0: loss = 0.634947 (* 1 = 0.634947 loss)
I0728 19:37:01.493685 118397 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0728 19:37:29.846078 118397 solver.cpp:236] Iteration 3990, loss = 0.609338
I0728 19:37:29.846156 118397 solver.cpp:252]     Train net output #0: loss = 0.637781 (* 1 = 0.637781 loss)
I0728 19:37:29.846171 118397 sgd_solver.cpp:106] Iteration 3990, lr = 0.01
I0728 19:37:54.625097 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_4000.caffemodel
I0728 19:37:54.738270 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_4000.solverstate
I0728 19:37:54.742645 118397 solver.cpp:340] Iteration 4000, Testing net (#0)
I0728 19:38:19.759022 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 19:38:19.759104 118397 solver.cpp:408]     Test net output #1: loss = 0.607858 (* 1 = 0.607858 loss)
I0728 19:38:22.550283 118397 solver.cpp:236] Iteration 4000, loss = 0.608895
I0728 19:38:22.550356 118397 solver.cpp:252]     Train net output #0: loss = 0.637921 (* 1 = 0.637921 loss)
I0728 19:38:22.550377 118397 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0728 19:38:48.246074 118397 solver.cpp:236] Iteration 4010, loss = 0.612942
I0728 19:38:48.246320 118397 solver.cpp:252]     Train net output #0: loss = 0.656404 (* 1 = 0.656404 loss)
I0728 19:38:48.246342 118397 sgd_solver.cpp:106] Iteration 4010, lr = 0.01
I0728 19:39:15.743430 118397 solver.cpp:236] Iteration 4020, loss = 0.609328
I0728 19:39:15.743501 118397 solver.cpp:252]     Train net output #0: loss = 0.652783 (* 1 = 0.652783 loss)
I0728 19:39:15.743518 118397 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0728 19:39:48.276828 118397 solver.cpp:236] Iteration 4030, loss = 0.614804
I0728 19:39:48.276964 118397 solver.cpp:252]     Train net output #0: loss = 0.637218 (* 1 = 0.637218 loss)
I0728 19:39:48.276980 118397 sgd_solver.cpp:106] Iteration 4030, lr = 0.01
I0728 19:40:17.662480 118397 solver.cpp:236] Iteration 4040, loss = 0.620076
I0728 19:40:17.662546 118397 solver.cpp:252]     Train net output #0: loss = 0.636806 (* 1 = 0.636806 loss)
I0728 19:40:17.662561 118397 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0728 19:40:48.550614 118397 solver.cpp:236] Iteration 4050, loss = 0.619128
I0728 19:40:48.550830 118397 solver.cpp:252]     Train net output #0: loss = 0.634568 (* 1 = 0.634568 loss)
I0728 19:40:48.550849 118397 sgd_solver.cpp:106] Iteration 4050, lr = 0.01
I0728 19:41:17.502476 118397 solver.cpp:236] Iteration 4060, loss = 0.625038
I0728 19:41:17.502548 118397 solver.cpp:252]     Train net output #0: loss = 0.635565 (* 1 = 0.635565 loss)
I0728 19:41:17.502564 118397 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0728 19:41:42.636912 118397 solver.cpp:236] Iteration 4070, loss = 0.620743
I0728 19:41:42.637079 118397 solver.cpp:252]     Train net output #0: loss = 0.633761 (* 1 = 0.633761 loss)
I0728 19:41:42.637095 118397 sgd_solver.cpp:106] Iteration 4070, lr = 0.01
I0728 19:42:10.838546 118397 solver.cpp:236] Iteration 4080, loss = 0.624584
I0728 19:42:10.838623 118397 solver.cpp:252]     Train net output #0: loss = 0.628969 (* 1 = 0.628969 loss)
I0728 19:42:10.838656 118397 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0728 19:42:40.241139 118397 solver.cpp:236] Iteration 4090, loss = 0.620475
I0728 19:42:40.241308 118397 solver.cpp:252]     Train net output #0: loss = 0.671677 (* 1 = 0.671677 loss)
I0728 19:42:40.241327 118397 sgd_solver.cpp:106] Iteration 4090, lr = 0.01
I0728 19:43:05.537744 118397 solver.cpp:236] Iteration 4100, loss = 0.621863
I0728 19:43:05.537816 118397 solver.cpp:252]     Train net output #0: loss = 0.639499 (* 1 = 0.639499 loss)
I0728 19:43:05.537837 118397 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0728 19:43:31.792101 118397 solver.cpp:236] Iteration 4110, loss = 0.62148
I0728 19:43:31.792248 118397 solver.cpp:252]     Train net output #0: loss = 0.296883 (* 1 = 0.296883 loss)
I0728 19:43:31.792264 118397 sgd_solver.cpp:106] Iteration 4110, lr = 0.01
I0728 19:43:53.902204 118397 solver.cpp:236] Iteration 4120, loss = 0.6254
I0728 19:43:53.902257 118397 solver.cpp:252]     Train net output #0: loss = 0.638047 (* 1 = 0.638047 loss)
I0728 19:43:53.902267 118397 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0728 19:44:20.924412 118397 solver.cpp:236] Iteration 4130, loss = 0.62537
I0728 19:44:20.924643 118397 solver.cpp:252]     Train net output #0: loss = 0.642703 (* 1 = 0.642703 loss)
I0728 19:44:20.924671 118397 sgd_solver.cpp:106] Iteration 4130, lr = 0.01
I0728 19:44:51.890825 118397 solver.cpp:236] Iteration 4140, loss = 0.620346
I0728 19:44:51.890992 118397 solver.cpp:252]     Train net output #0: loss = 0.663796 (* 1 = 0.663796 loss)
I0728 19:44:51.891018 118397 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0728 19:45:17.851193 118397 solver.cpp:236] Iteration 4150, loss = 0.622021
I0728 19:45:17.851270 118397 solver.cpp:252]     Train net output #0: loss = 0.636935 (* 1 = 0.636935 loss)
I0728 19:45:17.851285 118397 sgd_solver.cpp:106] Iteration 4150, lr = 0.01
I0728 19:45:50.158417 118397 solver.cpp:236] Iteration 4160, loss = 0.622489
I0728 19:45:50.158593 118397 solver.cpp:252]     Train net output #0: loss = 0.637055 (* 1 = 0.637055 loss)
I0728 19:45:50.158615 118397 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0728 19:46:25.844703 118397 solver.cpp:236] Iteration 4170, loss = 0.620333
I0728 19:46:25.844871 118397 solver.cpp:252]     Train net output #0: loss = 0.653218 (* 1 = 0.653218 loss)
I0728 19:46:25.844898 118397 sgd_solver.cpp:106] Iteration 4170, lr = 0.01
I0728 19:46:54.291332 118397 solver.cpp:236] Iteration 4180, loss = 0.618208
I0728 19:46:54.291422 118397 solver.cpp:252]     Train net output #0: loss = 0.633683 (* 1 = 0.633683 loss)
I0728 19:46:54.291443 118397 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0728 19:47:21.646109 118397 solver.cpp:236] Iteration 4190, loss = 0.616881
I0728 19:47:21.646276 118397 solver.cpp:252]     Train net output #0: loss = 0.636206 (* 1 = 0.636206 loss)
I0728 19:47:21.646299 118397 sgd_solver.cpp:106] Iteration 4190, lr = 0.01
I0728 19:47:44.834843 118397 solver.cpp:236] Iteration 4200, loss = 0.610073
I0728 19:47:44.834908 118397 solver.cpp:252]     Train net output #0: loss = 0.717363 (* 1 = 0.717363 loss)
I0728 19:47:44.834923 118397 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0728 19:48:11.327877 118397 solver.cpp:236] Iteration 4210, loss = 0.601146
I0728 19:48:11.328057 118397 solver.cpp:252]     Train net output #0: loss = 0.66497 (* 1 = 0.66497 loss)
I0728 19:48:11.328078 118397 sgd_solver.cpp:106] Iteration 4210, lr = 0.01
I0728 19:48:37.733119 118397 solver.cpp:236] Iteration 4220, loss = 0.603379
I0728 19:48:37.733192 118397 solver.cpp:252]     Train net output #0: loss = 0.64369 (* 1 = 0.64369 loss)
I0728 19:48:37.733211 118397 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0728 19:49:06.682816 118397 solver.cpp:236] Iteration 4230, loss = 0.601421
I0728 19:49:06.683032 118397 solver.cpp:252]     Train net output #0: loss = 0.642054 (* 1 = 0.642054 loss)
I0728 19:49:06.683060 118397 sgd_solver.cpp:106] Iteration 4230, lr = 0.01
I0728 19:49:33.066849 118397 solver.cpp:236] Iteration 4240, loss = 0.6011
I0728 19:49:33.066932 118397 solver.cpp:252]     Train net output #0: loss = 0.671301 (* 1 = 0.671301 loss)
I0728 19:49:33.066947 118397 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0728 19:49:55.629544 118397 solver.cpp:236] Iteration 4250, loss = 0.600121
I0728 19:49:55.629693 118397 solver.cpp:252]     Train net output #0: loss = 0.637606 (* 1 = 0.637606 loss)
I0728 19:49:55.629710 118397 sgd_solver.cpp:106] Iteration 4250, lr = 0.01
I0728 19:50:22.394501 118397 solver.cpp:236] Iteration 4260, loss = 0.598496
I0728 19:50:22.394588 118397 solver.cpp:252]     Train net output #0: loss = 0.640157 (* 1 = 0.640157 loss)
I0728 19:50:22.394609 118397 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0728 19:50:49.632230 118397 solver.cpp:236] Iteration 4270, loss = 0.595649
I0728 19:50:49.632545 118397 solver.cpp:252]     Train net output #0: loss = 0.344849 (* 1 = 0.344849 loss)
I0728 19:50:49.632568 118397 sgd_solver.cpp:106] Iteration 4270, lr = 0.01
I0728 19:51:19.042866 118397 solver.cpp:236] Iteration 4280, loss = 0.599122
I0728 19:51:19.042953 118397 solver.cpp:252]     Train net output #0: loss = 0.639901 (* 1 = 0.639901 loss)
I0728 19:51:19.042969 118397 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0728 19:51:49.880856 118397 solver.cpp:236] Iteration 4290, loss = 0.604306
I0728 19:51:49.881041 118397 solver.cpp:252]     Train net output #0: loss = 0.638674 (* 1 = 0.638674 loss)
I0728 19:51:49.881057 118397 sgd_solver.cpp:106] Iteration 4290, lr = 0.01
I0728 19:52:14.578330 118397 solver.cpp:236] Iteration 4300, loss = 0.608887
I0728 19:52:14.578413 118397 solver.cpp:252]     Train net output #0: loss = 0.684991 (* 1 = 0.684991 loss)
I0728 19:52:14.578438 118397 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0728 19:52:44.297065 118397 solver.cpp:236] Iteration 4310, loss = 0.623752
I0728 19:52:44.297221 118397 solver.cpp:252]     Train net output #0: loss = 0.639684 (* 1 = 0.639684 loss)
I0728 19:52:44.297248 118397 sgd_solver.cpp:106] Iteration 4310, lr = 0.01
I0728 19:53:09.948622 118397 solver.cpp:236] Iteration 4320, loss = 0.619844
I0728 19:53:09.948698 118397 solver.cpp:252]     Train net output #0: loss = 0.653148 (* 1 = 0.653148 loss)
I0728 19:53:09.948711 118397 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0728 19:53:35.952988 118397 solver.cpp:236] Iteration 4330, loss = 0.612576
I0728 19:53:35.953194 118397 solver.cpp:252]     Train net output #0: loss = 0.675175 (* 1 = 0.675175 loss)
I0728 19:53:35.953224 118397 sgd_solver.cpp:106] Iteration 4330, lr = 0.01
I0728 19:54:00.041084 118397 solver.cpp:236] Iteration 4340, loss = 0.608708
I0728 19:54:00.041158 118397 solver.cpp:252]     Train net output #0: loss = 0.294603 (* 1 = 0.294603 loss)
I0728 19:54:00.041182 118397 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0728 19:54:24.908711 118397 solver.cpp:236] Iteration 4350, loss = 0.605833
I0728 19:54:24.908859 118397 solver.cpp:252]     Train net output #0: loss = 0.642048 (* 1 = 0.642048 loss)
I0728 19:54:24.908876 118397 sgd_solver.cpp:106] Iteration 4350, lr = 0.01
I0728 19:54:49.810727 118397 solver.cpp:236] Iteration 4360, loss = 0.602068
I0728 19:54:49.810807 118397 solver.cpp:252]     Train net output #0: loss = 0.652714 (* 1 = 0.652714 loss)
I0728 19:54:49.810828 118397 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0728 19:55:19.474752 118397 solver.cpp:236] Iteration 4370, loss = 0.602444
I0728 19:55:19.474953 118397 solver.cpp:252]     Train net output #0: loss = 0.665748 (* 1 = 0.665748 loss)
I0728 19:55:19.474979 118397 sgd_solver.cpp:106] Iteration 4370, lr = 0.01
I0728 19:55:45.914546 118397 solver.cpp:236] Iteration 4380, loss = 0.595157
I0728 19:55:45.914621 118397 solver.cpp:252]     Train net output #0: loss = 0.368095 (* 1 = 0.368095 loss)
I0728 19:55:45.914654 118397 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0728 19:56:12.330873 118397 solver.cpp:236] Iteration 4390, loss = 0.591587
I0728 19:56:12.333680 118397 solver.cpp:252]     Train net output #0: loss = 0.684974 (* 1 = 0.684974 loss)
I0728 19:56:12.333716 118397 sgd_solver.cpp:106] Iteration 4390, lr = 0.01
I0728 19:56:41.504670 118397 solver.cpp:236] Iteration 4400, loss = 0.595756
I0728 19:56:41.504750 118397 solver.cpp:252]     Train net output #0: loss = 0.641931 (* 1 = 0.641931 loss)
I0728 19:56:41.504771 118397 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0728 19:57:11.514052 118397 solver.cpp:236] Iteration 4410, loss = 0.593951
I0728 19:57:11.514200 118397 solver.cpp:252]     Train net output #0: loss = 0.641618 (* 1 = 0.641618 loss)
I0728 19:57:11.514228 118397 sgd_solver.cpp:106] Iteration 4410, lr = 0.01
I0728 19:57:34.552711 118397 solver.cpp:236] Iteration 4420, loss = 0.589373
I0728 19:57:34.552785 118397 solver.cpp:252]     Train net output #0: loss = 0.708511 (* 1 = 0.708511 loss)
I0728 19:57:34.552801 118397 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0728 19:57:59.237260 118397 solver.cpp:236] Iteration 4430, loss = 0.589082
I0728 19:57:59.237454 118397 solver.cpp:252]     Train net output #0: loss = 0.663314 (* 1 = 0.663314 loss)
I0728 19:57:59.237495 118397 sgd_solver.cpp:106] Iteration 4430, lr = 0.01
I0728 19:58:25.414705 118397 solver.cpp:236] Iteration 4440, loss = 0.593536
I0728 19:58:25.414795 118397 solver.cpp:252]     Train net output #0: loss = 0.401447 (* 1 = 0.401447 loss)
I0728 19:58:25.414810 118397 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0728 19:58:50.069344 118397 solver.cpp:236] Iteration 4450, loss = 0.59305
I0728 19:58:50.069483 118397 solver.cpp:252]     Train net output #0: loss = 0.642051 (* 1 = 0.642051 loss)
I0728 19:58:50.069504 118397 sgd_solver.cpp:106] Iteration 4450, lr = 0.01
I0728 19:59:15.388062 118397 solver.cpp:236] Iteration 4460, loss = 0.59256
I0728 19:59:15.388149 118397 solver.cpp:252]     Train net output #0: loss = 0.654238 (* 1 = 0.654238 loss)
I0728 19:59:15.388167 118397 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0728 19:59:42.430995 118397 solver.cpp:236] Iteration 4470, loss = 0.59801
I0728 19:59:42.431193 118397 solver.cpp:252]     Train net output #0: loss = 0.639388 (* 1 = 0.639388 loss)
I0728 19:59:42.431211 118397 sgd_solver.cpp:106] Iteration 4470, lr = 0.01
I0728 20:00:09.139232 118397 solver.cpp:236] Iteration 4480, loss = 0.602063
I0728 20:00:09.139312 118397 solver.cpp:252]     Train net output #0: loss = 0.671192 (* 1 = 0.671192 loss)
I0728 20:00:09.139330 118397 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0728 20:00:35.159085 118397 solver.cpp:236] Iteration 4490, loss = 0.600107
I0728 20:00:35.159319 118397 solver.cpp:252]     Train net output #0: loss = 0.646107 (* 1 = 0.646107 loss)
I0728 20:00:35.159337 118397 sgd_solver.cpp:106] Iteration 4490, lr = 0.01
I0728 20:00:57.823390 118397 solver.cpp:340] Iteration 4500, Testing net (#0)
I0728 20:01:29.107286 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 20:01:29.107483 118397 solver.cpp:408]     Test net output #1: loss = 0.633944 (* 1 = 0.633944 loss)
I0728 20:01:32.609050 118397 solver.cpp:236] Iteration 4500, loss = 0.59712
I0728 20:01:32.609130 118397 solver.cpp:252]     Train net output #0: loss = 0.636285 (* 1 = 0.636285 loss)
I0728 20:01:32.609150 118397 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0728 20:01:58.979063 118397 solver.cpp:236] Iteration 4510, loss = 0.588767
I0728 20:01:58.979140 118397 solver.cpp:252]     Train net output #0: loss = 0.282163 (* 1 = 0.282163 loss)
I0728 20:01:58.979156 118397 sgd_solver.cpp:106] Iteration 4510, lr = 0.01
I0728 20:02:29.386503 118397 solver.cpp:236] Iteration 4520, loss = 0.588533
I0728 20:02:29.386715 118397 solver.cpp:252]     Train net output #0: loss = 0.739161 (* 1 = 0.739161 loss)
I0728 20:02:29.386749 118397 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0728 20:02:58.818495 118397 solver.cpp:236] Iteration 4530, loss = 0.600585
I0728 20:02:58.818572 118397 solver.cpp:252]     Train net output #0: loss = 0.650481 (* 1 = 0.650481 loss)
I0728 20:02:58.818588 118397 sgd_solver.cpp:106] Iteration 4530, lr = 0.01
I0728 20:03:26.726153 118397 solver.cpp:236] Iteration 4540, loss = 0.606832
I0728 20:03:26.726353 118397 solver.cpp:252]     Train net output #0: loss = 0.637832 (* 1 = 0.637832 loss)
I0728 20:03:26.726372 118397 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0728 20:03:56.101954 118397 solver.cpp:236] Iteration 4550, loss = 0.60534
I0728 20:03:56.102043 118397 solver.cpp:252]     Train net output #0: loss = 0.680093 (* 1 = 0.680093 loss)
I0728 20:03:56.102059 118397 sgd_solver.cpp:106] Iteration 4550, lr = 0.01
I0728 20:04:23.127348 118397 solver.cpp:236] Iteration 4560, loss = 0.609004
I0728 20:04:23.127516 118397 solver.cpp:252]     Train net output #0: loss = 0.636817 (* 1 = 0.636817 loss)
I0728 20:04:23.127533 118397 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0728 20:04:51.569893 118397 solver.cpp:236] Iteration 4570, loss = 0.60639
I0728 20:04:51.569965 118397 solver.cpp:252]     Train net output #0: loss = 0.640171 (* 1 = 0.640171 loss)
I0728 20:04:51.569986 118397 sgd_solver.cpp:106] Iteration 4570, lr = 0.01
I0728 20:05:24.946277 118397 solver.cpp:236] Iteration 4580, loss = 0.60294
I0728 20:05:24.946446 118397 solver.cpp:252]     Train net output #0: loss = 0.647808 (* 1 = 0.647808 loss)
I0728 20:05:24.946475 118397 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0728 20:05:50.128396 118397 solver.cpp:236] Iteration 4590, loss = 0.606808
I0728 20:05:50.128490 118397 solver.cpp:252]     Train net output #0: loss = 0.643152 (* 1 = 0.643152 loss)
I0728 20:05:50.128505 118397 sgd_solver.cpp:106] Iteration 4590, lr = 0.01
I0728 20:06:19.221112 118397 solver.cpp:236] Iteration 4600, loss = 0.609117
I0728 20:06:19.221288 118397 solver.cpp:252]     Train net output #0: loss = 0.640704 (* 1 = 0.640704 loss)
I0728 20:06:19.221315 118397 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0728 20:06:46.360467 118397 solver.cpp:236] Iteration 4610, loss = 0.618294
I0728 20:06:46.360535 118397 solver.cpp:252]     Train net output #0: loss = 0.642919 (* 1 = 0.642919 loss)
I0728 20:06:46.360550 118397 sgd_solver.cpp:106] Iteration 4610, lr = 0.01
I0728 20:07:11.311645 118397 solver.cpp:236] Iteration 4620, loss = 0.626246
I0728 20:07:11.311799 118397 solver.cpp:252]     Train net output #0: loss = 0.63023 (* 1 = 0.63023 loss)
I0728 20:07:11.311811 118397 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0728 20:07:38.348650 118397 solver.cpp:236] Iteration 4630, loss = 0.621237
I0728 20:07:38.348716 118397 solver.cpp:252]     Train net output #0: loss = 0.63818 (* 1 = 0.63818 loss)
I0728 20:07:38.348731 118397 sgd_solver.cpp:106] Iteration 4630, lr = 0.01
I0728 20:07:59.837124 118397 solver.cpp:236] Iteration 4640, loss = 0.61719
I0728 20:07:59.837286 118397 solver.cpp:252]     Train net output #0: loss = 0.641755 (* 1 = 0.641755 loss)
I0728 20:07:59.837303 118397 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0728 20:08:32.552557 118397 solver.cpp:236] Iteration 4650, loss = 0.619006
I0728 20:08:32.552737 118397 solver.cpp:252]     Train net output #0: loss = 0.638176 (* 1 = 0.638176 loss)
I0728 20:08:32.552764 118397 sgd_solver.cpp:106] Iteration 4650, lr = 0.01
I0728 20:08:56.976043 118397 solver.cpp:236] Iteration 4660, loss = 0.612369
I0728 20:08:56.976119 118397 solver.cpp:252]     Train net output #0: loss = 0.264536 (* 1 = 0.264536 loss)
I0728 20:08:56.976135 118397 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0728 20:09:22.078503 118397 solver.cpp:236] Iteration 4670, loss = 0.615499
I0728 20:09:22.078668 118397 solver.cpp:252]     Train net output #0: loss = 0.634111 (* 1 = 0.634111 loss)
I0728 20:09:22.078686 118397 sgd_solver.cpp:106] Iteration 4670, lr = 0.01
I0728 20:09:50.515933 118397 solver.cpp:236] Iteration 4680, loss = 0.616712
I0728 20:09:50.516024 118397 solver.cpp:252]     Train net output #0: loss = 0.337184 (* 1 = 0.337184 loss)
I0728 20:09:50.516041 118397 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0728 20:10:19.237179 118397 solver.cpp:236] Iteration 4690, loss = 0.614674
I0728 20:10:19.237395 118397 solver.cpp:252]     Train net output #0: loss = 0.701941 (* 1 = 0.701941 loss)
I0728 20:10:19.237411 118397 sgd_solver.cpp:106] Iteration 4690, lr = 0.01
I0728 20:10:44.298902 118397 solver.cpp:236] Iteration 4700, loss = 0.615837
I0728 20:10:44.298996 118397 solver.cpp:252]     Train net output #0: loss = 0.646264 (* 1 = 0.646264 loss)
I0728 20:10:44.299017 118397 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0728 20:11:13.264518 118397 solver.cpp:236] Iteration 4710, loss = 0.615645
I0728 20:11:13.264731 118397 solver.cpp:252]     Train net output #0: loss = 0.64573 (* 1 = 0.64573 loss)
I0728 20:11:13.264751 118397 sgd_solver.cpp:106] Iteration 4710, lr = 0.01
I0728 20:11:39.483223 118397 solver.cpp:236] Iteration 4720, loss = 0.616495
I0728 20:11:39.483324 118397 solver.cpp:252]     Train net output #0: loss = 0.639167 (* 1 = 0.639167 loss)
I0728 20:11:39.483346 118397 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0728 20:12:05.142627 118397 solver.cpp:236] Iteration 4730, loss = 0.616066
I0728 20:12:05.142834 118397 solver.cpp:252]     Train net output #0: loss = 0.637028 (* 1 = 0.637028 loss)
I0728 20:12:05.142875 118397 sgd_solver.cpp:106] Iteration 4730, lr = 0.01
I0728 20:12:31.516023 118397 solver.cpp:236] Iteration 4740, loss = 0.613643
I0728 20:12:31.516109 118397 solver.cpp:252]     Train net output #0: loss = 0.659314 (* 1 = 0.659314 loss)
I0728 20:12:31.516131 118397 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0728 20:13:00.104151 118397 solver.cpp:236] Iteration 4750, loss = 0.616586
I0728 20:13:00.104282 118397 solver.cpp:252]     Train net output #0: loss = 0.639719 (* 1 = 0.639719 loss)
I0728 20:13:00.104298 118397 sgd_solver.cpp:106] Iteration 4750, lr = 0.01
I0728 20:13:25.022294 118397 solver.cpp:236] Iteration 4760, loss = 0.621089
I0728 20:13:25.022364 118397 solver.cpp:252]     Train net output #0: loss = 0.654783 (* 1 = 0.654783 loss)
I0728 20:13:25.022382 118397 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0728 20:13:50.746007 118397 solver.cpp:236] Iteration 4770, loss = 0.618626
I0728 20:13:50.746173 118397 solver.cpp:252]     Train net output #0: loss = 0.63784 (* 1 = 0.63784 loss)
I0728 20:13:50.746201 118397 sgd_solver.cpp:106] Iteration 4770, lr = 0.01
I0728 20:14:16.544497 118397 solver.cpp:236] Iteration 4780, loss = 0.614776
I0728 20:14:16.544572 118397 solver.cpp:252]     Train net output #0: loss = 0.643307 (* 1 = 0.643307 loss)
I0728 20:14:16.544595 118397 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0728 20:14:44.905200 118397 solver.cpp:236] Iteration 4790, loss = 0.616379
I0728 20:14:44.905369 118397 solver.cpp:252]     Train net output #0: loss = 0.648859 (* 1 = 0.648859 loss)
I0728 20:14:44.905386 118397 sgd_solver.cpp:106] Iteration 4790, lr = 0.01
I0728 20:15:15.472296 118397 solver.cpp:236] Iteration 4800, loss = 0.612108
I0728 20:15:15.472509 118397 solver.cpp:252]     Train net output #0: loss = 0.635218 (* 1 = 0.635218 loss)
I0728 20:15:15.472533 118397 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0728 20:15:43.230021 118397 solver.cpp:236] Iteration 4810, loss = 0.603996
I0728 20:15:43.230095 118397 solver.cpp:252]     Train net output #0: loss = 0.30147 (* 1 = 0.30147 loss)
I0728 20:15:43.230111 118397 sgd_solver.cpp:106] Iteration 4810, lr = 0.01
I0728 20:16:14.377035 118397 solver.cpp:236] Iteration 4820, loss = 0.605586
I0728 20:16:14.377279 118397 solver.cpp:252]     Train net output #0: loss = 0.638851 (* 1 = 0.638851 loss)
I0728 20:16:14.377306 118397 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0728 20:16:43.085644 118397 solver.cpp:236] Iteration 4830, loss = 0.605593
I0728 20:16:43.085718 118397 solver.cpp:252]     Train net output #0: loss = 0.638415 (* 1 = 0.638415 loss)
I0728 20:16:43.085737 118397 sgd_solver.cpp:106] Iteration 4830, lr = 0.01
I0728 20:17:11.112890 118397 solver.cpp:236] Iteration 4840, loss = 0.605647
I0728 20:17:11.113045 118397 solver.cpp:252]     Train net output #0: loss = 0.654612 (* 1 = 0.654612 loss)
I0728 20:17:11.113066 118397 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0728 20:17:34.943117 118397 solver.cpp:236] Iteration 4850, loss = 0.600224
I0728 20:17:34.943205 118397 solver.cpp:252]     Train net output #0: loss = 0.661858 (* 1 = 0.661858 loss)
I0728 20:17:34.943227 118397 sgd_solver.cpp:106] Iteration 4850, lr = 0.01
I0728 20:18:05.257277 118397 solver.cpp:236] Iteration 4860, loss = 0.602259
I0728 20:18:05.257431 118397 solver.cpp:252]     Train net output #0: loss = 0.64361 (* 1 = 0.64361 loss)
I0728 20:18:05.257448 118397 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0728 20:18:31.635566 118397 solver.cpp:236] Iteration 4870, loss = 0.603437
I0728 20:18:31.635654 118397 solver.cpp:252]     Train net output #0: loss = 0.638052 (* 1 = 0.638052 loss)
I0728 20:18:31.635671 118397 sgd_solver.cpp:106] Iteration 4870, lr = 0.01
I0728 20:19:01.622558 118397 solver.cpp:236] Iteration 4880, loss = 0.611695
I0728 20:19:01.622743 118397 solver.cpp:252]     Train net output #0: loss = 0.63688 (* 1 = 0.63688 loss)
I0728 20:19:01.622761 118397 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0728 20:19:30.557826 118397 solver.cpp:236] Iteration 4890, loss = 0.608542
I0728 20:19:30.557905 118397 solver.cpp:252]     Train net output #0: loss = 0.65722 (* 1 = 0.65722 loss)
I0728 20:19:30.557927 118397 sgd_solver.cpp:106] Iteration 4890, lr = 0.01
I0728 20:20:00.066133 118397 solver.cpp:236] Iteration 4900, loss = 0.611846
I0728 20:20:00.066293 118397 solver.cpp:252]     Train net output #0: loss = 0.635027 (* 1 = 0.635027 loss)
I0728 20:20:00.066313 118397 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0728 20:20:35.347551 118397 solver.cpp:236] Iteration 4910, loss = 0.620237
I0728 20:20:35.347743 118397 solver.cpp:252]     Train net output #0: loss = 0.63486 (* 1 = 0.63486 loss)
I0728 20:20:35.347765 118397 sgd_solver.cpp:106] Iteration 4910, lr = 0.01
I0728 20:21:00.593961 118397 solver.cpp:236] Iteration 4920, loss = 0.612856
I0728 20:21:00.594038 118397 solver.cpp:252]     Train net output #0: loss = 0.664908 (* 1 = 0.664908 loss)
I0728 20:21:00.594053 118397 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0728 20:21:23.028584 118397 solver.cpp:236] Iteration 4930, loss = 0.613986
I0728 20:21:23.028753 118397 solver.cpp:252]     Train net output #0: loss = 0.640686 (* 1 = 0.640686 loss)
I0728 20:21:23.028779 118397 sgd_solver.cpp:106] Iteration 4930, lr = 0.01
I0728 20:21:48.150261 118397 solver.cpp:236] Iteration 4940, loss = 0.614265
I0728 20:21:48.150331 118397 solver.cpp:252]     Train net output #0: loss = 0.639137 (* 1 = 0.639137 loss)
I0728 20:21:48.150346 118397 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0728 20:22:13.920454 118397 solver.cpp:236] Iteration 4950, loss = 0.614801
I0728 20:22:13.920609 118397 solver.cpp:252]     Train net output #0: loss = 0.661071 (* 1 = 0.661071 loss)
I0728 20:22:13.920627 118397 sgd_solver.cpp:106] Iteration 4950, lr = 0.01
I0728 20:22:41.268429 118397 solver.cpp:236] Iteration 4960, loss = 0.611414
I0728 20:22:41.268504 118397 solver.cpp:252]     Train net output #0: loss = 0.632976 (* 1 = 0.632976 loss)
I0728 20:22:41.268522 118397 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0728 20:23:07.351367 118397 solver.cpp:236] Iteration 4970, loss = 0.607062
I0728 20:23:07.351547 118397 solver.cpp:252]     Train net output #0: loss = 0.662673 (* 1 = 0.662673 loss)
I0728 20:23:07.351574 118397 sgd_solver.cpp:106] Iteration 4970, lr = 0.01
I0728 20:23:31.824249 118397 solver.cpp:236] Iteration 4980, loss = 0.605125
I0728 20:23:31.824331 118397 solver.cpp:252]     Train net output #0: loss = 0.633398 (* 1 = 0.633398 loss)
I0728 20:23:31.824347 118397 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0728 20:23:59.492064 118397 solver.cpp:236] Iteration 4990, loss = 0.607783
I0728 20:23:59.492218 118397 solver.cpp:252]     Train net output #0: loss = 0.642089 (* 1 = 0.642089 loss)
I0728 20:23:59.492246 118397 sgd_solver.cpp:106] Iteration 4990, lr = 0.01
I0728 20:24:20.148442 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_5000.caffemodel
I0728 20:24:20.242710 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_5000.solverstate
I0728 20:24:20.246592 118397 solver.cpp:340] Iteration 5000, Testing net (#0)
I0728 20:24:46.627688 118397 solver.cpp:408]     Test net output #0: accuracy = 0.770312
I0728 20:24:46.627969 118397 solver.cpp:408]     Test net output #1: loss = 0.559904 (* 1 = 0.559904 loss)
I0728 20:24:49.136837 118397 solver.cpp:236] Iteration 5000, loss = 0.607331
I0728 20:24:49.136900 118397 solver.cpp:252]     Train net output #0: loss = 0.634153 (* 1 = 0.634153 loss)
I0728 20:24:49.136916 118397 sgd_solver.cpp:106] Iteration 5000, lr = 0.009
I0728 20:25:13.852073 118397 solver.cpp:236] Iteration 5010, loss = 0.602787
I0728 20:25:13.852157 118397 solver.cpp:252]     Train net output #0: loss = 0.40267 (* 1 = 0.40267 loss)
I0728 20:25:13.852174 118397 sgd_solver.cpp:106] Iteration 5010, lr = 0.009
I0728 20:25:40.306248 118397 solver.cpp:236] Iteration 5020, loss = 0.606249
I0728 20:25:40.306391 118397 solver.cpp:252]     Train net output #0: loss = 0.652767 (* 1 = 0.652767 loss)
I0728 20:25:40.306407 118397 sgd_solver.cpp:106] Iteration 5020, lr = 0.009
I0728 20:26:09.042971 118397 solver.cpp:236] Iteration 5030, loss = 0.608149
I0728 20:26:09.043053 118397 solver.cpp:252]     Train net output #0: loss = 0.643801 (* 1 = 0.643801 loss)
I0728 20:26:09.043076 118397 sgd_solver.cpp:106] Iteration 5030, lr = 0.009
I0728 20:26:33.199812 118397 solver.cpp:236] Iteration 5040, loss = 0.611234
I0728 20:26:33.200033 118397 solver.cpp:252]     Train net output #0: loss = 0.649034 (* 1 = 0.649034 loss)
I0728 20:26:33.200088 118397 sgd_solver.cpp:106] Iteration 5040, lr = 0.009
I0728 20:27:04.001045 118397 solver.cpp:236] Iteration 5050, loss = 0.615915
I0728 20:27:04.001238 118397 solver.cpp:252]     Train net output #0: loss = 0.630949 (* 1 = 0.630949 loss)
I0728 20:27:04.001255 118397 sgd_solver.cpp:106] Iteration 5050, lr = 0.009
I0728 20:27:29.180727 118397 solver.cpp:236] Iteration 5060, loss = 0.615393
I0728 20:27:29.180814 118397 solver.cpp:252]     Train net output #0: loss = 0.67607 (* 1 = 0.67607 loss)
I0728 20:27:29.180835 118397 sgd_solver.cpp:106] Iteration 5060, lr = 0.009
I0728 20:27:54.704859 118397 solver.cpp:236] Iteration 5070, loss = 0.614792
I0728 20:27:54.705035 118397 solver.cpp:252]     Train net output #0: loss = 0.34677 (* 1 = 0.34677 loss)
I0728 20:27:54.705054 118397 sgd_solver.cpp:106] Iteration 5070, lr = 0.009
I0728 20:28:26.275063 118397 solver.cpp:236] Iteration 5080, loss = 0.616895
I0728 20:28:26.275225 118397 solver.cpp:252]     Train net output #0: loss = 0.637189 (* 1 = 0.637189 loss)
I0728 20:28:26.275252 118397 sgd_solver.cpp:106] Iteration 5080, lr = 0.009
I0728 20:28:58.522647 118397 solver.cpp:236] Iteration 5090, loss = 0.617064
I0728 20:28:58.522858 118397 solver.cpp:252]     Train net output #0: loss = 0.640666 (* 1 = 0.640666 loss)
I0728 20:28:58.522876 118397 sgd_solver.cpp:106] Iteration 5090, lr = 0.009
I0728 20:29:25.215085 118397 solver.cpp:236] Iteration 5100, loss = 0.614335
I0728 20:29:25.215160 118397 solver.cpp:252]     Train net output #0: loss = 0.63886 (* 1 = 0.63886 loss)
I0728 20:29:25.215178 118397 sgd_solver.cpp:106] Iteration 5100, lr = 0.009
I0728 20:29:54.062136 118397 solver.cpp:236] Iteration 5110, loss = 0.618728
I0728 20:29:54.062347 118397 solver.cpp:252]     Train net output #0: loss = 0.633594 (* 1 = 0.633594 loss)
I0728 20:29:54.062374 118397 sgd_solver.cpp:106] Iteration 5110, lr = 0.009
I0728 20:30:20.598176 118397 solver.cpp:236] Iteration 5120, loss = 0.617267
I0728 20:30:20.598251 118397 solver.cpp:252]     Train net output #0: loss = 0.667172 (* 1 = 0.667172 loss)
I0728 20:30:20.598268 118397 sgd_solver.cpp:106] Iteration 5120, lr = 0.009
I0728 20:30:50.316418 118397 solver.cpp:236] Iteration 5130, loss = 0.617234
I0728 20:30:50.316638 118397 solver.cpp:252]     Train net output #0: loss = 0.63895 (* 1 = 0.63895 loss)
I0728 20:30:50.316654 118397 sgd_solver.cpp:106] Iteration 5130, lr = 0.009
I0728 20:31:15.324313 118397 solver.cpp:236] Iteration 5140, loss = 0.614852
I0728 20:31:15.324396 118397 solver.cpp:252]     Train net output #0: loss = 0.652408 (* 1 = 0.652408 loss)
I0728 20:31:15.324412 118397 sgd_solver.cpp:106] Iteration 5140, lr = 0.009
I0728 20:31:43.971900 118397 solver.cpp:236] Iteration 5150, loss = 0.609065
I0728 20:31:43.972126 118397 solver.cpp:252]     Train net output #0: loss = 0.640725 (* 1 = 0.640725 loss)
I0728 20:31:43.972144 118397 sgd_solver.cpp:106] Iteration 5150, lr = 0.009
I0728 20:32:10.041028 118397 solver.cpp:236] Iteration 5160, loss = 0.61269
I0728 20:32:10.041097 118397 solver.cpp:252]     Train net output #0: loss = 0.635824 (* 1 = 0.635824 loss)
I0728 20:32:10.041112 118397 sgd_solver.cpp:106] Iteration 5160, lr = 0.009
I0728 20:32:33.444612 118397 solver.cpp:236] Iteration 5170, loss = 0.612702
I0728 20:32:33.444780 118397 solver.cpp:252]     Train net output #0: loss = 0.646434 (* 1 = 0.646434 loss)
I0728 20:32:33.444802 118397 sgd_solver.cpp:106] Iteration 5170, lr = 0.009
I0728 20:32:57.260890 118397 solver.cpp:236] Iteration 5180, loss = 0.610941
I0728 20:32:57.260974 118397 solver.cpp:252]     Train net output #0: loss = 0.640325 (* 1 = 0.640325 loss)
I0728 20:32:57.260995 118397 sgd_solver.cpp:106] Iteration 5180, lr = 0.009
I0728 20:33:22.956137 118397 solver.cpp:236] Iteration 5190, loss = 0.600833
I0728 20:33:22.956295 118397 solver.cpp:252]     Train net output #0: loss = 0.230323 (* 1 = 0.230323 loss)
I0728 20:33:22.956311 118397 sgd_solver.cpp:106] Iteration 5190, lr = 0.009
I0728 20:33:51.835171 118397 solver.cpp:236] Iteration 5200, loss = 0.603782
I0728 20:33:51.835239 118397 solver.cpp:252]     Train net output #0: loss = 0.656955 (* 1 = 0.656955 loss)
I0728 20:33:51.835255 118397 sgd_solver.cpp:106] Iteration 5200, lr = 0.009
I0728 20:34:21.083179 118397 solver.cpp:236] Iteration 5210, loss = 0.604493
I0728 20:34:21.083403 118397 solver.cpp:252]     Train net output #0: loss = 0.654827 (* 1 = 0.654827 loss)
I0728 20:34:21.083423 118397 sgd_solver.cpp:106] Iteration 5210, lr = 0.009
I0728 20:34:42.950567 118397 solver.cpp:236] Iteration 5220, loss = 0.603717
I0728 20:34:42.950664 118397 solver.cpp:252]     Train net output #0: loss = 0.643643 (* 1 = 0.643643 loss)
I0728 20:34:42.950683 118397 sgd_solver.cpp:106] Iteration 5220, lr = 0.009
I0728 20:35:09.517731 118397 solver.cpp:236] Iteration 5230, loss = 0.598032
I0728 20:35:09.522738 118397 solver.cpp:252]     Train net output #0: loss = 0.667834 (* 1 = 0.667834 loss)
I0728 20:35:09.522780 118397 sgd_solver.cpp:106] Iteration 5230, lr = 0.009
I0728 20:35:36.958956 118397 solver.cpp:236] Iteration 5240, loss = 0.599942
I0728 20:35:36.959022 118397 solver.cpp:252]     Train net output #0: loss = 0.640259 (* 1 = 0.640259 loss)
I0728 20:35:36.959039 118397 sgd_solver.cpp:106] Iteration 5240, lr = 0.009
I0728 20:36:03.523262 118397 solver.cpp:236] Iteration 5250, loss = 0.600204
I0728 20:36:03.523444 118397 solver.cpp:252]     Train net output #0: loss = 0.350115 (* 1 = 0.350115 loss)
I0728 20:36:03.523468 118397 sgd_solver.cpp:106] Iteration 5250, lr = 0.009
I0728 20:36:31.846073 118397 solver.cpp:236] Iteration 5260, loss = 0.597548
I0728 20:36:31.846148 118397 solver.cpp:252]     Train net output #0: loss = 0.668173 (* 1 = 0.668173 loss)
I0728 20:36:31.846168 118397 sgd_solver.cpp:106] Iteration 5260, lr = 0.009
I0728 20:36:59.812199 118397 solver.cpp:236] Iteration 5270, loss = 0.603544
I0728 20:36:59.812379 118397 solver.cpp:252]     Train net output #0: loss = 0.636007 (* 1 = 0.636007 loss)
I0728 20:36:59.812412 118397 sgd_solver.cpp:106] Iteration 5270, lr = 0.009
I0728 20:37:26.255066 118397 solver.cpp:236] Iteration 5280, loss = 0.601065
I0728 20:37:26.255146 118397 solver.cpp:252]     Train net output #0: loss = 0.636301 (* 1 = 0.636301 loss)
I0728 20:37:26.255162 118397 sgd_solver.cpp:106] Iteration 5280, lr = 0.009
I0728 20:37:59.267426 118397 solver.cpp:236] Iteration 5290, loss = 0.613811
I0728 20:37:59.267601 118397 solver.cpp:252]     Train net output #0: loss = 0.637926 (* 1 = 0.637926 loss)
I0728 20:37:59.267626 118397 sgd_solver.cpp:106] Iteration 5290, lr = 0.009
I0728 20:38:30.398130 118397 solver.cpp:236] Iteration 5300, loss = 0.608877
I0728 20:38:30.398305 118397 solver.cpp:252]     Train net output #0: loss = 0.638021 (* 1 = 0.638021 loss)
I0728 20:38:30.398324 118397 sgd_solver.cpp:106] Iteration 5300, lr = 0.009
I0728 20:38:55.620383 118397 solver.cpp:236] Iteration 5310, loss = 0.609176
I0728 20:38:55.620462 118397 solver.cpp:252]     Train net output #0: loss = 0.642808 (* 1 = 0.642808 loss)
I0728 20:38:55.620478 118397 sgd_solver.cpp:106] Iteration 5310, lr = 0.009
I0728 20:39:17.527357 118397 solver.cpp:236] Iteration 5320, loss = 0.605358
I0728 20:39:17.527581 118397 solver.cpp:252]     Train net output #0: loss = 0.310559 (* 1 = 0.310559 loss)
I0728 20:39:17.527601 118397 sgd_solver.cpp:106] Iteration 5320, lr = 0.009
I0728 20:39:46.793231 118397 solver.cpp:236] Iteration 5330, loss = 0.609257
I0728 20:39:46.793319 118397 solver.cpp:252]     Train net output #0: loss = 0.663333 (* 1 = 0.663333 loss)
I0728 20:39:46.793340 118397 sgd_solver.cpp:106] Iteration 5330, lr = 0.009
I0728 20:40:08.526715 118397 solver.cpp:236] Iteration 5340, loss = 0.601729
I0728 20:40:08.528259 118397 solver.cpp:252]     Train net output #0: loss = 0.652924 (* 1 = 0.652924 loss)
I0728 20:40:08.528280 118397 sgd_solver.cpp:106] Iteration 5340, lr = 0.009
I0728 20:40:37.468829 118397 solver.cpp:236] Iteration 5350, loss = 0.601939
I0728 20:40:37.468895 118397 solver.cpp:252]     Train net output #0: loss = 0.64137 (* 1 = 0.64137 loss)
I0728 20:40:37.468911 118397 sgd_solver.cpp:106] Iteration 5350, lr = 0.009
I0728 20:41:08.654206 118397 solver.cpp:236] Iteration 5360, loss = 0.606963
I0728 20:41:08.654371 118397 solver.cpp:252]     Train net output #0: loss = 0.642502 (* 1 = 0.642502 loss)
I0728 20:41:08.654394 118397 sgd_solver.cpp:106] Iteration 5360, lr = 0.009
I0728 20:41:34.840230 118397 solver.cpp:236] Iteration 5370, loss = 0.605943
I0728 20:41:34.840292 118397 solver.cpp:252]     Train net output #0: loss = 0.630354 (* 1 = 0.630354 loss)
I0728 20:41:34.840308 118397 sgd_solver.cpp:106] Iteration 5370, lr = 0.009
I0728 20:42:04.197396 118397 solver.cpp:236] Iteration 5380, loss = 0.607632
I0728 20:42:04.197527 118397 solver.cpp:252]     Train net output #0: loss = 0.647237 (* 1 = 0.647237 loss)
I0728 20:42:04.197545 118397 sgd_solver.cpp:106] Iteration 5380, lr = 0.009
I0728 20:42:28.156795 118397 solver.cpp:236] Iteration 5390, loss = 0.607153
I0728 20:42:28.156877 118397 solver.cpp:252]     Train net output #0: loss = 0.633341 (* 1 = 0.633341 loss)
I0728 20:42:28.156898 118397 sgd_solver.cpp:106] Iteration 5390, lr = 0.009
I0728 20:42:50.810153 118397 solver.cpp:236] Iteration 5400, loss = 0.609384
I0728 20:42:50.810292 118397 solver.cpp:252]     Train net output #0: loss = 0.634862 (* 1 = 0.634862 loss)
I0728 20:42:50.810308 118397 sgd_solver.cpp:106] Iteration 5400, lr = 0.009
I0728 20:43:17.961220 118397 solver.cpp:236] Iteration 5410, loss = 0.606054
I0728 20:43:17.961292 118397 solver.cpp:252]     Train net output #0: loss = 0.634318 (* 1 = 0.634318 loss)
I0728 20:43:17.961308 118397 sgd_solver.cpp:106] Iteration 5410, lr = 0.009
I0728 20:43:42.298318 118397 solver.cpp:236] Iteration 5420, loss = 0.608388
I0728 20:43:42.298478 118397 solver.cpp:252]     Train net output #0: loss = 0.639593 (* 1 = 0.639593 loss)
I0728 20:43:42.298494 118397 sgd_solver.cpp:106] Iteration 5420, lr = 0.009
I0728 20:44:09.528328 118397 solver.cpp:236] Iteration 5430, loss = 0.610437
I0728 20:44:09.528391 118397 solver.cpp:252]     Train net output #0: loss = 0.640658 (* 1 = 0.640658 loss)
I0728 20:44:09.528408 118397 sgd_solver.cpp:106] Iteration 5430, lr = 0.009
I0728 20:44:40.798223 118397 solver.cpp:236] Iteration 5440, loss = 0.619724
I0728 20:44:40.798380 118397 solver.cpp:252]     Train net output #0: loss = 0.634472 (* 1 = 0.634472 loss)
I0728 20:44:40.798398 118397 sgd_solver.cpp:106] Iteration 5440, lr = 0.009
I0728 20:45:03.794283 118397 solver.cpp:236] Iteration 5450, loss = 0.621953
I0728 20:45:03.794353 118397 solver.cpp:252]     Train net output #0: loss = 0.639958 (* 1 = 0.639958 loss)
I0728 20:45:03.794369 118397 sgd_solver.cpp:106] Iteration 5450, lr = 0.009
I0728 20:45:38.102392 118397 solver.cpp:236] Iteration 5460, loss = 0.616501
I0728 20:45:38.102669 118397 solver.cpp:252]     Train net output #0: loss = 0.651859 (* 1 = 0.651859 loss)
I0728 20:45:38.102690 118397 sgd_solver.cpp:106] Iteration 5460, lr = 0.009
I0728 20:46:04.797359 118397 solver.cpp:236] Iteration 5470, loss = 0.614925
I0728 20:46:04.797446 118397 solver.cpp:252]     Train net output #0: loss = 0.633364 (* 1 = 0.633364 loss)
I0728 20:46:04.797467 118397 sgd_solver.cpp:106] Iteration 5470, lr = 0.009
I0728 20:46:31.336156 118397 solver.cpp:236] Iteration 5480, loss = 0.617264
I0728 20:46:31.336316 118397 solver.cpp:252]     Train net output #0: loss = 0.639189 (* 1 = 0.639189 loss)
I0728 20:46:31.336333 118397 sgd_solver.cpp:106] Iteration 5480, lr = 0.009
I0728 20:47:01.351711 118397 solver.cpp:236] Iteration 5490, loss = 0.617144
I0728 20:47:01.354833 118397 solver.cpp:252]     Train net output #0: loss = 0.639838 (* 1 = 0.639838 loss)
I0728 20:47:01.354851 118397 sgd_solver.cpp:106] Iteration 5490, lr = 0.009
I0728 20:47:27.563351 118397 solver.cpp:340] Iteration 5500, Testing net (#0)
I0728 20:47:53.917227 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 20:47:53.917426 118397 solver.cpp:408]     Test net output #1: loss = 0.652405 (* 1 = 0.652405 loss)
I0728 20:47:57.062659 118397 solver.cpp:236] Iteration 5500, loss = 0.614421
I0728 20:47:57.062737 118397 solver.cpp:252]     Train net output #0: loss = 0.651402 (* 1 = 0.651402 loss)
I0728 20:47:57.062757 118397 sgd_solver.cpp:106] Iteration 5500, lr = 0.009
I0728 20:48:30.069850 118397 solver.cpp:236] Iteration 5510, loss = 0.615108
I0728 20:48:30.070029 118397 solver.cpp:252]     Train net output #0: loss = 0.641767 (* 1 = 0.641767 loss)
I0728 20:48:30.070050 118397 sgd_solver.cpp:106] Iteration 5510, lr = 0.009
I0728 20:48:57.999303 118397 solver.cpp:236] Iteration 5520, loss = 0.617815
I0728 20:48:57.999387 118397 solver.cpp:252]     Train net output #0: loss = 0.63054 (* 1 = 0.63054 loss)
I0728 20:48:57.999410 118397 sgd_solver.cpp:106] Iteration 5520, lr = 0.009
I0728 20:49:24.079176 118397 solver.cpp:236] Iteration 5530, loss = 0.614556
I0728 20:49:24.079313 118397 solver.cpp:252]     Train net output #0: loss = 0.63647 (* 1 = 0.63647 loss)
I0728 20:49:24.079329 118397 sgd_solver.cpp:106] Iteration 5530, lr = 0.009
I0728 20:49:55.985775 118397 solver.cpp:236] Iteration 5540, loss = 0.609332
I0728 20:49:55.985929 118397 solver.cpp:252]     Train net output #0: loss = 0.668728 (* 1 = 0.668728 loss)
I0728 20:49:55.985949 118397 sgd_solver.cpp:106] Iteration 5540, lr = 0.009
I0728 20:50:23.730568 118397 solver.cpp:236] Iteration 5550, loss = 0.613123
I0728 20:50:23.730648 118397 solver.cpp:252]     Train net output #0: loss = 0.63648 (* 1 = 0.63648 loss)
I0728 20:50:23.730664 118397 sgd_solver.cpp:106] Iteration 5550, lr = 0.009
I0728 20:51:03.800853 118397 solver.cpp:236] Iteration 5560, loss = 0.617131
I0728 20:51:03.800989 118397 solver.cpp:252]     Train net output #0: loss = 0.635636 (* 1 = 0.635636 loss)
I0728 20:51:03.801004 118397 sgd_solver.cpp:106] Iteration 5560, lr = 0.009
I0728 20:51:42.554808 118397 solver.cpp:236] Iteration 5570, loss = 0.616601
I0728 20:51:42.554993 118397 solver.cpp:252]     Train net output #0: loss = 0.643246 (* 1 = 0.643246 loss)
I0728 20:51:42.555013 118397 sgd_solver.cpp:106] Iteration 5570, lr = 0.009
I0728 20:52:28.416635 118397 solver.cpp:236] Iteration 5580, loss = 0.61467
I0728 20:52:28.416820 118397 solver.cpp:252]     Train net output #0: loss = 0.635953 (* 1 = 0.635953 loss)
I0728 20:52:28.416849 118397 sgd_solver.cpp:106] Iteration 5580, lr = 0.009
I0728 20:53:12.200121 118397 solver.cpp:236] Iteration 5590, loss = 0.613067
I0728 20:53:12.200294 118397 solver.cpp:252]     Train net output #0: loss = 0.647978 (* 1 = 0.647978 loss)
I0728 20:53:12.200312 118397 sgd_solver.cpp:106] Iteration 5590, lr = 0.009
I0728 20:53:55.129212 118397 solver.cpp:236] Iteration 5600, loss = 0.615865
I0728 20:53:55.129395 118397 solver.cpp:252]     Train net output #0: loss = 0.631694 (* 1 = 0.631694 loss)
I0728 20:53:55.129415 118397 sgd_solver.cpp:106] Iteration 5600, lr = 0.009
I0728 20:54:36.496207 118397 solver.cpp:236] Iteration 5610, loss = 0.615285
I0728 20:54:36.496426 118397 solver.cpp:252]     Train net output #0: loss = 0.642569 (* 1 = 0.642569 loss)
I0728 20:54:36.496443 118397 sgd_solver.cpp:106] Iteration 5610, lr = 0.009
I0728 20:55:14.023386 118397 solver.cpp:236] Iteration 5620, loss = 0.609693
I0728 20:55:14.023568 118397 solver.cpp:252]     Train net output #0: loss = 0.668041 (* 1 = 0.668041 loss)
I0728 20:55:14.023587 118397 sgd_solver.cpp:106] Iteration 5620, lr = 0.009
I0728 20:55:59.302852 118397 solver.cpp:236] Iteration 5630, loss = 0.613008
I0728 20:55:59.303021 118397 solver.cpp:252]     Train net output #0: loss = 0.637147 (* 1 = 0.637147 loss)
I0728 20:55:59.303038 118397 sgd_solver.cpp:106] Iteration 5630, lr = 0.009
I0728 20:56:44.850014 118397 solver.cpp:236] Iteration 5640, loss = 0.6185
I0728 20:56:44.850183 118397 solver.cpp:252]     Train net output #0: loss = 0.636254 (* 1 = 0.636254 loss)
I0728 20:56:44.850200 118397 sgd_solver.cpp:106] Iteration 5640, lr = 0.009
I0728 20:57:24.403694 118397 solver.cpp:236] Iteration 5650, loss = 0.614621
I0728 20:57:24.408310 118397 solver.cpp:252]     Train net output #0: loss = 0.367009 (* 1 = 0.367009 loss)
I0728 20:57:24.408327 118397 sgd_solver.cpp:106] Iteration 5650, lr = 0.009
I0728 20:58:03.775169 118397 solver.cpp:236] Iteration 5660, loss = 0.610849
I0728 20:58:03.782680 118397 solver.cpp:252]     Train net output #0: loss = 0.297137 (* 1 = 0.297137 loss)
I0728 20:58:03.782696 118397 sgd_solver.cpp:106] Iteration 5660, lr = 0.009
I0728 20:58:49.444090 118397 solver.cpp:236] Iteration 5670, loss = 0.613535
I0728 20:58:49.444232 118397 solver.cpp:252]     Train net output #0: loss = 0.633015 (* 1 = 0.633015 loss)
I0728 20:58:49.444249 118397 sgd_solver.cpp:106] Iteration 5670, lr = 0.009
I0728 20:59:24.309660 118397 solver.cpp:236] Iteration 5680, loss = 0.610806
I0728 20:59:24.309814 118397 solver.cpp:252]     Train net output #0: loss = 0.345818 (* 1 = 0.345818 loss)
I0728 20:59:24.309831 118397 sgd_solver.cpp:106] Iteration 5680, lr = 0.009
I0728 20:59:57.694351 118397 solver.cpp:236] Iteration 5690, loss = 0.604884
I0728 20:59:57.694515 118397 solver.cpp:252]     Train net output #0: loss = 0.714439 (* 1 = 0.714439 loss)
I0728 20:59:57.694536 118397 sgd_solver.cpp:106] Iteration 5690, lr = 0.009
I0728 21:00:32.611791 118397 solver.cpp:236] Iteration 5700, loss = 0.605417
I0728 21:00:32.611922 118397 solver.cpp:252]     Train net output #0: loss = 0.643552 (* 1 = 0.643552 loss)
I0728 21:00:32.611939 118397 sgd_solver.cpp:106] Iteration 5700, lr = 0.009
I0728 21:01:08.094602 118397 solver.cpp:236] Iteration 5710, loss = 0.605783
I0728 21:01:08.094835 118397 solver.cpp:252]     Train net output #0: loss = 0.633272 (* 1 = 0.633272 loss)
I0728 21:01:08.094851 118397 sgd_solver.cpp:106] Iteration 5710, lr = 0.009
I0728 21:01:45.233510 118397 solver.cpp:236] Iteration 5720, loss = 0.614152
I0728 21:01:45.233688 118397 solver.cpp:252]     Train net output #0: loss = 0.635171 (* 1 = 0.635171 loss)
I0728 21:01:45.233726 118397 sgd_solver.cpp:106] Iteration 5720, lr = 0.009
I0728 21:02:19.042863 118397 solver.cpp:236] Iteration 5730, loss = 0.608686
I0728 21:02:19.043014 118397 solver.cpp:252]     Train net output #0: loss = 0.641919 (* 1 = 0.641919 loss)
I0728 21:02:19.043031 118397 sgd_solver.cpp:106] Iteration 5730, lr = 0.009
I0728 21:02:52.205530 118397 solver.cpp:236] Iteration 5740, loss = 0.605909
I0728 21:02:52.205796 118397 solver.cpp:252]     Train net output #0: loss = 0.641281 (* 1 = 0.641281 loss)
I0728 21:02:52.205849 118397 sgd_solver.cpp:106] Iteration 5740, lr = 0.009
I0728 21:03:38.050201 118397 solver.cpp:236] Iteration 5750, loss = 0.608812
I0728 21:03:38.050348 118397 solver.cpp:252]     Train net output #0: loss = 0.638394 (* 1 = 0.638394 loss)
I0728 21:03:38.050365 118397 sgd_solver.cpp:106] Iteration 5750, lr = 0.009
I0728 21:04:15.549029 118397 solver.cpp:236] Iteration 5760, loss = 0.613778
I0728 21:04:15.549204 118397 solver.cpp:252]     Train net output #0: loss = 0.632407 (* 1 = 0.632407 loss)
I0728 21:04:15.549233 118397 sgd_solver.cpp:106] Iteration 5760, lr = 0.009
I0728 21:04:54.179833 118397 solver.cpp:236] Iteration 5770, loss = 0.609507
I0728 21:04:54.180162 118397 solver.cpp:252]     Train net output #0: loss = 0.674236 (* 1 = 0.674236 loss)
I0728 21:04:54.180184 118397 sgd_solver.cpp:106] Iteration 5770, lr = 0.009
I0728 21:05:30.890681 118397 solver.cpp:236] Iteration 5780, loss = 0.608197
I0728 21:05:30.890938 118397 solver.cpp:252]     Train net output #0: loss = 0.642801 (* 1 = 0.642801 loss)
I0728 21:05:30.890969 118397 sgd_solver.cpp:106] Iteration 5780, lr = 0.009
I0728 21:06:04.352074 118397 solver.cpp:236] Iteration 5790, loss = 0.61411
I0728 21:06:04.352350 118397 solver.cpp:252]     Train net output #0: loss = 0.63939 (* 1 = 0.63939 loss)
I0728 21:06:04.352367 118397 sgd_solver.cpp:106] Iteration 5790, lr = 0.009
I0728 21:06:39.926980 118397 solver.cpp:236] Iteration 5800, loss = 0.613588
I0728 21:06:39.927186 118397 solver.cpp:252]     Train net output #0: loss = 0.654391 (* 1 = 0.654391 loss)
I0728 21:06:39.927215 118397 sgd_solver.cpp:106] Iteration 5800, lr = 0.009
I0728 21:07:16.859249 118397 solver.cpp:236] Iteration 5810, loss = 0.611304
I0728 21:07:16.859515 118397 solver.cpp:252]     Train net output #0: loss = 0.632529 (* 1 = 0.632529 loss)
I0728 21:07:16.859535 118397 sgd_solver.cpp:106] Iteration 5810, lr = 0.009
I0728 21:07:50.419469 118397 solver.cpp:236] Iteration 5820, loss = 0.608935
I0728 21:07:50.419647 118397 solver.cpp:252]     Train net output #0: loss = 0.642345 (* 1 = 0.642345 loss)
I0728 21:07:50.419675 118397 sgd_solver.cpp:106] Iteration 5820, lr = 0.009
I0728 21:08:29.614320 118397 solver.cpp:236] Iteration 5830, loss = 0.610633
I0728 21:08:29.614485 118397 solver.cpp:252]     Train net output #0: loss = 0.638187 (* 1 = 0.638187 loss)
I0728 21:08:29.614506 118397 sgd_solver.cpp:106] Iteration 5830, lr = 0.009
I0728 21:09:10.497174 118397 solver.cpp:236] Iteration 5840, loss = 0.610977
I0728 21:09:10.497417 118397 solver.cpp:252]     Train net output #0: loss = 0.636167 (* 1 = 0.636167 loss)
I0728 21:09:10.497443 118397 sgd_solver.cpp:106] Iteration 5840, lr = 0.009
I0728 21:09:52.004724 118397 solver.cpp:236] Iteration 5850, loss = 0.608515
I0728 21:09:52.004942 118397 solver.cpp:252]     Train net output #0: loss = 0.634325 (* 1 = 0.634325 loss)
I0728 21:09:52.004958 118397 sgd_solver.cpp:106] Iteration 5850, lr = 0.009
I0728 21:10:24.855195 118397 solver.cpp:236] Iteration 5860, loss = 0.603807
I0728 21:10:24.855422 118397 solver.cpp:252]     Train net output #0: loss = 0.653226 (* 1 = 0.653226 loss)
I0728 21:10:24.855443 118397 sgd_solver.cpp:106] Iteration 5860, lr = 0.009
I0728 21:10:56.873261 118397 solver.cpp:236] Iteration 5870, loss = 0.602289
I0728 21:10:56.873430 118397 solver.cpp:252]     Train net output #0: loss = 0.361879 (* 1 = 0.361879 loss)
I0728 21:10:56.873457 118397 sgd_solver.cpp:106] Iteration 5870, lr = 0.009
I0728 21:11:34.440181 118397 solver.cpp:236] Iteration 5880, loss = 0.608333
I0728 21:11:34.440397 118397 solver.cpp:252]     Train net output #0: loss = 0.629839 (* 1 = 0.629839 loss)
I0728 21:11:34.440417 118397 sgd_solver.cpp:106] Iteration 5880, lr = 0.009
I0728 21:12:07.109208 118397 solver.cpp:236] Iteration 5890, loss = 0.602502
I0728 21:12:07.109345 118397 solver.cpp:252]     Train net output #0: loss = 0.654955 (* 1 = 0.654955 loss)
I0728 21:12:07.109366 118397 sgd_solver.cpp:106] Iteration 5890, lr = 0.009
I0728 21:12:44.312630 118397 solver.cpp:236] Iteration 5900, loss = 0.603147
I0728 21:12:44.312883 118397 solver.cpp:252]     Train net output #0: loss = 0.636249 (* 1 = 0.636249 loss)
I0728 21:12:44.312899 118397 sgd_solver.cpp:106] Iteration 5900, lr = 0.009
I0728 21:13:31.919605 118397 solver.cpp:236] Iteration 5910, loss = 0.603123
I0728 21:13:31.919775 118397 solver.cpp:252]     Train net output #0: loss = 0.663715 (* 1 = 0.663715 loss)
I0728 21:13:31.919803 118397 sgd_solver.cpp:106] Iteration 5910, lr = 0.009
I0728 21:14:06.639618 118397 solver.cpp:236] Iteration 5920, loss = 0.603649
I0728 21:14:06.639829 118397 solver.cpp:252]     Train net output #0: loss = 0.633508 (* 1 = 0.633508 loss)
I0728 21:14:06.639855 118397 sgd_solver.cpp:106] Iteration 5920, lr = 0.009
I0728 21:14:44.890724 118397 solver.cpp:236] Iteration 5930, loss = 0.606633
I0728 21:14:44.890981 118397 solver.cpp:252]     Train net output #0: loss = 0.635249 (* 1 = 0.635249 loss)
I0728 21:14:44.891010 118397 sgd_solver.cpp:106] Iteration 5930, lr = 0.009
I0728 21:15:25.799556 118397 solver.cpp:236] Iteration 5940, loss = 0.600784
I0728 21:15:25.799760 118397 solver.cpp:252]     Train net output #0: loss = 0.652836 (* 1 = 0.652836 loss)
I0728 21:15:25.799779 118397 sgd_solver.cpp:106] Iteration 5940, lr = 0.009
I0728 21:15:55.415141 118397 solver.cpp:236] Iteration 5950, loss = 0.5994
I0728 21:15:55.415217 118397 solver.cpp:252]     Train net output #0: loss = 0.696822 (* 1 = 0.696822 loss)
I0728 21:15:55.415236 118397 sgd_solver.cpp:106] Iteration 5950, lr = 0.009
I0728 21:16:28.263278 118397 solver.cpp:236] Iteration 5960, loss = 0.603887
I0728 21:16:28.263463 118397 solver.cpp:252]     Train net output #0: loss = 0.643621 (* 1 = 0.643621 loss)
I0728 21:16:28.263504 118397 sgd_solver.cpp:106] Iteration 5960, lr = 0.009
I0728 21:17:03.444084 118397 solver.cpp:236] Iteration 5970, loss = 0.60933
I0728 21:17:03.444314 118397 solver.cpp:252]     Train net output #0: loss = 0.637122 (* 1 = 0.637122 loss)
I0728 21:17:03.444347 118397 sgd_solver.cpp:106] Iteration 5970, lr = 0.009
I0728 21:17:40.840837 118397 solver.cpp:236] Iteration 5980, loss = 0.605182
I0728 21:17:40.841092 118397 solver.cpp:252]     Train net output #0: loss = 0.653639 (* 1 = 0.653639 loss)
I0728 21:17:40.841109 118397 sgd_solver.cpp:106] Iteration 5980, lr = 0.009
I0728 21:18:12.670259 118397 solver.cpp:236] Iteration 5990, loss = 0.611484
I0728 21:18:12.670389 118397 solver.cpp:252]     Train net output #0: loss = 0.426858 (* 1 = 0.426858 loss)
I0728 21:18:12.670406 118397 sgd_solver.cpp:106] Iteration 5990, lr = 0.009
I0728 21:18:49.364886 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_6000.caffemodel
I0728 21:18:49.460286 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_6000.solverstate
I0728 21:18:49.464586 118397 solver.cpp:340] Iteration 6000, Testing net (#0)
I0728 21:19:25.949547 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 21:19:25.949740 118397 solver.cpp:408]     Test net output #1: loss = 0.610656 (* 1 = 0.610656 loss)
I0728 21:19:29.374239 118397 solver.cpp:236] Iteration 6000, loss = 0.607324
I0728 21:19:29.374315 118397 solver.cpp:252]     Train net output #0: loss = 0.643031 (* 1 = 0.643031 loss)
I0728 21:19:29.374333 118397 sgd_solver.cpp:106] Iteration 6000, lr = 0.009
I0728 21:20:07.081944 118397 solver.cpp:236] Iteration 6010, loss = 0.609854
I0728 21:20:07.082115 118397 solver.cpp:252]     Train net output #0: loss = 0.651269 (* 1 = 0.651269 loss)
I0728 21:20:07.082136 118397 sgd_solver.cpp:106] Iteration 6010, lr = 0.009
I0728 21:20:46.099028 118397 solver.cpp:236] Iteration 6020, loss = 0.606009
I0728 21:20:46.099172 118397 solver.cpp:252]     Train net output #0: loss = 0.63916 (* 1 = 0.63916 loss)
I0728 21:20:46.099191 118397 sgd_solver.cpp:106] Iteration 6020, lr = 0.009
I0728 21:21:23.697178 118397 solver.cpp:236] Iteration 6030, loss = 0.603953
I0728 21:21:23.697360 118397 solver.cpp:252]     Train net output #0: loss = 0.640381 (* 1 = 0.640381 loss)
I0728 21:21:23.697376 118397 sgd_solver.cpp:106] Iteration 6030, lr = 0.009
I0728 21:21:53.613863 118397 solver.cpp:236] Iteration 6040, loss = 0.607085
I0728 21:21:53.613956 118397 solver.cpp:252]     Train net output #0: loss = 0.644164 (* 1 = 0.644164 loss)
I0728 21:21:53.613975 118397 sgd_solver.cpp:106] Iteration 6040, lr = 0.009
I0728 21:22:28.125195 118397 solver.cpp:236] Iteration 6050, loss = 0.60839
I0728 21:22:28.125334 118397 solver.cpp:252]     Train net output #0: loss = 0.642535 (* 1 = 0.642535 loss)
I0728 21:22:28.125355 118397 sgd_solver.cpp:106] Iteration 6050, lr = 0.009
I0728 21:22:59.590924 118397 solver.cpp:236] Iteration 6060, loss = 0.603235
I0728 21:22:59.591176 118397 solver.cpp:252]     Train net output #0: loss = 0.642707 (* 1 = 0.642707 loss)
I0728 21:22:59.591192 118397 sgd_solver.cpp:106] Iteration 6060, lr = 0.009
I0728 21:23:30.812800 118397 solver.cpp:236] Iteration 6070, loss = 0.603317
I0728 21:23:30.813014 118397 solver.cpp:252]     Train net output #0: loss = 0.633611 (* 1 = 0.633611 loss)
I0728 21:23:30.813030 118397 sgd_solver.cpp:106] Iteration 6070, lr = 0.009
I0728 21:24:01.090451 118397 solver.cpp:236] Iteration 6080, loss = 0.605419
I0728 21:24:01.090670 118397 solver.cpp:252]     Train net output #0: loss = 0.63811 (* 1 = 0.63811 loss)
I0728 21:24:01.090688 118397 sgd_solver.cpp:106] Iteration 6080, lr = 0.009
I0728 21:24:33.612918 118397 solver.cpp:236] Iteration 6090, loss = 0.607149
I0728 21:24:33.613135 118397 solver.cpp:252]     Train net output #0: loss = 0.633705 (* 1 = 0.633705 loss)
I0728 21:24:33.613167 118397 sgd_solver.cpp:106] Iteration 6090, lr = 0.009
I0728 21:25:04.704102 118397 solver.cpp:236] Iteration 6100, loss = 0.608385
I0728 21:25:04.704293 118397 solver.cpp:252]     Train net output #0: loss = 0.639606 (* 1 = 0.639606 loss)
I0728 21:25:04.704320 118397 sgd_solver.cpp:106] Iteration 6100, lr = 0.009
I0728 21:25:39.701263 118397 solver.cpp:236] Iteration 6110, loss = 0.611154
I0728 21:25:39.701431 118397 solver.cpp:252]     Train net output #0: loss = 0.637025 (* 1 = 0.637025 loss)
I0728 21:25:39.701452 118397 sgd_solver.cpp:106] Iteration 6110, lr = 0.009
I0728 21:26:09.799510 118397 solver.cpp:236] Iteration 6120, loss = 0.614699
I0728 21:26:09.799684 118397 solver.cpp:252]     Train net output #0: loss = 0.638099 (* 1 = 0.638099 loss)
I0728 21:26:09.799701 118397 sgd_solver.cpp:106] Iteration 6120, lr = 0.009
I0728 21:26:35.268193 118397 solver.cpp:236] Iteration 6130, loss = 0.613365
I0728 21:26:35.268290 118397 solver.cpp:252]     Train net output #0: loss = 0.663918 (* 1 = 0.663918 loss)
I0728 21:26:35.268314 118397 sgd_solver.cpp:106] Iteration 6130, lr = 0.009
I0728 21:27:05.370225 118397 solver.cpp:236] Iteration 6140, loss = 0.609049
I0728 21:27:05.370385 118397 solver.cpp:252]     Train net output #0: loss = 0.646402 (* 1 = 0.646402 loss)
I0728 21:27:05.370403 118397 sgd_solver.cpp:106] Iteration 6140, lr = 0.009
I0728 21:27:31.674387 118397 solver.cpp:236] Iteration 6150, loss = 0.605905
I0728 21:27:31.674454 118397 solver.cpp:252]     Train net output #0: loss = 0.345192 (* 1 = 0.345192 loss)
I0728 21:27:31.674468 118397 sgd_solver.cpp:106] Iteration 6150, lr = 0.009
I0728 21:28:00.459002 118397 solver.cpp:236] Iteration 6160, loss = 0.606171
I0728 21:28:00.459146 118397 solver.cpp:252]     Train net output #0: loss = 0.666943 (* 1 = 0.666943 loss)
I0728 21:28:00.459164 118397 sgd_solver.cpp:106] Iteration 6160, lr = 0.009
I0728 21:28:32.780521 118397 solver.cpp:236] Iteration 6170, loss = 0.603667
I0728 21:28:32.780709 118397 solver.cpp:252]     Train net output #0: loss = 0.629811 (* 1 = 0.629811 loss)
I0728 21:28:32.780730 118397 sgd_solver.cpp:106] Iteration 6170, lr = 0.009
I0728 21:29:05.765107 118397 solver.cpp:236] Iteration 6180, loss = 0.600474
I0728 21:29:05.765383 118397 solver.cpp:252]     Train net output #0: loss = 0.642426 (* 1 = 0.642426 loss)
I0728 21:29:05.765410 118397 sgd_solver.cpp:106] Iteration 6180, lr = 0.009
I0728 21:29:34.290367 118397 solver.cpp:236] Iteration 6190, loss = 0.597607
I0728 21:29:34.290431 118397 solver.cpp:252]     Train net output #0: loss = 0.640785 (* 1 = 0.640785 loss)
I0728 21:29:34.290446 118397 sgd_solver.cpp:106] Iteration 6190, lr = 0.009
I0728 21:29:58.961786 118397 solver.cpp:236] Iteration 6200, loss = 0.593841
I0728 21:29:58.961923 118397 solver.cpp:252]     Train net output #0: loss = 0.672013 (* 1 = 0.672013 loss)
I0728 21:29:58.961940 118397 sgd_solver.cpp:106] Iteration 6200, lr = 0.009
I0728 21:30:26.435336 118397 solver.cpp:236] Iteration 6210, loss = 0.587652
I0728 21:30:26.435420 118397 solver.cpp:252]     Train net output #0: loss = 0.650087 (* 1 = 0.650087 loss)
I0728 21:30:26.435444 118397 sgd_solver.cpp:106] Iteration 6210, lr = 0.009
I0728 21:31:00.177659 118397 solver.cpp:236] Iteration 6220, loss = 0.589614
I0728 21:31:00.177878 118397 solver.cpp:252]     Train net output #0: loss = 0.638387 (* 1 = 0.638387 loss)
I0728 21:31:00.177901 118397 sgd_solver.cpp:106] Iteration 6220, lr = 0.009
I0728 21:31:29.840134 118397 solver.cpp:236] Iteration 6230, loss = 0.588099
I0728 21:31:29.840210 118397 solver.cpp:252]     Train net output #0: loss = 0.35075 (* 1 = 0.35075 loss)
I0728 21:31:29.840229 118397 sgd_solver.cpp:106] Iteration 6230, lr = 0.009
I0728 21:31:57.086176 118397 solver.cpp:236] Iteration 6240, loss = 0.594941
I0728 21:31:57.086403 118397 solver.cpp:252]     Train net output #0: loss = 0.646402 (* 1 = 0.646402 loss)
I0728 21:31:57.086421 118397 sgd_solver.cpp:106] Iteration 6240, lr = 0.009
I0728 21:32:20.898994 118397 solver.cpp:236] Iteration 6250, loss = 0.598166
I0728 21:32:20.899072 118397 solver.cpp:252]     Train net output #0: loss = 0.639811 (* 1 = 0.639811 loss)
I0728 21:32:20.899094 118397 sgd_solver.cpp:106] Iteration 6250, lr = 0.009
I0728 21:32:48.717319 118397 solver.cpp:236] Iteration 6260, loss = 0.601029
I0728 21:32:48.717483 118397 solver.cpp:252]     Train net output #0: loss = 0.636497 (* 1 = 0.636497 loss)
I0728 21:32:48.717501 118397 sgd_solver.cpp:106] Iteration 6260, lr = 0.009
I0728 21:33:18.018648 118397 solver.cpp:236] Iteration 6270, loss = 0.597793
I0728 21:33:18.018719 118397 solver.cpp:252]     Train net output #0: loss = 0.645174 (* 1 = 0.645174 loss)
I0728 21:33:18.018738 118397 sgd_solver.cpp:106] Iteration 6270, lr = 0.009
I0728 21:33:48.031059 118397 solver.cpp:236] Iteration 6280, loss = 0.603389
I0728 21:33:48.031260 118397 solver.cpp:252]     Train net output #0: loss = 0.636311 (* 1 = 0.636311 loss)
I0728 21:33:48.031280 118397 sgd_solver.cpp:106] Iteration 6280, lr = 0.009
I0728 21:34:17.208605 118397 solver.cpp:236] Iteration 6290, loss = 0.60589
I0728 21:34:17.208675 118397 solver.cpp:252]     Train net output #0: loss = 0.628509 (* 1 = 0.628509 loss)
I0728 21:34:17.208690 118397 sgd_solver.cpp:106] Iteration 6290, lr = 0.009
I0728 21:34:45.557384 118397 solver.cpp:236] Iteration 6300, loss = 0.60818
I0728 21:34:45.557554 118397 solver.cpp:252]     Train net output #0: loss = 0.70032 (* 1 = 0.70032 loss)
I0728 21:34:45.557585 118397 sgd_solver.cpp:106] Iteration 6300, lr = 0.009
I0728 21:35:17.067945 118397 solver.cpp:236] Iteration 6310, loss = 0.614984
I0728 21:35:17.068137 118397 solver.cpp:252]     Train net output #0: loss = 0.638145 (* 1 = 0.638145 loss)
I0728 21:35:17.068155 118397 sgd_solver.cpp:106] Iteration 6310, lr = 0.009
I0728 21:35:52.274405 118397 solver.cpp:236] Iteration 6320, loss = 0.613735
I0728 21:35:52.274569 118397 solver.cpp:252]     Train net output #0: loss = 0.442004 (* 1 = 0.442004 loss)
I0728 21:35:52.274585 118397 sgd_solver.cpp:106] Iteration 6320, lr = 0.009
I0728 21:36:21.375497 118397 solver.cpp:236] Iteration 6330, loss = 0.616108
I0728 21:36:21.375571 118397 solver.cpp:252]     Train net output #0: loss = 0.303937 (* 1 = 0.303937 loss)
I0728 21:36:21.375586 118397 sgd_solver.cpp:106] Iteration 6330, lr = 0.009
I0728 21:36:52.040942 118397 solver.cpp:236] Iteration 6340, loss = 0.614162
I0728 21:36:52.041123 118397 solver.cpp:252]     Train net output #0: loss = 0.658611 (* 1 = 0.658611 loss)
I0728 21:36:52.041164 118397 sgd_solver.cpp:106] Iteration 6340, lr = 0.009
I0728 21:37:21.171042 118397 solver.cpp:236] Iteration 6350, loss = 0.611291
I0728 21:37:21.171128 118397 solver.cpp:252]     Train net output #0: loss = 0.635749 (* 1 = 0.635749 loss)
I0728 21:37:21.171149 118397 sgd_solver.cpp:106] Iteration 6350, lr = 0.009
I0728 21:37:53.213040 118397 solver.cpp:236] Iteration 6360, loss = 0.608248
I0728 21:37:53.213189 118397 solver.cpp:252]     Train net output #0: loss = 0.651788 (* 1 = 0.651788 loss)
I0728 21:37:53.213207 118397 sgd_solver.cpp:106] Iteration 6360, lr = 0.009
I0728 21:38:23.571472 118397 solver.cpp:236] Iteration 6370, loss = 0.611567
I0728 21:38:23.571684 118397 solver.cpp:252]     Train net output #0: loss = 0.642629 (* 1 = 0.642629 loss)
I0728 21:38:23.571702 118397 sgd_solver.cpp:106] Iteration 6370, lr = 0.009
I0728 21:38:55.650928 118397 solver.cpp:236] Iteration 6380, loss = 0.605552
I0728 21:38:55.651126 118397 solver.cpp:252]     Train net output #0: loss = 0.641317 (* 1 = 0.641317 loss)
I0728 21:38:55.651142 118397 sgd_solver.cpp:106] Iteration 6380, lr = 0.009
I0728 21:39:25.234532 118397 solver.cpp:236] Iteration 6390, loss = 0.600868
I0728 21:39:25.234607 118397 solver.cpp:252]     Train net output #0: loss = 0.420601 (* 1 = 0.420601 loss)
I0728 21:39:25.234622 118397 sgd_solver.cpp:106] Iteration 6390, lr = 0.009
I0728 21:39:54.177109 118397 solver.cpp:236] Iteration 6400, loss = 0.604249
I0728 21:39:54.177268 118397 solver.cpp:252]     Train net output #0: loss = 0.635251 (* 1 = 0.635251 loss)
I0728 21:39:54.177284 118397 sgd_solver.cpp:106] Iteration 6400, lr = 0.009
I0728 21:40:21.381992 118397 solver.cpp:236] Iteration 6410, loss = 0.599876
I0728 21:40:21.382066 118397 solver.cpp:252]     Train net output #0: loss = 0.633428 (* 1 = 0.633428 loss)
I0728 21:40:21.382082 118397 sgd_solver.cpp:106] Iteration 6410, lr = 0.009
I0728 21:40:49.566087 118397 solver.cpp:236] Iteration 6420, loss = 0.598486
I0728 21:40:49.566299 118397 solver.cpp:252]     Train net output #0: loss = 0.638058 (* 1 = 0.638058 loss)
I0728 21:40:49.566326 118397 sgd_solver.cpp:106] Iteration 6420, lr = 0.009
I0728 21:41:17.932440 118397 solver.cpp:236] Iteration 6430, loss = 0.598479
I0728 21:41:17.932507 118397 solver.cpp:252]     Train net output #0: loss = 0.638408 (* 1 = 0.638408 loss)
I0728 21:41:17.932520 118397 sgd_solver.cpp:106] Iteration 6430, lr = 0.009
I0728 21:41:48.700767 118397 solver.cpp:236] Iteration 6440, loss = 0.598366
I0728 21:41:48.700999 118397 solver.cpp:252]     Train net output #0: loss = 0.639863 (* 1 = 0.639863 loss)
I0728 21:41:48.701015 118397 sgd_solver.cpp:106] Iteration 6440, lr = 0.009
I0728 21:42:20.748371 118397 solver.cpp:236] Iteration 6450, loss = 0.601392
I0728 21:42:20.748589 118397 solver.cpp:252]     Train net output #0: loss = 0.643616 (* 1 = 0.643616 loss)
I0728 21:42:20.748617 118397 sgd_solver.cpp:106] Iteration 6450, lr = 0.009
I0728 21:42:49.119711 118397 solver.cpp:236] Iteration 6460, loss = 0.601988
I0728 21:42:49.119778 118397 solver.cpp:252]     Train net output #0: loss = 0.661457 (* 1 = 0.661457 loss)
I0728 21:42:49.119793 118397 sgd_solver.cpp:106] Iteration 6460, lr = 0.009
I0728 21:43:18.768522 118397 solver.cpp:236] Iteration 6470, loss = 0.602075
I0728 21:43:18.768678 118397 solver.cpp:252]     Train net output #0: loss = 0.637307 (* 1 = 0.637307 loss)
I0728 21:43:18.768695 118397 sgd_solver.cpp:106] Iteration 6470, lr = 0.009
I0728 21:43:49.119663 118397 solver.cpp:236] Iteration 6480, loss = 0.607454
I0728 21:43:49.119820 118397 solver.cpp:252]     Train net output #0: loss = 0.631122 (* 1 = 0.631122 loss)
I0728 21:43:49.119848 118397 sgd_solver.cpp:106] Iteration 6480, lr = 0.009
I0728 21:44:25.523680 118397 solver.cpp:236] Iteration 6490, loss = 0.609586
I0728 21:44:25.523829 118397 solver.cpp:252]     Train net output #0: loss = 0.639657 (* 1 = 0.639657 loss)
I0728 21:44:25.523849 118397 sgd_solver.cpp:106] Iteration 6490, lr = 0.009
I0728 21:44:50.904539 118397 solver.cpp:340] Iteration 6500, Testing net (#0)
I0728 21:45:22.645644 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 21:45:22.645826 118397 solver.cpp:408]     Test net output #1: loss = 0.62639 (* 1 = 0.62639 loss)
I0728 21:45:26.139551 118397 solver.cpp:236] Iteration 6500, loss = 0.607628
I0728 21:45:26.139611 118397 solver.cpp:252]     Train net output #0: loss = 0.665089 (* 1 = 0.665089 loss)
I0728 21:45:26.139626 118397 sgd_solver.cpp:106] Iteration 6500, lr = 0.009
I0728 21:45:55.337294 118397 solver.cpp:236] Iteration 6510, loss = 0.611152
I0728 21:45:55.337461 118397 solver.cpp:252]     Train net output #0: loss = 0.637678 (* 1 = 0.637678 loss)
I0728 21:45:55.337483 118397 sgd_solver.cpp:106] Iteration 6510, lr = 0.009
I0728 21:46:25.581535 118397 solver.cpp:236] Iteration 6520, loss = 0.610659
I0728 21:46:25.581759 118397 solver.cpp:252]     Train net output #0: loss = 0.653667 (* 1 = 0.653667 loss)
I0728 21:46:25.581775 118397 sgd_solver.cpp:106] Iteration 6520, lr = 0.009
I0728 21:46:59.118724 118397 solver.cpp:236] Iteration 6530, loss = 0.614281
I0728 21:46:59.119060 118397 solver.cpp:252]     Train net output #0: loss = 0.637844 (* 1 = 0.637844 loss)
I0728 21:46:59.119078 118397 sgd_solver.cpp:106] Iteration 6530, lr = 0.009
I0728 21:47:26.432443 118397 solver.cpp:236] Iteration 6540, loss = 0.613771
I0728 21:47:26.432507 118397 solver.cpp:252]     Train net output #0: loss = 0.631497 (* 1 = 0.631497 loss)
I0728 21:47:26.432524 118397 sgd_solver.cpp:106] Iteration 6540, lr = 0.009
I0728 21:47:58.043815 118397 solver.cpp:236] Iteration 6550, loss = 0.616495
I0728 21:47:58.043962 118397 solver.cpp:252]     Train net output #0: loss = 0.640543 (* 1 = 0.640543 loss)
I0728 21:47:58.043984 118397 sgd_solver.cpp:106] Iteration 6550, lr = 0.009
I0728 21:48:29.882424 118397 solver.cpp:236] Iteration 6560, loss = 0.618631
I0728 21:48:29.882650 118397 solver.cpp:252]     Train net output #0: loss = 0.643393 (* 1 = 0.643393 loss)
I0728 21:48:29.882670 118397 sgd_solver.cpp:106] Iteration 6560, lr = 0.009
I0728 21:49:02.262822 118397 solver.cpp:236] Iteration 6570, loss = 0.618378
I0728 21:49:02.263001 118397 solver.cpp:252]     Train net output #0: loss = 0.634302 (* 1 = 0.634302 loss)
I0728 21:49:02.263021 118397 sgd_solver.cpp:106] Iteration 6570, lr = 0.009
I0728 21:49:30.886554 118397 solver.cpp:236] Iteration 6580, loss = 0.618752
I0728 21:49:30.886617 118397 solver.cpp:252]     Train net output #0: loss = 0.64774 (* 1 = 0.64774 loss)
I0728 21:49:30.886648 118397 sgd_solver.cpp:106] Iteration 6580, lr = 0.009
I0728 21:49:57.863391 118397 solver.cpp:236] Iteration 6590, loss = 0.621296
I0728 21:49:57.863564 118397 solver.cpp:252]     Train net output #0: loss = 0.641584 (* 1 = 0.641584 loss)
I0728 21:49:57.863590 118397 sgd_solver.cpp:106] Iteration 6590, lr = 0.009
I0728 21:50:27.138427 118397 solver.cpp:236] Iteration 6600, loss = 0.612948
I0728 21:50:27.138496 118397 solver.cpp:252]     Train net output #0: loss = 0.233691 (* 1 = 0.233691 loss)
I0728 21:50:27.138515 118397 sgd_solver.cpp:106] Iteration 6600, lr = 0.009
I0728 21:50:55.688552 118397 solver.cpp:236] Iteration 6610, loss = 0.608911
I0728 21:50:55.688760 118397 solver.cpp:252]     Train net output #0: loss = 0.276846 (* 1 = 0.276846 loss)
I0728 21:50:55.688788 118397 sgd_solver.cpp:106] Iteration 6610, lr = 0.009
I0728 21:51:22.768515 118397 solver.cpp:236] Iteration 6620, loss = 0.607694
I0728 21:51:22.768573 118397 solver.cpp:252]     Train net output #0: loss = 0.642843 (* 1 = 0.642843 loss)
I0728 21:51:22.768589 118397 sgd_solver.cpp:106] Iteration 6620, lr = 0.009
I0728 21:51:52.043063 118397 solver.cpp:236] Iteration 6630, loss = 0.599384
I0728 21:51:52.043180 118397 solver.cpp:252]     Train net output #0: loss = 0.688797 (* 1 = 0.688797 loss)
I0728 21:51:52.043196 118397 sgd_solver.cpp:106] Iteration 6630, lr = 0.009
I0728 21:52:23.297891 118397 solver.cpp:236] Iteration 6640, loss = 0.605846
I0728 21:52:23.298015 118397 solver.cpp:252]     Train net output #0: loss = 0.636609 (* 1 = 0.636609 loss)
I0728 21:52:23.298032 118397 sgd_solver.cpp:106] Iteration 6640, lr = 0.009
I0728 21:52:53.685089 118397 solver.cpp:236] Iteration 6650, loss = 0.604266
I0728 21:52:53.685246 118397 solver.cpp:252]     Train net output #0: loss = 0.634325 (* 1 = 0.634325 loss)
I0728 21:52:53.685266 118397 sgd_solver.cpp:106] Iteration 6650, lr = 0.009
I0728 21:53:25.188165 118397 solver.cpp:236] Iteration 6660, loss = 0.604283
I0728 21:53:25.188371 118397 solver.cpp:252]     Train net output #0: loss = 0.643624 (* 1 = 0.643624 loss)
I0728 21:53:25.188401 118397 sgd_solver.cpp:106] Iteration 6660, lr = 0.009
I0728 21:53:54.787163 118397 solver.cpp:236] Iteration 6670, loss = 0.604351
I0728 21:53:54.787225 118397 solver.cpp:252]     Train net output #0: loss = 0.642945 (* 1 = 0.642945 loss)
I0728 21:53:54.787240 118397 sgd_solver.cpp:106] Iteration 6670, lr = 0.009
I0728 21:54:29.332595 118397 solver.cpp:236] Iteration 6680, loss = 0.604348
I0728 21:54:29.332873 118397 solver.cpp:252]     Train net output #0: loss = 0.638564 (* 1 = 0.638564 loss)
I0728 21:54:29.332890 118397 sgd_solver.cpp:106] Iteration 6680, lr = 0.009
I0728 21:55:00.083746 118397 solver.cpp:236] Iteration 6690, loss = 0.604329
I0728 21:55:00.083935 118397 solver.cpp:252]     Train net output #0: loss = 0.637486 (* 1 = 0.637486 loss)
I0728 21:55:00.083953 118397 sgd_solver.cpp:106] Iteration 6690, lr = 0.009
I0728 21:55:27.391829 118397 solver.cpp:236] Iteration 6700, loss = 0.607912
I0728 21:55:27.391886 118397 solver.cpp:252]     Train net output #0: loss = 0.267511 (* 1 = 0.267511 loss)
I0728 21:55:27.391901 118397 sgd_solver.cpp:106] Iteration 6700, lr = 0.009
I0728 21:55:58.521894 118397 solver.cpp:236] Iteration 6710, loss = 0.611263
I0728 21:55:58.522066 118397 solver.cpp:252]     Train net output #0: loss = 0.654547 (* 1 = 0.654547 loss)
I0728 21:55:58.522101 118397 sgd_solver.cpp:106] Iteration 6710, lr = 0.009
I0728 21:56:24.405321 118397 solver.cpp:236] Iteration 6720, loss = 0.615181
I0728 21:56:24.405395 118397 solver.cpp:252]     Train net output #0: loss = 0.644854 (* 1 = 0.644854 loss)
I0728 21:56:24.405411 118397 sgd_solver.cpp:106] Iteration 6720, lr = 0.009
I0728 21:56:58.166908 118397 solver.cpp:236] Iteration 6730, loss = 0.619554
I0728 21:56:58.167055 118397 solver.cpp:252]     Train net output #0: loss = 0.6429 (* 1 = 0.6429 loss)
I0728 21:56:58.167071 118397 sgd_solver.cpp:106] Iteration 6730, lr = 0.009
I0728 21:57:28.471570 118397 solver.cpp:236] Iteration 6740, loss = 0.612677
I0728 21:57:28.471770 118397 solver.cpp:252]     Train net output #0: loss = 0.653226 (* 1 = 0.653226 loss)
I0728 21:57:28.471786 118397 sgd_solver.cpp:106] Iteration 6740, lr = 0.009
I0728 21:58:02.660634 118397 solver.cpp:236] Iteration 6750, loss = 0.614279
I0728 21:58:02.660825 118397 solver.cpp:252]     Train net output #0: loss = 0.639405 (* 1 = 0.639405 loss)
I0728 21:58:02.660851 118397 sgd_solver.cpp:106] Iteration 6750, lr = 0.009
I0728 21:58:30.328584 118397 solver.cpp:236] Iteration 6760, loss = 0.617053
I0728 21:58:30.328668 118397 solver.cpp:252]     Train net output #0: loss = 0.634078 (* 1 = 0.634078 loss)
I0728 21:58:30.328690 118397 sgd_solver.cpp:106] Iteration 6760, lr = 0.009
I0728 21:59:01.488358 118397 solver.cpp:236] Iteration 6770, loss = 0.615924
I0728 21:59:01.488503 118397 solver.cpp:252]     Train net output #0: loss = 0.666504 (* 1 = 0.666504 loss)
I0728 21:59:01.488520 118397 sgd_solver.cpp:106] Iteration 6770, lr = 0.009
I0728 21:59:33.009471 118397 solver.cpp:236] Iteration 6780, loss = 0.616832
I0728 21:59:33.009654 118397 solver.cpp:252]     Train net output #0: loss = 0.636269 (* 1 = 0.636269 loss)
I0728 21:59:33.009675 118397 sgd_solver.cpp:106] Iteration 6780, lr = 0.009
I0728 22:00:09.755499 118397 solver.cpp:236] Iteration 6790, loss = 0.615439
I0728 22:00:09.755790 118397 solver.cpp:252]     Train net output #0: loss = 0.635854 (* 1 = 0.635854 loss)
I0728 22:00:09.755812 118397 sgd_solver.cpp:106] Iteration 6790, lr = 0.009
I0728 22:00:40.713675 118397 solver.cpp:236] Iteration 6800, loss = 0.622277
I0728 22:00:40.713884 118397 solver.cpp:252]     Train net output #0: loss = 0.646019 (* 1 = 0.646019 loss)
I0728 22:00:40.713912 118397 sgd_solver.cpp:106] Iteration 6800, lr = 0.009
I0728 22:01:11.198274 118397 solver.cpp:236] Iteration 6810, loss = 0.619816
I0728 22:01:11.198606 118397 solver.cpp:252]     Train net output #0: loss = 0.641686 (* 1 = 0.641686 loss)
I0728 22:01:11.198664 118397 sgd_solver.cpp:106] Iteration 6810, lr = 0.009
I0728 22:01:40.064595 118397 solver.cpp:236] Iteration 6820, loss = 0.615331
I0728 22:01:40.064666 118397 solver.cpp:252]     Train net output #0: loss = 0.658618 (* 1 = 0.658618 loss)
I0728 22:01:40.064680 118397 sgd_solver.cpp:106] Iteration 6820, lr = 0.009
I0728 22:02:13.764555 118397 solver.cpp:236] Iteration 6830, loss = 0.618667
I0728 22:02:13.764763 118397 solver.cpp:252]     Train net output #0: loss = 0.639379 (* 1 = 0.639379 loss)
I0728 22:02:13.764783 118397 sgd_solver.cpp:106] Iteration 6830, lr = 0.009
I0728 22:02:44.210609 118397 solver.cpp:236] Iteration 6840, loss = 0.622269
I0728 22:02:44.210919 118397 solver.cpp:252]     Train net output #0: loss = 0.637335 (* 1 = 0.637335 loss)
I0728 22:02:44.210939 118397 sgd_solver.cpp:106] Iteration 6840, lr = 0.009
I0728 22:03:20.134001 118397 solver.cpp:236] Iteration 6850, loss = 0.62254
I0728 22:03:20.134217 118397 solver.cpp:252]     Train net output #0: loss = 0.643487 (* 1 = 0.643487 loss)
I0728 22:03:20.134243 118397 sgd_solver.cpp:106] Iteration 6850, lr = 0.009
I0728 22:03:48.120173 118397 solver.cpp:236] Iteration 6860, loss = 0.622224
I0728 22:03:48.120239 118397 solver.cpp:252]     Train net output #0: loss = 0.634154 (* 1 = 0.634154 loss)
I0728 22:03:48.120252 118397 sgd_solver.cpp:106] Iteration 6860, lr = 0.009
I0728 22:04:17.908592 118397 solver.cpp:236] Iteration 6870, loss = 0.625596
I0728 22:04:17.908756 118397 solver.cpp:252]     Train net output #0: loss = 0.633876 (* 1 = 0.633876 loss)
I0728 22:04:17.908771 118397 sgd_solver.cpp:106] Iteration 6870, lr = 0.009
I0728 22:04:50.209377 118397 solver.cpp:236] Iteration 6880, loss = 0.617781
I0728 22:04:50.209522 118397 solver.cpp:252]     Train net output #0: loss = 0.678051 (* 1 = 0.678051 loss)
I0728 22:04:50.209537 118397 sgd_solver.cpp:106] Iteration 6880, lr = 0.009
I0728 22:05:23.986809 118397 solver.cpp:236] Iteration 6890, loss = 0.617297
I0728 22:05:23.987102 118397 solver.cpp:252]     Train net output #0: loss = 0.633769 (* 1 = 0.633769 loss)
I0728 22:05:23.987119 118397 sgd_solver.cpp:106] Iteration 6890, lr = 0.009
I0728 22:05:51.017750 118397 solver.cpp:236] Iteration 6900, loss = 0.613019
I0728 22:05:51.017823 118397 solver.cpp:252]     Train net output #0: loss = 0.669079 (* 1 = 0.669079 loss)
I0728 22:05:51.017841 118397 sgd_solver.cpp:106] Iteration 6900, lr = 0.009
I0728 22:06:22.176321 118397 solver.cpp:236] Iteration 6910, loss = 0.613254
I0728 22:06:22.176470 118397 solver.cpp:252]     Train net output #0: loss = 0.642597 (* 1 = 0.642597 loss)
I0728 22:06:22.176497 118397 sgd_solver.cpp:106] Iteration 6910, lr = 0.009
I0728 22:06:53.945391 118397 solver.cpp:236] Iteration 6920, loss = 0.618591
I0728 22:06:53.945636 118397 solver.cpp:252]     Train net output #0: loss = 0.638441 (* 1 = 0.638441 loss)
I0728 22:06:53.945659 118397 sgd_solver.cpp:106] Iteration 6920, lr = 0.009
I0728 22:07:22.871774 118397 solver.cpp:236] Iteration 6930, loss = 0.610936
I0728 22:07:22.871843 118397 solver.cpp:252]     Train net output #0: loss = 0.684841 (* 1 = 0.684841 loss)
I0728 22:07:22.871857 118397 sgd_solver.cpp:106] Iteration 6930, lr = 0.009
I0728 22:07:54.699904 118397 solver.cpp:236] Iteration 6940, loss = 0.60474
I0728 22:07:54.700052 118397 solver.cpp:252]     Train net output #0: loss = 0.706652 (* 1 = 0.706652 loss)
I0728 22:07:54.700067 118397 sgd_solver.cpp:106] Iteration 6940, lr = 0.009
I0728 22:08:21.565955 118397 solver.cpp:236] Iteration 6950, loss = 0.598454
I0728 22:08:21.566045 118397 solver.cpp:252]     Train net output #0: loss = 0.641243 (* 1 = 0.641243 loss)
I0728 22:08:21.566066 118397 sgd_solver.cpp:106] Iteration 6950, lr = 0.009
I0728 22:08:45.610555 118397 solver.cpp:236] Iteration 6960, loss = 0.594397
I0728 22:08:45.610772 118397 solver.cpp:252]     Train net output #0: loss = 0.645932 (* 1 = 0.645932 loss)
I0728 22:08:45.610816 118397 sgd_solver.cpp:106] Iteration 6960, lr = 0.009
I0728 22:09:14.595952 118397 solver.cpp:236] Iteration 6970, loss = 0.588916
I0728 22:09:14.596020 118397 solver.cpp:252]     Train net output #0: loss = 0.661512 (* 1 = 0.661512 loss)
I0728 22:09:14.596035 118397 sgd_solver.cpp:106] Iteration 6970, lr = 0.009
I0728 22:09:48.821354 118397 solver.cpp:236] Iteration 6980, loss = 0.593629
I0728 22:09:48.821555 118397 solver.cpp:252]     Train net output #0: loss = 0.640576 (* 1 = 0.640576 loss)
I0728 22:09:48.821597 118397 sgd_solver.cpp:106] Iteration 6980, lr = 0.009
I0728 22:10:22.702271 118397 solver.cpp:236] Iteration 6990, loss = 0.595557
I0728 22:10:22.702457 118397 solver.cpp:252]     Train net output #0: loss = 0.638516 (* 1 = 0.638516 loss)
I0728 22:10:22.702477 118397 sgd_solver.cpp:106] Iteration 6990, lr = 0.009
I0728 22:10:49.188521 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_7000.caffemodel
I0728 22:10:49.287356 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_7000.solverstate
I0728 22:10:49.291168 118397 solver.cpp:340] Iteration 7000, Testing net (#0)
I0728 22:11:16.925266 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 22:11:16.925427 118397 solver.cpp:408]     Test net output #1: loss = 0.608639 (* 1 = 0.608639 loss)
I0728 22:11:19.266039 118397 solver.cpp:236] Iteration 7000, loss = 0.600156
I0728 22:11:19.266108 118397 solver.cpp:252]     Train net output #0: loss = 0.642252 (* 1 = 0.642252 loss)
I0728 22:11:19.266126 118397 sgd_solver.cpp:106] Iteration 7000, lr = 0.009
I0728 22:11:46.756876 118397 solver.cpp:236] Iteration 7010, loss = 0.599952
I0728 22:11:46.756947 118397 solver.cpp:252]     Train net output #0: loss = 0.643766 (* 1 = 0.643766 loss)
I0728 22:11:46.756963 118397 sgd_solver.cpp:106] Iteration 7010, lr = 0.009
I0728 22:12:17.174666 118397 solver.cpp:236] Iteration 7020, loss = 0.599657
I0728 22:12:17.174851 118397 solver.cpp:252]     Train net output #0: loss = 0.631696 (* 1 = 0.631696 loss)
I0728 22:12:17.174878 118397 sgd_solver.cpp:106] Iteration 7020, lr = 0.009
I0728 22:12:40.978493 118397 solver.cpp:236] Iteration 7030, loss = 0.600647
I0728 22:12:40.978560 118397 solver.cpp:252]     Train net output #0: loss = 0.674625 (* 1 = 0.674625 loss)
I0728 22:12:40.978575 118397 sgd_solver.cpp:106] Iteration 7030, lr = 0.009
I0728 22:13:08.217952 118397 solver.cpp:236] Iteration 7040, loss = 0.612606
I0728 22:13:08.218127 118397 solver.cpp:252]     Train net output #0: loss = 0.640723 (* 1 = 0.640723 loss)
I0728 22:13:08.218147 118397 sgd_solver.cpp:106] Iteration 7040, lr = 0.009
I0728 22:13:32.323546 118397 solver.cpp:236] Iteration 7050, loss = 0.616001
I0728 22:13:32.323617 118397 solver.cpp:252]     Train net output #0: loss = 0.634295 (* 1 = 0.634295 loss)
I0728 22:13:32.323632 118397 sgd_solver.cpp:106] Iteration 7050, lr = 0.009
I0728 22:14:01.760181 118397 solver.cpp:236] Iteration 7060, loss = 0.617868
I0728 22:14:01.760377 118397 solver.cpp:252]     Train net output #0: loss = 0.634307 (* 1 = 0.634307 loss)
I0728 22:14:01.760417 118397 sgd_solver.cpp:106] Iteration 7060, lr = 0.009
I0728 22:14:29.902165 118397 solver.cpp:236] Iteration 7070, loss = 0.623957
I0728 22:14:29.902232 118397 solver.cpp:252]     Train net output #0: loss = 0.635675 (* 1 = 0.635675 loss)
I0728 22:14:29.902247 118397 sgd_solver.cpp:106] Iteration 7070, lr = 0.009
I0728 22:14:54.492872 118397 solver.cpp:236] Iteration 7080, loss = 0.625927
I0728 22:14:54.493060 118397 solver.cpp:252]     Train net output #0: loss = 0.636609 (* 1 = 0.636609 loss)
I0728 22:14:54.493108 118397 sgd_solver.cpp:106] Iteration 7080, lr = 0.009
I0728 22:15:28.523736 118397 solver.cpp:236] Iteration 7090, loss = 0.621701
I0728 22:15:28.523871 118397 solver.cpp:252]     Train net output #0: loss = 0.654918 (* 1 = 0.654918 loss)
I0728 22:15:28.523886 118397 sgd_solver.cpp:106] Iteration 7090, lr = 0.009
I0728 22:15:54.645172 118397 solver.cpp:236] Iteration 7100, loss = 0.622218
I0728 22:15:54.645241 118397 solver.cpp:252]     Train net output #0: loss = 0.642141 (* 1 = 0.642141 loss)
I0728 22:15:54.645254 118397 sgd_solver.cpp:106] Iteration 7100, lr = 0.009
I0728 22:16:29.694082 118397 solver.cpp:236] Iteration 7110, loss = 0.624408
I0728 22:16:29.694208 118397 solver.cpp:252]     Train net output #0: loss = 0.62978 (* 1 = 0.62978 loss)
I0728 22:16:29.694227 118397 sgd_solver.cpp:106] Iteration 7110, lr = 0.009
I0728 22:17:03.190827 118397 solver.cpp:236] Iteration 7120, loss = 0.624361
I0728 22:17:03.190948 118397 solver.cpp:252]     Train net output #0: loss = 0.635796 (* 1 = 0.635796 loss)
I0728 22:17:03.190963 118397 sgd_solver.cpp:106] Iteration 7120, lr = 0.009
I0728 22:17:30.647795 118397 solver.cpp:236] Iteration 7130, loss = 0.62259
I0728 22:17:30.647866 118397 solver.cpp:252]     Train net output #0: loss = 0.681726 (* 1 = 0.681726 loss)
I0728 22:17:30.647881 118397 sgd_solver.cpp:106] Iteration 7130, lr = 0.009
I0728 22:18:00.315047 118397 solver.cpp:236] Iteration 7140, loss = 0.610516
I0728 22:18:00.315243 118397 solver.cpp:252]     Train net output #0: loss = 0.697038 (* 1 = 0.697038 loss)
I0728 22:18:00.315265 118397 sgd_solver.cpp:106] Iteration 7140, lr = 0.009
I0728 22:18:27.418598 118397 solver.cpp:236] Iteration 7150, loss = 0.610386
I0728 22:18:27.418678 118397 solver.cpp:252]     Train net output #0: loss = 0.635424 (* 1 = 0.635424 loss)
I0728 22:18:27.418691 118397 sgd_solver.cpp:106] Iteration 7150, lr = 0.009
I0728 22:18:58.368636 118397 solver.cpp:236] Iteration 7160, loss = 0.61168
I0728 22:18:58.368806 118397 solver.cpp:252]     Train net output #0: loss = 0.482715 (* 1 = 0.482715 loss)
I0728 22:18:58.368824 118397 sgd_solver.cpp:106] Iteration 7160, lr = 0.009
I0728 22:19:28.625227 118397 solver.cpp:236] Iteration 7170, loss = 0.609858
I0728 22:19:28.626868 118397 solver.cpp:252]     Train net output #0: loss = 0.664985 (* 1 = 0.664985 loss)
I0728 22:19:28.626884 118397 sgd_solver.cpp:106] Iteration 7170, lr = 0.009
I0728 22:19:58.047757 118397 solver.cpp:236] Iteration 7180, loss = 0.607769
I0728 22:19:58.047824 118397 solver.cpp:252]     Train net output #0: loss = 0.642894 (* 1 = 0.642894 loss)
I0728 22:19:58.047838 118397 sgd_solver.cpp:106] Iteration 7180, lr = 0.009
I0728 22:20:30.400260 118397 solver.cpp:236] Iteration 7190, loss = 0.612031
I0728 22:20:30.400465 118397 solver.cpp:252]     Train net output #0: loss = 0.639634 (* 1 = 0.639634 loss)
I0728 22:20:30.400495 118397 sgd_solver.cpp:106] Iteration 7190, lr = 0.009
I0728 22:21:02.419426 118397 solver.cpp:236] Iteration 7200, loss = 0.60896
I0728 22:21:02.419605 118397 solver.cpp:252]     Train net output #0: loss = 0.645083 (* 1 = 0.645083 loss)
I0728 22:21:02.419633 118397 sgd_solver.cpp:106] Iteration 7200, lr = 0.009
I0728 22:21:42.545627 118397 solver.cpp:236] Iteration 7210, loss = 0.610579
I0728 22:21:42.545856 118397 solver.cpp:252]     Train net output #0: loss = 0.643587 (* 1 = 0.643587 loss)
I0728 22:21:42.545877 118397 sgd_solver.cpp:106] Iteration 7210, lr = 0.009
I0728 22:22:14.413945 118397 solver.cpp:236] Iteration 7220, loss = 0.609052
I0728 22:22:14.414134 118397 solver.cpp:252]     Train net output #0: loss = 0.472749 (* 1 = 0.472749 loss)
I0728 22:22:14.414167 118397 sgd_solver.cpp:106] Iteration 7220, lr = 0.009
I0728 22:22:47.607434 118397 solver.cpp:236] Iteration 7230, loss = 0.604173
I0728 22:22:47.607592 118397 solver.cpp:252]     Train net output #0: loss = 0.200723 (* 1 = 0.200723 loss)
I0728 22:22:47.607614 118397 sgd_solver.cpp:106] Iteration 7230, lr = 0.009
I0728 22:23:23.078960 118397 solver.cpp:236] Iteration 7240, loss = 0.615071
I0728 22:23:23.079130 118397 solver.cpp:252]     Train net output #0: loss = 0.685334 (* 1 = 0.685334 loss)
I0728 22:23:23.079149 118397 sgd_solver.cpp:106] Iteration 7240, lr = 0.009
I0728 22:23:58.710580 118397 solver.cpp:236] Iteration 7250, loss = 0.617039
I0728 22:23:58.710832 118397 solver.cpp:252]     Train net output #0: loss = 0.527091 (* 1 = 0.527091 loss)
I0728 22:23:58.710852 118397 sgd_solver.cpp:106] Iteration 7250, lr = 0.009
I0728 22:24:32.167207 118397 solver.cpp:236] Iteration 7260, loss = 0.614034
I0728 22:24:32.167392 118397 solver.cpp:252]     Train net output #0: loss = 0.657721 (* 1 = 0.657721 loss)
I0728 22:24:32.167428 118397 sgd_solver.cpp:106] Iteration 7260, lr = 0.009
I0728 22:25:08.382777 118397 solver.cpp:236] Iteration 7270, loss = 0.611277
I0728 22:25:08.382958 118397 solver.cpp:252]     Train net output #0: loss = 0.286615 (* 1 = 0.286615 loss)
I0728 22:25:08.382984 118397 sgd_solver.cpp:106] Iteration 7270, lr = 0.009
I0728 22:25:47.514925 118397 solver.cpp:236] Iteration 7280, loss = 0.613673
I0728 22:25:47.515120 118397 solver.cpp:252]     Train net output #0: loss = 0.634302 (* 1 = 0.634302 loss)
I0728 22:25:47.515146 118397 sgd_solver.cpp:106] Iteration 7280, lr = 0.009
I0728 22:26:18.383543 118397 solver.cpp:236] Iteration 7290, loss = 0.611587
I0728 22:26:18.383750 118397 solver.cpp:252]     Train net output #0: loss = 0.641002 (* 1 = 0.641002 loss)
I0728 22:26:18.383767 118397 sgd_solver.cpp:106] Iteration 7290, lr = 0.009
I0728 22:26:57.063324 118397 solver.cpp:236] Iteration 7300, loss = 0.613743
I0728 22:26:57.067085 118397 solver.cpp:252]     Train net output #0: loss = 0.650321 (* 1 = 0.650321 loss)
I0728 22:26:57.067112 118397 sgd_solver.cpp:106] Iteration 7300, lr = 0.009
I0728 22:27:35.820679 118397 solver.cpp:236] Iteration 7310, loss = 0.609787
I0728 22:27:35.820837 118397 solver.cpp:252]     Train net output #0: loss = 0.63865 (* 1 = 0.63865 loss)
I0728 22:27:35.820854 118397 sgd_solver.cpp:106] Iteration 7310, lr = 0.009
I0728 22:28:11.961150 118397 solver.cpp:236] Iteration 7320, loss = 0.608811
I0728 22:28:11.961310 118397 solver.cpp:252]     Train net output #0: loss = 0.64256 (* 1 = 0.64256 loss)
I0728 22:28:11.961333 118397 sgd_solver.cpp:106] Iteration 7320, lr = 0.009
I0728 22:28:45.660821 118397 solver.cpp:236] Iteration 7330, loss = 0.621648
I0728 22:28:45.660987 118397 solver.cpp:252]     Train net output #0: loss = 0.635996 (* 1 = 0.635996 loss)
I0728 22:28:45.661005 118397 sgd_solver.cpp:106] Iteration 7330, lr = 0.009
I0728 22:29:15.408591 118397 solver.cpp:236] Iteration 7340, loss = 0.614489
I0728 22:29:15.408656 118397 solver.cpp:252]     Train net output #0: loss = 0.659027 (* 1 = 0.659027 loss)
I0728 22:29:15.408670 118397 sgd_solver.cpp:106] Iteration 7340, lr = 0.009
I0728 22:29:46.413915 118397 solver.cpp:236] Iteration 7350, loss = 0.61556
I0728 22:29:46.414068 118397 solver.cpp:252]     Train net output #0: loss = 0.632437 (* 1 = 0.632437 loss)
I0728 22:29:46.414085 118397 sgd_solver.cpp:106] Iteration 7350, lr = 0.009
I0728 22:30:14.535387 118397 solver.cpp:236] Iteration 7360, loss = 0.615556
I0728 22:30:14.535456 118397 solver.cpp:252]     Train net output #0: loss = 0.641003 (* 1 = 0.641003 loss)
I0728 22:30:14.535470 118397 sgd_solver.cpp:106] Iteration 7360, lr = 0.009
I0728 22:30:49.754449 118397 solver.cpp:236] Iteration 7370, loss = 0.610684
I0728 22:30:49.754604 118397 solver.cpp:252]     Train net output #0: loss = 0.672291 (* 1 = 0.672291 loss)
I0728 22:30:49.754621 118397 sgd_solver.cpp:106] Iteration 7370, lr = 0.009
I0728 22:31:26.397569 118397 solver.cpp:236] Iteration 7380, loss = 0.605118
I0728 22:31:26.397711 118397 solver.cpp:252]     Train net output #0: loss = 0.652498 (* 1 = 0.652498 loss)
I0728 22:31:26.397727 118397 sgd_solver.cpp:106] Iteration 7380, lr = 0.009
I0728 22:31:56.047116 118397 solver.cpp:236] Iteration 7390, loss = 0.602208
I0728 22:31:56.047184 118397 solver.cpp:252]     Train net output #0: loss = 0.387825 (* 1 = 0.387825 loss)
I0728 22:31:56.047197 118397 sgd_solver.cpp:106] Iteration 7390, lr = 0.009
I0728 22:32:33.498322 118397 solver.cpp:236] Iteration 7400, loss = 0.602147
I0728 22:32:33.498549 118397 solver.cpp:252]     Train net output #0: loss = 0.344374 (* 1 = 0.344374 loss)
I0728 22:32:33.498565 118397 sgd_solver.cpp:106] Iteration 7400, lr = 0.009
I0728 22:33:08.652454 118397 solver.cpp:236] Iteration 7410, loss = 0.604765
I0728 22:33:08.652655 118397 solver.cpp:252]     Train net output #0: loss = 0.631596 (* 1 = 0.631596 loss)
I0728 22:33:08.652679 118397 sgd_solver.cpp:106] Iteration 7410, lr = 0.009
I0728 22:33:39.639742 118397 solver.cpp:236] Iteration 7420, loss = 0.601913
I0728 22:33:39.639897 118397 solver.cpp:252]     Train net output #0: loss = 0.358691 (* 1 = 0.358691 loss)
I0728 22:33:39.639916 118397 sgd_solver.cpp:106] Iteration 7420, lr = 0.009
I0728 22:34:08.762686 118397 solver.cpp:236] Iteration 7430, loss = 0.599391
I0728 22:34:08.762748 118397 solver.cpp:252]     Train net output #0: loss = 0.647611 (* 1 = 0.647611 loss)
I0728 22:34:08.762760 118397 sgd_solver.cpp:106] Iteration 7430, lr = 0.009
I0728 22:34:39.069631 118397 solver.cpp:236] Iteration 7440, loss = 0.59861
I0728 22:34:39.069799 118397 solver.cpp:252]     Train net output #0: loss = 0.655516 (* 1 = 0.655516 loss)
I0728 22:34:39.069829 118397 sgd_solver.cpp:106] Iteration 7440, lr = 0.009
I0728 22:35:18.053721 118397 solver.cpp:236] Iteration 7450, loss = 0.597853
I0728 22:35:18.053967 118397 solver.cpp:252]     Train net output #0: loss = 0.63983 (* 1 = 0.63983 loss)
I0728 22:35:18.053987 118397 sgd_solver.cpp:106] Iteration 7450, lr = 0.009
I0728 22:35:45.565246 118397 solver.cpp:236] Iteration 7460, loss = 0.5966
I0728 22:35:45.565310 118397 solver.cpp:252]     Train net output #0: loss = 0.688465 (* 1 = 0.688465 loss)
I0728 22:35:45.565325 118397 sgd_solver.cpp:106] Iteration 7460, lr = 0.009
I0728 22:36:21.662067 118397 solver.cpp:236] Iteration 7470, loss = 0.605017
I0728 22:36:21.662212 118397 solver.cpp:252]     Train net output #0: loss = 0.645184 (* 1 = 0.645184 loss)
I0728 22:36:21.662227 118397 sgd_solver.cpp:106] Iteration 7470, lr = 0.009
I0728 22:36:53.666595 118397 solver.cpp:236] Iteration 7480, loss = 0.607524
I0728 22:36:53.666791 118397 solver.cpp:252]     Train net output #0: loss = 0.638148 (* 1 = 0.638148 loss)
I0728 22:36:53.666810 118397 sgd_solver.cpp:106] Iteration 7480, lr = 0.009
I0728 22:37:31.820137 118397 solver.cpp:236] Iteration 7490, loss = 0.612283
I0728 22:37:31.820297 118397 solver.cpp:252]     Train net output #0: loss = 0.639964 (* 1 = 0.639964 loss)
I0728 22:37:31.820329 118397 sgd_solver.cpp:106] Iteration 7490, lr = 0.009
I0728 22:38:02.425724 118397 solver.cpp:340] Iteration 7500, Testing net (#0)
I0728 22:38:29.245825 118397 solver.cpp:408]     Test net output #0: accuracy = 0.7375
I0728 22:38:29.245898 118397 solver.cpp:408]     Test net output #1: loss = 0.584037 (* 1 = 0.584037 loss)
I0728 22:38:32.323477 118397 solver.cpp:236] Iteration 7500, loss = 0.614693
I0728 22:38:32.323544 118397 solver.cpp:252]     Train net output #0: loss = 0.629993 (* 1 = 0.629993 loss)
I0728 22:38:32.323560 118397 sgd_solver.cpp:106] Iteration 7500, lr = 0.009
I0728 22:39:07.697587 118397 solver.cpp:236] Iteration 7510, loss = 0.612111
I0728 22:39:07.697783 118397 solver.cpp:252]     Train net output #0: loss = 0.63979 (* 1 = 0.63979 loss)
I0728 22:39:07.697824 118397 sgd_solver.cpp:106] Iteration 7510, lr = 0.009
I0728 22:39:38.403445 118397 solver.cpp:236] Iteration 7520, loss = 0.60898
I0728 22:39:38.403599 118397 solver.cpp:252]     Train net output #0: loss = 0.679029 (* 1 = 0.679029 loss)
I0728 22:39:38.403616 118397 sgd_solver.cpp:106] Iteration 7520, lr = 0.009
I0728 22:40:10.683069 118397 solver.cpp:236] Iteration 7530, loss = 0.611055
I0728 22:40:10.683336 118397 solver.cpp:252]     Train net output #0: loss = 0.398795 (* 1 = 0.398795 loss)
I0728 22:40:10.683358 118397 sgd_solver.cpp:106] Iteration 7530, lr = 0.009
I0728 22:40:41.396675 118397 solver.cpp:236] Iteration 7540, loss = 0.613959
I0728 22:40:41.396832 118397 solver.cpp:252]     Train net output #0: loss = 0.638382 (* 1 = 0.638382 loss)
I0728 22:40:41.396850 118397 sgd_solver.cpp:106] Iteration 7540, lr = 0.009
I0728 22:41:10.832770 118397 solver.cpp:236] Iteration 7550, loss = 0.608957
I0728 22:41:10.832854 118397 solver.cpp:252]     Train net output #0: loss = 0.663902 (* 1 = 0.663902 loss)
I0728 22:41:10.832878 118397 sgd_solver.cpp:106] Iteration 7550, lr = 0.009
I0728 22:41:44.983801 118397 solver.cpp:236] Iteration 7560, loss = 0.615166
I0728 22:41:44.983954 118397 solver.cpp:252]     Train net output #0: loss = 0.640164 (* 1 = 0.640164 loss)
I0728 22:41:44.983969 118397 sgd_solver.cpp:106] Iteration 7560, lr = 0.009
I0728 22:42:17.628283 118397 solver.cpp:236] Iteration 7570, loss = 0.614043
I0728 22:42:17.628476 118397 solver.cpp:252]     Train net output #0: loss = 0.439871 (* 1 = 0.439871 loss)
I0728 22:42:17.628500 118397 sgd_solver.cpp:106] Iteration 7570, lr = 0.009
I0728 22:42:49.845533 118397 solver.cpp:236] Iteration 7580, loss = 0.616944
I0728 22:42:49.845775 118397 solver.cpp:252]     Train net output #0: loss = 0.653392 (* 1 = 0.653392 loss)
I0728 22:42:49.845790 118397 sgd_solver.cpp:106] Iteration 7580, lr = 0.009
I0728 22:43:22.363955 118397 solver.cpp:236] Iteration 7590, loss = 0.612005
I0728 22:43:22.364224 118397 solver.cpp:252]     Train net output #0: loss = 0.378023 (* 1 = 0.378023 loss)
I0728 22:43:22.364259 118397 sgd_solver.cpp:106] Iteration 7590, lr = 0.009
I0728 22:43:54.085630 118397 solver.cpp:236] Iteration 7600, loss = 0.607153
I0728 22:43:54.085778 118397 solver.cpp:252]     Train net output #0: loss = 0.648233 (* 1 = 0.648233 loss)
I0728 22:43:54.085801 118397 sgd_solver.cpp:106] Iteration 7600, lr = 0.009
I0728 22:44:24.044857 118397 solver.cpp:236] Iteration 7610, loss = 0.607821
I0728 22:44:24.044925 118397 solver.cpp:252]     Train net output #0: loss = 0.656158 (* 1 = 0.656158 loss)
I0728 22:44:24.044939 118397 sgd_solver.cpp:106] Iteration 7610, lr = 0.009
I0728 22:44:53.412251 118397 solver.cpp:236] Iteration 7620, loss = 0.616316
I0728 22:44:53.412394 118397 solver.cpp:252]     Train net output #0: loss = 0.636843 (* 1 = 0.636843 loss)
I0728 22:44:53.412410 118397 sgd_solver.cpp:106] Iteration 7620, lr = 0.009
I0728 22:45:27.819639 118397 solver.cpp:236] Iteration 7630, loss = 0.615222
I0728 22:45:27.819803 118397 solver.cpp:252]     Train net output #0: loss = 0.639889 (* 1 = 0.639889 loss)
I0728 22:45:27.819820 118397 sgd_solver.cpp:106] Iteration 7630, lr = 0.009
I0728 22:46:06.281349 118397 solver.cpp:236] Iteration 7640, loss = 0.61208
I0728 22:46:06.281481 118397 solver.cpp:252]     Train net output #0: loss = 0.650071 (* 1 = 0.650071 loss)
I0728 22:46:06.281497 118397 sgd_solver.cpp:106] Iteration 7640, lr = 0.009
I0728 22:46:35.927783 118397 solver.cpp:236] Iteration 7650, loss = 0.61499
I0728 22:46:35.927846 118397 solver.cpp:252]     Train net output #0: loss = 0.640375 (* 1 = 0.640375 loss)
I0728 22:46:35.927861 118397 sgd_solver.cpp:106] Iteration 7650, lr = 0.009
I0728 22:47:13.852429 118397 solver.cpp:236] Iteration 7660, loss = 0.61154
I0728 22:47:13.852645 118397 solver.cpp:252]     Train net output #0: loss = 0.639978 (* 1 = 0.639978 loss)
I0728 22:47:13.852670 118397 sgd_solver.cpp:106] Iteration 7660, lr = 0.009
I0728 22:47:45.799741 118397 solver.cpp:236] Iteration 7670, loss = 0.607599
I0728 22:47:45.799988 118397 solver.cpp:252]     Train net output #0: loss = 0.330363 (* 1 = 0.330363 loss)
I0728 22:47:45.800007 118397 sgd_solver.cpp:106] Iteration 7670, lr = 0.009
I0728 22:48:18.675271 118397 solver.cpp:236] Iteration 7680, loss = 0.605262
I0728 22:48:18.675503 118397 solver.cpp:252]     Train net output #0: loss = 0.641295 (* 1 = 0.641295 loss)
I0728 22:48:18.675521 118397 sgd_solver.cpp:106] Iteration 7680, lr = 0.009
I0728 22:48:51.266688 118397 solver.cpp:236] Iteration 7690, loss = 0.604978
I0728 22:48:51.266867 118397 solver.cpp:252]     Train net output #0: loss = 0.359701 (* 1 = 0.359701 loss)
I0728 22:48:51.266898 118397 sgd_solver.cpp:106] Iteration 7690, lr = 0.009
I0728 22:49:21.770040 118397 solver.cpp:236] Iteration 7700, loss = 0.604409
I0728 22:49:21.770238 118397 solver.cpp:252]     Train net output #0: loss = 0.664835 (* 1 = 0.664835 loss)
I0728 22:49:21.770283 118397 sgd_solver.cpp:106] Iteration 7700, lr = 0.009
I0728 22:49:52.334939 118397 solver.cpp:236] Iteration 7710, loss = 0.607601
I0728 22:49:52.335176 118397 solver.cpp:252]     Train net output #0: loss = 0.636751 (* 1 = 0.636751 loss)
I0728 22:49:52.335196 118397 sgd_solver.cpp:106] Iteration 7710, lr = 0.009
I0728 22:50:24.592911 118397 solver.cpp:236] Iteration 7720, loss = 0.600516
I0728 22:50:24.593052 118397 solver.cpp:252]     Train net output #0: loss = 0.647677 (* 1 = 0.647677 loss)
I0728 22:50:24.593070 118397 sgd_solver.cpp:106] Iteration 7720, lr = 0.009
I0728 22:50:55.828188 118397 solver.cpp:236] Iteration 7730, loss = 0.603997
I0728 22:50:55.828369 118397 solver.cpp:252]     Train net output #0: loss = 0.641029 (* 1 = 0.641029 loss)
I0728 22:50:55.828392 118397 sgd_solver.cpp:106] Iteration 7730, lr = 0.009
I0728 22:51:29.504698 118397 solver.cpp:236] Iteration 7740, loss = 0.607324
I0728 22:51:29.504883 118397 solver.cpp:252]     Train net output #0: loss = 0.633165 (* 1 = 0.633165 loss)
I0728 22:51:29.504922 118397 sgd_solver.cpp:106] Iteration 7740, lr = 0.009
I0728 22:52:04.411355 118397 solver.cpp:236] Iteration 7750, loss = 0.606902
I0728 22:52:04.411572 118397 solver.cpp:252]     Train net output #0: loss = 0.647447 (* 1 = 0.647447 loss)
I0728 22:52:04.411592 118397 sgd_solver.cpp:106] Iteration 7750, lr = 0.009
I0728 22:52:39.350922 118397 solver.cpp:236] Iteration 7760, loss = 0.609584
I0728 22:52:39.351142 118397 solver.cpp:252]     Train net output #0: loss = 0.629921 (* 1 = 0.629921 loss)
I0728 22:52:39.351173 118397 sgd_solver.cpp:106] Iteration 7760, lr = 0.009
I0728 22:53:13.778080 118397 solver.cpp:236] Iteration 7770, loss = 0.610715
I0728 22:53:13.778231 118397 solver.cpp:252]     Train net output #0: loss = 0.642261 (* 1 = 0.642261 loss)
I0728 22:53:13.778259 118397 sgd_solver.cpp:106] Iteration 7770, lr = 0.009
I0728 22:53:53.399132 118397 solver.cpp:236] Iteration 7780, loss = 0.608139
I0728 22:53:53.399307 118397 solver.cpp:252]     Train net output #0: loss = 0.657206 (* 1 = 0.657206 loss)
I0728 22:53:53.399354 118397 sgd_solver.cpp:106] Iteration 7780, lr = 0.009
I0728 22:54:31.624073 118397 solver.cpp:236] Iteration 7790, loss = 0.614508
I0728 22:54:31.624213 118397 solver.cpp:252]     Train net output #0: loss = 0.631234 (* 1 = 0.631234 loss)
I0728 22:54:31.624230 118397 sgd_solver.cpp:106] Iteration 7790, lr = 0.009
I0728 22:55:06.023279 118397 solver.cpp:236] Iteration 7800, loss = 0.615834
I0728 22:55:06.023424 118397 solver.cpp:252]     Train net output #0: loss = 0.643561 (* 1 = 0.643561 loss)
I0728 22:55:06.023442 118397 sgd_solver.cpp:106] Iteration 7800, lr = 0.009
I0728 22:55:40.145314 118397 solver.cpp:236] Iteration 7810, loss = 0.608689
I0728 22:55:40.145474 118397 solver.cpp:252]     Train net output #0: loss = 0.652754 (* 1 = 0.652754 loss)
I0728 22:55:40.145490 118397 sgd_solver.cpp:106] Iteration 7810, lr = 0.009
I0728 22:56:13.859285 118397 solver.cpp:236] Iteration 7820, loss = 0.613653
I0728 22:56:13.859427 118397 solver.cpp:252]     Train net output #0: loss = 0.637527 (* 1 = 0.637527 loss)
I0728 22:56:13.859443 118397 sgd_solver.cpp:106] Iteration 7820, lr = 0.009
I0728 22:56:50.853354 118397 solver.cpp:236] Iteration 7830, loss = 0.611536
I0728 22:56:50.853514 118397 solver.cpp:252]     Train net output #0: loss = 0.638223 (* 1 = 0.638223 loss)
I0728 22:56:50.853531 118397 sgd_solver.cpp:106] Iteration 7830, lr = 0.009
I0728 22:57:21.532454 118397 solver.cpp:236] Iteration 7840, loss = 0.613427
I0728 22:57:21.532598 118397 solver.cpp:252]     Train net output #0: loss = 0.645613 (* 1 = 0.645613 loss)
I0728 22:57:21.532629 118397 sgd_solver.cpp:106] Iteration 7840, lr = 0.009
I0728 22:57:51.028642 118397 solver.cpp:236] Iteration 7850, loss = 0.606946
I0728 22:57:51.028715 118397 solver.cpp:252]     Train net output #0: loss = 0.272268 (* 1 = 0.272268 loss)
I0728 22:57:51.028729 118397 sgd_solver.cpp:106] Iteration 7850, lr = 0.009
I0728 22:58:24.253545 118397 solver.cpp:236] Iteration 7860, loss = 0.603631
I0728 22:58:24.253703 118397 solver.cpp:252]     Train net output #0: loss = 0.684955 (* 1 = 0.684955 loss)
I0728 22:58:24.253720 118397 sgd_solver.cpp:106] Iteration 7860, lr = 0.009
I0728 22:58:55.341495 118397 solver.cpp:236] Iteration 7870, loss = 0.608974
I0728 22:58:55.341743 118397 solver.cpp:252]     Train net output #0: loss = 0.650767 (* 1 = 0.650767 loss)
I0728 22:58:55.341760 118397 sgd_solver.cpp:106] Iteration 7870, lr = 0.009
I0728 22:59:26.205950 118397 solver.cpp:236] Iteration 7880, loss = 0.613141
I0728 22:59:26.206127 118397 solver.cpp:252]     Train net output #0: loss = 0.635233 (* 1 = 0.635233 loss)
I0728 22:59:26.206146 118397 sgd_solver.cpp:106] Iteration 7880, lr = 0.009
I0728 22:59:57.355697 118397 solver.cpp:236] Iteration 7890, loss = 0.606854
I0728 22:59:57.355926 118397 solver.cpp:252]     Train net output #0: loss = 0.668024 (* 1 = 0.668024 loss)
I0728 22:59:57.355955 118397 sgd_solver.cpp:106] Iteration 7890, lr = 0.009
I0728 23:00:29.927690 118397 solver.cpp:236] Iteration 7900, loss = 0.605606
I0728 23:00:29.927851 118397 solver.cpp:252]     Train net output #0: loss = 0.651085 (* 1 = 0.651085 loss)
I0728 23:00:29.927871 118397 sgd_solver.cpp:106] Iteration 7900, lr = 0.009
I0728 23:00:58.441304 118397 solver.cpp:236] Iteration 7910, loss = 0.608825
I0728 23:00:58.441377 118397 solver.cpp:252]     Train net output #0: loss = 0.635876 (* 1 = 0.635876 loss)
I0728 23:00:58.441393 118397 sgd_solver.cpp:106] Iteration 7910, lr = 0.009
I0728 23:01:31.524421 118397 solver.cpp:236] Iteration 7920, loss = 0.611012
I0728 23:01:31.524711 118397 solver.cpp:252]     Train net output #0: loss = 0.641156 (* 1 = 0.641156 loss)
I0728 23:01:31.524727 118397 sgd_solver.cpp:106] Iteration 7920, lr = 0.009
I0728 23:02:03.475962 118397 solver.cpp:236] Iteration 7930, loss = 0.60863
I0728 23:02:03.476197 118397 solver.cpp:252]     Train net output #0: loss = 0.640641 (* 1 = 0.640641 loss)
I0728 23:02:03.476222 118397 sgd_solver.cpp:106] Iteration 7930, lr = 0.009
I0728 23:02:36.661564 118397 solver.cpp:236] Iteration 7940, loss = 0.609321
I0728 23:02:36.661782 118397 solver.cpp:252]     Train net output #0: loss = 0.639242 (* 1 = 0.639242 loss)
I0728 23:02:36.661800 118397 sgd_solver.cpp:106] Iteration 7940, lr = 0.009
I0728 23:03:12.677979 118397 solver.cpp:236] Iteration 7950, loss = 0.615858
I0728 23:03:12.678205 118397 solver.cpp:252]     Train net output #0: loss = 0.63743 (* 1 = 0.63743 loss)
I0728 23:03:12.678234 118397 sgd_solver.cpp:106] Iteration 7950, lr = 0.009
I0728 23:03:43.666960 118397 solver.cpp:236] Iteration 7960, loss = 0.616736
I0728 23:03:43.667210 118397 solver.cpp:252]     Train net output #0: loss = 0.642865 (* 1 = 0.642865 loss)
I0728 23:03:43.667225 118397 sgd_solver.cpp:106] Iteration 7960, lr = 0.009
I0728 23:04:15.770386 118397 solver.cpp:236] Iteration 7970, loss = 0.615806
I0728 23:04:15.770542 118397 solver.cpp:252]     Train net output #0: loss = 0.628642 (* 1 = 0.628642 loss)
I0728 23:04:15.770560 118397 sgd_solver.cpp:106] Iteration 7970, lr = 0.009
I0728 23:04:46.643636 118397 solver.cpp:236] Iteration 7980, loss = 0.614377
I0728 23:04:46.643836 118397 solver.cpp:252]     Train net output #0: loss = 0.638502 (* 1 = 0.638502 loss)
I0728 23:04:46.643859 118397 sgd_solver.cpp:106] Iteration 7980, lr = 0.009
I0728 23:05:18.869765 118397 solver.cpp:236] Iteration 7990, loss = 0.617022
I0728 23:05:18.869915 118397 solver.cpp:252]     Train net output #0: loss = 0.643336 (* 1 = 0.643336 loss)
I0728 23:05:18.869930 118397 sgd_solver.cpp:106] Iteration 7990, lr = 0.009
I0728 23:05:48.451632 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_8000.caffemodel
I0728 23:05:48.561813 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_8000.solverstate
I0728 23:05:48.565839 118397 solver.cpp:340] Iteration 8000, Testing net (#0)
I0728 23:06:20.204218 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 23:06:20.204444 118397 solver.cpp:408]     Test net output #1: loss = 0.607668 (* 1 = 0.607668 loss)
I0728 23:06:22.322377 118397 solver.cpp:236] Iteration 8000, loss = 0.620279
I0728 23:06:22.322454 118397 solver.cpp:252]     Train net output #0: loss = 0.637938 (* 1 = 0.637938 loss)
I0728 23:06:22.322471 118397 sgd_solver.cpp:106] Iteration 8000, lr = 0.009
I0728 23:06:52.621767 118397 solver.cpp:236] Iteration 8010, loss = 0.620036
I0728 23:06:52.621959 118397 solver.cpp:252]     Train net output #0: loss = 0.636312 (* 1 = 0.636312 loss)
I0728 23:06:52.621979 118397 sgd_solver.cpp:106] Iteration 8010, lr = 0.009
I0728 23:07:21.813004 118397 solver.cpp:236] Iteration 8020, loss = 0.607285
I0728 23:07:21.813069 118397 solver.cpp:252]     Train net output #0: loss = 0.709636 (* 1 = 0.709636 loss)
I0728 23:07:21.813084 118397 sgd_solver.cpp:106] Iteration 8020, lr = 0.009
I0728 23:07:56.063230 118397 solver.cpp:236] Iteration 8030, loss = 0.605335
I0728 23:07:56.063429 118397 solver.cpp:252]     Train net output #0: loss = 0.657326 (* 1 = 0.657326 loss)
I0728 23:07:56.063449 118397 sgd_solver.cpp:106] Iteration 8030, lr = 0.009
I0728 23:08:22.617108 118397 solver.cpp:236] Iteration 8040, loss = 0.605252
I0728 23:08:22.617177 118397 solver.cpp:252]     Train net output #0: loss = 0.651387 (* 1 = 0.651387 loss)
I0728 23:08:22.617192 118397 sgd_solver.cpp:106] Iteration 8040, lr = 0.009
I0728 23:08:54.751833 118397 solver.cpp:236] Iteration 8050, loss = 0.600043
I0728 23:08:54.752169 118397 solver.cpp:252]     Train net output #0: loss = 0.295343 (* 1 = 0.295343 loss)
I0728 23:08:54.752189 118397 sgd_solver.cpp:106] Iteration 8050, lr = 0.009
I0728 23:09:24.612651 118397 solver.cpp:236] Iteration 8060, loss = 0.602667
I0728 23:09:24.612732 118397 solver.cpp:252]     Train net output #0: loss = 0.270038 (* 1 = 0.270038 loss)
I0728 23:09:24.612746 118397 sgd_solver.cpp:106] Iteration 8060, lr = 0.009
I0728 23:09:51.145066 118397 solver.cpp:236] Iteration 8070, loss = 0.603245
I0728 23:09:51.145298 118397 solver.cpp:252]     Train net output #0: loss = 0.637795 (* 1 = 0.637795 loss)
I0728 23:09:51.145320 118397 sgd_solver.cpp:106] Iteration 8070, lr = 0.009
I0728 23:10:21.549480 118397 solver.cpp:236] Iteration 8080, loss = 0.600994
I0728 23:10:21.549700 118397 solver.cpp:252]     Train net output #0: loss = 0.37181 (* 1 = 0.37181 loss)
I0728 23:10:21.549736 118397 sgd_solver.cpp:106] Iteration 8080, lr = 0.009
I0728 23:10:56.360404 118397 solver.cpp:236] Iteration 8090, loss = 0.599855
I0728 23:10:56.360561 118397 solver.cpp:252]     Train net output #0: loss = 0.689063 (* 1 = 0.689063 loss)
I0728 23:10:56.360591 118397 sgd_solver.cpp:106] Iteration 8090, lr = 0.009
I0728 23:11:29.170032 118397 solver.cpp:236] Iteration 8100, loss = 0.599945
I0728 23:11:29.170203 118397 solver.cpp:252]     Train net output #0: loss = 0.637053 (* 1 = 0.637053 loss)
I0728 23:11:29.170225 118397 sgd_solver.cpp:106] Iteration 8100, lr = 0.009
I0728 23:11:57.733513 118397 solver.cpp:236] Iteration 8110, loss = 0.598188
I0728 23:11:57.733571 118397 solver.cpp:252]     Train net output #0: loss = 0.637586 (* 1 = 0.637586 loss)
I0728 23:11:57.733583 118397 sgd_solver.cpp:106] Iteration 8110, lr = 0.009
I0728 23:12:29.948103 118397 solver.cpp:236] Iteration 8120, loss = 0.611138
I0728 23:12:29.948246 118397 solver.cpp:252]     Train net output #0: loss = 0.631985 (* 1 = 0.631985 loss)
I0728 23:12:29.948261 118397 sgd_solver.cpp:106] Iteration 8120, lr = 0.009
I0728 23:12:56.115815 118397 solver.cpp:236] Iteration 8130, loss = 0.610679
I0728 23:12:56.115875 118397 solver.cpp:252]     Train net output #0: loss = 0.352761 (* 1 = 0.352761 loss)
I0728 23:12:56.115890 118397 sgd_solver.cpp:106] Iteration 8130, lr = 0.009
I0728 23:13:31.017053 118397 solver.cpp:236] Iteration 8140, loss = 0.610999
I0728 23:13:31.017181 118397 solver.cpp:252]     Train net output #0: loss = 0.633463 (* 1 = 0.633463 loss)
I0728 23:13:31.017199 118397 sgd_solver.cpp:106] Iteration 8140, lr = 0.009
I0728 23:14:00.624944 118397 solver.cpp:236] Iteration 8150, loss = 0.616127
I0728 23:14:00.625015 118397 solver.cpp:252]     Train net output #0: loss = 0.633808 (* 1 = 0.633808 loss)
I0728 23:14:00.625032 118397 sgd_solver.cpp:106] Iteration 8150, lr = 0.009
I0728 23:14:30.014407 118397 solver.cpp:236] Iteration 8160, loss = 0.610424
I0728 23:14:30.014554 118397 solver.cpp:252]     Train net output #0: loss = 0.643849 (* 1 = 0.643849 loss)
I0728 23:14:30.014574 118397 sgd_solver.cpp:106] Iteration 8160, lr = 0.009
I0728 23:15:05.553566 118397 solver.cpp:236] Iteration 8170, loss = 0.608056
I0728 23:15:05.553761 118397 solver.cpp:252]     Train net output #0: loss = 0.642342 (* 1 = 0.642342 loss)
I0728 23:15:05.553784 118397 sgd_solver.cpp:106] Iteration 8170, lr = 0.009
I0728 23:15:34.403203 118397 solver.cpp:236] Iteration 8180, loss = 0.606861
I0728 23:15:34.403273 118397 solver.cpp:252]     Train net output #0: loss = 0.640021 (* 1 = 0.640021 loss)
I0728 23:15:34.403290 118397 sgd_solver.cpp:106] Iteration 8180, lr = 0.009
I0728 23:16:05.594391 118397 solver.cpp:236] Iteration 8190, loss = 0.608092
I0728 23:16:05.594528 118397 solver.cpp:252]     Train net output #0: loss = 0.642323 (* 1 = 0.642323 loss)
I0728 23:16:05.594545 118397 sgd_solver.cpp:106] Iteration 8190, lr = 0.009
I0728 23:16:43.521872 118397 solver.cpp:236] Iteration 8200, loss = 0.610084
I0728 23:16:43.522094 118397 solver.cpp:252]     Train net output #0: loss = 0.633045 (* 1 = 0.633045 loss)
I0728 23:16:43.522117 118397 sgd_solver.cpp:106] Iteration 8200, lr = 0.009
I0728 23:17:15.816030 118397 solver.cpp:236] Iteration 8210, loss = 0.614376
I0728 23:17:15.816191 118397 solver.cpp:252]     Train net output #0: loss = 0.632934 (* 1 = 0.632934 loss)
I0728 23:17:15.816221 118397 sgd_solver.cpp:106] Iteration 8210, lr = 0.009
I0728 23:17:47.560588 118397 solver.cpp:236] Iteration 8220, loss = 0.606495
I0728 23:17:47.560740 118397 solver.cpp:252]     Train net output #0: loss = 0.262768 (* 1 = 0.262768 loss)
I0728 23:17:47.560766 118397 sgd_solver.cpp:106] Iteration 8220, lr = 0.009
I0728 23:18:15.732527 118397 solver.cpp:236] Iteration 8230, loss = 0.597824
I0728 23:18:15.732592 118397 solver.cpp:252]     Train net output #0: loss = 0.692423 (* 1 = 0.692423 loss)
I0728 23:18:15.732607 118397 sgd_solver.cpp:106] Iteration 8230, lr = 0.009
I0728 23:18:50.561483 118397 solver.cpp:236] Iteration 8240, loss = 0.60033
I0728 23:18:50.561630 118397 solver.cpp:252]     Train net output #0: loss = 0.634232 (* 1 = 0.634232 loss)
I0728 23:18:50.561664 118397 sgd_solver.cpp:106] Iteration 8240, lr = 0.009
I0728 23:19:22.623581 118397 solver.cpp:236] Iteration 8250, loss = 0.603591
I0728 23:19:22.623793 118397 solver.cpp:252]     Train net output #0: loss = 0.643964 (* 1 = 0.643964 loss)
I0728 23:19:22.623822 118397 sgd_solver.cpp:106] Iteration 8250, lr = 0.009
I0728 23:19:55.509954 118397 solver.cpp:236] Iteration 8260, loss = 0.606674
I0728 23:19:55.510190 118397 solver.cpp:252]     Train net output #0: loss = 0.652541 (* 1 = 0.652541 loss)
I0728 23:19:55.510215 118397 sgd_solver.cpp:106] Iteration 8260, lr = 0.009
I0728 23:20:21.009160 118397 solver.cpp:236] Iteration 8270, loss = 0.606301
I0728 23:20:21.009238 118397 solver.cpp:252]     Train net output #0: loss = 0.640008 (* 1 = 0.640008 loss)
I0728 23:20:21.009254 118397 sgd_solver.cpp:106] Iteration 8270, lr = 0.009
I0728 23:20:51.696873 118397 solver.cpp:236] Iteration 8280, loss = 0.609301
I0728 23:20:51.697058 118397 solver.cpp:252]     Train net output #0: loss = 0.643817 (* 1 = 0.643817 loss)
I0728 23:20:51.697077 118397 sgd_solver.cpp:106] Iteration 8280, lr = 0.009
I0728 23:21:21.880043 118397 solver.cpp:236] Iteration 8290, loss = 0.606349
I0728 23:21:21.880180 118397 solver.cpp:252]     Train net output #0: loss = 0.333067 (* 1 = 0.333067 loss)
I0728 23:21:21.880197 118397 sgd_solver.cpp:106] Iteration 8290, lr = 0.009
I0728 23:21:55.994927 118397 solver.cpp:236] Iteration 8300, loss = 0.604883
I0728 23:21:55.995100 118397 solver.cpp:252]     Train net output #0: loss = 0.651406 (* 1 = 0.651406 loss)
I0728 23:21:55.995131 118397 sgd_solver.cpp:106] Iteration 8300, lr = 0.009
I0728 23:22:26.793617 118397 solver.cpp:236] Iteration 8310, loss = 0.605106
I0728 23:22:26.793810 118397 solver.cpp:252]     Train net output #0: loss = 0.636799 (* 1 = 0.636799 loss)
I0728 23:22:26.793849 118397 sgd_solver.cpp:106] Iteration 8310, lr = 0.009
I0728 23:22:59.628432 118397 solver.cpp:236] Iteration 8320, loss = 0.610986
I0728 23:22:59.628564 118397 solver.cpp:252]     Train net output #0: loss = 0.639787 (* 1 = 0.639787 loss)
I0728 23:22:59.628581 118397 sgd_solver.cpp:106] Iteration 8320, lr = 0.009
I0728 23:23:26.719821 118397 solver.cpp:236] Iteration 8330, loss = 0.621955
I0728 23:23:26.719894 118397 solver.cpp:252]     Train net output #0: loss = 0.638218 (* 1 = 0.638218 loss)
I0728 23:23:26.719913 118397 sgd_solver.cpp:106] Iteration 8330, lr = 0.009
I0728 23:23:59.620474 118397 solver.cpp:236] Iteration 8340, loss = 0.613244
I0728 23:23:59.620621 118397 solver.cpp:252]     Train net output #0: loss = 0.657365 (* 1 = 0.657365 loss)
I0728 23:23:59.620656 118397 sgd_solver.cpp:106] Iteration 8340, lr = 0.009
I0728 23:24:26.038486 118397 solver.cpp:236] Iteration 8350, loss = 0.613323
I0728 23:24:26.038561 118397 solver.cpp:252]     Train net output #0: loss = 0.640411 (* 1 = 0.640411 loss)
I0728 23:24:26.038578 118397 sgd_solver.cpp:106] Iteration 8350, lr = 0.009
I0728 23:24:56.502418 118397 solver.cpp:236] Iteration 8360, loss = 0.615839
I0728 23:24:56.502643 118397 solver.cpp:252]     Train net output #0: loss = 0.636482 (* 1 = 0.636482 loss)
I0728 23:24:56.502665 118397 sgd_solver.cpp:106] Iteration 8360, lr = 0.009
I0728 23:25:22.629199 118397 solver.cpp:236] Iteration 8370, loss = 0.61773
I0728 23:25:22.629277 118397 solver.cpp:252]     Train net output #0: loss = 0.631275 (* 1 = 0.631275 loss)
I0728 23:25:22.629292 118397 sgd_solver.cpp:106] Iteration 8370, lr = 0.009
I0728 23:25:57.913333 118397 solver.cpp:236] Iteration 8380, loss = 0.617732
I0728 23:25:57.913513 118397 solver.cpp:252]     Train net output #0: loss = 0.640593 (* 1 = 0.640593 loss)
I0728 23:25:57.913530 118397 sgd_solver.cpp:106] Iteration 8380, lr = 0.009
I0728 23:26:29.190817 118397 solver.cpp:236] Iteration 8390, loss = 0.614149
I0728 23:26:29.191148 118397 solver.cpp:252]     Train net output #0: loss = 0.669154 (* 1 = 0.669154 loss)
I0728 23:26:29.191184 118397 sgd_solver.cpp:106] Iteration 8390, lr = 0.009
I0728 23:27:02.821043 118397 solver.cpp:236] Iteration 8400, loss = 0.614774
I0728 23:27:02.821244 118397 solver.cpp:252]     Train net output #0: loss = 0.649281 (* 1 = 0.649281 loss)
I0728 23:27:02.821259 118397 sgd_solver.cpp:106] Iteration 8400, lr = 0.009
I0728 23:27:32.542800 118397 solver.cpp:236] Iteration 8410, loss = 0.614736
I0728 23:27:32.542884 118397 solver.cpp:252]     Train net output #0: loss = 0.637992 (* 1 = 0.637992 loss)
I0728 23:27:32.542906 118397 sgd_solver.cpp:106] Iteration 8410, lr = 0.009
I0728 23:28:03.967203 118397 solver.cpp:236] Iteration 8420, loss = 0.61419
I0728 23:28:03.967414 118397 solver.cpp:252]     Train net output #0: loss = 0.638814 (* 1 = 0.638814 loss)
I0728 23:28:03.967444 118397 sgd_solver.cpp:106] Iteration 8420, lr = 0.009
I0728 23:28:32.508218 118397 solver.cpp:236] Iteration 8430, loss = 0.617684
I0728 23:28:32.508283 118397 solver.cpp:252]     Train net output #0: loss = 0.639527 (* 1 = 0.639527 loss)
I0728 23:28:32.508297 118397 sgd_solver.cpp:106] Iteration 8430, lr = 0.009
I0728 23:28:57.935227 118397 solver.cpp:236] Iteration 8440, loss = 0.621109
I0728 23:28:57.935448 118397 solver.cpp:252]     Train net output #0: loss = 0.635238 (* 1 = 0.635238 loss)
I0728 23:28:57.935467 118397 sgd_solver.cpp:106] Iteration 8440, lr = 0.009
I0728 23:29:20.227807 118397 solver.cpp:236] Iteration 8450, loss = 0.615377
I0728 23:29:20.227881 118397 solver.cpp:252]     Train net output #0: loss = 0.293761 (* 1 = 0.293761 loss)
I0728 23:29:20.227898 118397 sgd_solver.cpp:106] Iteration 8450, lr = 0.009
I0728 23:29:49.122649 118397 solver.cpp:236] Iteration 8460, loss = 0.612832
I0728 23:29:49.122884 118397 solver.cpp:252]     Train net output #0: loss = 0.642643 (* 1 = 0.642643 loss)
I0728 23:29:49.122902 118397 sgd_solver.cpp:106] Iteration 8460, lr = 0.009
I0728 23:30:17.475877 118397 solver.cpp:236] Iteration 8470, loss = 0.607821
I0728 23:30:17.475973 118397 solver.cpp:252]     Train net output #0: loss = 0.645907 (* 1 = 0.645907 loss)
I0728 23:30:17.475987 118397 sgd_solver.cpp:106] Iteration 8470, lr = 0.009
I0728 23:30:44.984298 118397 solver.cpp:236] Iteration 8480, loss = 0.610774
I0728 23:30:44.984434 118397 solver.cpp:252]     Train net output #0: loss = 0.631981 (* 1 = 0.631981 loss)
I0728 23:30:44.984459 118397 sgd_solver.cpp:106] Iteration 8480, lr = 0.009
I0728 23:31:10.373657 118397 solver.cpp:236] Iteration 8490, loss = 0.617904
I0728 23:31:10.373725 118397 solver.cpp:252]     Train net output #0: loss = 0.633081 (* 1 = 0.633081 loss)
I0728 23:31:10.373741 118397 sgd_solver.cpp:106] Iteration 8490, lr = 0.009
I0728 23:31:32.812765 118397 solver.cpp:340] Iteration 8500, Testing net (#0)
I0728 23:32:05.262585 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0728 23:32:05.262728 118397 solver.cpp:408]     Test net output #1: loss = 0.671394 (* 1 = 0.671394 loss)
I0728 23:32:07.064424 118397 solver.cpp:236] Iteration 8500, loss = 0.609655
I0728 23:32:07.064532 118397 solver.cpp:252]     Train net output #0: loss = 0.237768 (* 1 = 0.237768 loss)
I0728 23:32:07.064549 118397 sgd_solver.cpp:106] Iteration 8500, lr = 0.009
I0728 23:32:34.017570 118397 solver.cpp:236] Iteration 8510, loss = 0.60847
I0728 23:32:34.017632 118397 solver.cpp:252]     Train net output #0: loss = 0.641512 (* 1 = 0.641512 loss)
I0728 23:32:34.017645 118397 sgd_solver.cpp:106] Iteration 8510, lr = 0.009
I0728 23:33:04.549520 118397 solver.cpp:236] Iteration 8520, loss = 0.608615
I0728 23:33:04.549720 118397 solver.cpp:252]     Train net output #0: loss = 0.635703 (* 1 = 0.635703 loss)
I0728 23:33:04.549737 118397 sgd_solver.cpp:106] Iteration 8520, lr = 0.009
I0728 23:33:38.520603 118397 solver.cpp:236] Iteration 8530, loss = 0.605453
I0728 23:33:38.520788 118397 solver.cpp:252]     Train net output #0: loss = 0.641153 (* 1 = 0.641153 loss)
I0728 23:33:38.520817 118397 sgd_solver.cpp:106] Iteration 8530, lr = 0.009
I0728 23:34:09.969565 118397 solver.cpp:236] Iteration 8540, loss = 0.60758
I0728 23:34:09.969830 118397 solver.cpp:252]     Train net output #0: loss = 0.635671 (* 1 = 0.635671 loss)
I0728 23:34:09.969847 118397 sgd_solver.cpp:106] Iteration 8540, lr = 0.009
I0728 23:34:42.365938 118397 solver.cpp:236] Iteration 8550, loss = 0.607885
I0728 23:34:42.366120 118397 solver.cpp:252]     Train net output #0: loss = 0.649495 (* 1 = 0.649495 loss)
I0728 23:34:42.366137 118397 sgd_solver.cpp:106] Iteration 8550, lr = 0.009
I0728 23:35:10.598165 118397 solver.cpp:236] Iteration 8560, loss = 0.608158
I0728 23:35:10.598242 118397 solver.cpp:252]     Train net output #0: loss = 0.643694 (* 1 = 0.643694 loss)
I0728 23:35:10.598258 118397 sgd_solver.cpp:106] Iteration 8560, lr = 0.009
I0728 23:35:42.898833 118397 solver.cpp:236] Iteration 8570, loss = 0.610816
I0728 23:35:42.899080 118397 solver.cpp:252]     Train net output #0: loss = 0.633796 (* 1 = 0.633796 loss)
I0728 23:35:42.899098 118397 sgd_solver.cpp:106] Iteration 8570, lr = 0.009
I0728 23:36:09.564107 118397 solver.cpp:236] Iteration 8580, loss = 0.610447
I0728 23:36:09.564185 118397 solver.cpp:252]     Train net output #0: loss = 0.633859 (* 1 = 0.633859 loss)
I0728 23:36:09.564199 118397 sgd_solver.cpp:106] Iteration 8580, lr = 0.009
I0728 23:36:36.677422 118397 solver.cpp:236] Iteration 8590, loss = 0.61008
I0728 23:36:36.677613 118397 solver.cpp:252]     Train net output #0: loss = 0.640346 (* 1 = 0.640346 loss)
I0728 23:36:36.677641 118397 sgd_solver.cpp:106] Iteration 8590, lr = 0.009
I0728 23:37:09.223176 118397 solver.cpp:236] Iteration 8600, loss = 0.616955
I0728 23:37:09.223325 118397 solver.cpp:252]     Train net output #0: loss = 0.642767 (* 1 = 0.642767 loss)
I0728 23:37:09.223347 118397 sgd_solver.cpp:106] Iteration 8600, lr = 0.009
I0728 23:37:36.424243 118397 solver.cpp:236] Iteration 8610, loss = 0.612306
I0728 23:37:36.424309 118397 solver.cpp:252]     Train net output #0: loss = 0.642501 (* 1 = 0.642501 loss)
I0728 23:37:36.424325 118397 sgd_solver.cpp:106] Iteration 8610, lr = 0.009
I0728 23:38:04.134088 118397 solver.cpp:236] Iteration 8620, loss = 0.605224
I0728 23:38:04.134239 118397 solver.cpp:252]     Train net output #0: loss = 0.308537 (* 1 = 0.308537 loss)
I0728 23:38:04.134255 118397 sgd_solver.cpp:106] Iteration 8620, lr = 0.009
I0728 23:38:33.938349 118397 solver.cpp:236] Iteration 8630, loss = 0.605178
I0728 23:38:33.938412 118397 solver.cpp:252]     Train net output #0: loss = 0.640916 (* 1 = 0.640916 loss)
I0728 23:38:33.938426 118397 sgd_solver.cpp:106] Iteration 8630, lr = 0.009
I0728 23:39:00.295142 118397 solver.cpp:236] Iteration 8640, loss = 0.605001
I0728 23:39:00.295511 118397 solver.cpp:252]     Train net output #0: loss = 0.633074 (* 1 = 0.633074 loss)
I0728 23:39:00.295538 118397 sgd_solver.cpp:106] Iteration 8640, lr = 0.009
I0728 23:39:28.544934 118397 solver.cpp:236] Iteration 8650, loss = 0.609321
I0728 23:39:28.545006 118397 solver.cpp:252]     Train net output #0: loss = 0.633795 (* 1 = 0.633795 loss)
I0728 23:39:28.545019 118397 sgd_solver.cpp:106] Iteration 8650, lr = 0.009
I0728 23:40:02.669240 118397 solver.cpp:236] Iteration 8660, loss = 0.609003
I0728 23:40:02.669473 118397 solver.cpp:252]     Train net output #0: loss = 0.641492 (* 1 = 0.641492 loss)
I0728 23:40:02.669504 118397 sgd_solver.cpp:106] Iteration 8660, lr = 0.009
I0728 23:40:30.916213 118397 solver.cpp:236] Iteration 8670, loss = 0.598841
I0728 23:40:30.916290 118397 solver.cpp:252]     Train net output #0: loss = 0.67996 (* 1 = 0.67996 loss)
I0728 23:40:30.916308 118397 sgd_solver.cpp:106] Iteration 8670, lr = 0.009
I0728 23:41:06.015869 118397 solver.cpp:236] Iteration 8680, loss = 0.599614
I0728 23:41:06.016031 118397 solver.cpp:252]     Train net output #0: loss = 0.362463 (* 1 = 0.362463 loss)
I0728 23:41:06.016047 118397 sgd_solver.cpp:106] Iteration 8680, lr = 0.009
I0728 23:41:31.582800 118397 solver.cpp:236] Iteration 8690, loss = 0.599774
I0728 23:41:31.582876 118397 solver.cpp:252]     Train net output #0: loss = 0.632749 (* 1 = 0.632749 loss)
I0728 23:41:31.582892 118397 sgd_solver.cpp:106] Iteration 8690, lr = 0.009
I0728 23:42:04.201345 118397 solver.cpp:236] Iteration 8700, loss = 0.602302
I0728 23:42:04.201503 118397 solver.cpp:252]     Train net output #0: loss = 0.637421 (* 1 = 0.637421 loss)
I0728 23:42:04.201519 118397 sgd_solver.cpp:106] Iteration 8700, lr = 0.009
I0728 23:42:37.226799 118397 solver.cpp:236] Iteration 8710, loss = 0.605744
I0728 23:42:37.227063 118397 solver.cpp:252]     Train net output #0: loss = 0.637058 (* 1 = 0.637058 loss)
I0728 23:42:37.227087 118397 sgd_solver.cpp:106] Iteration 8710, lr = 0.009
I0728 23:43:07.168911 118397 solver.cpp:236] Iteration 8720, loss = 0.612397
I0728 23:43:07.168980 118397 solver.cpp:252]     Train net output #0: loss = 0.640864 (* 1 = 0.640864 loss)
I0728 23:43:07.168998 118397 sgd_solver.cpp:106] Iteration 8720, lr = 0.009
I0728 23:43:33.053310 118397 solver.cpp:236] Iteration 8730, loss = 0.609331
I0728 23:43:33.053477 118397 solver.cpp:252]     Train net output #0: loss = 0.655116 (* 1 = 0.655116 loss)
I0728 23:43:33.053498 118397 sgd_solver.cpp:106] Iteration 8730, lr = 0.009
I0728 23:44:00.902804 118397 solver.cpp:236] Iteration 8740, loss = 0.596566
I0728 23:44:00.902886 118397 solver.cpp:252]     Train net output #0: loss = 0.685752 (* 1 = 0.685752 loss)
I0728 23:44:00.902911 118397 sgd_solver.cpp:106] Iteration 8740, lr = 0.009
I0728 23:44:35.231027 118397 solver.cpp:236] Iteration 8750, loss = 0.599968
I0728 23:44:35.231207 118397 solver.cpp:252]     Train net output #0: loss = 0.639417 (* 1 = 0.639417 loss)
I0728 23:44:35.231236 118397 sgd_solver.cpp:106] Iteration 8750, lr = 0.009
I0728 23:45:07.856901 118397 solver.cpp:236] Iteration 8760, loss = 0.60295
I0728 23:45:07.857098 118397 solver.cpp:252]     Train net output #0: loss = 0.63718 (* 1 = 0.63718 loss)
I0728 23:45:07.857126 118397 sgd_solver.cpp:106] Iteration 8760, lr = 0.009
I0728 23:45:40.407599 118397 solver.cpp:236] Iteration 8770, loss = 0.612807
I0728 23:45:40.407753 118397 solver.cpp:252]     Train net output #0: loss = 0.354797 (* 1 = 0.354797 loss)
I0728 23:45:40.407773 118397 sgd_solver.cpp:106] Iteration 8770, lr = 0.009
I0728 23:46:09.830730 118397 solver.cpp:236] Iteration 8780, loss = 0.609681
I0728 23:46:09.830816 118397 solver.cpp:252]     Train net output #0: loss = 0.655634 (* 1 = 0.655634 loss)
I0728 23:46:09.830842 118397 sgd_solver.cpp:106] Iteration 8780, lr = 0.009
I0728 23:46:33.964385 118397 solver.cpp:236] Iteration 8790, loss = 0.610026
I0728 23:46:33.964553 118397 solver.cpp:252]     Train net output #0: loss = 0.427816 (* 1 = 0.427816 loss)
I0728 23:46:33.964570 118397 sgd_solver.cpp:106] Iteration 8790, lr = 0.009
I0728 23:47:06.428064 118397 solver.cpp:236] Iteration 8800, loss = 0.60795
I0728 23:47:06.428267 118397 solver.cpp:252]     Train net output #0: loss = 0.64871 (* 1 = 0.64871 loss)
I0728 23:47:06.428297 118397 sgd_solver.cpp:106] Iteration 8800, lr = 0.009
I0728 23:47:39.915084 118397 solver.cpp:236] Iteration 8810, loss = 0.610749
I0728 23:47:39.915248 118397 solver.cpp:252]     Train net output #0: loss = 0.636182 (* 1 = 0.636182 loss)
I0728 23:47:39.915269 118397 sgd_solver.cpp:106] Iteration 8810, lr = 0.009
I0728 23:48:11.102721 118397 solver.cpp:236] Iteration 8820, loss = 0.606657
I0728 23:48:11.103001 118397 solver.cpp:252]     Train net output #0: loss = 0.671345 (* 1 = 0.671345 loss)
I0728 23:48:11.103029 118397 sgd_solver.cpp:106] Iteration 8820, lr = 0.009
I0728 23:48:40.894018 118397 solver.cpp:236] Iteration 8830, loss = 0.613341
I0728 23:48:40.894089 118397 solver.cpp:252]     Train net output #0: loss = 0.639093 (* 1 = 0.639093 loss)
I0728 23:48:40.894105 118397 sgd_solver.cpp:106] Iteration 8830, lr = 0.009
I0728 23:49:15.248096 118397 solver.cpp:236] Iteration 8840, loss = 0.624232
I0728 23:49:15.248275 118397 solver.cpp:252]     Train net output #0: loss = 0.637599 (* 1 = 0.637599 loss)
I0728 23:49:15.248299 118397 sgd_solver.cpp:106] Iteration 8840, lr = 0.009
I0728 23:49:51.728832 118397 solver.cpp:236] Iteration 8850, loss = 0.621041
I0728 23:49:51.729034 118397 solver.cpp:252]     Train net output #0: loss = 0.639506 (* 1 = 0.639506 loss)
I0728 23:49:51.729063 118397 sgd_solver.cpp:106] Iteration 8850, lr = 0.009
I0728 23:50:23.419518 118397 solver.cpp:236] Iteration 8860, loss = 0.620284
I0728 23:50:23.419731 118397 solver.cpp:252]     Train net output #0: loss = 0.63064 (* 1 = 0.63064 loss)
I0728 23:50:23.419759 118397 sgd_solver.cpp:106] Iteration 8860, lr = 0.009
I0728 23:50:54.870420 118397 solver.cpp:236] Iteration 8870, loss = 0.623159
I0728 23:50:54.870594 118397 solver.cpp:252]     Train net output #0: loss = 0.635991 (* 1 = 0.635991 loss)
I0728 23:50:54.870618 118397 sgd_solver.cpp:106] Iteration 8870, lr = 0.009
I0728 23:51:21.010164 118397 solver.cpp:236] Iteration 8880, loss = 0.621473
I0728 23:51:21.010273 118397 solver.cpp:252]     Train net output #0: loss = 0.649793 (* 1 = 0.649793 loss)
I0728 23:51:21.010291 118397 sgd_solver.cpp:106] Iteration 8880, lr = 0.009
I0728 23:51:51.911772 118397 solver.cpp:236] Iteration 8890, loss = 0.620928
I0728 23:51:51.911947 118397 solver.cpp:252]     Train net output #0: loss = 0.6391 (* 1 = 0.6391 loss)
I0728 23:51:51.911967 118397 sgd_solver.cpp:106] Iteration 8890, lr = 0.009
I0728 23:52:19.152364 118397 solver.cpp:236] Iteration 8900, loss = 0.620164
I0728 23:52:19.152454 118397 solver.cpp:252]     Train net output #0: loss = 0.635953 (* 1 = 0.635953 loss)
I0728 23:52:19.152477 118397 sgd_solver.cpp:106] Iteration 8900, lr = 0.009
I0728 23:52:50.353091 118397 solver.cpp:236] Iteration 8910, loss = 0.617217
I0728 23:52:50.353237 118397 solver.cpp:252]     Train net output #0: loss = 0.63853 (* 1 = 0.63853 loss)
I0728 23:52:50.353253 118397 sgd_solver.cpp:106] Iteration 8910, lr = 0.009
I0728 23:53:21.467711 118397 solver.cpp:236] Iteration 8920, loss = 0.62371
I0728 23:53:21.467867 118397 solver.cpp:252]     Train net output #0: loss = 0.632044 (* 1 = 0.632044 loss)
I0728 23:53:21.467881 118397 sgd_solver.cpp:106] Iteration 8920, lr = 0.009
I0728 23:53:52.262622 118397 solver.cpp:236] Iteration 8930, loss = 0.622465
I0728 23:53:52.262883 118397 solver.cpp:252]     Train net output #0: loss = 0.635591 (* 1 = 0.635591 loss)
I0728 23:53:52.262899 118397 sgd_solver.cpp:106] Iteration 8930, lr = 0.009
I0728 23:54:19.613154 118397 solver.cpp:236] Iteration 8940, loss = 0.616514
I0728 23:54:19.613221 118397 solver.cpp:252]     Train net output #0: loss = 0.256582 (* 1 = 0.256582 loss)
I0728 23:54:19.613234 118397 sgd_solver.cpp:106] Iteration 8940, lr = 0.009
I0728 23:54:53.242049 118397 solver.cpp:236] Iteration 8950, loss = 0.612044
I0728 23:54:53.242198 118397 solver.cpp:252]     Train net output #0: loss = 0.659914 (* 1 = 0.659914 loss)
I0728 23:54:53.242213 118397 sgd_solver.cpp:106] Iteration 8950, lr = 0.009
I0728 23:55:30.712335 118397 solver.cpp:236] Iteration 8960, loss = 0.612619
I0728 23:55:30.712546 118397 solver.cpp:252]     Train net output #0: loss = 0.645965 (* 1 = 0.645965 loss)
I0728 23:55:30.712577 118397 sgd_solver.cpp:106] Iteration 8960, lr = 0.009
I0728 23:56:01.315474 118397 solver.cpp:236] Iteration 8970, loss = 0.60628
I0728 23:56:01.315745 118397 solver.cpp:252]     Train net output #0: loss = 0.663685 (* 1 = 0.663685 loss)
I0728 23:56:01.315768 118397 sgd_solver.cpp:106] Iteration 8970, lr = 0.009
I0728 23:56:32.461242 118397 solver.cpp:236] Iteration 8980, loss = 0.605821
I0728 23:56:32.461565 118397 solver.cpp:252]     Train net output #0: loss = 0.678229 (* 1 = 0.678229 loss)
I0728 23:56:32.461587 118397 sgd_solver.cpp:106] Iteration 8980, lr = 0.009
I0728 23:57:04.653549 118397 solver.cpp:236] Iteration 8990, loss = 0.602965
I0728 23:57:04.653687 118397 solver.cpp:252]     Train net output #0: loss = 0.640428 (* 1 = 0.640428 loss)
I0728 23:57:04.653704 118397 sgd_solver.cpp:106] Iteration 8990, lr = 0.009
I0728 23:57:34.487526 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_9000.caffemodel
I0728 23:57:34.584190 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_9000.solverstate
I0728 23:57:34.588126 118397 solver.cpp:340] Iteration 9000, Testing net (#0)
I0728 23:58:02.915102 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0728 23:58:02.915344 118397 solver.cpp:408]     Test net output #1: loss = 0.613711 (* 1 = 0.613711 loss)
I0728 23:58:06.155535 118397 solver.cpp:236] Iteration 9000, loss = 0.605737
I0728 23:58:06.155594 118397 solver.cpp:252]     Train net output #0: loss = 0.634649 (* 1 = 0.634649 loss)
I0728 23:58:06.155611 118397 sgd_solver.cpp:106] Iteration 9000, lr = 0.009
I0728 23:58:36.368713 118397 solver.cpp:236] Iteration 9010, loss = 0.60843
I0728 23:58:36.368943 118397 solver.cpp:252]     Train net output #0: loss = 0.637916 (* 1 = 0.637916 loss)
I0728 23:58:36.368973 118397 sgd_solver.cpp:106] Iteration 9010, lr = 0.009
I0728 23:59:02.044530 118397 solver.cpp:236] Iteration 9020, loss = 0.603731
I0728 23:59:02.044594 118397 solver.cpp:252]     Train net output #0: loss = 0.66529 (* 1 = 0.66529 loss)
I0728 23:59:02.044606 118397 sgd_solver.cpp:106] Iteration 9020, lr = 0.009
I0728 23:59:32.763167 118397 solver.cpp:236] Iteration 9030, loss = 0.598538
I0728 23:59:32.763388 118397 solver.cpp:252]     Train net output #0: loss = 0.642155 (* 1 = 0.642155 loss)
I0728 23:59:32.763416 118397 sgd_solver.cpp:106] Iteration 9030, lr = 0.009
I0729 00:00:03.821125 118397 solver.cpp:236] Iteration 9040, loss = 0.604138
I0729 00:00:03.821296 118397 solver.cpp:252]     Train net output #0: loss = 0.635404 (* 1 = 0.635404 loss)
I0729 00:00:03.821342 118397 sgd_solver.cpp:106] Iteration 9040, lr = 0.009
I0729 00:00:28.453930 118397 solver.cpp:236] Iteration 9050, loss = 0.601201
I0729 00:00:28.454007 118397 solver.cpp:252]     Train net output #0: loss = 0.68187 (* 1 = 0.68187 loss)
I0729 00:00:28.454026 118397 sgd_solver.cpp:106] Iteration 9050, lr = 0.009
I0729 00:01:00.890789 118397 solver.cpp:236] Iteration 9060, loss = 0.602541
I0729 00:01:00.891010 118397 solver.cpp:252]     Train net output #0: loss = 0.636253 (* 1 = 0.636253 loss)
I0729 00:01:00.891026 118397 sgd_solver.cpp:106] Iteration 9060, lr = 0.009
I0729 00:01:32.092068 118397 solver.cpp:236] Iteration 9070, loss = 0.609195
I0729 00:01:32.092260 118397 solver.cpp:252]     Train net output #0: loss = 0.64027 (* 1 = 0.64027 loss)
I0729 00:01:32.092285 118397 sgd_solver.cpp:106] Iteration 9070, lr = 0.009
I0729 00:02:08.587651 118397 solver.cpp:236] Iteration 9080, loss = 0.613703
I0729 00:02:08.587803 118397 solver.cpp:252]     Train net output #0: loss = 0.639746 (* 1 = 0.639746 loss)
I0729 00:02:08.587821 118397 sgd_solver.cpp:106] Iteration 9080, lr = 0.009
I0729 00:02:36.659828 118397 solver.cpp:236] Iteration 9090, loss = 0.616481
I0729 00:02:36.659889 118397 solver.cpp:252]     Train net output #0: loss = 0.637217 (* 1 = 0.637217 loss)
I0729 00:02:36.659904 118397 sgd_solver.cpp:106] Iteration 9090, lr = 0.009
I0729 00:03:08.673465 118397 solver.cpp:236] Iteration 9100, loss = 0.616548
I0729 00:03:08.673621 118397 solver.cpp:252]     Train net output #0: loss = 0.632447 (* 1 = 0.632447 loss)
I0729 00:03:08.673640 118397 sgd_solver.cpp:106] Iteration 9100, lr = 0.009
I0729 00:03:42.425586 118397 solver.cpp:236] Iteration 9110, loss = 0.616258
I0729 00:03:42.425856 118397 solver.cpp:252]     Train net output #0: loss = 0.63288 (* 1 = 0.63288 loss)
I0729 00:03:42.425874 118397 sgd_solver.cpp:106] Iteration 9110, lr = 0.009
I0729 00:04:16.190872 118397 solver.cpp:236] Iteration 9120, loss = 0.615973
I0729 00:04:16.191103 118397 solver.cpp:252]     Train net output #0: loss = 0.643148 (* 1 = 0.643148 loss)
I0729 00:04:16.191124 118397 sgd_solver.cpp:106] Iteration 9120, lr = 0.009
I0729 00:04:51.154105 118397 solver.cpp:236] Iteration 9130, loss = 0.619115
I0729 00:04:51.154259 118397 solver.cpp:252]     Train net output #0: loss = 0.657372 (* 1 = 0.657372 loss)
I0729 00:04:51.154276 118397 sgd_solver.cpp:106] Iteration 9130, lr = 0.009
I0729 00:05:15.189714 118397 solver.cpp:236] Iteration 9140, loss = 0.612263
I0729 00:05:15.189775 118397 solver.cpp:252]     Train net output #0: loss = 0.646196 (* 1 = 0.646196 loss)
I0729 00:05:15.189790 118397 sgd_solver.cpp:106] Iteration 9140, lr = 0.009
I0729 00:05:47.001286 118397 solver.cpp:236] Iteration 9150, loss = 0.617231
I0729 00:05:47.001464 118397 solver.cpp:252]     Train net output #0: loss = 0.63642 (* 1 = 0.63642 loss)
I0729 00:05:47.001488 118397 sgd_solver.cpp:106] Iteration 9150, lr = 0.009
I0729 00:06:19.184764 118397 solver.cpp:236] Iteration 9160, loss = 0.613259
I0729 00:06:19.184936 118397 solver.cpp:252]     Train net output #0: loss = 0.638894 (* 1 = 0.638894 loss)
I0729 00:06:19.184973 118397 sgd_solver.cpp:106] Iteration 9160, lr = 0.009
I0729 00:06:52.697695 118397 solver.cpp:236] Iteration 9170, loss = 0.613129
I0729 00:06:52.698835 118397 solver.cpp:252]     Train net output #0: loss = 0.633748 (* 1 = 0.633748 loss)
I0729 00:06:52.698853 118397 sgd_solver.cpp:106] Iteration 9170, lr = 0.009
I0729 00:07:29.035702 118397 solver.cpp:236] Iteration 9180, loss = 0.613073
I0729 00:07:29.035845 118397 solver.cpp:252]     Train net output #0: loss = 0.631414 (* 1 = 0.631414 loss)
I0729 00:07:29.035862 118397 sgd_solver.cpp:106] Iteration 9180, lr = 0.009
I0729 00:08:00.655268 118397 solver.cpp:236] Iteration 9190, loss = 0.610776
I0729 00:08:00.655413 118397 solver.cpp:252]     Train net output #0: loss = 0.643756 (* 1 = 0.643756 loss)
I0729 00:08:00.655431 118397 sgd_solver.cpp:106] Iteration 9190, lr = 0.009
I0729 00:08:34.408295 118397 solver.cpp:236] Iteration 9200, loss = 0.604848
I0729 00:08:34.408459 118397 solver.cpp:252]     Train net output #0: loss = 0.644752 (* 1 = 0.644752 loss)
I0729 00:08:34.408475 118397 sgd_solver.cpp:106] Iteration 9200, lr = 0.009
I0729 00:09:08.121896 118397 solver.cpp:236] Iteration 9210, loss = 0.602724
I0729 00:09:08.122042 118397 solver.cpp:252]     Train net output #0: loss = 0.633719 (* 1 = 0.633719 loss)
I0729 00:09:08.122059 118397 sgd_solver.cpp:106] Iteration 9210, lr = 0.009
I0729 00:09:39.476285 118397 solver.cpp:236] Iteration 9220, loss = 0.60093
I0729 00:09:39.476485 118397 solver.cpp:252]     Train net output #0: loss = 0.674148 (* 1 = 0.674148 loss)
I0729 00:09:39.476521 118397 sgd_solver.cpp:106] Iteration 9220, lr = 0.009
I0729 00:10:13.927755 118397 solver.cpp:236] Iteration 9230, loss = 0.597028
I0729 00:10:13.927975 118397 solver.cpp:252]     Train net output #0: loss = 0.643529 (* 1 = 0.643529 loss)
I0729 00:10:13.927990 118397 sgd_solver.cpp:106] Iteration 9230, lr = 0.009
I0729 00:10:47.308280 118397 solver.cpp:236] Iteration 9240, loss = 0.604549
I0729 00:10:47.308437 118397 solver.cpp:252]     Train net output #0: loss = 0.6339 (* 1 = 0.6339 loss)
I0729 00:10:47.308454 118397 sgd_solver.cpp:106] Iteration 9240, lr = 0.009
I0729 00:11:21.117547 118397 solver.cpp:236] Iteration 9250, loss = 0.604672
I0729 00:11:21.117760 118397 solver.cpp:252]     Train net output #0: loss = 0.651096 (* 1 = 0.651096 loss)
I0729 00:11:21.117775 118397 sgd_solver.cpp:106] Iteration 9250, lr = 0.009
I0729 00:11:52.796389 118397 solver.cpp:236] Iteration 9260, loss = 0.601526
I0729 00:11:52.796550 118397 solver.cpp:252]     Train net output #0: loss = 0.638833 (* 1 = 0.638833 loss)
I0729 00:11:52.796571 118397 sgd_solver.cpp:106] Iteration 9260, lr = 0.009
I0729 00:12:27.721200 118397 solver.cpp:236] Iteration 9270, loss = 0.601488
I0729 00:12:27.721509 118397 solver.cpp:252]     Train net output #0: loss = 0.629602 (* 1 = 0.629602 loss)
I0729 00:12:27.721526 118397 sgd_solver.cpp:106] Iteration 9270, lr = 0.009
I0729 00:13:07.367291 118397 solver.cpp:236] Iteration 9280, loss = 0.599395
I0729 00:13:07.367457 118397 solver.cpp:252]     Train net output #0: loss = 0.633789 (* 1 = 0.633789 loss)
I0729 00:13:07.367475 118397 sgd_solver.cpp:106] Iteration 9280, lr = 0.009
I0729 00:13:36.639394 118397 solver.cpp:236] Iteration 9290, loss = 0.598748
I0729 00:13:36.639461 118397 solver.cpp:252]     Train net output #0: loss = 0.662338 (* 1 = 0.662338 loss)
I0729 00:13:36.639474 118397 sgd_solver.cpp:106] Iteration 9290, lr = 0.009
I0729 00:14:14.785545 118397 solver.cpp:236] Iteration 9300, loss = 0.60541
I0729 00:14:14.785745 118397 solver.cpp:252]     Train net output #0: loss = 0.634463 (* 1 = 0.634463 loss)
I0729 00:14:14.785780 118397 sgd_solver.cpp:106] Iteration 9300, lr = 0.009
I0729 00:14:44.811192 118397 solver.cpp:236] Iteration 9310, loss = 0.601142
I0729 00:14:44.811415 118397 solver.cpp:252]     Train net output #0: loss = 0.643224 (* 1 = 0.643224 loss)
I0729 00:14:44.811449 118397 sgd_solver.cpp:106] Iteration 9310, lr = 0.009
I0729 00:15:16.009348 118397 solver.cpp:236] Iteration 9320, loss = 0.60502
I0729 00:15:16.009479 118397 solver.cpp:252]     Train net output #0: loss = 0.689498 (* 1 = 0.689498 loss)
I0729 00:15:16.009502 118397 sgd_solver.cpp:106] Iteration 9320, lr = 0.009
I0729 00:15:45.728162 118397 solver.cpp:236] Iteration 9330, loss = 0.60881
I0729 00:15:45.728229 118397 solver.cpp:252]     Train net output #0: loss = 0.633564 (* 1 = 0.633564 loss)
I0729 00:15:45.728245 118397 sgd_solver.cpp:106] Iteration 9330, lr = 0.009
I0729 00:16:21.877339 118397 solver.cpp:236] Iteration 9340, loss = 0.610563
I0729 00:16:21.877495 118397 solver.cpp:252]     Train net output #0: loss = 0.637406 (* 1 = 0.637406 loss)
I0729 00:16:21.877511 118397 sgd_solver.cpp:106] Iteration 9340, lr = 0.009
I0729 00:16:51.455454 118397 solver.cpp:236] Iteration 9350, loss = 0.610922
I0729 00:16:51.455519 118397 solver.cpp:252]     Train net output #0: loss = 0.639349 (* 1 = 0.639349 loss)
I0729 00:16:51.455533 118397 sgd_solver.cpp:106] Iteration 9350, lr = 0.009
I0729 00:17:23.980689 118397 solver.cpp:236] Iteration 9360, loss = 0.616768
I0729 00:17:23.980871 118397 solver.cpp:252]     Train net output #0: loss = 0.636383 (* 1 = 0.636383 loss)
I0729 00:17:23.980901 118397 sgd_solver.cpp:106] Iteration 9360, lr = 0.009
I0729 00:18:06.848590 118397 solver.cpp:236] Iteration 9370, loss = 0.611853
I0729 00:18:06.848783 118397 solver.cpp:252]     Train net output #0: loss = 0.642671 (* 1 = 0.642671 loss)
I0729 00:18:06.848814 118397 sgd_solver.cpp:106] Iteration 9370, lr = 0.009
I0729 00:18:41.935608 118397 solver.cpp:236] Iteration 9380, loss = 0.612189
I0729 00:18:41.935734 118397 solver.cpp:252]     Train net output #0: loss = 0.653666 (* 1 = 0.653666 loss)
I0729 00:18:41.935752 118397 sgd_solver.cpp:106] Iteration 9380, lr = 0.009
I0729 00:19:17.500751 118397 solver.cpp:236] Iteration 9390, loss = 0.617643
I0729 00:19:17.500885 118397 solver.cpp:252]     Train net output #0: loss = 0.642264 (* 1 = 0.642264 loss)
I0729 00:19:17.500905 118397 sgd_solver.cpp:106] Iteration 9390, lr = 0.009
I0729 00:19:54.958415 118397 solver.cpp:236] Iteration 9400, loss = 0.614567
I0729 00:19:54.958614 118397 solver.cpp:252]     Train net output #0: loss = 0.404299 (* 1 = 0.404299 loss)
I0729 00:19:54.958649 118397 sgd_solver.cpp:106] Iteration 9400, lr = 0.009
I0729 00:20:30.044062 118397 solver.cpp:236] Iteration 9410, loss = 0.61443
I0729 00:20:30.044199 118397 solver.cpp:252]     Train net output #0: loss = 0.707321 (* 1 = 0.707321 loss)
I0729 00:20:30.044217 118397 sgd_solver.cpp:106] Iteration 9410, lr = 0.009
I0729 00:21:02.549515 118397 solver.cpp:236] Iteration 9420, loss = 0.620094
I0729 00:21:02.549659 118397 solver.cpp:252]     Train net output #0: loss = 0.633568 (* 1 = 0.633568 loss)
I0729 00:21:02.549674 118397 sgd_solver.cpp:106] Iteration 9420, lr = 0.009
I0729 00:21:41.665134 118397 solver.cpp:236] Iteration 9430, loss = 0.621508
I0729 00:21:41.665335 118397 solver.cpp:252]     Train net output #0: loss = 0.638314 (* 1 = 0.638314 loss)
I0729 00:21:41.665355 118397 sgd_solver.cpp:106] Iteration 9430, lr = 0.009
I0729 00:22:14.412472 118397 solver.cpp:236] Iteration 9440, loss = 0.61855
I0729 00:22:14.412705 118397 solver.cpp:252]     Train net output #0: loss = 0.639016 (* 1 = 0.639016 loss)
I0729 00:22:14.412720 118397 sgd_solver.cpp:106] Iteration 9440, lr = 0.009
I0729 00:22:51.125864 118397 solver.cpp:236] Iteration 9450, loss = 0.621028
I0729 00:22:51.126019 118397 solver.cpp:252]     Train net output #0: loss = 0.633728 (* 1 = 0.633728 loss)
I0729 00:22:51.126035 118397 sgd_solver.cpp:106] Iteration 9450, lr = 0.009
I0729 00:23:25.392611 118397 solver.cpp:236] Iteration 9460, loss = 0.61899
I0729 00:23:25.392777 118397 solver.cpp:252]     Train net output #0: loss = 0.630794 (* 1 = 0.630794 loss)
I0729 00:23:25.392799 118397 sgd_solver.cpp:106] Iteration 9460, lr = 0.009
I0729 00:24:00.389845 118397 solver.cpp:236] Iteration 9470, loss = 0.623775
I0729 00:24:00.390023 118397 solver.cpp:252]     Train net output #0: loss = 0.63365 (* 1 = 0.63365 loss)
I0729 00:24:00.390039 118397 sgd_solver.cpp:106] Iteration 9470, lr = 0.009
I0729 00:24:34.255064 118397 solver.cpp:236] Iteration 9480, loss = 0.623526
I0729 00:24:34.255203 118397 solver.cpp:252]     Train net output #0: loss = 0.64182 (* 1 = 0.64182 loss)
I0729 00:24:34.255226 118397 sgd_solver.cpp:106] Iteration 9480, lr = 0.009
I0729 00:25:11.350137 118397 solver.cpp:236] Iteration 9490, loss = 0.620918
I0729 00:25:11.350338 118397 solver.cpp:252]     Train net output #0: loss = 0.639949 (* 1 = 0.639949 loss)
I0729 00:25:11.350378 118397 sgd_solver.cpp:106] Iteration 9490, lr = 0.009
I0729 00:25:45.894120 118397 solver.cpp:340] Iteration 9500, Testing net (#0)
I0729 00:26:17.630434 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 00:26:17.630764 118397 solver.cpp:408]     Test net output #1: loss = 0.642804 (* 1 = 0.642804 loss)
I0729 00:26:21.232834 118397 solver.cpp:236] Iteration 9500, loss = 0.62065
I0729 00:26:21.232897 118397 solver.cpp:252]     Train net output #0: loss = 0.644084 (* 1 = 0.644084 loss)
I0729 00:26:21.232913 118397 sgd_solver.cpp:106] Iteration 9500, lr = 0.009
I0729 00:26:49.748636 118397 solver.cpp:236] Iteration 9510, loss = 0.624636
I0729 00:26:49.748790 118397 solver.cpp:252]     Train net output #0: loss = 0.638055 (* 1 = 0.638055 loss)
I0729 00:26:49.748807 118397 sgd_solver.cpp:106] Iteration 9510, lr = 0.009
I0729 00:27:24.504235 118397 solver.cpp:236] Iteration 9520, loss = 0.621771
I0729 00:27:24.504442 118397 solver.cpp:252]     Train net output #0: loss = 0.635779 (* 1 = 0.635779 loss)
I0729 00:27:24.504457 118397 sgd_solver.cpp:106] Iteration 9520, lr = 0.009
I0729 00:27:54.569216 118397 solver.cpp:236] Iteration 9530, loss = 0.617291
I0729 00:27:54.569469 118397 solver.cpp:252]     Train net output #0: loss = 0.325392 (* 1 = 0.325392 loss)
I0729 00:27:54.569484 118397 sgd_solver.cpp:106] Iteration 9530, lr = 0.009
I0729 00:28:26.482563 118397 solver.cpp:236] Iteration 9540, loss = 0.621192
I0729 00:28:26.482736 118397 solver.cpp:252]     Train net output #0: loss = 0.642484 (* 1 = 0.642484 loss)
I0729 00:28:26.482769 118397 sgd_solver.cpp:106] Iteration 9540, lr = 0.009
I0729 00:29:07.738749 118397 solver.cpp:236] Iteration 9550, loss = 0.620678
I0729 00:29:07.738991 118397 solver.cpp:252]     Train net output #0: loss = 0.638845 (* 1 = 0.638845 loss)
I0729 00:29:07.739012 118397 sgd_solver.cpp:106] Iteration 9550, lr = 0.009
I0729 00:29:40.028024 118397 solver.cpp:236] Iteration 9560, loss = 0.613881
I0729 00:29:40.028194 118397 solver.cpp:252]     Train net output #0: loss = 0.299625 (* 1 = 0.299625 loss)
I0729 00:29:40.028215 118397 sgd_solver.cpp:106] Iteration 9560, lr = 0.009
I0729 00:30:11.640499 118397 solver.cpp:236] Iteration 9570, loss = 0.615396
I0729 00:30:11.640722 118397 solver.cpp:252]     Train net output #0: loss = 0.688324 (* 1 = 0.688324 loss)
I0729 00:30:11.640739 118397 sgd_solver.cpp:106] Iteration 9570, lr = 0.009
I0729 00:30:46.424578 118397 solver.cpp:236] Iteration 9580, loss = 0.618284
I0729 00:30:46.424738 118397 solver.cpp:252]     Train net output #0: loss = 0.640286 (* 1 = 0.640286 loss)
I0729 00:30:46.424757 118397 sgd_solver.cpp:106] Iteration 9580, lr = 0.009
I0729 00:31:20.677237 118397 solver.cpp:236] Iteration 9590, loss = 0.621565
I0729 00:31:20.677413 118397 solver.cpp:252]     Train net output #0: loss = 0.637346 (* 1 = 0.637346 loss)
I0729 00:31:20.677430 118397 sgd_solver.cpp:106] Iteration 9590, lr = 0.009
I0729 00:31:51.462569 118397 solver.cpp:236] Iteration 9600, loss = 0.621126
I0729 00:31:51.462728 118397 solver.cpp:252]     Train net output #0: loss = 0.673272 (* 1 = 0.673272 loss)
I0729 00:31:51.462748 118397 sgd_solver.cpp:106] Iteration 9600, lr = 0.009
I0729 00:32:26.955212 118397 solver.cpp:236] Iteration 9610, loss = 0.618553
I0729 00:32:26.955461 118397 solver.cpp:252]     Train net output #0: loss = 0.640039 (* 1 = 0.640039 loss)
I0729 00:32:26.955479 118397 sgd_solver.cpp:106] Iteration 9610, lr = 0.009
I0729 00:33:00.440239 118397 solver.cpp:236] Iteration 9620, loss = 0.618992
I0729 00:33:00.440392 118397 solver.cpp:252]     Train net output #0: loss = 0.634646 (* 1 = 0.634646 loss)
I0729 00:33:00.440410 118397 sgd_solver.cpp:106] Iteration 9620, lr = 0.009
I0729 00:33:26.245292 118397 solver.cpp:236] Iteration 9630, loss = 0.616798
I0729 00:33:26.245355 118397 solver.cpp:252]     Train net output #0: loss = 0.657638 (* 1 = 0.657638 loss)
I0729 00:33:26.245369 118397 sgd_solver.cpp:106] Iteration 9630, lr = 0.009
I0729 00:34:05.010236 118397 solver.cpp:236] Iteration 9640, loss = 0.614464
I0729 00:34:05.010462 118397 solver.cpp:252]     Train net output #0: loss = 0.648614 (* 1 = 0.648614 loss)
I0729 00:34:05.010480 118397 sgd_solver.cpp:106] Iteration 9640, lr = 0.009
I0729 00:34:33.638159 118397 solver.cpp:236] Iteration 9650, loss = 0.608796
I0729 00:34:33.638228 118397 solver.cpp:252]     Train net output #0: loss = 0.637714 (* 1 = 0.637714 loss)
I0729 00:34:33.638242 118397 sgd_solver.cpp:106] Iteration 9650, lr = 0.009
I0729 00:35:12.775097 118397 solver.cpp:236] Iteration 9660, loss = 0.614585
I0729 00:35:12.775254 118397 solver.cpp:252]     Train net output #0: loss = 0.639205 (* 1 = 0.639205 loss)
I0729 00:35:12.775272 118397 sgd_solver.cpp:106] Iteration 9660, lr = 0.009
I0729 00:35:46.037533 118397 solver.cpp:236] Iteration 9670, loss = 0.610511
I0729 00:35:46.037680 118397 solver.cpp:252]     Train net output #0: loss = 0.636303 (* 1 = 0.636303 loss)
I0729 00:35:46.037696 118397 sgd_solver.cpp:106] Iteration 9670, lr = 0.009
I0729 00:36:17.984540 118397 solver.cpp:236] Iteration 9680, loss = 0.604091
I0729 00:36:17.984729 118397 solver.cpp:252]     Train net output #0: loss = 0.647659 (* 1 = 0.647659 loss)
I0729 00:36:17.984750 118397 sgd_solver.cpp:106] Iteration 9680, lr = 0.009
I0729 00:36:50.845309 118397 solver.cpp:236] Iteration 9690, loss = 0.604082
I0729 00:36:50.845510 118397 solver.cpp:252]     Train net output #0: loss = 0.638394 (* 1 = 0.638394 loss)
I0729 00:36:50.845541 118397 sgd_solver.cpp:106] Iteration 9690, lr = 0.009
I0729 00:37:23.968873 118397 solver.cpp:236] Iteration 9700, loss = 0.605115
I0729 00:37:23.969092 118397 solver.cpp:252]     Train net output #0: loss = 0.632972 (* 1 = 0.632972 loss)
I0729 00:37:23.969111 118397 sgd_solver.cpp:106] Iteration 9700, lr = 0.009
I0729 00:37:56.204076 118397 solver.cpp:236] Iteration 9710, loss = 0.604443
I0729 00:37:56.204247 118397 solver.cpp:252]     Train net output #0: loss = 0.664551 (* 1 = 0.664551 loss)
I0729 00:37:56.204289 118397 sgd_solver.cpp:106] Iteration 9710, lr = 0.009
I0729 00:38:27.773412 118397 solver.cpp:236] Iteration 9720, loss = 0.602615
I0729 00:38:27.773602 118397 solver.cpp:252]     Train net output #0: loss = 0.645414 (* 1 = 0.645414 loss)
I0729 00:38:27.773625 118397 sgd_solver.cpp:106] Iteration 9720, lr = 0.009
I0729 00:38:59.820988 118397 solver.cpp:236] Iteration 9730, loss = 0.604263
I0729 00:38:59.821177 118397 solver.cpp:252]     Train net output #0: loss = 0.640291 (* 1 = 0.640291 loss)
I0729 00:38:59.821193 118397 sgd_solver.cpp:106] Iteration 9730, lr = 0.009
I0729 00:39:34.881134 118397 solver.cpp:236] Iteration 9740, loss = 0.605471
I0729 00:39:34.881283 118397 solver.cpp:252]     Train net output #0: loss = 0.636169 (* 1 = 0.636169 loss)
I0729 00:39:34.881299 118397 sgd_solver.cpp:106] Iteration 9740, lr = 0.009
I0729 00:40:09.090570 118397 solver.cpp:236] Iteration 9750, loss = 0.608617
I0729 00:40:09.090785 118397 solver.cpp:252]     Train net output #0: loss = 0.391605 (* 1 = 0.391605 loss)
I0729 00:40:09.090833 118397 sgd_solver.cpp:106] Iteration 9750, lr = 0.009
I0729 00:40:44.130460 118397 solver.cpp:236] Iteration 9760, loss = 0.61179
I0729 00:40:44.130614 118397 solver.cpp:252]     Train net output #0: loss = 0.646133 (* 1 = 0.646133 loss)
I0729 00:40:44.130638 118397 sgd_solver.cpp:106] Iteration 9760, lr = 0.009
I0729 00:41:16.163682 118397 solver.cpp:236] Iteration 9770, loss = 0.609861
I0729 00:41:16.163873 118397 solver.cpp:252]     Train net output #0: loss = 0.40165 (* 1 = 0.40165 loss)
I0729 00:41:16.163902 118397 sgd_solver.cpp:106] Iteration 9770, lr = 0.009
I0729 00:41:50.789943 118397 solver.cpp:236] Iteration 9780, loss = 0.616375
I0729 00:41:50.790093 118397 solver.cpp:252]     Train net output #0: loss = 0.64503 (* 1 = 0.64503 loss)
I0729 00:41:50.790108 118397 sgd_solver.cpp:106] Iteration 9780, lr = 0.009
I0729 00:42:23.901831 118397 solver.cpp:236] Iteration 9790, loss = 0.613846
I0729 00:42:23.901962 118397 solver.cpp:252]     Train net output #0: loss = 0.637821 (* 1 = 0.637821 loss)
I0729 00:42:23.901978 118397 sgd_solver.cpp:106] Iteration 9790, lr = 0.009
I0729 00:42:58.699270 118397 solver.cpp:236] Iteration 9800, loss = 0.61102
I0729 00:42:58.699431 118397 solver.cpp:252]     Train net output #0: loss = 0.665892 (* 1 = 0.665892 loss)
I0729 00:42:58.699456 118397 sgd_solver.cpp:106] Iteration 9800, lr = 0.009
I0729 00:43:36.967053 118397 solver.cpp:236] Iteration 9810, loss = 0.612626
I0729 00:43:36.967231 118397 solver.cpp:252]     Train net output #0: loss = 0.663743 (* 1 = 0.663743 loss)
I0729 00:43:36.967257 118397 sgd_solver.cpp:106] Iteration 9810, lr = 0.009
I0729 00:44:10.376760 118397 solver.cpp:236] Iteration 9820, loss = 0.614773
I0729 00:44:10.376912 118397 solver.cpp:252]     Train net output #0: loss = 0.646704 (* 1 = 0.646704 loss)
I0729 00:44:10.376940 118397 sgd_solver.cpp:106] Iteration 9820, lr = 0.009
I0729 00:44:49.002701 118397 solver.cpp:236] Iteration 9830, loss = 0.619304
I0729 00:44:49.002904 118397 solver.cpp:252]     Train net output #0: loss = 0.638237 (* 1 = 0.638237 loss)
I0729 00:44:49.002933 118397 sgd_solver.cpp:106] Iteration 9830, lr = 0.009
I0729 00:45:20.416918 118397 solver.cpp:236] Iteration 9840, loss = 0.613728
I0729 00:45:20.417150 118397 solver.cpp:252]     Train net output #0: loss = 0.661874 (* 1 = 0.661874 loss)
I0729 00:45:20.417178 118397 sgd_solver.cpp:106] Iteration 9840, lr = 0.009
I0729 00:45:56.417973 118397 solver.cpp:236] Iteration 9850, loss = 0.614782
I0729 00:45:56.418228 118397 solver.cpp:252]     Train net output #0: loss = 0.637428 (* 1 = 0.637428 loss)
I0729 00:45:56.418244 118397 sgd_solver.cpp:106] Iteration 9850, lr = 0.009
I0729 00:46:28.128038 118397 solver.cpp:236] Iteration 9860, loss = 0.611943
I0729 00:46:28.128213 118397 solver.cpp:252]     Train net output #0: loss = 0.644891 (* 1 = 0.644891 loss)
I0729 00:46:28.128235 118397 sgd_solver.cpp:106] Iteration 9860, lr = 0.009
I0729 00:47:04.798462 118397 solver.cpp:236] Iteration 9870, loss = 0.616299
I0729 00:47:04.798698 118397 solver.cpp:252]     Train net output #0: loss = 0.632732 (* 1 = 0.632732 loss)
I0729 00:47:04.798738 118397 sgd_solver.cpp:106] Iteration 9870, lr = 0.009
I0729 00:47:38.137501 118397 solver.cpp:236] Iteration 9880, loss = 0.61523
I0729 00:47:38.137658 118397 solver.cpp:252]     Train net output #0: loss = 0.639973 (* 1 = 0.639973 loss)
I0729 00:47:38.137673 118397 sgd_solver.cpp:106] Iteration 9880, lr = 0.009
I0729 00:48:14.807250 118397 solver.cpp:236] Iteration 9890, loss = 0.611785
I0729 00:48:14.807442 118397 solver.cpp:252]     Train net output #0: loss = 0.652249 (* 1 = 0.652249 loss)
I0729 00:48:14.807458 118397 sgd_solver.cpp:106] Iteration 9890, lr = 0.009
I0729 00:48:47.047554 118397 solver.cpp:236] Iteration 9900, loss = 0.61785
I0729 00:48:47.047719 118397 solver.cpp:252]     Train net output #0: loss = 0.63941 (* 1 = 0.63941 loss)
I0729 00:48:47.047737 118397 sgd_solver.cpp:106] Iteration 9900, lr = 0.009
I0729 00:49:27.175668 118397 solver.cpp:236] Iteration 9910, loss = 0.622071
I0729 00:49:27.175835 118397 solver.cpp:252]     Train net output #0: loss = 0.636241 (* 1 = 0.636241 loss)
I0729 00:49:27.175879 118397 sgd_solver.cpp:106] Iteration 9910, lr = 0.009
I0729 00:50:02.659611 118397 solver.cpp:236] Iteration 9920, loss = 0.619932
I0729 00:50:02.659762 118397 solver.cpp:252]     Train net output #0: loss = 0.64197 (* 1 = 0.64197 loss)
I0729 00:50:02.659780 118397 sgd_solver.cpp:106] Iteration 9920, lr = 0.009
I0729 00:50:34.340301 118397 solver.cpp:236] Iteration 9930, loss = 0.621247
I0729 00:50:34.340492 118397 solver.cpp:252]     Train net output #0: loss = 0.63417 (* 1 = 0.63417 loss)
I0729 00:50:34.340517 118397 sgd_solver.cpp:106] Iteration 9930, lr = 0.009
I0729 00:51:04.370259 118397 solver.cpp:236] Iteration 9940, loss = 0.622349
I0729 00:51:04.370512 118397 solver.cpp:252]     Train net output #0: loss = 0.632194 (* 1 = 0.632194 loss)
I0729 00:51:04.370537 118397 sgd_solver.cpp:106] Iteration 9940, lr = 0.009
I0729 00:51:37.747956 118397 solver.cpp:236] Iteration 9950, loss = 0.61672
I0729 00:51:37.748095 118397 solver.cpp:252]     Train net output #0: loss = 0.731063 (* 1 = 0.731063 loss)
I0729 00:51:37.748111 118397 sgd_solver.cpp:106] Iteration 9950, lr = 0.009
I0729 00:52:11.564599 118397 solver.cpp:236] Iteration 9960, loss = 0.61898
I0729 00:52:11.566357 118397 solver.cpp:252]     Train net output #0: loss = 0.633882 (* 1 = 0.633882 loss)
I0729 00:52:11.566380 118397 sgd_solver.cpp:106] Iteration 9960, lr = 0.009
I0729 00:52:42.902767 118397 solver.cpp:236] Iteration 9970, loss = 0.617874
I0729 00:52:42.902987 118397 solver.cpp:252]     Train net output #0: loss = 0.636147 (* 1 = 0.636147 loss)
I0729 00:52:42.903007 118397 sgd_solver.cpp:106] Iteration 9970, lr = 0.009
I0729 00:53:17.630491 118397 solver.cpp:236] Iteration 9980, loss = 0.615136
I0729 00:53:17.630841 118397 solver.cpp:252]     Train net output #0: loss = 0.34912 (* 1 = 0.34912 loss)
I0729 00:53:17.630858 118397 sgd_solver.cpp:106] Iteration 9980, lr = 0.009
I0729 00:53:51.326833 118397 solver.cpp:236] Iteration 9990, loss = 0.614713
I0729 00:53:51.326985 118397 solver.cpp:252]     Train net output #0: loss = 0.651639 (* 1 = 0.651639 loss)
I0729 00:53:51.327003 118397 sgd_solver.cpp:106] Iteration 9990, lr = 0.009
I0729 00:54:18.927474 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_10000.caffemodel
I0729 00:54:19.069823 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_10000.solverstate
I0729 00:54:19.073683 118397 solver.cpp:340] Iteration 10000, Testing net (#0)
I0729 00:54:52.704771 118397 solver.cpp:408]     Test net output #0: accuracy = 0.7625
I0729 00:54:52.704957 118397 solver.cpp:408]     Test net output #1: loss = 0.552751 (* 1 = 0.552751 loss)
I0729 00:54:57.292639 118397 solver.cpp:236] Iteration 10000, loss = 0.611259
I0729 00:54:57.292714 118397 solver.cpp:252]     Train net output #0: loss = 0.639536 (* 1 = 0.639536 loss)
I0729 00:54:57.292734 118397 sgd_solver.cpp:106] Iteration 10000, lr = 0.0081
I0729 00:55:34.048149 118397 solver.cpp:236] Iteration 10010, loss = 0.606234
I0729 00:55:34.048420 118397 solver.cpp:252]     Train net output #0: loss = 0.635181 (* 1 = 0.635181 loss)
I0729 00:55:34.048439 118397 sgd_solver.cpp:106] Iteration 10010, lr = 0.0081
I0729 00:56:11.185477 118397 solver.cpp:236] Iteration 10020, loss = 0.602084
I0729 00:56:11.185775 118397 solver.cpp:252]     Train net output #0: loss = 0.654771 (* 1 = 0.654771 loss)
I0729 00:56:11.185791 118397 sgd_solver.cpp:106] Iteration 10020, lr = 0.0081
I0729 00:56:42.607839 118397 solver.cpp:236] Iteration 10030, loss = 0.597022
I0729 00:56:42.608072 118397 solver.cpp:252]     Train net output #0: loss = 0.313025 (* 1 = 0.313025 loss)
I0729 00:56:42.608090 118397 sgd_solver.cpp:106] Iteration 10030, lr = 0.0081
I0729 00:57:10.973506 118397 solver.cpp:236] Iteration 10040, loss = 0.596302
I0729 00:57:10.973577 118397 solver.cpp:252]     Train net output #0: loss = 0.636317 (* 1 = 0.636317 loss)
I0729 00:57:10.973590 118397 sgd_solver.cpp:106] Iteration 10040, lr = 0.0081
I0729 00:57:44.086206 118397 solver.cpp:236] Iteration 10050, loss = 0.604195
I0729 00:57:44.086380 118397 solver.cpp:252]     Train net output #0: loss = 0.641402 (* 1 = 0.641402 loss)
I0729 00:57:44.086400 118397 sgd_solver.cpp:106] Iteration 10050, lr = 0.0081
I0729 00:58:19.482476 118397 solver.cpp:236] Iteration 10060, loss = 0.604072
I0729 00:58:19.482617 118397 solver.cpp:252]     Train net output #0: loss = 0.63163 (* 1 = 0.63163 loss)
I0729 00:58:19.482640 118397 sgd_solver.cpp:106] Iteration 10060, lr = 0.0081
I0729 00:58:51.993636 118397 solver.cpp:236] Iteration 10070, loss = 0.600442
I0729 00:58:51.993798 118397 solver.cpp:252]     Train net output #0: loss = 0.641061 (* 1 = 0.641061 loss)
I0729 00:58:51.993818 118397 sgd_solver.cpp:106] Iteration 10070, lr = 0.0081
I0729 00:59:21.566465 118397 solver.cpp:236] Iteration 10080, loss = 0.600931
I0729 00:59:21.566560 118397 solver.cpp:252]     Train net output #0: loss = 0.649289 (* 1 = 0.649289 loss)
I0729 00:59:21.566577 118397 sgd_solver.cpp:106] Iteration 10080, lr = 0.0081
I0729 00:59:48.853523 118397 solver.cpp:236] Iteration 10090, loss = 0.606769
I0729 00:59:48.853845 118397 solver.cpp:252]     Train net output #0: loss = 0.642303 (* 1 = 0.642303 loss)
I0729 00:59:48.853870 118397 sgd_solver.cpp:106] Iteration 10090, lr = 0.0081
I0729 01:00:25.070785 118397 solver.cpp:236] Iteration 10100, loss = 0.608971
I0729 01:00:25.070971 118397 solver.cpp:252]     Train net output #0: loss = 0.648021 (* 1 = 0.648021 loss)
I0729 01:00:25.070996 118397 sgd_solver.cpp:106] Iteration 10100, lr = 0.0081
I0729 01:01:02.157888 118397 solver.cpp:236] Iteration 10110, loss = 0.613862
I0729 01:01:02.158037 118397 solver.cpp:252]     Train net output #0: loss = 0.634787 (* 1 = 0.634787 loss)
I0729 01:01:02.158056 118397 sgd_solver.cpp:106] Iteration 10110, lr = 0.0081
I0729 01:01:35.366040 118397 solver.cpp:236] Iteration 10120, loss = 0.619514
I0729 01:01:35.366219 118397 solver.cpp:252]     Train net output #0: loss = 0.637583 (* 1 = 0.637583 loss)
I0729 01:01:35.366238 118397 sgd_solver.cpp:106] Iteration 10120, lr = 0.0081
I0729 01:02:07.069846 118397 solver.cpp:236] Iteration 10130, loss = 0.619868
I0729 01:02:07.072005 118397 solver.cpp:252]     Train net output #0: loss = 0.414699 (* 1 = 0.414699 loss)
I0729 01:02:07.072036 118397 sgd_solver.cpp:106] Iteration 10130, lr = 0.0081
I0729 01:02:41.651507 118397 solver.cpp:236] Iteration 10140, loss = 0.619531
I0729 01:02:41.651733 118397 solver.cpp:252]     Train net output #0: loss = 0.661436 (* 1 = 0.661436 loss)
I0729 01:02:41.651749 118397 sgd_solver.cpp:106] Iteration 10140, lr = 0.0081
I0729 01:03:13.533421 118397 solver.cpp:236] Iteration 10150, loss = 0.616616
I0729 01:03:13.533643 118397 solver.cpp:252]     Train net output #0: loss = 0.631486 (* 1 = 0.631486 loss)
I0729 01:03:13.533664 118397 sgd_solver.cpp:106] Iteration 10150, lr = 0.0081
I0729 01:03:50.422708 118397 solver.cpp:236] Iteration 10160, loss = 0.616699
I0729 01:03:50.422885 118397 solver.cpp:252]     Train net output #0: loss = 0.633213 (* 1 = 0.633213 loss)
I0729 01:03:50.422912 118397 sgd_solver.cpp:106] Iteration 10160, lr = 0.0081
I0729 01:04:22.635246 118397 solver.cpp:236] Iteration 10170, loss = 0.619072
I0729 01:04:22.635476 118397 solver.cpp:252]     Train net output #0: loss = 0.399574 (* 1 = 0.399574 loss)
I0729 01:04:22.635504 118397 sgd_solver.cpp:106] Iteration 10170, lr = 0.0081
I0729 01:04:57.097335 118397 solver.cpp:236] Iteration 10180, loss = 0.619522
I0729 01:04:57.097527 118397 solver.cpp:252]     Train net output #0: loss = 0.654536 (* 1 = 0.654536 loss)
I0729 01:04:57.097544 118397 sgd_solver.cpp:106] Iteration 10180, lr = 0.0081
I0729 01:05:26.846843 118397 solver.cpp:236] Iteration 10190, loss = 0.619755
I0729 01:05:26.846920 118397 solver.cpp:252]     Train net output #0: loss = 0.636736 (* 1 = 0.636736 loss)
I0729 01:05:26.846933 118397 sgd_solver.cpp:106] Iteration 10190, lr = 0.0081
I0729 01:06:00.477358 118397 solver.cpp:236] Iteration 10200, loss = 0.615653
I0729 01:06:00.477584 118397 solver.cpp:252]     Train net output #0: loss = 0.637126 (* 1 = 0.637126 loss)
I0729 01:06:00.477623 118397 sgd_solver.cpp:106] Iteration 10200, lr = 0.0081
I0729 01:06:35.165958 118397 solver.cpp:236] Iteration 10210, loss = 0.614963
I0729 01:06:35.166158 118397 solver.cpp:252]     Train net output #0: loss = 0.666408 (* 1 = 0.666408 loss)
I0729 01:06:35.166198 118397 sgd_solver.cpp:106] Iteration 10210, lr = 0.0081
I0729 01:07:03.747617 118397 solver.cpp:236] Iteration 10220, loss = 0.613683
I0729 01:07:03.747691 118397 solver.cpp:252]     Train net output #0: loss = 0.638398 (* 1 = 0.638398 loss)
I0729 01:07:03.747709 118397 sgd_solver.cpp:106] Iteration 10220, lr = 0.0081
I0729 01:07:37.484844 118397 solver.cpp:236] Iteration 10230, loss = 0.615782
I0729 01:07:37.484988 118397 solver.cpp:252]     Train net output #0: loss = 0.396876 (* 1 = 0.396876 loss)
I0729 01:07:37.485009 118397 sgd_solver.cpp:106] Iteration 10230, lr = 0.0081
I0729 01:08:13.227221 118397 solver.cpp:236] Iteration 10240, loss = 0.621709
I0729 01:08:13.227383 118397 solver.cpp:252]     Train net output #0: loss = 0.637846 (* 1 = 0.637846 loss)
I0729 01:08:13.227411 118397 sgd_solver.cpp:106] Iteration 10240, lr = 0.0081
I0729 01:08:42.583190 118397 solver.cpp:236] Iteration 10250, loss = 0.621131
I0729 01:08:42.583257 118397 solver.cpp:252]     Train net output #0: loss = 0.635485 (* 1 = 0.635485 loss)
I0729 01:08:42.583276 118397 sgd_solver.cpp:106] Iteration 10250, lr = 0.0081
I0729 01:09:11.383214 118397 solver.cpp:236] Iteration 10260, loss = 0.616482
I0729 01:09:11.383414 118397 solver.cpp:252]     Train net output #0: loss = 0.651032 (* 1 = 0.651032 loss)
I0729 01:09:11.383452 118397 sgd_solver.cpp:106] Iteration 10260, lr = 0.0081
I0729 01:09:46.935444 118397 solver.cpp:236] Iteration 10270, loss = 0.616121
I0729 01:09:46.935596 118397 solver.cpp:252]     Train net output #0: loss = 0.633289 (* 1 = 0.633289 loss)
I0729 01:09:46.935613 118397 sgd_solver.cpp:106] Iteration 10270, lr = 0.0081
I0729 01:10:18.232507 118397 solver.cpp:236] Iteration 10280, loss = 0.606281
I0729 01:10:18.232681 118397 solver.cpp:252]     Train net output #0: loss = 0.286023 (* 1 = 0.286023 loss)
I0729 01:10:18.232698 118397 sgd_solver.cpp:106] Iteration 10280, lr = 0.0081
I0729 01:10:55.913533 118397 solver.cpp:236] Iteration 10290, loss = 0.596546
I0729 01:10:55.913743 118397 solver.cpp:252]     Train net output #0: loss = 0.210431 (* 1 = 0.210431 loss)
I0729 01:10:55.913763 118397 sgd_solver.cpp:106] Iteration 10290, lr = 0.0081
I0729 01:11:34.951562 118397 solver.cpp:236] Iteration 10300, loss = 0.595693
I0729 01:11:34.951757 118397 solver.cpp:252]     Train net output #0: loss = 0.667425 (* 1 = 0.667425 loss)
I0729 01:11:34.951781 118397 sgd_solver.cpp:106] Iteration 10300, lr = 0.0081
I0729 01:12:27.185633 118397 solver.cpp:236] Iteration 10310, loss = 0.59352
I0729 01:12:27.185772 118397 solver.cpp:252]     Train net output #0: loss = 0.630313 (* 1 = 0.630313 loss)
I0729 01:12:27.185789 118397 sgd_solver.cpp:106] Iteration 10310, lr = 0.0081
I0729 01:13:12.683691 118397 solver.cpp:236] Iteration 10320, loss = 0.594917
I0729 01:13:12.683881 118397 solver.cpp:252]     Train net output #0: loss = 0.635828 (* 1 = 0.635828 loss)
I0729 01:13:12.683902 118397 sgd_solver.cpp:106] Iteration 10320, lr = 0.0081
I0729 01:13:52.483382 118397 solver.cpp:236] Iteration 10330, loss = 0.593022
I0729 01:13:52.483537 118397 solver.cpp:252]     Train net output #0: loss = 0.647917 (* 1 = 0.647917 loss)
I0729 01:13:52.483554 118397 sgd_solver.cpp:106] Iteration 10330, lr = 0.0081
I0729 01:14:29.207257 118397 solver.cpp:236] Iteration 10340, loss = 0.587152
I0729 01:14:29.207506 118397 solver.cpp:252]     Train net output #0: loss = 0.649679 (* 1 = 0.649679 loss)
I0729 01:14:29.207525 118397 sgd_solver.cpp:106] Iteration 10340, lr = 0.0081
I0729 01:15:12.715961 118397 solver.cpp:236] Iteration 10350, loss = 0.590213
I0729 01:15:12.716136 118397 solver.cpp:252]     Train net output #0: loss = 0.636056 (* 1 = 0.636056 loss)
I0729 01:15:12.716151 118397 sgd_solver.cpp:106] Iteration 10350, lr = 0.0081
I0729 01:15:56.400436 118397 solver.cpp:236] Iteration 10360, loss = 0.593116
I0729 01:15:56.400583 118397 solver.cpp:252]     Train net output #0: loss = 0.639411 (* 1 = 0.639411 loss)
I0729 01:15:56.400617 118397 sgd_solver.cpp:106] Iteration 10360, lr = 0.0081
I0729 01:16:31.973283 118397 solver.cpp:236] Iteration 10370, loss = 0.590277
I0729 01:16:31.973436 118397 solver.cpp:252]     Train net output #0: loss = 0.302712 (* 1 = 0.302712 loss)
I0729 01:16:31.973466 118397 sgd_solver.cpp:106] Iteration 10370, lr = 0.0081
I0729 01:17:17.889575 118397 solver.cpp:236] Iteration 10380, loss = 0.602667
I0729 01:17:17.889829 118397 solver.cpp:252]     Train net output #0: loss = 0.637908 (* 1 = 0.637908 loss)
I0729 01:17:17.889845 118397 sgd_solver.cpp:106] Iteration 10380, lr = 0.0081
I0729 01:18:00.981436 118397 solver.cpp:236] Iteration 10390, loss = 0.607494
I0729 01:18:00.981614 118397 solver.cpp:252]     Train net output #0: loss = 0.645164 (* 1 = 0.645164 loss)
I0729 01:18:00.981644 118397 sgd_solver.cpp:106] Iteration 10390, lr = 0.0081
I0729 01:18:38.189554 118397 solver.cpp:236] Iteration 10400, loss = 0.609776
I0729 01:18:38.189759 118397 solver.cpp:252]     Train net output #0: loss = 0.639344 (* 1 = 0.639344 loss)
I0729 01:18:38.189795 118397 sgd_solver.cpp:106] Iteration 10400, lr = 0.0081
I0729 01:19:17.651329 118397 solver.cpp:236] Iteration 10410, loss = 0.610239
I0729 01:19:17.651517 118397 solver.cpp:252]     Train net output #0: loss = 0.639522 (* 1 = 0.639522 loss)
I0729 01:19:17.651549 118397 sgd_solver.cpp:106] Iteration 10410, lr = 0.0081
I0729 01:19:54.415477 118397 solver.cpp:236] Iteration 10420, loss = 0.610023
I0729 01:19:54.415647 118397 solver.cpp:252]     Train net output #0: loss = 0.637258 (* 1 = 0.637258 loss)
I0729 01:19:54.415669 118397 sgd_solver.cpp:106] Iteration 10420, lr = 0.0081
I0729 01:20:30.119938 118397 solver.cpp:236] Iteration 10430, loss = 0.614185
I0729 01:20:30.120087 118397 solver.cpp:252]     Train net output #0: loss = 0.635019 (* 1 = 0.635019 loss)
I0729 01:20:30.120106 118397 sgd_solver.cpp:106] Iteration 10430, lr = 0.0081
I0729 01:21:09.778978 118397 solver.cpp:236] Iteration 10440, loss = 0.617222
I0729 01:21:09.779135 118397 solver.cpp:252]     Train net output #0: loss = 0.635185 (* 1 = 0.635185 loss)
I0729 01:21:09.779165 118397 sgd_solver.cpp:106] Iteration 10440, lr = 0.0081
I0729 01:21:43.754154 118397 solver.cpp:236] Iteration 10450, loss = 0.611158
I0729 01:21:43.754304 118397 solver.cpp:252]     Train net output #0: loss = 0.654411 (* 1 = 0.654411 loss)
I0729 01:21:43.754326 118397 sgd_solver.cpp:106] Iteration 10450, lr = 0.0081
I0729 01:22:25.508796 118397 solver.cpp:236] Iteration 10460, loss = 0.613743
I0729 01:22:25.508975 118397 solver.cpp:252]     Train net output #0: loss = 0.636399 (* 1 = 0.636399 loss)
I0729 01:22:25.509002 118397 sgd_solver.cpp:106] Iteration 10460, lr = 0.0081
I0729 01:22:56.392403 118397 solver.cpp:236] Iteration 10470, loss = 0.609049
I0729 01:22:56.392660 118397 solver.cpp:252]     Train net output #0: loss = 0.653983 (* 1 = 0.653983 loss)
I0729 01:22:56.392679 118397 sgd_solver.cpp:106] Iteration 10470, lr = 0.0081
I0729 01:23:30.791836 118397 solver.cpp:236] Iteration 10480, loss = 0.602022
I0729 01:23:30.792009 118397 solver.cpp:252]     Train net output #0: loss = 0.196319 (* 1 = 0.196319 loss)
I0729 01:23:30.792027 118397 sgd_solver.cpp:106] Iteration 10480, lr = 0.0081
I0729 01:24:04.421905 118397 solver.cpp:236] Iteration 10490, loss = 0.604721
I0729 01:24:04.422169 118397 solver.cpp:252]     Train net output #0: loss = 0.642532 (* 1 = 0.642532 loss)
I0729 01:24:04.422185 118397 sgd_solver.cpp:106] Iteration 10490, lr = 0.0081
I0729 01:24:41.585671 118397 solver.cpp:340] Iteration 10500, Testing net (#0)
I0729 01:25:19.365593 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 01:25:19.365746 118397 solver.cpp:408]     Test net output #1: loss = 0.614732 (* 1 = 0.614732 loss)
I0729 01:25:22.511508 118397 solver.cpp:236] Iteration 10500, loss = 0.605897
I0729 01:25:22.511574 118397 solver.cpp:252]     Train net output #0: loss = 0.626945 (* 1 = 0.626945 loss)
I0729 01:25:22.511589 118397 sgd_solver.cpp:106] Iteration 10500, lr = 0.0081
I0729 01:26:00.161319 118397 solver.cpp:236] Iteration 10510, loss = 0.599674
I0729 01:26:00.161505 118397 solver.cpp:252]     Train net output #0: loss = 0.663189 (* 1 = 0.663189 loss)
I0729 01:26:00.161525 118397 sgd_solver.cpp:106] Iteration 10510, lr = 0.0081
I0729 01:26:34.696146 118397 solver.cpp:236] Iteration 10520, loss = 0.594866
I0729 01:26:34.696353 118397 solver.cpp:252]     Train net output #0: loss = 0.672931 (* 1 = 0.672931 loss)
I0729 01:26:34.696368 118397 sgd_solver.cpp:106] Iteration 10520, lr = 0.0081
I0729 01:27:05.484814 118397 solver.cpp:236] Iteration 10530, loss = 0.58966
I0729 01:27:05.485146 118397 solver.cpp:252]     Train net output #0: loss = 0.654149 (* 1 = 0.654149 loss)
I0729 01:27:05.485163 118397 sgd_solver.cpp:106] Iteration 10530, lr = 0.0081
I0729 01:27:39.515964 118397 solver.cpp:236] Iteration 10540, loss = 0.592389
I0729 01:27:39.516130 118397 solver.cpp:252]     Train net output #0: loss = 0.642707 (* 1 = 0.642707 loss)
I0729 01:27:39.516173 118397 sgd_solver.cpp:106] Iteration 10540, lr = 0.0081
I0729 01:28:11.756008 118397 solver.cpp:236] Iteration 10550, loss = 0.594211
I0729 01:28:11.756162 118397 solver.cpp:252]     Train net output #0: loss = 0.634392 (* 1 = 0.634392 loss)
I0729 01:28:11.756176 118397 sgd_solver.cpp:106] Iteration 10550, lr = 0.0081
I0729 01:28:46.100206 118397 solver.cpp:236] Iteration 10560, loss = 0.591236
I0729 01:28:46.100364 118397 solver.cpp:252]     Train net output #0: loss = 0.658091 (* 1 = 0.658091 loss)
I0729 01:28:46.100395 118397 sgd_solver.cpp:106] Iteration 10560, lr = 0.0081
I0729 01:29:15.794148 118397 solver.cpp:236] Iteration 10570, loss = 0.59637
I0729 01:29:15.794214 118397 solver.cpp:252]     Train net output #0: loss = 0.656038 (* 1 = 0.656038 loss)
I0729 01:29:15.794229 118397 sgd_solver.cpp:106] Iteration 10570, lr = 0.0081
I0729 01:29:58.997755 118397 solver.cpp:236] Iteration 10580, loss = 0.598836
I0729 01:29:58.997931 118397 solver.cpp:252]     Train net output #0: loss = 0.417542 (* 1 = 0.417542 loss)
I0729 01:29:58.997956 118397 sgd_solver.cpp:106] Iteration 10580, lr = 0.0081
I0729 01:30:30.947340 118397 solver.cpp:236] Iteration 10590, loss = 0.595183
I0729 01:30:30.947605 118397 solver.cpp:252]     Train net output #0: loss = 0.655367 (* 1 = 0.655367 loss)
I0729 01:30:30.947621 118397 sgd_solver.cpp:106] Iteration 10590, lr = 0.0081
I0729 01:31:05.876453 118397 solver.cpp:236] Iteration 10600, loss = 0.597947
I0729 01:31:05.876611 118397 solver.cpp:252]     Train net output #0: loss = 0.636554 (* 1 = 0.636554 loss)
I0729 01:31:05.876631 118397 sgd_solver.cpp:106] Iteration 10600, lr = 0.0081
I0729 01:31:34.625785 118397 solver.cpp:236] Iteration 10610, loss = 0.6049
I0729 01:31:34.625861 118397 solver.cpp:252]     Train net output #0: loss = 0.638243 (* 1 = 0.638243 loss)
I0729 01:31:34.625879 118397 sgd_solver.cpp:106] Iteration 10610, lr = 0.0081
I0729 01:32:11.133440 118397 solver.cpp:236] Iteration 10620, loss = 0.60977
I0729 01:32:11.133594 118397 solver.cpp:252]     Train net output #0: loss = 0.639882 (* 1 = 0.639882 loss)
I0729 01:32:11.133618 118397 sgd_solver.cpp:106] Iteration 10620, lr = 0.0081
I0729 01:32:41.948011 118397 solver.cpp:236] Iteration 10630, loss = 0.615009
I0729 01:32:41.948163 118397 solver.cpp:252]     Train net output #0: loss = 0.632728 (* 1 = 0.632728 loss)
I0729 01:32:41.948184 118397 sgd_solver.cpp:106] Iteration 10630, lr = 0.0081
I0729 01:33:16.216141 118397 solver.cpp:236] Iteration 10640, loss = 0.609665
I0729 01:33:16.216528 118397 solver.cpp:252]     Train net output #0: loss = 0.646457 (* 1 = 0.646457 loss)
I0729 01:33:16.216552 118397 sgd_solver.cpp:106] Iteration 10640, lr = 0.0081
I0729 01:33:51.061839 118397 solver.cpp:236] Iteration 10650, loss = 0.608063
I0729 01:33:51.062026 118397 solver.cpp:252]     Train net output #0: loss = 0.639677 (* 1 = 0.639677 loss)
I0729 01:33:51.062050 118397 sgd_solver.cpp:106] Iteration 10650, lr = 0.0081
I0729 01:34:25.047669 118397 solver.cpp:236] Iteration 10660, loss = 0.610835
I0729 01:34:25.047827 118397 solver.cpp:252]     Train net output #0: loss = 0.632761 (* 1 = 0.632761 loss)
I0729 01:34:25.047850 118397 sgd_solver.cpp:106] Iteration 10660, lr = 0.0081
I0729 01:34:59.447010 118397 solver.cpp:236] Iteration 10670, loss = 0.616267
I0729 01:34:59.447196 118397 solver.cpp:252]     Train net output #0: loss = 0.64032 (* 1 = 0.64032 loss)
I0729 01:34:59.447213 118397 sgd_solver.cpp:106] Iteration 10670, lr = 0.0081
I0729 01:35:29.816884 118397 solver.cpp:236] Iteration 10680, loss = 0.619916
I0729 01:35:29.817059 118397 solver.cpp:252]     Train net output #0: loss = 0.632823 (* 1 = 0.632823 loss)
I0729 01:35:29.817078 118397 sgd_solver.cpp:106] Iteration 10680, lr = 0.0081
I0729 01:36:02.182029 118397 solver.cpp:236] Iteration 10690, loss = 0.616939
I0729 01:36:02.182204 118397 solver.cpp:252]     Train net output #0: loss = 0.661668 (* 1 = 0.661668 loss)
I0729 01:36:02.182221 118397 sgd_solver.cpp:106] Iteration 10690, lr = 0.0081
I0729 01:36:34.866879 118397 solver.cpp:236] Iteration 10700, loss = 0.607738
I0729 01:36:34.867107 118397 solver.cpp:252]     Train net output #0: loss = 0.707343 (* 1 = 0.707343 loss)
I0729 01:36:34.867126 118397 sgd_solver.cpp:106] Iteration 10700, lr = 0.0081
I0729 01:37:00.854836 118397 solver.cpp:236] Iteration 10710, loss = 0.600846
I0729 01:37:00.854914 118397 solver.cpp:252]     Train net output #0: loss = 0.646725 (* 1 = 0.646725 loss)
I0729 01:37:00.854931 118397 sgd_solver.cpp:106] Iteration 10710, lr = 0.0081
I0729 01:37:32.670948 118397 solver.cpp:236] Iteration 10720, loss = 0.595467
I0729 01:37:32.671063 118397 solver.cpp:252]     Train net output #0: loss = 0.350541 (* 1 = 0.350541 loss)
I0729 01:37:32.671079 118397 sgd_solver.cpp:106] Iteration 10720, lr = 0.0081
I0729 01:38:09.864508 118397 solver.cpp:236] Iteration 10730, loss = 0.595577
I0729 01:38:09.864687 118397 solver.cpp:252]     Train net output #0: loss = 0.62852 (* 1 = 0.62852 loss)
I0729 01:38:09.864704 118397 sgd_solver.cpp:106] Iteration 10730, lr = 0.0081
I0729 01:38:37.791466 118397 solver.cpp:236] Iteration 10740, loss = 0.596071
I0729 01:38:37.791543 118397 solver.cpp:252]     Train net output #0: loss = 0.638264 (* 1 = 0.638264 loss)
I0729 01:38:37.791565 118397 sgd_solver.cpp:106] Iteration 10740, lr = 0.0081
I0729 01:39:08.637290 118397 solver.cpp:236] Iteration 10750, loss = 0.596064
I0729 01:39:08.637527 118397 solver.cpp:252]     Train net output #0: loss = 0.27131 (* 1 = 0.27131 loss)
I0729 01:39:08.637553 118397 sgd_solver.cpp:106] Iteration 10750, lr = 0.0081
I0729 01:39:43.403439 118397 solver.cpp:236] Iteration 10760, loss = 0.590784
I0729 01:39:43.403578 118397 solver.cpp:252]     Train net output #0: loss = 0.639743 (* 1 = 0.639743 loss)
I0729 01:39:43.403597 118397 sgd_solver.cpp:106] Iteration 10760, lr = 0.0081
I0729 01:40:17.915668 118397 solver.cpp:236] Iteration 10770, loss = 0.588312
I0729 01:40:17.915814 118397 solver.cpp:252]     Train net output #0: loss = 0.647559 (* 1 = 0.647559 loss)
I0729 01:40:17.915832 118397 sgd_solver.cpp:106] Iteration 10770, lr = 0.0081
I0729 01:40:52.735877 118397 solver.cpp:236] Iteration 10780, loss = 0.586495
I0729 01:40:52.736017 118397 solver.cpp:252]     Train net output #0: loss = 0.427978 (* 1 = 0.427978 loss)
I0729 01:40:52.736038 118397 sgd_solver.cpp:106] Iteration 10780, lr = 0.0081
I0729 01:41:18.368782 118397 solver.cpp:236] Iteration 10790, loss = 0.594507
I0729 01:41:18.368855 118397 solver.cpp:252]     Train net output #0: loss = 0.635787 (* 1 = 0.635787 loss)
I0729 01:41:18.368870 118397 sgd_solver.cpp:106] Iteration 10790, lr = 0.0081
I0729 01:41:53.330569 118397 solver.cpp:236] Iteration 10800, loss = 0.599821
I0729 01:41:53.330791 118397 solver.cpp:252]     Train net output #0: loss = 0.645454 (* 1 = 0.645454 loss)
I0729 01:41:53.330821 118397 sgd_solver.cpp:106] Iteration 10800, lr = 0.0081
I0729 01:42:30.578510 118397 solver.cpp:236] Iteration 10810, loss = 0.603629
I0729 01:42:30.578737 118397 solver.cpp:252]     Train net output #0: loss = 0.640307 (* 1 = 0.640307 loss)
I0729 01:42:30.578758 118397 sgd_solver.cpp:106] Iteration 10810, lr = 0.0081
I0729 01:43:04.660336 118397 solver.cpp:236] Iteration 10820, loss = 0.609896
I0729 01:43:04.660501 118397 solver.cpp:252]     Train net output #0: loss = 0.630185 (* 1 = 0.630185 loss)
I0729 01:43:04.660518 118397 sgd_solver.cpp:106] Iteration 10820, lr = 0.0081
I0729 01:43:36.724086 118397 solver.cpp:236] Iteration 10830, loss = 0.605148
I0729 01:43:36.724254 118397 solver.cpp:252]     Train net output #0: loss = 0.643318 (* 1 = 0.643318 loss)
I0729 01:43:36.724277 118397 sgd_solver.cpp:106] Iteration 10830, lr = 0.0081
I0729 01:44:12.804249 118397 solver.cpp:236] Iteration 10840, loss = 0.609815
I0729 01:44:12.804388 118397 solver.cpp:252]     Train net output #0: loss = 0.631094 (* 1 = 0.631094 loss)
I0729 01:44:12.804405 118397 sgd_solver.cpp:106] Iteration 10840, lr = 0.0081
I0729 01:44:51.586309 118397 solver.cpp:236] Iteration 10850, loss = 0.613181
I0729 01:44:51.586443 118397 solver.cpp:252]     Train net output #0: loss = 0.633884 (* 1 = 0.633884 loss)
I0729 01:44:51.586459 118397 sgd_solver.cpp:106] Iteration 10850, lr = 0.0081
I0729 01:45:25.421797 118397 solver.cpp:236] Iteration 10860, loss = 0.612442
I0729 01:45:25.421958 118397 solver.cpp:252]     Train net output #0: loss = 0.65929 (* 1 = 0.65929 loss)
I0729 01:45:25.422004 118397 sgd_solver.cpp:106] Iteration 10860, lr = 0.0081
I0729 01:45:55.211554 118397 solver.cpp:236] Iteration 10870, loss = 0.61262
I0729 01:45:55.211628 118397 solver.cpp:252]     Train net output #0: loss = 0.644487 (* 1 = 0.644487 loss)
I0729 01:45:55.211645 118397 sgd_solver.cpp:106] Iteration 10870, lr = 0.0081
I0729 01:46:27.571094 118397 solver.cpp:236] Iteration 10880, loss = 0.609415
I0729 01:46:27.571385 118397 solver.cpp:252]     Train net output #0: loss = 0.639768 (* 1 = 0.639768 loss)
I0729 01:46:27.571406 118397 sgd_solver.cpp:106] Iteration 10880, lr = 0.0081
I0729 01:47:09.103188 118397 solver.cpp:236] Iteration 10890, loss = 0.607144
I0729 01:47:09.103381 118397 solver.cpp:252]     Train net output #0: loss = 0.643997 (* 1 = 0.643997 loss)
I0729 01:47:09.103415 118397 sgd_solver.cpp:106] Iteration 10890, lr = 0.0081
I0729 01:47:41.841454 118397 solver.cpp:236] Iteration 10900, loss = 0.600614
I0729 01:47:41.841636 118397 solver.cpp:252]     Train net output #0: loss = 0.288049 (* 1 = 0.288049 loss)
I0729 01:47:41.841665 118397 sgd_solver.cpp:106] Iteration 10900, lr = 0.0081
I0729 01:48:13.840631 118397 solver.cpp:236] Iteration 10910, loss = 0.603516
I0729 01:48:13.840771 118397 solver.cpp:252]     Train net output #0: loss = 0.642773 (* 1 = 0.642773 loss)
I0729 01:48:13.840788 118397 sgd_solver.cpp:106] Iteration 10910, lr = 0.0081
I0729 01:48:52.836452 118397 solver.cpp:236] Iteration 10920, loss = 0.597329
I0729 01:48:52.836585 118397 solver.cpp:252]     Train net output #0: loss = 0.372119 (* 1 = 0.372119 loss)
I0729 01:48:52.836601 118397 sgd_solver.cpp:106] Iteration 10920, lr = 0.0081
I0729 01:49:24.438957 118397 solver.cpp:236] Iteration 10930, loss = 0.59652
I0729 01:49:24.439177 118397 solver.cpp:252]     Train net output #0: loss = 0.645682 (* 1 = 0.645682 loss)
I0729 01:49:24.439194 118397 sgd_solver.cpp:106] Iteration 10930, lr = 0.0081
I0729 01:49:59.144709 118397 solver.cpp:236] Iteration 10940, loss = 0.594078
I0729 01:49:59.144920 118397 solver.cpp:252]     Train net output #0: loss = 0.631268 (* 1 = 0.631268 loss)
I0729 01:49:59.144948 118397 sgd_solver.cpp:106] Iteration 10940, lr = 0.0081
I0729 01:50:28.132520 118397 solver.cpp:236] Iteration 10950, loss = 0.590556
I0729 01:50:28.132587 118397 solver.cpp:252]     Train net output #0: loss = 0.637539 (* 1 = 0.637539 loss)
I0729 01:50:28.132603 118397 sgd_solver.cpp:106] Iteration 10950, lr = 0.0081
I0729 01:51:06.942797 118397 solver.cpp:236] Iteration 10960, loss = 0.59666
I0729 01:51:06.943084 118397 solver.cpp:252]     Train net output #0: loss = 0.633987 (* 1 = 0.633987 loss)
I0729 01:51:06.943104 118397 sgd_solver.cpp:106] Iteration 10960, lr = 0.0081
I0729 01:51:41.587038 118397 solver.cpp:236] Iteration 10970, loss = 0.593959
I0729 01:51:41.587230 118397 solver.cpp:252]     Train net output #0: loss = 0.640594 (* 1 = 0.640594 loss)
I0729 01:51:41.587260 118397 sgd_solver.cpp:106] Iteration 10970, lr = 0.0081
I0729 01:52:13.330860 118397 solver.cpp:236] Iteration 10980, loss = 0.596884
I0729 01:52:13.330998 118397 solver.cpp:252]     Train net output #0: loss = 0.633718 (* 1 = 0.633718 loss)
I0729 01:52:13.331017 118397 sgd_solver.cpp:106] Iteration 10980, lr = 0.0081
I0729 01:52:50.887869 118397 solver.cpp:236] Iteration 10990, loss = 0.596698
I0729 01:52:50.888010 118397 solver.cpp:252]     Train net output #0: loss = 0.633675 (* 1 = 0.633675 loss)
I0729 01:52:50.888026 118397 sgd_solver.cpp:106] Iteration 10990, lr = 0.0081
I0729 01:53:26.243993 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_11000.caffemodel
I0729 01:53:26.369822 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_11000.solverstate
I0729 01:53:26.373536 118397 solver.cpp:340] Iteration 11000, Testing net (#0)
I0729 01:53:57.497922 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 01:53:57.498090 118397 solver.cpp:408]     Test net output #1: loss = 0.633903 (* 1 = 0.633903 loss)
I0729 01:53:59.445117 118397 solver.cpp:236] Iteration 11000, loss = 0.605722
I0729 01:53:59.445173 118397 solver.cpp:252]     Train net output #0: loss = 0.63279 (* 1 = 0.63279 loss)
I0729 01:53:59.445190 118397 sgd_solver.cpp:106] Iteration 11000, lr = 0.0081
I0729 01:54:27.099755 118397 solver.cpp:236] Iteration 11010, loss = 0.605632
I0729 01:54:27.099858 118397 solver.cpp:252]     Train net output #0: loss = 0.642032 (* 1 = 0.642032 loss)
I0729 01:54:27.099884 118397 sgd_solver.cpp:106] Iteration 11010, lr = 0.0081
I0729 01:55:01.647714 118397 solver.cpp:236] Iteration 11020, loss = 0.605581
I0729 01:55:01.647866 118397 solver.cpp:252]     Train net output #0: loss = 0.656164 (* 1 = 0.656164 loss)
I0729 01:55:01.647882 118397 sgd_solver.cpp:106] Iteration 11020, lr = 0.0081
I0729 01:55:38.751477 118397 solver.cpp:236] Iteration 11030, loss = 0.612352
I0729 01:55:38.751807 118397 solver.cpp:252]     Train net output #0: loss = 0.638265 (* 1 = 0.638265 loss)
I0729 01:55:38.751960 118397 sgd_solver.cpp:106] Iteration 11030, lr = 0.0081
I0729 01:56:11.776012 118397 solver.cpp:236] Iteration 11040, loss = 0.612945
I0729 01:56:11.776180 118397 solver.cpp:252]     Train net output #0: loss = 0.636093 (* 1 = 0.636093 loss)
I0729 01:56:11.776208 118397 sgd_solver.cpp:106] Iteration 11040, lr = 0.0081
I0729 01:56:50.770771 118397 solver.cpp:236] Iteration 11050, loss = 0.61602
I0729 01:56:50.771013 118397 solver.cpp:252]     Train net output #0: loss = 0.642075 (* 1 = 0.642075 loss)
I0729 01:56:50.771039 118397 sgd_solver.cpp:106] Iteration 11050, lr = 0.0081
I0729 01:57:25.237088 118397 solver.cpp:236] Iteration 11060, loss = 0.612899
I0729 01:57:25.237404 118397 solver.cpp:252]     Train net output #0: loss = 0.637711 (* 1 = 0.637711 loss)
I0729 01:57:25.237429 118397 sgd_solver.cpp:106] Iteration 11060, lr = 0.0081
I0729 01:58:00.673802 118397 solver.cpp:236] Iteration 11070, loss = 0.612603
I0729 01:58:00.673976 118397 solver.cpp:252]     Train net output #0: loss = 0.652558 (* 1 = 0.652558 loss)
I0729 01:58:00.674020 118397 sgd_solver.cpp:106] Iteration 11070, lr = 0.0081
I0729 01:58:42.579632 118397 solver.cpp:236] Iteration 11080, loss = 0.605693
I0729 01:58:42.579866 118397 solver.cpp:252]     Train net output #0: loss = 0.282239 (* 1 = 0.282239 loss)
I0729 01:58:42.579893 118397 sgd_solver.cpp:106] Iteration 11080, lr = 0.0081
I0729 01:59:15.964802 118397 solver.cpp:236] Iteration 11090, loss = 0.60302
I0729 01:59:15.964982 118397 solver.cpp:252]     Train net output #0: loss = 0.65614 (* 1 = 0.65614 loss)
I0729 01:59:15.965004 118397 sgd_solver.cpp:106] Iteration 11090, lr = 0.0081
I0729 01:59:55.952262 118397 solver.cpp:236] Iteration 11100, loss = 0.601002
I0729 01:59:55.952447 118397 solver.cpp:252]     Train net output #0: loss = 0.637118 (* 1 = 0.637118 loss)
I0729 01:59:55.952462 118397 sgd_solver.cpp:106] Iteration 11100, lr = 0.0081
I0729 02:00:39.292098 118397 solver.cpp:236] Iteration 11110, loss = 0.600365
I0729 02:00:39.292299 118397 solver.cpp:252]     Train net output #0: loss = 0.638412 (* 1 = 0.638412 loss)
I0729 02:00:39.292330 118397 sgd_solver.cpp:106] Iteration 11110, lr = 0.0081
I0729 02:01:22.227548 118397 solver.cpp:236] Iteration 11120, loss = 0.605672
I0729 02:01:22.227722 118397 solver.cpp:252]     Train net output #0: loss = 0.63518 (* 1 = 0.63518 loss)
I0729 02:01:22.227743 118397 sgd_solver.cpp:106] Iteration 11120, lr = 0.0081
I0729 02:02:05.752902 118397 solver.cpp:236] Iteration 11130, loss = 0.599934
I0729 02:02:05.758702 118397 solver.cpp:252]     Train net output #0: loss = 0.641534 (* 1 = 0.641534 loss)
I0729 02:02:05.758735 118397 sgd_solver.cpp:106] Iteration 11130, lr = 0.0081
I0729 02:02:44.753633 118397 solver.cpp:236] Iteration 11140, loss = 0.599554
I0729 02:02:44.753830 118397 solver.cpp:252]     Train net output #0: loss = 0.644276 (* 1 = 0.644276 loss)
I0729 02:02:44.753857 118397 sgd_solver.cpp:106] Iteration 11140, lr = 0.0081
I0729 02:03:16.216648 118397 solver.cpp:236] Iteration 11150, loss = 0.599491
I0729 02:03:16.216802 118397 solver.cpp:252]     Train net output #0: loss = 0.640037 (* 1 = 0.640037 loss)
I0729 02:03:16.216842 118397 sgd_solver.cpp:106] Iteration 11150, lr = 0.0081
I0729 02:03:54.791136 118397 solver.cpp:236] Iteration 11160, loss = 0.593641
I0729 02:03:54.791404 118397 solver.cpp:252]     Train net output #0: loss = 0.645116 (* 1 = 0.645116 loss)
I0729 02:03:54.791442 118397 sgd_solver.cpp:106] Iteration 11160, lr = 0.0081
I0729 02:04:33.124164 118397 solver.cpp:236] Iteration 11170, loss = 0.600653
I0729 02:04:33.124347 118397 solver.cpp:252]     Train net output #0: loss = 0.643539 (* 1 = 0.643539 loss)
I0729 02:04:33.124368 118397 sgd_solver.cpp:106] Iteration 11170, lr = 0.0081
I0729 02:05:12.170266 118397 solver.cpp:236] Iteration 11180, loss = 0.60744
I0729 02:05:12.170444 118397 solver.cpp:252]     Train net output #0: loss = 0.629212 (* 1 = 0.629212 loss)
I0729 02:05:12.170466 118397 sgd_solver.cpp:106] Iteration 11180, lr = 0.0081
I0729 02:05:52.007170 118397 solver.cpp:236] Iteration 11190, loss = 0.605385
I0729 02:05:52.007357 118397 solver.cpp:252]     Train net output #0: loss = 0.66822 (* 1 = 0.66822 loss)
I0729 02:05:52.007388 118397 sgd_solver.cpp:106] Iteration 11190, lr = 0.0081
I0729 02:06:27.045464 118397 solver.cpp:236] Iteration 11200, loss = 0.602978
I0729 02:06:27.045605 118397 solver.cpp:252]     Train net output #0: loss = 0.642068 (* 1 = 0.642068 loss)
I0729 02:06:27.045624 118397 sgd_solver.cpp:106] Iteration 11200, lr = 0.0081
I0729 02:07:03.994084 118397 solver.cpp:236] Iteration 11210, loss = 0.603243
I0729 02:07:03.994257 118397 solver.cpp:252]     Train net output #0: loss = 0.640357 (* 1 = 0.640357 loss)
I0729 02:07:03.994277 118397 sgd_solver.cpp:106] Iteration 11210, lr = 0.0081
I0729 02:07:42.568316 118397 solver.cpp:236] Iteration 11220, loss = 0.603394
I0729 02:07:42.568467 118397 solver.cpp:252]     Train net output #0: loss = 0.637755 (* 1 = 0.637755 loss)
I0729 02:07:42.568487 118397 sgd_solver.cpp:106] Iteration 11220, lr = 0.0081
I0729 02:08:17.793629 118397 solver.cpp:236] Iteration 11230, loss = 0.603553
I0729 02:08:17.793812 118397 solver.cpp:252]     Train net output #0: loss = 0.643054 (* 1 = 0.643054 loss)
I0729 02:08:17.793834 118397 sgd_solver.cpp:106] Iteration 11230, lr = 0.0081
I0729 02:09:02.935195 118397 solver.cpp:236] Iteration 11240, loss = 0.596011
I0729 02:09:02.935478 118397 solver.cpp:252]     Train net output #0: loss = 0.697687 (* 1 = 0.697687 loss)
I0729 02:09:02.935530 118397 sgd_solver.cpp:106] Iteration 11240, lr = 0.0081
I0729 02:09:44.680627 118397 solver.cpp:236] Iteration 11250, loss = 0.6028
I0729 02:09:44.680785 118397 solver.cpp:252]     Train net output #0: loss = 0.642179 (* 1 = 0.642179 loss)
I0729 02:09:44.680805 118397 sgd_solver.cpp:106] Iteration 11250, lr = 0.0081
I0729 02:10:25.479755 118397 solver.cpp:236] Iteration 11260, loss = 0.609387
I0729 02:10:25.482698 118397 solver.cpp:252]     Train net output #0: loss = 0.635104 (* 1 = 0.635104 loss)
I0729 02:10:25.482723 118397 sgd_solver.cpp:106] Iteration 11260, lr = 0.0081
I0729 02:11:02.893563 118397 solver.cpp:236] Iteration 11270, loss = 0.605339
I0729 02:11:02.893775 118397 solver.cpp:252]     Train net output #0: loss = 0.645952 (* 1 = 0.645952 loss)
I0729 02:11:02.893803 118397 sgd_solver.cpp:106] Iteration 11270, lr = 0.0081
I0729 02:11:37.826247 118397 solver.cpp:236] Iteration 11280, loss = 0.602402
I0729 02:11:37.826426 118397 solver.cpp:252]     Train net output #0: loss = 0.64185 (* 1 = 0.64185 loss)
I0729 02:11:37.826447 118397 sgd_solver.cpp:106] Iteration 11280, lr = 0.0081
I0729 02:12:17.570544 118397 solver.cpp:236] Iteration 11290, loss = 0.610525
I0729 02:12:17.570822 118397 solver.cpp:252]     Train net output #0: loss = 0.637318 (* 1 = 0.637318 loss)
I0729 02:12:17.570840 118397 sgd_solver.cpp:106] Iteration 11290, lr = 0.0081
I0729 02:12:58.778360 118397 solver.cpp:236] Iteration 11300, loss = 0.612252
I0729 02:12:58.778590 118397 solver.cpp:252]     Train net output #0: loss = 0.630267 (* 1 = 0.630267 loss)
I0729 02:12:58.778621 118397 sgd_solver.cpp:106] Iteration 11300, lr = 0.0081
I0729 02:13:36.423862 118397 solver.cpp:236] Iteration 11310, loss = 0.614548
I0729 02:13:36.424021 118397 solver.cpp:252]     Train net output #0: loss = 0.629804 (* 1 = 0.629804 loss)
I0729 02:13:36.424041 118397 sgd_solver.cpp:106] Iteration 11310, lr = 0.0081
I0729 02:14:13.591549 118397 solver.cpp:236] Iteration 11320, loss = 0.609299
I0729 02:14:13.591724 118397 solver.cpp:252]     Train net output #0: loss = 0.640292 (* 1 = 0.640292 loss)
I0729 02:14:13.591749 118397 sgd_solver.cpp:106] Iteration 11320, lr = 0.0081
I0729 02:14:57.558480 118397 solver.cpp:236] Iteration 11330, loss = 0.612179
I0729 02:14:57.558655 118397 solver.cpp:252]     Train net output #0: loss = 0.643295 (* 1 = 0.643295 loss)
I0729 02:14:57.558676 118397 sgd_solver.cpp:106] Iteration 11330, lr = 0.0081
I0729 02:15:39.811283 118397 solver.cpp:236] Iteration 11340, loss = 0.616542
I0729 02:15:39.811465 118397 solver.cpp:252]     Train net output #0: loss = 0.349161 (* 1 = 0.349161 loss)
I0729 02:15:39.811494 118397 sgd_solver.cpp:106] Iteration 11340, lr = 0.0081
I0729 02:16:17.439590 118397 solver.cpp:236] Iteration 11350, loss = 0.612615
I0729 02:16:17.439723 118397 solver.cpp:252]     Train net output #0: loss = 0.644285 (* 1 = 0.644285 loss)
I0729 02:16:17.439751 118397 sgd_solver.cpp:106] Iteration 11350, lr = 0.0081
I0729 02:16:47.732147 118397 solver.cpp:236] Iteration 11360, loss = 0.609008
I0729 02:16:47.732324 118397 solver.cpp:252]     Train net output #0: loss = 0.64255 (* 1 = 0.64255 loss)
I0729 02:16:47.732363 118397 sgd_solver.cpp:106] Iteration 11360, lr = 0.0081
I0729 02:17:26.496263 118397 solver.cpp:236] Iteration 11370, loss = 0.608882
I0729 02:17:26.496399 118397 solver.cpp:252]     Train net output #0: loss = 0.634387 (* 1 = 0.634387 loss)
I0729 02:17:26.496423 118397 sgd_solver.cpp:106] Iteration 11370, lr = 0.0081
I0729 02:18:03.655019 118397 solver.cpp:236] Iteration 11380, loss = 0.609998
I0729 02:18:03.655182 118397 solver.cpp:252]     Train net output #0: loss = 0.662063 (* 1 = 0.662063 loss)
I0729 02:18:03.655200 118397 sgd_solver.cpp:106] Iteration 11380, lr = 0.0081
I0729 02:18:42.842674 118397 solver.cpp:236] Iteration 11390, loss = 0.606931
I0729 02:18:42.842892 118397 solver.cpp:252]     Train net output #0: loss = 0.633397 (* 1 = 0.633397 loss)
I0729 02:18:42.842921 118397 sgd_solver.cpp:106] Iteration 11390, lr = 0.0081
I0729 02:19:19.851683 118397 solver.cpp:236] Iteration 11400, loss = 0.607319
I0729 02:19:19.851866 118397 solver.cpp:252]     Train net output #0: loss = 0.637966 (* 1 = 0.637966 loss)
I0729 02:19:19.851897 118397 sgd_solver.cpp:106] Iteration 11400, lr = 0.0081
I0729 02:19:56.368460 118397 solver.cpp:236] Iteration 11410, loss = 0.607583
I0729 02:19:56.368620 118397 solver.cpp:252]     Train net output #0: loss = 0.636144 (* 1 = 0.636144 loss)
I0729 02:19:56.368638 118397 sgd_solver.cpp:106] Iteration 11410, lr = 0.0081
I0729 02:20:29.580791 118397 solver.cpp:236] Iteration 11420, loss = 0.610225
I0729 02:20:29.580958 118397 solver.cpp:252]     Train net output #0: loss = 0.637252 (* 1 = 0.637252 loss)
I0729 02:20:29.580988 118397 sgd_solver.cpp:106] Iteration 11420, lr = 0.0081
I0729 02:21:15.304821 118397 solver.cpp:236] Iteration 11430, loss = 0.611829
I0729 02:21:15.305032 118397 solver.cpp:252]     Train net output #0: loss = 0.638837 (* 1 = 0.638837 loss)
I0729 02:21:15.305073 118397 sgd_solver.cpp:106] Iteration 11430, lr = 0.0081
I0729 02:21:51.613715 118397 solver.cpp:236] Iteration 11440, loss = 0.612177
I0729 02:21:51.613849 118397 solver.cpp:252]     Train net output #0: loss = 0.637589 (* 1 = 0.637589 loss)
I0729 02:21:51.613868 118397 sgd_solver.cpp:106] Iteration 11440, lr = 0.0081
I0729 02:22:33.724303 118397 solver.cpp:236] Iteration 11450, loss = 0.612616
I0729 02:22:33.724505 118397 solver.cpp:252]     Train net output #0: loss = 0.626739 (* 1 = 0.626739 loss)
I0729 02:22:33.724546 118397 sgd_solver.cpp:106] Iteration 11450, lr = 0.0081
I0729 02:23:18.833349 118397 solver.cpp:236] Iteration 11460, loss = 0.612553
I0729 02:23:18.833534 118397 solver.cpp:252]     Train net output #0: loss = 0.640993 (* 1 = 0.640993 loss)
I0729 02:23:18.833564 118397 sgd_solver.cpp:106] Iteration 11460, lr = 0.0081
I0729 02:23:56.480139 118397 solver.cpp:236] Iteration 11470, loss = 0.6068
I0729 02:23:56.480309 118397 solver.cpp:252]     Train net output #0: loss = 0.677108 (* 1 = 0.677108 loss)
I0729 02:23:56.480346 118397 sgd_solver.cpp:106] Iteration 11470, lr = 0.0081
I0729 02:24:37.716505 118397 solver.cpp:236] Iteration 11480, loss = 0.601869
I0729 02:24:37.716667 118397 solver.cpp:252]     Train net output #0: loss = 0.665414 (* 1 = 0.665414 loss)
I0729 02:24:37.716684 118397 sgd_solver.cpp:106] Iteration 11480, lr = 0.0081
I0729 02:25:18.600917 118397 solver.cpp:236] Iteration 11490, loss = 0.598786
I0729 02:25:18.601089 118397 solver.cpp:252]     Train net output #0: loss = 0.648414 (* 1 = 0.648414 loss)
I0729 02:25:18.601107 118397 sgd_solver.cpp:106] Iteration 11490, lr = 0.0081
I0729 02:25:46.446354 118397 solver.cpp:340] Iteration 11500, Testing net (#0)
I0729 02:26:28.621374 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 02:26:28.621541 118397 solver.cpp:408]     Test net output #1: loss = 0.614179 (* 1 = 0.614179 loss)
I0729 02:26:31.191159 118397 solver.cpp:236] Iteration 11500, loss = 0.601214
I0729 02:26:31.191241 118397 solver.cpp:252]     Train net output #0: loss = 0.637594 (* 1 = 0.637594 loss)
I0729 02:26:31.191258 118397 sgd_solver.cpp:106] Iteration 11500, lr = 0.0081
I0729 02:27:09.486678 118397 solver.cpp:236] Iteration 11510, loss = 0.601323
I0729 02:27:09.486802 118397 solver.cpp:252]     Train net output #0: loss = 0.638689 (* 1 = 0.638689 loss)
I0729 02:27:09.486817 118397 sgd_solver.cpp:106] Iteration 11510, lr = 0.0081
I0729 02:27:45.829675 118397 solver.cpp:236] Iteration 11520, loss = 0.603875
I0729 02:27:45.829870 118397 solver.cpp:252]     Train net output #0: loss = 0.63377 (* 1 = 0.63377 loss)
I0729 02:27:45.829886 118397 sgd_solver.cpp:106] Iteration 11520, lr = 0.0081
I0729 02:28:28.803151 118397 solver.cpp:236] Iteration 11530, loss = 0.601419
I0729 02:28:28.803407 118397 solver.cpp:252]     Train net output #0: loss = 0.631644 (* 1 = 0.631644 loss)
I0729 02:28:28.803426 118397 sgd_solver.cpp:106] Iteration 11530, lr = 0.0081
I0729 02:29:06.424749 118397 solver.cpp:236] Iteration 11540, loss = 0.606561
I0729 02:29:06.424926 118397 solver.cpp:252]     Train net output #0: loss = 0.639318 (* 1 = 0.639318 loss)
I0729 02:29:06.424943 118397 sgd_solver.cpp:106] Iteration 11540, lr = 0.0081
I0729 02:29:50.189587 118397 solver.cpp:236] Iteration 11550, loss = 0.600668
I0729 02:29:50.189762 118397 solver.cpp:252]     Train net output #0: loss = 0.36085 (* 1 = 0.36085 loss)
I0729 02:29:50.189785 118397 sgd_solver.cpp:106] Iteration 11550, lr = 0.0081
I0729 02:30:27.093881 118397 solver.cpp:236] Iteration 11560, loss = 0.604051
I0729 02:30:27.094058 118397 solver.cpp:252]     Train net output #0: loss = 0.658737 (* 1 = 0.658737 loss)
I0729 02:30:27.094079 118397 sgd_solver.cpp:106] Iteration 11560, lr = 0.0081
I0729 02:31:09.485092 118397 solver.cpp:236] Iteration 11570, loss = 0.609186
I0729 02:31:09.485240 118397 solver.cpp:252]     Train net output #0: loss = 0.628611 (* 1 = 0.628611 loss)
I0729 02:31:09.485267 118397 sgd_solver.cpp:106] Iteration 11570, lr = 0.0081
I0729 02:31:54.587230 118397 solver.cpp:236] Iteration 11580, loss = 0.616047
I0729 02:31:54.587429 118397 solver.cpp:252]     Train net output #0: loss = 0.633144 (* 1 = 0.633144 loss)
I0729 02:31:54.587451 118397 sgd_solver.cpp:106] Iteration 11580, lr = 0.0081
I0729 02:32:32.370152 118397 solver.cpp:236] Iteration 11590, loss = 0.621595
I0729 02:32:32.370354 118397 solver.cpp:252]     Train net output #0: loss = 0.630631 (* 1 = 0.630631 loss)
I0729 02:32:32.370381 118397 sgd_solver.cpp:106] Iteration 11590, lr = 0.0081
I0729 02:33:15.503646 118397 solver.cpp:236] Iteration 11600, loss = 0.616773
I0729 02:33:15.503832 118397 solver.cpp:252]     Train net output #0: loss = 0.653084 (* 1 = 0.653084 loss)
I0729 02:33:15.503867 118397 sgd_solver.cpp:106] Iteration 11600, lr = 0.0081
I0729 02:33:54.153554 118397 solver.cpp:236] Iteration 11610, loss = 0.617399
I0729 02:33:54.153769 118397 solver.cpp:252]     Train net output #0: loss = 0.636715 (* 1 = 0.636715 loss)
I0729 02:33:54.153797 118397 sgd_solver.cpp:106] Iteration 11610, lr = 0.0081
I0729 02:34:29.879971 118397 solver.cpp:236] Iteration 11620, loss = 0.615082
I0729 02:34:29.880151 118397 solver.cpp:252]     Train net output #0: loss = 0.633998 (* 1 = 0.633998 loss)
I0729 02:34:29.880183 118397 sgd_solver.cpp:106] Iteration 11620, lr = 0.0081
I0729 02:35:19.868607 118397 solver.cpp:236] Iteration 11630, loss = 0.615111
I0729 02:35:19.868752 118397 solver.cpp:252]     Train net output #0: loss = 0.639672 (* 1 = 0.639672 loss)
I0729 02:35:19.868773 118397 sgd_solver.cpp:106] Iteration 11630, lr = 0.0081
I0729 02:35:53.405434 118397 solver.cpp:236] Iteration 11640, loss = 0.612372
I0729 02:35:53.405570 118397 solver.cpp:252]     Train net output #0: loss = 0.629491 (* 1 = 0.629491 loss)
I0729 02:35:53.405588 118397 sgd_solver.cpp:106] Iteration 11640, lr = 0.0081
I0729 02:36:31.458292 118397 solver.cpp:236] Iteration 11650, loss = 0.612895
I0729 02:36:31.458523 118397 solver.cpp:252]     Train net output #0: loss = 0.635278 (* 1 = 0.635278 loss)
I0729 02:36:31.458542 118397 sgd_solver.cpp:106] Iteration 11650, lr = 0.0081
I0729 02:37:18.346979 118397 solver.cpp:236] Iteration 11660, loss = 0.61382
I0729 02:37:18.347134 118397 solver.cpp:252]     Train net output #0: loss = 0.653792 (* 1 = 0.653792 loss)
I0729 02:37:18.347153 118397 sgd_solver.cpp:106] Iteration 11660, lr = 0.0081
I0729 02:37:50.803974 118397 solver.cpp:236] Iteration 11670, loss = 0.613791
I0729 02:37:50.804155 118397 solver.cpp:252]     Train net output #0: loss = 0.640008 (* 1 = 0.640008 loss)
I0729 02:37:50.804188 118397 sgd_solver.cpp:106] Iteration 11670, lr = 0.0081
I0729 02:38:23.687455 118397 solver.cpp:236] Iteration 11680, loss = 0.61196
I0729 02:38:23.687594 118397 solver.cpp:252]     Train net output #0: loss = 0.642396 (* 1 = 0.642396 loss)
I0729 02:38:23.687618 118397 sgd_solver.cpp:106] Iteration 11680, lr = 0.0081
I0729 02:39:02.507632 118397 solver.cpp:236] Iteration 11690, loss = 0.609892
I0729 02:39:02.507819 118397 solver.cpp:252]     Train net output #0: loss = 0.641149 (* 1 = 0.641149 loss)
I0729 02:39:02.507836 118397 sgd_solver.cpp:106] Iteration 11690, lr = 0.0081
I0729 02:39:37.038568 118397 solver.cpp:236] Iteration 11700, loss = 0.61442
I0729 02:39:37.038795 118397 solver.cpp:252]     Train net output #0: loss = 0.638778 (* 1 = 0.638778 loss)
I0729 02:39:37.038812 118397 sgd_solver.cpp:106] Iteration 11700, lr = 0.0081
I0729 02:40:21.833133 118397 solver.cpp:236] Iteration 11710, loss = 0.613378
I0729 02:40:21.833328 118397 solver.cpp:252]     Train net output #0: loss = 0.633976 (* 1 = 0.633976 loss)
I0729 02:40:21.833360 118397 sgd_solver.cpp:106] Iteration 11710, lr = 0.0081
I0729 02:41:01.122541 118397 solver.cpp:236] Iteration 11720, loss = 0.615627
I0729 02:41:01.122706 118397 solver.cpp:252]     Train net output #0: loss = 0.636431 (* 1 = 0.636431 loss)
I0729 02:41:01.122728 118397 sgd_solver.cpp:106] Iteration 11720, lr = 0.0081
I0729 02:41:37.300895 118397 solver.cpp:236] Iteration 11730, loss = 0.615474
I0729 02:41:37.301034 118397 solver.cpp:252]     Train net output #0: loss = 0.635383 (* 1 = 0.635383 loss)
I0729 02:41:37.301050 118397 sgd_solver.cpp:106] Iteration 11730, lr = 0.0081
I0729 02:42:25.660696 118397 solver.cpp:236] Iteration 11740, loss = 0.615624
I0729 02:42:25.660864 118397 solver.cpp:252]     Train net output #0: loss = 0.64425 (* 1 = 0.64425 loss)
I0729 02:42:25.660886 118397 sgd_solver.cpp:106] Iteration 11740, lr = 0.0081
I0729 02:42:59.043619 118397 solver.cpp:236] Iteration 11750, loss = 0.614773
I0729 02:42:59.043750 118397 solver.cpp:252]     Train net output #0: loss = 0.657398 (* 1 = 0.657398 loss)
I0729 02:42:59.043766 118397 sgd_solver.cpp:106] Iteration 11750, lr = 0.0081
I0729 02:43:40.673467 118397 solver.cpp:236] Iteration 11760, loss = 0.613362
I0729 02:43:40.673627 118397 solver.cpp:252]     Train net output #0: loss = 0.640029 (* 1 = 0.640029 loss)
I0729 02:43:40.673646 118397 sgd_solver.cpp:106] Iteration 11760, lr = 0.0081
I0729 02:44:21.994199 118397 solver.cpp:236] Iteration 11770, loss = 0.616387
I0729 02:44:21.994392 118397 solver.cpp:252]     Train net output #0: loss = 0.64324 (* 1 = 0.64324 loss)
I0729 02:44:21.994421 118397 sgd_solver.cpp:106] Iteration 11770, lr = 0.0081
I0729 02:44:58.749977 118397 solver.cpp:236] Iteration 11780, loss = 0.618169
I0729 02:44:58.750177 118397 solver.cpp:252]     Train net output #0: loss = 0.639273 (* 1 = 0.639273 loss)
I0729 02:44:58.750216 118397 sgd_solver.cpp:106] Iteration 11780, lr = 0.0081
I0729 02:45:41.850277 118397 solver.cpp:236] Iteration 11790, loss = 0.620911
I0729 02:45:41.850450 118397 solver.cpp:252]     Train net output #0: loss = 0.640387 (* 1 = 0.640387 loss)
I0729 02:45:41.850467 118397 sgd_solver.cpp:106] Iteration 11790, lr = 0.0081
I0729 02:46:20.075244 118397 solver.cpp:236] Iteration 11800, loss = 0.616038
I0729 02:46:20.075475 118397 solver.cpp:252]     Train net output #0: loss = 0.637576 (* 1 = 0.637576 loss)
I0729 02:46:20.075497 118397 sgd_solver.cpp:106] Iteration 11800, lr = 0.0081
I0729 02:46:53.388330 118397 solver.cpp:236] Iteration 11810, loss = 0.616917
I0729 02:46:53.388521 118397 solver.cpp:252]     Train net output #0: loss = 0.637592 (* 1 = 0.637592 loss)
I0729 02:46:53.388546 118397 sgd_solver.cpp:106] Iteration 11810, lr = 0.0081
I0729 02:47:41.444026 118397 solver.cpp:236] Iteration 11820, loss = 0.616926
I0729 02:47:41.444211 118397 solver.cpp:252]     Train net output #0: loss = 0.634055 (* 1 = 0.634055 loss)
I0729 02:47:41.444231 118397 sgd_solver.cpp:106] Iteration 11820, lr = 0.0081
I0729 02:48:19.885999 118397 solver.cpp:236] Iteration 11830, loss = 0.619335
I0729 02:48:19.886237 118397 solver.cpp:252]     Train net output #0: loss = 0.629979 (* 1 = 0.629979 loss)
I0729 02:48:19.886289 118397 sgd_solver.cpp:106] Iteration 11830, lr = 0.0081
I0729 02:48:59.922196 118397 solver.cpp:236] Iteration 11840, loss = 0.612957
I0729 02:48:59.922365 118397 solver.cpp:252]     Train net output #0: loss = 0.273667 (* 1 = 0.273667 loss)
I0729 02:48:59.922411 118397 sgd_solver.cpp:106] Iteration 11840, lr = 0.0081
I0729 02:49:45.420948 118397 solver.cpp:236] Iteration 11850, loss = 0.613769
I0729 02:49:45.421149 118397 solver.cpp:252]     Train net output #0: loss = 0.675107 (* 1 = 0.675107 loss)
I0729 02:49:45.421167 118397 sgd_solver.cpp:106] Iteration 11850, lr = 0.0081
I0729 02:50:19.662776 118397 solver.cpp:236] Iteration 11860, loss = 0.610449
I0729 02:50:19.663077 118397 solver.cpp:252]     Train net output #0: loss = 0.64607 (* 1 = 0.64607 loss)
I0729 02:50:19.663105 118397 sgd_solver.cpp:106] Iteration 11860, lr = 0.0081
I0729 02:51:06.876554 118397 solver.cpp:236] Iteration 11870, loss = 0.602531
I0729 02:51:06.876832 118397 solver.cpp:252]     Train net output #0: loss = 0.338218 (* 1 = 0.338218 loss)
I0729 02:51:06.876847 118397 sgd_solver.cpp:106] Iteration 11870, lr = 0.0081
I0729 02:51:41.333174 118397 solver.cpp:236] Iteration 11880, loss = 0.606373
I0729 02:51:41.333348 118397 solver.cpp:252]     Train net output #0: loss = 0.642749 (* 1 = 0.642749 loss)
I0729 02:51:41.333374 118397 sgd_solver.cpp:106] Iteration 11880, lr = 0.0081
I0729 02:52:16.548676 118397 solver.cpp:236] Iteration 11890, loss = 0.605764
I0729 02:52:16.548851 118397 solver.cpp:252]     Train net output #0: loss = 0.633673 (* 1 = 0.633673 loss)
I0729 02:52:16.548871 118397 sgd_solver.cpp:106] Iteration 11890, lr = 0.0081
I0729 02:52:53.131515 118397 solver.cpp:236] Iteration 11900, loss = 0.608936
I0729 02:52:53.131742 118397 solver.cpp:252]     Train net output #0: loss = 0.636184 (* 1 = 0.636184 loss)
I0729 02:52:53.131778 118397 sgd_solver.cpp:106] Iteration 11900, lr = 0.0081
I0729 02:53:34.033589 118397 solver.cpp:236] Iteration 11910, loss = 0.605704
I0729 02:53:34.033747 118397 solver.cpp:252]     Train net output #0: loss = 0.643432 (* 1 = 0.643432 loss)
I0729 02:53:34.033763 118397 sgd_solver.cpp:106] Iteration 11910, lr = 0.0081
I0729 02:54:14.445122 118397 solver.cpp:236] Iteration 11920, loss = 0.605816
I0729 02:54:14.445327 118397 solver.cpp:252]     Train net output #0: loss = 0.635579 (* 1 = 0.635579 loss)
I0729 02:54:14.445349 118397 sgd_solver.cpp:106] Iteration 11920, lr = 0.0081
I0729 02:54:52.518205 118397 solver.cpp:236] Iteration 11930, loss = 0.603584
I0729 02:54:52.526708 118397 solver.cpp:252]     Train net output #0: loss = 0.633715 (* 1 = 0.633715 loss)
I0729 02:54:52.526726 118397 sgd_solver.cpp:106] Iteration 11930, lr = 0.0081
I0729 02:55:31.563098 118397 solver.cpp:236] Iteration 11940, loss = 0.60943
I0729 02:55:31.563246 118397 solver.cpp:252]     Train net output #0: loss = 0.640657 (* 1 = 0.640657 loss)
I0729 02:55:31.563263 118397 sgd_solver.cpp:106] Iteration 11940, lr = 0.0081
I0729 02:56:08.610321 118397 solver.cpp:236] Iteration 11950, loss = 0.608621
I0729 02:56:08.610499 118397 solver.cpp:252]     Train net output #0: loss = 0.657616 (* 1 = 0.657616 loss)
I0729 02:56:08.610538 118397 sgd_solver.cpp:106] Iteration 11950, lr = 0.0081
I0729 02:56:50.447983 118397 solver.cpp:236] Iteration 11960, loss = 0.611879
I0729 02:56:50.454704 118397 solver.cpp:252]     Train net output #0: loss = 0.632794 (* 1 = 0.632794 loss)
I0729 02:56:50.454725 118397 sgd_solver.cpp:106] Iteration 11960, lr = 0.0081
I0729 02:57:29.574717 118397 solver.cpp:236] Iteration 11970, loss = 0.619738
I0729 02:57:29.574877 118397 solver.cpp:252]     Train net output #0: loss = 0.636331 (* 1 = 0.636331 loss)
I0729 02:57:29.574899 118397 sgd_solver.cpp:106] Iteration 11970, lr = 0.0081
I0729 02:58:13.252658 118397 solver.cpp:236] Iteration 11980, loss = 0.61447
I0729 02:58:13.252833 118397 solver.cpp:252]     Train net output #0: loss = 0.647267 (* 1 = 0.647267 loss)
I0729 02:58:13.252876 118397 sgd_solver.cpp:106] Iteration 11980, lr = 0.0081
I0729 02:58:46.426151 118397 solver.cpp:236] Iteration 11990, loss = 0.609067
I0729 02:58:46.426349 118397 solver.cpp:252]     Train net output #0: loss = 0.670444 (* 1 = 0.670444 loss)
I0729 02:58:46.426378 118397 sgd_solver.cpp:106] Iteration 11990, lr = 0.0081
I0729 02:59:15.969944 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_12000.caffemodel
I0729 02:59:16.069802 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_12000.solverstate
I0729 02:59:16.073694 118397 solver.cpp:340] Iteration 12000, Testing net (#0)
I0729 03:00:01.122902 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 03:00:01.123118 118397 solver.cpp:408]     Test net output #1: loss = 0.607591 (* 1 = 0.607591 loss)
I0729 03:00:04.207236 118397 solver.cpp:236] Iteration 12000, loss = 0.608948
I0729 03:00:04.207312 118397 solver.cpp:252]     Train net output #0: loss = 0.63078 (* 1 = 0.63078 loss)
I0729 03:00:04.207329 118397 sgd_solver.cpp:106] Iteration 12000, lr = 0.0081
I0729 03:00:42.463635 118397 solver.cpp:236] Iteration 12010, loss = 0.609313
I0729 03:00:42.463798 118397 solver.cpp:252]     Train net output #0: loss = 0.63498 (* 1 = 0.63498 loss)
I0729 03:00:42.463819 118397 sgd_solver.cpp:106] Iteration 12010, lr = 0.0081
I0729 03:01:28.931771 118397 solver.cpp:236] Iteration 12020, loss = 0.603772
I0729 03:01:28.931993 118397 solver.cpp:252]     Train net output #0: loss = 0.653855 (* 1 = 0.653855 loss)
I0729 03:01:28.932024 118397 sgd_solver.cpp:106] Iteration 12020, lr = 0.0081
I0729 03:02:13.776828 118397 solver.cpp:236] Iteration 12030, loss = 0.597162
I0729 03:02:13.776989 118397 solver.cpp:252]     Train net output #0: loss = 0.675171 (* 1 = 0.675171 loss)
I0729 03:02:13.777009 118397 sgd_solver.cpp:106] Iteration 12030, lr = 0.0081
I0729 03:02:51.411166 118397 solver.cpp:236] Iteration 12040, loss = 0.596637
I0729 03:02:51.418707 118397 solver.cpp:252]     Train net output #0: loss = 0.370407 (* 1 = 0.370407 loss)
I0729 03:02:51.418726 118397 sgd_solver.cpp:106] Iteration 12040, lr = 0.0081
I0729 03:03:33.607785 118397 solver.cpp:236] Iteration 12050, loss = 0.602304
I0729 03:03:33.608007 118397 solver.cpp:252]     Train net output #0: loss = 0.638771 (* 1 = 0.638771 loss)
I0729 03:03:33.608027 118397 sgd_solver.cpp:106] Iteration 12050, lr = 0.0081
I0729 03:04:09.506381 118397 solver.cpp:236] Iteration 12060, loss = 0.604776
I0729 03:04:09.506608 118397 solver.cpp:252]     Train net output #0: loss = 0.634539 (* 1 = 0.634539 loss)
I0729 03:04:09.506625 118397 sgd_solver.cpp:106] Iteration 12060, lr = 0.0081
I0729 03:04:45.287142 118397 solver.cpp:236] Iteration 12070, loss = 0.602452
I0729 03:04:45.290016 118397 solver.cpp:252]     Train net output #0: loss = 0.631983 (* 1 = 0.631983 loss)
I0729 03:04:45.290035 118397 sgd_solver.cpp:106] Iteration 12070, lr = 0.0081
I0729 03:05:21.471916 118397 solver.cpp:236] Iteration 12080, loss = 0.604238
I0729 03:05:21.472139 118397 solver.cpp:252]     Train net output #0: loss = 0.641279 (* 1 = 0.641279 loss)
I0729 03:05:21.472156 118397 sgd_solver.cpp:106] Iteration 12080, lr = 0.0081
I0729 03:05:55.221958 118397 solver.cpp:236] Iteration 12090, loss = 0.60959
I0729 03:05:55.222172 118397 solver.cpp:252]     Train net output #0: loss = 0.633943 (* 1 = 0.633943 loss)
I0729 03:05:55.222189 118397 sgd_solver.cpp:106] Iteration 12090, lr = 0.0081
I0729 03:06:30.159289 118397 solver.cpp:236] Iteration 12100, loss = 0.609463
I0729 03:06:30.166198 118397 solver.cpp:252]     Train net output #0: loss = 0.63632 (* 1 = 0.63632 loss)
I0729 03:06:30.166223 118397 sgd_solver.cpp:106] Iteration 12100, lr = 0.0081
I0729 03:07:12.791560 118397 solver.cpp:236] Iteration 12110, loss = 0.61026
I0729 03:07:12.791743 118397 solver.cpp:252]     Train net output #0: loss = 0.650808 (* 1 = 0.650808 loss)
I0729 03:07:12.791769 118397 sgd_solver.cpp:106] Iteration 12110, lr = 0.0081
I0729 03:07:46.072860 118397 solver.cpp:236] Iteration 12120, loss = 0.610881
I0729 03:07:46.073055 118397 solver.cpp:252]     Train net output #0: loss = 0.637345 (* 1 = 0.637345 loss)
I0729 03:07:46.073094 118397 sgd_solver.cpp:106] Iteration 12120, lr = 0.0081
I0729 03:08:28.917675 118397 solver.cpp:236] Iteration 12130, loss = 0.614023
I0729 03:08:28.917829 118397 solver.cpp:252]     Train net output #0: loss = 0.643762 (* 1 = 0.643762 loss)
I0729 03:08:28.917856 118397 sgd_solver.cpp:106] Iteration 12130, lr = 0.0081
I0729 03:09:11.240164 118397 solver.cpp:236] Iteration 12140, loss = 0.615733
I0729 03:09:11.240340 118397 solver.cpp:252]     Train net output #0: loss = 0.332883 (* 1 = 0.332883 loss)
I0729 03:09:11.240357 118397 sgd_solver.cpp:106] Iteration 12140, lr = 0.0081
I0729 03:09:45.823890 118397 solver.cpp:236] Iteration 12150, loss = 0.61025
I0729 03:09:45.824117 118397 solver.cpp:252]     Train net output #0: loss = 0.356569 (* 1 = 0.356569 loss)
I0729 03:09:45.824163 118397 sgd_solver.cpp:106] Iteration 12150, lr = 0.0081
I0729 03:10:26.917282 118397 solver.cpp:236] Iteration 12160, loss = 0.600758
I0729 03:10:26.917498 118397 solver.cpp:252]     Train net output #0: loss = 0.676994 (* 1 = 0.676994 loss)
I0729 03:10:26.917527 118397 sgd_solver.cpp:106] Iteration 12160, lr = 0.0081
I0729 03:11:05.288364 118397 solver.cpp:236] Iteration 12170, loss = 0.602775
I0729 03:11:05.288532 118397 solver.cpp:252]     Train net output #0: loss = 0.641907 (* 1 = 0.641907 loss)
I0729 03:11:05.288552 118397 sgd_solver.cpp:106] Iteration 12170, lr = 0.0081
I0729 03:11:43.896677 118397 solver.cpp:236] Iteration 12180, loss = 0.600905
I0729 03:11:43.896883 118397 solver.cpp:252]     Train net output #0: loss = 0.424986 (* 1 = 0.424986 loss)
I0729 03:11:43.896920 118397 sgd_solver.cpp:106] Iteration 12180, lr = 0.0081
I0729 03:12:27.593910 118397 solver.cpp:236] Iteration 12190, loss = 0.595673
I0729 03:12:27.594074 118397 solver.cpp:252]     Train net output #0: loss = 0.68106 (* 1 = 0.68106 loss)
I0729 03:12:27.594105 118397 sgd_solver.cpp:106] Iteration 12190, lr = 0.0081
I0729 03:13:09.347264 118397 solver.cpp:236] Iteration 12200, loss = 0.596422
I0729 03:13:09.347508 118397 solver.cpp:252]     Train net output #0: loss = 0.64491 (* 1 = 0.64491 loss)
I0729 03:13:09.347523 118397 sgd_solver.cpp:106] Iteration 12200, lr = 0.0081
I0729 03:13:51.002023 118397 solver.cpp:236] Iteration 12210, loss = 0.595171
I0729 03:13:51.002158 118397 solver.cpp:252]     Train net output #0: loss = 0.632569 (* 1 = 0.632569 loss)
I0729 03:13:51.002173 118397 sgd_solver.cpp:106] Iteration 12210, lr = 0.0081
I0729 03:14:41.451004 118397 solver.cpp:236] Iteration 12220, loss = 0.599918
I0729 03:14:41.451201 118397 solver.cpp:252]     Train net output #0: loss = 0.635413 (* 1 = 0.635413 loss)
I0729 03:14:41.451222 118397 sgd_solver.cpp:106] Iteration 12220, lr = 0.0081
I0729 03:15:20.052023 118397 solver.cpp:236] Iteration 12230, loss = 0.605644
I0729 03:15:20.052222 118397 solver.cpp:252]     Train net output #0: loss = 0.638452 (* 1 = 0.638452 loss)
I0729 03:15:20.052258 118397 sgd_solver.cpp:106] Iteration 12230, lr = 0.0081
I0729 03:16:00.545528 118397 solver.cpp:236] Iteration 12240, loss = 0.607248
I0729 03:16:00.545649 118397 solver.cpp:252]     Train net output #0: loss = 0.630377 (* 1 = 0.630377 loss)
I0729 03:16:00.545675 118397 sgd_solver.cpp:106] Iteration 12240, lr = 0.0081
I0729 03:16:37.983055 118397 solver.cpp:236] Iteration 12250, loss = 0.612533
I0729 03:16:37.983198 118397 solver.cpp:252]     Train net output #0: loss = 0.640012 (* 1 = 0.640012 loss)
I0729 03:16:37.983217 118397 sgd_solver.cpp:106] Iteration 12250, lr = 0.0081
I0729 03:17:16.853122 118397 solver.cpp:236] Iteration 12260, loss = 0.622046
I0729 03:17:16.853265 118397 solver.cpp:252]     Train net output #0: loss = 0.636697 (* 1 = 0.636697 loss)
I0729 03:17:16.853281 118397 sgd_solver.cpp:106] Iteration 12260, lr = 0.0081
I0729 03:17:56.060945 118397 solver.cpp:236] Iteration 12270, loss = 0.619861
I0729 03:17:56.061105 118397 solver.cpp:252]     Train net output #0: loss = 0.638229 (* 1 = 0.638229 loss)
I0729 03:17:56.061133 118397 sgd_solver.cpp:106] Iteration 12270, lr = 0.0081
I0729 03:18:30.940554 118397 solver.cpp:236] Iteration 12280, loss = 0.618394
I0729 03:18:30.940738 118397 solver.cpp:252]     Train net output #0: loss = 0.646518 (* 1 = 0.646518 loss)
I0729 03:18:30.940770 118397 sgd_solver.cpp:106] Iteration 12280, lr = 0.0081
I0729 03:19:04.259543 118397 solver.cpp:236] Iteration 12290, loss = 0.62142
I0729 03:19:04.259685 118397 solver.cpp:252]     Train net output #0: loss = 0.634693 (* 1 = 0.634693 loss)
I0729 03:19:04.259713 118397 sgd_solver.cpp:106] Iteration 12290, lr = 0.0081
I0729 03:19:38.311203 118397 solver.cpp:236] Iteration 12300, loss = 0.617585
I0729 03:19:38.311664 118397 solver.cpp:252]     Train net output #0: loss = 0.641663 (* 1 = 0.641663 loss)
I0729 03:19:38.311682 118397 sgd_solver.cpp:106] Iteration 12300, lr = 0.0081
I0729 03:20:15.092718 118397 solver.cpp:236] Iteration 12310, loss = 0.617879
I0729 03:20:15.092895 118397 solver.cpp:252]     Train net output #0: loss = 0.639925 (* 1 = 0.639925 loss)
I0729 03:20:15.092938 118397 sgd_solver.cpp:106] Iteration 12310, lr = 0.0081
I0729 03:20:52.280612 118397 solver.cpp:236] Iteration 12320, loss = 0.618249
I0729 03:20:52.280778 118397 solver.cpp:252]     Train net output #0: loss = 0.635182 (* 1 = 0.635182 loss)
I0729 03:20:52.280805 118397 sgd_solver.cpp:106] Iteration 12320, lr = 0.0081
I0729 03:21:30.686560 118397 solver.cpp:236] Iteration 12330, loss = 0.610467
I0729 03:21:30.686774 118397 solver.cpp:252]     Train net output #0: loss = 0.295723 (* 1 = 0.295723 loss)
I0729 03:21:30.686810 118397 sgd_solver.cpp:106] Iteration 12330, lr = 0.0081
I0729 03:22:12.845134 118397 solver.cpp:236] Iteration 12340, loss = 0.609231
I0729 03:22:12.845347 118397 solver.cpp:252]     Train net output #0: loss = 0.658635 (* 1 = 0.658635 loss)
I0729 03:22:12.845378 118397 sgd_solver.cpp:106] Iteration 12340, lr = 0.0081
I0729 03:22:49.807940 118397 solver.cpp:236] Iteration 12350, loss = 0.607465
I0729 03:22:49.808125 118397 solver.cpp:252]     Train net output #0: loss = 0.631127 (* 1 = 0.631127 loss)
I0729 03:22:49.808166 118397 sgd_solver.cpp:106] Iteration 12350, lr = 0.0081
I0729 03:23:34.493191 118397 solver.cpp:236] Iteration 12360, loss = 0.605443
I0729 03:23:34.493348 118397 solver.cpp:252]     Train net output #0: loss = 0.63955 (* 1 = 0.63955 loss)
I0729 03:23:34.493402 118397 sgd_solver.cpp:106] Iteration 12360, lr = 0.0081
I0729 03:24:14.046229 118397 solver.cpp:236] Iteration 12370, loss = 0.602313
I0729 03:24:14.046416 118397 solver.cpp:252]     Train net output #0: loss = 0.647104 (* 1 = 0.647104 loss)
I0729 03:24:14.046444 118397 sgd_solver.cpp:106] Iteration 12370, lr = 0.0081
I0729 03:25:01.865559 118397 solver.cpp:236] Iteration 12380, loss = 0.605441
I0729 03:25:01.865799 118397 solver.cpp:252]     Train net output #0: loss = 0.633476 (* 1 = 0.633476 loss)
I0729 03:25:01.865816 118397 sgd_solver.cpp:106] Iteration 12380, lr = 0.0081
I0729 03:25:36.190198 118397 solver.cpp:236] Iteration 12390, loss = 0.591687
I0729 03:25:36.190362 118397 solver.cpp:252]     Train net output #0: loss = 0.699633 (* 1 = 0.699633 loss)
I0729 03:25:36.190379 118397 sgd_solver.cpp:106] Iteration 12390, lr = 0.0081
I0729 03:26:19.396911 118397 solver.cpp:236] Iteration 12400, loss = 0.602611
I0729 03:26:19.397056 118397 solver.cpp:252]     Train net output #0: loss = 0.649094 (* 1 = 0.649094 loss)
I0729 03:26:19.397073 118397 sgd_solver.cpp:106] Iteration 12400, lr = 0.0081
I0729 03:26:59.527631 118397 solver.cpp:236] Iteration 12410, loss = 0.605298
I0729 03:26:59.527822 118397 solver.cpp:252]     Train net output #0: loss = 0.646003 (* 1 = 0.646003 loss)
I0729 03:26:59.527843 118397 sgd_solver.cpp:106] Iteration 12410, lr = 0.0081
I0729 03:27:40.628429 118397 solver.cpp:236] Iteration 12420, loss = 0.602994
I0729 03:27:40.628566 118397 solver.cpp:252]     Train net output #0: loss = 0.394443 (* 1 = 0.394443 loss)
I0729 03:27:40.628583 118397 sgd_solver.cpp:106] Iteration 12420, lr = 0.0081
I0729 03:28:20.599098 118397 solver.cpp:236] Iteration 12430, loss = 0.611754
I0729 03:28:20.599278 118397 solver.cpp:252]     Train net output #0: loss = 0.644786 (* 1 = 0.644786 loss)
I0729 03:28:20.599293 118397 sgd_solver.cpp:106] Iteration 12430, lr = 0.0081
I0729 03:29:04.276324 118397 solver.cpp:236] Iteration 12440, loss = 0.613221
I0729 03:29:04.276569 118397 solver.cpp:252]     Train net output #0: loss = 0.638786 (* 1 = 0.638786 loss)
I0729 03:29:04.276590 118397 sgd_solver.cpp:106] Iteration 12440, lr = 0.0081
I0729 03:29:41.685982 118397 solver.cpp:236] Iteration 12450, loss = 0.611224
I0729 03:29:41.686161 118397 solver.cpp:252]     Train net output #0: loss = 0.651758 (* 1 = 0.651758 loss)
I0729 03:29:41.686180 118397 sgd_solver.cpp:106] Iteration 12450, lr = 0.0081
I0729 03:30:20.814298 118397 solver.cpp:236] Iteration 12460, loss = 0.611052
I0729 03:30:20.814427 118397 solver.cpp:252]     Train net output #0: loss = 0.641382 (* 1 = 0.641382 loss)
I0729 03:30:20.814443 118397 sgd_solver.cpp:106] Iteration 12460, lr = 0.0081
I0729 03:30:55.331262 118397 solver.cpp:236] Iteration 12470, loss = 0.60934
I0729 03:30:55.331485 118397 solver.cpp:252]     Train net output #0: loss = 0.641838 (* 1 = 0.641838 loss)
I0729 03:30:55.331506 118397 sgd_solver.cpp:106] Iteration 12470, lr = 0.0081
I0729 03:31:35.266855 118397 solver.cpp:236] Iteration 12480, loss = 0.599292
I0729 03:31:35.267063 118397 solver.cpp:252]     Train net output #0: loss = 0.7154 (* 1 = 0.7154 loss)
I0729 03:31:35.267082 118397 sgd_solver.cpp:106] Iteration 12480, lr = 0.0081
I0729 03:32:22.797430 118397 solver.cpp:236] Iteration 12490, loss = 0.616516
I0729 03:32:22.797636 118397 solver.cpp:252]     Train net output #0: loss = 0.644484 (* 1 = 0.644484 loss)
I0729 03:32:22.797664 118397 sgd_solver.cpp:106] Iteration 12490, lr = 0.0081
I0729 03:32:58.563994 118397 solver.cpp:340] Iteration 12500, Testing net (#0)
I0729 03:33:28.379668 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 03:33:28.379734 118397 solver.cpp:408]     Test net output #1: loss = 0.607933 (* 1 = 0.607933 loss)
I0729 03:33:31.805280 118397 solver.cpp:236] Iteration 12500, loss = 0.606057
I0729 03:33:31.805516 118397 solver.cpp:252]     Train net output #0: loss = 0.64059 (* 1 = 0.64059 loss)
I0729 03:33:31.805533 118397 sgd_solver.cpp:106] Iteration 12500, lr = 0.0081
I0729 03:34:10.885005 118397 solver.cpp:236] Iteration 12510, loss = 0.603479
I0729 03:34:10.885211 118397 solver.cpp:252]     Train net output #0: loss = 0.638991 (* 1 = 0.638991 loss)
I0729 03:34:10.885257 118397 sgd_solver.cpp:106] Iteration 12510, lr = 0.0081
I0729 03:34:47.163621 118397 solver.cpp:236] Iteration 12520, loss = 0.60289
I0729 03:34:47.163836 118397 solver.cpp:252]     Train net output #0: loss = 0.639489 (* 1 = 0.639489 loss)
I0729 03:34:47.163871 118397 sgd_solver.cpp:106] Iteration 12520, lr = 0.0081
I0729 03:35:17.859251 118397 solver.cpp:236] Iteration 12530, loss = 0.601924
I0729 03:35:17.859417 118397 solver.cpp:252]     Train net output #0: loss = 0.634305 (* 1 = 0.634305 loss)
I0729 03:35:17.859436 118397 sgd_solver.cpp:106] Iteration 12530, lr = 0.0081
I0729 03:35:54.672924 118397 solver.cpp:236] Iteration 12540, loss = 0.597478
I0729 03:35:54.673141 118397 solver.cpp:252]     Train net output #0: loss = 0.648017 (* 1 = 0.648017 loss)
I0729 03:35:54.673167 118397 sgd_solver.cpp:106] Iteration 12540, lr = 0.0081
I0729 03:36:35.658550 118397 solver.cpp:236] Iteration 12550, loss = 0.59653
I0729 03:36:35.658788 118397 solver.cpp:252]     Train net output #0: loss = 0.344441 (* 1 = 0.344441 loss)
I0729 03:36:35.658809 118397 sgd_solver.cpp:106] Iteration 12550, lr = 0.0081
I0729 03:37:12.088500 118397 solver.cpp:236] Iteration 12560, loss = 0.596461
I0729 03:37:12.088685 118397 solver.cpp:252]     Train net output #0: loss = 0.645285 (* 1 = 0.645285 loss)
I0729 03:37:12.088707 118397 sgd_solver.cpp:106] Iteration 12560, lr = 0.0081
I0729 03:37:52.303323 118397 solver.cpp:236] Iteration 12570, loss = 0.601317
I0729 03:37:52.303514 118397 solver.cpp:252]     Train net output #0: loss = 0.63738 (* 1 = 0.63738 loss)
I0729 03:37:52.303539 118397 sgd_solver.cpp:106] Iteration 12570, lr = 0.0081
I0729 03:38:34.107369 118397 solver.cpp:236] Iteration 12580, loss = 0.613399
I0729 03:38:34.107681 118397 solver.cpp:252]     Train net output #0: loss = 0.635684 (* 1 = 0.635684 loss)
I0729 03:38:34.107719 118397 sgd_solver.cpp:106] Iteration 12580, lr = 0.0081
I0729 03:39:10.477919 118397 solver.cpp:236] Iteration 12590, loss = 0.612025
I0729 03:39:10.478080 118397 solver.cpp:252]     Train net output #0: loss = 0.631164 (* 1 = 0.631164 loss)
I0729 03:39:10.478109 118397 sgd_solver.cpp:106] Iteration 12590, lr = 0.0081
I0729 03:39:47.252926 118397 solver.cpp:236] Iteration 12600, loss = 0.6081
I0729 03:39:47.253172 118397 solver.cpp:252]     Train net output #0: loss = 0.301995 (* 1 = 0.301995 loss)
I0729 03:39:47.253199 118397 sgd_solver.cpp:106] Iteration 12600, lr = 0.0081
I0729 03:40:26.653343 118397 solver.cpp:236] Iteration 12610, loss = 0.608958
I0729 03:40:26.653561 118397 solver.cpp:252]     Train net output #0: loss = 0.659961 (* 1 = 0.659961 loss)
I0729 03:40:26.653578 118397 sgd_solver.cpp:106] Iteration 12610, lr = 0.0081
I0729 03:41:00.327875 118397 solver.cpp:236] Iteration 12620, loss = 0.598564
I0729 03:41:00.328135 118397 solver.cpp:252]     Train net output #0: loss = 0.653203 (* 1 = 0.653203 loss)
I0729 03:41:00.328155 118397 sgd_solver.cpp:106] Iteration 12620, lr = 0.0081
I0729 03:41:35.590100 118397 solver.cpp:236] Iteration 12630, loss = 0.589668
I0729 03:41:35.590306 118397 solver.cpp:252]     Train net output #0: loss = 0.687955 (* 1 = 0.687955 loss)
I0729 03:41:35.590335 118397 sgd_solver.cpp:106] Iteration 12630, lr = 0.0081
I0729 03:42:12.974294 118397 solver.cpp:236] Iteration 12640, loss = 0.595789
I0729 03:42:12.974486 118397 solver.cpp:252]     Train net output #0: loss = 0.635621 (* 1 = 0.635621 loss)
I0729 03:42:12.974516 118397 sgd_solver.cpp:106] Iteration 12640, lr = 0.0081
I0729 03:42:44.538391 118397 solver.cpp:236] Iteration 12650, loss = 0.59931
I0729 03:42:44.538606 118397 solver.cpp:252]     Train net output #0: loss = 0.466535 (* 1 = 0.466535 loss)
I0729 03:42:44.538651 118397 sgd_solver.cpp:106] Iteration 12650, lr = 0.0081
I0729 03:43:20.304226 118397 solver.cpp:236] Iteration 12660, loss = 0.601777
I0729 03:43:20.304406 118397 solver.cpp:252]     Train net output #0: loss = 0.638333 (* 1 = 0.638333 loss)
I0729 03:43:20.304448 118397 sgd_solver.cpp:106] Iteration 12660, lr = 0.0081
I0729 03:44:04.488179 118397 solver.cpp:236] Iteration 12670, loss = 0.601806
I0729 03:44:04.488348 118397 solver.cpp:252]     Train net output #0: loss = 0.640731 (* 1 = 0.640731 loss)
I0729 03:44:04.488375 118397 sgd_solver.cpp:106] Iteration 12670, lr = 0.0081
I0729 03:44:46.230841 118397 solver.cpp:236] Iteration 12680, loss = 0.601809
I0729 03:44:46.230979 118397 solver.cpp:252]     Train net output #0: loss = 0.6345 (* 1 = 0.6345 loss)
I0729 03:44:46.230998 118397 sgd_solver.cpp:106] Iteration 12680, lr = 0.0081
I0729 03:45:24.948410 118397 solver.cpp:236] Iteration 12690, loss = 0.601725
I0729 03:45:24.948580 118397 solver.cpp:252]     Train net output #0: loss = 0.630558 (* 1 = 0.630558 loss)
I0729 03:45:24.948621 118397 sgd_solver.cpp:106] Iteration 12690, lr = 0.0081
I0729 03:46:02.785869 118397 solver.cpp:236] Iteration 12700, loss = 0.601797
I0729 03:46:02.786011 118397 solver.cpp:252]     Train net output #0: loss = 0.647237 (* 1 = 0.647237 loss)
I0729 03:46:02.786038 118397 sgd_solver.cpp:106] Iteration 12700, lr = 0.0081
I0729 03:46:36.039965 118397 solver.cpp:236] Iteration 12710, loss = 0.599281
I0729 03:46:36.040113 118397 solver.cpp:252]     Train net output #0: loss = 0.679303 (* 1 = 0.679303 loss)
I0729 03:46:36.040146 118397 sgd_solver.cpp:106] Iteration 12710, lr = 0.0081
I0729 03:47:13.459089 118397 solver.cpp:236] Iteration 12720, loss = 0.611284
I0729 03:47:13.462707 118397 solver.cpp:252]     Train net output #0: loss = 0.437639 (* 1 = 0.437639 loss)
I0729 03:47:13.462736 118397 sgd_solver.cpp:106] Iteration 12720, lr = 0.0081
I0729 03:47:55.262063 118397 solver.cpp:236] Iteration 12730, loss = 0.618268
I0729 03:47:55.262228 118397 solver.cpp:252]     Train net output #0: loss = 0.63582 (* 1 = 0.63582 loss)
I0729 03:47:55.262246 118397 sgd_solver.cpp:106] Iteration 12730, lr = 0.0081
I0729 03:48:32.168803 118397 solver.cpp:236] Iteration 12740, loss = 0.614084
I0729 03:48:32.168985 118397 solver.cpp:252]     Train net output #0: loss = 0.6421 (* 1 = 0.6421 loss)
I0729 03:48:32.169033 118397 sgd_solver.cpp:106] Iteration 12740, lr = 0.0081
I0729 03:49:06.234066 118397 solver.cpp:236] Iteration 12750, loss = 0.612921
I0729 03:49:06.234242 118397 solver.cpp:252]     Train net output #0: loss = 0.636746 (* 1 = 0.636746 loss)
I0729 03:49:06.234254 118397 sgd_solver.cpp:106] Iteration 12750, lr = 0.0081
I0729 03:49:44.239326 118397 solver.cpp:236] Iteration 12760, loss = 0.607894
I0729 03:49:44.239507 118397 solver.cpp:252]     Train net output #0: loss = 0.638894 (* 1 = 0.638894 loss)
I0729 03:49:44.239526 118397 sgd_solver.cpp:106] Iteration 12760, lr = 0.0081
I0729 03:50:23.794289 118397 solver.cpp:236] Iteration 12770, loss = 0.610852
I0729 03:50:23.794450 118397 solver.cpp:252]     Train net output #0: loss = 0.6359 (* 1 = 0.6359 loss)
I0729 03:50:23.794469 118397 sgd_solver.cpp:106] Iteration 12770, lr = 0.0081
I0729 03:51:04.820001 118397 solver.cpp:236] Iteration 12780, loss = 0.609315
I0729 03:51:04.820200 118397 solver.cpp:252]     Train net output #0: loss = 0.638729 (* 1 = 0.638729 loss)
I0729 03:51:04.820230 118397 sgd_solver.cpp:106] Iteration 12780, lr = 0.0081
I0729 03:51:43.171485 118397 solver.cpp:236] Iteration 12790, loss = 0.609498
I0729 03:51:43.171707 118397 solver.cpp:252]     Train net output #0: loss = 0.638731 (* 1 = 0.638731 loss)
I0729 03:51:43.171743 118397 sgd_solver.cpp:106] Iteration 12790, lr = 0.0081
I0729 03:52:25.648032 118397 solver.cpp:236] Iteration 12800, loss = 0.615857
I0729 03:52:25.648401 118397 solver.cpp:252]     Train net output #0: loss = 0.63591 (* 1 = 0.63591 loss)
I0729 03:52:25.648424 118397 sgd_solver.cpp:106] Iteration 12800, lr = 0.0081
I0729 03:53:05.263105 118397 solver.cpp:236] Iteration 12810, loss = 0.617504
I0729 03:53:05.263286 118397 solver.cpp:252]     Train net output #0: loss = 0.639289 (* 1 = 0.639289 loss)
I0729 03:53:05.263335 118397 sgd_solver.cpp:106] Iteration 12810, lr = 0.0081
I0729 03:53:41.352813 118397 solver.cpp:236] Iteration 12820, loss = 0.618699
I0729 03:53:41.353032 118397 solver.cpp:252]     Train net output #0: loss = 0.636934 (* 1 = 0.636934 loss)
I0729 03:53:41.353056 118397 sgd_solver.cpp:106] Iteration 12820, lr = 0.0081
I0729 03:54:15.464350 118397 solver.cpp:236] Iteration 12830, loss = 0.616263
I0729 03:54:15.464562 118397 solver.cpp:252]     Train net output #0: loss = 0.641108 (* 1 = 0.641108 loss)
I0729 03:54:15.464586 118397 sgd_solver.cpp:106] Iteration 12830, lr = 0.0081
I0729 03:54:52.854887 118397 solver.cpp:236] Iteration 12840, loss = 0.614053
I0729 03:54:52.855088 118397 solver.cpp:252]     Train net output #0: loss = 0.666181 (* 1 = 0.666181 loss)
I0729 03:54:52.855116 118397 sgd_solver.cpp:106] Iteration 12840, lr = 0.0081
I0729 03:55:41.136482 118397 solver.cpp:236] Iteration 12850, loss = 0.611102
I0729 03:55:41.136652 118397 solver.cpp:252]     Train net output #0: loss = 0.642481 (* 1 = 0.642481 loss)
I0729 03:55:41.136669 118397 sgd_solver.cpp:106] Iteration 12850, lr = 0.0081
I0729 03:56:18.041308 118397 solver.cpp:236] Iteration 12860, loss = 0.611102
I0729 03:56:18.041519 118397 solver.cpp:252]     Train net output #0: loss = 0.399304 (* 1 = 0.399304 loss)
I0729 03:56:18.041554 118397 sgd_solver.cpp:106] Iteration 12860, lr = 0.0081
I0729 03:56:51.360323 118397 solver.cpp:236] Iteration 12870, loss = 0.606022
I0729 03:56:51.360553 118397 solver.cpp:252]     Train net output #0: loss = 0.677243 (* 1 = 0.677243 loss)
I0729 03:56:51.360570 118397 sgd_solver.cpp:106] Iteration 12870, lr = 0.0081
I0729 03:57:28.907244 118397 solver.cpp:236] Iteration 12880, loss = 0.602892
I0729 03:57:28.907382 118397 solver.cpp:252]     Train net output #0: loss = 0.649827 (* 1 = 0.649827 loss)
I0729 03:57:28.907398 118397 sgd_solver.cpp:106] Iteration 12880, lr = 0.0081
I0729 03:58:06.128517 118397 solver.cpp:236] Iteration 12890, loss = 0.598526
I0729 03:58:06.128700 118397 solver.cpp:252]     Train net output #0: loss = 0.636335 (* 1 = 0.636335 loss)
I0729 03:58:06.128718 118397 sgd_solver.cpp:106] Iteration 12890, lr = 0.0081
I0729 03:58:47.466500 118397 solver.cpp:236] Iteration 12900, loss = 0.598373
I0729 03:58:47.466647 118397 solver.cpp:252]     Train net output #0: loss = 0.645745 (* 1 = 0.645745 loss)
I0729 03:58:47.466665 118397 sgd_solver.cpp:106] Iteration 12900, lr = 0.0081
I0729 03:59:17.680235 118397 solver.cpp:236] Iteration 12910, loss = 0.595181
I0729 03:59:17.680536 118397 solver.cpp:252]     Train net output #0: loss = 0.64964 (* 1 = 0.64964 loss)
I0729 03:59:17.680551 118397 sgd_solver.cpp:106] Iteration 12910, lr = 0.0081
I0729 03:59:55.979444 118397 solver.cpp:236] Iteration 12920, loss = 0.595549
I0729 03:59:55.979676 118397 solver.cpp:252]     Train net output #0: loss = 0.633059 (* 1 = 0.633059 loss)
I0729 03:59:55.979699 118397 sgd_solver.cpp:106] Iteration 12920, lr = 0.0081
I0729 04:00:34.494315 118397 solver.cpp:236] Iteration 12930, loss = 0.59984
I0729 04:00:34.494518 118397 solver.cpp:252]     Train net output #0: loss = 0.632002 (* 1 = 0.632002 loss)
I0729 04:00:34.494557 118397 sgd_solver.cpp:106] Iteration 12930, lr = 0.0081
I0729 04:01:18.061234 118397 solver.cpp:236] Iteration 12940, loss = 0.602227
I0729 04:01:18.061434 118397 solver.cpp:252]     Train net output #0: loss = 0.39308 (* 1 = 0.39308 loss)
I0729 04:01:18.061455 118397 sgd_solver.cpp:106] Iteration 12940, lr = 0.0081
I0729 04:01:58.319217 118397 solver.cpp:236] Iteration 12950, loss = 0.607997
I0729 04:01:58.319337 118397 solver.cpp:252]     Train net output #0: loss = 0.633576 (* 1 = 0.633576 loss)
I0729 04:01:58.319358 118397 sgd_solver.cpp:106] Iteration 12950, lr = 0.0081
I0729 04:02:39.390410 118397 solver.cpp:236] Iteration 12960, loss = 0.610374
I0729 04:02:39.390559 118397 solver.cpp:252]     Train net output #0: loss = 0.634109 (* 1 = 0.634109 loss)
I0729 04:02:39.390578 118397 sgd_solver.cpp:106] Iteration 12960, lr = 0.0081
I0729 04:03:14.345832 118397 solver.cpp:236] Iteration 12970, loss = 0.612524
I0729 04:03:14.345984 118397 solver.cpp:252]     Train net output #0: loss = 0.642408 (* 1 = 0.642408 loss)
I0729 04:03:14.346001 118397 sgd_solver.cpp:106] Iteration 12970, lr = 0.0081
I0729 04:03:45.885004 118397 solver.cpp:236] Iteration 12980, loss = 0.608391
I0729 04:03:45.885192 118397 solver.cpp:252]     Train net output #0: loss = 0.655594 (* 1 = 0.655594 loss)
I0729 04:03:45.885221 118397 sgd_solver.cpp:106] Iteration 12980, lr = 0.0081
I0729 04:04:27.479708 118397 solver.cpp:236] Iteration 12990, loss = 0.611651
I0729 04:04:27.479962 118397 solver.cpp:252]     Train net output #0: loss = 0.659997 (* 1 = 0.659997 loss)
I0729 04:04:27.479981 118397 sgd_solver.cpp:106] Iteration 12990, lr = 0.0081
I0729 04:04:59.738428 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_13000.caffemodel
I0729 04:04:59.833631 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_13000.solverstate
I0729 04:04:59.837769 118397 solver.cpp:340] Iteration 13000, Testing net (#0)
I0729 04:05:35.140147 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 04:05:35.140321 118397 solver.cpp:408]     Test net output #1: loss = 0.633456 (* 1 = 0.633456 loss)
I0729 04:05:40.289050 118397 solver.cpp:236] Iteration 13000, loss = 0.611399
I0729 04:05:40.289119 118397 solver.cpp:252]     Train net output #0: loss = 0.635705 (* 1 = 0.635705 loss)
I0729 04:05:40.289135 118397 sgd_solver.cpp:106] Iteration 13000, lr = 0.0081
I0729 04:06:11.833359 118397 solver.cpp:236] Iteration 13010, loss = 0.614635
I0729 04:06:11.833510 118397 solver.cpp:252]     Train net output #0: loss = 0.633951 (* 1 = 0.633951 loss)
I0729 04:06:11.833534 118397 sgd_solver.cpp:106] Iteration 13010, lr = 0.0081
I0729 04:06:48.602041 118397 solver.cpp:236] Iteration 13020, loss = 0.609511
I0729 04:06:48.602258 118397 solver.cpp:252]     Train net output #0: loss = 0.65742 (* 1 = 0.65742 loss)
I0729 04:06:48.602275 118397 sgd_solver.cpp:106] Iteration 13020, lr = 0.0081
I0729 04:07:21.503760 118397 solver.cpp:236] Iteration 13030, loss = 0.608082
I0729 04:07:21.503965 118397 solver.cpp:252]     Train net output #0: loss = 0.39838 (* 1 = 0.39838 loss)
I0729 04:07:21.503994 118397 sgd_solver.cpp:106] Iteration 13030, lr = 0.0081
I0729 04:07:52.632436 118397 solver.cpp:236] Iteration 13040, loss = 0.610255
I0729 04:07:52.632783 118397 solver.cpp:252]     Train net output #0: loss = 0.641105 (* 1 = 0.641105 loss)
I0729 04:07:52.632802 118397 sgd_solver.cpp:106] Iteration 13040, lr = 0.0081
I0729 04:08:21.118896 118397 solver.cpp:236] Iteration 13050, loss = 0.607385
I0729 04:08:21.118958 118397 solver.cpp:252]     Train net output #0: loss = 0.635725 (* 1 = 0.635725 loss)
I0729 04:08:21.118971 118397 sgd_solver.cpp:106] Iteration 13050, lr = 0.0081
I0729 04:08:54.179059 118397 solver.cpp:236] Iteration 13060, loss = 0.610002
I0729 04:08:54.179260 118397 solver.cpp:252]     Train net output #0: loss = 0.638331 (* 1 = 0.638331 loss)
I0729 04:08:54.179288 118397 sgd_solver.cpp:106] Iteration 13060, lr = 0.0081
I0729 04:09:29.773043 118397 solver.cpp:236] Iteration 13070, loss = 0.609814
I0729 04:09:29.773185 118397 solver.cpp:252]     Train net output #0: loss = 0.641653 (* 1 = 0.641653 loss)
I0729 04:09:29.773200 118397 sgd_solver.cpp:106] Iteration 13070, lr = 0.0081
I0729 04:10:00.183013 118397 solver.cpp:236] Iteration 13080, loss = 0.616437
I0729 04:10:00.183167 118397 solver.cpp:252]     Train net output #0: loss = 0.63071 (* 1 = 0.63071 loss)
I0729 04:10:00.183185 118397 sgd_solver.cpp:106] Iteration 13080, lr = 0.0081
I0729 04:10:35.751796 118397 solver.cpp:236] Iteration 13090, loss = 0.615692
I0729 04:10:35.751976 118397 solver.cpp:252]     Train net output #0: loss = 0.646593 (* 1 = 0.646593 loss)
I0729 04:10:35.751996 118397 sgd_solver.cpp:106] Iteration 13090, lr = 0.0081
I0729 04:11:05.359602 118397 solver.cpp:236] Iteration 13100, loss = 0.613815
I0729 04:11:05.359671 118397 solver.cpp:252]     Train net output #0: loss = 0.640405 (* 1 = 0.640405 loss)
I0729 04:11:05.359689 118397 sgd_solver.cpp:106] Iteration 13100, lr = 0.0081
I0729 04:11:36.771697 118397 solver.cpp:236] Iteration 13110, loss = 0.613671
I0729 04:11:36.771900 118397 solver.cpp:252]     Train net output #0: loss = 0.647338 (* 1 = 0.647338 loss)
I0729 04:11:36.771932 118397 sgd_solver.cpp:106] Iteration 13110, lr = 0.0081
I0729 04:12:14.541286 118397 solver.cpp:236] Iteration 13120, loss = 0.615512
I0729 04:12:14.541473 118397 solver.cpp:252]     Train net output #0: loss = 0.637042 (* 1 = 0.637042 loss)
I0729 04:12:14.541501 118397 sgd_solver.cpp:106] Iteration 13120, lr = 0.0081
I0729 04:12:48.137346 118397 solver.cpp:236] Iteration 13130, loss = 0.616995
I0729 04:12:48.138011 118397 solver.cpp:252]     Train net output #0: loss = 0.632353 (* 1 = 0.632353 loss)
I0729 04:12:48.138031 118397 sgd_solver.cpp:106] Iteration 13130, lr = 0.0081
I0729 04:13:23.024288 118397 solver.cpp:236] Iteration 13140, loss = 0.616816
I0729 04:13:23.024521 118397 solver.cpp:252]     Train net output #0: loss = 0.63228 (* 1 = 0.63228 loss)
I0729 04:13:23.024544 118397 sgd_solver.cpp:106] Iteration 13140, lr = 0.0081
I0729 04:13:55.970661 118397 solver.cpp:236] Iteration 13150, loss = 0.614308
I0729 04:13:55.970887 118397 solver.cpp:252]     Train net output #0: loss = 0.646904 (* 1 = 0.646904 loss)
I0729 04:13:55.970914 118397 sgd_solver.cpp:106] Iteration 13150, lr = 0.0081
I0729 04:14:27.600590 118397 solver.cpp:236] Iteration 13160, loss = 0.612453
I0729 04:14:27.600812 118397 solver.cpp:252]     Train net output #0: loss = 0.347427 (* 1 = 0.347427 loss)
I0729 04:14:27.600832 118397 sgd_solver.cpp:106] Iteration 13160, lr = 0.0081
I0729 04:14:58.559365 118397 solver.cpp:236] Iteration 13170, loss = 0.612561
I0729 04:14:58.559520 118397 solver.cpp:252]     Train net output #0: loss = 0.63222 (* 1 = 0.63222 loss)
I0729 04:14:58.559551 118397 sgd_solver.cpp:106] Iteration 13170, lr = 0.0081
I0729 04:15:37.468899 118397 solver.cpp:236] Iteration 13180, loss = 0.612275
I0729 04:15:37.469099 118397 solver.cpp:252]     Train net output #0: loss = 0.632502 (* 1 = 0.632502 loss)
I0729 04:15:37.469147 118397 sgd_solver.cpp:106] Iteration 13180, lr = 0.0081
I0729 04:16:16.174796 118397 solver.cpp:236] Iteration 13190, loss = 0.614153
I0729 04:16:16.175022 118397 solver.cpp:252]     Train net output #0: loss = 0.63807 (* 1 = 0.63807 loss)
I0729 04:16:16.175055 118397 sgd_solver.cpp:106] Iteration 13190, lr = 0.0081
I0729 04:16:50.870165 118397 solver.cpp:236] Iteration 13200, loss = 0.61632
I0729 04:16:50.870492 118397 solver.cpp:252]     Train net output #0: loss = 0.634898 (* 1 = 0.634898 loss)
I0729 04:16:50.870508 118397 sgd_solver.cpp:106] Iteration 13200, lr = 0.0081
I0729 04:17:28.542083 118397 solver.cpp:236] Iteration 13210, loss = 0.616318
I0729 04:17:28.542212 118397 solver.cpp:252]     Train net output #0: loss = 0.644851 (* 1 = 0.644851 loss)
I0729 04:17:28.542227 118397 sgd_solver.cpp:106] Iteration 13210, lr = 0.0081
I0729 04:17:58.475193 118397 solver.cpp:236] Iteration 13220, loss = 0.616412
I0729 04:17:58.475255 118397 solver.cpp:252]     Train net output #0: loss = 0.636103 (* 1 = 0.636103 loss)
I0729 04:17:58.475266 118397 sgd_solver.cpp:106] Iteration 13220, lr = 0.0081
I0729 04:18:28.967434 118397 solver.cpp:236] Iteration 13230, loss = 0.616427
I0729 04:18:28.967608 118397 solver.cpp:252]     Train net output #0: loss = 0.629035 (* 1 = 0.629035 loss)
I0729 04:18:28.967640 118397 sgd_solver.cpp:106] Iteration 13230, lr = 0.0081
I0729 04:18:58.386778 118397 solver.cpp:236] Iteration 13240, loss = 0.614603
I0729 04:18:58.386847 118397 solver.cpp:252]     Train net output #0: loss = 0.640846 (* 1 = 0.640846 loss)
I0729 04:18:58.386862 118397 sgd_solver.cpp:106] Iteration 13240, lr = 0.0081
I0729 04:19:29.403945 118397 solver.cpp:236] Iteration 13250, loss = 0.610398
I0729 04:19:29.404096 118397 solver.cpp:252]     Train net output #0: loss = 0.3059 (* 1 = 0.3059 loss)
I0729 04:19:29.404117 118397 sgd_solver.cpp:106] Iteration 13250, lr = 0.0081
I0729 04:19:57.838876 118397 solver.cpp:236] Iteration 13260, loss = 0.612082
I0729 04:19:57.838939 118397 solver.cpp:252]     Train net output #0: loss = 0.664254 (* 1 = 0.664254 loss)
I0729 04:19:57.838953 118397 sgd_solver.cpp:106] Iteration 13260, lr = 0.0081
I0729 04:20:31.730183 118397 solver.cpp:236] Iteration 13270, loss = 0.611191
I0729 04:20:31.730325 118397 solver.cpp:252]     Train net output #0: loss = 0.631814 (* 1 = 0.631814 loss)
I0729 04:20:31.730345 118397 sgd_solver.cpp:106] Iteration 13270, lr = 0.0081
I0729 04:21:00.552844 118397 solver.cpp:236] Iteration 13280, loss = 0.609127
I0729 04:21:00.552911 118397 solver.cpp:252]     Train net output #0: loss = 0.37135 (* 1 = 0.37135 loss)
I0729 04:21:00.552927 118397 sgd_solver.cpp:106] Iteration 13280, lr = 0.0081
I0729 04:21:38.503629 118397 solver.cpp:236] Iteration 13290, loss = 0.607647
I0729 04:21:38.503772 118397 solver.cpp:252]     Train net output #0: loss = 0.65085 (* 1 = 0.65085 loss)
I0729 04:21:38.503790 118397 sgd_solver.cpp:106] Iteration 13290, lr = 0.0081
I0729 04:22:14.200754 118397 solver.cpp:236] Iteration 13300, loss = 0.6101
I0729 04:22:14.200974 118397 solver.cpp:252]     Train net output #0: loss = 0.640066 (* 1 = 0.640066 loss)
I0729 04:22:14.200995 118397 sgd_solver.cpp:106] Iteration 13300, lr = 0.0081
I0729 04:22:47.521708 118397 solver.cpp:236] Iteration 13310, loss = 0.609218
I0729 04:22:47.521865 118397 solver.cpp:252]     Train net output #0: loss = 0.64893 (* 1 = 0.64893 loss)
I0729 04:22:47.521911 118397 sgd_solver.cpp:106] Iteration 13310, lr = 0.0081
I0729 04:23:22.936578 118397 solver.cpp:236] Iteration 13320, loss = 0.60961
I0729 04:23:22.936753 118397 solver.cpp:252]     Train net output #0: loss = 0.647308 (* 1 = 0.647308 loss)
I0729 04:23:22.936771 118397 sgd_solver.cpp:106] Iteration 13320, lr = 0.0081
I0729 04:23:54.962129 118397 solver.cpp:236] Iteration 13330, loss = 0.606921
I0729 04:23:54.962263 118397 solver.cpp:252]     Train net output #0: loss = 0.635735 (* 1 = 0.635735 loss)
I0729 04:23:54.962278 118397 sgd_solver.cpp:106] Iteration 13330, lr = 0.0081
I0729 04:24:25.793618 118397 solver.cpp:236] Iteration 13340, loss = 0.60473
I0729 04:24:25.793782 118397 solver.cpp:252]     Train net output #0: loss = 0.643731 (* 1 = 0.643731 loss)
I0729 04:24:25.793802 118397 sgd_solver.cpp:106] Iteration 13340, lr = 0.0081
I0729 04:24:58.743098 118397 solver.cpp:236] Iteration 13350, loss = 0.608345
I0729 04:24:58.743456 118397 solver.cpp:252]     Train net output #0: loss = 0.323167 (* 1 = 0.323167 loss)
I0729 04:24:58.743475 118397 sgd_solver.cpp:106] Iteration 13350, lr = 0.0081
I0729 04:25:31.012780 118397 solver.cpp:236] Iteration 13360, loss = 0.60248
I0729 04:25:31.012938 118397 solver.cpp:252]     Train net output #0: loss = 0.298634 (* 1 = 0.298634 loss)
I0729 04:25:31.012960 118397 sgd_solver.cpp:106] Iteration 13360, lr = 0.0081
I0729 04:26:04.357228 118397 solver.cpp:236] Iteration 13370, loss = 0.604186
I0729 04:26:04.357372 118397 solver.cpp:252]     Train net output #0: loss = 0.646753 (* 1 = 0.646753 loss)
I0729 04:26:04.357389 118397 sgd_solver.cpp:106] Iteration 13370, lr = 0.0081
I0729 04:26:33.880559 118397 solver.cpp:236] Iteration 13380, loss = 0.606782
I0729 04:26:33.880635 118397 solver.cpp:252]     Train net output #0: loss = 0.641014 (* 1 = 0.641014 loss)
I0729 04:26:33.880650 118397 sgd_solver.cpp:106] Iteration 13380, lr = 0.0081
I0729 04:27:14.636344 118397 solver.cpp:236] Iteration 13390, loss = 0.608151
I0729 04:27:14.636623 118397 solver.cpp:252]     Train net output #0: loss = 0.636078 (* 1 = 0.636078 loss)
I0729 04:27:14.636639 118397 sgd_solver.cpp:106] Iteration 13390, lr = 0.0081
I0729 04:27:53.976343 118397 solver.cpp:236] Iteration 13400, loss = 0.60562
I0729 04:27:53.976531 118397 solver.cpp:252]     Train net output #0: loss = 0.403133 (* 1 = 0.403133 loss)
I0729 04:27:53.976547 118397 sgd_solver.cpp:106] Iteration 13400, lr = 0.0081
I0729 04:28:34.022989 118397 solver.cpp:236] Iteration 13410, loss = 0.60598
I0729 04:28:34.023164 118397 solver.cpp:252]     Train net output #0: loss = 0.642033 (* 1 = 0.642033 loss)
I0729 04:28:34.023180 118397 sgd_solver.cpp:106] Iteration 13410, lr = 0.0081
I0729 04:29:18.214467 118397 solver.cpp:236] Iteration 13420, loss = 0.60289
I0729 04:29:18.214671 118397 solver.cpp:252]     Train net output #0: loss = 0.6555 (* 1 = 0.6555 loss)
I0729 04:29:18.214691 118397 sgd_solver.cpp:106] Iteration 13420, lr = 0.0081
I0729 04:29:59.018404 118397 solver.cpp:236] Iteration 13430, loss = 0.603044
I0729 04:29:59.018556 118397 solver.cpp:252]     Train net output #0: loss = 0.636846 (* 1 = 0.636846 loss)
I0729 04:29:59.018576 118397 sgd_solver.cpp:106] Iteration 13430, lr = 0.0081
I0729 04:30:39.437453 118397 solver.cpp:236] Iteration 13440, loss = 0.605026
I0729 04:30:39.437647 118397 solver.cpp:252]     Train net output #0: loss = 0.63673 (* 1 = 0.63673 loss)
I0729 04:30:39.437664 118397 sgd_solver.cpp:106] Iteration 13440, lr = 0.0081
I0729 04:31:17.080268 118397 solver.cpp:236] Iteration 13450, loss = 0.61055
I0729 04:31:17.080399 118397 solver.cpp:252]     Train net output #0: loss = 0.633449 (* 1 = 0.633449 loss)
I0729 04:31:17.080416 118397 sgd_solver.cpp:106] Iteration 13450, lr = 0.0081
I0729 04:31:56.186578 118397 solver.cpp:236] Iteration 13460, loss = 0.60853
I0729 04:31:56.186820 118397 solver.cpp:252]     Train net output #0: loss = 0.291985 (* 1 = 0.291985 loss)
I0729 04:31:56.186839 118397 sgd_solver.cpp:106] Iteration 13460, lr = 0.0081
I0729 04:32:35.828908 118397 solver.cpp:236] Iteration 13470, loss = 0.605001
I0729 04:32:35.829077 118397 solver.cpp:252]     Train net output #0: loss = 0.658066 (* 1 = 0.658066 loss)
I0729 04:32:35.829121 118397 sgd_solver.cpp:106] Iteration 13470, lr = 0.0081
I0729 04:33:15.372707 118397 solver.cpp:236] Iteration 13480, loss = 0.601278
I0729 04:33:15.372882 118397 solver.cpp:252]     Train net output #0: loss = 0.645732 (* 1 = 0.645732 loss)
I0729 04:33:15.372903 118397 sgd_solver.cpp:106] Iteration 13480, lr = 0.0081
I0729 04:33:59.081351 118397 solver.cpp:236] Iteration 13490, loss = 0.60137
I0729 04:33:59.081503 118397 solver.cpp:252]     Train net output #0: loss = 0.638638 (* 1 = 0.638638 loss)
I0729 04:33:59.081532 118397 sgd_solver.cpp:106] Iteration 13490, lr = 0.0081
I0729 04:34:35.892125 118397 solver.cpp:340] Iteration 13500, Testing net (#0)
I0729 04:35:24.200011 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 04:35:24.200234 118397 solver.cpp:408]     Test net output #1: loss = 0.649411 (* 1 = 0.649411 loss)
I0729 04:35:29.652792 118397 solver.cpp:236] Iteration 13500, loss = 0.598055
I0729 04:35:29.652851 118397 solver.cpp:252]     Train net output #0: loss = 0.653453 (* 1 = 0.653453 loss)
I0729 04:35:29.652866 118397 sgd_solver.cpp:106] Iteration 13500, lr = 0.0081
I0729 04:36:16.535305 118397 solver.cpp:236] Iteration 13510, loss = 0.60307
I0729 04:36:16.535501 118397 solver.cpp:252]     Train net output #0: loss = 0.642722 (* 1 = 0.642722 loss)
I0729 04:36:16.535528 118397 sgd_solver.cpp:106] Iteration 13510, lr = 0.0081
I0729 04:37:03.115005 118397 solver.cpp:236] Iteration 13520, loss = 0.606595
I0729 04:37:03.115195 118397 solver.cpp:252]     Train net output #0: loss = 0.633904 (* 1 = 0.633904 loss)
I0729 04:37:03.115222 118397 sgd_solver.cpp:106] Iteration 13520, lr = 0.0081
I0729 04:37:39.897064 118397 solver.cpp:236] Iteration 13530, loss = 0.606926
I0729 04:37:39.897266 118397 solver.cpp:252]     Train net output #0: loss = 0.64655 (* 1 = 0.64655 loss)
I0729 04:37:39.897297 118397 sgd_solver.cpp:106] Iteration 13530, lr = 0.0081
I0729 04:38:30.273880 118397 solver.cpp:236] Iteration 13540, loss = 0.606594
I0729 04:38:30.274036 118397 solver.cpp:252]     Train net output #0: loss = 0.638953 (* 1 = 0.638953 loss)
I0729 04:38:30.274073 118397 sgd_solver.cpp:106] Iteration 13540, lr = 0.0081
I0729 04:39:08.332465 118397 solver.cpp:236] Iteration 13550, loss = 0.598352
I0729 04:39:08.332674 118397 solver.cpp:252]     Train net output #0: loss = 0.660415 (* 1 = 0.660415 loss)
I0729 04:39:08.332701 118397 sgd_solver.cpp:106] Iteration 13550, lr = 0.0081
I0729 04:39:52.486960 118397 solver.cpp:236] Iteration 13560, loss = 0.600535
I0729 04:39:52.487215 118397 solver.cpp:252]     Train net output #0: loss = 0.641005 (* 1 = 0.641005 loss)
I0729 04:39:52.487239 118397 sgd_solver.cpp:106] Iteration 13560, lr = 0.0081
I0729 04:40:27.603744 118397 solver.cpp:236] Iteration 13570, loss = 0.596674
I0729 04:40:27.603904 118397 solver.cpp:252]     Train net output #0: loss = 0.639678 (* 1 = 0.639678 loss)
I0729 04:40:27.603921 118397 sgd_solver.cpp:106] Iteration 13570, lr = 0.0081
I0729 04:41:05.301054 118397 solver.cpp:236] Iteration 13580, loss = 0.60014
I0729 04:41:05.301244 118397 solver.cpp:252]     Train net output #0: loss = 0.642884 (* 1 = 0.642884 loss)
I0729 04:41:05.301272 118397 sgd_solver.cpp:106] Iteration 13580, lr = 0.0081
I0729 04:41:45.315274 118397 solver.cpp:236] Iteration 13590, loss = 0.597165
I0729 04:41:45.315424 118397 solver.cpp:252]     Train net output #0: loss = 0.637534 (* 1 = 0.637534 loss)
I0729 04:41:45.315443 118397 sgd_solver.cpp:106] Iteration 13590, lr = 0.0081
I0729 04:42:20.524566 118397 solver.cpp:236] Iteration 13600, loss = 0.597892
I0729 04:42:20.524716 118397 solver.cpp:252]     Train net output #0: loss = 0.640898 (* 1 = 0.640898 loss)
I0729 04:42:20.524737 118397 sgd_solver.cpp:106] Iteration 13600, lr = 0.0081
I0729 04:42:56.453358 118397 solver.cpp:236] Iteration 13610, loss = 0.596053
I0729 04:42:56.453634 118397 solver.cpp:252]     Train net output #0: loss = 0.631471 (* 1 = 0.631471 loss)
I0729 04:42:56.453655 118397 sgd_solver.cpp:106] Iteration 13610, lr = 0.0081
I0729 04:43:38.163950 118397 solver.cpp:236] Iteration 13620, loss = 0.597892
I0729 04:43:38.164109 118397 solver.cpp:252]     Train net output #0: loss = 0.633524 (* 1 = 0.633524 loss)
I0729 04:43:38.164153 118397 sgd_solver.cpp:106] Iteration 13620, lr = 0.0081
I0729 04:44:19.642828 118397 solver.cpp:236] Iteration 13630, loss = 0.598341
I0729 04:44:19.643045 118397 solver.cpp:252]     Train net output #0: loss = 0.637697 (* 1 = 0.637697 loss)
I0729 04:44:19.643074 118397 sgd_solver.cpp:106] Iteration 13630, lr = 0.0081
I0729 04:45:05.877316 118397 solver.cpp:236] Iteration 13640, loss = 0.598376
I0729 04:45:05.878094 118397 solver.cpp:252]     Train net output #0: loss = 0.633702 (* 1 = 0.633702 loss)
I0729 04:45:05.878113 118397 sgd_solver.cpp:106] Iteration 13640, lr = 0.0081
I0729 04:45:46.882315 118397 solver.cpp:236] Iteration 13650, loss = 0.604316
I0729 04:45:46.882525 118397 solver.cpp:252]     Train net output #0: loss = 0.638446 (* 1 = 0.638446 loss)
I0729 04:45:46.882555 118397 sgd_solver.cpp:106] Iteration 13650, lr = 0.0081
I0729 04:46:32.193704 118397 solver.cpp:236] Iteration 13660, loss = 0.610024
I0729 04:46:32.193836 118397 solver.cpp:252]     Train net output #0: loss = 0.630392 (* 1 = 0.630392 loss)
I0729 04:46:32.193853 118397 sgd_solver.cpp:106] Iteration 13660, lr = 0.0081
I0729 04:47:18.049520 118397 solver.cpp:236] Iteration 13670, loss = 0.618967
I0729 04:47:18.049734 118397 solver.cpp:252]     Train net output #0: loss = 0.634565 (* 1 = 0.634565 loss)
I0729 04:47:18.049777 118397 sgd_solver.cpp:106] Iteration 13670, lr = 0.0081
I0729 04:47:59.095767 118397 solver.cpp:236] Iteration 13680, loss = 0.619097
I0729 04:47:59.095962 118397 solver.cpp:252]     Train net output #0: loss = 0.642074 (* 1 = 0.642074 loss)
I0729 04:47:59.095988 118397 sgd_solver.cpp:106] Iteration 13680, lr = 0.0081
I0729 04:48:45.297844 118397 solver.cpp:236] Iteration 13690, loss = 0.613636
I0729 04:48:45.298084 118397 solver.cpp:252]     Train net output #0: loss = 0.667479 (* 1 = 0.667479 loss)
I0729 04:48:45.298106 118397 sgd_solver.cpp:106] Iteration 13690, lr = 0.0081
I0729 04:49:25.243203 118397 solver.cpp:236] Iteration 13700, loss = 0.620221
I0729 04:49:25.243396 118397 solver.cpp:252]     Train net output #0: loss = 0.636002 (* 1 = 0.636002 loss)
I0729 04:49:25.243422 118397 sgd_solver.cpp:106] Iteration 13700, lr = 0.0081
I0729 04:50:04.188143 118397 solver.cpp:236] Iteration 13710, loss = 0.618411
I0729 04:50:04.188369 118397 solver.cpp:252]     Train net output #0: loss = 0.634795 (* 1 = 0.634795 loss)
I0729 04:50:04.188392 118397 sgd_solver.cpp:106] Iteration 13710, lr = 0.0081
I0729 04:50:46.721913 118397 solver.cpp:236] Iteration 13720, loss = 0.618352
I0729 04:50:46.722090 118397 solver.cpp:252]     Train net output #0: loss = 0.634056 (* 1 = 0.634056 loss)
I0729 04:50:46.722105 118397 sgd_solver.cpp:106] Iteration 13720, lr = 0.0081
I0729 04:51:22.305470 118397 solver.cpp:236] Iteration 13730, loss = 0.620048
I0729 04:51:22.305613 118397 solver.cpp:252]     Train net output #0: loss = 0.634135 (* 1 = 0.634135 loss)
I0729 04:51:22.305632 118397 sgd_solver.cpp:106] Iteration 13730, lr = 0.0081
I0729 04:52:00.605798 118397 solver.cpp:236] Iteration 13740, loss = 0.620063
I0729 04:52:00.605965 118397 solver.cpp:252]     Train net output #0: loss = 0.402374 (* 1 = 0.402374 loss)
I0729 04:52:00.605984 118397 sgd_solver.cpp:106] Iteration 13740, lr = 0.0081
I0729 04:52:37.929700 118397 solver.cpp:236] Iteration 13750, loss = 0.620355
I0729 04:52:37.929886 118397 solver.cpp:252]     Train net output #0: loss = 0.64951 (* 1 = 0.64951 loss)
I0729 04:52:37.929925 118397 sgd_solver.cpp:106] Iteration 13750, lr = 0.0081
I0729 04:53:22.637387 118397 solver.cpp:236] Iteration 13760, loss = 0.614837
I0729 04:53:22.637531 118397 solver.cpp:252]     Train net output #0: loss = 0.34701 (* 1 = 0.34701 loss)
I0729 04:53:22.637554 118397 sgd_solver.cpp:106] Iteration 13760, lr = 0.0081
I0729 04:54:04.969883 118397 solver.cpp:236] Iteration 13770, loss = 0.614711
I0729 04:54:04.970046 118397 solver.cpp:252]     Train net output #0: loss = 0.631091 (* 1 = 0.631091 loss)
I0729 04:54:04.970065 118397 sgd_solver.cpp:106] Iteration 13770, lr = 0.0081
I0729 04:54:52.549922 118397 solver.cpp:236] Iteration 13780, loss = 0.612286
I0729 04:54:52.550084 118397 solver.cpp:252]     Train net output #0: loss = 0.640114 (* 1 = 0.640114 loss)
I0729 04:54:52.550107 118397 sgd_solver.cpp:106] Iteration 13780, lr = 0.0081
I0729 04:55:36.926435 118397 solver.cpp:236] Iteration 13790, loss = 0.615032
I0729 04:55:36.926728 118397 solver.cpp:252]     Train net output #0: loss = 0.296287 (* 1 = 0.296287 loss)
I0729 04:55:36.926753 118397 sgd_solver.cpp:106] Iteration 13790, lr = 0.0081
I0729 04:56:21.530170 118397 solver.cpp:236] Iteration 13800, loss = 0.614193
I0729 04:56:21.530344 118397 solver.cpp:252]     Train net output #0: loss = 0.635903 (* 1 = 0.635903 loss)
I0729 04:56:21.530364 118397 sgd_solver.cpp:106] Iteration 13800, lr = 0.0081
I0729 04:57:07.243427 118397 solver.cpp:236] Iteration 13810, loss = 0.613849
I0729 04:57:07.243629 118397 solver.cpp:252]     Train net output #0: loss = 0.450901 (* 1 = 0.450901 loss)
I0729 04:57:07.243649 118397 sgd_solver.cpp:106] Iteration 13810, lr = 0.0081
I0729 04:57:53.924970 118397 solver.cpp:236] Iteration 13820, loss = 0.611738
I0729 04:57:53.925159 118397 solver.cpp:252]     Train net output #0: loss = 0.650828 (* 1 = 0.650828 loss)
I0729 04:57:53.925207 118397 sgd_solver.cpp:106] Iteration 13820, lr = 0.0081
I0729 04:58:41.104439 118397 solver.cpp:236] Iteration 13830, loss = 0.609688
I0729 04:58:41.104646 118397 solver.cpp:252]     Train net output #0: loss = 0.639869 (* 1 = 0.639869 loss)
I0729 04:58:41.104676 118397 sgd_solver.cpp:106] Iteration 13830, lr = 0.0081
I0729 04:59:24.083540 118397 solver.cpp:236] Iteration 13840, loss = 0.606967
I0729 04:59:24.083674 118397 solver.cpp:252]     Train net output #0: loss = 0.643019 (* 1 = 0.643019 loss)
I0729 04:59:24.083690 118397 sgd_solver.cpp:106] Iteration 13840, lr = 0.0081
I0729 05:00:04.487516 118397 solver.cpp:236] Iteration 13850, loss = 0.604799
I0729 05:00:04.487727 118397 solver.cpp:252]     Train net output #0: loss = 0.661465 (* 1 = 0.661465 loss)
I0729 05:00:04.487766 118397 sgd_solver.cpp:106] Iteration 13850, lr = 0.0081
I0729 05:00:42.111539 118397 solver.cpp:236] Iteration 13860, loss = 0.610648
I0729 05:00:42.111737 118397 solver.cpp:252]     Train net output #0: loss = 0.634995 (* 1 = 0.634995 loss)
I0729 05:00:42.111766 118397 sgd_solver.cpp:106] Iteration 13860, lr = 0.0081
I0729 05:01:23.372915 118397 solver.cpp:236] Iteration 13870, loss = 0.611171
I0729 05:01:23.373093 118397 solver.cpp:252]     Train net output #0: loss = 0.636946 (* 1 = 0.636946 loss)
I0729 05:01:23.373131 118397 sgd_solver.cpp:106] Iteration 13870, lr = 0.0081
I0729 05:02:07.338083 118397 solver.cpp:236] Iteration 13880, loss = 0.613237
I0729 05:02:07.338263 118397 solver.cpp:252]     Train net output #0: loss = 0.646142 (* 1 = 0.646142 loss)
I0729 05:02:07.338301 118397 sgd_solver.cpp:106] Iteration 13880, lr = 0.0081
I0729 05:02:50.575456 118397 solver.cpp:236] Iteration 13890, loss = 0.619319
I0729 05:02:50.575598 118397 solver.cpp:252]     Train net output #0: loss = 0.637827 (* 1 = 0.637827 loss)
I0729 05:02:50.575628 118397 sgd_solver.cpp:106] Iteration 13890, lr = 0.0081
I0729 05:03:28.101799 118397 solver.cpp:236] Iteration 13900, loss = 0.61602
I0729 05:03:28.101989 118397 solver.cpp:252]     Train net output #0: loss = 0.635196 (* 1 = 0.635196 loss)
I0729 05:03:28.102015 118397 sgd_solver.cpp:106] Iteration 13900, lr = 0.0081
I0729 05:04:09.719406 118397 solver.cpp:236] Iteration 13910, loss = 0.615403
I0729 05:04:09.719609 118397 solver.cpp:252]     Train net output #0: loss = 0.633925 (* 1 = 0.633925 loss)
I0729 05:04:09.719638 118397 sgd_solver.cpp:106] Iteration 13910, lr = 0.0081
I0729 05:04:41.462666 118397 solver.cpp:236] Iteration 13920, loss = 0.608663
I0729 05:04:41.462905 118397 solver.cpp:252]     Train net output #0: loss = 0.649822 (* 1 = 0.649822 loss)
I0729 05:04:41.462935 118397 sgd_solver.cpp:106] Iteration 13920, lr = 0.0081
I0729 05:05:16.765029 118397 solver.cpp:236] Iteration 13930, loss = 0.612341
I0729 05:05:16.765200 118397 solver.cpp:252]     Train net output #0: loss = 0.643013 (* 1 = 0.643013 loss)
I0729 05:05:16.765221 118397 sgd_solver.cpp:106] Iteration 13930, lr = 0.0081
I0729 05:06:02.212419 118397 solver.cpp:236] Iteration 13940, loss = 0.617897
I0729 05:06:02.212621 118397 solver.cpp:252]     Train net output #0: loss = 0.637181 (* 1 = 0.637181 loss)
I0729 05:06:02.212654 118397 sgd_solver.cpp:106] Iteration 13940, lr = 0.0081
I0729 05:06:42.956894 118397 solver.cpp:236] Iteration 13950, loss = 0.6177
I0729 05:06:42.957056 118397 solver.cpp:252]     Train net output #0: loss = 0.646955 (* 1 = 0.646955 loss)
I0729 05:06:42.957075 118397 sgd_solver.cpp:106] Iteration 13950, lr = 0.0081
I0729 05:07:30.243191 118397 solver.cpp:236] Iteration 13960, loss = 0.615197
I0729 05:07:30.243417 118397 solver.cpp:252]     Train net output #0: loss = 0.642554 (* 1 = 0.642554 loss)
I0729 05:07:30.243438 118397 sgd_solver.cpp:106] Iteration 13960, lr = 0.0081
I0729 05:08:15.095458 118397 solver.cpp:236] Iteration 13970, loss = 0.615134
I0729 05:08:15.095629 118397 solver.cpp:252]     Train net output #0: loss = 0.634636 (* 1 = 0.634636 loss)
I0729 05:08:15.095650 118397 sgd_solver.cpp:106] Iteration 13970, lr = 0.0081
I0729 05:08:56.264942 118397 solver.cpp:236] Iteration 13980, loss = 0.612979
I0729 05:08:56.265133 118397 solver.cpp:252]     Train net output #0: loss = 0.362319 (* 1 = 0.362319 loss)
I0729 05:08:56.265156 118397 sgd_solver.cpp:106] Iteration 13980, lr = 0.0081
I0729 05:09:47.075896 118397 solver.cpp:236] Iteration 13990, loss = 0.60998
I0729 05:09:47.076161 118397 solver.cpp:252]     Train net output #0: loss = 0.642003 (* 1 = 0.642003 loss)
I0729 05:09:47.076190 118397 sgd_solver.cpp:106] Iteration 13990, lr = 0.0081
I0729 05:10:28.761474 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_14000.caffemodel
I0729 05:10:28.859870 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_14000.solverstate
I0729 05:10:28.864135 118397 solver.cpp:340] Iteration 14000, Testing net (#0)
I0729 05:11:17.409718 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 05:11:17.409945 118397 solver.cpp:408]     Test net output #1: loss = 0.608932 (* 1 = 0.608932 loss)
I0729 05:11:21.504231 118397 solver.cpp:236] Iteration 14000, loss = 0.606919
I0729 05:11:21.504294 118397 solver.cpp:252]     Train net output #0: loss = 0.644936 (* 1 = 0.644936 loss)
I0729 05:11:21.504308 118397 sgd_solver.cpp:106] Iteration 14000, lr = 0.0081
I0729 05:12:10.752426 118397 solver.cpp:236] Iteration 14010, loss = 0.609749
I0729 05:12:10.752665 118397 solver.cpp:252]     Train net output #0: loss = 0.634356 (* 1 = 0.634356 loss)
I0729 05:12:10.752688 118397 sgd_solver.cpp:106] Iteration 14010, lr = 0.0081
I0729 05:12:54.899094 118397 solver.cpp:236] Iteration 14020, loss = 0.616278
I0729 05:12:54.899286 118397 solver.cpp:252]     Train net output #0: loss = 0.634212 (* 1 = 0.634212 loss)
I0729 05:12:54.899312 118397 sgd_solver.cpp:106] Iteration 14020, lr = 0.0081
I0729 05:13:39.540063 118397 solver.cpp:236] Iteration 14030, loss = 0.614639
I0729 05:13:39.540220 118397 solver.cpp:252]     Train net output #0: loss = 0.629883 (* 1 = 0.629883 loss)
I0729 05:13:39.540236 118397 sgd_solver.cpp:106] Iteration 14030, lr = 0.0081
I0729 05:14:18.747356 118397 solver.cpp:236] Iteration 14040, loss = 0.612006
I0729 05:14:18.747552 118397 solver.cpp:252]     Train net output #0: loss = 0.636495 (* 1 = 0.636495 loss)
I0729 05:14:18.747567 118397 sgd_solver.cpp:106] Iteration 14040, lr = 0.0081
I0729 05:15:11.280124 118397 solver.cpp:236] Iteration 14050, loss = 0.616504
I0729 05:15:11.280279 118397 solver.cpp:252]     Train net output #0: loss = 0.634754 (* 1 = 0.634754 loss)
I0729 05:15:11.280306 118397 sgd_solver.cpp:106] Iteration 14050, lr = 0.0081
I0729 05:15:52.755069 118397 solver.cpp:236] Iteration 14060, loss = 0.616315
I0729 05:15:52.755234 118397 solver.cpp:252]     Train net output #0: loss = 0.632694 (* 1 = 0.632694 loss)
I0729 05:15:52.755259 118397 sgd_solver.cpp:106] Iteration 14060, lr = 0.0081
I0729 05:16:34.530648 118397 solver.cpp:236] Iteration 14070, loss = 0.613565
I0729 05:16:34.530781 118397 solver.cpp:252]     Train net output #0: loss = 0.644743 (* 1 = 0.644743 loss)
I0729 05:16:34.530800 118397 sgd_solver.cpp:106] Iteration 14070, lr = 0.0081
I0729 05:17:18.234705 118397 solver.cpp:236] Iteration 14080, loss = 0.612673
I0729 05:17:18.234897 118397 solver.cpp:252]     Train net output #0: loss = 0.639356 (* 1 = 0.639356 loss)
I0729 05:17:18.234936 118397 sgd_solver.cpp:106] Iteration 14080, lr = 0.0081
I0729 05:17:59.750627 118397 solver.cpp:236] Iteration 14090, loss = 0.615542
I0729 05:17:59.750811 118397 solver.cpp:252]     Train net output #0: loss = 0.638823 (* 1 = 0.638823 loss)
I0729 05:17:59.750844 118397 sgd_solver.cpp:106] Iteration 14090, lr = 0.0081
I0729 05:18:38.904635 118397 solver.cpp:236] Iteration 14100, loss = 0.614353
I0729 05:18:38.904911 118397 solver.cpp:252]     Train net output #0: loss = 0.650217 (* 1 = 0.650217 loss)
I0729 05:18:38.904927 118397 sgd_solver.cpp:106] Iteration 14100, lr = 0.0081
I0729 05:19:17.953411 118397 solver.cpp:236] Iteration 14110, loss = 0.612082
I0729 05:19:17.953611 118397 solver.cpp:252]     Train net output #0: loss = 0.643046 (* 1 = 0.643046 loss)
I0729 05:19:17.953639 118397 sgd_solver.cpp:106] Iteration 14110, lr = 0.0081
I0729 05:20:02.673116 118397 solver.cpp:236] Iteration 14120, loss = 0.609151
I0729 05:20:02.673310 118397 solver.cpp:252]     Train net output #0: loss = 0.368978 (* 1 = 0.368978 loss)
I0729 05:20:02.673331 118397 sgd_solver.cpp:106] Iteration 14120, lr = 0.0081
I0729 05:20:43.146901 118397 solver.cpp:236] Iteration 14130, loss = 0.605271
I0729 05:20:43.147121 118397 solver.cpp:252]     Train net output #0: loss = 0.666971 (* 1 = 0.666971 loss)
I0729 05:20:43.147142 118397 sgd_solver.cpp:106] Iteration 14130, lr = 0.0081
I0729 05:21:31.389892 118397 solver.cpp:236] Iteration 14140, loss = 0.6052
I0729 05:21:31.390096 118397 solver.cpp:252]     Train net output #0: loss = 0.634255 (* 1 = 0.634255 loss)
I0729 05:21:31.390115 118397 sgd_solver.cpp:106] Iteration 14140, lr = 0.0081
I0729 05:22:11.654153 118397 solver.cpp:236] Iteration 14150, loss = 0.605128
I0729 05:22:11.654326 118397 solver.cpp:252]     Train net output #0: loss = 0.638413 (* 1 = 0.638413 loss)
I0729 05:22:11.654356 118397 sgd_solver.cpp:106] Iteration 14150, lr = 0.0081
I0729 05:22:58.342685 118397 solver.cpp:236] Iteration 14160, loss = 0.60563
I0729 05:22:58.342833 118397 solver.cpp:252]     Train net output #0: loss = 0.641527 (* 1 = 0.641527 loss)
I0729 05:22:58.342852 118397 sgd_solver.cpp:106] Iteration 14160, lr = 0.0081
I0729 05:23:31.955638 118397 solver.cpp:236] Iteration 14170, loss = 0.591674
I0729 05:23:31.955932 118397 solver.cpp:252]     Train net output #0: loss = 0.701555 (* 1 = 0.701555 loss)
I0729 05:23:31.955948 118397 sgd_solver.cpp:106] Iteration 14170, lr = 0.0081
I0729 05:24:09.019701 118397 solver.cpp:236] Iteration 14180, loss = 0.602219
I0729 05:24:09.019922 118397 solver.cpp:252]     Train net output #0: loss = 0.642089 (* 1 = 0.642089 loss)
I0729 05:24:09.019949 118397 sgd_solver.cpp:106] Iteration 14180, lr = 0.0081
I0729 05:24:49.793514 118397 solver.cpp:236] Iteration 14190, loss = 0.602435
I0729 05:24:49.793733 118397 solver.cpp:252]     Train net output #0: loss = 0.647067 (* 1 = 0.647067 loss)
I0729 05:24:49.793759 118397 sgd_solver.cpp:106] Iteration 14190, lr = 0.0081
I0729 05:25:30.978911 118397 solver.cpp:236] Iteration 14200, loss = 0.609506
I0729 05:25:30.979059 118397 solver.cpp:252]     Train net output #0: loss = 0.632435 (* 1 = 0.632435 loss)
I0729 05:25:30.979076 118397 sgd_solver.cpp:106] Iteration 14200, lr = 0.0081
I0729 05:26:05.669531 118397 solver.cpp:236] Iteration 14210, loss = 0.608807
I0729 05:26:05.669697 118397 solver.cpp:252]     Train net output #0: loss = 0.642858 (* 1 = 0.642858 loss)
I0729 05:26:05.669731 118397 sgd_solver.cpp:106] Iteration 14210, lr = 0.0081
I0729 05:26:45.535048 118397 solver.cpp:236] Iteration 14220, loss = 0.614545
I0729 05:26:45.535218 118397 solver.cpp:252]     Train net output #0: loss = 0.635209 (* 1 = 0.635209 loss)
I0729 05:26:45.535239 118397 sgd_solver.cpp:106] Iteration 14220, lr = 0.0081
I0729 05:27:25.763149 118397 solver.cpp:236] Iteration 14230, loss = 0.616032
I0729 05:27:25.763391 118397 solver.cpp:252]     Train net output #0: loss = 0.631824 (* 1 = 0.631824 loss)
I0729 05:27:25.763413 118397 sgd_solver.cpp:106] Iteration 14230, lr = 0.0081
I0729 05:28:06.335286 118397 solver.cpp:236] Iteration 14240, loss = 0.613162
I0729 05:28:06.335479 118397 solver.cpp:252]     Train net output #0: loss = 0.348546 (* 1 = 0.348546 loss)
I0729 05:28:06.335506 118397 sgd_solver.cpp:106] Iteration 14240, lr = 0.0081
I0729 05:28:47.445385 118397 solver.cpp:236] Iteration 14250, loss = 0.610523
I0729 05:28:47.445534 118397 solver.cpp:252]     Train net output #0: loss = 0.638342 (* 1 = 0.638342 loss)
I0729 05:28:47.445562 118397 sgd_solver.cpp:106] Iteration 14250, lr = 0.0081
I0729 05:29:21.557850 118397 solver.cpp:236] Iteration 14260, loss = 0.607355
I0729 05:29:21.559638 118397 solver.cpp:252]     Train net output #0: loss = 0.656293 (* 1 = 0.656293 loss)
I0729 05:29:21.559653 118397 sgd_solver.cpp:106] Iteration 14260, lr = 0.0081
I0729 05:30:00.851936 118397 solver.cpp:236] Iteration 14270, loss = 0.610673
I0729 05:30:00.852108 118397 solver.cpp:252]     Train net output #0: loss = 0.269729 (* 1 = 0.269729 loss)
I0729 05:30:00.852128 118397 sgd_solver.cpp:106] Iteration 14270, lr = 0.0081
I0729 05:30:37.798828 118397 solver.cpp:236] Iteration 14280, loss = 0.600331
I0729 05:30:37.799047 118397 solver.cpp:252]     Train net output #0: loss = 0.658312 (* 1 = 0.658312 loss)
I0729 05:30:37.799077 118397 sgd_solver.cpp:106] Iteration 14280, lr = 0.0081
I0729 05:31:16.503991 118397 solver.cpp:236] Iteration 14290, loss = 0.597352
I0729 05:31:16.504214 118397 solver.cpp:252]     Train net output #0: loss = 0.636592 (* 1 = 0.636592 loss)
I0729 05:31:16.504236 118397 sgd_solver.cpp:106] Iteration 14290, lr = 0.0081
I0729 05:31:58.419394 118397 solver.cpp:236] Iteration 14300, loss = 0.597119
I0729 05:31:58.419620 118397 solver.cpp:252]     Train net output #0: loss = 0.63683 (* 1 = 0.63683 loss)
I0729 05:31:58.419633 118397 sgd_solver.cpp:106] Iteration 14300, lr = 0.0081
I0729 05:32:38.490105 118397 solver.cpp:236] Iteration 14310, loss = 0.597201
I0729 05:32:38.490285 118397 solver.cpp:252]     Train net output #0: loss = 0.38204 (* 1 = 0.38204 loss)
I0729 05:32:38.490329 118397 sgd_solver.cpp:106] Iteration 14310, lr = 0.0081
I0729 05:33:12.080369 118397 solver.cpp:236] Iteration 14320, loss = 0.595631
I0729 05:33:12.080510 118397 solver.cpp:252]     Train net output #0: loss = 0.650574 (* 1 = 0.650574 loss)
I0729 05:33:12.080528 118397 sgd_solver.cpp:106] Iteration 14320, lr = 0.0081
I0729 05:33:55.350930 118397 solver.cpp:236] Iteration 14330, loss = 0.595367
I0729 05:33:55.351064 118397 solver.cpp:252]     Train net output #0: loss = 0.635615 (* 1 = 0.635615 loss)
I0729 05:33:55.351081 118397 sgd_solver.cpp:106] Iteration 14330, lr = 0.0081
I0729 05:34:29.443549 118397 solver.cpp:236] Iteration 14340, loss = 0.594347
I0729 05:34:29.443696 118397 solver.cpp:252]     Train net output #0: loss = 0.391433 (* 1 = 0.391433 loss)
I0729 05:34:29.443716 118397 sgd_solver.cpp:106] Iteration 14340, lr = 0.0081
I0729 05:35:05.401484 118397 solver.cpp:236] Iteration 14350, loss = 0.591211
I0729 05:35:05.401626 118397 solver.cpp:252]     Train net output #0: loss = 0.768525 (* 1 = 0.768525 loss)
I0729 05:35:05.401643 118397 sgd_solver.cpp:106] Iteration 14350, lr = 0.0081
I0729 05:35:49.403995 118397 solver.cpp:236] Iteration 14360, loss = 0.599109
I0729 05:35:49.404244 118397 solver.cpp:252]     Train net output #0: loss = 0.387855 (* 1 = 0.387855 loss)
I0729 05:35:49.404260 118397 sgd_solver.cpp:106] Iteration 14360, lr = 0.0081
I0729 05:36:31.455348 118397 solver.cpp:236] Iteration 14370, loss = 0.609958
I0729 05:36:31.455543 118397 solver.cpp:252]     Train net output #0: loss = 0.631668 (* 1 = 0.631668 loss)
I0729 05:36:31.455572 118397 sgd_solver.cpp:106] Iteration 14370, lr = 0.0081
I0729 05:37:12.405624 118397 solver.cpp:236] Iteration 14380, loss = 0.610372
I0729 05:37:12.405784 118397 solver.cpp:252]     Train net output #0: loss = 0.643419 (* 1 = 0.643419 loss)
I0729 05:37:12.405802 118397 sgd_solver.cpp:106] Iteration 14380, lr = 0.0081
I0729 05:37:51.691869 118397 solver.cpp:236] Iteration 14390, loss = 0.61072
I0729 05:37:51.692054 118397 solver.cpp:252]     Train net output #0: loss = 0.649052 (* 1 = 0.649052 loss)
I0729 05:37:51.692070 118397 sgd_solver.cpp:106] Iteration 14390, lr = 0.0081
I0729 05:38:35.952724 118397 solver.cpp:236] Iteration 14400, loss = 0.606315
I0729 05:38:35.952870 118397 solver.cpp:252]     Train net output #0: loss = 0.636349 (* 1 = 0.636349 loss)
I0729 05:38:35.952888 118397 sgd_solver.cpp:106] Iteration 14400, lr = 0.0081
I0729 05:39:15.313434 118397 solver.cpp:236] Iteration 14410, loss = 0.605461
I0729 05:39:15.313691 118397 solver.cpp:252]     Train net output #0: loss = 0.673914 (* 1 = 0.673914 loss)
I0729 05:39:15.313711 118397 sgd_solver.cpp:106] Iteration 14410, lr = 0.0081
I0729 05:39:56.943593 118397 solver.cpp:236] Iteration 14420, loss = 0.597574
I0729 05:39:56.943783 118397 solver.cpp:252]     Train net output #0: loss = 0.317321 (* 1 = 0.317321 loss)
I0729 05:39:56.943804 118397 sgd_solver.cpp:106] Iteration 14420, lr = 0.0081
I0729 05:40:41.414605 118397 solver.cpp:236] Iteration 14430, loss = 0.600764
I0729 05:40:41.414805 118397 solver.cpp:252]     Train net output #0: loss = 0.632499 (* 1 = 0.632499 loss)
I0729 05:40:41.414834 118397 sgd_solver.cpp:106] Iteration 14430, lr = 0.0081
I0729 05:41:21.778411 118397 solver.cpp:236] Iteration 14440, loss = 0.607175
I0729 05:41:21.778635 118397 solver.cpp:252]     Train net output #0: loss = 0.635723 (* 1 = 0.635723 loss)
I0729 05:41:21.778679 118397 sgd_solver.cpp:106] Iteration 14440, lr = 0.0081
I0729 05:41:56.924571 118397 solver.cpp:236] Iteration 14450, loss = 0.612952
I0729 05:41:56.924757 118397 solver.cpp:252]     Train net output #0: loss = 0.635713 (* 1 = 0.635713 loss)
I0729 05:41:56.924795 118397 sgd_solver.cpp:106] Iteration 14450, lr = 0.0081
I0729 05:42:41.584720 118397 solver.cpp:236] Iteration 14460, loss = 0.609945
I0729 05:42:41.584946 118397 solver.cpp:252]     Train net output #0: loss = 0.636582 (* 1 = 0.636582 loss)
I0729 05:42:41.584969 118397 sgd_solver.cpp:106] Iteration 14460, lr = 0.0081
I0729 05:43:17.732849 118397 solver.cpp:236] Iteration 14470, loss = 0.609898
I0729 05:43:17.733013 118397 solver.cpp:252]     Train net output #0: loss = 0.637207 (* 1 = 0.637207 loss)
I0729 05:43:17.733031 118397 sgd_solver.cpp:106] Iteration 14470, lr = 0.0081
I0729 05:43:50.368499 118397 solver.cpp:236] Iteration 14480, loss = 0.614754
I0729 05:43:50.368659 118397 solver.cpp:252]     Train net output #0: loss = 0.632944 (* 1 = 0.632944 loss)
I0729 05:43:50.368675 118397 sgd_solver.cpp:106] Iteration 14480, lr = 0.0081
I0729 05:44:27.300180 118397 solver.cpp:236] Iteration 14490, loss = 0.612455
I0729 05:44:27.300356 118397 solver.cpp:252]     Train net output #0: loss = 0.642752 (* 1 = 0.642752 loss)
I0729 05:44:27.300390 118397 sgd_solver.cpp:106] Iteration 14490, lr = 0.0081
I0729 05:45:08.479818 118397 solver.cpp:340] Iteration 14500, Testing net (#0)
I0729 05:45:45.370388 118397 solver.cpp:408]     Test net output #0: accuracy = 0.729688
I0729 05:45:45.370540 118397 solver.cpp:408]     Test net output #1: loss = 0.584284 (* 1 = 0.584284 loss)
I0729 05:45:47.750486 118397 solver.cpp:236] Iteration 14500, loss = 0.618264
I0729 05:45:47.750548 118397 solver.cpp:252]     Train net output #0: loss = 0.640912 (* 1 = 0.640912 loss)
I0729 05:45:47.750565 118397 sgd_solver.cpp:106] Iteration 14500, lr = 0.0081
I0729 05:46:32.992506 118397 solver.cpp:236] Iteration 14510, loss = 0.617339
I0729 05:46:32.992662 118397 solver.cpp:252]     Train net output #0: loss = 0.639524 (* 1 = 0.639524 loss)
I0729 05:46:32.992679 118397 sgd_solver.cpp:106] Iteration 14510, lr = 0.0081
I0729 05:47:15.958930 118397 solver.cpp:236] Iteration 14520, loss = 0.623871
I0729 05:47:15.959079 118397 solver.cpp:252]     Train net output #0: loss = 0.637887 (* 1 = 0.637887 loss)
I0729 05:47:15.959115 118397 sgd_solver.cpp:106] Iteration 14520, lr = 0.0081
I0729 05:47:57.577309 118397 solver.cpp:236] Iteration 14530, loss = 0.621106
I0729 05:47:57.577510 118397 solver.cpp:252]     Train net output #0: loss = 0.640603 (* 1 = 0.640603 loss)
I0729 05:47:57.577525 118397 sgd_solver.cpp:106] Iteration 14530, lr = 0.0081
I0729 05:48:41.907245 118397 solver.cpp:236] Iteration 14540, loss = 0.61552
I0729 05:48:41.907476 118397 solver.cpp:252]     Train net output #0: loss = 0.647654 (* 1 = 0.647654 loss)
I0729 05:48:41.907500 118397 sgd_solver.cpp:106] Iteration 14540, lr = 0.0081
I0729 05:49:22.680688 118397 solver.cpp:236] Iteration 14550, loss = 0.610212
I0729 05:49:22.680824 118397 solver.cpp:252]     Train net output #0: loss = 0.642139 (* 1 = 0.642139 loss)
I0729 05:49:22.680838 118397 sgd_solver.cpp:106] Iteration 14550, lr = 0.0081
I0729 05:50:13.258581 118397 solver.cpp:236] Iteration 14560, loss = 0.608547
I0729 05:50:13.258841 118397 solver.cpp:252]     Train net output #0: loss = 0.632935 (* 1 = 0.632935 loss)
I0729 05:50:13.258873 118397 sgd_solver.cpp:106] Iteration 14560, lr = 0.0081
I0729 05:50:57.921190 118397 solver.cpp:236] Iteration 14570, loss = 0.610839
I0729 05:50:57.921380 118397 solver.cpp:252]     Train net output #0: loss = 0.633656 (* 1 = 0.633656 loss)
I0729 05:50:57.921402 118397 sgd_solver.cpp:106] Iteration 14570, lr = 0.0081
I0729 05:51:37.801079 118397 solver.cpp:236] Iteration 14580, loss = 0.601699
I0729 05:51:37.801297 118397 solver.cpp:252]     Train net output #0: loss = 0.692918 (* 1 = 0.692918 loss)
I0729 05:51:37.801319 118397 sgd_solver.cpp:106] Iteration 14580, lr = 0.0081
I0729 05:52:32.995780 118397 solver.cpp:236] Iteration 14590, loss = 0.609499
I0729 05:52:32.995968 118397 solver.cpp:252]     Train net output #0: loss = 0.636681 (* 1 = 0.636681 loss)
I0729 05:52:32.995991 118397 sgd_solver.cpp:106] Iteration 14590, lr = 0.0081
I0729 05:53:16.809687 118397 solver.cpp:236] Iteration 14600, loss = 0.603641
I0729 05:53:16.809887 118397 solver.cpp:252]     Train net output #0: loss = 0.637859 (* 1 = 0.637859 loss)
I0729 05:53:16.809926 118397 sgd_solver.cpp:106] Iteration 14600, lr = 0.0081
I0729 05:54:04.897074 118397 solver.cpp:236] Iteration 14610, loss = 0.60556
I0729 05:54:04.897217 118397 solver.cpp:252]     Train net output #0: loss = 0.642563 (* 1 = 0.642563 loss)
I0729 05:54:04.897235 118397 sgd_solver.cpp:106] Iteration 14610, lr = 0.0081
I0729 05:54:54.430724 118397 solver.cpp:236] Iteration 14620, loss = 0.608282
I0729 05:54:54.430924 118397 solver.cpp:252]     Train net output #0: loss = 0.635286 (* 1 = 0.635286 loss)
I0729 05:54:54.430943 118397 sgd_solver.cpp:106] Iteration 14620, lr = 0.0081
I0729 05:55:36.091960 118397 solver.cpp:236] Iteration 14630, loss = 0.606204
I0729 05:55:36.092169 118397 solver.cpp:252]     Train net output #0: loss = 0.637077 (* 1 = 0.637077 loss)
I0729 05:55:36.092206 118397 sgd_solver.cpp:106] Iteration 14630, lr = 0.0081
I0729 05:56:24.390666 118397 solver.cpp:236] Iteration 14640, loss = 0.607538
I0729 05:56:24.390961 118397 solver.cpp:252]     Train net output #0: loss = 0.673887 (* 1 = 0.673887 loss)
I0729 05:56:24.390980 118397 sgd_solver.cpp:106] Iteration 14640, lr = 0.0081
I0729 05:57:12.683336 118397 solver.cpp:236] Iteration 14650, loss = 0.613974
I0729 05:57:12.683534 118397 solver.cpp:252]     Train net output #0: loss = 0.632921 (* 1 = 0.632921 loss)
I0729 05:57:12.683576 118397 sgd_solver.cpp:106] Iteration 14650, lr = 0.0081
I0729 05:57:57.953758 118397 solver.cpp:236] Iteration 14660, loss = 0.616186
I0729 05:57:57.953968 118397 solver.cpp:252]     Train net output #0: loss = 0.641976 (* 1 = 0.641976 loss)
I0729 05:57:57.953987 118397 sgd_solver.cpp:106] Iteration 14660, lr = 0.0081
I0729 05:58:40.501529 118397 solver.cpp:236] Iteration 14670, loss = 0.616201
I0729 05:58:40.501726 118397 solver.cpp:252]     Train net output #0: loss = 0.635218 (* 1 = 0.635218 loss)
I0729 05:58:40.501767 118397 sgd_solver.cpp:106] Iteration 14670, lr = 0.0081
I0729 05:59:24.585592 118397 solver.cpp:236] Iteration 14680, loss = 0.622955
I0729 05:59:24.588861 118397 solver.cpp:252]     Train net output #0: loss = 0.640416 (* 1 = 0.640416 loss)
I0729 05:59:24.588881 118397 sgd_solver.cpp:106] Iteration 14680, lr = 0.0081
I0729 06:00:03.303449 118397 solver.cpp:236] Iteration 14690, loss = 0.614455
I0729 06:00:03.303616 118397 solver.cpp:252]     Train net output #0: loss = 0.363964 (* 1 = 0.363964 loss)
I0729 06:00:03.303643 118397 sgd_solver.cpp:106] Iteration 14690, lr = 0.0081
I0729 06:00:57.499757 118397 solver.cpp:236] Iteration 14700, loss = 0.614183
I0729 06:00:57.499909 118397 solver.cpp:252]     Train net output #0: loss = 0.67348 (* 1 = 0.67348 loss)
I0729 06:00:57.499948 118397 sgd_solver.cpp:106] Iteration 14700, lr = 0.0081
I0729 06:01:44.981864 118397 solver.cpp:236] Iteration 14710, loss = 0.617832
I0729 06:01:44.982139 118397 solver.cpp:252]     Train net output #0: loss = 0.6372 (* 1 = 0.6372 loss)
I0729 06:01:44.982158 118397 sgd_solver.cpp:106] Iteration 14710, lr = 0.0081
I0729 06:02:26.932579 118397 solver.cpp:236] Iteration 14720, loss = 0.613894
I0729 06:02:26.932787 118397 solver.cpp:252]     Train net output #0: loss = 0.402261 (* 1 = 0.402261 loss)
I0729 06:02:26.932808 118397 sgd_solver.cpp:106] Iteration 14720, lr = 0.0081
I0729 06:03:09.607245 118397 solver.cpp:236] Iteration 14730, loss = 0.614886
I0729 06:03:09.607398 118397 solver.cpp:252]     Train net output #0: loss = 0.668458 (* 1 = 0.668458 loss)
I0729 06:03:09.607419 118397 sgd_solver.cpp:106] Iteration 14730, lr = 0.0081
I0729 06:04:05.425820 118397 solver.cpp:236] Iteration 14740, loss = 0.620291
I0729 06:04:05.426146 118397 solver.cpp:252]     Train net output #0: loss = 0.632124 (* 1 = 0.632124 loss)
I0729 06:04:05.426172 118397 sgd_solver.cpp:106] Iteration 14740, lr = 0.0081
I0729 06:04:53.041879 118397 solver.cpp:236] Iteration 14750, loss = 0.61769
I0729 06:04:53.042086 118397 solver.cpp:252]     Train net output #0: loss = 0.638833 (* 1 = 0.638833 loss)
I0729 06:04:53.042119 118397 sgd_solver.cpp:106] Iteration 14750, lr = 0.0081
I0729 06:05:42.591450 118397 solver.cpp:236] Iteration 14760, loss = 0.61716
I0729 06:05:42.591619 118397 solver.cpp:252]     Train net output #0: loss = 0.633325 (* 1 = 0.633325 loss)
I0729 06:05:42.591639 118397 sgd_solver.cpp:106] Iteration 14760, lr = 0.0081
I0729 06:06:15.756516 118397 solver.cpp:236] Iteration 14770, loss = 0.609012
I0729 06:06:15.756660 118397 solver.cpp:252]     Train net output #0: loss = 0.662907 (* 1 = 0.662907 loss)
I0729 06:06:15.756686 118397 sgd_solver.cpp:106] Iteration 14770, lr = 0.0081
I0729 06:06:52.540887 118397 solver.cpp:236] Iteration 14780, loss = 0.609957
I0729 06:06:52.541117 118397 solver.cpp:252]     Train net output #0: loss = 0.639989 (* 1 = 0.639989 loss)
I0729 06:06:52.541136 118397 sgd_solver.cpp:106] Iteration 14780, lr = 0.0081
I0729 06:07:38.673065 118397 solver.cpp:236] Iteration 14790, loss = 0.615236
I0729 06:07:38.673235 118397 solver.cpp:252]     Train net output #0: loss = 0.631593 (* 1 = 0.631593 loss)
I0729 06:07:38.673259 118397 sgd_solver.cpp:106] Iteration 14790, lr = 0.0081
I0729 06:08:19.979635 118397 solver.cpp:236] Iteration 14800, loss = 0.617842
I0729 06:08:19.979800 118397 solver.cpp:252]     Train net output #0: loss = 0.6359 (* 1 = 0.6359 loss)
I0729 06:08:19.979821 118397 sgd_solver.cpp:106] Iteration 14800, lr = 0.0081
I0729 06:09:04.570062 118397 solver.cpp:236] Iteration 14810, loss = 0.608088
I0729 06:09:04.570258 118397 solver.cpp:252]     Train net output #0: loss = 0.679673 (* 1 = 0.679673 loss)
I0729 06:09:04.570273 118397 sgd_solver.cpp:106] Iteration 14810, lr = 0.0081
I0729 06:09:40.516384 118397 solver.cpp:236] Iteration 14820, loss = 0.607717
I0729 06:09:40.516587 118397 solver.cpp:252]     Train net output #0: loss = 0.645041 (* 1 = 0.645041 loss)
I0729 06:09:40.516603 118397 sgd_solver.cpp:106] Iteration 14820, lr = 0.0081
I0729 06:10:16.925120 118397 solver.cpp:236] Iteration 14830, loss = 0.611598
I0729 06:10:16.925287 118397 solver.cpp:252]     Train net output #0: loss = 0.634981 (* 1 = 0.634981 loss)
I0729 06:10:16.925305 118397 sgd_solver.cpp:106] Iteration 14830, lr = 0.0081
I0729 06:10:56.558835 118397 solver.cpp:236] Iteration 14840, loss = 0.608427
I0729 06:10:56.558990 118397 solver.cpp:252]     Train net output #0: loss = 0.441863 (* 1 = 0.441863 loss)
I0729 06:10:56.559005 118397 sgd_solver.cpp:106] Iteration 14840, lr = 0.0081
I0729 06:11:44.870657 118397 solver.cpp:236] Iteration 14850, loss = 0.607941
I0729 06:11:44.870808 118397 solver.cpp:252]     Train net output #0: loss = 0.651204 (* 1 = 0.651204 loss)
I0729 06:11:44.870828 118397 sgd_solver.cpp:106] Iteration 14850, lr = 0.0081
I0729 06:12:36.014644 118397 solver.cpp:236] Iteration 14860, loss = 0.605783
I0729 06:12:36.014920 118397 solver.cpp:252]     Train net output #0: loss = 0.638277 (* 1 = 0.638277 loss)
I0729 06:12:36.014946 118397 sgd_solver.cpp:106] Iteration 14860, lr = 0.0081
I0729 06:13:14.412950 118397 solver.cpp:236] Iteration 14870, loss = 0.611556
I0729 06:13:14.413173 118397 solver.cpp:252]     Train net output #0: loss = 0.639563 (* 1 = 0.639563 loss)
I0729 06:13:14.413188 118397 sgd_solver.cpp:106] Iteration 14870, lr = 0.0081
I0729 06:13:53.559985 118397 solver.cpp:236] Iteration 14880, loss = 0.611169
I0729 06:13:53.560135 118397 solver.cpp:252]     Train net output #0: loss = 0.639566 (* 1 = 0.639566 loss)
I0729 06:13:53.560153 118397 sgd_solver.cpp:106] Iteration 14880, lr = 0.0081
I0729 06:14:34.094270 118397 solver.cpp:236] Iteration 14890, loss = 0.611083
I0729 06:14:34.094441 118397 solver.cpp:252]     Train net output #0: loss = 0.633551 (* 1 = 0.633551 loss)
I0729 06:14:34.094491 118397 sgd_solver.cpp:106] Iteration 14890, lr = 0.0081
I0729 06:15:17.214376 118397 solver.cpp:236] Iteration 14900, loss = 0.613033
I0729 06:15:17.214536 118397 solver.cpp:252]     Train net output #0: loss = 0.630556 (* 1 = 0.630556 loss)
I0729 06:15:17.214565 118397 sgd_solver.cpp:106] Iteration 14900, lr = 0.0081
I0729 06:15:55.038954 118397 solver.cpp:236] Iteration 14910, loss = 0.619467
I0729 06:15:55.039140 118397 solver.cpp:252]     Train net output #0: loss = 0.638844 (* 1 = 0.638844 loss)
I0729 06:15:55.039166 118397 sgd_solver.cpp:106] Iteration 14910, lr = 0.0081
I0729 06:16:33.632066 118397 solver.cpp:236] Iteration 14920, loss = 0.614585
I0729 06:16:33.632220 118397 solver.cpp:252]     Train net output #0: loss = 0.312797 (* 1 = 0.312797 loss)
I0729 06:16:33.632238 118397 sgd_solver.cpp:106] Iteration 14920, lr = 0.0081
I0729 06:17:25.800209 118397 solver.cpp:236] Iteration 14930, loss = 0.615215
I0729 06:17:25.800433 118397 solver.cpp:252]     Train net output #0: loss = 0.639699 (* 1 = 0.639699 loss)
I0729 06:17:25.800451 118397 sgd_solver.cpp:106] Iteration 14930, lr = 0.0081
I0729 06:18:03.401212 118397 solver.cpp:236] Iteration 14940, loss = 0.609385
I0729 06:18:03.401453 118397 solver.cpp:252]     Train net output #0: loss = 0.639038 (* 1 = 0.639038 loss)
I0729 06:18:03.401474 118397 sgd_solver.cpp:106] Iteration 14940, lr = 0.0081
I0729 06:18:41.456781 118397 solver.cpp:236] Iteration 14950, loss = 0.608784
I0729 06:18:41.456974 118397 solver.cpp:252]     Train net output #0: loss = 0.642141 (* 1 = 0.642141 loss)
I0729 06:18:41.456995 118397 sgd_solver.cpp:106] Iteration 14950, lr = 0.0081
I0729 06:19:14.386700 118397 solver.cpp:236] Iteration 14960, loss = 0.606343
I0729 06:19:14.386828 118397 solver.cpp:252]     Train net output #0: loss = 0.636249 (* 1 = 0.636249 loss)
I0729 06:19:14.386845 118397 sgd_solver.cpp:106] Iteration 14960, lr = 0.0081
I0729 06:19:53.233078 118397 solver.cpp:236] Iteration 14970, loss = 0.608996
I0729 06:19:53.233286 118397 solver.cpp:252]     Train net output #0: loss = 0.634119 (* 1 = 0.634119 loss)
I0729 06:19:53.233314 118397 sgd_solver.cpp:106] Iteration 14970, lr = 0.0081
I0729 06:20:39.687520 118397 solver.cpp:236] Iteration 14980, loss = 0.608549
I0729 06:20:39.687754 118397 solver.cpp:252]     Train net output #0: loss = 0.630815 (* 1 = 0.630815 loss)
I0729 06:20:39.687780 118397 sgd_solver.cpp:106] Iteration 14980, lr = 0.0081
I0729 06:21:20.111733 118397 solver.cpp:236] Iteration 14990, loss = 0.603385
I0729 06:21:20.111933 118397 solver.cpp:252]     Train net output #0: loss = 0.644742 (* 1 = 0.644742 loss)
I0729 06:21:20.111985 118397 sgd_solver.cpp:106] Iteration 14990, lr = 0.0081
I0729 06:21:51.092319 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_15000.caffemodel
I0729 06:21:51.190160 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_15000.solverstate
I0729 06:21:51.193827 118397 solver.cpp:340] Iteration 15000, Testing net (#0)
I0729 06:22:36.947254 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 06:22:36.947401 118397 solver.cpp:408]     Test net output #1: loss = 0.634196 (* 1 = 0.634196 loss)
I0729 06:22:40.363076 118397 solver.cpp:236] Iteration 15000, loss = 0.604139
I0729 06:22:40.363135 118397 solver.cpp:252]     Train net output #0: loss = 0.633925 (* 1 = 0.633925 loss)
I0729 06:22:40.363154 118397 sgd_solver.cpp:106] Iteration 15000, lr = 0.00729
I0729 06:23:25.461966 118397 solver.cpp:236] Iteration 15010, loss = 0.601373
I0729 06:23:25.462167 118397 solver.cpp:252]     Train net output #0: loss = 0.631118 (* 1 = 0.631118 loss)
I0729 06:23:25.462188 118397 sgd_solver.cpp:106] Iteration 15010, lr = 0.00729
I0729 06:24:13.974611 118397 solver.cpp:236] Iteration 15020, loss = 0.605038
I0729 06:24:13.974812 118397 solver.cpp:252]     Train net output #0: loss = 0.652697 (* 1 = 0.652697 loss)
I0729 06:24:13.974843 118397 sgd_solver.cpp:106] Iteration 15020, lr = 0.00729
I0729 06:24:55.678578 118397 solver.cpp:236] Iteration 15030, loss = 0.5986
I0729 06:24:55.678791 118397 solver.cpp:252]     Train net output #0: loss = 0.645361 (* 1 = 0.645361 loss)
I0729 06:24:55.678838 118397 sgd_solver.cpp:106] Iteration 15030, lr = 0.00729
I0729 06:25:36.494212 118397 solver.cpp:236] Iteration 15040, loss = 0.601309
I0729 06:25:36.494400 118397 solver.cpp:252]     Train net output #0: loss = 0.65184 (* 1 = 0.65184 loss)
I0729 06:25:36.494431 118397 sgd_solver.cpp:106] Iteration 15040, lr = 0.00729
I0729 06:26:21.953250 118397 solver.cpp:236] Iteration 15050, loss = 0.600974
I0729 06:26:21.953477 118397 solver.cpp:252]     Train net output #0: loss = 0.634002 (* 1 = 0.634002 loss)
I0729 06:26:21.953498 118397 sgd_solver.cpp:106] Iteration 15050, lr = 0.00729
I0729 06:27:02.398412 118397 solver.cpp:236] Iteration 15060, loss = 0.600994
I0729 06:27:02.398586 118397 solver.cpp:252]     Train net output #0: loss = 0.386776 (* 1 = 0.386776 loss)
I0729 06:27:02.398602 118397 sgd_solver.cpp:106] Iteration 15060, lr = 0.00729
I0729 06:27:42.821745 118397 solver.cpp:236] Iteration 15070, loss = 0.59865
I0729 06:27:42.821882 118397 solver.cpp:252]     Train net output #0: loss = 0.650174 (* 1 = 0.650174 loss)
I0729 06:27:42.821900 118397 sgd_solver.cpp:106] Iteration 15070, lr = 0.00729
I0729 06:28:22.559777 118397 solver.cpp:236] Iteration 15080, loss = 0.598547
I0729 06:28:22.559944 118397 solver.cpp:252]     Train net output #0: loss = 0.637925 (* 1 = 0.637925 loss)
I0729 06:28:22.559962 118397 sgd_solver.cpp:106] Iteration 15080, lr = 0.00729
I0729 06:28:52.893676 118397 solver.cpp:236] Iteration 15090, loss = 0.598804
I0729 06:28:52.893849 118397 solver.cpp:252]     Train net output #0: loss = 0.641017 (* 1 = 0.641017 loss)
I0729 06:28:52.893873 118397 sgd_solver.cpp:106] Iteration 15090, lr = 0.00729
I0729 06:29:36.198925 118397 solver.cpp:236] Iteration 15100, loss = 0.598552
I0729 06:29:36.199110 118397 solver.cpp:252]     Train net output #0: loss = 0.635026 (* 1 = 0.635026 loss)
I0729 06:29:36.199138 118397 sgd_solver.cpp:106] Iteration 15100, lr = 0.00729
I0729 06:30:03.518328 118397 solver.cpp:236] Iteration 15110, loss = 0.593398
I0729 06:30:03.518417 118397 solver.cpp:252]     Train net output #0: loss = 0.308714 (* 1 = 0.308714 loss)
I0729 06:30:03.518443 118397 sgd_solver.cpp:106] Iteration 15110, lr = 0.00729
I0729 06:30:29.607103 118397 solver.cpp:236] Iteration 15120, loss = 0.59876
I0729 06:30:29.607262 118397 solver.cpp:252]     Train net output #0: loss = 0.677847 (* 1 = 0.677847 loss)
I0729 06:30:29.607282 118397 sgd_solver.cpp:106] Iteration 15120, lr = 0.00729
I0729 06:30:54.443884 118397 solver.cpp:236] Iteration 15130, loss = 0.605069
I0729 06:30:54.443958 118397 solver.cpp:252]     Train net output #0: loss = 0.63309 (* 1 = 0.63309 loss)
I0729 06:30:54.443974 118397 sgd_solver.cpp:106] Iteration 15130, lr = 0.00729
I0729 06:31:20.781167 118397 solver.cpp:236] Iteration 15140, loss = 0.608949
I0729 06:31:20.781366 118397 solver.cpp:252]     Train net output #0: loss = 0.464812 (* 1 = 0.464812 loss)
I0729 06:31:20.781389 118397 sgd_solver.cpp:106] Iteration 15140, lr = 0.00729
I0729 06:31:57.069727 118397 solver.cpp:236] Iteration 15150, loss = 0.607302
I0729 06:31:57.069902 118397 solver.cpp:252]     Train net output #0: loss = 0.677432 (* 1 = 0.677432 loss)
I0729 06:31:57.069926 118397 sgd_solver.cpp:106] Iteration 15150, lr = 0.00729
I0729 06:32:37.637181 118397 solver.cpp:236] Iteration 15160, loss = 0.610876
I0729 06:32:37.637418 118397 solver.cpp:252]     Train net output #0: loss = 0.644468 (* 1 = 0.644468 loss)
I0729 06:32:37.637444 118397 sgd_solver.cpp:106] Iteration 15160, lr = 0.00729
I0729 06:33:14.965965 118397 solver.cpp:236] Iteration 15170, loss = 0.607512
I0729 06:33:14.966111 118397 solver.cpp:252]     Train net output #0: loss = 0.638652 (* 1 = 0.638652 loss)
I0729 06:33:14.966130 118397 sgd_solver.cpp:106] Iteration 15170, lr = 0.00729
I0729 06:34:01.012208 118397 solver.cpp:236] Iteration 15180, loss = 0.601031
I0729 06:34:01.012341 118397 solver.cpp:252]     Train net output #0: loss = 0.649522 (* 1 = 0.649522 loss)
I0729 06:34:01.012358 118397 sgd_solver.cpp:106] Iteration 15180, lr = 0.00729
I0729 06:34:37.998513 118397 solver.cpp:236] Iteration 15190, loss = 0.603763
I0729 06:34:37.998705 118397 solver.cpp:252]     Train net output #0: loss = 0.642058 (* 1 = 0.642058 loss)
I0729 06:34:37.998764 118397 sgd_solver.cpp:106] Iteration 15190, lr = 0.00729
I0729 06:35:26.962327 118397 solver.cpp:236] Iteration 15200, loss = 0.600694
I0729 06:35:26.962473 118397 solver.cpp:252]     Train net output #0: loss = 0.632693 (* 1 = 0.632693 loss)
I0729 06:35:26.962489 118397 sgd_solver.cpp:106] Iteration 15200, lr = 0.00729
I0729 06:36:14.103996 118397 solver.cpp:236] Iteration 15210, loss = 0.608226
I0729 06:36:14.104133 118397 solver.cpp:252]     Train net output #0: loss = 0.6344 (* 1 = 0.6344 loss)
I0729 06:36:14.104161 118397 sgd_solver.cpp:106] Iteration 15210, lr = 0.00729
I0729 06:36:58.370510 118397 solver.cpp:236] Iteration 15220, loss = 0.60805
I0729 06:36:58.370746 118397 solver.cpp:252]     Train net output #0: loss = 0.633541 (* 1 = 0.633541 loss)
I0729 06:36:58.370764 118397 sgd_solver.cpp:106] Iteration 15220, lr = 0.00729
I0729 06:37:44.440438 118397 solver.cpp:236] Iteration 15230, loss = 0.604813
I0729 06:37:44.440600 118397 solver.cpp:252]     Train net output #0: loss = 0.636376 (* 1 = 0.636376 loss)
I0729 06:37:44.440620 118397 sgd_solver.cpp:106] Iteration 15230, lr = 0.00729
I0729 06:38:30.197549 118397 solver.cpp:236] Iteration 15240, loss = 0.603455
I0729 06:38:30.197789 118397 solver.cpp:252]     Train net output #0: loss = 0.374353 (* 1 = 0.374353 loss)
I0729 06:38:30.197808 118397 sgd_solver.cpp:106] Iteration 15240, lr = 0.00729
I0729 06:39:12.676818 118397 solver.cpp:236] Iteration 15250, loss = 0.608165
I0729 06:39:12.677000 118397 solver.cpp:252]     Train net output #0: loss = 0.638196 (* 1 = 0.638196 loss)
I0729 06:39:12.677024 118397 sgd_solver.cpp:106] Iteration 15250, lr = 0.00729
I0729 06:39:57.096046 118397 solver.cpp:236] Iteration 15260, loss = 0.60903
I0729 06:39:57.096268 118397 solver.cpp:252]     Train net output #0: loss = 0.638468 (* 1 = 0.638468 loss)
I0729 06:39:57.096289 118397 sgd_solver.cpp:106] Iteration 15260, lr = 0.00729
I0729 06:40:42.911675 118397 solver.cpp:236] Iteration 15270, loss = 0.612379
I0729 06:40:42.911813 118397 solver.cpp:252]     Train net output #0: loss = 0.636821 (* 1 = 0.636821 loss)
I0729 06:40:42.911830 118397 sgd_solver.cpp:106] Iteration 15270, lr = 0.00729
I0729 06:41:40.921303 118397 solver.cpp:236] Iteration 15280, loss = 0.618917
I0729 06:41:40.921502 118397 solver.cpp:252]     Train net output #0: loss = 0.642374 (* 1 = 0.642374 loss)
I0729 06:41:40.921532 118397 sgd_solver.cpp:106] Iteration 15280, lr = 0.00729
I0729 06:42:24.454262 118397 solver.cpp:236] Iteration 15290, loss = 0.618662
I0729 06:42:24.454440 118397 solver.cpp:252]     Train net output #0: loss = 0.640945 (* 1 = 0.640945 loss)
I0729 06:42:24.454488 118397 sgd_solver.cpp:106] Iteration 15290, lr = 0.00729
I0729 06:43:03.679141 118397 solver.cpp:236] Iteration 15300, loss = 0.615734
I0729 06:43:03.679374 118397 solver.cpp:252]     Train net output #0: loss = 0.645373 (* 1 = 0.645373 loss)
I0729 06:43:03.679405 118397 sgd_solver.cpp:106] Iteration 15300, lr = 0.00729
I0729 06:43:54.308701 118397 solver.cpp:236] Iteration 15310, loss = 0.612913
I0729 06:43:54.308928 118397 solver.cpp:252]     Train net output #0: loss = 0.655309 (* 1 = 0.655309 loss)
I0729 06:43:54.308946 118397 sgd_solver.cpp:106] Iteration 15310, lr = 0.00729
I0729 06:44:34.915206 118397 solver.cpp:236] Iteration 15320, loss = 0.607598
I0729 06:44:34.915365 118397 solver.cpp:252]     Train net output #0: loss = 0.647822 (* 1 = 0.647822 loss)
I0729 06:44:34.915381 118397 sgd_solver.cpp:106] Iteration 15320, lr = 0.00729
I0729 06:45:13.765031 118397 solver.cpp:236] Iteration 15330, loss = 0.601158
I0729 06:45:13.765187 118397 solver.cpp:252]     Train net output #0: loss = 0.654902 (* 1 = 0.654902 loss)
I0729 06:45:13.765223 118397 sgd_solver.cpp:106] Iteration 15330, lr = 0.00729
I0729 06:46:08.789870 118397 solver.cpp:236] Iteration 15340, loss = 0.596302
I0729 06:46:08.790030 118397 solver.cpp:252]     Train net output #0: loss = 0.649108 (* 1 = 0.649108 loss)
I0729 06:46:08.790048 118397 sgd_solver.cpp:106] Iteration 15340, lr = 0.00729
I0729 06:46:51.450487 118397 solver.cpp:236] Iteration 15350, loss = 0.594282
I0729 06:46:51.450680 118397 solver.cpp:252]     Train net output #0: loss = 0.330265 (* 1 = 0.330265 loss)
I0729 06:46:51.450696 118397 sgd_solver.cpp:106] Iteration 15350, lr = 0.00729
I0729 06:47:42.220643 118397 solver.cpp:236] Iteration 15360, loss = 0.594613
I0729 06:47:42.220778 118397 solver.cpp:252]     Train net output #0: loss = 0.629102 (* 1 = 0.629102 loss)
I0729 06:47:42.220795 118397 sgd_solver.cpp:106] Iteration 15360, lr = 0.00729
I0729 06:48:21.196168 118397 solver.cpp:236] Iteration 15370, loss = 0.594287
I0729 06:48:21.196411 118397 solver.cpp:252]     Train net output #0: loss = 0.634477 (* 1 = 0.634477 loss)
I0729 06:48:21.196429 118397 sgd_solver.cpp:106] Iteration 15370, lr = 0.00729
I0729 06:49:08.558718 118397 solver.cpp:236] Iteration 15380, loss = 0.591148
I0729 06:49:08.558905 118397 solver.cpp:252]     Train net output #0: loss = 0.340217 (* 1 = 0.340217 loss)
I0729 06:49:08.558931 118397 sgd_solver.cpp:106] Iteration 15380, lr = 0.00729
I0729 06:49:50.240198 118397 solver.cpp:236] Iteration 15390, loss = 0.594171
I0729 06:49:50.240404 118397 solver.cpp:252]     Train net output #0: loss = 0.638064 (* 1 = 0.638064 loss)
I0729 06:49:50.240420 118397 sgd_solver.cpp:106] Iteration 15390, lr = 0.00729
I0729 06:50:32.817025 118397 solver.cpp:236] Iteration 15400, loss = 0.59491
I0729 06:50:32.817270 118397 solver.cpp:252]     Train net output #0: loss = 0.63724 (* 1 = 0.63724 loss)
I0729 06:50:32.817286 118397 sgd_solver.cpp:106] Iteration 15400, lr = 0.00729
I0729 06:51:21.621167 118397 solver.cpp:236] Iteration 15410, loss = 0.600592
I0729 06:51:21.621354 118397 solver.cpp:252]     Train net output #0: loss = 0.633062 (* 1 = 0.633062 loss)
I0729 06:51:21.621389 118397 sgd_solver.cpp:106] Iteration 15410, lr = 0.00729
I0729 06:52:06.507272 118397 solver.cpp:236] Iteration 15420, loss = 0.606068
I0729 06:52:06.507418 118397 solver.cpp:252]     Train net output #0: loss = 0.639358 (* 1 = 0.639358 loss)
I0729 06:52:06.507436 118397 sgd_solver.cpp:106] Iteration 15420, lr = 0.00729
I0729 06:52:52.738731 118397 solver.cpp:236] Iteration 15430, loss = 0.610205
I0729 06:52:52.738870 118397 solver.cpp:252]     Train net output #0: loss = 0.645829 (* 1 = 0.645829 loss)
I0729 06:52:52.738888 118397 sgd_solver.cpp:106] Iteration 15430, lr = 0.00729
I0729 06:53:45.279175 118397 solver.cpp:236] Iteration 15440, loss = 0.615055
I0729 06:53:45.279369 118397 solver.cpp:252]     Train net output #0: loss = 0.643166 (* 1 = 0.643166 loss)
I0729 06:53:45.279392 118397 sgd_solver.cpp:106] Iteration 15440, lr = 0.00729
I0729 06:54:27.011373 118397 solver.cpp:236] Iteration 15450, loss = 0.616953
I0729 06:54:27.011536 118397 solver.cpp:252]     Train net output #0: loss = 0.631846 (* 1 = 0.631846 loss)
I0729 06:54:27.011565 118397 sgd_solver.cpp:106] Iteration 15450, lr = 0.00729
I0729 06:55:10.729641 118397 solver.cpp:236] Iteration 15460, loss = 0.616797
I0729 06:55:10.729843 118397 solver.cpp:252]     Train net output #0: loss = 0.633566 (* 1 = 0.633566 loss)
I0729 06:55:10.729871 118397 sgd_solver.cpp:106] Iteration 15460, lr = 0.00729
I0729 06:55:45.372663 118397 solver.cpp:236] Iteration 15470, loss = 0.617205
I0729 06:55:45.372931 118397 solver.cpp:252]     Train net output #0: loss = 0.644065 (* 1 = 0.644065 loss)
I0729 06:55:45.372958 118397 sgd_solver.cpp:106] Iteration 15470, lr = 0.00729
I0729 06:56:27.699272 118397 solver.cpp:236] Iteration 15480, loss = 0.622957
I0729 06:56:27.699450 118397 solver.cpp:252]     Train net output #0: loss = 0.633217 (* 1 = 0.633217 loss)
I0729 06:56:27.699496 118397 sgd_solver.cpp:106] Iteration 15480, lr = 0.00729
I0729 06:57:09.456671 118397 solver.cpp:236] Iteration 15490, loss = 0.61994
I0729 06:57:09.456908 118397 solver.cpp:252]     Train net output #0: loss = 0.634034 (* 1 = 0.634034 loss)
I0729 06:57:09.456924 118397 sgd_solver.cpp:106] Iteration 15490, lr = 0.00729
I0729 06:57:47.162389 118397 solver.cpp:340] Iteration 15500, Testing net (#0)
I0729 06:58:29.899123 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 06:58:29.899341 118397 solver.cpp:408]     Test net output #1: loss = 0.611027 (* 1 = 0.611027 loss)
I0729 06:58:33.424311 118397 solver.cpp:236] Iteration 15500, loss = 0.619435
I0729 06:58:33.424365 118397 solver.cpp:252]     Train net output #0: loss = 0.644522 (* 1 = 0.644522 loss)
I0729 06:58:33.424381 118397 sgd_solver.cpp:106] Iteration 15500, lr = 0.00729
I0729 06:59:11.137655 118397 solver.cpp:236] Iteration 15510, loss = 0.610523
I0729 06:59:11.137881 118397 solver.cpp:252]     Train net output #0: loss = 0.326098 (* 1 = 0.326098 loss)
I0729 06:59:11.137895 118397 sgd_solver.cpp:106] Iteration 15510, lr = 0.00729
I0729 06:59:49.865928 118397 solver.cpp:236] Iteration 15520, loss = 0.60554
I0729 06:59:49.866122 118397 solver.cpp:252]     Train net output #0: loss = 0.661566 (* 1 = 0.661566 loss)
I0729 06:59:49.866153 118397 sgd_solver.cpp:106] Iteration 15520, lr = 0.00729
I0729 07:00:33.432334 118397 solver.cpp:236] Iteration 15530, loss = 0.611495
I0729 07:00:33.432565 118397 solver.cpp:252]     Train net output #0: loss = 0.633204 (* 1 = 0.633204 loss)
I0729 07:00:33.432585 118397 sgd_solver.cpp:106] Iteration 15530, lr = 0.00729
I0729 07:01:17.263545 118397 solver.cpp:236] Iteration 15540, loss = 0.612321
I0729 07:01:17.263695 118397 solver.cpp:252]     Train net output #0: loss = 0.632697 (* 1 = 0.632697 loss)
I0729 07:01:17.263713 118397 sgd_solver.cpp:106] Iteration 15540, lr = 0.00729
I0729 07:02:00.789343 118397 solver.cpp:236] Iteration 15550, loss = 0.606779
I0729 07:02:00.790132 118397 solver.cpp:252]     Train net output #0: loss = 0.29732 (* 1 = 0.29732 loss)
I0729 07:02:00.790151 118397 sgd_solver.cpp:106] Iteration 15550, lr = 0.00729
I0729 07:02:39.204057 118397 solver.cpp:236] Iteration 15560, loss = 0.605146
I0729 07:02:39.204380 118397 solver.cpp:252]     Train net output #0: loss = 0.347764 (* 1 = 0.347764 loss)
I0729 07:02:39.204403 118397 sgd_solver.cpp:106] Iteration 15560, lr = 0.00729
I0729 07:03:18.616488 118397 solver.cpp:236] Iteration 15570, loss = 0.607197
I0729 07:03:18.616637 118397 solver.cpp:252]     Train net output #0: loss = 0.631407 (* 1 = 0.631407 loss)
I0729 07:03:18.616659 118397 sgd_solver.cpp:106] Iteration 15570, lr = 0.00729
I0729 07:04:01.800247 118397 solver.cpp:236] Iteration 15580, loss = 0.604841
I0729 07:04:01.800431 118397 solver.cpp:252]     Train net output #0: loss = 0.636326 (* 1 = 0.636326 loss)
I0729 07:04:01.800447 118397 sgd_solver.cpp:106] Iteration 15580, lr = 0.00729
I0729 07:04:39.200120 118397 solver.cpp:236] Iteration 15590, loss = 0.605245
I0729 07:04:39.200430 118397 solver.cpp:252]     Train net output #0: loss = 0.646354 (* 1 = 0.646354 loss)
I0729 07:04:39.200464 118397 sgd_solver.cpp:106] Iteration 15590, lr = 0.00729
I0729 07:05:13.089754 118397 solver.cpp:236] Iteration 15600, loss = 0.608314
I0729 07:05:13.089885 118397 solver.cpp:252]     Train net output #0: loss = 0.631384 (* 1 = 0.631384 loss)
I0729 07:05:13.089902 118397 sgd_solver.cpp:106] Iteration 15600, lr = 0.00729
I0729 07:05:52.271860 118397 solver.cpp:236] Iteration 15610, loss = 0.61684
I0729 07:05:52.272030 118397 solver.cpp:252]     Train net output #0: loss = 0.636854 (* 1 = 0.636854 loss)
I0729 07:05:52.272047 118397 sgd_solver.cpp:106] Iteration 15610, lr = 0.00729
I0729 07:06:24.658387 118397 solver.cpp:236] Iteration 15620, loss = 0.610432
I0729 07:06:24.658537 118397 solver.cpp:252]     Train net output #0: loss = 0.663766 (* 1 = 0.663766 loss)
I0729 07:06:24.658556 118397 sgd_solver.cpp:106] Iteration 15620, lr = 0.00729
I0729 07:07:03.510329 118397 solver.cpp:236] Iteration 15630, loss = 0.609492
I0729 07:07:03.510519 118397 solver.cpp:252]     Train net output #0: loss = 0.65777 (* 1 = 0.65777 loss)
I0729 07:07:03.510552 118397 sgd_solver.cpp:106] Iteration 15630, lr = 0.00729
I0729 07:07:45.424751 118397 solver.cpp:236] Iteration 15640, loss = 0.611462
I0729 07:07:45.424973 118397 solver.cpp:252]     Train net output #0: loss = 0.635812 (* 1 = 0.635812 loss)
I0729 07:07:45.424990 118397 sgd_solver.cpp:106] Iteration 15640, lr = 0.00729
I0729 07:08:21.877818 118397 solver.cpp:236] Iteration 15650, loss = 0.615477
I0729 07:08:21.877971 118397 solver.cpp:252]     Train net output #0: loss = 0.434662 (* 1 = 0.434662 loss)
I0729 07:08:21.877993 118397 sgd_solver.cpp:106] Iteration 15650, lr = 0.00729
I0729 07:08:56.070878 118397 solver.cpp:236] Iteration 15660, loss = 0.614182
I0729 07:08:56.071100 118397 solver.cpp:252]     Train net output #0: loss = 0.651311 (* 1 = 0.651311 loss)
I0729 07:08:56.071121 118397 sgd_solver.cpp:106] Iteration 15660, lr = 0.00729
I0729 07:09:35.862387 118397 solver.cpp:236] Iteration 15670, loss = 0.611976
I0729 07:09:35.862541 118397 solver.cpp:252]     Train net output #0: loss = 0.640796 (* 1 = 0.640796 loss)
I0729 07:09:35.862560 118397 sgd_solver.cpp:106] Iteration 15670, lr = 0.00729
I0729 07:10:11.210273 118397 solver.cpp:236] Iteration 15680, loss = 0.611506
I0729 07:10:11.210461 118397 solver.cpp:252]     Train net output #0: loss = 0.638064 (* 1 = 0.638064 loss)
I0729 07:10:11.210490 118397 sgd_solver.cpp:106] Iteration 15680, lr = 0.00729
I0729 07:10:44.608184 118397 solver.cpp:236] Iteration 15690, loss = 0.608376
I0729 07:10:44.608361 118397 solver.cpp:252]     Train net output #0: loss = 0.361429 (* 1 = 0.361429 loss)
I0729 07:10:44.608388 118397 sgd_solver.cpp:106] Iteration 15690, lr = 0.00729
I0729 07:11:22.462399 118397 solver.cpp:236] Iteration 15700, loss = 0.608159
I0729 07:11:22.462543 118397 solver.cpp:252]     Train net output #0: loss = 0.650391 (* 1 = 0.650391 loss)
I0729 07:11:22.462560 118397 sgd_solver.cpp:106] Iteration 15700, lr = 0.00729
I0729 07:11:56.004813 118397 solver.cpp:236] Iteration 15710, loss = 0.608582
I0729 07:11:56.005026 118397 solver.cpp:252]     Train net output #0: loss = 0.631578 (* 1 = 0.631578 loss)
I0729 07:11:56.005061 118397 sgd_solver.cpp:106] Iteration 15710, lr = 0.00729
I0729 07:12:36.720526 118397 solver.cpp:236] Iteration 15720, loss = 0.61789
I0729 07:12:36.720721 118397 solver.cpp:252]     Train net output #0: loss = 0.63424 (* 1 = 0.63424 loss)
I0729 07:12:36.720741 118397 sgd_solver.cpp:106] Iteration 15720, lr = 0.00729
I0729 07:13:14.539161 118397 solver.cpp:236] Iteration 15730, loss = 0.613485
I0729 07:13:14.539350 118397 solver.cpp:252]     Train net output #0: loss = 0.666458 (* 1 = 0.666458 loss)
I0729 07:13:14.539376 118397 sgd_solver.cpp:106] Iteration 15730, lr = 0.00729
I0729 07:13:51.732101 118397 solver.cpp:236] Iteration 15740, loss = 0.61104
I0729 07:13:51.732269 118397 solver.cpp:252]     Train net output #0: loss = 0.642913 (* 1 = 0.642913 loss)
I0729 07:13:51.732303 118397 sgd_solver.cpp:106] Iteration 15740, lr = 0.00729
I0729 07:14:30.753113 118397 solver.cpp:236] Iteration 15750, loss = 0.610748
I0729 07:14:30.753275 118397 solver.cpp:252]     Train net output #0: loss = 0.462781 (* 1 = 0.462781 loss)
I0729 07:14:30.753294 118397 sgd_solver.cpp:106] Iteration 15750, lr = 0.00729
I0729 07:15:04.462353 118397 solver.cpp:236] Iteration 15760, loss = 0.60559
I0729 07:15:04.462529 118397 solver.cpp:252]     Train net output #0: loss = 0.665697 (* 1 = 0.665697 loss)
I0729 07:15:04.462548 118397 sgd_solver.cpp:106] Iteration 15760, lr = 0.00729
I0729 07:15:38.184715 118397 solver.cpp:236] Iteration 15770, loss = 0.607611
I0729 07:15:38.184880 118397 solver.cpp:252]     Train net output #0: loss = 0.668868 (* 1 = 0.668868 loss)
I0729 07:15:38.184897 118397 sgd_solver.cpp:106] Iteration 15770, lr = 0.00729
I0729 07:16:10.793211 118397 solver.cpp:236] Iteration 15780, loss = 0.604701
I0729 07:16:10.793402 118397 solver.cpp:252]     Train net output #0: loss = 0.638051 (* 1 = 0.638051 loss)
I0729 07:16:10.793437 118397 sgd_solver.cpp:106] Iteration 15780, lr = 0.00729
I0729 07:16:48.688259 118397 solver.cpp:236] Iteration 15790, loss = 0.604914
I0729 07:16:48.688444 118397 solver.cpp:252]     Train net output #0: loss = 0.37054 (* 1 = 0.37054 loss)
I0729 07:16:48.688472 118397 sgd_solver.cpp:106] Iteration 15790, lr = 0.00729
I0729 07:17:18.684401 118397 solver.cpp:236] Iteration 15800, loss = 0.598112
I0729 07:17:18.684484 118397 solver.cpp:252]     Train net output #0: loss = 0.668276 (* 1 = 0.668276 loss)
I0729 07:17:18.684502 118397 sgd_solver.cpp:106] Iteration 15800, lr = 0.00729
I0729 07:17:55.990496 118397 solver.cpp:236] Iteration 15810, loss = 0.597478
I0729 07:17:55.990738 118397 solver.cpp:252]     Train net output #0: loss = 0.664046 (* 1 = 0.664046 loss)
I0729 07:17:55.990766 118397 sgd_solver.cpp:106] Iteration 15810, lr = 0.00729
I0729 07:18:36.622655 118397 solver.cpp:236] Iteration 15820, loss = 0.598152
I0729 07:18:36.622819 118397 solver.cpp:252]     Train net output #0: loss = 0.638377 (* 1 = 0.638377 loss)
I0729 07:18:36.622848 118397 sgd_solver.cpp:106] Iteration 15820, lr = 0.00729
I0729 07:19:04.539098 118397 solver.cpp:236] Iteration 15830, loss = 0.598519
I0729 07:19:04.539172 118397 solver.cpp:252]     Train net output #0: loss = 0.647594 (* 1 = 0.647594 loss)
I0729 07:19:04.539188 118397 sgd_solver.cpp:106] Iteration 15830, lr = 0.00729
I0729 07:19:44.584430 118397 solver.cpp:236] Iteration 15840, loss = 0.598511
I0729 07:19:44.584573 118397 solver.cpp:252]     Train net output #0: loss = 0.634956 (* 1 = 0.634956 loss)
I0729 07:19:44.584594 118397 sgd_solver.cpp:106] Iteration 15840, lr = 0.00729
I0729 07:20:20.078274 118397 solver.cpp:236] Iteration 15850, loss = 0.597958
I0729 07:20:20.078460 118397 solver.cpp:252]     Train net output #0: loss = 0.637784 (* 1 = 0.637784 loss)
I0729 07:20:20.078497 118397 sgd_solver.cpp:106] Iteration 15850, lr = 0.00729
I0729 07:20:49.432005 118397 solver.cpp:236] Iteration 15860, loss = 0.603592
I0729 07:20:49.432075 118397 solver.cpp:252]     Train net output #0: loss = 0.635334 (* 1 = 0.635334 loss)
I0729 07:20:49.432095 118397 sgd_solver.cpp:106] Iteration 15860, lr = 0.00729
I0729 07:21:26.867708 118397 solver.cpp:236] Iteration 15870, loss = 0.601215
I0729 07:21:26.867856 118397 solver.cpp:252]     Train net output #0: loss = 0.637979 (* 1 = 0.637979 loss)
I0729 07:21:26.867873 118397 sgd_solver.cpp:106] Iteration 15870, lr = 0.00729
I0729 07:22:00.903079 118397 solver.cpp:236] Iteration 15880, loss = 0.604329
I0729 07:22:00.903285 118397 solver.cpp:252]     Train net output #0: loss = 0.634888 (* 1 = 0.634888 loss)
I0729 07:22:00.903314 118397 sgd_solver.cpp:106] Iteration 15880, lr = 0.00729
I0729 07:22:35.931392 118397 solver.cpp:236] Iteration 15890, loss = 0.60678
I0729 07:22:35.931561 118397 solver.cpp:252]     Train net output #0: loss = 0.633146 (* 1 = 0.633146 loss)
I0729 07:22:35.931602 118397 sgd_solver.cpp:106] Iteration 15890, lr = 0.00729
I0729 07:23:09.586805 118397 solver.cpp:236] Iteration 15900, loss = 0.610458
I0729 07:23:09.587097 118397 solver.cpp:252]     Train net output #0: loss = 0.324624 (* 1 = 0.324624 loss)
I0729 07:23:09.587132 118397 sgd_solver.cpp:106] Iteration 15900, lr = 0.00729
I0729 07:23:49.699479 118397 solver.cpp:236] Iteration 15910, loss = 0.60181
I0729 07:23:49.699723 118397 solver.cpp:252]     Train net output #0: loss = 0.674187 (* 1 = 0.674187 loss)
I0729 07:23:49.699746 118397 sgd_solver.cpp:106] Iteration 15910, lr = 0.00729
I0729 07:24:25.308141 118397 solver.cpp:236] Iteration 15920, loss = 0.597926
I0729 07:24:25.308481 118397 solver.cpp:252]     Train net output #0: loss = 0.657606 (* 1 = 0.657606 loss)
I0729 07:24:25.308500 118397 sgd_solver.cpp:106] Iteration 15920, lr = 0.00729
I0729 07:25:04.776476 118397 solver.cpp:236] Iteration 15930, loss = 0.601864
I0729 07:25:04.776746 118397 solver.cpp:252]     Train net output #0: loss = 0.635612 (* 1 = 0.635612 loss)
I0729 07:25:04.776767 118397 sgd_solver.cpp:106] Iteration 15930, lr = 0.00729
I0729 07:25:43.325997 118397 solver.cpp:236] Iteration 15940, loss = 0.604297
I0729 07:25:43.326191 118397 solver.cpp:252]     Train net output #0: loss = 0.632027 (* 1 = 0.632027 loss)
I0729 07:25:43.326213 118397 sgd_solver.cpp:106] Iteration 15940, lr = 0.00729
I0729 07:26:21.488318 118397 solver.cpp:236] Iteration 15950, loss = 0.604323
I0729 07:26:21.488471 118397 solver.cpp:252]     Train net output #0: loss = 0.646261 (* 1 = 0.646261 loss)
I0729 07:26:21.488488 118397 sgd_solver.cpp:106] Iteration 15950, lr = 0.00729
I0729 07:27:00.611860 118397 solver.cpp:236] Iteration 15960, loss = 0.607117
I0729 07:27:00.612004 118397 solver.cpp:252]     Train net output #0: loss = 0.636062 (* 1 = 0.636062 loss)
I0729 07:27:00.612022 118397 sgd_solver.cpp:106] Iteration 15960, lr = 0.00729
I0729 07:27:38.835387 118397 solver.cpp:236] Iteration 15970, loss = 0.604786
I0729 07:27:38.835600 118397 solver.cpp:252]     Train net output #0: loss = 0.379417 (* 1 = 0.379417 loss)
I0729 07:27:38.835620 118397 sgd_solver.cpp:106] Iteration 15970, lr = 0.00729
I0729 07:28:17.637953 118397 solver.cpp:236] Iteration 15980, loss = 0.604535
I0729 07:28:17.641521 118397 solver.cpp:252]     Train net output #0: loss = 0.642404 (* 1 = 0.642404 loss)
I0729 07:28:17.641540 118397 sgd_solver.cpp:106] Iteration 15980, lr = 0.00729
I0729 07:28:57.178134 118397 solver.cpp:236] Iteration 15990, loss = 0.604635
I0729 07:28:57.178282 118397 solver.cpp:252]     Train net output #0: loss = 0.634214 (* 1 = 0.634214 loss)
I0729 07:28:57.178300 118397 sgd_solver.cpp:106] Iteration 15990, lr = 0.00729
I0729 07:29:31.860745 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_16000.caffemodel
I0729 07:29:31.954546 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_16000.solverstate
I0729 07:29:31.958890 118397 solver.cpp:340] Iteration 16000, Testing net (#0)
I0729 07:30:21.777292 118397 solver.cpp:408]     Test net output #0: accuracy = 0.704687
I0729 07:30:21.777456 118397 solver.cpp:408]     Test net output #1: loss = 0.60896 (* 1 = 0.60896 loss)
I0729 07:30:26.604790 118397 solver.cpp:236] Iteration 16000, loss = 0.610271
I0729 07:30:26.604859 118397 solver.cpp:252]     Train net output #0: loss = 0.628502 (* 1 = 0.628502 loss)
I0729 07:30:26.604877 118397 sgd_solver.cpp:106] Iteration 16000, lr = 0.00729
I0729 07:31:04.000613 118397 solver.cpp:236] Iteration 16010, loss = 0.614129
I0729 07:31:04.000800 118397 solver.cpp:252]     Train net output #0: loss = 0.638302 (* 1 = 0.638302 loss)
I0729 07:31:04.000823 118397 sgd_solver.cpp:106] Iteration 16010, lr = 0.00729
I0729 07:31:44.985481 118397 solver.cpp:236] Iteration 16020, loss = 0.613679
I0729 07:31:44.985640 118397 solver.cpp:252]     Train net output #0: loss = 0.657626 (* 1 = 0.657626 loss)
I0729 07:31:44.985664 118397 sgd_solver.cpp:106] Iteration 16020, lr = 0.00729
I0729 07:32:28.589129 118397 solver.cpp:236] Iteration 16030, loss = 0.611255
I0729 07:32:28.589293 118397 solver.cpp:252]     Train net output #0: loss = 0.639113 (* 1 = 0.639113 loss)
I0729 07:32:28.589313 118397 sgd_solver.cpp:106] Iteration 16030, lr = 0.00729
I0729 07:33:03.207065 118397 solver.cpp:236] Iteration 16040, loss = 0.605578
I0729 07:33:03.207202 118397 solver.cpp:252]     Train net output #0: loss = 0.639735 (* 1 = 0.639735 loss)
I0729 07:33:03.207219 118397 sgd_solver.cpp:106] Iteration 16040, lr = 0.00729
I0729 07:33:51.528450 118397 solver.cpp:236] Iteration 16050, loss = 0.608127
I0729 07:33:51.528674 118397 solver.cpp:252]     Train net output #0: loss = 0.634652 (* 1 = 0.634652 loss)
I0729 07:33:51.528697 118397 sgd_solver.cpp:106] Iteration 16050, lr = 0.00729
I0729 07:34:29.185466 118397 solver.cpp:236] Iteration 16060, loss = 0.607731
I0729 07:34:29.185715 118397 solver.cpp:252]     Train net output #0: loss = 0.630343 (* 1 = 0.630343 loss)
I0729 07:34:29.185734 118397 sgd_solver.cpp:106] Iteration 16060, lr = 0.00729
I0729 07:35:12.337003 118397 solver.cpp:236] Iteration 16070, loss = 0.610131
I0729 07:35:12.337169 118397 solver.cpp:252]     Train net output #0: loss = 0.639752 (* 1 = 0.639752 loss)
I0729 07:35:12.337198 118397 sgd_solver.cpp:106] Iteration 16070, lr = 0.00729
I0729 07:35:49.629474 118397 solver.cpp:236] Iteration 16080, loss = 0.613175
I0729 07:35:49.629739 118397 solver.cpp:252]     Train net output #0: loss = 0.636444 (* 1 = 0.636444 loss)
I0729 07:35:49.629796 118397 sgd_solver.cpp:106] Iteration 16080, lr = 0.00729
I0729 07:36:33.696858 118397 solver.cpp:236] Iteration 16090, loss = 0.612956
I0729 07:36:33.697013 118397 solver.cpp:252]     Train net output #0: loss = 0.635415 (* 1 = 0.635415 loss)
I0729 07:36:33.697049 118397 sgd_solver.cpp:106] Iteration 16090, lr = 0.00729
I0729 07:37:19.106922 118397 solver.cpp:236] Iteration 16100, loss = 0.61306
I0729 07:37:19.107059 118397 solver.cpp:252]     Train net output #0: loss = 0.635079 (* 1 = 0.635079 loss)
I0729 07:37:19.107076 118397 sgd_solver.cpp:106] Iteration 16100, lr = 0.00729
I0729 07:37:51.498769 118397 solver.cpp:236] Iteration 16110, loss = 0.61343
I0729 07:37:51.499027 118397 solver.cpp:252]     Train net output #0: loss = 0.636827 (* 1 = 0.636827 loss)
I0729 07:37:51.499047 118397 sgd_solver.cpp:106] Iteration 16110, lr = 0.00729
I0729 07:38:34.975517 118397 solver.cpp:236] Iteration 16120, loss = 0.609656
I0729 07:38:34.975682 118397 solver.cpp:252]     Train net output #0: loss = 0.664665 (* 1 = 0.664665 loss)
I0729 07:38:34.975698 118397 sgd_solver.cpp:106] Iteration 16120, lr = 0.00729
I0729 07:39:08.563438 118397 solver.cpp:236] Iteration 16130, loss = 0.61463
I0729 07:39:08.563653 118397 solver.cpp:252]     Train net output #0: loss = 0.643368 (* 1 = 0.643368 loss)
I0729 07:39:08.563683 118397 sgd_solver.cpp:106] Iteration 16130, lr = 0.00729
I0729 07:39:51.811873 118397 solver.cpp:236] Iteration 16140, loss = 0.620322
I0729 07:39:51.812055 118397 solver.cpp:252]     Train net output #0: loss = 0.644562 (* 1 = 0.644562 loss)
I0729 07:39:51.812096 118397 sgd_solver.cpp:106] Iteration 16140, lr = 0.00729
I0729 07:40:33.042132 118397 solver.cpp:236] Iteration 16150, loss = 0.618391
I0729 07:40:33.042287 118397 solver.cpp:252]     Train net output #0: loss = 0.641048 (* 1 = 0.641048 loss)
I0729 07:40:33.042309 118397 sgd_solver.cpp:106] Iteration 16150, lr = 0.00729
I0729 07:41:17.975941 118397 solver.cpp:236] Iteration 16160, loss = 0.619062
I0729 07:41:17.976192 118397 solver.cpp:252]     Train net output #0: loss = 0.637125 (* 1 = 0.637125 loss)
I0729 07:41:17.976213 118397 sgd_solver.cpp:106] Iteration 16160, lr = 0.00729
I0729 07:42:00.631405 118397 solver.cpp:236] Iteration 16170, loss = 0.616443
I0729 07:42:00.631593 118397 solver.cpp:252]     Train net output #0: loss = 0.63904 (* 1 = 0.63904 loss)
I0729 07:42:00.631613 118397 sgd_solver.cpp:106] Iteration 16170, lr = 0.00729
I0729 07:42:34.344368 118397 solver.cpp:236] Iteration 16180, loss = 0.613741
I0729 07:42:34.344553 118397 solver.cpp:252]     Train net output #0: loss = 0.64659 (* 1 = 0.64659 loss)
I0729 07:42:34.344593 118397 sgd_solver.cpp:106] Iteration 16180, lr = 0.00729
I0729 07:43:12.812252 118397 solver.cpp:236] Iteration 16190, loss = 0.61355
I0729 07:43:12.812391 118397 solver.cpp:252]     Train net output #0: loss = 0.637165 (* 1 = 0.637165 loss)
I0729 07:43:12.812410 118397 sgd_solver.cpp:106] Iteration 16190, lr = 0.00729
I0729 07:43:40.632125 118397 solver.cpp:236] Iteration 16200, loss = 0.613382
I0729 07:43:40.632202 118397 solver.cpp:252]     Train net output #0: loss = 0.632276 (* 1 = 0.632276 loss)
I0729 07:43:40.632217 118397 sgd_solver.cpp:106] Iteration 16200, lr = 0.00729
I0729 07:44:21.248126 118397 solver.cpp:236] Iteration 16210, loss = 0.613057
I0729 07:44:21.248371 118397 solver.cpp:252]     Train net output #0: loss = 0.637505 (* 1 = 0.637505 loss)
I0729 07:44:21.248389 118397 sgd_solver.cpp:106] Iteration 16210, lr = 0.00729
I0729 07:44:59.584173 118397 solver.cpp:236] Iteration 16220, loss = 0.613779
I0729 07:44:59.584383 118397 solver.cpp:252]     Train net output #0: loss = 0.685635 (* 1 = 0.685635 loss)
I0729 07:44:59.584411 118397 sgd_solver.cpp:106] Iteration 16220, lr = 0.00729
I0729 07:45:41.598803 118397 solver.cpp:236] Iteration 16230, loss = 0.609868
I0729 07:45:41.599025 118397 solver.cpp:252]     Train net output #0: loss = 0.645184 (* 1 = 0.645184 loss)
I0729 07:45:41.599053 118397 sgd_solver.cpp:106] Iteration 16230, lr = 0.00729
I0729 07:46:22.682811 118397 solver.cpp:236] Iteration 16240, loss = 0.604389
I0729 07:46:22.682986 118397 solver.cpp:252]     Train net output #0: loss = 0.636896 (* 1 = 0.636896 loss)
I0729 07:46:22.683014 118397 sgd_solver.cpp:106] Iteration 16240, lr = 0.00729
I0729 07:46:57.527992 118397 solver.cpp:236] Iteration 16250, loss = 0.603587
I0729 07:46:57.528151 118397 solver.cpp:252]     Train net output #0: loss = 0.637481 (* 1 = 0.637481 loss)
I0729 07:46:57.528170 118397 sgd_solver.cpp:106] Iteration 16250, lr = 0.00729
I0729 07:47:36.193631 118397 solver.cpp:236] Iteration 16260, loss = 0.597305
I0729 07:47:36.193871 118397 solver.cpp:252]     Train net output #0: loss = 0.641057 (* 1 = 0.641057 loss)
I0729 07:47:36.193897 118397 sgd_solver.cpp:106] Iteration 16260, lr = 0.00729
I0729 07:48:12.793366 118397 solver.cpp:236] Iteration 16270, loss = 0.599929
I0729 07:48:12.793578 118397 solver.cpp:252]     Train net output #0: loss = 0.639737 (* 1 = 0.639737 loss)
I0729 07:48:12.793594 118397 sgd_solver.cpp:106] Iteration 16270, lr = 0.00729
I0729 07:48:49.325563 118397 solver.cpp:236] Iteration 16280, loss = 0.599888
I0729 07:48:49.325718 118397 solver.cpp:252]     Train net output #0: loss = 0.641838 (* 1 = 0.641838 loss)
I0729 07:48:49.325743 118397 sgd_solver.cpp:106] Iteration 16280, lr = 0.00729
I0729 07:49:28.878507 118397 solver.cpp:236] Iteration 16290, loss = 0.597127
I0729 07:49:28.878710 118397 solver.cpp:252]     Train net output #0: loss = 0.63916 (* 1 = 0.63916 loss)
I0729 07:49:28.878729 118397 sgd_solver.cpp:106] Iteration 16290, lr = 0.00729
I0729 07:50:08.458403 118397 solver.cpp:236] Iteration 16300, loss = 0.597277
I0729 07:50:08.458623 118397 solver.cpp:252]     Train net output #0: loss = 0.632791 (* 1 = 0.632791 loss)
I0729 07:50:08.458678 118397 sgd_solver.cpp:106] Iteration 16300, lr = 0.00729
I0729 07:50:51.137442 118397 solver.cpp:236] Iteration 16310, loss = 0.602001
I0729 07:50:51.137616 118397 solver.cpp:252]     Train net output #0: loss = 0.633401 (* 1 = 0.633401 loss)
I0729 07:50:51.137673 118397 sgd_solver.cpp:106] Iteration 16310, lr = 0.00729
I0729 07:51:32.955682 118397 solver.cpp:236] Iteration 16320, loss = 0.608243
I0729 07:51:32.955865 118397 solver.cpp:252]     Train net output #0: loss = 0.394459 (* 1 = 0.394459 loss)
I0729 07:51:32.955883 118397 sgd_solver.cpp:106] Iteration 16320, lr = 0.00729
I0729 07:52:10.744408 118397 solver.cpp:236] Iteration 16330, loss = 0.606618
I0729 07:52:10.744611 118397 solver.cpp:252]     Train net output #0: loss = 0.643149 (* 1 = 0.643149 loss)
I0729 07:52:10.744632 118397 sgd_solver.cpp:106] Iteration 16330, lr = 0.00729
I0729 07:52:50.239131 118397 solver.cpp:236] Iteration 16340, loss = 0.609433
I0729 07:52:50.239362 118397 solver.cpp:252]     Train net output #0: loss = 0.63511 (* 1 = 0.63511 loss)
I0729 07:52:50.239380 118397 sgd_solver.cpp:106] Iteration 16340, lr = 0.00729
I0729 07:53:30.123756 118397 solver.cpp:236] Iteration 16350, loss = 0.611764
I0729 07:53:30.124383 118397 solver.cpp:252]     Train net output #0: loss = 0.635207 (* 1 = 0.635207 loss)
I0729 07:53:30.124406 118397 sgd_solver.cpp:106] Iteration 16350, lr = 0.00729
I0729 07:54:09.234236 118397 solver.cpp:236] Iteration 16360, loss = 0.61325
I0729 07:54:09.234450 118397 solver.cpp:252]     Train net output #0: loss = 0.644493 (* 1 = 0.644493 loss)
I0729 07:54:09.234485 118397 sgd_solver.cpp:106] Iteration 16360, lr = 0.00729
I0729 07:54:40.197211 118397 solver.cpp:236] Iteration 16370, loss = 0.606522
I0729 07:54:40.197427 118397 solver.cpp:252]     Train net output #0: loss = 0.675115 (* 1 = 0.675115 loss)
I0729 07:54:40.197460 118397 sgd_solver.cpp:106] Iteration 16370, lr = 0.00729
I0729 07:55:19.804095 118397 solver.cpp:236] Iteration 16380, loss = 0.610471
I0729 07:55:19.804255 118397 solver.cpp:252]     Train net output #0: loss = 0.638445 (* 1 = 0.638445 loss)
I0729 07:55:19.804287 118397 sgd_solver.cpp:106] Iteration 16380, lr = 0.00729
I0729 07:55:57.277243 118397 solver.cpp:236] Iteration 16390, loss = 0.616217
I0729 07:55:57.277410 118397 solver.cpp:252]     Train net output #0: loss = 0.639962 (* 1 = 0.639962 loss)
I0729 07:55:57.277428 118397 sgd_solver.cpp:106] Iteration 16390, lr = 0.00729
I0729 07:56:29.427628 118397 solver.cpp:236] Iteration 16400, loss = 0.612858
I0729 07:56:29.427785 118397 solver.cpp:252]     Train net output #0: loss = 0.65488 (* 1 = 0.65488 loss)
I0729 07:56:29.427803 118397 sgd_solver.cpp:106] Iteration 16400, lr = 0.00729
I0729 07:57:08.660626 118397 solver.cpp:236] Iteration 16410, loss = 0.610957
I0729 07:57:08.660842 118397 solver.cpp:252]     Train net output #0: loss = 0.634999 (* 1 = 0.634999 loss)
I0729 07:57:08.660882 118397 sgd_solver.cpp:106] Iteration 16410, lr = 0.00729
I0729 07:57:48.113216 118397 solver.cpp:236] Iteration 16420, loss = 0.613451
I0729 07:57:48.113363 118397 solver.cpp:252]     Train net output #0: loss = 0.627755 (* 1 = 0.627755 loss)
I0729 07:57:48.113381 118397 sgd_solver.cpp:106] Iteration 16420, lr = 0.00729
I0729 07:58:24.055510 118397 solver.cpp:236] Iteration 16430, loss = 0.613992
I0729 07:58:24.055737 118397 solver.cpp:252]     Train net output #0: loss = 0.636489 (* 1 = 0.636489 loss)
I0729 07:58:24.055762 118397 sgd_solver.cpp:106] Iteration 16430, lr = 0.00729
I0729 07:59:02.081387 118397 solver.cpp:236] Iteration 16440, loss = 0.613903
I0729 07:59:02.081619 118397 solver.cpp:252]     Train net output #0: loss = 0.641022 (* 1 = 0.641022 loss)
I0729 07:59:02.081641 118397 sgd_solver.cpp:106] Iteration 16440, lr = 0.00729
I0729 07:59:34.569948 118397 solver.cpp:236] Iteration 16450, loss = 0.608522
I0729 07:59:34.570113 118397 solver.cpp:252]     Train net output #0: loss = 0.646961 (* 1 = 0.646961 loss)
I0729 07:59:34.570130 118397 sgd_solver.cpp:106] Iteration 16450, lr = 0.00729
I0729 08:00:05.980736 118397 solver.cpp:236] Iteration 16460, loss = 0.610424
I0729 08:00:05.980893 118397 solver.cpp:252]     Train net output #0: loss = 0.642423 (* 1 = 0.642423 loss)
I0729 08:00:05.980911 118397 sgd_solver.cpp:106] Iteration 16460, lr = 0.00729
I0729 08:00:43.365427 118397 solver.cpp:236] Iteration 16470, loss = 0.616921
I0729 08:00:43.365604 118397 solver.cpp:252]     Train net output #0: loss = 0.634816 (* 1 = 0.634816 loss)
I0729 08:00:43.365633 118397 sgd_solver.cpp:106] Iteration 16470, lr = 0.00729
I0729 08:01:18.911113 118397 solver.cpp:236] Iteration 16480, loss = 0.612919
I0729 08:01:18.911278 118397 solver.cpp:252]     Train net output #0: loss = 0.62972 (* 1 = 0.62972 loss)
I0729 08:01:18.911308 118397 sgd_solver.cpp:106] Iteration 16480, lr = 0.00729
I0729 08:02:10.698246 118397 solver.cpp:236] Iteration 16490, loss = 0.610034
I0729 08:02:10.698424 118397 solver.cpp:252]     Train net output #0: loss = 0.637551 (* 1 = 0.637551 loss)
I0729 08:02:10.698453 118397 sgd_solver.cpp:106] Iteration 16490, lr = 0.00729
I0729 08:02:38.168112 118397 solver.cpp:340] Iteration 16500, Testing net (#0)
I0729 08:03:25.399626 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 08:03:25.399842 118397 solver.cpp:408]     Test net output #1: loss = 0.688998 (* 1 = 0.688998 loss)
I0729 08:03:30.914727 118397 solver.cpp:236] Iteration 16500, loss = 0.602048
I0729 08:03:30.914808 118397 solver.cpp:252]     Train net output #0: loss = 0.698098 (* 1 = 0.698098 loss)
I0729 08:03:30.914829 118397 sgd_solver.cpp:106] Iteration 16500, lr = 0.00729
I0729 08:04:03.390872 118397 solver.cpp:236] Iteration 16510, loss = 0.604512
I0729 08:04:03.391191 118397 solver.cpp:252]     Train net output #0: loss = 0.659477 (* 1 = 0.659477 loss)
I0729 08:04:03.391228 118397 sgd_solver.cpp:106] Iteration 16510, lr = 0.00729
I0729 08:04:44.312911 118397 solver.cpp:236] Iteration 16520, loss = 0.605029
I0729 08:04:44.313165 118397 solver.cpp:252]     Train net output #0: loss = 0.651011 (* 1 = 0.651011 loss)
I0729 08:04:44.313196 118397 sgd_solver.cpp:106] Iteration 16520, lr = 0.00729
I0729 08:05:24.593014 118397 solver.cpp:236] Iteration 16530, loss = 0.605928
I0729 08:05:24.593209 118397 solver.cpp:252]     Train net output #0: loss = 0.633345 (* 1 = 0.633345 loss)
I0729 08:05:24.593231 118397 sgd_solver.cpp:106] Iteration 16530, lr = 0.00729
I0729 08:06:01.600128 118397 solver.cpp:236] Iteration 16540, loss = 0.601534
I0729 08:06:01.600263 118397 solver.cpp:252]     Train net output #0: loss = 0.686874 (* 1 = 0.686874 loss)
I0729 08:06:01.600281 118397 sgd_solver.cpp:106] Iteration 16540, lr = 0.00729
I0729 08:06:43.423172 118397 solver.cpp:236] Iteration 16550, loss = 0.609313
I0729 08:06:43.423318 118397 solver.cpp:252]     Train net output #0: loss = 0.637662 (* 1 = 0.637662 loss)
I0729 08:06:43.423337 118397 sgd_solver.cpp:106] Iteration 16550, lr = 0.00729
I0729 08:07:14.735311 118397 solver.cpp:236] Iteration 16560, loss = 0.611891
I0729 08:07:14.735460 118397 solver.cpp:252]     Train net output #0: loss = 0.63383 (* 1 = 0.63383 loss)
I0729 08:07:14.735481 118397 sgd_solver.cpp:106] Iteration 16560, lr = 0.00729
I0729 08:07:57.645568 118397 solver.cpp:236] Iteration 16570, loss = 0.612822
I0729 08:07:57.645776 118397 solver.cpp:252]     Train net output #0: loss = 0.633315 (* 1 = 0.633315 loss)
I0729 08:07:57.645797 118397 sgd_solver.cpp:106] Iteration 16570, lr = 0.00729
I0729 08:08:30.721379 118397 solver.cpp:236] Iteration 16580, loss = 0.612884
I0729 08:08:30.721590 118397 solver.cpp:252]     Train net output #0: loss = 0.344155 (* 1 = 0.344155 loss)
I0729 08:08:30.721616 118397 sgd_solver.cpp:106] Iteration 16580, lr = 0.00729
I0729 08:09:04.437152 118397 solver.cpp:236] Iteration 16590, loss = 0.606822
I0729 08:09:04.437341 118397 solver.cpp:252]     Train net output #0: loss = 0.669254 (* 1 = 0.669254 loss)
I0729 08:09:04.437369 118397 sgd_solver.cpp:106] Iteration 16590, lr = 0.00729
I0729 08:09:48.330696 118397 solver.cpp:236] Iteration 16600, loss = 0.620134
I0729 08:09:48.330826 118397 solver.cpp:252]     Train net output #0: loss = 0.639814 (* 1 = 0.639814 loss)
I0729 08:09:48.330844 118397 sgd_solver.cpp:106] Iteration 16600, lr = 0.00729
I0729 08:10:20.599057 118397 solver.cpp:236] Iteration 16610, loss = 0.614568
I0729 08:10:20.599227 118397 solver.cpp:252]     Train net output #0: loss = 0.638228 (* 1 = 0.638228 loss)
I0729 08:10:20.599252 118397 sgd_solver.cpp:106] Iteration 16610, lr = 0.00729
I0729 08:10:58.493966 118397 solver.cpp:236] Iteration 16620, loss = 0.611391
I0729 08:10:58.494117 118397 solver.cpp:252]     Train net output #0: loss = 0.635998 (* 1 = 0.635998 loss)
I0729 08:10:58.494144 118397 sgd_solver.cpp:106] Iteration 16620, lr = 0.00729
I0729 08:11:41.576035 118397 solver.cpp:236] Iteration 16630, loss = 0.608102
I0729 08:11:41.576288 118397 solver.cpp:252]     Train net output #0: loss = 0.659988 (* 1 = 0.659988 loss)
I0729 08:11:41.576311 118397 sgd_solver.cpp:106] Iteration 16630, lr = 0.00729
I0729 08:12:18.369931 118397 solver.cpp:236] Iteration 16640, loss = 0.612583
I0729 08:12:18.370122 118397 solver.cpp:252]     Train net output #0: loss = 0.63983 (* 1 = 0.63983 loss)
I0729 08:12:18.370139 118397 sgd_solver.cpp:106] Iteration 16640, lr = 0.00729
I0729 08:12:59.603929 118397 solver.cpp:236] Iteration 16650, loss = 0.610216
I0729 08:12:59.604074 118397 solver.cpp:252]     Train net output #0: loss = 0.632911 (* 1 = 0.632911 loss)
I0729 08:12:59.604092 118397 sgd_solver.cpp:106] Iteration 16650, lr = 0.00729
I0729 08:13:34.072849 118397 solver.cpp:236] Iteration 16660, loss = 0.607911
I0729 08:13:34.073042 118397 solver.cpp:252]     Train net output #0: loss = 0.636864 (* 1 = 0.636864 loss)
I0729 08:13:34.073060 118397 sgd_solver.cpp:106] Iteration 16660, lr = 0.00729
I0729 08:14:18.225522 118397 solver.cpp:236] Iteration 16670, loss = 0.609886
I0729 08:14:18.225693 118397 solver.cpp:252]     Train net output #0: loss = 0.637547 (* 1 = 0.637547 loss)
I0729 08:14:18.225711 118397 sgd_solver.cpp:106] Iteration 16670, lr = 0.00729
I0729 08:14:54.155143 118397 solver.cpp:236] Iteration 16680, loss = 0.609826
I0729 08:14:54.155339 118397 solver.cpp:252]     Train net output #0: loss = 0.63881 (* 1 = 0.63881 loss)
I0729 08:14:54.155355 118397 sgd_solver.cpp:106] Iteration 16680, lr = 0.00729
I0729 08:15:42.954582 118397 solver.cpp:236] Iteration 16690, loss = 0.615941
I0729 08:15:42.954740 118397 solver.cpp:252]     Train net output #0: loss = 0.63703 (* 1 = 0.63703 loss)
I0729 08:15:42.954758 118397 sgd_solver.cpp:106] Iteration 16690, lr = 0.00729
I0729 08:16:16.415660 118397 solver.cpp:236] Iteration 16700, loss = 0.605601
I0729 08:16:16.415819 118397 solver.cpp:252]     Train net output #0: loss = 0.671831 (* 1 = 0.671831 loss)
I0729 08:16:16.415840 118397 sgd_solver.cpp:106] Iteration 16700, lr = 0.00729
I0729 08:16:59.486855 118397 solver.cpp:236] Iteration 16710, loss = 0.5972
I0729 08:16:59.486981 118397 solver.cpp:252]     Train net output #0: loss = 0.685862 (* 1 = 0.685862 loss)
I0729 08:16:59.486997 118397 sgd_solver.cpp:106] Iteration 16710, lr = 0.00729
I0729 08:17:38.363953 118397 solver.cpp:236] Iteration 16720, loss = 0.602356
I0729 08:17:38.364091 118397 solver.cpp:252]     Train net output #0: loss = 0.637825 (* 1 = 0.637825 loss)
I0729 08:17:38.364109 118397 sgd_solver.cpp:106] Iteration 16720, lr = 0.00729
I0729 08:18:19.793588 118397 solver.cpp:236] Iteration 16730, loss = 0.604541
I0729 08:18:19.793754 118397 solver.cpp:252]     Train net output #0: loss = 0.635906 (* 1 = 0.635906 loss)
I0729 08:18:19.793781 118397 sgd_solver.cpp:106] Iteration 16730, lr = 0.00729
I0729 08:18:59.117688 118397 solver.cpp:236] Iteration 16740, loss = 0.604556
I0729 08:18:59.117902 118397 solver.cpp:252]     Train net output #0: loss = 0.63237 (* 1 = 0.63237 loss)
I0729 08:18:59.117918 118397 sgd_solver.cpp:106] Iteration 16740, lr = 0.00729
I0729 08:19:33.465947 118397 solver.cpp:236] Iteration 16750, loss = 0.602203
I0729 08:19:33.466140 118397 solver.cpp:252]     Train net output #0: loss = 0.647632 (* 1 = 0.647632 loss)
I0729 08:19:33.466167 118397 sgd_solver.cpp:106] Iteration 16750, lr = 0.00729
I0729 08:20:14.104401 118397 solver.cpp:236] Iteration 16760, loss = 0.604529
I0729 08:20:14.104588 118397 solver.cpp:252]     Train net output #0: loss = 0.636593 (* 1 = 0.636593 loss)
I0729 08:20:14.104615 118397 sgd_solver.cpp:106] Iteration 16760, lr = 0.00729
I0729 08:20:49.743878 118397 solver.cpp:236] Iteration 16770, loss = 0.602217
I0729 08:20:49.744017 118397 solver.cpp:252]     Train net output #0: loss = 0.433551 (* 1 = 0.433551 loss)
I0729 08:20:49.744035 118397 sgd_solver.cpp:106] Iteration 16770, lr = 0.00729
I0729 08:21:22.884531 118397 solver.cpp:236] Iteration 16780, loss = 0.60203
I0729 08:21:22.884709 118397 solver.cpp:252]     Train net output #0: loss = 0.645558 (* 1 = 0.645558 loss)
I0729 08:21:22.884752 118397 sgd_solver.cpp:106] Iteration 16780, lr = 0.00729
I0729 08:22:00.963806 118397 solver.cpp:236] Iteration 16790, loss = 0.599145
I0729 08:22:00.964038 118397 solver.cpp:252]     Train net output #0: loss = 0.657929 (* 1 = 0.657929 loss)
I0729 08:22:00.964073 118397 sgd_solver.cpp:106] Iteration 16790, lr = 0.00729
I0729 08:22:47.092811 118397 solver.cpp:236] Iteration 16800, loss = 0.605599
I0729 08:22:47.093022 118397 solver.cpp:252]     Train net output #0: loss = 0.636429 (* 1 = 0.636429 loss)
I0729 08:22:47.093057 118397 sgd_solver.cpp:106] Iteration 16800, lr = 0.00729
I0729 08:23:21.442159 118397 solver.cpp:236] Iteration 16810, loss = 0.610703
I0729 08:23:21.442351 118397 solver.cpp:252]     Train net output #0: loss = 0.300553 (* 1 = 0.300553 loss)
I0729 08:23:21.442381 118397 sgd_solver.cpp:106] Iteration 16810, lr = 0.00729
I0729 08:23:57.869246 118397 solver.cpp:236] Iteration 16820, loss = 0.606364
I0729 08:23:57.869449 118397 solver.cpp:252]     Train net output #0: loss = 0.64975 (* 1 = 0.64975 loss)
I0729 08:23:57.869482 118397 sgd_solver.cpp:106] Iteration 16820, lr = 0.00729
I0729 08:24:33.959846 118397 solver.cpp:236] Iteration 16830, loss = 0.603036
I0729 08:24:33.959991 118397 solver.cpp:252]     Train net output #0: loss = 0.639772 (* 1 = 0.639772 loss)
I0729 08:24:33.960010 118397 sgd_solver.cpp:106] Iteration 16830, lr = 0.00729
I0729 08:25:12.692610 118397 solver.cpp:236] Iteration 16840, loss = 0.596531
I0729 08:25:12.692824 118397 solver.cpp:252]     Train net output #0: loss = 0.311255 (* 1 = 0.311255 loss)
I0729 08:25:12.692855 118397 sgd_solver.cpp:106] Iteration 16840, lr = 0.00729
I0729 08:25:53.082862 118397 solver.cpp:236] Iteration 16850, loss = 0.586226
I0729 08:25:53.083070 118397 solver.cpp:252]     Train net output #0: loss = 0.254465 (* 1 = 0.254465 loss)
I0729 08:25:53.083101 118397 sgd_solver.cpp:106] Iteration 16850, lr = 0.00729
I0729 08:26:28.535152 118397 solver.cpp:236] Iteration 16860, loss = 0.581853
I0729 08:26:28.535420 118397 solver.cpp:252]     Train net output #0: loss = 0.253942 (* 1 = 0.253942 loss)
I0729 08:26:28.535440 118397 sgd_solver.cpp:106] Iteration 16860, lr = 0.00729
I0729 08:27:08.990087 118397 solver.cpp:236] Iteration 16870, loss = 0.575119
I0729 08:27:08.990258 118397 solver.cpp:252]     Train net output #0: loss = 0.677806 (* 1 = 0.677806 loss)
I0729 08:27:08.990300 118397 sgd_solver.cpp:106] Iteration 16870, lr = 0.00729
I0729 08:27:44.520557 118397 solver.cpp:236] Iteration 16880, loss = 0.564391
I0729 08:27:44.520742 118397 solver.cpp:252]     Train net output #0: loss = 0.253033 (* 1 = 0.253033 loss)
I0729 08:27:44.520761 118397 sgd_solver.cpp:106] Iteration 16880, lr = 0.00729
I0729 08:28:27.220263 118397 solver.cpp:236] Iteration 16890, loss = 0.560622
I0729 08:28:27.220424 118397 solver.cpp:252]     Train net output #0: loss = 0.25475 (* 1 = 0.25475 loss)
I0729 08:28:27.220453 118397 sgd_solver.cpp:106] Iteration 16890, lr = 0.00729
I0729 08:29:04.388847 118397 solver.cpp:236] Iteration 16900, loss = 0.563387
I0729 08:29:04.388996 118397 solver.cpp:252]     Train net output #0: loss = 0.633656 (* 1 = 0.633656 loss)
I0729 08:29:04.389024 118397 sgd_solver.cpp:106] Iteration 16900, lr = 0.00729
I0729 08:29:36.174226 118397 solver.cpp:236] Iteration 16910, loss = 0.564667
I0729 08:29:36.175283 118397 solver.cpp:252]     Train net output #0: loss = 0.644085 (* 1 = 0.644085 loss)
I0729 08:29:36.175302 118397 sgd_solver.cpp:106] Iteration 16910, lr = 0.00729
I0729 08:30:12.383914 118397 solver.cpp:236] Iteration 16920, loss = 0.564251
I0729 08:30:12.384080 118397 solver.cpp:252]     Train net output #0: loss = 0.645241 (* 1 = 0.645241 loss)
I0729 08:30:12.384096 118397 sgd_solver.cpp:106] Iteration 16920, lr = 0.00729
I0729 08:30:47.346428 118397 solver.cpp:236] Iteration 16930, loss = 0.567112
I0729 08:30:47.346612 118397 solver.cpp:252]     Train net output #0: loss = 0.634331 (* 1 = 0.634331 loss)
I0729 08:30:47.346639 118397 sgd_solver.cpp:106] Iteration 16930, lr = 0.00729
I0729 08:31:26.363719 118397 solver.cpp:236] Iteration 16940, loss = 0.560284
I0729 08:31:26.363862 118397 solver.cpp:252]     Train net output #0: loss = 0.235665 (* 1 = 0.235665 loss)
I0729 08:31:26.363876 118397 sgd_solver.cpp:106] Iteration 16940, lr = 0.00729
I0729 08:32:05.396090 118397 solver.cpp:236] Iteration 16950, loss = 0.572961
I0729 08:32:05.396237 118397 solver.cpp:252]     Train net output #0: loss = 0.670953 (* 1 = 0.670953 loss)
I0729 08:32:05.396255 118397 sgd_solver.cpp:106] Iteration 16950, lr = 0.00729
I0729 08:32:33.800307 118397 solver.cpp:236] Iteration 16960, loss = 0.574438
I0729 08:32:33.800379 118397 solver.cpp:252]     Train net output #0: loss = 0.638025 (* 1 = 0.638025 loss)
I0729 08:32:33.800397 118397 sgd_solver.cpp:106] Iteration 16960, lr = 0.00729
I0729 08:33:11.054407 118397 solver.cpp:236] Iteration 16970, loss = 0.583332
I0729 08:33:11.054575 118397 solver.cpp:252]     Train net output #0: loss = 0.639515 (* 1 = 0.639515 loss)
I0729 08:33:11.054599 118397 sgd_solver.cpp:106] Iteration 16970, lr = 0.00729
I0729 08:33:49.359550 118397 solver.cpp:236] Iteration 16980, loss = 0.594403
I0729 08:33:49.359782 118397 solver.cpp:252]     Train net output #0: loss = 0.63561 (* 1 = 0.63561 loss)
I0729 08:33:49.359799 118397 sgd_solver.cpp:106] Iteration 16980, lr = 0.00729
I0729 08:34:29.005530 118397 solver.cpp:236] Iteration 16990, loss = 0.601104
I0729 08:34:29.005731 118397 solver.cpp:252]     Train net output #0: loss = 0.375984 (* 1 = 0.375984 loss)
I0729 08:34:29.005764 118397 sgd_solver.cpp:106] Iteration 16990, lr = 0.00729
I0729 08:35:02.622622 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_17000.caffemodel
I0729 08:35:02.725523 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_17000.solverstate
I0729 08:35:02.729720 118397 solver.cpp:340] Iteration 17000, Testing net (#0)
I0729 08:35:33.830097 118397 solver.cpp:408]     Test net output #0: accuracy = 0.770312
I0729 08:35:33.830293 118397 solver.cpp:408]     Test net output #1: loss = 0.540751 (* 1 = 0.540751 loss)
I0729 08:35:39.020815 118397 solver.cpp:236] Iteration 17000, loss = 0.594702
I0729 08:35:39.020889 118397 solver.cpp:252]     Train net output #0: loss = 0.64944 (* 1 = 0.64944 loss)
I0729 08:35:39.020907 118397 sgd_solver.cpp:106] Iteration 17000, lr = 0.00729
I0729 08:36:15.188596 118397 solver.cpp:236] Iteration 17010, loss = 0.596345
I0729 08:36:15.188809 118397 solver.cpp:252]     Train net output #0: loss = 0.653845 (* 1 = 0.653845 loss)
I0729 08:36:15.188839 118397 sgd_solver.cpp:106] Iteration 17010, lr = 0.00729
I0729 08:36:48.471820 118397 solver.cpp:236] Iteration 17020, loss = 0.599244
I0729 08:36:48.471964 118397 solver.cpp:252]     Train net output #0: loss = 0.635436 (* 1 = 0.635436 loss)
I0729 08:36:48.471984 118397 sgd_solver.cpp:106] Iteration 17020, lr = 0.00729
I0729 08:37:17.572510 118397 solver.cpp:236] Iteration 17030, loss = 0.598212
I0729 08:37:17.572587 118397 solver.cpp:252]     Train net output #0: loss = 0.636249 (* 1 = 0.636249 loss)
I0729 08:37:17.572610 118397 sgd_solver.cpp:106] Iteration 17030, lr = 0.00729
I0729 08:37:55.054244 118397 solver.cpp:236] Iteration 17040, loss = 0.614704
I0729 08:37:55.054401 118397 solver.cpp:252]     Train net output #0: loss = 0.639216 (* 1 = 0.639216 loss)
I0729 08:37:55.054419 118397 sgd_solver.cpp:106] Iteration 17040, lr = 0.00729
I0729 08:38:39.982038 118397 solver.cpp:236] Iteration 17050, loss = 0.614772
I0729 08:38:39.982183 118397 solver.cpp:252]     Train net output #0: loss = 0.635915 (* 1 = 0.635915 loss)
I0729 08:38:39.982204 118397 sgd_solver.cpp:106] Iteration 17050, lr = 0.00729
I0729 08:39:18.251915 118397 solver.cpp:236] Iteration 17060, loss = 0.615474
I0729 08:39:18.252068 118397 solver.cpp:252]     Train net output #0: loss = 0.636612 (* 1 = 0.636612 loss)
I0729 08:39:18.252089 118397 sgd_solver.cpp:106] Iteration 17060, lr = 0.00729
I0729 08:39:56.438477 118397 solver.cpp:236] Iteration 17070, loss = 0.6136
I0729 08:39:56.438683 118397 solver.cpp:252]     Train net output #0: loss = 0.642157 (* 1 = 0.642157 loss)
I0729 08:39:56.438724 118397 sgd_solver.cpp:106] Iteration 17070, lr = 0.00729
I0729 08:40:36.177131 118397 solver.cpp:236] Iteration 17080, loss = 0.611494
I0729 08:40:36.177331 118397 solver.cpp:252]     Train net output #0: loss = 0.401064 (* 1 = 0.401064 loss)
I0729 08:40:36.177384 118397 sgd_solver.cpp:106] Iteration 17080, lr = 0.00729
I0729 08:41:17.862519 118397 solver.cpp:236] Iteration 17090, loss = 0.611586
I0729 08:41:17.862740 118397 solver.cpp:252]     Train net output #0: loss = 0.652757 (* 1 = 0.652757 loss)
I0729 08:41:17.862766 118397 sgd_solver.cpp:106] Iteration 17090, lr = 0.00729
I0729 08:41:54.314469 118397 solver.cpp:236] Iteration 17100, loss = 0.612719
I0729 08:41:54.314625 118397 solver.cpp:252]     Train net output #0: loss = 0.419278 (* 1 = 0.419278 loss)
I0729 08:41:54.314651 118397 sgd_solver.cpp:106] Iteration 17100, lr = 0.00729
I0729 08:42:33.250442 118397 solver.cpp:236] Iteration 17110, loss = 0.612989
I0729 08:42:33.250716 118397 solver.cpp:252]     Train net output #0: loss = 0.32012 (* 1 = 0.32012 loss)
I0729 08:42:33.250749 118397 sgd_solver.cpp:106] Iteration 17110, lr = 0.00729
I0729 08:43:14.371632 118397 solver.cpp:236] Iteration 17120, loss = 0.610115
I0729 08:43:14.371799 118397 solver.cpp:252]     Train net output #0: loss = 0.642034 (* 1 = 0.642034 loss)
I0729 08:43:14.371842 118397 sgd_solver.cpp:106] Iteration 17120, lr = 0.00729
I0729 08:43:52.430685 118397 solver.cpp:236] Iteration 17130, loss = 0.605547
I0729 08:43:52.430866 118397 solver.cpp:252]     Train net output #0: loss = 0.670731 (* 1 = 0.670731 loss)
I0729 08:43:52.430896 118397 sgd_solver.cpp:106] Iteration 17130, lr = 0.00729
I0729 08:44:39.804549 118397 solver.cpp:236] Iteration 17140, loss = 0.603142
I0729 08:44:39.804733 118397 solver.cpp:252]     Train net output #0: loss = 0.637828 (* 1 = 0.637828 loss)
I0729 08:44:39.804771 118397 sgd_solver.cpp:106] Iteration 17140, lr = 0.00729
I0729 08:45:12.421293 118397 solver.cpp:236] Iteration 17150, loss = 0.600752
I0729 08:45:12.421494 118397 solver.cpp:252]     Train net output #0: loss = 0.637415 (* 1 = 0.637415 loss)
I0729 08:45:12.421520 118397 sgd_solver.cpp:106] Iteration 17150, lr = 0.00729
I0729 08:45:57.565112 118397 solver.cpp:236] Iteration 17160, loss = 0.602632
I0729 08:45:57.565274 118397 solver.cpp:252]     Train net output #0: loss = 0.632674 (* 1 = 0.632674 loss)
I0729 08:45:57.565307 118397 sgd_solver.cpp:106] Iteration 17160, lr = 0.00729
I0729 08:46:29.569845 118397 solver.cpp:236] Iteration 17170, loss = 0.602104
I0729 08:46:29.570001 118397 solver.cpp:252]     Train net output #0: loss = 0.41268 (* 1 = 0.41268 loss)
I0729 08:46:29.570022 118397 sgd_solver.cpp:106] Iteration 17170, lr = 0.00729
I0729 08:47:03.647315 118397 solver.cpp:236] Iteration 17180, loss = 0.606585
I0729 08:47:03.647496 118397 solver.cpp:252]     Train net output #0: loss = 0.63847 (* 1 = 0.63847 loss)
I0729 08:47:03.647523 118397 sgd_solver.cpp:106] Iteration 17180, lr = 0.00729
I0729 08:47:41.392845 118397 solver.cpp:236] Iteration 17190, loss = 0.604168
I0729 08:47:41.392992 118397 solver.cpp:252]     Train net output #0: loss = 0.637559 (* 1 = 0.637559 loss)
I0729 08:47:41.393010 118397 sgd_solver.cpp:106] Iteration 17190, lr = 0.00729
I0729 08:48:20.731534 118397 solver.cpp:236] Iteration 17200, loss = 0.608931
I0729 08:48:20.731755 118397 solver.cpp:252]     Train net output #0: loss = 0.635224 (* 1 = 0.635224 loss)
I0729 08:48:20.731778 118397 sgd_solver.cpp:106] Iteration 17200, lr = 0.00729
I0729 08:48:59.398227 118397 solver.cpp:236] Iteration 17210, loss = 0.611862
I0729 08:48:59.398442 118397 solver.cpp:252]     Train net output #0: loss = 0.63651 (* 1 = 0.63651 loss)
I0729 08:48:59.398460 118397 sgd_solver.cpp:106] Iteration 17210, lr = 0.00729
I0729 08:49:36.881058 118397 solver.cpp:236] Iteration 17220, loss = 0.608619
I0729 08:49:36.881237 118397 solver.cpp:252]     Train net output #0: loss = 0.646268 (* 1 = 0.646268 loss)
I0729 08:49:36.881254 118397 sgd_solver.cpp:106] Iteration 17220, lr = 0.00729
I0729 08:50:15.939646 118397 solver.cpp:236] Iteration 17230, loss = 0.617331
I0729 08:50:15.939847 118397 solver.cpp:252]     Train net output #0: loss = 0.636478 (* 1 = 0.636478 loss)
I0729 08:50:15.939867 118397 sgd_solver.cpp:106] Iteration 17230, lr = 0.00729
I0729 08:50:49.799022 118397 solver.cpp:236] Iteration 17240, loss = 0.614333
I0729 08:50:49.799162 118397 solver.cpp:252]     Train net output #0: loss = 0.645865 (* 1 = 0.645865 loss)
I0729 08:50:49.799181 118397 sgd_solver.cpp:106] Iteration 17240, lr = 0.00729
I0729 08:51:23.629436 118397 solver.cpp:236] Iteration 17250, loss = 0.616907
I0729 08:51:23.629619 118397 solver.cpp:252]     Train net output #0: loss = 0.63216 (* 1 = 0.63216 loss)
I0729 08:51:23.629654 118397 sgd_solver.cpp:106] Iteration 17250, lr = 0.00729
I0729 08:52:03.578330 118397 solver.cpp:236] Iteration 17260, loss = 0.616792
I0729 08:52:03.578580 118397 solver.cpp:252]     Train net output #0: loss = 0.63367 (* 1 = 0.63367 loss)
I0729 08:52:03.578598 118397 sgd_solver.cpp:106] Iteration 17260, lr = 0.00729
I0729 08:52:40.047539 118397 solver.cpp:236] Iteration 17270, loss = 0.611815
I0729 08:52:40.047679 118397 solver.cpp:252]     Train net output #0: loss = 0.662176 (* 1 = 0.662176 loss)
I0729 08:52:40.047699 118397 sgd_solver.cpp:106] Iteration 17270, lr = 0.00729
I0729 08:53:20.200669 118397 solver.cpp:236] Iteration 17280, loss = 0.602995
I0729 08:53:20.200786 118397 solver.cpp:252]     Train net output #0: loss = 0.27028 (* 1 = 0.27028 loss)
I0729 08:53:20.200804 118397 sgd_solver.cpp:106] Iteration 17280, lr = 0.00729
I0729 08:53:51.928750 118397 solver.cpp:236] Iteration 17290, loss = 0.602734
I0729 08:53:51.928899 118397 solver.cpp:252]     Train net output #0: loss = 0.663575 (* 1 = 0.663575 loss)
I0729 08:53:51.928916 118397 sgd_solver.cpp:106] Iteration 17290, lr = 0.00729
I0729 08:54:25.303771 118397 solver.cpp:236] Iteration 17300, loss = 0.593093
I0729 08:54:25.303956 118397 solver.cpp:252]     Train net output #0: loss = 0.293428 (* 1 = 0.293428 loss)
I0729 08:54:25.303977 118397 sgd_solver.cpp:106] Iteration 17300, lr = 0.00729
I0729 08:55:01.585449 118397 solver.cpp:236] Iteration 17310, loss = 0.589859
I0729 08:55:01.585610 118397 solver.cpp:252]     Train net output #0: loss = 0.639002 (* 1 = 0.639002 loss)
I0729 08:55:01.585629 118397 sgd_solver.cpp:106] Iteration 17310, lr = 0.00729
I0729 08:55:39.562235 118397 solver.cpp:236] Iteration 17320, loss = 0.593128
I0729 08:55:39.562465 118397 solver.cpp:252]     Train net output #0: loss = 0.391771 (* 1 = 0.391771 loss)
I0729 08:55:39.562503 118397 sgd_solver.cpp:106] Iteration 17320, lr = 0.00729
I0729 08:56:14.680156 118397 solver.cpp:236] Iteration 17330, loss = 0.58405
I0729 08:56:14.680413 118397 solver.cpp:252]     Train net output #0: loss = 0.273262 (* 1 = 0.273262 loss)
I0729 08:56:14.680434 118397 sgd_solver.cpp:106] Iteration 17330, lr = 0.00729
I0729 08:56:50.311435 118397 solver.cpp:236] Iteration 17340, loss = 0.584162
I0729 08:56:50.311662 118397 solver.cpp:252]     Train net output #0: loss = 0.679319 (* 1 = 0.679319 loss)
I0729 08:56:50.311681 118397 sgd_solver.cpp:106] Iteration 17340, lr = 0.00729
I0729 08:57:22.655987 118397 solver.cpp:236] Iteration 17350, loss = 0.582303
I0729 08:57:22.656129 118397 solver.cpp:252]     Train net output #0: loss = 0.629311 (* 1 = 0.629311 loss)
I0729 08:57:22.656155 118397 sgd_solver.cpp:106] Iteration 17350, lr = 0.00729
I0729 08:58:02.129995 118397 solver.cpp:236] Iteration 17360, loss = 0.580218
I0729 08:58:02.130269 118397 solver.cpp:252]     Train net output #0: loss = 0.638265 (* 1 = 0.638265 loss)
I0729 08:58:02.130286 118397 sgd_solver.cpp:106] Iteration 17360, lr = 0.00729
I0729 08:58:33.738623 118397 solver.cpp:236] Iteration 17370, loss = 0.578656
I0729 08:58:33.738900 118397 solver.cpp:252]     Train net output #0: loss = 0.659191 (* 1 = 0.659191 loss)
I0729 08:58:33.738919 118397 sgd_solver.cpp:106] Iteration 17370, lr = 0.00729
I0729 08:59:14.488909 118397 solver.cpp:236] Iteration 17380, loss = 0.586061
I0729 08:59:14.489050 118397 solver.cpp:252]     Train net output #0: loss = 0.650601 (* 1 = 0.650601 loss)
I0729 08:59:14.489068 118397 sgd_solver.cpp:106] Iteration 17380, lr = 0.00729
I0729 08:59:47.563488 118397 solver.cpp:236] Iteration 17390, loss = 0.591464
I0729 08:59:47.563675 118397 solver.cpp:252]     Train net output #0: loss = 0.642866 (* 1 = 0.642866 loss)
I0729 08:59:47.563704 118397 sgd_solver.cpp:106] Iteration 17390, lr = 0.00729
I0729 09:00:19.168689 118397 solver.cpp:236] Iteration 17400, loss = 0.593771
I0729 09:00:19.168891 118397 solver.cpp:252]     Train net output #0: loss = 0.361521 (* 1 = 0.361521 loss)
I0729 09:00:19.168917 118397 sgd_solver.cpp:106] Iteration 17400, lr = 0.00729
I0729 09:00:52.249644 118397 solver.cpp:236] Iteration 17410, loss = 0.591362
I0729 09:00:52.249806 118397 solver.cpp:252]     Train net output #0: loss = 0.724841 (* 1 = 0.724841 loss)
I0729 09:00:52.249832 118397 sgd_solver.cpp:106] Iteration 17410, lr = 0.00729
I0729 09:01:28.263380 118397 solver.cpp:236] Iteration 17420, loss = 0.594091
I0729 09:01:28.263581 118397 solver.cpp:252]     Train net output #0: loss = 0.651488 (* 1 = 0.651488 loss)
I0729 09:01:28.263604 118397 sgd_solver.cpp:106] Iteration 17420, lr = 0.00729
I0729 09:02:06.168642 118397 solver.cpp:236] Iteration 17430, loss = 0.603168
I0729 09:02:06.168823 118397 solver.cpp:252]     Train net output #0: loss = 0.642527 (* 1 = 0.642527 loss)
I0729 09:02:06.168846 118397 sgd_solver.cpp:106] Iteration 17430, lr = 0.00729
I0729 09:02:41.974910 118397 solver.cpp:236] Iteration 17440, loss = 0.606346
I0729 09:02:41.975106 118397 solver.cpp:252]     Train net output #0: loss = 0.634807 (* 1 = 0.634807 loss)
I0729 09:02:41.975132 118397 sgd_solver.cpp:106] Iteration 17440, lr = 0.00729
I0729 09:03:14.280607 118397 solver.cpp:236] Iteration 17450, loss = 0.602986
I0729 09:03:14.280767 118397 solver.cpp:252]     Train net output #0: loss = 0.278388 (* 1 = 0.278388 loss)
I0729 09:03:14.280796 118397 sgd_solver.cpp:106] Iteration 17450, lr = 0.00729
I0729 09:03:48.601454 118397 solver.cpp:236] Iteration 17460, loss = 0.600311
I0729 09:03:48.601619 118397 solver.cpp:252]     Train net output #0: loss = 0.646044 (* 1 = 0.646044 loss)
I0729 09:03:48.601640 118397 sgd_solver.cpp:106] Iteration 17460, lr = 0.00729
I0729 09:04:26.262145 118397 solver.cpp:236] Iteration 17470, loss = 0.60993
I0729 09:04:26.262298 118397 solver.cpp:252]     Train net output #0: loss = 0.639153 (* 1 = 0.639153 loss)
I0729 09:04:26.262317 118397 sgd_solver.cpp:106] Iteration 17470, lr = 0.00729
I0729 09:05:05.312072 118397 solver.cpp:236] Iteration 17480, loss = 0.603342
I0729 09:05:05.312332 118397 solver.cpp:252]     Train net output #0: loss = 0.330182 (* 1 = 0.330182 loss)
I0729 09:05:05.312350 118397 sgd_solver.cpp:106] Iteration 17480, lr = 0.00729
I0729 09:05:37.597617 118397 solver.cpp:236] Iteration 17490, loss = 0.597342
I0729 09:05:37.597786 118397 solver.cpp:252]     Train net output #0: loss = 0.651997 (* 1 = 0.651997 loss)
I0729 09:05:37.597812 118397 sgd_solver.cpp:106] Iteration 17490, lr = 0.00729
I0729 09:06:03.333560 118397 solver.cpp:340] Iteration 17500, Testing net (#0)
I0729 09:06:41.673447 118397 solver.cpp:408]     Test net output #0: accuracy = 0.671875
I0729 09:06:41.673656 118397 solver.cpp:408]     Test net output #1: loss = 0.664356 (* 1 = 0.664356 loss)
I0729 09:06:44.749420 118397 solver.cpp:236] Iteration 17500, loss = 0.59505
I0729 09:06:44.749495 118397 solver.cpp:252]     Train net output #0: loss = 0.661195 (* 1 = 0.661195 loss)
I0729 09:06:44.749511 118397 sgd_solver.cpp:106] Iteration 17500, lr = 0.00729
I0729 09:07:15.530433 118397 solver.cpp:236] Iteration 17510, loss = 0.60126
I0729 09:07:15.530575 118397 solver.cpp:252]     Train net output #0: loss = 0.646172 (* 1 = 0.646172 loss)
I0729 09:07:15.530591 118397 sgd_solver.cpp:106] Iteration 17510, lr = 0.00729
I0729 09:07:52.652240 118397 solver.cpp:236] Iteration 17520, loss = 0.600899
I0729 09:07:52.652393 118397 solver.cpp:252]     Train net output #0: loss = 0.635938 (* 1 = 0.635938 loss)
I0729 09:07:52.652412 118397 sgd_solver.cpp:106] Iteration 17520, lr = 0.00729
I0729 09:08:28.454092 118397 solver.cpp:236] Iteration 17530, loss = 0.593553
I0729 09:08:28.454236 118397 solver.cpp:252]     Train net output #0: loss = 0.648028 (* 1 = 0.648028 loss)
I0729 09:08:28.454253 118397 sgd_solver.cpp:106] Iteration 17530, lr = 0.00729
I0729 09:09:02.375826 118397 solver.cpp:236] Iteration 17540, loss = 0.592944
I0729 09:09:02.375991 118397 solver.cpp:252]     Train net output #0: loss = 0.650284 (* 1 = 0.650284 loss)
I0729 09:09:02.376009 118397 sgd_solver.cpp:106] Iteration 17540, lr = 0.00729
I0729 09:09:39.520859 118397 solver.cpp:236] Iteration 17550, loss = 0.592234
I0729 09:09:39.521029 118397 solver.cpp:252]     Train net output #0: loss = 0.647488 (* 1 = 0.647488 loss)
I0729 09:09:39.521051 118397 sgd_solver.cpp:106] Iteration 17550, lr = 0.00729
I0729 09:10:12.597313 118397 solver.cpp:236] Iteration 17560, loss = 0.594282
I0729 09:10:12.597501 118397 solver.cpp:252]     Train net output #0: loss = 0.632509 (* 1 = 0.632509 loss)
I0729 09:10:12.597520 118397 sgd_solver.cpp:106] Iteration 17560, lr = 0.00729
I0729 09:10:50.038724 118397 solver.cpp:236] Iteration 17570, loss = 0.593395
I0729 09:10:50.042696 118397 solver.cpp:252]     Train net output #0: loss = 0.630923 (* 1 = 0.630923 loss)
I0729 09:10:50.042716 118397 sgd_solver.cpp:106] Iteration 17570, lr = 0.00729
I0729 09:11:21.642833 118397 solver.cpp:236] Iteration 17580, loss = 0.596852
I0729 09:11:21.643000 118397 solver.cpp:252]     Train net output #0: loss = 0.639746 (* 1 = 0.639746 loss)
I0729 09:11:21.643031 118397 sgd_solver.cpp:106] Iteration 17580, lr = 0.00729
I0729 09:11:54.428113 118397 solver.cpp:236] Iteration 17590, loss = 0.597016
I0729 09:11:54.428409 118397 solver.cpp:252]     Train net output #0: loss = 0.65442 (* 1 = 0.65442 loss)
I0729 09:11:54.428434 118397 sgd_solver.cpp:106] Iteration 17590, lr = 0.00729
I0729 09:12:28.105195 118397 solver.cpp:236] Iteration 17600, loss = 0.604389
I0729 09:12:28.105329 118397 solver.cpp:252]     Train net output #0: loss = 0.636075 (* 1 = 0.636075 loss)
I0729 09:12:28.105346 118397 sgd_solver.cpp:106] Iteration 17600, lr = 0.00729
I0729 09:13:02.511265 118397 solver.cpp:236] Iteration 17610, loss = 0.600758
I0729 09:13:02.511415 118397 solver.cpp:252]     Train net output #0: loss = 0.644436 (* 1 = 0.644436 loss)
I0729 09:13:02.511432 118397 sgd_solver.cpp:106] Iteration 17610, lr = 0.00729
I0729 09:13:40.030524 118397 solver.cpp:236] Iteration 17620, loss = 0.598602
I0729 09:13:40.030712 118397 solver.cpp:252]     Train net output #0: loss = 0.646061 (* 1 = 0.646061 loss)
I0729 09:13:40.030736 118397 sgd_solver.cpp:106] Iteration 17620, lr = 0.00729
I0729 09:14:06.947918 118397 solver.cpp:236] Iteration 17630, loss = 0.602808
I0729 09:14:06.948001 118397 solver.cpp:252]     Train net output #0: loss = 0.63247 (* 1 = 0.63247 loss)
I0729 09:14:06.948024 118397 sgd_solver.cpp:106] Iteration 17630, lr = 0.00729
I0729 09:14:36.850905 118397 solver.cpp:236] Iteration 17640, loss = 0.602154
I0729 09:14:36.851130 118397 solver.cpp:252]     Train net output #0: loss = 0.633713 (* 1 = 0.633713 loss)
I0729 09:14:36.851162 118397 sgd_solver.cpp:106] Iteration 17640, lr = 0.00729
I0729 09:15:12.534642 118397 solver.cpp:236] Iteration 17650, loss = 0.599342
I0729 09:15:12.534889 118397 solver.cpp:252]     Train net output #0: loss = 0.316144 (* 1 = 0.316144 loss)
I0729 09:15:12.534909 118397 sgd_solver.cpp:106] Iteration 17650, lr = 0.00729
I0729 09:15:45.333778 118397 solver.cpp:236] Iteration 17660, loss = 0.603974
I0729 09:15:45.333962 118397 solver.cpp:252]     Train net output #0: loss = 0.648983 (* 1 = 0.648983 loss)
I0729 09:15:45.333999 118397 sgd_solver.cpp:106] Iteration 17660, lr = 0.00729
I0729 09:16:26.474108 118397 solver.cpp:236] Iteration 17670, loss = 0.604285
I0729 09:16:26.474251 118397 solver.cpp:252]     Train net output #0: loss = 0.63812 (* 1 = 0.63812 loss)
I0729 09:16:26.474269 118397 sgd_solver.cpp:106] Iteration 17670, lr = 0.00729
I0729 09:16:56.999080 118397 solver.cpp:236] Iteration 17680, loss = 0.60524
I0729 09:16:56.999321 118397 solver.cpp:252]     Train net output #0: loss = 0.644517 (* 1 = 0.644517 loss)
I0729 09:16:56.999341 118397 sgd_solver.cpp:106] Iteration 17680, lr = 0.00729
I0729 09:17:28.794976 118397 solver.cpp:236] Iteration 17690, loss = 0.608674
I0729 09:17:28.795142 118397 solver.cpp:252]     Train net output #0: loss = 0.64187 (* 1 = 0.64187 loss)
I0729 09:17:28.795182 118397 sgd_solver.cpp:106] Iteration 17690, lr = 0.00729
I0729 09:18:00.472607 118397 solver.cpp:236] Iteration 17700, loss = 0.607586
I0729 09:18:00.472755 118397 solver.cpp:252]     Train net output #0: loss = 0.635072 (* 1 = 0.635072 loss)
I0729 09:18:00.472793 118397 sgd_solver.cpp:106] Iteration 17700, lr = 0.00729
I0729 09:18:28.809597 118397 solver.cpp:236] Iteration 17710, loss = 0.610852
I0729 09:18:28.809686 118397 solver.cpp:252]     Train net output #0: loss = 0.634954 (* 1 = 0.634954 loss)
I0729 09:18:28.809708 118397 sgd_solver.cpp:106] Iteration 17710, lr = 0.00729
I0729 09:19:00.861840 118397 solver.cpp:236] Iteration 17720, loss = 0.610789
I0729 09:19:00.862011 118397 solver.cpp:252]     Train net output #0: loss = 0.64822 (* 1 = 0.64822 loss)
I0729 09:19:00.862037 118397 sgd_solver.cpp:106] Iteration 17720, lr = 0.00729
I0729 09:19:34.899021 118397 solver.cpp:236] Iteration 17730, loss = 0.611326
I0729 09:19:34.899164 118397 solver.cpp:252]     Train net output #0: loss = 0.633514 (* 1 = 0.633514 loss)
I0729 09:19:34.899181 118397 sgd_solver.cpp:106] Iteration 17730, lr = 0.00729
I0729 09:20:01.822060 118397 solver.cpp:236] Iteration 17740, loss = 0.611324
I0729 09:20:01.822139 118397 solver.cpp:252]     Train net output #0: loss = 0.637264 (* 1 = 0.637264 loss)
I0729 09:20:01.822159 118397 sgd_solver.cpp:106] Iteration 17740, lr = 0.00729
I0729 09:20:30.987972 118397 solver.cpp:236] Iteration 17750, loss = 0.617231
I0729 09:20:30.988214 118397 solver.cpp:252]     Train net output #0: loss = 0.639495 (* 1 = 0.639495 loss)
I0729 09:20:30.988232 118397 sgd_solver.cpp:106] Iteration 17750, lr = 0.00729
I0729 09:21:02.381070 118397 solver.cpp:236] Iteration 17760, loss = 0.615837
I0729 09:21:02.381222 118397 solver.cpp:252]     Train net output #0: loss = 0.638594 (* 1 = 0.638594 loss)
I0729 09:21:02.381247 118397 sgd_solver.cpp:106] Iteration 17760, lr = 0.00729
I0729 09:21:37.328919 118397 solver.cpp:236] Iteration 17770, loss = 0.615569
I0729 09:21:37.329150 118397 solver.cpp:252]     Train net output #0: loss = 0.63748 (* 1 = 0.63748 loss)
I0729 09:21:37.329186 118397 sgd_solver.cpp:106] Iteration 17770, lr = 0.00729
I0729 09:22:14.977805 118397 solver.cpp:236] Iteration 17780, loss = 0.619122
I0729 09:22:14.990701 118397 solver.cpp:252]     Train net output #0: loss = 0.63026 (* 1 = 0.63026 loss)
I0729 09:22:14.990718 118397 sgd_solver.cpp:106] Iteration 17780, lr = 0.00729
I0729 09:22:43.514454 118397 solver.cpp:236] Iteration 17790, loss = 0.613012
I0729 09:22:43.514528 118397 solver.cpp:252]     Train net output #0: loss = 0.278607 (* 1 = 0.278607 loss)
I0729 09:22:43.514544 118397 sgd_solver.cpp:106] Iteration 17790, lr = 0.00729
I0729 09:23:14.254667 118397 solver.cpp:236] Iteration 17800, loss = 0.611855
I0729 09:23:14.254947 118397 solver.cpp:252]     Train net output #0: loss = 0.670166 (* 1 = 0.670166 loss)
I0729 09:23:14.254966 118397 sgd_solver.cpp:106] Iteration 17800, lr = 0.00729
I0729 09:23:47.068856 118397 solver.cpp:236] Iteration 17810, loss = 0.609247
I0729 09:23:47.069150 118397 solver.cpp:252]     Train net output #0: loss = 0.370513 (* 1 = 0.370513 loss)
I0729 09:23:47.069183 118397 sgd_solver.cpp:106] Iteration 17810, lr = 0.00729
I0729 09:24:13.898264 118397 solver.cpp:236] Iteration 17820, loss = 0.609012
I0729 09:24:13.898352 118397 solver.cpp:252]     Train net output #0: loss = 0.642646 (* 1 = 0.642646 loss)
I0729 09:24:13.898377 118397 sgd_solver.cpp:106] Iteration 17820, lr = 0.00729
I0729 09:24:42.986387 118397 solver.cpp:236] Iteration 17830, loss = 0.609202
I0729 09:24:42.986558 118397 solver.cpp:252]     Train net output #0: loss = 0.633592 (* 1 = 0.633592 loss)
I0729 09:24:42.986577 118397 sgd_solver.cpp:106] Iteration 17830, lr = 0.00729
I0729 09:25:10.490111 118397 solver.cpp:236] Iteration 17840, loss = 0.609239
I0729 09:25:10.490181 118397 solver.cpp:252]     Train net output #0: loss = 0.637513 (* 1 = 0.637513 loss)
I0729 09:25:10.490198 118397 sgd_solver.cpp:106] Iteration 17840, lr = 0.00729
I0729 09:25:43.242461 118397 solver.cpp:236] Iteration 17850, loss = 0.612027
I0729 09:25:43.242594 118397 solver.cpp:252]     Train net output #0: loss = 0.63714 (* 1 = 0.63714 loss)
I0729 09:25:43.242612 118397 sgd_solver.cpp:106] Iteration 17850, lr = 0.00729
I0729 09:26:12.221374 118397 solver.cpp:236] Iteration 17860, loss = 0.60931
I0729 09:26:12.221444 118397 solver.cpp:252]     Train net output #0: loss = 0.635877 (* 1 = 0.635877 loss)
I0729 09:26:12.221467 118397 sgd_solver.cpp:106] Iteration 17860, lr = 0.00729
I0729 09:26:43.281518 118397 solver.cpp:236] Iteration 17870, loss = 0.604369
I0729 09:26:43.281829 118397 solver.cpp:252]     Train net output #0: loss = 0.372185 (* 1 = 0.372185 loss)
I0729 09:26:43.281848 118397 sgd_solver.cpp:106] Iteration 17870, lr = 0.00729
I0729 09:27:12.457692 118397 solver.cpp:236] Iteration 17880, loss = 0.602983
I0729 09:27:12.457767 118397 solver.cpp:252]     Train net output #0: loss = 0.653177 (* 1 = 0.653177 loss)
I0729 09:27:12.457784 118397 sgd_solver.cpp:106] Iteration 17880, lr = 0.00729
I0729 09:27:42.386180 118397 solver.cpp:236] Iteration 17890, loss = 0.601822
I0729 09:27:42.386411 118397 solver.cpp:252]     Train net output #0: loss = 0.654474 (* 1 = 0.654474 loss)
I0729 09:27:42.386430 118397 sgd_solver.cpp:106] Iteration 17890, lr = 0.00729
I0729 09:28:18.368026 118397 solver.cpp:236] Iteration 17900, loss = 0.600193
I0729 09:28:18.368252 118397 solver.cpp:252]     Train net output #0: loss = 0.645851 (* 1 = 0.645851 loss)
I0729 09:28:18.368288 118397 sgd_solver.cpp:106] Iteration 17900, lr = 0.00729
I0729 09:28:51.744366 118397 solver.cpp:236] Iteration 17910, loss = 0.602511
I0729 09:28:51.744611 118397 solver.cpp:252]     Train net output #0: loss = 0.63484 (* 1 = 0.63484 loss)
I0729 09:28:51.744634 118397 sgd_solver.cpp:106] Iteration 17910, lr = 0.00729
I0729 09:29:20.839383 118397 solver.cpp:236] Iteration 17920, loss = 0.604896
I0729 09:29:20.839455 118397 solver.cpp:252]     Train net output #0: loss = 0.63836 (* 1 = 0.63836 loss)
I0729 09:29:20.839471 118397 sgd_solver.cpp:106] Iteration 17920, lr = 0.00729
I0729 09:29:49.229377 118397 solver.cpp:236] Iteration 17930, loss = 0.602167
I0729 09:29:49.229538 118397 solver.cpp:252]     Train net output #0: loss = 0.637923 (* 1 = 0.637923 loss)
I0729 09:29:49.229555 118397 sgd_solver.cpp:106] Iteration 17930, lr = 0.00729
I0729 09:30:17.457551 118397 solver.cpp:236] Iteration 17940, loss = 0.599458
I0729 09:30:17.457620 118397 solver.cpp:252]     Train net output #0: loss = 0.665319 (* 1 = 0.665319 loss)
I0729 09:30:17.457638 118397 sgd_solver.cpp:106] Iteration 17940, lr = 0.00729
I0729 09:30:47.945119 118397 solver.cpp:236] Iteration 17950, loss = 0.600462
I0729 09:30:47.945348 118397 solver.cpp:252]     Train net output #0: loss = 0.633878 (* 1 = 0.633878 loss)
I0729 09:30:47.945369 118397 sgd_solver.cpp:106] Iteration 17950, lr = 0.00729
I0729 09:31:19.167263 118397 solver.cpp:236] Iteration 17960, loss = 0.600621
I0729 09:31:19.167469 118397 solver.cpp:252]     Train net output #0: loss = 0.632586 (* 1 = 0.632586 loss)
I0729 09:31:19.167493 118397 sgd_solver.cpp:106] Iteration 17960, lr = 0.00729
I0729 09:31:50.349840 118397 solver.cpp:236] Iteration 17970, loss = 0.605519
I0729 09:31:50.350044 118397 solver.cpp:252]     Train net output #0: loss = 0.632974 (* 1 = 0.632974 loss)
I0729 09:31:50.350078 118397 sgd_solver.cpp:106] Iteration 17970, lr = 0.00729
I0729 09:32:22.010710 118397 solver.cpp:236] Iteration 17980, loss = 0.606756
I0729 09:32:22.010968 118397 solver.cpp:252]     Train net output #0: loss = 0.632603 (* 1 = 0.632603 loss)
I0729 09:32:22.010988 118397 sgd_solver.cpp:106] Iteration 17980, lr = 0.00729
I0729 09:32:53.021354 118397 solver.cpp:236] Iteration 17990, loss = 0.615982
I0729 09:32:53.021580 118397 solver.cpp:252]     Train net output #0: loss = 0.630582 (* 1 = 0.630582 loss)
I0729 09:32:53.021610 118397 sgd_solver.cpp:106] Iteration 17990, lr = 0.00729
I0729 09:33:17.412040 118397 solver.cpp:461] Snapshotting to binary proto file models/fnet_iter_18000.caffemodel
I0729 09:33:17.505839 118397 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/fnet_iter_18000.solverstate
I0729 09:33:17.509387 118397 solver.cpp:340] Iteration 18000, Testing net (#0)
I0729 09:33:45.412364 118397 solver.cpp:408]     Test net output #0: accuracy = 0.7375
I0729 09:33:45.412564 118397 solver.cpp:408]     Test net output #1: loss = 0.578578 (* 1 = 0.578578 loss)
I0729 09:33:48.421140 118397 solver.cpp:236] Iteration 18000, loss = 0.613645
I0729 09:33:48.421213 118397 solver.cpp:252]     Train net output #0: loss = 0.656825 (* 1 = 0.656825 loss)
I0729 09:33:48.421231 118397 sgd_solver.cpp:106] Iteration 18000, lr = 0.00729
I0729 09:34:18.078650 118397 solver.cpp:236] Iteration 18010, loss = 0.614685
I0729 09:34:18.078830 118397 solver.cpp:252]     Train net output #0: loss = 0.64911 (* 1 = 0.64911 loss)
I0729 09:34:18.078850 118397 sgd_solver.cpp:106] Iteration 18010, lr = 0.00729
I0729 09:34:46.785543 118397 solver.cpp:236] Iteration 18020, loss = 0.608583
I0729 09:34:46.785632 118397 solver.cpp:252]     Train net output #0: loss = 0.642648 (* 1 = 0.642648 loss)
I0729 09:34:46.785650 118397 sgd_solver.cpp:106] Iteration 18020, lr = 0.00729
I0729 09:35:16.009816 118397 solver.cpp:236] Iteration 18030, loss = 0.606112
I0729 09:35:16.009964 118397 solver.cpp:252]     Train net output #0: loss = 0.641689 (* 1 = 0.641689 loss)
I0729 09:35:16.009984 118397 sgd_solver.cpp:106] Iteration 18030, lr = 0.00729
I0729 09:35:50.257773 118397 solver.cpp:236] Iteration 18040, loss = 0.609172
I0729 09:35:50.257943 118397 solver.cpp:252]     Train net output #0: loss = 0.64416 (* 1 = 0.64416 loss)
I0729 09:35:50.257982 118397 sgd_solver.cpp:106] Iteration 18040, lr = 0.00729
I0729 09:36:18.630309 118397 solver.cpp:236] Iteration 18050, loss = 0.605874
I0729 09:36:18.630385 118397 solver.cpp:252]     Train net output #0: loss = 0.633773 (* 1 = 0.633773 loss)
I0729 09:36:18.630401 118397 sgd_solver.cpp:106] Iteration 18050, lr = 0.00729
I0729 09:36:47.272081 118397 solver.cpp:236] Iteration 18060, loss = 0.60539
I0729 09:36:47.272259 118397 solver.cpp:252]     Train net output #0: loss = 0.633734 (* 1 = 0.633734 loss)
I0729 09:36:47.272277 118397 sgd_solver.cpp:106] Iteration 18060, lr = 0.00729
I0729 09:37:16.901549 118397 solver.cpp:236] Iteration 18070, loss = 0.602821
I0729 09:37:16.901623 118397 solver.cpp:252]     Train net output #0: loss = 0.641689 (* 1 = 0.641689 loss)
I0729 09:37:16.901646 118397 sgd_solver.cpp:106] Iteration 18070, lr = 0.00729
I0729 09:37:48.899189 118397 solver.cpp:236] Iteration 18080, loss = 0.600423
I0729 09:37:48.899382 118397 solver.cpp:252]     Train net output #0: loss = 0.639689 (* 1 = 0.639689 loss)
I0729 09:37:48.899406 118397 sgd_solver.cpp:106] Iteration 18080, lr = 0.00729
I0729 09:38:14.585280 118397 solver.cpp:236] Iteration 18090, loss = 0.591881
I0729 09:38:14.585362 118397 solver.cpp:252]     Train net output #0: loss = 0.66173 (* 1 = 0.66173 loss)
I0729 09:38:14.585381 118397 sgd_solver.cpp:106] Iteration 18090, lr = 0.00729
I0729 09:38:44.439050 118397 solver.cpp:236] Iteration 18100, loss = 0.601549
I0729 09:38:44.439226 118397 solver.cpp:252]     Train net output #0: loss = 0.641887 (* 1 = 0.641887 loss)
I0729 09:38:44.439246 118397 sgd_solver.cpp:106] Iteration 18100, lr = 0.00729
I0729 09:39:17.326411 118397 solver.cpp:236] Iteration 18110, loss = 0.603062
I0729 09:39:17.326591 118397 solver.cpp:252]     Train net output #0: loss = 0.639617 (* 1 = 0.639617 loss)
I0729 09:39:17.326618 118397 sgd_solver.cpp:106] Iteration 18110, lr = 0.00729
I0729 09:39:44.705826 118397 solver.cpp:236] Iteration 18120, loss = 0.606987
I0729 09:39:44.705916 118397 solver.cpp:252]     Train net output #0: loss = 0.637923 (* 1 = 0.637923 loss)
I0729 09:39:44.705932 118397 sgd_solver.cpp:106] Iteration 18120, lr = 0.00729
I0729 09:40:12.056043 118397 solver.cpp:236] Iteration 18130, loss = 0.614574
I0729 09:40:12.056186 118397 solver.cpp:252]     Train net output #0: loss = 0.637256 (* 1 = 0.637256 loss)
I0729 09:40:12.056205 118397 sgd_solver.cpp:106] Iteration 18130, lr = 0.00729
I0729 09:40:38.041332 118397 solver.cpp:236] Iteration 18140, loss = 0.611608
I0729 09:40:38.041393 118397 solver.cpp:252]     Train net output #0: loss = 0.645384 (* 1 = 0.645384 loss)
I0729 09:40:38.041410 118397 sgd_solver.cpp:106] Iteration 18140, lr = 0.00729
I0729 09:41:01.668587 118397 solver.cpp:236] Iteration 18150, loss = 0.611474
I0729 09:41:01.668740 118397 solver.cpp:252]     Train net output #0: loss = 0.632233 (* 1 = 0.632233 loss)
I0729 09:41:01.668757 118397 sgd_solver.cpp:106] Iteration 18150, lr = 0.00729
I0729 09:41:29.595314 118397 solver.cpp:236] Iteration 18160, loss = 0.611643
I0729 09:41:29.595391 118397 solver.cpp:252]     Train net output #0: loss = 0.641651 (* 1 = 0.641651 loss)
I0729 09:41:29.595407 118397 sgd_solver.cpp:106] Iteration 18160, lr = 0.00729
I0729 09:41:59.468593 118397 solver.cpp:236] Iteration 18170, loss = 0.611791
I0729 09:41:59.468895 118397 solver.cpp:252]     Train net output #0: loss = 0.635168 (* 1 = 0.635168 loss)
I0729 09:41:59.468914 118397 sgd_solver.cpp:106] Iteration 18170, lr = 0.00729
I0729 09:42:25.113895 118397 solver.cpp:236] Iteration 18180, loss = 0.6066
I0729 09:42:25.113970 118397 solver.cpp:252]     Train net output #0: loss = 0.360765 (* 1 = 0.360765 loss)
I0729 09:42:25.113984 118397 sgd_solver.cpp:106] Iteration 18180, lr = 0.00729
I0729 09:42:55.071996 118397 solver.cpp:236] Iteration 18190, loss = 0.613172
I0729 09:42:55.072227 118397 solver.cpp:252]     Train net output #0: loss = 0.655239 (* 1 = 0.655239 loss)
I0729 09:42:55.072245 118397 sgd_solver.cpp:106] Iteration 18190, lr = 0.00729
I0729 09:43:23.602804 118397 solver.cpp:236] Iteration 18200, loss = 0.612447
I0729 09:43:23.602879 118397 solver.cpp:252]     Train net output #0: loss = 0.633675 (* 1 = 0.633675 loss)
I0729 09:43:23.602896 118397 sgd_solver.cpp:106] Iteration 18200, lr = 0.00729
I0729 09:43:52.023244 118397 solver.cpp:236] Iteration 18210, loss = 0.612474
I0729 09:43:52.023468 118397 solver.cpp:252]     Train net output #0: loss = 0.633878 (* 1 = 0.633878 loss)
I0729 09:43:52.023488 118397 sgd_solver.cpp:106] Iteration 18210, lr = 0.00729
I0729 09:44:22.045580 118397 solver.cpp:236] Iteration 18220, loss = 0.612733
I0729 09:44:22.045783 118397 solver.cpp:252]     Train net output #0: loss = 0.643143 (* 1 = 0.643143 loss)
I0729 09:44:22.045800 118397 sgd_solver.cpp:106] Iteration 18220, lr = 0.00729
I0729 09:44:44.611135 118397 solver.cpp:236] Iteration 18230, loss = 0.612622
I0729 09:44:44.611238 118397 solver.cpp:252]     Train net output #0: loss = 0.636664 (* 1 = 0.636664 loss)
I0729 09:44:44.611266 118397 sgd_solver.cpp:106] Iteration 18230, lr = 0.00729
I0729 09:45:14.258195 118397 solver.cpp:236] Iteration 18240, loss = 0.613267
I0729 09:45:14.258365 118397 solver.cpp:252]     Train net output #0: loss = 0.640647 (* 1 = 0.640647 loss)
I0729 09:45:14.258384 118397 sgd_solver.cpp:106] Iteration 18240, lr = 0.00729
I0729 09:45:40.476754 118397 solver.cpp:236] Iteration 18250, loss = 0.61321
I0729 09:45:40.476826 118397 solver.cpp:252]     Train net output #0: loss = 0.647965 (* 1 = 0.647965 loss)
I0729 09:45:40.476841 118397 sgd_solver.cpp:106] Iteration 18250, lr = 0.00729
I0729 09:46:06.511397 118397 solver.cpp:236] Iteration 18260, loss = 0.613397
