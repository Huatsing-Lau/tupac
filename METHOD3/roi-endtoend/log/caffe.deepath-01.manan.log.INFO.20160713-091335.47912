Log file created at: 2016/07/13 09:13:35
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0713 09:13:35.518753 47912 caffe.cpp:184] Using GPUs 0
I0713 09:13:35.815953 47912 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 1500
base_lr: 0.025
display: 100
max_iter: 500000
lr_policy: "step"
gamma: 0.1
momentum: 0.85
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/resultlayer3"
solver_mode: GPU
device_id: 0
net: "train_val-resultlayer-3stack.prototxt"
test_initialization: false
average_loss: 50
I0713 09:13:35.816156 47912 solver.cpp:90] Creating training net from net file: train_val-resultlayer-3stack.prototxt
I0713 09:13:35.817251 47912 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0713 09:13:35.817628 47912 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "conv53"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv54"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0713 09:13:35.820066 47912 layer_factory.hpp:76] Creating layer data
I0713 09:13:35.820127 47912 net.cpp:106] Creating Layer data
I0713 09:13:35.820155 47912 net.cpp:411] data -> data
I0713 09:13:35.820190 47912 net.cpp:411] data -> label
I0713 09:13:35.820689 47912 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0713 09:13:35.832818 47912 image_data_layer.cpp:46] Shuffling data
I0713 09:13:35.834532 47912 image_data_layer.cpp:51] A total of 23544 images.
I0713 09:13:35.909541 47912 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0713 09:13:36.164141 47912 net.cpp:150] Setting up data
I0713 09:13:36.164213 47912 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0713 09:13:36.164227 47912 net.cpp:157] Top shape: 8 (8)
I0713 09:13:36.164237 47912 net.cpp:165] Memory required for data: 96000032
I0713 09:13:36.164254 47912 layer_factory.hpp:76] Creating layer label_data_1_split
I0713 09:13:36.164279 47912 net.cpp:106] Creating Layer label_data_1_split
I0713 09:13:36.164294 47912 net.cpp:454] label_data_1_split <- label
I0713 09:13:36.164314 47912 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0713 09:13:36.164331 47912 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0713 09:13:36.164392 47912 net.cpp:150] Setting up label_data_1_split
I0713 09:13:36.164408 47912 net.cpp:157] Top shape: 8 (8)
I0713 09:13:36.164418 47912 net.cpp:157] Top shape: 8 (8)
I0713 09:13:36.164456 47912 net.cpp:165] Memory required for data: 96000096
I0713 09:13:36.164466 47912 layer_factory.hpp:76] Creating layer conv11
I0713 09:13:36.164489 47912 net.cpp:106] Creating Layer conv11
I0713 09:13:36.164500 47912 net.cpp:454] conv11 <- data
I0713 09:13:36.164515 47912 net.cpp:411] conv11 -> conv11
I0713 09:13:36.345947 47912 net.cpp:150] Setting up conv11
I0713 09:13:36.346014 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.346025 47912 net.cpp:165] Memory required for data: 1120000096
I0713 09:13:36.346057 47912 layer_factory.hpp:76] Creating layer relu11
I0713 09:13:36.346079 47912 net.cpp:106] Creating Layer relu11
I0713 09:13:36.346091 47912 net.cpp:454] relu11 <- conv11
I0713 09:13:36.346103 47912 net.cpp:397] relu11 -> conv11 (in-place)
I0713 09:13:36.346314 47912 net.cpp:150] Setting up relu11
I0713 09:13:36.346343 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.346354 47912 net.cpp:165] Memory required for data: 2144000096
I0713 09:13:36.346364 47912 layer_factory.hpp:76] Creating layer conv12
I0713 09:13:36.346385 47912 net.cpp:106] Creating Layer conv12
I0713 09:13:36.346395 47912 net.cpp:454] conv12 <- conv11
I0713 09:13:36.346410 47912 net.cpp:411] conv12 -> conv12
I0713 09:13:36.351614 47912 net.cpp:150] Setting up conv12
I0713 09:13:36.351651 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.351661 47912 net.cpp:165] Memory required for data: 3168000096
I0713 09:13:36.351677 47912 layer_factory.hpp:76] Creating layer relu12
I0713 09:13:36.351693 47912 net.cpp:106] Creating Layer relu12
I0713 09:13:36.351704 47912 net.cpp:454] relu12 <- conv12
I0713 09:13:36.351716 47912 net.cpp:397] relu12 -> conv12 (in-place)
I0713 09:13:36.352169 47912 net.cpp:150] Setting up relu12
I0713 09:13:36.352201 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.352211 47912 net.cpp:165] Memory required for data: 4192000096
I0713 09:13:36.352221 47912 layer_factory.hpp:76] Creating layer pool1
I0713 09:13:36.352236 47912 net.cpp:106] Creating Layer pool1
I0713 09:13:36.352246 47912 net.cpp:454] pool1 <- conv12
I0713 09:13:36.352260 47912 net.cpp:411] pool1 -> pool1
I0713 09:13:36.352494 47912 net.cpp:150] Setting up pool1
I0713 09:13:36.352511 47912 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0713 09:13:36.352533 47912 net.cpp:165] Memory required for data: 4448000096
I0713 09:13:36.352543 47912 layer_factory.hpp:76] Creating layer conv21
I0713 09:13:36.352565 47912 net.cpp:106] Creating Layer conv21
I0713 09:13:36.352574 47912 net.cpp:454] conv21 <- pool1
I0713 09:13:36.352588 47912 net.cpp:411] conv21 -> conv21
I0713 09:13:36.355844 47912 net.cpp:150] Setting up conv21
I0713 09:13:36.355880 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.355890 47912 net.cpp:165] Memory required for data: 4960000096
I0713 09:13:36.355906 47912 layer_factory.hpp:76] Creating layer relu21
I0713 09:13:36.355923 47912 net.cpp:106] Creating Layer relu21
I0713 09:13:36.355933 47912 net.cpp:454] relu21 <- conv21
I0713 09:13:36.355945 47912 net.cpp:397] relu21 -> conv21 (in-place)
I0713 09:13:36.356379 47912 net.cpp:150] Setting up relu21
I0713 09:13:36.356410 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.356420 47912 net.cpp:165] Memory required for data: 5472000096
I0713 09:13:36.356431 47912 layer_factory.hpp:76] Creating layer conv22
I0713 09:13:36.356453 47912 net.cpp:106] Creating Layer conv22
I0713 09:13:36.356463 47912 net.cpp:454] conv22 <- conv21
I0713 09:13:36.356475 47912 net.cpp:411] conv22 -> conv22
I0713 09:13:36.360580 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:36.360929 47912 net.cpp:150] Setting up conv22
I0713 09:13:36.360960 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.360970 47912 net.cpp:165] Memory required for data: 5984000096
I0713 09:13:36.360985 47912 layer_factory.hpp:76] Creating layer relu22
I0713 09:13:36.360996 47912 net.cpp:106] Creating Layer relu22
I0713 09:13:36.361006 47912 net.cpp:454] relu22 <- conv22
I0713 09:13:36.361060 47912 net.cpp:397] relu22 -> conv22 (in-place)
I0713 09:13:36.361553 47912 net.cpp:150] Setting up relu22
I0713 09:13:36.361585 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.361596 47912 net.cpp:165] Memory required for data: 6496000096
I0713 09:13:36.361608 47912 layer_factory.hpp:76] Creating layer pool2
I0713 09:13:36.361623 47912 net.cpp:106] Creating Layer pool2
I0713 09:13:36.361632 47912 net.cpp:454] pool2 <- conv22
I0713 09:13:36.361644 47912 net.cpp:411] pool2 -> pool2
I0713 09:13:36.361876 47912 net.cpp:150] Setting up pool2
I0713 09:13:36.361908 47912 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0713 09:13:36.361918 47912 net.cpp:165] Memory required for data: 6624000096
I0713 09:13:36.361928 47912 layer_factory.hpp:76] Creating layer conv31
I0713 09:13:36.361946 47912 net.cpp:106] Creating Layer conv31
I0713 09:13:36.361958 47912 net.cpp:454] conv31 <- pool2
I0713 09:13:36.361971 47912 net.cpp:411] conv31 -> conv31
I0713 09:13:36.363695 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:36.363742 47912 net.cpp:150] Setting up conv31
I0713 09:13:36.363755 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.363765 47912 net.cpp:165] Memory required for data: 6816000096
I0713 09:13:36.363783 47912 layer_factory.hpp:76] Creating layer relu31
I0713 09:13:36.363796 47912 net.cpp:106] Creating Layer relu31
I0713 09:13:36.363806 47912 net.cpp:454] relu31 <- conv31
I0713 09:13:36.363821 47912 net.cpp:397] relu31 -> conv31 (in-place)
I0713 09:13:36.364275 47912 net.cpp:150] Setting up relu31
I0713 09:13:36.364307 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.364316 47912 net.cpp:165] Memory required for data: 7008000096
I0713 09:13:36.364326 47912 layer_factory.hpp:76] Creating layer conv32
I0713 09:13:36.364344 47912 net.cpp:106] Creating Layer conv32
I0713 09:13:36.364354 47912 net.cpp:454] conv32 <- conv31
I0713 09:13:36.364368 47912 net.cpp:411] conv32 -> conv32
I0713 09:13:36.367072 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:36.367120 47912 net.cpp:150] Setting up conv32
I0713 09:13:36.367132 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.367141 47912 net.cpp:165] Memory required for data: 7200000096
I0713 09:13:36.367154 47912 layer_factory.hpp:76] Creating layer relu32
I0713 09:13:36.367169 47912 net.cpp:106] Creating Layer relu32
I0713 09:13:36.367180 47912 net.cpp:454] relu32 <- conv32
I0713 09:13:36.367190 47912 net.cpp:397] relu32 -> conv32 (in-place)
I0713 09:13:36.367406 47912 net.cpp:150] Setting up relu32
I0713 09:13:36.367435 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.367444 47912 net.cpp:165] Memory required for data: 7392000096
I0713 09:13:36.367455 47912 layer_factory.hpp:76] Creating layer pool3
I0713 09:13:36.367470 47912 net.cpp:106] Creating Layer pool3
I0713 09:13:36.367480 47912 net.cpp:454] pool3 <- conv32
I0713 09:13:36.367491 47912 net.cpp:411] pool3 -> pool3
I0713 09:13:36.367975 47912 net.cpp:150] Setting up pool3
I0713 09:13:36.368006 47912 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0713 09:13:36.368016 47912 net.cpp:165] Memory required for data: 7440000096
I0713 09:13:36.368026 47912 layer_factory.hpp:76] Creating layer conv41
I0713 09:13:36.368047 47912 net.cpp:106] Creating Layer conv41
I0713 09:13:36.368058 47912 net.cpp:454] conv41 <- pool3
I0713 09:13:36.368070 47912 net.cpp:411] conv41 -> conv41
I0713 09:13:36.369736 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:36.369786 47912 net.cpp:150] Setting up conv41
I0713 09:13:36.369798 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.369807 47912 net.cpp:165] Memory required for data: 7504000096
I0713 09:13:36.369820 47912 layer_factory.hpp:76] Creating layer relu41
I0713 09:13:36.369832 47912 net.cpp:106] Creating Layer relu41
I0713 09:13:36.369842 47912 net.cpp:454] relu41 <- conv41
I0713 09:13:36.369855 47912 net.cpp:397] relu41 -> conv41 (in-place)
I0713 09:13:36.370651 47912 net.cpp:150] Setting up relu41
I0713 09:13:36.370672 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.370682 47912 net.cpp:165] Memory required for data: 7568000096
I0713 09:13:36.370692 47912 layer_factory.hpp:76] Creating layer conv42
I0713 09:13:36.370707 47912 net.cpp:106] Creating Layer conv42
I0713 09:13:36.370718 47912 net.cpp:454] conv42 <- conv41
I0713 09:13:36.370733 47912 net.cpp:411] conv42 -> conv42
I0713 09:13:36.373829 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:36.373879 47912 net.cpp:150] Setting up conv42
I0713 09:13:36.373893 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.373901 47912 net.cpp:165] Memory required for data: 7632000096
I0713 09:13:36.373914 47912 layer_factory.hpp:76] Creating layer relu42
I0713 09:13:36.373926 47912 net.cpp:106] Creating Layer relu42
I0713 09:13:36.373936 47912 net.cpp:454] relu42 <- conv42
I0713 09:13:36.373950 47912 net.cpp:397] relu42 -> conv42 (in-place)
I0713 09:13:36.374161 47912 net.cpp:150] Setting up relu42
I0713 09:13:36.374189 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.374198 47912 net.cpp:165] Memory required for data: 7696000096
I0713 09:13:36.374207 47912 layer_factory.hpp:76] Creating layer pool4
I0713 09:13:36.374222 47912 net.cpp:106] Creating Layer pool4
I0713 09:13:36.374233 47912 net.cpp:454] pool4 <- conv42
I0713 09:13:36.374243 47912 net.cpp:411] pool4 -> pool4
I0713 09:13:36.374737 47912 net.cpp:150] Setting up pool4
I0713 09:13:36.374769 47912 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0713 09:13:36.374778 47912 net.cpp:165] Memory required for data: 7712257120
I0713 09:13:36.374788 47912 layer_factory.hpp:76] Creating layer conv51
I0713 09:13:36.374806 47912 net.cpp:106] Creating Layer conv51
I0713 09:13:36.374817 47912 net.cpp:454] conv51 <- pool4
I0713 09:13:36.374828 47912 net.cpp:411] conv51 -> conv51
I0713 09:13:36.379962 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:36.379997 47912 net.cpp:150] Setting up conv51
I0713 09:13:36.380012 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.380022 47912 net.cpp:165] Memory required for data: 7744771168
I0713 09:13:36.380054 47912 layer_factory.hpp:76] Creating layer relu51
I0713 09:13:36.380067 47912 net.cpp:106] Creating Layer relu51
I0713 09:13:36.380079 47912 net.cpp:454] relu51 <- conv51
I0713 09:13:36.380091 47912 net.cpp:397] relu51 -> conv51 (in-place)
I0713 09:13:36.380277 47912 net.cpp:150] Setting up relu51
I0713 09:13:36.380295 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.380303 47912 net.cpp:165] Memory required for data: 7777285216
I0713 09:13:36.380313 47912 layer_factory.hpp:76] Creating layer conv52
I0713 09:13:36.380329 47912 net.cpp:106] Creating Layer conv52
I0713 09:13:36.380339 47912 net.cpp:454] conv52 <- conv51
I0713 09:13:36.380353 47912 net.cpp:411] conv52 -> conv52
I0713 09:13:36.387329 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0713 09:13:36.387364 47912 net.cpp:150] Setting up conv52
I0713 09:13:36.387378 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.387387 47912 net.cpp:165] Memory required for data: 7809799264
I0713 09:13:36.387399 47912 layer_factory.hpp:76] Creating layer relu52
I0713 09:13:36.387413 47912 net.cpp:106] Creating Layer relu52
I0713 09:13:36.387421 47912 net.cpp:454] relu52 <- conv52
I0713 09:13:36.387434 47912 net.cpp:397] relu52 -> conv52 (in-place)
I0713 09:13:36.387887 47912 net.cpp:150] Setting up relu52
I0713 09:13:36.387908 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.387918 47912 net.cpp:165] Memory required for data: 7842313312
I0713 09:13:36.387928 47912 layer_factory.hpp:76] Creating layer conv53
I0713 09:13:36.387956 47912 net.cpp:106] Creating Layer conv53
I0713 09:13:36.387967 47912 net.cpp:454] conv53 <- conv52
I0713 09:13:36.387981 47912 net.cpp:411] conv53 -> conv53
I0713 09:13:36.421821 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0713 09:13:36.422219 47912 net.cpp:150] Setting up conv53
I0713 09:13:36.422255 47912 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0713 09:13:36.422266 47912 net.cpp:165] Memory required for data: 7868929120
I0713 09:13:36.422284 47912 layer_factory.hpp:76] Creating layer relu53
I0713 09:13:36.422302 47912 net.cpp:106] Creating Layer relu53
I0713 09:13:36.422328 47912 net.cpp:454] relu53 <- conv53
I0713 09:13:36.422343 47912 net.cpp:397] relu53 -> conv53 (in-place)
I0713 09:13:36.422866 47912 net.cpp:150] Setting up relu53
I0713 09:13:36.422899 47912 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0713 09:13:36.422910 47912 net.cpp:165] Memory required for data: 7895544928
I0713 09:13:36.422920 47912 layer_factory.hpp:76] Creating layer conv54
I0713 09:13:36.422936 47912 net.cpp:106] Creating Layer conv54
I0713 09:13:36.422946 47912 net.cpp:454] conv54 <- conv53
I0713 09:13:36.422961 47912 net.cpp:411] conv54 -> conv54
I0713 09:13:36.424166 47912 net.cpp:150] Setting up conv54
I0713 09:13:36.424201 47912 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0713 09:13:36.424211 47912 net.cpp:165] Memory required for data: 7895752864
I0713 09:13:36.424224 47912 layer_factory.hpp:76] Creating layer interloss
I0713 09:13:36.424237 47912 net.cpp:106] Creating Layer interloss
I0713 09:13:36.424247 47912 net.cpp:454] interloss <- conv54
I0713 09:13:36.424258 47912 net.cpp:411] interloss -> interloss
I0713 09:13:36.424527 47912 net.cpp:150] Setting up interloss
I0713 09:13:36.424557 47912 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0713 09:13:36.424566 47912 net.cpp:165] Memory required for data: 7895960800
I0713 09:13:36.424577 47912 layer_factory.hpp:76] Creating layer conv61
I0713 09:13:36.424594 47912 net.cpp:106] Creating Layer conv61
I0713 09:13:36.424605 47912 net.cpp:454] conv61 <- interloss
I0713 09:13:36.424617 47912 net.cpp:411] conv61 -> conv61
I0713 09:13:36.426012 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5614272
I0713 09:13:36.426399 47912 net.cpp:150] Setting up conv61
I0713 09:13:36.426430 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.426440 47912 net.cpp:165] Memory required for data: 7902614752
I0713 09:13:36.426451 47912 layer_factory.hpp:76] Creating layer relu61
I0713 09:13:36.426466 47912 net.cpp:106] Creating Layer relu61
I0713 09:13:36.426476 47912 net.cpp:454] relu61 <- conv61
I0713 09:13:36.426488 47912 net.cpp:397] relu61 -> conv61 (in-place)
I0713 09:13:36.427021 47912 net.cpp:150] Setting up relu61
I0713 09:13:36.427052 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.427062 47912 net.cpp:165] Memory required for data: 7909268704
I0713 09:13:36.427073 47912 layer_factory.hpp:76] Creating layer conv62
I0713 09:13:36.427096 47912 net.cpp:106] Creating Layer conv62
I0713 09:13:36.427106 47912 net.cpp:454] conv62 <- conv61
I0713 09:13:36.427121 47912 net.cpp:411] conv62 -> conv62
I0713 09:13:36.429116 47912 net.cpp:150] Setting up conv62
I0713 09:13:36.429148 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.429158 47912 net.cpp:165] Memory required for data: 7915922656
I0713 09:13:36.429170 47912 layer_factory.hpp:76] Creating layer relu62
I0713 09:13:36.429184 47912 net.cpp:106] Creating Layer relu62
I0713 09:13:36.429194 47912 net.cpp:454] relu62 <- conv62
I0713 09:13:36.429205 47912 net.cpp:397] relu62 -> conv62 (in-place)
I0713 09:13:36.429687 47912 net.cpp:150] Setting up relu62
I0713 09:13:36.429718 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.429728 47912 net.cpp:165] Memory required for data: 7922576608
I0713 09:13:36.429738 47912 layer_factory.hpp:76] Creating layer pool5
I0713 09:13:36.429752 47912 net.cpp:106] Creating Layer pool5
I0713 09:13:36.429762 47912 net.cpp:454] pool5 <- conv62
I0713 09:13:36.429772 47912 net.cpp:411] pool5 -> pool5
I0713 09:13:36.430039 47912 net.cpp:150] Setting up pool5
I0713 09:13:36.430068 47912 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0713 09:13:36.430078 47912 net.cpp:165] Memory required for data: 7924298976
I0713 09:13:36.430088 47912 layer_factory.hpp:76] Creating layer conv71
I0713 09:13:36.430117 47912 net.cpp:106] Creating Layer conv71
I0713 09:13:36.430129 47912 net.cpp:454] conv71 <- pool5
I0713 09:13:36.430140 47912 net.cpp:411] conv71 -> conv71
I0713 09:13:36.432155 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:36.432202 47912 net.cpp:150] Setting up conv71
I0713 09:13:36.432215 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.432224 47912 net.cpp:165] Memory required for data: 7926882528
I0713 09:13:36.432237 47912 layer_factory.hpp:76] Creating layer relu71
I0713 09:13:36.432251 47912 net.cpp:106] Creating Layer relu71
I0713 09:13:36.432262 47912 net.cpp:454] relu71 <- conv71
I0713 09:13:36.432273 47912 net.cpp:397] relu71 -> conv71 (in-place)
I0713 09:13:36.432750 47912 net.cpp:150] Setting up relu71
I0713 09:13:36.432782 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.432791 47912 net.cpp:165] Memory required for data: 7929466080
I0713 09:13:36.432802 47912 layer_factory.hpp:76] Creating layer conv72
I0713 09:13:36.432821 47912 net.cpp:106] Creating Layer conv72
I0713 09:13:36.432831 47912 net.cpp:454] conv72 <- conv71
I0713 09:13:36.432842 47912 net.cpp:411] conv72 -> conv72
I0713 09:13:36.434649 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:36.434710 47912 net.cpp:150] Setting up conv72
I0713 09:13:36.434751 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.434761 47912 net.cpp:165] Memory required for data: 7932049632
I0713 09:13:36.434773 47912 layer_factory.hpp:76] Creating layer relu72
I0713 09:13:36.434797 47912 net.cpp:106] Creating Layer relu72
I0713 09:13:36.434806 47912 net.cpp:454] relu72 <- conv72
I0713 09:13:36.434818 47912 net.cpp:397] relu72 -> conv72 (in-place)
I0713 09:13:36.435053 47912 net.cpp:150] Setting up relu72
I0713 09:13:36.435083 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.435092 47912 net.cpp:165] Memory required for data: 7934633184
I0713 09:13:36.435102 47912 layer_factory.hpp:76] Creating layer pool6
I0713 09:13:36.435117 47912 net.cpp:106] Creating Layer pool6
I0713 09:13:36.435127 47912 net.cpp:454] pool6 <- conv72
I0713 09:13:36.435150 47912 net.cpp:411] pool6 -> pool6
I0713 09:13:36.435698 47912 net.cpp:150] Setting up pool6
I0713 09:13:36.435729 47912 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0713 09:13:36.435739 47912 net.cpp:165] Memory required for data: 7935324384
I0713 09:13:36.435747 47912 layer_factory.hpp:76] Creating layer conv81
I0713 09:13:36.435765 47912 net.cpp:106] Creating Layer conv81
I0713 09:13:36.435775 47912 net.cpp:454] conv81 <- pool6
I0713 09:13:36.435789 47912 net.cpp:411] conv81 -> conv81
I0713 09:13:36.438374 47912 net.cpp:150] Setting up conv81
I0713 09:13:36.438406 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.438416 47912 net.cpp:165] Memory required for data: 7936245984
I0713 09:13:36.438438 47912 layer_factory.hpp:76] Creating layer relu81
I0713 09:13:36.438455 47912 net.cpp:106] Creating Layer relu81
I0713 09:13:36.438468 47912 net.cpp:454] relu81 <- conv81
I0713 09:13:36.438493 47912 net.cpp:397] relu81 -> conv81 (in-place)
I0713 09:13:36.438963 47912 net.cpp:150] Setting up relu81
I0713 09:13:36.438995 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.439005 47912 net.cpp:165] Memory required for data: 7937167584
I0713 09:13:36.439015 47912 layer_factory.hpp:76] Creating layer conv82
I0713 09:13:36.439033 47912 net.cpp:106] Creating Layer conv82
I0713 09:13:36.439043 47912 net.cpp:454] conv82 <- conv81
I0713 09:13:36.439059 47912 net.cpp:411] conv82 -> conv82
I0713 09:13:36.441279 47912 net.cpp:150] Setting up conv82
I0713 09:13:36.441313 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.441323 47912 net.cpp:165] Memory required for data: 7938089184
I0713 09:13:36.441335 47912 layer_factory.hpp:76] Creating layer relu82
I0713 09:13:36.441349 47912 net.cpp:106] Creating Layer relu82
I0713 09:13:36.441360 47912 net.cpp:454] relu82 <- conv82
I0713 09:13:36.441371 47912 net.cpp:397] relu82 -> conv82 (in-place)
I0713 09:13:36.441632 47912 net.cpp:150] Setting up relu82
I0713 09:13:36.441661 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.441670 47912 net.cpp:165] Memory required for data: 7939010784
I0713 09:13:36.441679 47912 layer_factory.hpp:76] Creating layer pool7
I0713 09:13:36.441691 47912 net.cpp:106] Creating Layer pool7
I0713 09:13:36.441701 47912 net.cpp:454] pool7 <- conv82
I0713 09:13:36.441715 47912 net.cpp:411] pool7 -> pool7
I0713 09:13:36.442240 47912 net.cpp:150] Setting up pool7
I0713 09:13:36.442271 47912 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0713 09:13:36.442281 47912 net.cpp:165] Memory required for data: 7939272928
I0713 09:13:36.442291 47912 layer_factory.hpp:76] Creating layer drop0
I0713 09:13:36.442308 47912 net.cpp:106] Creating Layer drop0
I0713 09:13:36.442319 47912 net.cpp:454] drop0 <- pool7
I0713 09:13:36.442329 47912 net.cpp:397] drop0 -> pool7 (in-place)
I0713 09:13:36.442370 47912 net.cpp:150] Setting up drop0
I0713 09:13:36.442384 47912 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0713 09:13:36.442394 47912 net.cpp:165] Memory required for data: 7939535072
I0713 09:13:36.442402 47912 layer_factory.hpp:76] Creating layer conv91
I0713 09:13:36.442420 47912 net.cpp:106] Creating Layer conv91
I0713 09:13:36.442428 47912 net.cpp:454] conv91 <- pool7
I0713 09:13:36.442440 47912 net.cpp:411] conv91 -> conv91
I0713 09:13:36.443895 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0713 09:13:36.443940 47912 net.cpp:150] Setting up conv91
I0713 09:13:36.443954 47912 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:36.443964 47912 net.cpp:165] Memory required for data: 7939535168
I0713 09:13:36.443977 47912 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0713 09:13:36.443990 47912 net.cpp:106] Creating Layer conv91_conv91_0_split
I0713 09:13:36.444000 47912 net.cpp:454] conv91_conv91_0_split <- conv91
I0713 09:13:36.444011 47912 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0713 09:13:36.444042 47912 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0713 09:13:36.444111 47912 net.cpp:150] Setting up conv91_conv91_0_split
I0713 09:13:36.444139 47912 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:36.444149 47912 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:36.444159 47912 net.cpp:165] Memory required for data: 7939535360
I0713 09:13:36.444169 47912 layer_factory.hpp:76] Creating layer accuracy
I0713 09:13:36.444183 47912 net.cpp:106] Creating Layer accuracy
I0713 09:13:36.444206 47912 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0713 09:13:36.444216 47912 net.cpp:454] accuracy <- label_data_1_split_0
I0713 09:13:36.444231 47912 net.cpp:411] accuracy -> accuracy
I0713 09:13:36.444262 47912 net.cpp:150] Setting up accuracy
I0713 09:13:36.444274 47912 net.cpp:157] Top shape: (1)
I0713 09:13:36.444283 47912 net.cpp:165] Memory required for data: 7939535364
I0713 09:13:36.444293 47912 layer_factory.hpp:76] Creating layer loss
I0713 09:13:36.444306 47912 net.cpp:106] Creating Layer loss
I0713 09:13:36.444316 47912 net.cpp:454] loss <- conv91_conv91_0_split_1
I0713 09:13:36.444339 47912 net.cpp:454] loss <- label_data_1_split_1
I0713 09:13:36.444349 47912 net.cpp:411] loss -> loss
I0713 09:13:36.444367 47912 layer_factory.hpp:76] Creating layer loss
I0713 09:13:36.444715 47912 net.cpp:150] Setting up loss
I0713 09:13:36.444746 47912 net.cpp:157] Top shape: (1)
I0713 09:13:36.444754 47912 net.cpp:160]     with loss weight 1
I0713 09:13:36.444785 47912 net.cpp:165] Memory required for data: 7939535368
I0713 09:13:36.444795 47912 net.cpp:226] loss needs backward computation.
I0713 09:13:36.444805 47912 net.cpp:228] accuracy does not need backward computation.
I0713 09:13:36.444816 47912 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0713 09:13:36.444826 47912 net.cpp:226] conv91 needs backward computation.
I0713 09:13:36.444835 47912 net.cpp:226] drop0 needs backward computation.
I0713 09:13:36.444844 47912 net.cpp:226] pool7 needs backward computation.
I0713 09:13:36.444854 47912 net.cpp:226] relu82 needs backward computation.
I0713 09:13:36.444876 47912 net.cpp:226] conv82 needs backward computation.
I0713 09:13:36.444887 47912 net.cpp:226] relu81 needs backward computation.
I0713 09:13:36.444895 47912 net.cpp:226] conv81 needs backward computation.
I0713 09:13:36.444905 47912 net.cpp:226] pool6 needs backward computation.
I0713 09:13:36.444914 47912 net.cpp:226] relu72 needs backward computation.
I0713 09:13:36.444923 47912 net.cpp:226] conv72 needs backward computation.
I0713 09:13:36.444932 47912 net.cpp:226] relu71 needs backward computation.
I0713 09:13:36.444941 47912 net.cpp:226] conv71 needs backward computation.
I0713 09:13:36.444950 47912 net.cpp:226] pool5 needs backward computation.
I0713 09:13:36.444959 47912 net.cpp:226] relu62 needs backward computation.
I0713 09:13:36.444968 47912 net.cpp:226] conv62 needs backward computation.
I0713 09:13:36.444977 47912 net.cpp:226] relu61 needs backward computation.
I0713 09:13:36.444986 47912 net.cpp:226] conv61 needs backward computation.
I0713 09:13:36.444995 47912 net.cpp:226] interloss needs backward computation.
I0713 09:13:36.445013 47912 net.cpp:226] conv54 needs backward computation.
I0713 09:13:36.445024 47912 net.cpp:228] relu53 does not need backward computation.
I0713 09:13:36.445037 47912 net.cpp:228] conv53 does not need backward computation.
I0713 09:13:36.445046 47912 net.cpp:228] relu52 does not need backward computation.
I0713 09:13:36.445056 47912 net.cpp:228] conv52 does not need backward computation.
I0713 09:13:36.445065 47912 net.cpp:228] relu51 does not need backward computation.
I0713 09:13:36.445075 47912 net.cpp:228] conv51 does not need backward computation.
I0713 09:13:36.445086 47912 net.cpp:228] pool4 does not need backward computation.
I0713 09:13:36.445094 47912 net.cpp:228] relu42 does not need backward computation.
I0713 09:13:36.445103 47912 net.cpp:228] conv42 does not need backward computation.
I0713 09:13:36.445113 47912 net.cpp:228] relu41 does not need backward computation.
I0713 09:13:36.445123 47912 net.cpp:228] conv41 does not need backward computation.
I0713 09:13:36.445133 47912 net.cpp:228] pool3 does not need backward computation.
I0713 09:13:36.445143 47912 net.cpp:228] relu32 does not need backward computation.
I0713 09:13:36.445152 47912 net.cpp:228] conv32 does not need backward computation.
I0713 09:13:36.445163 47912 net.cpp:228] relu31 does not need backward computation.
I0713 09:13:36.445171 47912 net.cpp:228] conv31 does not need backward computation.
I0713 09:13:36.445183 47912 net.cpp:228] pool2 does not need backward computation.
I0713 09:13:36.445191 47912 net.cpp:228] relu22 does not need backward computation.
I0713 09:13:36.445200 47912 net.cpp:228] conv22 does not need backward computation.
I0713 09:13:36.445210 47912 net.cpp:228] relu21 does not need backward computation.
I0713 09:13:36.445219 47912 net.cpp:228] conv21 does not need backward computation.
I0713 09:13:36.445230 47912 net.cpp:228] pool1 does not need backward computation.
I0713 09:13:36.445238 47912 net.cpp:228] relu12 does not need backward computation.
I0713 09:13:36.445248 47912 net.cpp:228] conv12 does not need backward computation.
I0713 09:13:36.445257 47912 net.cpp:228] relu11 does not need backward computation.
I0713 09:13:36.445267 47912 net.cpp:228] conv11 does not need backward computation.
I0713 09:13:36.445277 47912 net.cpp:228] label_data_1_split does not need backward computation.
I0713 09:13:36.445287 47912 net.cpp:228] data does not need backward computation.
I0713 09:13:36.445297 47912 net.cpp:270] This network produces output accuracy
I0713 09:13:36.445307 47912 net.cpp:270] This network produces output loss
I0713 09:13:36.445345 47912 net.cpp:283] Network initialization done.
I0713 09:13:36.446447 47912 solver.cpp:180] Creating test net (#0) specified by net file: train_val-resultlayer-3stack.prototxt
I0713 09:13:36.446521 47912 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0713 09:13:36.446871 47912 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "conv53"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv54"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0713 09:13:36.449396 47912 layer_factory.hpp:76] Creating layer data
I0713 09:13:36.449434 47912 net.cpp:106] Creating Layer data
I0713 09:13:36.449446 47912 net.cpp:411] data -> data
I0713 09:13:36.449461 47912 net.cpp:411] data -> label
I0713 09:13:36.449476 47912 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0713 09:13:36.451098 47912 image_data_layer.cpp:46] Shuffling data
I0713 09:13:36.451331 47912 image_data_layer.cpp:51] A total of 2617 images.
I0713 09:13:36.552660 47912 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0713 09:13:36.851680 47912 net.cpp:150] Setting up data
I0713 09:13:36.851778 47912 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0713 09:13:36.851814 47912 net.cpp:157] Top shape: 8 (8)
I0713 09:13:36.851826 47912 net.cpp:165] Memory required for data: 96000032
I0713 09:13:36.851845 47912 layer_factory.hpp:76] Creating layer label_data_1_split
I0713 09:13:36.851874 47912 net.cpp:106] Creating Layer label_data_1_split
I0713 09:13:36.851889 47912 net.cpp:454] label_data_1_split <- label
I0713 09:13:36.851902 47912 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0713 09:13:36.851920 47912 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0713 09:13:36.852293 47912 net.cpp:150] Setting up label_data_1_split
I0713 09:13:36.852322 47912 net.cpp:157] Top shape: 8 (8)
I0713 09:13:36.852334 47912 net.cpp:157] Top shape: 8 (8)
I0713 09:13:36.852344 47912 net.cpp:165] Memory required for data: 96000096
I0713 09:13:36.852352 47912 layer_factory.hpp:76] Creating layer conv11
I0713 09:13:36.852394 47912 net.cpp:106] Creating Layer conv11
I0713 09:13:36.852408 47912 net.cpp:454] conv11 <- data
I0713 09:13:36.852454 47912 net.cpp:411] conv11 -> conv11
I0713 09:13:36.859211 47912 net.cpp:150] Setting up conv11
I0713 09:13:36.859249 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.859261 47912 net.cpp:165] Memory required for data: 1120000096
I0713 09:13:36.859278 47912 layer_factory.hpp:76] Creating layer relu11
I0713 09:13:36.859295 47912 net.cpp:106] Creating Layer relu11
I0713 09:13:36.859307 47912 net.cpp:454] relu11 <- conv11
I0713 09:13:36.859351 47912 net.cpp:397] relu11 -> conv11 (in-place)
I0713 09:13:36.860214 47912 net.cpp:150] Setting up relu11
I0713 09:13:36.860247 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.860257 47912 net.cpp:165] Memory required for data: 2144000096
I0713 09:13:36.860267 47912 layer_factory.hpp:76] Creating layer conv12
I0713 09:13:36.860293 47912 net.cpp:106] Creating Layer conv12
I0713 09:13:36.860306 47912 net.cpp:454] conv12 <- conv11
I0713 09:13:36.860323 47912 net.cpp:411] conv12 -> conv12
I0713 09:13:36.864964 47912 net.cpp:150] Setting up conv12
I0713 09:13:36.865001 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.865012 47912 net.cpp:165] Memory required for data: 3168000096
I0713 09:13:36.865031 47912 layer_factory.hpp:76] Creating layer relu12
I0713 09:13:36.865046 47912 net.cpp:106] Creating Layer relu12
I0713 09:13:36.865056 47912 net.cpp:454] relu12 <- conv12
I0713 09:13:36.865084 47912 net.cpp:397] relu12 -> conv12 (in-place)
I0713 09:13:36.865959 47912 net.cpp:150] Setting up relu12
I0713 09:13:36.865991 47912 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:36.866003 47912 net.cpp:165] Memory required for data: 4192000096
I0713 09:13:36.866011 47912 layer_factory.hpp:76] Creating layer pool1
I0713 09:13:36.866031 47912 net.cpp:106] Creating Layer pool1
I0713 09:13:36.866042 47912 net.cpp:454] pool1 <- conv12
I0713 09:13:36.866055 47912 net.cpp:411] pool1 -> pool1
I0713 09:13:36.866324 47912 net.cpp:150] Setting up pool1
I0713 09:13:36.866360 47912 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0713 09:13:36.866370 47912 net.cpp:165] Memory required for data: 4448000096
I0713 09:13:36.866380 47912 layer_factory.hpp:76] Creating layer conv21
I0713 09:13:36.866399 47912 net.cpp:106] Creating Layer conv21
I0713 09:13:36.866408 47912 net.cpp:454] conv21 <- pool1
I0713 09:13:36.866430 47912 net.cpp:411] conv21 -> conv21
I0713 09:13:36.870005 47912 net.cpp:150] Setting up conv21
I0713 09:13:36.870043 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.870052 47912 net.cpp:165] Memory required for data: 4960000096
I0713 09:13:36.870069 47912 layer_factory.hpp:76] Creating layer relu21
I0713 09:13:36.870092 47912 net.cpp:106] Creating Layer relu21
I0713 09:13:36.870103 47912 net.cpp:454] relu21 <- conv21
I0713 09:13:36.870115 47912 net.cpp:397] relu21 -> conv21 (in-place)
I0713 09:13:36.870759 47912 net.cpp:150] Setting up relu21
I0713 09:13:36.870791 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.870810 47912 net.cpp:165] Memory required for data: 5472000096
I0713 09:13:36.870821 47912 layer_factory.hpp:76] Creating layer conv22
I0713 09:13:36.870836 47912 net.cpp:106] Creating Layer conv22
I0713 09:13:36.870847 47912 net.cpp:454] conv22 <- conv21
I0713 09:13:36.870865 47912 net.cpp:411] conv22 -> conv22
I0713 09:13:36.874133 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:36.874335 47912 net.cpp:150] Setting up conv22
I0713 09:13:36.874364 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.874374 47912 net.cpp:165] Memory required for data: 5984000096
I0713 09:13:36.874387 47912 layer_factory.hpp:76] Creating layer relu22
I0713 09:13:36.874406 47912 net.cpp:106] Creating Layer relu22
I0713 09:13:36.874418 47912 net.cpp:454] relu22 <- conv22
I0713 09:13:36.874428 47912 net.cpp:397] relu22 -> conv22 (in-place)
I0713 09:13:36.874692 47912 net.cpp:150] Setting up relu22
I0713 09:13:36.874712 47912 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:36.874722 47912 net.cpp:165] Memory required for data: 6496000096
I0713 09:13:36.874730 47912 layer_factory.hpp:76] Creating layer pool2
I0713 09:13:36.874749 47912 net.cpp:106] Creating Layer pool2
I0713 09:13:36.874760 47912 net.cpp:454] pool2 <- conv22
I0713 09:13:36.874780 47912 net.cpp:411] pool2 -> pool2
I0713 09:13:36.875546 47912 net.cpp:150] Setting up pool2
I0713 09:13:36.875579 47912 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0713 09:13:36.875589 47912 net.cpp:165] Memory required for data: 6624000096
I0713 09:13:36.875622 47912 layer_factory.hpp:76] Creating layer conv31
I0713 09:13:36.875643 47912 net.cpp:106] Creating Layer conv31
I0713 09:13:36.875658 47912 net.cpp:454] conv31 <- pool2
I0713 09:13:36.875676 47912 net.cpp:411] conv31 -> conv31
I0713 09:13:36.878538 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:36.878599 47912 net.cpp:150] Setting up conv31
I0713 09:13:36.878615 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.878624 47912 net.cpp:165] Memory required for data: 6816000096
I0713 09:13:36.878648 47912 layer_factory.hpp:76] Creating layer relu31
I0713 09:13:36.878671 47912 net.cpp:106] Creating Layer relu31
I0713 09:13:36.878682 47912 net.cpp:454] relu31 <- conv31
I0713 09:13:36.878695 47912 net.cpp:397] relu31 -> conv31 (in-place)
I0713 09:13:36.879441 47912 net.cpp:150] Setting up relu31
I0713 09:13:36.879472 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.879482 47912 net.cpp:165] Memory required for data: 7008000096
I0713 09:13:36.879492 47912 layer_factory.hpp:76] Creating layer conv32
I0713 09:13:36.879513 47912 net.cpp:106] Creating Layer conv32
I0713 09:13:36.879539 47912 net.cpp:454] conv32 <- conv31
I0713 09:13:36.879550 47912 net.cpp:411] conv32 -> conv32
I0713 09:13:36.882397 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:36.882453 47912 net.cpp:150] Setting up conv32
I0713 09:13:36.882468 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.882478 47912 net.cpp:165] Memory required for data: 7200000096
I0713 09:13:36.882491 47912 layer_factory.hpp:76] Creating layer relu32
I0713 09:13:36.882504 47912 net.cpp:106] Creating Layer relu32
I0713 09:13:36.882514 47912 net.cpp:454] relu32 <- conv32
I0713 09:13:36.882529 47912 net.cpp:397] relu32 -> conv32 (in-place)
I0713 09:13:36.882773 47912 net.cpp:150] Setting up relu32
I0713 09:13:36.882794 47912 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:36.882804 47912 net.cpp:165] Memory required for data: 7392000096
I0713 09:13:36.882813 47912 layer_factory.hpp:76] Creating layer pool3
I0713 09:13:36.882832 47912 net.cpp:106] Creating Layer pool3
I0713 09:13:36.882843 47912 net.cpp:454] pool3 <- conv32
I0713 09:13:36.882870 47912 net.cpp:411] pool3 -> pool3
I0713 09:13:36.883424 47912 net.cpp:150] Setting up pool3
I0713 09:13:36.883456 47912 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0713 09:13:36.883466 47912 net.cpp:165] Memory required for data: 7440000096
I0713 09:13:36.883476 47912 layer_factory.hpp:76] Creating layer conv41
I0713 09:13:36.883496 47912 net.cpp:106] Creating Layer conv41
I0713 09:13:36.883505 47912 net.cpp:454] conv41 <- pool3
I0713 09:13:36.883522 47912 net.cpp:411] conv41 -> conv41
I0713 09:13:36.885500 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:36.885550 47912 net.cpp:150] Setting up conv41
I0713 09:13:36.885565 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.885573 47912 net.cpp:165] Memory required for data: 7504000096
I0713 09:13:36.885586 47912 layer_factory.hpp:76] Creating layer relu41
I0713 09:13:36.885601 47912 net.cpp:106] Creating Layer relu41
I0713 09:13:36.885617 47912 net.cpp:454] relu41 <- conv41
I0713 09:13:36.885640 47912 net.cpp:397] relu41 -> conv41 (in-place)
I0713 09:13:36.885882 47912 net.cpp:150] Setting up relu41
I0713 09:13:36.885910 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.885920 47912 net.cpp:165] Memory required for data: 7568000096
I0713 09:13:36.885929 47912 layer_factory.hpp:76] Creating layer conv42
I0713 09:13:36.885946 47912 net.cpp:106] Creating Layer conv42
I0713 09:13:36.885956 47912 net.cpp:454] conv42 <- conv41
I0713 09:13:36.885970 47912 net.cpp:411] conv42 -> conv42
I0713 09:13:36.890063 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:36.890125 47912 net.cpp:150] Setting up conv42
I0713 09:13:36.890161 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.890175 47912 net.cpp:165] Memory required for data: 7632000096
I0713 09:13:36.890225 47912 layer_factory.hpp:76] Creating layer relu42
I0713 09:13:36.890244 47912 net.cpp:106] Creating Layer relu42
I0713 09:13:36.890256 47912 net.cpp:454] relu42 <- conv42
I0713 09:13:36.890287 47912 net.cpp:397] relu42 -> conv42 (in-place)
I0713 09:13:36.890662 47912 net.cpp:150] Setting up relu42
I0713 09:13:36.890700 47912 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:36.890714 47912 net.cpp:165] Memory required for data: 7696000096
I0713 09:13:36.890730 47912 layer_factory.hpp:76] Creating layer pool4
I0713 09:13:36.890748 47912 net.cpp:106] Creating Layer pool4
I0713 09:13:36.890774 47912 net.cpp:454] pool4 <- conv42
I0713 09:13:36.890805 47912 net.cpp:411] pool4 -> pool4
I0713 09:13:36.891428 47912 net.cpp:150] Setting up pool4
I0713 09:13:36.891461 47912 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0713 09:13:36.891471 47912 net.cpp:165] Memory required for data: 7712257120
I0713 09:13:36.891480 47912 layer_factory.hpp:76] Creating layer conv51
I0713 09:13:36.891500 47912 net.cpp:106] Creating Layer conv51
I0713 09:13:36.891511 47912 net.cpp:454] conv51 <- pool4
I0713 09:13:36.891530 47912 net.cpp:411] conv51 -> conv51
I0713 09:13:36.895702 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:36.895750 47912 net.cpp:150] Setting up conv51
I0713 09:13:36.895772 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.895783 47912 net.cpp:165] Memory required for data: 7744771168
I0713 09:13:36.895807 47912 layer_factory.hpp:76] Creating layer relu51
I0713 09:13:36.895833 47912 net.cpp:106] Creating Layer relu51
I0713 09:13:36.895843 47912 net.cpp:454] relu51 <- conv51
I0713 09:13:36.895855 47912 net.cpp:397] relu51 -> conv51 (in-place)
I0713 09:13:36.896093 47912 net.cpp:150] Setting up relu51
I0713 09:13:36.896122 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.896131 47912 net.cpp:165] Memory required for data: 7777285216
I0713 09:13:36.896143 47912 layer_factory.hpp:76] Creating layer conv52
I0713 09:13:36.896168 47912 net.cpp:106] Creating Layer conv52
I0713 09:13:36.896179 47912 net.cpp:454] conv52 <- conv51
I0713 09:13:36.896190 47912 net.cpp:411] conv52 -> conv52
I0713 09:13:36.903328 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0713 09:13:36.903388 47912 net.cpp:150] Setting up conv52
I0713 09:13:36.903405 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.903416 47912 net.cpp:165] Memory required for data: 7809799264
I0713 09:13:36.903429 47912 layer_factory.hpp:76] Creating layer relu52
I0713 09:13:36.903450 47912 net.cpp:106] Creating Layer relu52
I0713 09:13:36.903463 47912 net.cpp:454] relu52 <- conv52
I0713 09:13:36.903475 47912 net.cpp:397] relu52 -> conv52 (in-place)
I0713 09:13:36.932714 47912 net.cpp:150] Setting up relu52
I0713 09:13:36.932752 47912 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:36.932763 47912 net.cpp:165] Memory required for data: 7842313312
I0713 09:13:36.932773 47912 layer_factory.hpp:76] Creating layer conv53
I0713 09:13:36.932801 47912 net.cpp:106] Creating Layer conv53
I0713 09:13:36.932814 47912 net.cpp:454] conv53 <- conv52
I0713 09:13:36.932827 47912 net.cpp:411] conv53 -> conv53
I0713 09:13:36.979203 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0713 09:13:36.979429 47912 net.cpp:150] Setting up conv53
I0713 09:13:36.979470 47912 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0713 09:13:36.979480 47912 net.cpp:165] Memory required for data: 7868929120
I0713 09:13:36.979496 47912 layer_factory.hpp:76] Creating layer relu53
I0713 09:13:36.979514 47912 net.cpp:106] Creating Layer relu53
I0713 09:13:36.979526 47912 net.cpp:454] relu53 <- conv53
I0713 09:13:36.979548 47912 net.cpp:397] relu53 -> conv53 (in-place)
I0713 09:13:36.980103 47912 net.cpp:150] Setting up relu53
I0713 09:13:36.980136 47912 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0713 09:13:36.980146 47912 net.cpp:165] Memory required for data: 7895544928
I0713 09:13:36.980157 47912 layer_factory.hpp:76] Creating layer conv54
I0713 09:13:36.980212 47912 net.cpp:106] Creating Layer conv54
I0713 09:13:36.980226 47912 net.cpp:454] conv54 <- conv53
I0713 09:13:36.980239 47912 net.cpp:411] conv54 -> conv54
I0713 09:13:36.981757 47912 net.cpp:150] Setting up conv54
I0713 09:13:36.981791 47912 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0713 09:13:36.981802 47912 net.cpp:165] Memory required for data: 7895752864
I0713 09:13:36.981815 47912 layer_factory.hpp:76] Creating layer interloss
I0713 09:13:36.981828 47912 net.cpp:106] Creating Layer interloss
I0713 09:13:36.981838 47912 net.cpp:454] interloss <- conv54
I0713 09:13:36.981849 47912 net.cpp:411] interloss -> interloss
I0713 09:13:36.982174 47912 net.cpp:150] Setting up interloss
I0713 09:13:36.982204 47912 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0713 09:13:36.982213 47912 net.cpp:165] Memory required for data: 7895960800
I0713 09:13:36.982224 47912 layer_factory.hpp:76] Creating layer conv61
I0713 09:13:36.982245 47912 net.cpp:106] Creating Layer conv61
I0713 09:13:36.982257 47912 net.cpp:454] conv61 <- interloss
I0713 09:13:36.982269 47912 net.cpp:411] conv61 -> conv61
I0713 09:13:36.983844 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5614272
I0713 09:13:36.984206 47912 net.cpp:150] Setting up conv61
I0713 09:13:36.984227 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.984237 47912 net.cpp:165] Memory required for data: 7902614752
I0713 09:13:36.984251 47912 layer_factory.hpp:76] Creating layer relu61
I0713 09:13:36.984272 47912 net.cpp:106] Creating Layer relu61
I0713 09:13:36.984284 47912 net.cpp:454] relu61 <- conv61
I0713 09:13:36.984297 47912 net.cpp:397] relu61 -> conv61 (in-place)
I0713 09:13:36.984829 47912 net.cpp:150] Setting up relu61
I0713 09:13:36.984861 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.984872 47912 net.cpp:165] Memory required for data: 7909268704
I0713 09:13:36.984884 47912 layer_factory.hpp:76] Creating layer conv62
I0713 09:13:36.984922 47912 net.cpp:106] Creating Layer conv62
I0713 09:13:36.984936 47912 net.cpp:454] conv62 <- conv61
I0713 09:13:36.984957 47912 net.cpp:411] conv62 -> conv62
I0713 09:13:36.986459 47912 net.cpp:150] Setting up conv62
I0713 09:13:36.986493 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.986503 47912 net.cpp:165] Memory required for data: 7915922656
I0713 09:13:36.986517 47912 layer_factory.hpp:76] Creating layer relu62
I0713 09:13:36.986538 47912 net.cpp:106] Creating Layer relu62
I0713 09:13:36.986551 47912 net.cpp:454] relu62 <- conv62
I0713 09:13:36.986568 47912 net.cpp:397] relu62 -> conv62 (in-place)
I0713 09:13:36.987099 47912 net.cpp:150] Setting up relu62
I0713 09:13:36.987131 47912 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:36.987141 47912 net.cpp:165] Memory required for data: 7922576608
I0713 09:13:36.987151 47912 layer_factory.hpp:76] Creating layer pool5
I0713 09:13:36.987165 47912 net.cpp:106] Creating Layer pool5
I0713 09:13:36.987175 47912 net.cpp:454] pool5 <- conv62
I0713 09:13:36.987195 47912 net.cpp:411] pool5 -> pool5
I0713 09:13:36.987747 47912 net.cpp:150] Setting up pool5
I0713 09:13:36.987781 47912 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0713 09:13:36.987790 47912 net.cpp:165] Memory required for data: 7924298976
I0713 09:13:36.987800 47912 layer_factory.hpp:76] Creating layer conv71
I0713 09:13:36.987821 47912 net.cpp:106] Creating Layer conv71
I0713 09:13:36.987833 47912 net.cpp:454] conv71 <- pool5
I0713 09:13:36.987857 47912 net.cpp:411] conv71 -> conv71
I0713 09:13:36.989603 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:36.989665 47912 net.cpp:150] Setting up conv71
I0713 09:13:36.989680 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.989689 47912 net.cpp:165] Memory required for data: 7926882528
I0713 09:13:36.989703 47912 layer_factory.hpp:76] Creating layer relu71
I0713 09:13:36.989720 47912 net.cpp:106] Creating Layer relu71
I0713 09:13:36.989739 47912 net.cpp:454] relu71 <- conv71
I0713 09:13:36.989751 47912 net.cpp:397] relu71 -> conv71 (in-place)
I0713 09:13:36.990298 47912 net.cpp:150] Setting up relu71
I0713 09:13:36.990329 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.990339 47912 net.cpp:165] Memory required for data: 7929466080
I0713 09:13:36.990350 47912 layer_factory.hpp:76] Creating layer conv72
I0713 09:13:36.990375 47912 net.cpp:106] Creating Layer conv72
I0713 09:13:36.990386 47912 net.cpp:454] conv72 <- conv71
I0713 09:13:36.990401 47912 net.cpp:411] conv72 -> conv72
I0713 09:13:36.992455 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:36.992517 47912 net.cpp:150] Setting up conv72
I0713 09:13:36.992532 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.992542 47912 net.cpp:165] Memory required for data: 7932049632
I0713 09:13:36.992555 47912 layer_factory.hpp:76] Creating layer relu72
I0713 09:13:36.992568 47912 net.cpp:106] Creating Layer relu72
I0713 09:13:36.992578 47912 net.cpp:454] relu72 <- conv72
I0713 09:13:36.992593 47912 net.cpp:397] relu72 -> conv72 (in-place)
I0713 09:13:36.992801 47912 net.cpp:150] Setting up relu72
I0713 09:13:36.992831 47912 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:36.992841 47912 net.cpp:165] Memory required for data: 7934633184
I0713 09:13:36.992856 47912 layer_factory.hpp:76] Creating layer pool6
I0713 09:13:36.992871 47912 net.cpp:106] Creating Layer pool6
I0713 09:13:36.992880 47912 net.cpp:454] pool6 <- conv72
I0713 09:13:36.992892 47912 net.cpp:411] pool6 -> pool6
I0713 09:13:36.993413 47912 net.cpp:150] Setting up pool6
I0713 09:13:36.993438 47912 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0713 09:13:36.993448 47912 net.cpp:165] Memory required for data: 7935324384
I0713 09:13:36.993460 47912 layer_factory.hpp:76] Creating layer conv81
I0713 09:13:36.993487 47912 net.cpp:106] Creating Layer conv81
I0713 09:13:36.993499 47912 net.cpp:454] conv81 <- pool6
I0713 09:13:36.993515 47912 net.cpp:411] conv81 -> conv81
I0713 09:13:36.996455 47912 net.cpp:150] Setting up conv81
I0713 09:13:36.996480 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.996490 47912 net.cpp:165] Memory required for data: 7936245984
I0713 09:13:36.996512 47912 layer_factory.hpp:76] Creating layer relu81
I0713 09:13:36.996528 47912 net.cpp:106] Creating Layer relu81
I0713 09:13:36.996539 47912 net.cpp:454] relu81 <- conv81
I0713 09:13:36.996551 47912 net.cpp:397] relu81 -> conv81 (in-place)
I0713 09:13:36.996762 47912 net.cpp:150] Setting up relu81
I0713 09:13:36.996781 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.996790 47912 net.cpp:165] Memory required for data: 7937167584
I0713 09:13:36.996800 47912 layer_factory.hpp:76] Creating layer conv82
I0713 09:13:36.996815 47912 net.cpp:106] Creating Layer conv82
I0713 09:13:36.996826 47912 net.cpp:454] conv82 <- conv81
I0713 09:13:36.996840 47912 net.cpp:411] conv82 -> conv82
I0713 09:13:36.999240 47912 net.cpp:150] Setting up conv82
I0713 09:13:36.999264 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.999274 47912 net.cpp:165] Memory required for data: 7938089184
I0713 09:13:36.999287 47912 layer_factory.hpp:76] Creating layer relu82
I0713 09:13:36.999300 47912 net.cpp:106] Creating Layer relu82
I0713 09:13:36.999310 47912 net.cpp:454] relu82 <- conv82
I0713 09:13:36.999326 47912 net.cpp:397] relu82 -> conv82 (in-place)
I0713 09:13:36.999518 47912 net.cpp:150] Setting up relu82
I0713 09:13:36.999536 47912 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:36.999547 47912 net.cpp:165] Memory required for data: 7939010784
I0713 09:13:36.999557 47912 layer_factory.hpp:76] Creating layer pool7
I0713 09:13:36.999572 47912 net.cpp:106] Creating Layer pool7
I0713 09:13:36.999583 47912 net.cpp:454] pool7 <- conv82
I0713 09:13:36.999594 47912 net.cpp:411] pool7 -> pool7
I0713 09:13:37.000084 47912 net.cpp:150] Setting up pool7
I0713 09:13:37.000107 47912 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0713 09:13:37.000115 47912 net.cpp:165] Memory required for data: 7939272928
I0713 09:13:37.000126 47912 layer_factory.hpp:76] Creating layer drop0
I0713 09:13:37.000166 47912 net.cpp:106] Creating Layer drop0
I0713 09:13:37.000177 47912 net.cpp:454] drop0 <- pool7
I0713 09:13:37.000188 47912 net.cpp:397] drop0 -> pool7 (in-place)
I0713 09:13:37.000233 47912 net.cpp:150] Setting up drop0
I0713 09:13:37.000248 47912 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0713 09:13:37.000257 47912 net.cpp:165] Memory required for data: 7939535072
I0713 09:13:37.000267 47912 layer_factory.hpp:76] Creating layer conv91
I0713 09:13:37.000293 47912 net.cpp:106] Creating Layer conv91
I0713 09:13:37.000308 47912 net.cpp:454] conv91 <- pool7
I0713 09:13:37.000327 47912 net.cpp:411] conv91 -> conv91
I0713 09:13:37.001806 47912 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0713 09:13:37.001845 47912 net.cpp:150] Setting up conv91
I0713 09:13:37.001859 47912 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:37.001869 47912 net.cpp:165] Memory required for data: 7939535168
I0713 09:13:37.001883 47912 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0713 09:13:37.001900 47912 net.cpp:106] Creating Layer conv91_conv91_0_split
I0713 09:13:37.001910 47912 net.cpp:454] conv91_conv91_0_split <- conv91
I0713 09:13:37.001924 47912 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0713 09:13:37.001940 47912 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0713 09:13:37.002002 47912 net.cpp:150] Setting up conv91_conv91_0_split
I0713 09:13:37.002020 47912 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:37.002032 47912 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:37.002040 47912 net.cpp:165] Memory required for data: 7939535360
I0713 09:13:37.002050 47912 layer_factory.hpp:76] Creating layer accuracy
I0713 09:13:37.002063 47912 net.cpp:106] Creating Layer accuracy
I0713 09:13:37.002073 47912 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0713 09:13:37.002082 47912 net.cpp:454] accuracy <- label_data_1_split_0
I0713 09:13:37.002094 47912 net.cpp:411] accuracy -> accuracy
I0713 09:13:37.002109 47912 net.cpp:150] Setting up accuracy
I0713 09:13:37.002118 47912 net.cpp:157] Top shape: (1)
I0713 09:13:37.002127 47912 net.cpp:165] Memory required for data: 7939535364
I0713 09:13:37.002136 47912 layer_factory.hpp:76] Creating layer loss
I0713 09:13:37.002151 47912 net.cpp:106] Creating Layer loss
I0713 09:13:37.002161 47912 net.cpp:454] loss <- conv91_conv91_0_split_1
I0713 09:13:37.002171 47912 net.cpp:454] loss <- label_data_1_split_1
I0713 09:13:37.002182 47912 net.cpp:411] loss -> loss
I0713 09:13:37.002197 47912 layer_factory.hpp:76] Creating layer loss
I0713 09:13:37.002583 47912 net.cpp:150] Setting up loss
I0713 09:13:37.002602 47912 net.cpp:157] Top shape: (1)
I0713 09:13:37.002612 47912 net.cpp:160]     with loss weight 1
I0713 09:13:37.002635 47912 net.cpp:165] Memory required for data: 7939535368
I0713 09:13:37.002645 47912 net.cpp:226] loss needs backward computation.
I0713 09:13:37.002655 47912 net.cpp:228] accuracy does not need backward computation.
I0713 09:13:37.002666 47912 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0713 09:13:37.002676 47912 net.cpp:226] conv91 needs backward computation.
I0713 09:13:37.002684 47912 net.cpp:226] drop0 needs backward computation.
I0713 09:13:37.002692 47912 net.cpp:226] pool7 needs backward computation.
I0713 09:13:37.002701 47912 net.cpp:226] relu82 needs backward computation.
I0713 09:13:37.002710 47912 net.cpp:226] conv82 needs backward computation.
I0713 09:13:37.002719 47912 net.cpp:226] relu81 needs backward computation.
I0713 09:13:37.002727 47912 net.cpp:226] conv81 needs backward computation.
I0713 09:13:37.002737 47912 net.cpp:226] pool6 needs backward computation.
I0713 09:13:37.002746 47912 net.cpp:226] relu72 needs backward computation.
I0713 09:13:37.002755 47912 net.cpp:226] conv72 needs backward computation.
I0713 09:13:37.002764 47912 net.cpp:226] relu71 needs backward computation.
I0713 09:13:37.002773 47912 net.cpp:226] conv71 needs backward computation.
I0713 09:13:37.002781 47912 net.cpp:226] pool5 needs backward computation.
I0713 09:13:37.002810 47912 net.cpp:226] relu62 needs backward computation.
I0713 09:13:37.002818 47912 net.cpp:226] conv62 needs backward computation.
I0713 09:13:37.002827 47912 net.cpp:226] relu61 needs backward computation.
I0713 09:13:37.002837 47912 net.cpp:226] conv61 needs backward computation.
I0713 09:13:37.002846 47912 net.cpp:226] interloss needs backward computation.
I0713 09:13:37.002856 47912 net.cpp:226] conv54 needs backward computation.
I0713 09:13:37.002864 47912 net.cpp:228] relu53 does not need backward computation.
I0713 09:13:37.002873 47912 net.cpp:228] conv53 does not need backward computation.
I0713 09:13:37.002882 47912 net.cpp:228] relu52 does not need backward computation.
I0713 09:13:37.002892 47912 net.cpp:228] conv52 does not need backward computation.
I0713 09:13:37.002900 47912 net.cpp:228] relu51 does not need backward computation.
I0713 09:13:37.002909 47912 net.cpp:228] conv51 does not need backward computation.
I0713 09:13:37.002918 47912 net.cpp:228] pool4 does not need backward computation.
I0713 09:13:37.002928 47912 net.cpp:228] relu42 does not need backward computation.
I0713 09:13:37.002936 47912 net.cpp:228] conv42 does not need backward computation.
I0713 09:13:37.002946 47912 net.cpp:228] relu41 does not need backward computation.
I0713 09:13:37.002955 47912 net.cpp:228] conv41 does not need backward computation.
I0713 09:13:37.002964 47912 net.cpp:228] pool3 does not need backward computation.
I0713 09:13:37.002974 47912 net.cpp:228] relu32 does not need backward computation.
I0713 09:13:37.002982 47912 net.cpp:228] conv32 does not need backward computation.
I0713 09:13:37.002995 47912 net.cpp:228] relu31 does not need backward computation.
I0713 09:13:37.003005 47912 net.cpp:228] conv31 does not need backward computation.
I0713 09:13:37.003013 47912 net.cpp:228] pool2 does not need backward computation.
I0713 09:13:37.003023 47912 net.cpp:228] relu22 does not need backward computation.
I0713 09:13:37.003032 47912 net.cpp:228] conv22 does not need backward computation.
I0713 09:13:37.003041 47912 net.cpp:228] relu21 does not need backward computation.
I0713 09:13:37.003051 47912 net.cpp:228] conv21 does not need backward computation.
I0713 09:13:37.003060 47912 net.cpp:228] pool1 does not need backward computation.
I0713 09:13:37.003069 47912 net.cpp:228] relu12 does not need backward computation.
I0713 09:13:37.003078 47912 net.cpp:228] conv12 does not need backward computation.
I0713 09:13:37.003087 47912 net.cpp:228] relu11 does not need backward computation.
I0713 09:13:37.003096 47912 net.cpp:228] conv11 does not need backward computation.
I0713 09:13:37.003106 47912 net.cpp:228] label_data_1_split does not need backward computation.
I0713 09:13:37.003115 47912 net.cpp:228] data does not need backward computation.
I0713 09:13:37.003124 47912 net.cpp:270] This network produces output accuracy
I0713 09:13:37.003134 47912 net.cpp:270] This network produces output loss
I0713 09:13:37.003170 47912 net.cpp:283] Network initialization done.
I0713 09:13:37.003509 47912 solver.cpp:59] Solver scaffolding done.
I0713 09:13:37.005211 47912 caffe.cpp:128] Finetuning from models/cnn10_iter_217316.caffemodel
I0713 09:13:37.400615 47912 caffe.cpp:212] Starting Optimization
I0713 09:13:37.400698 47912 solver.cpp:287] Solving FaceNN
I0713 09:13:37.400714 47912 solver.cpp:288] Learning Rate Policy: step
I0713 09:13:40.149365 47912 solver.cpp:236] Iteration 0, loss = 1.10906
I0713 09:13:40.149428 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:13:40.149451 47912 solver.cpp:252]     Train net output #1: loss = 1.10906 (* 1 = 1.10906 loss)
I0713 09:13:40.149476 47912 sgd_solver.cpp:106] Iteration 0, lr = 0.025
I0713 09:17:50.912644 47912 solver.cpp:236] Iteration 100, loss = 1.0843
I0713 09:17:50.931519 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:17:50.931574 47912 solver.cpp:252]     Train net output #1: loss = 1.05599 (* 1 = 1.05599 loss)
I0713 09:17:50.931599 47912 sgd_solver.cpp:106] Iteration 100, lr = 0.025
I0713 09:22:01.673590 47912 solver.cpp:236] Iteration 200, loss = 1.09026
I0713 09:22:01.685923 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:22:01.685957 47912 solver.cpp:252]     Train net output #1: loss = 1.04608 (* 1 = 1.04608 loss)
I0713 09:22:01.685972 47912 sgd_solver.cpp:106] Iteration 200, lr = 0.025
I0713 09:26:12.473659 47912 solver.cpp:236] Iteration 300, loss = 1.06648
I0713 09:26:12.483340 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:26:12.483369 47912 solver.cpp:252]     Train net output #1: loss = 1.10343 (* 1 = 1.10343 loss)
I0713 09:26:12.483383 47912 sgd_solver.cpp:106] Iteration 300, lr = 0.025
I0713 09:30:23.331499 47912 solver.cpp:236] Iteration 400, loss = 1.07787
I0713 09:30:23.339067 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:30:23.339108 47912 solver.cpp:252]     Train net output #1: loss = 1.09408 (* 1 = 1.09408 loss)
I0713 09:30:23.339128 47912 sgd_solver.cpp:106] Iteration 400, lr = 0.025
I0713 09:34:34.149202 47912 solver.cpp:236] Iteration 500, loss = 1.06188
I0713 09:34:34.161440 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:34:34.161466 47912 solver.cpp:252]     Train net output #1: loss = 1.06288 (* 1 = 1.06288 loss)
I0713 09:34:34.161480 47912 sgd_solver.cpp:106] Iteration 500, lr = 0.025
I0713 09:36:12.109758 47912 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:38:48.603374 47912 solver.cpp:236] Iteration 600, loss = 1.07525
I0713 09:38:48.603530 47912 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:38:48.603570 47912 solver.cpp:252]     Train net output #1: loss = 1.33334 (* 1 = 1.33334 loss)
I0713 09:38:48.603597 47912 sgd_solver.cpp:106] Iteration 600, lr = 0.025
I0713 09:47:39.317718 47912 solver.cpp:236] Iteration 700, loss = 1.08759
I0713 09:47:39.317945 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:47:39.317987 47912 solver.cpp:252]     Train net output #1: loss = 1.02257 (* 1 = 1.02257 loss)
I0713 09:47:39.318004 47912 sgd_solver.cpp:106] Iteration 700, lr = 0.025
I0713 09:56:29.143561 47912 solver.cpp:236] Iteration 800, loss = 1.08095
I0713 09:56:29.143712 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:56:29.143736 47912 solver.cpp:252]     Train net output #1: loss = 1.0979 (* 1 = 1.0979 loss)
I0713 09:56:29.143750 47912 sgd_solver.cpp:106] Iteration 800, lr = 0.025
I0713 10:03:24.108186 47912 solver.cpp:236] Iteration 900, loss = 1.09508
I0713 10:03:24.114811 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:03:24.114837 47912 solver.cpp:252]     Train net output #1: loss = 1.02494 (* 1 = 1.02494 loss)
I0713 10:03:24.114856 47912 sgd_solver.cpp:106] Iteration 900, lr = 0.025
I0713 10:12:14.913632 47912 solver.cpp:236] Iteration 1000, loss = 1.06544
I0713 10:12:14.920152 47912 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:12:14.920176 47912 solver.cpp:252]     Train net output #1: loss = 1.19248 (* 1 = 1.19248 loss)
I0713 10:12:14.920192 47912 sgd_solver.cpp:106] Iteration 1000, lr = 0.025
I0713 10:19:48.870389 47912 solver.cpp:236] Iteration 1100, loss = 1.08231
I0713 10:19:48.880579 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:19:48.880614 47912 solver.cpp:252]     Train net output #1: loss = 1.02827 (* 1 = 1.02827 loss)
I0713 10:19:48.880630 47912 sgd_solver.cpp:106] Iteration 1100, lr = 0.025
I0713 10:28:04.622745 47912 solver.cpp:236] Iteration 1200, loss = 1.05655
I0713 10:28:04.628351 47912 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0713 10:28:04.628381 47912 solver.cpp:252]     Train net output #1: loss = 0.777274 (* 1 = 0.777274 loss)
I0713 10:28:04.628398 47912 sgd_solver.cpp:106] Iteration 1200, lr = 0.025
I0713 10:36:57.218507 47912 solver.cpp:236] Iteration 1300, loss = 1.08229
I0713 10:36:57.232477 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:36:57.232496 47912 solver.cpp:252]     Train net output #1: loss = 1.069 (* 1 = 1.069 loss)
I0713 10:36:57.232506 47912 sgd_solver.cpp:106] Iteration 1300, lr = 0.025
I0713 10:44:25.555021 47912 solver.cpp:236] Iteration 1400, loss = 1.07916
I0713 10:44:25.562783 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:44:25.562809 47912 solver.cpp:252]     Train net output #1: loss = 1.04025 (* 1 = 1.04025 loss)
I0713 10:44:25.562819 47912 sgd_solver.cpp:106] Iteration 1400, lr = 0.025
I0713 10:53:13.829193 47912 solver.cpp:340] Iteration 1500, Testing net (#0)
I0713 11:00:54.680238 47912 solver.cpp:408]     Test net output #0: accuracy = 0.44
I0713 11:00:54.701262 47912 solver.cpp:408]     Test net output #1: loss = 1.07626 (* 1 = 1.07626 loss)
I0713 11:00:57.936936 47912 solver.cpp:236] Iteration 1500, loss = 1.06586
I0713 11:00:57.936987 47912 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 11:00:57.937011 47912 solver.cpp:252]     Train net output #1: loss = 1.0168 (* 1 = 1.0168 loss)
I0713 11:00:57.937026 47912 sgd_solver.cpp:106] Iteration 1500, lr = 0.025
I0713 11:09:33.307673 47912 solver.cpp:236] Iteration 1600, loss = 1.04272
I0713 11:09:33.320804 47912 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:09:33.320868 47912 solver.cpp:252]     Train net output #1: loss = 0.969815 (* 1 = 0.969815 loss)
I0713 11:09:33.320899 47912 sgd_solver.cpp:106] Iteration 1600, lr = 0.025
I0713 11:18:22.076726 47912 solver.cpp:236] Iteration 1700, loss = 1.07732
I0713 11:18:22.085201 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:18:22.085237 47912 solver.cpp:252]     Train net output #1: loss = 1.06457 (* 1 = 1.06457 loss)
I0713 11:18:22.085248 47912 sgd_solver.cpp:106] Iteration 1700, lr = 0.025
I0713 11:25:02.931870 47912 solver.cpp:236] Iteration 1800, loss = 1.0543
I0713 11:25:02.939745 47912 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:25:02.939772 47912 solver.cpp:252]     Train net output #1: loss = 1.0457 (* 1 = 1.0457 loss)
I0713 11:25:02.939785 47912 sgd_solver.cpp:106] Iteration 1800, lr = 0.025
I0713 11:33:53.603410 47912 solver.cpp:236] Iteration 1900, loss = 1.06789
I0713 11:33:53.614677 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:33:53.614711 47912 solver.cpp:252]     Train net output #1: loss = 1.07133 (* 1 = 1.07133 loss)
I0713 11:33:53.614725 47912 sgd_solver.cpp:106] Iteration 1900, lr = 0.025
I0713 11:42:07.550499 47912 solver.cpp:236] Iteration 2000, loss = 1.08146
I0713 11:42:07.568511 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:42:07.568554 47912 solver.cpp:252]     Train net output #1: loss = 1.04871 (* 1 = 1.04871 loss)
I0713 11:42:07.568569 47912 sgd_solver.cpp:106] Iteration 2000, lr = 0.025
I0713 11:50:28.788993 47912 solver.cpp:236] Iteration 2100, loss = 1.08725
I0713 11:50:28.805289 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:50:28.805346 47912 solver.cpp:252]     Train net output #1: loss = 1.01782 (* 1 = 1.01782 loss)
I0713 11:50:28.805371 47912 sgd_solver.cpp:106] Iteration 2100, lr = 0.025
I0713 11:59:20.342365 47912 solver.cpp:236] Iteration 2200, loss = 1.06003
I0713 11:59:20.351476 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:59:20.351505 47912 solver.cpp:252]     Train net output #1: loss = 1.02501 (* 1 = 1.02501 loss)
I0713 11:59:20.351516 47912 sgd_solver.cpp:106] Iteration 2200, lr = 0.025
I0713 12:07:09.015496 47912 solver.cpp:236] Iteration 2300, loss = 1.04291
I0713 12:07:09.021364 47912 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:07:09.021390 47912 solver.cpp:252]     Train net output #1: loss = 1.05385 (* 1 = 1.05385 loss)
I0713 12:07:09.021406 47912 sgd_solver.cpp:106] Iteration 2300, lr = 0.025
I0713 12:15:57.791133 47912 solver.cpp:236] Iteration 2400, loss = 1.08754
I0713 12:15:57.802381 47912 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 12:15:57.802418 47912 solver.cpp:252]     Train net output #1: loss = 1.21043 (* 1 = 1.21043 loss)
I0713 12:15:57.802433 47912 sgd_solver.cpp:106] Iteration 2400, lr = 0.025
I0713 12:24:14.999539 47912 solver.cpp:236] Iteration 2500, loss = 1.09587
