Log file created at: 2016/07/12 17:59:18
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0712 17:59:18.110164 44362 caffe.cpp:184] Using GPUs 3
I0712 17:59:18.724705 44362 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 1500
base_lr: 0.015
display: 100
max_iter: 500000
lr_policy: "step"
gamma: 0.1
momentum: 0.85
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/resultlayer"
solver_mode: GPU
device_id: 3
net: "train_val-resultlayer.prototxt"
test_initialization: false
average_loss: 50
I0712 17:59:18.724946 44362 solver.cpp:90] Creating training net from net file: train_val-resultlayer.prototxt
I0712 17:59:18.742905 44362 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0712 17:59:18.743283 44362 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "conv53"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv54"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "conv63"
  type: "Convolution"
  bottom: "conv62"
  top: "conv63"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu63"
  type: "ReLU"
  bottom: "conv63"
  top: "conv63"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv63"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "conv73"
  type: "Convolution"
  bottom: "conv72"
  top: "conv73"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu73"
  type: "ReLU"
  bottom: "conv73"
  top: "conv73"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv73"
  top: "pool6"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool6"
  top: "pool6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 15
    kernel_w: 15
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv81"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv81"
  bottom: "label"
  top: "loss"
}
I0712 17:59:18.745785 44362 layer_factory.hpp:76] Creating layer data
I0712 17:59:18.745848 44362 net.cpp:106] Creating Layer data
I0712 17:59:18.745864 44362 net.cpp:411] data -> data
I0712 17:59:18.745904 44362 net.cpp:411] data -> label
I0712 17:59:18.746376 44362 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0712 17:59:18.760203 44362 image_data_layer.cpp:46] Shuffling data
I0712 17:59:18.763057 44362 image_data_layer.cpp:51] A total of 23544 images.
I0712 17:59:18.879602 44362 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0712 17:59:19.123575 44362 net.cpp:150] Setting up data
I0712 17:59:19.142222 44362 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0712 17:59:19.142276 44362 net.cpp:157] Top shape: 8 (8)
I0712 17:59:19.142285 44362 net.cpp:165] Memory required for data: 96000032
I0712 17:59:19.142300 44362 layer_factory.hpp:76] Creating layer label_data_1_split
I0712 17:59:19.142323 44362 net.cpp:106] Creating Layer label_data_1_split
I0712 17:59:19.142335 44362 net.cpp:454] label_data_1_split <- label
I0712 17:59:19.142355 44362 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0712 17:59:19.142379 44362 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0712 17:59:19.142467 44362 net.cpp:150] Setting up label_data_1_split
I0712 17:59:19.142491 44362 net.cpp:157] Top shape: 8 (8)
I0712 17:59:19.142513 44362 net.cpp:157] Top shape: 8 (8)
I0712 17:59:19.142521 44362 net.cpp:165] Memory required for data: 96000096
I0712 17:59:19.142530 44362 layer_factory.hpp:76] Creating layer conv11
I0712 17:59:19.142586 44362 net.cpp:106] Creating Layer conv11
I0712 17:59:19.142597 44362 net.cpp:454] conv11 <- data
I0712 17:59:19.142611 44362 net.cpp:411] conv11 -> conv11
I0712 17:59:19.331466 44362 net.cpp:150] Setting up conv11
I0712 17:59:19.331532 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.331544 44362 net.cpp:165] Memory required for data: 1120000096
I0712 17:59:19.331590 44362 layer_factory.hpp:76] Creating layer relu11
I0712 17:59:19.331626 44362 net.cpp:106] Creating Layer relu11
I0712 17:59:19.331645 44362 net.cpp:454] relu11 <- conv11
I0712 17:59:19.331663 44362 net.cpp:397] relu11 -> conv11 (in-place)
I0712 17:59:19.331863 44362 net.cpp:150] Setting up relu11
I0712 17:59:19.331887 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.331900 44362 net.cpp:165] Memory required for data: 2144000096
I0712 17:59:19.331928 44362 layer_factory.hpp:76] Creating layer conv12
I0712 17:59:19.331955 44362 net.cpp:106] Creating Layer conv12
I0712 17:59:19.331970 44362 net.cpp:454] conv12 <- conv11
I0712 17:59:19.331989 44362 net.cpp:411] conv12 -> conv12
I0712 17:59:19.336997 44362 net.cpp:150] Setting up conv12
I0712 17:59:19.337029 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.337044 44362 net.cpp:165] Memory required for data: 3168000096
I0712 17:59:19.337065 44362 layer_factory.hpp:76] Creating layer relu12
I0712 17:59:19.337087 44362 net.cpp:106] Creating Layer relu12
I0712 17:59:19.337102 44362 net.cpp:454] relu12 <- conv12
I0712 17:59:19.337119 44362 net.cpp:397] relu12 -> conv12 (in-place)
I0712 17:59:19.337491 44362 net.cpp:150] Setting up relu12
I0712 17:59:19.337513 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.337527 44362 net.cpp:165] Memory required for data: 4192000096
I0712 17:59:19.337540 44362 layer_factory.hpp:76] Creating layer pool1
I0712 17:59:19.337563 44362 net.cpp:106] Creating Layer pool1
I0712 17:59:19.337576 44362 net.cpp:454] pool1 <- conv12
I0712 17:59:19.337596 44362 net.cpp:411] pool1 -> pool1
I0712 17:59:19.337877 44362 net.cpp:150] Setting up pool1
I0712 17:59:19.337898 44362 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0712 17:59:19.337913 44362 net.cpp:165] Memory required for data: 4448000096
I0712 17:59:19.337925 44362 layer_factory.hpp:76] Creating layer conv21
I0712 17:59:19.337954 44362 net.cpp:106] Creating Layer conv21
I0712 17:59:19.337967 44362 net.cpp:454] conv21 <- pool1
I0712 17:59:19.337988 44362 net.cpp:411] conv21 -> conv21
I0712 17:59:19.340842 44362 net.cpp:150] Setting up conv21
I0712 17:59:19.340868 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.340883 44362 net.cpp:165] Memory required for data: 4960000096
I0712 17:59:19.340904 44362 layer_factory.hpp:76] Creating layer relu21
I0712 17:59:19.340929 44362 net.cpp:106] Creating Layer relu21
I0712 17:59:19.340944 44362 net.cpp:454] relu21 <- conv21
I0712 17:59:19.340960 44362 net.cpp:397] relu21 -> conv21 (in-place)
I0712 17:59:19.341327 44362 net.cpp:150] Setting up relu21
I0712 17:59:19.341351 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.341364 44362 net.cpp:165] Memory required for data: 5472000096
I0712 17:59:19.341377 44362 layer_factory.hpp:76] Creating layer conv22
I0712 17:59:19.341403 44362 net.cpp:106] Creating Layer conv22
I0712 17:59:19.341418 44362 net.cpp:454] conv22 <- conv21
I0712 17:59:19.341434 44362 net.cpp:411] conv22 -> conv22
I0712 17:59:19.343626 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 17:59:19.343885 44362 net.cpp:150] Setting up conv22
I0712 17:59:19.343909 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.343922 44362 net.cpp:165] Memory required for data: 5984000096
I0712 17:59:19.343941 44362 layer_factory.hpp:76] Creating layer relu22
I0712 17:59:19.343961 44362 net.cpp:106] Creating Layer relu22
I0712 17:59:19.343974 44362 net.cpp:454] relu22 <- conv22
I0712 17:59:19.343994 44362 net.cpp:397] relu22 -> conv22 (in-place)
I0712 17:59:19.344367 44362 net.cpp:150] Setting up relu22
I0712 17:59:19.344419 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.344435 44362 net.cpp:165] Memory required for data: 6496000096
I0712 17:59:19.344451 44362 layer_factory.hpp:76] Creating layer pool2
I0712 17:59:19.344473 44362 net.cpp:106] Creating Layer pool2
I0712 17:59:19.344488 44362 net.cpp:454] pool2 <- conv22
I0712 17:59:19.344504 44362 net.cpp:411] pool2 -> pool2
I0712 17:59:19.344756 44362 net.cpp:150] Setting up pool2
I0712 17:59:19.344777 44362 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0712 17:59:19.344791 44362 net.cpp:165] Memory required for data: 6624000096
I0712 17:59:19.344805 44362 layer_factory.hpp:76] Creating layer conv31
I0712 17:59:19.344827 44362 net.cpp:106] Creating Layer conv31
I0712 17:59:19.344841 44362 net.cpp:454] conv31 <- pool2
I0712 17:59:19.344863 44362 net.cpp:411] conv31 -> conv31
I0712 17:59:19.346434 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 17:59:19.346474 44362 net.cpp:150] Setting up conv31
I0712 17:59:19.346493 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.346508 44362 net.cpp:165] Memory required for data: 6816000096
I0712 17:59:19.346534 44362 layer_factory.hpp:76] Creating layer relu31
I0712 17:59:19.346551 44362 net.cpp:106] Creating Layer relu31
I0712 17:59:19.346565 44362 net.cpp:454] relu31 <- conv31
I0712 17:59:19.346583 44362 net.cpp:397] relu31 -> conv31 (in-place)
I0712 17:59:19.346981 44362 net.cpp:150] Setting up relu31
I0712 17:59:19.347004 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.347018 44362 net.cpp:165] Memory required for data: 7008000096
I0712 17:59:19.347031 44362 layer_factory.hpp:76] Creating layer conv32
I0712 17:59:19.347056 44362 net.cpp:106] Creating Layer conv32
I0712 17:59:19.347071 44362 net.cpp:454] conv32 <- conv31
I0712 17:59:19.347096 44362 net.cpp:411] conv32 -> conv32
I0712 17:59:19.349673 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 17:59:19.349714 44362 net.cpp:150] Setting up conv32
I0712 17:59:19.349735 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.349747 44362 net.cpp:165] Memory required for data: 7200000096
I0712 17:59:19.349766 44362 layer_factory.hpp:76] Creating layer relu32
I0712 17:59:19.349787 44362 net.cpp:106] Creating Layer relu32
I0712 17:59:19.349802 44362 net.cpp:454] relu32 <- conv32
I0712 17:59:19.349822 44362 net.cpp:397] relu32 -> conv32 (in-place)
I0712 17:59:19.350065 44362 net.cpp:150] Setting up relu32
I0712 17:59:19.350087 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.350100 44362 net.cpp:165] Memory required for data: 7392000096
I0712 17:59:19.350114 44362 layer_factory.hpp:76] Creating layer pool3
I0712 17:59:19.350138 44362 net.cpp:106] Creating Layer pool3
I0712 17:59:19.350152 44362 net.cpp:454] pool3 <- conv32
I0712 17:59:19.350168 44362 net.cpp:411] pool3 -> pool3
I0712 17:59:19.350620 44362 net.cpp:150] Setting up pool3
I0712 17:59:19.350651 44362 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0712 17:59:19.350669 44362 net.cpp:165] Memory required for data: 7440000096
I0712 17:59:19.350687 44362 layer_factory.hpp:76] Creating layer conv41
I0712 17:59:19.350718 44362 net.cpp:106] Creating Layer conv41
I0712 17:59:19.350749 44362 net.cpp:454] conv41 <- pool3
I0712 17:59:19.350764 44362 net.cpp:411] conv41 -> conv41
I0712 17:59:19.352496 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 17:59:19.352545 44362 net.cpp:150] Setting up conv41
I0712 17:59:19.352558 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.352567 44362 net.cpp:165] Memory required for data: 7504000096
I0712 17:59:19.352578 44362 layer_factory.hpp:76] Creating layer relu41
I0712 17:59:19.352591 44362 net.cpp:106] Creating Layer relu41
I0712 17:59:19.352599 44362 net.cpp:454] relu41 <- conv41
I0712 17:59:19.352612 44362 net.cpp:397] relu41 -> conv41 (in-place)
I0712 17:59:19.353157 44362 net.cpp:150] Setting up relu41
I0712 17:59:19.353188 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.353220 44362 net.cpp:165] Memory required for data: 7568000096
I0712 17:59:19.353230 44362 layer_factory.hpp:76] Creating layer conv42
I0712 17:59:19.353247 44362 net.cpp:106] Creating Layer conv42
I0712 17:59:19.353263 44362 net.cpp:454] conv42 <- conv41
I0712 17:59:19.353293 44362 net.cpp:411] conv42 -> conv42
I0712 17:59:19.356230 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:19.356279 44362 net.cpp:150] Setting up conv42
I0712 17:59:19.356292 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.356300 44362 net.cpp:165] Memory required for data: 7632000096
I0712 17:59:19.356312 44362 layer_factory.hpp:76] Creating layer relu42
I0712 17:59:19.356323 44362 net.cpp:106] Creating Layer relu42
I0712 17:59:19.356331 44362 net.cpp:454] relu42 <- conv42
I0712 17:59:19.356343 44362 net.cpp:397] relu42 -> conv42 (in-place)
I0712 17:59:19.356587 44362 net.cpp:150] Setting up relu42
I0712 17:59:19.356614 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.356623 44362 net.cpp:165] Memory required for data: 7696000096
I0712 17:59:19.356634 44362 layer_factory.hpp:76] Creating layer pool4
I0712 17:59:19.356647 44362 net.cpp:106] Creating Layer pool4
I0712 17:59:19.356657 44362 net.cpp:454] pool4 <- conv42
I0712 17:59:19.356667 44362 net.cpp:411] pool4 -> pool4
I0712 17:59:19.357077 44362 net.cpp:150] Setting up pool4
I0712 17:59:19.357108 44362 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0712 17:59:19.357117 44362 net.cpp:165] Memory required for data: 7712257120
I0712 17:59:19.357125 44362 layer_factory.hpp:76] Creating layer conv51
I0712 17:59:19.357142 44362 net.cpp:106] Creating Layer conv51
I0712 17:59:19.357151 44362 net.cpp:454] conv51 <- pool4
I0712 17:59:19.357162 44362 net.cpp:411] conv51 -> conv51
I0712 17:59:19.361973 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:19.362016 44362 net.cpp:150] Setting up conv51
I0712 17:59:19.362030 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.362037 44362 net.cpp:165] Memory required for data: 7744771168
I0712 17:59:19.362056 44362 layer_factory.hpp:76] Creating layer relu51
I0712 17:59:19.362087 44362 net.cpp:106] Creating Layer relu51
I0712 17:59:19.362095 44362 net.cpp:454] relu51 <- conv51
I0712 17:59:19.362108 44362 net.cpp:397] relu51 -> conv51 (in-place)
I0712 17:59:19.362349 44362 net.cpp:150] Setting up relu51
I0712 17:59:19.362376 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.362385 44362 net.cpp:165] Memory required for data: 7777285216
I0712 17:59:19.362393 44362 layer_factory.hpp:76] Creating layer conv52
I0712 17:59:19.362413 44362 net.cpp:106] Creating Layer conv52
I0712 17:59:19.362423 44362 net.cpp:454] conv52 <- conv51
I0712 17:59:19.362437 44362 net.cpp:411] conv52 -> conv52
I0712 17:59:19.369153 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 17:59:19.369200 44362 net.cpp:150] Setting up conv52
I0712 17:59:19.369213 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.369221 44362 net.cpp:165] Memory required for data: 7809799264
I0712 17:59:19.369233 44362 layer_factory.hpp:76] Creating layer relu52
I0712 17:59:19.369246 44362 net.cpp:106] Creating Layer relu52
I0712 17:59:19.369254 44362 net.cpp:454] relu52 <- conv52
I0712 17:59:19.369263 44362 net.cpp:397] relu52 -> conv52 (in-place)
I0712 17:59:19.369657 44362 net.cpp:150] Setting up relu52
I0712 17:59:19.369688 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.369696 44362 net.cpp:165] Memory required for data: 7842313312
I0712 17:59:19.369704 44362 layer_factory.hpp:76] Creating layer conv53
I0712 17:59:19.369722 44362 net.cpp:106] Creating Layer conv53
I0712 17:59:19.369731 44362 net.cpp:454] conv53 <- conv52
I0712 17:59:19.369745 44362 net.cpp:411] conv53 -> conv53
I0712 17:59:19.409307 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0712 17:59:19.409610 44362 net.cpp:150] Setting up conv53
I0712 17:59:19.409657 44362 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 17:59:19.409696 44362 net.cpp:165] Memory required for data: 7868929120
I0712 17:59:19.409741 44362 layer_factory.hpp:76] Creating layer relu53
I0712 17:59:19.409770 44362 net.cpp:106] Creating Layer relu53
I0712 17:59:19.409781 44362 net.cpp:454] relu53 <- conv53
I0712 17:59:19.409792 44362 net.cpp:397] relu53 -> conv53 (in-place)
I0712 17:59:19.410174 44362 net.cpp:150] Setting up relu53
I0712 17:59:19.410207 44362 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 17:59:19.410217 44362 net.cpp:165] Memory required for data: 7895544928
I0712 17:59:19.410228 44362 layer_factory.hpp:76] Creating layer conv54
I0712 17:59:19.410243 44362 net.cpp:106] Creating Layer conv54
I0712 17:59:19.410251 44362 net.cpp:454] conv54 <- conv53
I0712 17:59:19.410264 44362 net.cpp:411] conv54 -> conv54
I0712 17:59:19.411423 44362 net.cpp:150] Setting up conv54
I0712 17:59:19.411458 44362 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 17:59:19.411466 44362 net.cpp:165] Memory required for data: 7895752864
I0712 17:59:19.411478 44362 layer_factory.hpp:76] Creating layer interloss
I0712 17:59:19.411491 44362 net.cpp:106] Creating Layer interloss
I0712 17:59:19.411500 44362 net.cpp:454] interloss <- conv54
I0712 17:59:19.411514 44362 net.cpp:411] interloss -> interloss
I0712 17:59:19.411831 44362 net.cpp:150] Setting up interloss
I0712 17:59:19.411859 44362 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 17:59:19.411867 44362 net.cpp:165] Memory required for data: 7895960800
I0712 17:59:19.411875 44362 layer_factory.hpp:76] Creating layer conv61
I0712 17:59:19.411890 44362 net.cpp:106] Creating Layer conv61
I0712 17:59:19.411900 44362 net.cpp:454] conv61 <- interloss
I0712 17:59:19.411909 44362 net.cpp:411] conv61 -> conv61
I0712 17:59:19.413027 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5614272
I0712 17:59:19.413317 44362 net.cpp:150] Setting up conv61
I0712 17:59:19.413347 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:19.413354 44362 net.cpp:165] Memory required for data: 7902614752
I0712 17:59:19.413370 44362 layer_factory.hpp:76] Creating layer relu61
I0712 17:59:19.413381 44362 net.cpp:106] Creating Layer relu61
I0712 17:59:19.413390 44362 net.cpp:454] relu61 <- conv61
I0712 17:59:19.413399 44362 net.cpp:397] relu61 -> conv61 (in-place)
I0712 17:59:19.413802 44362 net.cpp:150] Setting up relu61
I0712 17:59:19.413832 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:19.413841 44362 net.cpp:165] Memory required for data: 7909268704
I0712 17:59:19.413851 44362 layer_factory.hpp:76] Creating layer conv62
I0712 17:59:19.413875 44362 net.cpp:106] Creating Layer conv62
I0712 17:59:19.413884 44362 net.cpp:454] conv62 <- conv61
I0712 17:59:19.413899 44362 net.cpp:411] conv62 -> conv62
I0712 17:59:19.416797 44362 net.cpp:150] Setting up conv62
I0712 17:59:19.416823 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:19.416833 44362 net.cpp:165] Memory required for data: 7915922656
I0712 17:59:19.416846 44362 layer_factory.hpp:76] Creating layer relu62
I0712 17:59:19.416859 44362 net.cpp:106] Creating Layer relu62
I0712 17:59:19.416868 44362 net.cpp:454] relu62 <- conv62
I0712 17:59:19.416879 44362 net.cpp:397] relu62 -> conv62 (in-place)
I0712 17:59:19.417279 44362 net.cpp:150] Setting up relu62
I0712 17:59:19.417322 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:19.417331 44362 net.cpp:165] Memory required for data: 7922576608
I0712 17:59:19.417340 44362 layer_factory.hpp:76] Creating layer conv63
I0712 17:59:19.417356 44362 net.cpp:106] Creating Layer conv63
I0712 17:59:19.417377 44362 net.cpp:454] conv63 <- conv62
I0712 17:59:19.417390 44362 net.cpp:411] conv63 -> conv63
I0712 17:59:19.419051 44362 net.cpp:150] Setting up conv63
I0712 17:59:19.419085 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:19.419095 44362 net.cpp:165] Memory required for data: 7929230560
I0712 17:59:19.419106 44362 layer_factory.hpp:76] Creating layer relu63
I0712 17:59:19.419122 44362 net.cpp:106] Creating Layer relu63
I0712 17:59:19.419131 44362 net.cpp:454] relu63 <- conv63
I0712 17:59:19.419183 44362 net.cpp:397] relu63 -> conv63 (in-place)
I0712 17:59:19.419409 44362 net.cpp:150] Setting up relu63
I0712 17:59:19.419426 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:19.419447 44362 net.cpp:165] Memory required for data: 7935884512
I0712 17:59:19.419456 44362 layer_factory.hpp:76] Creating layer pool5
I0712 17:59:19.419472 44362 net.cpp:106] Creating Layer pool5
I0712 17:59:19.419481 44362 net.cpp:454] pool5 <- conv63
I0712 17:59:19.419492 44362 net.cpp:411] pool5 -> pool5
I0712 17:59:19.419895 44362 net.cpp:150] Setting up pool5
I0712 17:59:19.419926 44362 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0712 17:59:19.419947 44362 net.cpp:165] Memory required for data: 7937606880
I0712 17:59:19.419955 44362 layer_factory.hpp:76] Creating layer conv71
I0712 17:59:19.419971 44362 net.cpp:106] Creating Layer conv71
I0712 17:59:19.419981 44362 net.cpp:454] conv71 <- pool5
I0712 17:59:19.419993 44362 net.cpp:411] conv71 -> conv71
I0712 17:59:19.421697 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 17:59:19.421749 44362 net.cpp:150] Setting up conv71
I0712 17:59:19.421762 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:19.421772 44362 net.cpp:165] Memory required for data: 7941051616
I0712 17:59:19.421787 44362 layer_factory.hpp:76] Creating layer relu71
I0712 17:59:19.421798 44362 net.cpp:106] Creating Layer relu71
I0712 17:59:19.421808 44362 net.cpp:454] relu71 <- conv71
I0712 17:59:19.421824 44362 net.cpp:397] relu71 -> conv71 (in-place)
I0712 17:59:19.422058 44362 net.cpp:150] Setting up relu71
I0712 17:59:19.422086 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:19.422094 44362 net.cpp:165] Memory required for data: 7944496352
I0712 17:59:19.422103 44362 layer_factory.hpp:76] Creating layer conv72
I0712 17:59:19.422119 44362 net.cpp:106] Creating Layer conv72
I0712 17:59:19.422128 44362 net.cpp:454] conv72 <- conv71
I0712 17:59:19.422142 44362 net.cpp:411] conv72 -> conv72
I0712 17:59:19.425186 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:19.425236 44362 net.cpp:150] Setting up conv72
I0712 17:59:19.425251 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:19.425259 44362 net.cpp:165] Memory required for data: 7947941088
I0712 17:59:19.425281 44362 layer_factory.hpp:76] Creating layer relu72
I0712 17:59:19.425310 44362 net.cpp:106] Creating Layer relu72
I0712 17:59:19.425319 44362 net.cpp:454] relu72 <- conv72
I0712 17:59:19.425329 44362 net.cpp:397] relu72 -> conv72 (in-place)
I0712 17:59:19.425566 44362 net.cpp:150] Setting up relu72
I0712 17:59:19.425593 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:19.425602 44362 net.cpp:165] Memory required for data: 7951385824
I0712 17:59:19.425611 44362 layer_factory.hpp:76] Creating layer conv73
I0712 17:59:19.425631 44362 net.cpp:106] Creating Layer conv73
I0712 17:59:19.425640 44362 net.cpp:454] conv73 <- conv72
I0712 17:59:19.425653 44362 net.cpp:411] conv73 -> conv73
I0712 17:59:19.428648 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:19.428694 44362 net.cpp:150] Setting up conv73
I0712 17:59:19.428742 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:19.428755 44362 net.cpp:165] Memory required for data: 7954830560
I0712 17:59:19.428767 44362 layer_factory.hpp:76] Creating layer relu73
I0712 17:59:19.428779 44362 net.cpp:106] Creating Layer relu73
I0712 17:59:19.428788 44362 net.cpp:454] relu73 <- conv73
I0712 17:59:19.428798 44362 net.cpp:397] relu73 -> conv73 (in-place)
I0712 17:59:19.429163 44362 net.cpp:150] Setting up relu73
I0712 17:59:19.429194 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:19.429204 44362 net.cpp:165] Memory required for data: 7958275296
I0712 17:59:19.429213 44362 layer_factory.hpp:76] Creating layer pool6
I0712 17:59:19.429224 44362 net.cpp:106] Creating Layer pool6
I0712 17:59:19.429234 44362 net.cpp:454] pool6 <- conv73
I0712 17:59:19.429244 44362 net.cpp:411] pool6 -> pool6
I0712 17:59:19.429467 44362 net.cpp:150] Setting up pool6
I0712 17:59:19.429525 44362 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 17:59:19.429535 44362 net.cpp:165] Memory required for data: 7959196896
I0712 17:59:19.429544 44362 layer_factory.hpp:76] Creating layer drop0
I0712 17:59:19.429563 44362 net.cpp:106] Creating Layer drop0
I0712 17:59:19.429572 44362 net.cpp:454] drop0 <- pool6
I0712 17:59:19.429582 44362 net.cpp:397] drop0 -> pool6 (in-place)
I0712 17:59:19.429626 44362 net.cpp:150] Setting up drop0
I0712 17:59:19.429641 44362 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 17:59:19.429648 44362 net.cpp:165] Memory required for data: 7960118496
I0712 17:59:19.429656 44362 layer_factory.hpp:76] Creating layer conv81
I0712 17:59:19.429674 44362 net.cpp:106] Creating Layer conv81
I0712 17:59:19.429683 44362 net.cpp:454] conv81 <- pool6
I0712 17:59:19.429697 44362 net.cpp:411] conv81 -> conv81
I0712 17:59:19.431459 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345600
I0712 17:59:19.431710 44362 net.cpp:150] Setting up conv81
I0712 17:59:19.431743 44362 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 17:59:19.431753 44362 net.cpp:165] Memory required for data: 7960118592
I0712 17:59:19.431766 44362 layer_factory.hpp:76] Creating layer conv81_conv81_0_split
I0712 17:59:19.431777 44362 net.cpp:106] Creating Layer conv81_conv81_0_split
I0712 17:59:19.431785 44362 net.cpp:454] conv81_conv81_0_split <- conv81
I0712 17:59:19.431797 44362 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_0
I0712 17:59:19.431807 44362 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_1
I0712 17:59:19.431864 44362 net.cpp:150] Setting up conv81_conv81_0_split
I0712 17:59:19.431877 44362 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 17:59:19.431886 44362 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 17:59:19.431895 44362 net.cpp:165] Memory required for data: 7960118784
I0712 17:59:19.431902 44362 layer_factory.hpp:76] Creating layer accuracy
I0712 17:59:19.444496 44362 net.cpp:106] Creating Layer accuracy
I0712 17:59:19.444519 44362 net.cpp:454] accuracy <- conv81_conv81_0_split_0
I0712 17:59:19.444538 44362 net.cpp:454] accuracy <- label_data_1_split_0
I0712 17:59:19.444545 44362 net.cpp:411] accuracy -> accuracy
I0712 17:59:19.444571 44362 net.cpp:150] Setting up accuracy
I0712 17:59:19.444579 44362 net.cpp:157] Top shape: (1)
I0712 17:59:19.444583 44362 net.cpp:165] Memory required for data: 7960118788
I0712 17:59:19.444588 44362 layer_factory.hpp:76] Creating layer loss
I0712 17:59:19.444598 44362 net.cpp:106] Creating Layer loss
I0712 17:59:19.444603 44362 net.cpp:454] loss <- conv81_conv81_0_split_1
I0712 17:59:19.444608 44362 net.cpp:454] loss <- label_data_1_split_1
I0712 17:59:19.444614 44362 net.cpp:411] loss -> loss
I0712 17:59:19.444629 44362 layer_factory.hpp:76] Creating layer loss
I0712 17:59:19.445286 44362 net.cpp:150] Setting up loss
I0712 17:59:19.445299 44362 net.cpp:157] Top shape: (1)
I0712 17:59:19.445303 44362 net.cpp:160]     with loss weight 1
I0712 17:59:19.445931 44362 net.cpp:165] Memory required for data: 7960118792
I0712 17:59:19.445940 44362 net.cpp:226] loss needs backward computation.
I0712 17:59:19.445945 44362 net.cpp:228] accuracy does not need backward computation.
I0712 17:59:19.445951 44362 net.cpp:226] conv81_conv81_0_split needs backward computation.
I0712 17:59:19.445955 44362 net.cpp:226] conv81 needs backward computation.
I0712 17:59:19.445960 44362 net.cpp:226] drop0 needs backward computation.
I0712 17:59:19.445965 44362 net.cpp:226] pool6 needs backward computation.
I0712 17:59:19.445969 44362 net.cpp:226] relu73 needs backward computation.
I0712 17:59:19.445973 44362 net.cpp:226] conv73 needs backward computation.
I0712 17:59:19.445989 44362 net.cpp:226] relu72 needs backward computation.
I0712 17:59:19.445993 44362 net.cpp:226] conv72 needs backward computation.
I0712 17:59:19.445997 44362 net.cpp:226] relu71 needs backward computation.
I0712 17:59:19.446002 44362 net.cpp:226] conv71 needs backward computation.
I0712 17:59:19.446007 44362 net.cpp:226] pool5 needs backward computation.
I0712 17:59:19.446036 44362 net.cpp:226] relu63 needs backward computation.
I0712 17:59:19.446044 44362 net.cpp:226] conv63 needs backward computation.
I0712 17:59:19.446049 44362 net.cpp:226] relu62 needs backward computation.
I0712 17:59:19.446053 44362 net.cpp:226] conv62 needs backward computation.
I0712 17:59:19.446058 44362 net.cpp:226] relu61 needs backward computation.
I0712 17:59:19.446061 44362 net.cpp:226] conv61 needs backward computation.
I0712 17:59:19.446066 44362 net.cpp:226] interloss needs backward computation.
I0712 17:59:19.446071 44362 net.cpp:226] conv54 needs backward computation.
I0712 17:59:19.446076 44362 net.cpp:228] relu53 does not need backward computation.
I0712 17:59:19.446080 44362 net.cpp:228] conv53 does not need backward computation.
I0712 17:59:19.446085 44362 net.cpp:228] relu52 does not need backward computation.
I0712 17:59:19.446089 44362 net.cpp:228] conv52 does not need backward computation.
I0712 17:59:19.446094 44362 net.cpp:228] relu51 does not need backward computation.
I0712 17:59:19.446099 44362 net.cpp:228] conv51 does not need backward computation.
I0712 17:59:19.446104 44362 net.cpp:228] pool4 does not need backward computation.
I0712 17:59:19.446108 44362 net.cpp:228] relu42 does not need backward computation.
I0712 17:59:19.446112 44362 net.cpp:228] conv42 does not need backward computation.
I0712 17:59:19.446117 44362 net.cpp:228] relu41 does not need backward computation.
I0712 17:59:19.446122 44362 net.cpp:228] conv41 does not need backward computation.
I0712 17:59:19.446127 44362 net.cpp:228] pool3 does not need backward computation.
I0712 17:59:19.446131 44362 net.cpp:228] relu32 does not need backward computation.
I0712 17:59:19.446136 44362 net.cpp:228] conv32 does not need backward computation.
I0712 17:59:19.446141 44362 net.cpp:228] relu31 does not need backward computation.
I0712 17:59:19.446146 44362 net.cpp:228] conv31 does not need backward computation.
I0712 17:59:19.446151 44362 net.cpp:228] pool2 does not need backward computation.
I0712 17:59:19.446156 44362 net.cpp:228] relu22 does not need backward computation.
I0712 17:59:19.446161 44362 net.cpp:228] conv22 does not need backward computation.
I0712 17:59:19.446166 44362 net.cpp:228] relu21 does not need backward computation.
I0712 17:59:19.446169 44362 net.cpp:228] conv21 does not need backward computation.
I0712 17:59:19.446174 44362 net.cpp:228] pool1 does not need backward computation.
I0712 17:59:19.446179 44362 net.cpp:228] relu12 does not need backward computation.
I0712 17:59:19.446184 44362 net.cpp:228] conv12 does not need backward computation.
I0712 17:59:19.446188 44362 net.cpp:228] relu11 does not need backward computation.
I0712 17:59:19.446193 44362 net.cpp:228] conv11 does not need backward computation.
I0712 17:59:19.446198 44362 net.cpp:228] label_data_1_split does not need backward computation.
I0712 17:59:19.446208 44362 net.cpp:228] data does not need backward computation.
I0712 17:59:19.446211 44362 net.cpp:270] This network produces output accuracy
I0712 17:59:19.446216 44362 net.cpp:270] This network produces output loss
I0712 17:59:19.446254 44362 net.cpp:283] Network initialization done.
I0712 17:59:19.485121 44362 solver.cpp:180] Creating test net (#0) specified by net file: train_val-resultlayer.prototxt
I0712 17:59:19.485240 44362 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0712 17:59:19.485571 44362 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "conv53"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv54"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "conv63"
  type: "Convolution"
  bottom: "conv62"
  top: "conv63"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu63"
  type: "ReLU"
  bottom: "conv63"
  top: "conv63"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv63"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "conv73"
  type: "Convolution"
  bottom: "conv72"
  top: "conv73"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu73"
  type: "ReLU"
  bottom: "conv73"
  top: "conv73"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv73"
  top: "pool6"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool6"
  top: "pool6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 15
    kernel_w: 15
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv81"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv81"
  bottom: "label"
  top: "loss"
}
I0712 17:59:19.488116 44362 layer_factory.hpp:76] Creating layer data
I0712 17:59:19.488157 44362 net.cpp:106] Creating Layer data
I0712 17:59:19.488168 44362 net.cpp:411] data -> data
I0712 17:59:19.488185 44362 net.cpp:411] data -> label
I0712 17:59:19.488203 44362 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0712 17:59:19.490114 44362 image_data_layer.cpp:46] Shuffling data
I0712 17:59:19.490367 44362 image_data_layer.cpp:51] A total of 2617 images.
I0712 17:59:19.596784 44362 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0712 17:59:19.843232 44362 net.cpp:150] Setting up data
I0712 17:59:19.843288 44362 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0712 17:59:19.843302 44362 net.cpp:157] Top shape: 8 (8)
I0712 17:59:19.843310 44362 net.cpp:165] Memory required for data: 96000032
I0712 17:59:19.843324 44362 layer_factory.hpp:76] Creating layer label_data_1_split
I0712 17:59:19.843355 44362 net.cpp:106] Creating Layer label_data_1_split
I0712 17:59:19.843367 44362 net.cpp:454] label_data_1_split <- label
I0712 17:59:19.843381 44362 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0712 17:59:19.843397 44362 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0712 17:59:19.843479 44362 net.cpp:150] Setting up label_data_1_split
I0712 17:59:19.843504 44362 net.cpp:157] Top shape: 8 (8)
I0712 17:59:19.843515 44362 net.cpp:157] Top shape: 8 (8)
I0712 17:59:19.843524 44362 net.cpp:165] Memory required for data: 96000096
I0712 17:59:19.843533 44362 layer_factory.hpp:76] Creating layer conv11
I0712 17:59:19.843552 44362 net.cpp:106] Creating Layer conv11
I0712 17:59:19.843561 44362 net.cpp:454] conv11 <- data
I0712 17:59:19.843576 44362 net.cpp:411] conv11 -> conv11
I0712 17:59:19.854979 44362 net.cpp:150] Setting up conv11
I0712 17:59:19.855005 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.855017 44362 net.cpp:165] Memory required for data: 1120000096
I0712 17:59:19.855033 44362 layer_factory.hpp:76] Creating layer relu11
I0712 17:59:19.855047 44362 net.cpp:106] Creating Layer relu11
I0712 17:59:19.855057 44362 net.cpp:454] relu11 <- conv11
I0712 17:59:19.855067 44362 net.cpp:397] relu11 -> conv11 (in-place)
I0712 17:59:19.855389 44362 net.cpp:150] Setting up relu11
I0712 17:59:19.855411 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.855419 44362 net.cpp:165] Memory required for data: 2144000096
I0712 17:59:19.855428 44362 layer_factory.hpp:76] Creating layer conv12
I0712 17:59:19.855448 44362 net.cpp:106] Creating Layer conv12
I0712 17:59:19.855456 44362 net.cpp:454] conv12 <- conv11
I0712 17:59:19.855468 44362 net.cpp:411] conv12 -> conv12
I0712 17:59:19.867619 44362 net.cpp:150] Setting up conv12
I0712 17:59:19.867650 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.867661 44362 net.cpp:165] Memory required for data: 3168000096
I0712 17:59:19.867707 44362 layer_factory.hpp:76] Creating layer relu12
I0712 17:59:19.867722 44362 net.cpp:106] Creating Layer relu12
I0712 17:59:19.867735 44362 net.cpp:454] relu12 <- conv12
I0712 17:59:19.867746 44362 net.cpp:397] relu12 -> conv12 (in-place)
I0712 17:59:19.867954 44362 net.cpp:150] Setting up relu12
I0712 17:59:19.867972 44362 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 17:59:19.867981 44362 net.cpp:165] Memory required for data: 4192000096
I0712 17:59:19.867990 44362 layer_factory.hpp:76] Creating layer pool1
I0712 17:59:19.868002 44362 net.cpp:106] Creating Layer pool1
I0712 17:59:19.868010 44362 net.cpp:454] pool1 <- conv12
I0712 17:59:19.868021 44362 net.cpp:411] pool1 -> pool1
I0712 17:59:19.871953 44362 net.cpp:150] Setting up pool1
I0712 17:59:19.871974 44362 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0712 17:59:19.871984 44362 net.cpp:165] Memory required for data: 4448000096
I0712 17:59:19.871991 44362 layer_factory.hpp:76] Creating layer conv21
I0712 17:59:19.872007 44362 net.cpp:106] Creating Layer conv21
I0712 17:59:19.872016 44362 net.cpp:454] conv21 <- pool1
I0712 17:59:19.872028 44362 net.cpp:411] conv21 -> conv21
I0712 17:59:19.879159 44362 net.cpp:150] Setting up conv21
I0712 17:59:19.879184 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.879194 44362 net.cpp:165] Memory required for data: 4960000096
I0712 17:59:19.879209 44362 layer_factory.hpp:76] Creating layer relu21
I0712 17:59:19.879226 44362 net.cpp:106] Creating Layer relu21
I0712 17:59:19.879235 44362 net.cpp:454] relu21 <- conv21
I0712 17:59:19.879245 44362 net.cpp:397] relu21 -> conv21 (in-place)
I0712 17:59:19.880590 44362 net.cpp:150] Setting up relu21
I0712 17:59:19.880609 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.880617 44362 net.cpp:165] Memory required for data: 5472000096
I0712 17:59:19.880625 44362 layer_factory.hpp:76] Creating layer conv22
I0712 17:59:19.880642 44362 net.cpp:106] Creating Layer conv22
I0712 17:59:19.880650 44362 net.cpp:454] conv22 <- conv21
I0712 17:59:19.880661 44362 net.cpp:411] conv22 -> conv22
I0712 17:59:19.887051 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 17:59:19.887094 44362 net.cpp:150] Setting up conv22
I0712 17:59:19.887109 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.887117 44362 net.cpp:165] Memory required for data: 5984000096
I0712 17:59:19.887128 44362 layer_factory.hpp:76] Creating layer relu22
I0712 17:59:19.887141 44362 net.cpp:106] Creating Layer relu22
I0712 17:59:19.887150 44362 net.cpp:454] relu22 <- conv22
I0712 17:59:19.887161 44362 net.cpp:397] relu22 -> conv22 (in-place)
I0712 17:59:19.889161 44362 net.cpp:150] Setting up relu22
I0712 17:59:19.889183 44362 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 17:59:19.889191 44362 net.cpp:165] Memory required for data: 6496000096
I0712 17:59:19.889200 44362 layer_factory.hpp:76] Creating layer pool2
I0712 17:59:19.889215 44362 net.cpp:106] Creating Layer pool2
I0712 17:59:19.889224 44362 net.cpp:454] pool2 <- conv22
I0712 17:59:19.889235 44362 net.cpp:411] pool2 -> pool2
I0712 17:59:19.891680 44362 net.cpp:150] Setting up pool2
I0712 17:59:19.891698 44362 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0712 17:59:19.891706 44362 net.cpp:165] Memory required for data: 6624000096
I0712 17:59:19.891715 44362 layer_factory.hpp:76] Creating layer conv31
I0712 17:59:19.891729 44362 net.cpp:106] Creating Layer conv31
I0712 17:59:19.891737 44362 net.cpp:454] conv31 <- pool2
I0712 17:59:19.891749 44362 net.cpp:411] conv31 -> conv31
I0712 17:59:19.917548 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 17:59:19.917589 44362 net.cpp:150] Setting up conv31
I0712 17:59:19.917598 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.917603 44362 net.cpp:165] Memory required for data: 6816000096
I0712 17:59:19.917618 44362 layer_factory.hpp:76] Creating layer relu31
I0712 17:59:19.917626 44362 net.cpp:106] Creating Layer relu31
I0712 17:59:19.917656 44362 net.cpp:454] relu31 <- conv31
I0712 17:59:19.917665 44362 net.cpp:397] relu31 -> conv31 (in-place)
I0712 17:59:19.920228 44362 net.cpp:150] Setting up relu31
I0712 17:59:19.920239 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.920244 44362 net.cpp:165] Memory required for data: 7008000096
I0712 17:59:19.920249 44362 layer_factory.hpp:76] Creating layer conv32
I0712 17:59:19.920259 44362 net.cpp:106] Creating Layer conv32
I0712 17:59:19.920264 44362 net.cpp:454] conv32 <- conv31
I0712 17:59:19.920271 44362 net.cpp:411] conv32 -> conv32
I0712 17:59:19.926877 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 17:59:19.926923 44362 net.cpp:150] Setting up conv32
I0712 17:59:19.926935 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.926944 44362 net.cpp:165] Memory required for data: 7200000096
I0712 17:59:19.926957 44362 layer_factory.hpp:76] Creating layer relu32
I0712 17:59:19.926970 44362 net.cpp:106] Creating Layer relu32
I0712 17:59:19.926978 44362 net.cpp:454] relu32 <- conv32
I0712 17:59:19.926990 44362 net.cpp:397] relu32 -> conv32 (in-place)
I0712 17:59:19.928211 44362 net.cpp:150] Setting up relu32
I0712 17:59:19.928233 44362 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 17:59:19.928242 44362 net.cpp:165] Memory required for data: 7392000096
I0712 17:59:19.928251 44362 layer_factory.hpp:76] Creating layer pool3
I0712 17:59:19.928269 44362 net.cpp:106] Creating Layer pool3
I0712 17:59:19.928278 44362 net.cpp:454] pool3 <- conv32
I0712 17:59:19.928290 44362 net.cpp:411] pool3 -> pool3
I0712 17:59:19.929443 44362 net.cpp:150] Setting up pool3
I0712 17:59:19.929461 44362 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0712 17:59:19.929471 44362 net.cpp:165] Memory required for data: 7440000096
I0712 17:59:19.929478 44362 layer_factory.hpp:76] Creating layer conv41
I0712 17:59:19.929497 44362 net.cpp:106] Creating Layer conv41
I0712 17:59:19.929505 44362 net.cpp:454] conv41 <- pool3
I0712 17:59:19.929517 44362 net.cpp:411] conv41 -> conv41
I0712 17:59:19.940002 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 17:59:19.940043 44362 net.cpp:150] Setting up conv41
I0712 17:59:19.940057 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.940065 44362 net.cpp:165] Memory required for data: 7504000096
I0712 17:59:19.940078 44362 layer_factory.hpp:76] Creating layer relu41
I0712 17:59:19.940093 44362 net.cpp:106] Creating Layer relu41
I0712 17:59:19.940101 44362 net.cpp:454] relu41 <- conv41
I0712 17:59:19.940114 44362 net.cpp:397] relu41 -> conv41 (in-place)
I0712 17:59:19.944097 44362 net.cpp:150] Setting up relu41
I0712 17:59:19.944118 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.944126 44362 net.cpp:165] Memory required for data: 7568000096
I0712 17:59:19.944134 44362 layer_factory.hpp:76] Creating layer conv42
I0712 17:59:19.944149 44362 net.cpp:106] Creating Layer conv42
I0712 17:59:19.944159 44362 net.cpp:454] conv42 <- conv41
I0712 17:59:19.944170 44362 net.cpp:411] conv42 -> conv42
I0712 17:59:19.953285 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:19.953326 44362 net.cpp:150] Setting up conv42
I0712 17:59:19.953339 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.953348 44362 net.cpp:165] Memory required for data: 7632000096
I0712 17:59:19.953359 44362 layer_factory.hpp:76] Creating layer relu42
I0712 17:59:19.953372 44362 net.cpp:106] Creating Layer relu42
I0712 17:59:19.953380 44362 net.cpp:454] relu42 <- conv42
I0712 17:59:19.953392 44362 net.cpp:397] relu42 -> conv42 (in-place)
I0712 17:59:19.954748 44362 net.cpp:150] Setting up relu42
I0712 17:59:19.954768 44362 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 17:59:19.954777 44362 net.cpp:165] Memory required for data: 7696000096
I0712 17:59:19.954785 44362 layer_factory.hpp:76] Creating layer pool4
I0712 17:59:19.954798 44362 net.cpp:106] Creating Layer pool4
I0712 17:59:19.954807 44362 net.cpp:454] pool4 <- conv42
I0712 17:59:19.954839 44362 net.cpp:411] pool4 -> pool4
I0712 17:59:19.956960 44362 net.cpp:150] Setting up pool4
I0712 17:59:19.956979 44362 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0712 17:59:19.956987 44362 net.cpp:165] Memory required for data: 7712257120
I0712 17:59:19.956995 44362 layer_factory.hpp:76] Creating layer conv51
I0712 17:59:19.957010 44362 net.cpp:106] Creating Layer conv51
I0712 17:59:19.957018 44362 net.cpp:454] conv51 <- pool4
I0712 17:59:19.957029 44362 net.cpp:411] conv51 -> conv51
I0712 17:59:19.963408 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:19.963443 44362 net.cpp:150] Setting up conv51
I0712 17:59:19.963457 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.963466 44362 net.cpp:165] Memory required for data: 7744771168
I0712 17:59:19.963482 44362 layer_factory.hpp:76] Creating layer relu51
I0712 17:59:19.963495 44362 net.cpp:106] Creating Layer relu51
I0712 17:59:19.963505 44362 net.cpp:454] relu51 <- conv51
I0712 17:59:19.963515 44362 net.cpp:397] relu51 -> conv51 (in-place)
I0712 17:59:19.965821 44362 net.cpp:150] Setting up relu51
I0712 17:59:19.965840 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.965849 44362 net.cpp:165] Memory required for data: 7777285216
I0712 17:59:19.965858 44362 layer_factory.hpp:76] Creating layer conv52
I0712 17:59:19.965873 44362 net.cpp:106] Creating Layer conv52
I0712 17:59:19.965880 44362 net.cpp:454] conv52 <- conv51
I0712 17:59:19.965893 44362 net.cpp:411] conv52 -> conv52
I0712 17:59:19.977480 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 17:59:19.977516 44362 net.cpp:150] Setting up conv52
I0712 17:59:19.977530 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.977540 44362 net.cpp:165] Memory required for data: 7809799264
I0712 17:59:19.977551 44362 layer_factory.hpp:76] Creating layer relu52
I0712 17:59:19.977565 44362 net.cpp:106] Creating Layer relu52
I0712 17:59:19.977573 44362 net.cpp:454] relu52 <- conv52
I0712 17:59:19.977584 44362 net.cpp:397] relu52 -> conv52 (in-place)
I0712 17:59:19.979977 44362 net.cpp:150] Setting up relu52
I0712 17:59:19.979997 44362 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 17:59:19.980008 44362 net.cpp:165] Memory required for data: 7842313312
I0712 17:59:19.980017 44362 layer_factory.hpp:76] Creating layer conv53
I0712 17:59:19.980031 44362 net.cpp:106] Creating Layer conv53
I0712 17:59:19.980041 44362 net.cpp:454] conv53 <- conv52
I0712 17:59:19.980054 44362 net.cpp:411] conv53 -> conv53
I0712 17:59:20.017415 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0712 17:59:20.017475 44362 net.cpp:150] Setting up conv53
I0712 17:59:20.017493 44362 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 17:59:20.017503 44362 net.cpp:165] Memory required for data: 7868929120
I0712 17:59:20.017518 44362 layer_factory.hpp:76] Creating layer relu53
I0712 17:59:20.017535 44362 net.cpp:106] Creating Layer relu53
I0712 17:59:20.017547 44362 net.cpp:454] relu53 <- conv53
I0712 17:59:20.017560 44362 net.cpp:397] relu53 -> conv53 (in-place)
I0712 17:59:20.018801 44362 net.cpp:150] Setting up relu53
I0712 17:59:20.018820 44362 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 17:59:20.018827 44362 net.cpp:165] Memory required for data: 7895544928
I0712 17:59:20.018842 44362 layer_factory.hpp:76] Creating layer conv54
I0712 17:59:20.018858 44362 net.cpp:106] Creating Layer conv54
I0712 17:59:20.018867 44362 net.cpp:454] conv54 <- conv53
I0712 17:59:20.018878 44362 net.cpp:411] conv54 -> conv54
I0712 17:59:20.023525 44362 net.cpp:150] Setting up conv54
I0712 17:59:20.023547 44362 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 17:59:20.023556 44362 net.cpp:165] Memory required for data: 7895752864
I0712 17:59:20.023568 44362 layer_factory.hpp:76] Creating layer interloss
I0712 17:59:20.023581 44362 net.cpp:106] Creating Layer interloss
I0712 17:59:20.023589 44362 net.cpp:454] interloss <- conv54
I0712 17:59:20.023600 44362 net.cpp:411] interloss -> interloss
I0712 17:59:20.024184 44362 net.cpp:150] Setting up interloss
I0712 17:59:20.024235 44362 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 17:59:20.024245 44362 net.cpp:165] Memory required for data: 7895960800
I0712 17:59:20.024252 44362 layer_factory.hpp:76] Creating layer conv61
I0712 17:59:20.024268 44362 net.cpp:106] Creating Layer conv61
I0712 17:59:20.024277 44362 net.cpp:454] conv61 <- interloss
I0712 17:59:20.024289 44362 net.cpp:411] conv61 -> conv61
I0712 17:59:20.027477 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5614272
I0712 17:59:20.027693 44362 net.cpp:150] Setting up conv61
I0712 17:59:20.027712 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:20.027721 44362 net.cpp:165] Memory required for data: 7902614752
I0712 17:59:20.027734 44362 layer_factory.hpp:76] Creating layer relu61
I0712 17:59:20.027745 44362 net.cpp:106] Creating Layer relu61
I0712 17:59:20.027755 44362 net.cpp:454] relu61 <- conv61
I0712 17:59:20.027765 44362 net.cpp:397] relu61 -> conv61 (in-place)
I0712 17:59:20.027954 44362 net.cpp:150] Setting up relu61
I0712 17:59:20.027971 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:20.027979 44362 net.cpp:165] Memory required for data: 7909268704
I0712 17:59:20.027987 44362 layer_factory.hpp:76] Creating layer conv62
I0712 17:59:20.028007 44362 net.cpp:106] Creating Layer conv62
I0712 17:59:20.028015 44362 net.cpp:454] conv62 <- conv61
I0712 17:59:20.028028 44362 net.cpp:411] conv62 -> conv62
I0712 17:59:20.029541 44362 net.cpp:150] Setting up conv62
I0712 17:59:20.029567 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:20.029577 44362 net.cpp:165] Memory required for data: 7915922656
I0712 17:59:20.029588 44362 layer_factory.hpp:76] Creating layer relu62
I0712 17:59:20.029602 44362 net.cpp:106] Creating Layer relu62
I0712 17:59:20.029610 44362 net.cpp:454] relu62 <- conv62
I0712 17:59:20.029620 44362 net.cpp:397] relu62 -> conv62 (in-place)
I0712 17:59:20.029804 44362 net.cpp:150] Setting up relu62
I0712 17:59:20.029821 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:20.029834 44362 net.cpp:165] Memory required for data: 7922576608
I0712 17:59:20.029841 44362 layer_factory.hpp:76] Creating layer conv63
I0712 17:59:20.029855 44362 net.cpp:106] Creating Layer conv63
I0712 17:59:20.029863 44362 net.cpp:454] conv63 <- conv62
I0712 17:59:20.029875 44362 net.cpp:411] conv63 -> conv63
I0712 17:59:20.033130 44362 net.cpp:150] Setting up conv63
I0712 17:59:20.033157 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:20.033171 44362 net.cpp:165] Memory required for data: 7929230560
I0712 17:59:20.033184 44362 layer_factory.hpp:76] Creating layer relu63
I0712 17:59:20.033196 44362 net.cpp:106] Creating Layer relu63
I0712 17:59:20.033206 44362 net.cpp:454] relu63 <- conv63
I0712 17:59:20.033217 44362 net.cpp:397] relu63 -> conv63 (in-place)
I0712 17:59:20.034554 44362 net.cpp:150] Setting up relu63
I0712 17:59:20.034575 44362 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 17:59:20.034585 44362 net.cpp:165] Memory required for data: 7935884512
I0712 17:59:20.034595 44362 layer_factory.hpp:76] Creating layer pool5
I0712 17:59:20.034607 44362 net.cpp:106] Creating Layer pool5
I0712 17:59:20.034615 44362 net.cpp:454] pool5 <- conv63
I0712 17:59:20.034633 44362 net.cpp:411] pool5 -> pool5
I0712 17:59:20.036133 44362 net.cpp:150] Setting up pool5
I0712 17:59:20.036151 44362 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0712 17:59:20.036160 44362 net.cpp:165] Memory required for data: 7937606880
I0712 17:59:20.036173 44362 layer_factory.hpp:76] Creating layer conv71
I0712 17:59:20.036186 44362 net.cpp:106] Creating Layer conv71
I0712 17:59:20.036195 44362 net.cpp:454] conv71 <- pool5
I0712 17:59:20.036208 44362 net.cpp:411] conv71 -> conv71
I0712 17:59:20.040876 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 17:59:20.040922 44362 net.cpp:150] Setting up conv71
I0712 17:59:20.040936 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:20.040946 44362 net.cpp:165] Memory required for data: 7941051616
I0712 17:59:20.040958 44362 layer_factory.hpp:76] Creating layer relu71
I0712 17:59:20.040999 44362 net.cpp:106] Creating Layer relu71
I0712 17:59:20.041010 44362 net.cpp:454] relu71 <- conv71
I0712 17:59:20.041021 44362 net.cpp:397] relu71 -> conv71 (in-place)
I0712 17:59:20.042321 44362 net.cpp:150] Setting up relu71
I0712 17:59:20.042343 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:20.042352 44362 net.cpp:165] Memory required for data: 7944496352
I0712 17:59:20.042362 44362 layer_factory.hpp:76] Creating layer conv72
I0712 17:59:20.042378 44362 net.cpp:106] Creating Layer conv72
I0712 17:59:20.042387 44362 net.cpp:454] conv72 <- conv71
I0712 17:59:20.042400 44362 net.cpp:411] conv72 -> conv72
I0712 17:59:20.047070 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:20.047121 44362 net.cpp:150] Setting up conv72
I0712 17:59:20.047133 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:20.047142 44362 net.cpp:165] Memory required for data: 7947941088
I0712 17:59:20.047165 44362 layer_factory.hpp:76] Creating layer relu72
I0712 17:59:20.047178 44362 net.cpp:106] Creating Layer relu72
I0712 17:59:20.047188 44362 net.cpp:454] relu72 <- conv72
I0712 17:59:20.047199 44362 net.cpp:397] relu72 -> conv72 (in-place)
I0712 17:59:20.048506 44362 net.cpp:150] Setting up relu72
I0712 17:59:20.048527 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:20.048538 44362 net.cpp:165] Memory required for data: 7951385824
I0712 17:59:20.048547 44362 layer_factory.hpp:76] Creating layer conv73
I0712 17:59:20.048563 44362 net.cpp:106] Creating Layer conv73
I0712 17:59:20.048580 44362 net.cpp:454] conv73 <- conv72
I0712 17:59:20.048593 44362 net.cpp:411] conv73 -> conv73
I0712 17:59:20.051707 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 17:59:20.051746 44362 net.cpp:150] Setting up conv73
I0712 17:59:20.051762 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:20.051771 44362 net.cpp:165] Memory required for data: 7954830560
I0712 17:59:20.051784 44362 layer_factory.hpp:76] Creating layer relu73
I0712 17:59:20.051795 44362 net.cpp:106] Creating Layer relu73
I0712 17:59:20.051805 44362 net.cpp:454] relu73 <- conv73
I0712 17:59:20.051815 44362 net.cpp:397] relu73 -> conv73 (in-place)
I0712 17:59:20.052745 44362 net.cpp:150] Setting up relu73
I0712 17:59:20.052764 44362 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 17:59:20.052775 44362 net.cpp:165] Memory required for data: 7958275296
I0712 17:59:20.052784 44362 layer_factory.hpp:76] Creating layer pool6
I0712 17:59:20.052795 44362 net.cpp:106] Creating Layer pool6
I0712 17:59:20.052804 44362 net.cpp:454] pool6 <- conv73
I0712 17:59:20.052819 44362 net.cpp:411] pool6 -> pool6
I0712 17:59:20.053198 44362 net.cpp:150] Setting up pool6
I0712 17:59:20.053218 44362 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 17:59:20.053230 44362 net.cpp:165] Memory required for data: 7959196896
I0712 17:59:20.053238 44362 layer_factory.hpp:76] Creating layer drop0
I0712 17:59:20.053251 44362 net.cpp:106] Creating Layer drop0
I0712 17:59:20.053267 44362 net.cpp:454] drop0 <- pool6
I0712 17:59:20.053279 44362 net.cpp:397] drop0 -> pool6 (in-place)
I0712 17:59:20.053321 44362 net.cpp:150] Setting up drop0
I0712 17:59:20.053334 44362 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 17:59:20.053342 44362 net.cpp:165] Memory required for data: 7960118496
I0712 17:59:20.053350 44362 layer_factory.hpp:76] Creating layer conv81
I0712 17:59:20.053366 44362 net.cpp:106] Creating Layer conv81
I0712 17:59:20.053376 44362 net.cpp:454] conv81 <- pool6
I0712 17:59:20.053386 44362 net.cpp:411] conv81 -> conv81
I0712 17:59:20.055548 44362 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345600
I0712 17:59:20.055589 44362 net.cpp:150] Setting up conv81
I0712 17:59:20.055603 44362 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 17:59:20.055611 44362 net.cpp:165] Memory required for data: 7960118592
I0712 17:59:20.055624 44362 layer_factory.hpp:76] Creating layer conv81_conv81_0_split
I0712 17:59:20.055639 44362 net.cpp:106] Creating Layer conv81_conv81_0_split
I0712 17:59:20.055673 44362 net.cpp:454] conv81_conv81_0_split <- conv81
I0712 17:59:20.055693 44362 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_0
I0712 17:59:20.055706 44362 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_1
I0712 17:59:20.055765 44362 net.cpp:150] Setting up conv81_conv81_0_split
I0712 17:59:20.055778 44362 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 17:59:20.055788 44362 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 17:59:20.055795 44362 net.cpp:165] Memory required for data: 7960118784
I0712 17:59:20.055804 44362 layer_factory.hpp:76] Creating layer accuracy
I0712 17:59:20.055815 44362 net.cpp:106] Creating Layer accuracy
I0712 17:59:20.055824 44362 net.cpp:454] accuracy <- conv81_conv81_0_split_0
I0712 17:59:20.055837 44362 net.cpp:454] accuracy <- label_data_1_split_0
I0712 17:59:20.055850 44362 net.cpp:411] accuracy -> accuracy
I0712 17:59:20.055866 44362 net.cpp:150] Setting up accuracy
I0712 17:59:20.055876 44362 net.cpp:157] Top shape: (1)
I0712 17:59:20.055884 44362 net.cpp:165] Memory required for data: 7960118788
I0712 17:59:20.055892 44362 layer_factory.hpp:76] Creating layer loss
I0712 17:59:20.055903 44362 net.cpp:106] Creating Layer loss
I0712 17:59:20.055912 44362 net.cpp:454] loss <- conv81_conv81_0_split_1
I0712 17:59:20.055927 44362 net.cpp:454] loss <- label_data_1_split_1
I0712 17:59:20.055937 44362 net.cpp:411] loss -> loss
I0712 17:59:20.055948 44362 layer_factory.hpp:76] Creating layer loss
I0712 17:59:20.056264 44362 net.cpp:150] Setting up loss
I0712 17:59:20.056285 44362 net.cpp:157] Top shape: (1)
I0712 17:59:20.056298 44362 net.cpp:160]     with loss weight 1
I0712 17:59:20.056318 44362 net.cpp:165] Memory required for data: 7960118792
I0712 17:59:20.056327 44362 net.cpp:226] loss needs backward computation.
I0712 17:59:20.056336 44362 net.cpp:228] accuracy does not need backward computation.
I0712 17:59:20.056346 44362 net.cpp:226] conv81_conv81_0_split needs backward computation.
I0712 17:59:20.056355 44362 net.cpp:226] conv81 needs backward computation.
I0712 17:59:20.056363 44362 net.cpp:226] drop0 needs backward computation.
I0712 17:59:20.056371 44362 net.cpp:226] pool6 needs backward computation.
I0712 17:59:20.056380 44362 net.cpp:226] relu73 needs backward computation.
I0712 17:59:20.056387 44362 net.cpp:226] conv73 needs backward computation.
I0712 17:59:20.056396 44362 net.cpp:226] relu72 needs backward computation.
I0712 17:59:20.056403 44362 net.cpp:226] conv72 needs backward computation.
I0712 17:59:20.056416 44362 net.cpp:226] relu71 needs backward computation.
I0712 17:59:20.056423 44362 net.cpp:226] conv71 needs backward computation.
I0712 17:59:20.056434 44362 net.cpp:226] pool5 needs backward computation.
I0712 17:59:20.056442 44362 net.cpp:226] relu63 needs backward computation.
I0712 17:59:20.056450 44362 net.cpp:226] conv63 needs backward computation.
I0712 17:59:20.056459 44362 net.cpp:226] relu62 needs backward computation.
I0712 17:59:20.056468 44362 net.cpp:226] conv62 needs backward computation.
I0712 17:59:20.056479 44362 net.cpp:226] relu61 needs backward computation.
I0712 17:59:20.056488 44362 net.cpp:226] conv61 needs backward computation.
I0712 17:59:20.056499 44362 net.cpp:226] interloss needs backward computation.
I0712 17:59:20.056507 44362 net.cpp:226] conv54 needs backward computation.
I0712 17:59:20.056515 44362 net.cpp:228] relu53 does not need backward computation.
I0712 17:59:20.056524 44362 net.cpp:228] conv53 does not need backward computation.
I0712 17:59:20.056534 44362 net.cpp:228] relu52 does not need backward computation.
I0712 17:59:20.056541 44362 net.cpp:228] conv52 does not need backward computation.
I0712 17:59:20.056550 44362 net.cpp:228] relu51 does not need backward computation.
I0712 17:59:20.056561 44362 net.cpp:228] conv51 does not need backward computation.
I0712 17:59:20.056569 44362 net.cpp:228] pool4 does not need backward computation.
I0712 17:59:20.056581 44362 net.cpp:228] relu42 does not need backward computation.
I0712 17:59:20.056591 44362 net.cpp:228] conv42 does not need backward computation.
I0712 17:59:20.056612 44362 net.cpp:228] relu41 does not need backward computation.
I0712 17:59:20.056622 44362 net.cpp:228] conv41 does not need backward computation.
I0712 17:59:20.056630 44362 net.cpp:228] pool3 does not need backward computation.
I0712 17:59:20.056641 44362 net.cpp:228] relu32 does not need backward computation.
I0712 17:59:20.056653 44362 net.cpp:228] conv32 does not need backward computation.
I0712 17:59:20.056661 44362 net.cpp:228] relu31 does not need backward computation.
I0712 17:59:20.056670 44362 net.cpp:228] conv31 does not need backward computation.
I0712 17:59:20.056679 44362 net.cpp:228] pool2 does not need backward computation.
I0712 17:59:20.056689 44362 net.cpp:228] relu22 does not need backward computation.
I0712 17:59:20.056697 44362 net.cpp:228] conv22 does not need backward computation.
I0712 17:59:20.056706 44362 net.cpp:228] relu21 does not need backward computation.
I0712 17:59:20.056715 44362 net.cpp:228] conv21 does not need backward computation.
I0712 17:59:20.056723 44362 net.cpp:228] pool1 does not need backward computation.
I0712 17:59:20.056731 44362 net.cpp:228] relu12 does not need backward computation.
I0712 17:59:20.056740 44362 net.cpp:228] conv12 does not need backward computation.
I0712 17:59:20.056748 44362 net.cpp:228] relu11 does not need backward computation.
I0712 17:59:20.056759 44362 net.cpp:228] conv11 does not need backward computation.
I0712 17:59:20.056768 44362 net.cpp:228] label_data_1_split does not need backward computation.
I0712 17:59:20.056784 44362 net.cpp:228] data does not need backward computation.
I0712 17:59:20.056792 44362 net.cpp:270] This network produces output accuracy
I0712 17:59:20.056800 44362 net.cpp:270] This network produces output loss
I0712 17:59:20.056833 44362 net.cpp:283] Network initialization done.
I0712 17:59:20.057044 44362 solver.cpp:59] Solver scaffolding done.
I0712 17:59:20.058740 44362 caffe.cpp:128] Finetuning from models/cnn10_iter_217316.caffemodel
I0712 17:59:20.168365 44362 caffe.cpp:212] Starting Optimization
I0712 17:59:20.168438 44362 solver.cpp:287] Solving FaceNN
I0712 17:59:20.168454 44362 solver.cpp:288] Learning Rate Policy: step
I0712 17:59:20.171639 44362 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 17:59:21.158062 44362 solver.cpp:236] Iteration 0, loss = 1.08743
I0712 17:59:21.158149 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 17:59:21.158167 44362 solver.cpp:252]     Train net output #1: loss = 1.08743 (* 1 = 1.08743 loss)
I0712 17:59:21.158191 44362 sgd_solver.cpp:106] Iteration 0, lr = 0.015
I0712 18:01:03.252941 44362 solver.cpp:236] Iteration 100, loss = 1.06321
I0712 18:01:03.253721 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:01:03.253751 44362 solver.cpp:252]     Train net output #1: loss = 1.09371 (* 1 = 1.09371 loss)
I0712 18:01:03.253762 44362 sgd_solver.cpp:106] Iteration 100, lr = 0.015
I0712 18:02:43.966943 44362 solver.cpp:236] Iteration 200, loss = 1.08828
I0712 18:02:43.967154 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:02:43.967185 44362 solver.cpp:252]     Train net output #1: loss = 1.10975 (* 1 = 1.10975 loss)
I0712 18:02:43.967200 44362 sgd_solver.cpp:106] Iteration 200, lr = 0.015
I0712 18:04:24.962968 44362 solver.cpp:236] Iteration 300, loss = 1.05205
I0712 18:04:24.963152 44362 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 18:04:24.963181 44362 solver.cpp:252]     Train net output #1: loss = 0.893433 (* 1 = 0.893433 loss)
I0712 18:04:24.963209 44362 sgd_solver.cpp:106] Iteration 300, lr = 0.015
I0712 18:06:05.337651 44362 solver.cpp:236] Iteration 400, loss = 1.07156
I0712 18:06:05.337802 44362 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:06:05.337824 44362 solver.cpp:252]     Train net output #1: loss = 1.02277 (* 1 = 1.02277 loss)
I0712 18:06:05.337841 44362 sgd_solver.cpp:106] Iteration 400, lr = 0.015
I0712 18:07:45.789031 44362 solver.cpp:236] Iteration 500, loss = 1.08637
I0712 18:07:45.789275 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:07:45.789299 44362 solver.cpp:252]     Train net output #1: loss = 1.08936 (* 1 = 1.08936 loss)
I0712 18:07:45.789311 44362 sgd_solver.cpp:106] Iteration 500, lr = 0.015
I0712 18:09:26.562368 44362 solver.cpp:236] Iteration 600, loss = 1.0597
I0712 18:09:26.562558 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:09:26.562592 44362 solver.cpp:252]     Train net output #1: loss = 1.06522 (* 1 = 1.06522 loss)
I0712 18:09:26.562613 44362 sgd_solver.cpp:106] Iteration 600, lr = 0.015
I0712 18:11:06.935534 44362 solver.cpp:236] Iteration 700, loss = 1.07162
I0712 18:11:06.935704 44362 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 18:11:06.935729 44362 solver.cpp:252]     Train net output #1: loss = 1.19982 (* 1 = 1.19982 loss)
I0712 18:11:06.935740 44362 sgd_solver.cpp:106] Iteration 700, lr = 0.015
I0712 18:12:47.145938 44362 solver.cpp:236] Iteration 800, loss = 1.07835
I0712 18:12:47.146085 44362 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 18:12:47.146112 44362 solver.cpp:252]     Train net output #1: loss = 0.929599 (* 1 = 0.929599 loss)
I0712 18:12:47.146126 44362 sgd_solver.cpp:106] Iteration 800, lr = 0.015
I0712 18:14:28.141630 44362 solver.cpp:236] Iteration 900, loss = 1.07636
I0712 18:14:28.141800 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:14:28.141819 44362 solver.cpp:252]     Train net output #1: loss = 1.20343 (* 1 = 1.20343 loss)
I0712 18:14:28.141831 44362 sgd_solver.cpp:106] Iteration 900, lr = 0.015
I0712 18:16:08.412045 44362 solver.cpp:236] Iteration 1000, loss = 1.07321
I0712 18:16:08.412225 44362 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:16:08.412245 44362 solver.cpp:252]     Train net output #1: loss = 1.19419 (* 1 = 1.19419 loss)
I0712 18:16:08.412258 44362 sgd_solver.cpp:106] Iteration 1000, lr = 0.015
I0712 18:17:48.788584 44362 solver.cpp:236] Iteration 1100, loss = 1.09718
I0712 18:17:48.788753 44362 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:17:48.788772 44362 solver.cpp:252]     Train net output #1: loss = 1.14238 (* 1 = 1.14238 loss)
I0712 18:17:48.788785 44362 sgd_solver.cpp:106] Iteration 1100, lr = 0.015
I0712 18:19:29.081830 44362 solver.cpp:236] Iteration 1200, loss = 1.079
I0712 18:19:29.082023 44362 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:19:29.082052 44362 solver.cpp:252]     Train net output #1: loss = 1.08928 (* 1 = 1.08928 loss)
I0712 18:19:29.082074 44362 sgd_solver.cpp:106] Iteration 1200, lr = 0.015
I0712 18:20:24.143795 44362 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 18:21:09.162488 44362 solver.cpp:236] Iteration 1300, loss = 1.07066
I0712 18:21:09.162645 44362 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:21:09.162667 44362 solver.cpp:252]     Train net output #1: loss = 1.05094 (* 1 = 1.05094 loss)
I0712 18:21:09.162680 44362 sgd_solver.cpp:106] Iteration 1300, lr = 0.015
I0712 18:22:48.598404 44362 solver.cpp:236] Iteration 1400, loss = 1.08667
I0712 18:22:48.598516 44362 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 18:22:48.598536 44362 solver.cpp:252]     Train net output #1: loss = 0.942138 (* 1 = 0.942138 loss)
I0712 18:22:48.598548 44362 sgd_solver.cpp:106] Iteration 1400, lr = 0.015
I0712 18:24:27.030560 44362 solver.cpp:340] Iteration 1500, Testing net (#0)
F0712 18:24:27.106931 44362 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
