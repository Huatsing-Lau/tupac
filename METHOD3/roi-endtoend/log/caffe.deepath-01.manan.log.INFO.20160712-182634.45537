Log file created at: 2016/07/12 18:26:34
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0712 18:26:34.475342 45537 caffe.cpp:184] Using GPUs 3
I0712 18:26:34.903990 45537 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 1500
base_lr: 0.015
display: 100
max_iter: 500000
lr_policy: "step"
gamma: 0.1
momentum: 0.85
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/resultlayer"
solver_mode: GPU
device_id: 3
net: "train_val-resultlayer.prototxt"
test_initialization: false
average_loss: 50
I0712 18:26:34.904242 45537 solver.cpp:90] Creating training net from net file: train_val-resultlayer.prototxt
I0712 18:26:34.905380 45537 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0712 18:26:34.905750 45537 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "conv53"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv54"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "conv63"
  type: "Convolution"
  bottom: "conv62"
  top: "conv63"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu63"
  type: "ReLU"
  bottom: "conv63"
  top: "conv63"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv63"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "conv73"
  type: "Convolution"
  bottom: "conv72"
  top: "conv73"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu73"
  type: "ReLU"
  bottom: "conv73"
  top: "conv73"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv73"
  top: "pool6"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool6"
  top: "pool6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 15
    kernel_w: 15
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv81"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv81"
  bottom: "label"
  top: "loss"
}
I0712 18:26:34.908474 45537 layer_factory.hpp:76] Creating layer data
I0712 18:26:34.908529 45537 net.cpp:106] Creating Layer data
I0712 18:26:34.908543 45537 net.cpp:411] data -> data
I0712 18:26:34.908586 45537 net.cpp:411] data -> label
I0712 18:26:34.909044 45537 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0712 18:26:34.922868 45537 image_data_layer.cpp:46] Shuffling data
I0712 18:26:34.924793 45537 image_data_layer.cpp:51] A total of 23544 images.
I0712 18:26:34.999770 45537 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0712 18:26:35.253810 45537 net.cpp:150] Setting up data
I0712 18:26:35.253906 45537 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0712 18:26:35.253949 45537 net.cpp:157] Top shape: 8 (8)
I0712 18:26:35.253957 45537 net.cpp:165] Memory required for data: 96000032
I0712 18:26:35.253971 45537 layer_factory.hpp:76] Creating layer label_data_1_split
I0712 18:26:35.253998 45537 net.cpp:106] Creating Layer label_data_1_split
I0712 18:26:35.254009 45537 net.cpp:454] label_data_1_split <- label
I0712 18:26:35.254030 45537 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0712 18:26:35.254052 45537 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0712 18:26:35.254128 45537 net.cpp:150] Setting up label_data_1_split
I0712 18:26:35.254140 45537 net.cpp:157] Top shape: 8 (8)
I0712 18:26:35.254148 45537 net.cpp:157] Top shape: 8 (8)
I0712 18:26:35.254154 45537 net.cpp:165] Memory required for data: 96000096
I0712 18:26:35.254163 45537 layer_factory.hpp:76] Creating layer conv11
I0712 18:26:35.254225 45537 net.cpp:106] Creating Layer conv11
I0712 18:26:35.254232 45537 net.cpp:454] conv11 <- data
I0712 18:26:35.254246 45537 net.cpp:411] conv11 -> conv11
I0712 18:26:35.436038 45537 net.cpp:150] Setting up conv11
I0712 18:26:35.436095 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.436106 45537 net.cpp:165] Memory required for data: 1120000096
I0712 18:26:35.436138 45537 layer_factory.hpp:76] Creating layer relu11
I0712 18:26:35.436159 45537 net.cpp:106] Creating Layer relu11
I0712 18:26:35.436172 45537 net.cpp:454] relu11 <- conv11
I0712 18:26:35.436184 45537 net.cpp:397] relu11 -> conv11 (in-place)
I0712 18:26:35.436424 45537 net.cpp:150] Setting up relu11
I0712 18:26:35.436446 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.436463 45537 net.cpp:165] Memory required for data: 2144000096
I0712 18:26:35.436472 45537 layer_factory.hpp:76] Creating layer conv12
I0712 18:26:35.436492 45537 net.cpp:106] Creating Layer conv12
I0712 18:26:35.436501 45537 net.cpp:454] conv12 <- conv11
I0712 18:26:35.436513 45537 net.cpp:411] conv12 -> conv12
I0712 18:26:35.441004 45537 net.cpp:150] Setting up conv12
I0712 18:26:35.441047 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.441058 45537 net.cpp:165] Memory required for data: 3168000096
I0712 18:26:35.441078 45537 layer_factory.hpp:76] Creating layer relu12
I0712 18:26:35.441094 45537 net.cpp:106] Creating Layer relu12
I0712 18:26:35.441104 45537 net.cpp:454] relu12 <- conv12
I0712 18:26:35.441128 45537 net.cpp:397] relu12 -> conv12 (in-place)
I0712 18:26:35.441485 45537 net.cpp:150] Setting up relu12
I0712 18:26:35.441507 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.441516 45537 net.cpp:165] Memory required for data: 4192000096
I0712 18:26:35.441525 45537 layer_factory.hpp:76] Creating layer pool1
I0712 18:26:35.441540 45537 net.cpp:106] Creating Layer pool1
I0712 18:26:35.441547 45537 net.cpp:454] pool1 <- conv12
I0712 18:26:35.441560 45537 net.cpp:411] pool1 -> pool1
I0712 18:26:35.441833 45537 net.cpp:150] Setting up pool1
I0712 18:26:35.441854 45537 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0712 18:26:35.441864 45537 net.cpp:165] Memory required for data: 4448000096
I0712 18:26:35.441872 45537 layer_factory.hpp:76] Creating layer conv21
I0712 18:26:35.441890 45537 net.cpp:106] Creating Layer conv21
I0712 18:26:35.441898 45537 net.cpp:454] conv21 <- pool1
I0712 18:26:35.441911 45537 net.cpp:411] conv21 -> conv21
I0712 18:26:35.444519 45537 net.cpp:150] Setting up conv21
I0712 18:26:35.444556 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.444567 45537 net.cpp:165] Memory required for data: 4960000096
I0712 18:26:35.444586 45537 layer_factory.hpp:76] Creating layer relu21
I0712 18:26:35.444602 45537 net.cpp:106] Creating Layer relu21
I0712 18:26:35.444617 45537 net.cpp:454] relu21 <- conv21
I0712 18:26:35.444629 45537 net.cpp:397] relu21 -> conv21 (in-place)
I0712 18:26:35.444977 45537 net.cpp:150] Setting up relu21
I0712 18:26:35.444998 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.445006 45537 net.cpp:165] Memory required for data: 5472000096
I0712 18:26:35.445015 45537 layer_factory.hpp:76] Creating layer conv22
I0712 18:26:35.445032 45537 net.cpp:106] Creating Layer conv22
I0712 18:26:35.445042 45537 net.cpp:454] conv22 <- conv21
I0712 18:26:35.445055 45537 net.cpp:411] conv22 -> conv22
I0712 18:26:35.447077 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:26:35.447319 45537 net.cpp:150] Setting up conv22
I0712 18:26:35.447346 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.447356 45537 net.cpp:165] Memory required for data: 5984000096
I0712 18:26:35.447371 45537 layer_factory.hpp:76] Creating layer relu22
I0712 18:26:35.447384 45537 net.cpp:106] Creating Layer relu22
I0712 18:26:35.447402 45537 net.cpp:454] relu22 <- conv22
I0712 18:26:35.447412 45537 net.cpp:397] relu22 -> conv22 (in-place)
I0712 18:26:35.447746 45537 net.cpp:150] Setting up relu22
I0712 18:26:35.447800 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.447811 45537 net.cpp:165] Memory required for data: 6496000096
I0712 18:26:35.447829 45537 layer_factory.hpp:76] Creating layer pool2
I0712 18:26:35.447841 45537 net.cpp:106] Creating Layer pool2
I0712 18:26:35.447849 45537 net.cpp:454] pool2 <- conv22
I0712 18:26:35.447860 45537 net.cpp:411] pool2 -> pool2
I0712 18:26:35.448081 45537 net.cpp:150] Setting up pool2
I0712 18:26:35.448099 45537 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0712 18:26:35.448108 45537 net.cpp:165] Memory required for data: 6624000096
I0712 18:26:35.448117 45537 layer_factory.hpp:76] Creating layer conv31
I0712 18:26:35.448133 45537 net.cpp:106] Creating Layer conv31
I0712 18:26:35.448143 45537 net.cpp:454] conv31 <- pool2
I0712 18:26:35.448155 45537 net.cpp:411] conv31 -> conv31
I0712 18:26:35.449661 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:26:35.449702 45537 net.cpp:150] Setting up conv31
I0712 18:26:35.449714 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.449731 45537 net.cpp:165] Memory required for data: 6816000096
I0712 18:26:35.449748 45537 layer_factory.hpp:76] Creating layer relu31
I0712 18:26:35.449760 45537 net.cpp:106] Creating Layer relu31
I0712 18:26:35.449772 45537 net.cpp:454] relu31 <- conv31
I0712 18:26:35.449785 45537 net.cpp:397] relu31 -> conv31 (in-place)
I0712 18:26:35.450110 45537 net.cpp:150] Setting up relu31
I0712 18:26:35.450130 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.450139 45537 net.cpp:165] Memory required for data: 7008000096
I0712 18:26:35.450148 45537 layer_factory.hpp:76] Creating layer conv32
I0712 18:26:35.450165 45537 net.cpp:106] Creating Layer conv32
I0712 18:26:35.450176 45537 net.cpp:454] conv32 <- conv31
I0712 18:26:35.450188 45537 net.cpp:411] conv32 -> conv32
I0712 18:26:35.452558 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:26:35.452600 45537 net.cpp:150] Setting up conv32
I0712 18:26:35.452615 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.452631 45537 net.cpp:165] Memory required for data: 7200000096
I0712 18:26:35.452643 45537 layer_factory.hpp:76] Creating layer relu32
I0712 18:26:35.452656 45537 net.cpp:106] Creating Layer relu32
I0712 18:26:35.452666 45537 net.cpp:454] relu32 <- conv32
I0712 18:26:35.452679 45537 net.cpp:397] relu32 -> conv32 (in-place)
I0712 18:26:35.452868 45537 net.cpp:150] Setting up relu32
I0712 18:26:35.452895 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.452905 45537 net.cpp:165] Memory required for data: 7392000096
I0712 18:26:35.452913 45537 layer_factory.hpp:76] Creating layer pool3
I0712 18:26:35.452929 45537 net.cpp:106] Creating Layer pool3
I0712 18:26:35.452937 45537 net.cpp:454] pool3 <- conv32
I0712 18:26:35.452947 45537 net.cpp:411] pool3 -> pool3
I0712 18:26:35.453316 45537 net.cpp:150] Setting up pool3
I0712 18:26:35.453344 45537 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0712 18:26:35.453353 45537 net.cpp:165] Memory required for data: 7440000096
I0712 18:26:35.453362 45537 layer_factory.hpp:76] Creating layer conv41
I0712 18:26:35.453383 45537 net.cpp:106] Creating Layer conv41
I0712 18:26:35.453393 45537 net.cpp:454] conv41 <- pool3
I0712 18:26:35.453408 45537 net.cpp:411] conv41 -> conv41
I0712 18:26:35.455178 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:26:35.455215 45537 net.cpp:150] Setting up conv41
I0712 18:26:35.455231 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.455241 45537 net.cpp:165] Memory required for data: 7504000096
I0712 18:26:35.455253 45537 layer_factory.hpp:76] Creating layer relu41
I0712 18:26:35.455270 45537 net.cpp:106] Creating Layer relu41
I0712 18:26:35.455278 45537 net.cpp:454] relu41 <- conv41
I0712 18:26:35.455288 45537 net.cpp:397] relu41 -> conv41 (in-place)
I0712 18:26:35.455791 45537 net.cpp:150] Setting up relu41
I0712 18:26:35.455812 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.455852 45537 net.cpp:165] Memory required for data: 7568000096
I0712 18:26:35.455867 45537 layer_factory.hpp:76] Creating layer conv42
I0712 18:26:35.455885 45537 net.cpp:106] Creating Layer conv42
I0712 18:26:35.455895 45537 net.cpp:454] conv42 <- conv41
I0712 18:26:35.455906 45537 net.cpp:411] conv42 -> conv42
I0712 18:26:35.458936 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:35.458984 45537 net.cpp:150] Setting up conv42
I0712 18:26:35.458999 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.459008 45537 net.cpp:165] Memory required for data: 7632000096
I0712 18:26:35.459020 45537 layer_factory.hpp:76] Creating layer relu42
I0712 18:26:35.459044 45537 net.cpp:106] Creating Layer relu42
I0712 18:26:35.459053 45537 net.cpp:454] relu42 <- conv42
I0712 18:26:35.459064 45537 net.cpp:397] relu42 -> conv42 (in-place)
I0712 18:26:35.459252 45537 net.cpp:150] Setting up relu42
I0712 18:26:35.459270 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.459280 45537 net.cpp:165] Memory required for data: 7696000096
I0712 18:26:35.459287 45537 layer_factory.hpp:76] Creating layer pool4
I0712 18:26:35.459300 45537 net.cpp:106] Creating Layer pool4
I0712 18:26:35.459308 45537 net.cpp:454] pool4 <- conv42
I0712 18:26:35.459321 45537 net.cpp:411] pool4 -> pool4
I0712 18:26:35.459677 45537 net.cpp:150] Setting up pool4
I0712 18:26:35.459705 45537 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0712 18:26:35.459723 45537 net.cpp:165] Memory required for data: 7712257120
I0712 18:26:35.459733 45537 layer_factory.hpp:76] Creating layer conv51
I0712 18:26:35.459755 45537 net.cpp:106] Creating Layer conv51
I0712 18:26:35.459765 45537 net.cpp:454] conv51 <- pool4
I0712 18:26:35.459779 45537 net.cpp:411] conv51 -> conv51
I0712 18:26:35.465005 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:35.465070 45537 net.cpp:150] Setting up conv51
I0712 18:26:35.465087 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.465103 45537 net.cpp:165] Memory required for data: 7744771168
I0712 18:26:35.465123 45537 layer_factory.hpp:76] Creating layer relu51
I0712 18:26:35.465140 45537 net.cpp:106] Creating Layer relu51
I0712 18:26:35.465152 45537 net.cpp:454] relu51 <- conv51
I0712 18:26:35.465168 45537 net.cpp:397] relu51 -> conv51 (in-place)
I0712 18:26:35.465365 45537 net.cpp:150] Setting up relu51
I0712 18:26:35.465387 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.465396 45537 net.cpp:165] Memory required for data: 7777285216
I0712 18:26:35.465405 45537 layer_factory.hpp:76] Creating layer conv52
I0712 18:26:35.465421 45537 net.cpp:106] Creating Layer conv52
I0712 18:26:35.465430 45537 net.cpp:454] conv52 <- conv51
I0712 18:26:35.465445 45537 net.cpp:411] conv52 -> conv52
I0712 18:26:35.472589 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 18:26:35.472651 45537 net.cpp:150] Setting up conv52
I0712 18:26:35.472667 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.472677 45537 net.cpp:165] Memory required for data: 7809799264
I0712 18:26:35.472692 45537 layer_factory.hpp:76] Creating layer relu52
I0712 18:26:35.472713 45537 net.cpp:106] Creating Layer relu52
I0712 18:26:35.472724 45537 net.cpp:454] relu52 <- conv52
I0712 18:26:35.472736 45537 net.cpp:397] relu52 -> conv52 (in-place)
I0712 18:26:35.473067 45537 net.cpp:150] Setting up relu52
I0712 18:26:35.473088 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.473096 45537 net.cpp:165] Memory required for data: 7842313312
I0712 18:26:35.473105 45537 layer_factory.hpp:76] Creating layer conv53
I0712 18:26:35.473129 45537 net.cpp:106] Creating Layer conv53
I0712 18:26:35.473139 45537 net.cpp:454] conv53 <- conv52
I0712 18:26:35.473155 45537 net.cpp:411] conv53 -> conv53
I0712 18:26:35.507459 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0712 18:26:35.507710 45537 net.cpp:150] Setting up conv53
I0712 18:26:35.507735 45537 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:26:35.507781 45537 net.cpp:165] Memory required for data: 7868929120
I0712 18:26:35.507804 45537 layer_factory.hpp:76] Creating layer relu53
I0712 18:26:35.507824 45537 net.cpp:106] Creating Layer relu53
I0712 18:26:35.507835 45537 net.cpp:454] relu53 <- conv53
I0712 18:26:35.507848 45537 net.cpp:397] relu53 -> conv53 (in-place)
I0712 18:26:35.508188 45537 net.cpp:150] Setting up relu53
I0712 18:26:35.508214 45537 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:26:35.508229 45537 net.cpp:165] Memory required for data: 7895544928
I0712 18:26:35.508236 45537 layer_factory.hpp:76] Creating layer conv54
I0712 18:26:35.508256 45537 net.cpp:106] Creating Layer conv54
I0712 18:26:35.508265 45537 net.cpp:454] conv54 <- conv53
I0712 18:26:35.508277 45537 net.cpp:411] conv54 -> conv54
I0712 18:26:35.509374 45537 net.cpp:150] Setting up conv54
I0712 18:26:35.509397 45537 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 18:26:35.509407 45537 net.cpp:165] Memory required for data: 7895752864
I0712 18:26:35.509419 45537 layer_factory.hpp:76] Creating layer interloss
I0712 18:26:35.509434 45537 net.cpp:106] Creating Layer interloss
I0712 18:26:35.509443 45537 net.cpp:454] interloss <- conv54
I0712 18:26:35.509454 45537 net.cpp:411] interloss -> interloss
I0712 18:26:35.509724 45537 net.cpp:150] Setting up interloss
I0712 18:26:35.509742 45537 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 18:26:35.509752 45537 net.cpp:165] Memory required for data: 7895960800
I0712 18:26:35.509762 45537 layer_factory.hpp:76] Creating layer conv61
I0712 18:26:35.509778 45537 net.cpp:106] Creating Layer conv61
I0712 18:26:35.509788 45537 net.cpp:454] conv61 <- interloss
I0712 18:26:35.509799 45537 net.cpp:411] conv61 -> conv61
I0712 18:26:35.510891 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5614272
I0712 18:26:35.511109 45537 net.cpp:150] Setting up conv61
I0712 18:26:35.511129 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:35.511138 45537 net.cpp:165] Memory required for data: 7902614752
I0712 18:26:35.511150 45537 layer_factory.hpp:76] Creating layer relu61
I0712 18:26:35.511163 45537 net.cpp:106] Creating Layer relu61
I0712 18:26:35.511173 45537 net.cpp:454] relu61 <- conv61
I0712 18:26:35.511185 45537 net.cpp:397] relu61 -> conv61 (in-place)
I0712 18:26:35.511533 45537 net.cpp:150] Setting up relu61
I0712 18:26:35.511553 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:35.511562 45537 net.cpp:165] Memory required for data: 7909268704
I0712 18:26:35.511570 45537 layer_factory.hpp:76] Creating layer conv62
I0712 18:26:35.511595 45537 net.cpp:106] Creating Layer conv62
I0712 18:26:35.511605 45537 net.cpp:454] conv62 <- conv61
I0712 18:26:35.511616 45537 net.cpp:411] conv62 -> conv62
I0712 18:26:35.513608 45537 net.cpp:150] Setting up conv62
I0712 18:26:35.513638 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:35.513648 45537 net.cpp:165] Memory required for data: 7915922656
I0712 18:26:35.513660 45537 layer_factory.hpp:76] Creating layer relu62
I0712 18:26:35.513676 45537 net.cpp:106] Creating Layer relu62
I0712 18:26:35.513685 45537 net.cpp:454] relu62 <- conv62
I0712 18:26:35.513696 45537 net.cpp:397] relu62 -> conv62 (in-place)
I0712 18:26:35.514031 45537 net.cpp:150] Setting up relu62
I0712 18:26:35.514052 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:35.514061 45537 net.cpp:165] Memory required for data: 7922576608
I0712 18:26:35.514070 45537 layer_factory.hpp:76] Creating layer conv63
I0712 18:26:35.514089 45537 net.cpp:106] Creating Layer conv63
I0712 18:26:35.514099 45537 net.cpp:454] conv63 <- conv62
I0712 18:26:35.514111 45537 net.cpp:411] conv63 -> conv63
I0712 18:26:35.515687 45537 net.cpp:150] Setting up conv63
I0712 18:26:35.515712 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:35.515722 45537 net.cpp:165] Memory required for data: 7929230560
I0712 18:26:35.515739 45537 layer_factory.hpp:76] Creating layer relu63
I0712 18:26:35.515751 45537 net.cpp:106] Creating Layer relu63
I0712 18:26:35.515760 45537 net.cpp:454] relu63 <- conv63
I0712 18:26:35.515808 45537 net.cpp:397] relu63 -> conv63 (in-place)
I0712 18:26:35.515997 45537 net.cpp:150] Setting up relu63
I0712 18:26:35.516017 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:35.516026 45537 net.cpp:165] Memory required for data: 7935884512
I0712 18:26:35.516036 45537 layer_factory.hpp:76] Creating layer pool5
I0712 18:26:35.516048 45537 net.cpp:106] Creating Layer pool5
I0712 18:26:35.516057 45537 net.cpp:454] pool5 <- conv63
I0712 18:26:35.516067 45537 net.cpp:411] pool5 -> pool5
I0712 18:26:35.516433 45537 net.cpp:150] Setting up pool5
I0712 18:26:35.516453 45537 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0712 18:26:35.516469 45537 net.cpp:165] Memory required for data: 7937606880
I0712 18:26:35.516477 45537 layer_factory.hpp:76] Creating layer conv71
I0712 18:26:35.516500 45537 net.cpp:106] Creating Layer conv71
I0712 18:26:35.516510 45537 net.cpp:454] conv71 <- pool5
I0712 18:26:35.516521 45537 net.cpp:411] conv71 -> conv71
I0712 18:26:35.518172 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:26:35.518210 45537 net.cpp:150] Setting up conv71
I0712 18:26:35.518224 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:35.518249 45537 net.cpp:165] Memory required for data: 7941051616
I0712 18:26:35.518261 45537 layer_factory.hpp:76] Creating layer relu71
I0712 18:26:35.518273 45537 net.cpp:106] Creating Layer relu71
I0712 18:26:35.518282 45537 net.cpp:454] relu71 <- conv71
I0712 18:26:35.518296 45537 net.cpp:397] relu71 -> conv71 (in-place)
I0712 18:26:35.518486 45537 net.cpp:150] Setting up relu71
I0712 18:26:35.518507 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:35.518515 45537 net.cpp:165] Memory required for data: 7944496352
I0712 18:26:35.518524 45537 layer_factory.hpp:76] Creating layer conv72
I0712 18:26:35.518539 45537 net.cpp:106] Creating Layer conv72
I0712 18:26:35.518548 45537 net.cpp:454] conv72 <- conv71
I0712 18:26:35.518561 45537 net.cpp:411] conv72 -> conv72
I0712 18:26:35.521419 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:35.521474 45537 net.cpp:150] Setting up conv72
I0712 18:26:35.521488 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:35.521500 45537 net.cpp:165] Memory required for data: 7947941088
I0712 18:26:35.521523 45537 layer_factory.hpp:76] Creating layer relu72
I0712 18:26:35.521538 45537 net.cpp:106] Creating Layer relu72
I0712 18:26:35.521548 45537 net.cpp:454] relu72 <- conv72
I0712 18:26:35.521559 45537 net.cpp:397] relu72 -> conv72 (in-place)
I0712 18:26:35.521749 45537 net.cpp:150] Setting up relu72
I0712 18:26:35.521767 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:35.521777 45537 net.cpp:165] Memory required for data: 7951385824
I0712 18:26:35.521785 45537 layer_factory.hpp:76] Creating layer conv73
I0712 18:26:35.521803 45537 net.cpp:106] Creating Layer conv73
I0712 18:26:35.521813 45537 net.cpp:454] conv73 <- conv72
I0712 18:26:35.521826 45537 net.cpp:411] conv73 -> conv73
I0712 18:26:35.524744 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:35.524801 45537 net.cpp:150] Setting up conv73
I0712 18:26:35.524816 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:35.524832 45537 net.cpp:165] Memory required for data: 7954830560
I0712 18:26:35.524847 45537 layer_factory.hpp:76] Creating layer relu73
I0712 18:26:35.524866 45537 net.cpp:106] Creating Layer relu73
I0712 18:26:35.524876 45537 net.cpp:454] relu73 <- conv73
I0712 18:26:35.524889 45537 net.cpp:397] relu73 -> conv73 (in-place)
I0712 18:26:35.525228 45537 net.cpp:150] Setting up relu73
I0712 18:26:35.525249 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:35.525259 45537 net.cpp:165] Memory required for data: 7958275296
I0712 18:26:35.525274 45537 layer_factory.hpp:76] Creating layer pool6
I0712 18:26:35.525290 45537 net.cpp:106] Creating Layer pool6
I0712 18:26:35.525298 45537 net.cpp:454] pool6 <- conv73
I0712 18:26:35.525310 45537 net.cpp:411] pool6 -> pool6
I0712 18:26:35.525518 45537 net.cpp:150] Setting up pool6
I0712 18:26:35.525566 45537 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:26:35.525575 45537 net.cpp:165] Memory required for data: 7959196896
I0712 18:26:35.525584 45537 layer_factory.hpp:76] Creating layer drop0
I0712 18:26:35.525604 45537 net.cpp:106] Creating Layer drop0
I0712 18:26:35.525614 45537 net.cpp:454] drop0 <- pool6
I0712 18:26:35.525622 45537 net.cpp:397] drop0 -> pool6 (in-place)
I0712 18:26:35.525673 45537 net.cpp:150] Setting up drop0
I0712 18:26:35.525686 45537 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:26:35.525693 45537 net.cpp:165] Memory required for data: 7960118496
I0712 18:26:35.525702 45537 layer_factory.hpp:76] Creating layer conv81
I0712 18:26:35.525719 45537 net.cpp:106] Creating Layer conv81
I0712 18:26:35.525728 45537 net.cpp:454] conv81 <- pool6
I0712 18:26:35.525743 45537 net.cpp:411] conv81 -> conv81
I0712 18:26:35.527458 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345600
I0712 18:26:35.527676 45537 net.cpp:150] Setting up conv81
I0712 18:26:35.527696 45537 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:26:35.527705 45537 net.cpp:165] Memory required for data: 7960118592
I0712 18:26:35.527719 45537 layer_factory.hpp:76] Creating layer conv81_conv81_0_split
I0712 18:26:35.527731 45537 net.cpp:106] Creating Layer conv81_conv81_0_split
I0712 18:26:35.527740 45537 net.cpp:454] conv81_conv81_0_split <- conv81
I0712 18:26:35.527752 45537 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_0
I0712 18:26:35.527773 45537 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_1
I0712 18:26:35.527823 45537 net.cpp:150] Setting up conv81_conv81_0_split
I0712 18:26:35.527842 45537 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:26:35.527850 45537 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:26:35.527858 45537 net.cpp:165] Memory required for data: 7960118784
I0712 18:26:35.527866 45537 layer_factory.hpp:76] Creating layer accuracy
I0712 18:26:35.527882 45537 net.cpp:106] Creating Layer accuracy
I0712 18:26:35.527891 45537 net.cpp:454] accuracy <- conv81_conv81_0_split_0
I0712 18:26:35.527901 45537 net.cpp:454] accuracy <- label_data_1_split_0
I0712 18:26:35.527910 45537 net.cpp:411] accuracy -> accuracy
I0712 18:26:35.527932 45537 net.cpp:150] Setting up accuracy
I0712 18:26:35.527943 45537 net.cpp:157] Top shape: (1)
I0712 18:26:35.527954 45537 net.cpp:165] Memory required for data: 7960118788
I0712 18:26:35.527962 45537 layer_factory.hpp:76] Creating layer loss
I0712 18:26:35.527976 45537 net.cpp:106] Creating Layer loss
I0712 18:26:35.527983 45537 net.cpp:454] loss <- conv81_conv81_0_split_1
I0712 18:26:35.527993 45537 net.cpp:454] loss <- label_data_1_split_1
I0712 18:26:35.528012 45537 net.cpp:411] loss -> loss
I0712 18:26:35.528029 45537 layer_factory.hpp:76] Creating layer loss
I0712 18:26:35.528486 45537 net.cpp:150] Setting up loss
I0712 18:26:35.528506 45537 net.cpp:157] Top shape: (1)
I0712 18:26:35.528524 45537 net.cpp:160]     with loss weight 1
I0712 18:26:35.528554 45537 net.cpp:165] Memory required for data: 7960118792
I0712 18:26:35.528566 45537 net.cpp:226] loss needs backward computation.
I0712 18:26:35.528575 45537 net.cpp:228] accuracy does not need backward computation.
I0712 18:26:35.528584 45537 net.cpp:226] conv81_conv81_0_split needs backward computation.
I0712 18:26:35.528594 45537 net.cpp:226] conv81 needs backward computation.
I0712 18:26:35.528602 45537 net.cpp:226] drop0 needs backward computation.
I0712 18:26:35.528609 45537 net.cpp:226] pool6 needs backward computation.
I0712 18:26:35.528617 45537 net.cpp:226] relu73 needs backward computation.
I0712 18:26:35.528626 45537 net.cpp:226] conv73 needs backward computation.
I0712 18:26:35.528635 45537 net.cpp:226] relu72 needs backward computation.
I0712 18:26:35.528642 45537 net.cpp:226] conv72 needs backward computation.
I0712 18:26:35.528650 45537 net.cpp:226] relu71 needs backward computation.
I0712 18:26:35.528657 45537 net.cpp:226] conv71 needs backward computation.
I0712 18:26:35.528666 45537 net.cpp:226] pool5 needs backward computation.
I0712 18:26:35.528702 45537 net.cpp:226] relu63 needs backward computation.
I0712 18:26:35.528709 45537 net.cpp:226] conv63 needs backward computation.
I0712 18:26:35.528717 45537 net.cpp:226] relu62 needs backward computation.
I0712 18:26:35.528725 45537 net.cpp:226] conv62 needs backward computation.
I0712 18:26:35.528733 45537 net.cpp:226] relu61 needs backward computation.
I0712 18:26:35.528741 45537 net.cpp:226] conv61 needs backward computation.
I0712 18:26:35.528749 45537 net.cpp:226] interloss needs backward computation.
I0712 18:26:35.528759 45537 net.cpp:226] conv54 needs backward computation.
I0712 18:26:35.528766 45537 net.cpp:228] relu53 does not need backward computation.
I0712 18:26:35.528774 45537 net.cpp:228] conv53 does not need backward computation.
I0712 18:26:35.528782 45537 net.cpp:228] relu52 does not need backward computation.
I0712 18:26:35.528790 45537 net.cpp:228] conv52 does not need backward computation.
I0712 18:26:35.528800 45537 net.cpp:228] relu51 does not need backward computation.
I0712 18:26:35.528807 45537 net.cpp:228] conv51 does not need backward computation.
I0712 18:26:35.528815 45537 net.cpp:228] pool4 does not need backward computation.
I0712 18:26:35.528825 45537 net.cpp:228] relu42 does not need backward computation.
I0712 18:26:35.528839 45537 net.cpp:228] conv42 does not need backward computation.
I0712 18:26:35.528847 45537 net.cpp:228] relu41 does not need backward computation.
I0712 18:26:35.528859 45537 net.cpp:228] conv41 does not need backward computation.
I0712 18:26:35.528868 45537 net.cpp:228] pool3 does not need backward computation.
I0712 18:26:35.528877 45537 net.cpp:228] relu32 does not need backward computation.
I0712 18:26:35.528885 45537 net.cpp:228] conv32 does not need backward computation.
I0712 18:26:35.528893 45537 net.cpp:228] relu31 does not need backward computation.
I0712 18:26:35.528901 45537 net.cpp:228] conv31 does not need backward computation.
I0712 18:26:35.528910 45537 net.cpp:228] pool2 does not need backward computation.
I0712 18:26:35.528918 45537 net.cpp:228] relu22 does not need backward computation.
I0712 18:26:35.528926 45537 net.cpp:228] conv22 does not need backward computation.
I0712 18:26:35.528934 45537 net.cpp:228] relu21 does not need backward computation.
I0712 18:26:35.528942 45537 net.cpp:228] conv21 does not need backward computation.
I0712 18:26:35.528951 45537 net.cpp:228] pool1 does not need backward computation.
I0712 18:26:35.528959 45537 net.cpp:228] relu12 does not need backward computation.
I0712 18:26:35.528967 45537 net.cpp:228] conv12 does not need backward computation.
I0712 18:26:35.528975 45537 net.cpp:228] relu11 does not need backward computation.
I0712 18:26:35.528983 45537 net.cpp:228] conv11 does not need backward computation.
I0712 18:26:35.528992 45537 net.cpp:228] label_data_1_split does not need backward computation.
I0712 18:26:35.529001 45537 net.cpp:228] data does not need backward computation.
I0712 18:26:35.529008 45537 net.cpp:270] This network produces output accuracy
I0712 18:26:35.529017 45537 net.cpp:270] This network produces output loss
I0712 18:26:35.529052 45537 net.cpp:283] Network initialization done.
I0712 18:26:35.530175 45537 solver.cpp:180] Creating test net (#0) specified by net file: train_val-resultlayer.prototxt
I0712 18:26:35.530254 45537 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0712 18:26:35.530575 45537 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv54"
  type: "Convolution"
  bottom: "conv53"
  top: "conv54"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv54"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "conv63"
  type: "Convolution"
  bottom: "conv62"
  top: "conv63"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu63"
  type: "ReLU"
  bottom: "conv63"
  top: "conv63"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv63"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "conv73"
  type: "Convolution"
  bottom: "conv72"
  top: "conv73"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu73"
  type: "ReLU"
  bottom: "conv73"
  top: "conv73"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv73"
  top: "pool6"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool6"
  top: "pool6"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 15
    kernel_w: 15
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv81"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv81"
  bottom: "label"
  top: "loss"
}
I0712 18:26:35.532960 45537 layer_factory.hpp:76] Creating layer data
I0712 18:26:35.532984 45537 net.cpp:106] Creating Layer data
I0712 18:26:35.532995 45537 net.cpp:411] data -> data
I0712 18:26:35.533010 45537 net.cpp:411] data -> label
I0712 18:26:35.533025 45537 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0712 18:26:35.534525 45537 image_data_layer.cpp:46] Shuffling data
I0712 18:26:35.534751 45537 image_data_layer.cpp:51] A total of 2617 images.
I0712 18:26:35.620118 45537 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0712 18:26:35.860276 45537 net.cpp:150] Setting up data
I0712 18:26:35.860327 45537 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0712 18:26:35.860339 45537 net.cpp:157] Top shape: 8 (8)
I0712 18:26:35.860348 45537 net.cpp:165] Memory required for data: 96000032
I0712 18:26:35.860360 45537 layer_factory.hpp:76] Creating layer label_data_1_split
I0712 18:26:35.860380 45537 net.cpp:106] Creating Layer label_data_1_split
I0712 18:26:35.860390 45537 net.cpp:454] label_data_1_split <- label
I0712 18:26:35.860402 45537 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0712 18:26:35.860419 45537 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0712 18:26:35.860509 45537 net.cpp:150] Setting up label_data_1_split
I0712 18:26:35.860527 45537 net.cpp:157] Top shape: 8 (8)
I0712 18:26:35.860535 45537 net.cpp:157] Top shape: 8 (8)
I0712 18:26:35.860543 45537 net.cpp:165] Memory required for data: 96000096
I0712 18:26:35.860553 45537 layer_factory.hpp:76] Creating layer conv11
I0712 18:26:35.860571 45537 net.cpp:106] Creating Layer conv11
I0712 18:26:35.860580 45537 net.cpp:454] conv11 <- data
I0712 18:26:35.860592 45537 net.cpp:411] conv11 -> conv11
I0712 18:26:35.871342 45537 net.cpp:150] Setting up conv11
I0712 18:26:35.871404 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.871425 45537 net.cpp:165] Memory required for data: 1120000096
I0712 18:26:35.871455 45537 layer_factory.hpp:76] Creating layer relu11
I0712 18:26:35.871484 45537 net.cpp:106] Creating Layer relu11
I0712 18:26:35.871500 45537 net.cpp:454] relu11 <- conv11
I0712 18:26:35.871520 45537 net.cpp:397] relu11 -> conv11 (in-place)
I0712 18:26:35.871945 45537 net.cpp:150] Setting up relu11
I0712 18:26:35.871968 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.871975 45537 net.cpp:165] Memory required for data: 2144000096
I0712 18:26:35.871984 45537 layer_factory.hpp:76] Creating layer conv12
I0712 18:26:35.872020 45537 net.cpp:106] Creating Layer conv12
I0712 18:26:35.872030 45537 net.cpp:454] conv12 <- conv11
I0712 18:26:35.872048 45537 net.cpp:411] conv12 -> conv12
I0712 18:26:35.881779 45537 net.cpp:150] Setting up conv12
I0712 18:26:35.881836 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.881853 45537 net.cpp:165] Memory required for data: 3168000096
I0712 18:26:35.881918 45537 layer_factory.hpp:76] Creating layer relu12
I0712 18:26:35.881942 45537 net.cpp:106] Creating Layer relu12
I0712 18:26:35.881958 45537 net.cpp:454] relu12 <- conv12
I0712 18:26:35.881975 45537 net.cpp:397] relu12 -> conv12 (in-place)
I0712 18:26:35.882342 45537 net.cpp:150] Setting up relu12
I0712 18:26:35.882370 45537 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:26:35.882385 45537 net.cpp:165] Memory required for data: 4192000096
I0712 18:26:35.882400 45537 layer_factory.hpp:76] Creating layer pool1
I0712 18:26:35.882426 45537 net.cpp:106] Creating Layer pool1
I0712 18:26:35.882442 45537 net.cpp:454] pool1 <- conv12
I0712 18:26:35.882459 45537 net.cpp:411] pool1 -> pool1
I0712 18:26:35.883554 45537 net.cpp:150] Setting up pool1
I0712 18:26:35.883589 45537 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0712 18:26:35.883604 45537 net.cpp:165] Memory required for data: 4448000096
I0712 18:26:35.883631 45537 layer_factory.hpp:76] Creating layer conv21
I0712 18:26:35.883668 45537 net.cpp:106] Creating Layer conv21
I0712 18:26:35.883685 45537 net.cpp:454] conv21 <- pool1
I0712 18:26:35.883713 45537 net.cpp:411] conv21 -> conv21
I0712 18:26:35.889770 45537 net.cpp:150] Setting up conv21
I0712 18:26:35.889807 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.889823 45537 net.cpp:165] Memory required for data: 4960000096
I0712 18:26:35.889858 45537 layer_factory.hpp:76] Creating layer relu21
I0712 18:26:35.889883 45537 net.cpp:106] Creating Layer relu21
I0712 18:26:35.889897 45537 net.cpp:454] relu21 <- conv21
I0712 18:26:35.889924 45537 net.cpp:397] relu21 -> conv21 (in-place)
I0712 18:26:35.890249 45537 net.cpp:150] Setting up relu21
I0712 18:26:35.890275 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.890290 45537 net.cpp:165] Memory required for data: 5472000096
I0712 18:26:35.890303 45537 layer_factory.hpp:76] Creating layer conv22
I0712 18:26:35.890331 45537 net.cpp:106] Creating Layer conv22
I0712 18:26:35.890347 45537 net.cpp:454] conv22 <- conv21
I0712 18:26:35.890382 45537 net.cpp:411] conv22 -> conv22
I0712 18:26:35.897125 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:26:35.897349 45537 net.cpp:150] Setting up conv22
I0712 18:26:35.897385 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.897399 45537 net.cpp:165] Memory required for data: 5984000096
I0712 18:26:35.897418 45537 layer_factory.hpp:76] Creating layer relu22
I0712 18:26:35.897440 45537 net.cpp:106] Creating Layer relu22
I0712 18:26:35.897455 45537 net.cpp:454] relu22 <- conv22
I0712 18:26:35.897480 45537 net.cpp:397] relu22 -> conv22 (in-place)
I0712 18:26:35.898679 45537 net.cpp:150] Setting up relu22
I0712 18:26:35.898708 45537 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:26:35.898722 45537 net.cpp:165] Memory required for data: 6496000096
I0712 18:26:35.898738 45537 layer_factory.hpp:76] Creating layer pool2
I0712 18:26:35.898758 45537 net.cpp:106] Creating Layer pool2
I0712 18:26:35.898775 45537 net.cpp:454] pool2 <- conv22
I0712 18:26:35.898800 45537 net.cpp:411] pool2 -> pool2
I0712 18:26:35.901180 45537 net.cpp:150] Setting up pool2
I0712 18:26:35.901223 45537 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0712 18:26:35.901237 45537 net.cpp:165] Memory required for data: 6624000096
I0712 18:26:35.901250 45537 layer_factory.hpp:76] Creating layer conv31
I0712 18:26:35.901270 45537 net.cpp:106] Creating Layer conv31
I0712 18:26:35.901288 45537 net.cpp:454] conv31 <- pool2
I0712 18:26:35.901316 45537 net.cpp:411] conv31 -> conv31
I0712 18:26:35.909049 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:26:35.909118 45537 net.cpp:150] Setting up conv31
I0712 18:26:35.909142 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.909157 45537 net.cpp:165] Memory required for data: 6816000096
I0712 18:26:35.909189 45537 layer_factory.hpp:76] Creating layer relu31
I0712 18:26:35.909212 45537 net.cpp:106] Creating Layer relu31
I0712 18:26:35.909261 45537 net.cpp:454] relu31 <- conv31
I0712 18:26:35.909279 45537 net.cpp:397] relu31 -> conv31 (in-place)
I0712 18:26:35.911315 45537 net.cpp:150] Setting up relu31
I0712 18:26:35.911355 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.911370 45537 net.cpp:165] Memory required for data: 7008000096
I0712 18:26:35.911383 45537 layer_factory.hpp:76] Creating layer conv32
I0712 18:26:35.911412 45537 net.cpp:106] Creating Layer conv32
I0712 18:26:35.911429 45537 net.cpp:454] conv32 <- conv31
I0712 18:26:35.911454 45537 net.cpp:411] conv32 -> conv32
I0712 18:26:35.932642 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:26:35.932710 45537 net.cpp:150] Setting up conv32
I0712 18:26:35.932739 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.932756 45537 net.cpp:165] Memory required for data: 7200000096
I0712 18:26:35.932775 45537 layer_factory.hpp:76] Creating layer relu32
I0712 18:26:35.932792 45537 net.cpp:106] Creating Layer relu32
I0712 18:26:35.932807 45537 net.cpp:454] relu32 <- conv32
I0712 18:26:35.932824 45537 net.cpp:397] relu32 -> conv32 (in-place)
I0712 18:26:35.934175 45537 net.cpp:150] Setting up relu32
I0712 18:26:35.934216 45537 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:26:35.934229 45537 net.cpp:165] Memory required for data: 7392000096
I0712 18:26:35.934243 45537 layer_factory.hpp:76] Creating layer pool3
I0712 18:26:35.934263 45537 net.cpp:106] Creating Layer pool3
I0712 18:26:35.934278 45537 net.cpp:454] pool3 <- conv32
I0712 18:26:35.934303 45537 net.cpp:411] pool3 -> pool3
I0712 18:26:35.936450 45537 net.cpp:150] Setting up pool3
I0712 18:26:35.936478 45537 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0712 18:26:35.936502 45537 net.cpp:165] Memory required for data: 7440000096
I0712 18:26:35.936517 45537 layer_factory.hpp:76] Creating layer conv41
I0712 18:26:35.936537 45537 net.cpp:106] Creating Layer conv41
I0712 18:26:35.936550 45537 net.cpp:454] conv41 <- pool3
I0712 18:26:35.936579 45537 net.cpp:411] conv41 -> conv41
I0712 18:26:35.943632 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:26:35.943692 45537 net.cpp:150] Setting up conv41
I0712 18:26:35.943727 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.943743 45537 net.cpp:165] Memory required for data: 7504000096
I0712 18:26:35.943761 45537 layer_factory.hpp:76] Creating layer relu41
I0712 18:26:35.943783 45537 net.cpp:106] Creating Layer relu41
I0712 18:26:35.943796 45537 net.cpp:454] relu41 <- conv41
I0712 18:26:35.943821 45537 net.cpp:397] relu41 -> conv41 (in-place)
I0712 18:26:35.944663 45537 net.cpp:150] Setting up relu41
I0712 18:26:35.944701 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.944715 45537 net.cpp:165] Memory required for data: 7568000096
I0712 18:26:35.944730 45537 layer_factory.hpp:76] Creating layer conv42
I0712 18:26:35.944757 45537 net.cpp:106] Creating Layer conv42
I0712 18:26:35.944777 45537 net.cpp:454] conv42 <- conv41
I0712 18:26:35.944800 45537 net.cpp:411] conv42 -> conv42
I0712 18:26:35.950325 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:35.950403 45537 net.cpp:150] Setting up conv42
I0712 18:26:35.950428 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.950441 45537 net.cpp:165] Memory required for data: 7632000096
I0712 18:26:35.950460 45537 layer_factory.hpp:76] Creating layer relu42
I0712 18:26:35.950479 45537 net.cpp:106] Creating Layer relu42
I0712 18:26:35.950495 45537 net.cpp:454] relu42 <- conv42
I0712 18:26:35.950520 45537 net.cpp:397] relu42 -> conv42 (in-place)
I0712 18:26:35.952404 45537 net.cpp:150] Setting up relu42
I0712 18:26:35.952445 45537 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:26:35.952460 45537 net.cpp:165] Memory required for data: 7696000096
I0712 18:26:35.952474 45537 layer_factory.hpp:76] Creating layer pool4
I0712 18:26:35.952491 45537 net.cpp:106] Creating Layer pool4
I0712 18:26:35.952505 45537 net.cpp:454] pool4 <- conv42
I0712 18:26:35.952553 45537 net.cpp:411] pool4 -> pool4
I0712 18:26:35.953876 45537 net.cpp:150] Setting up pool4
I0712 18:26:35.953903 45537 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0712 18:26:35.953917 45537 net.cpp:165] Memory required for data: 7712257120
I0712 18:26:35.953929 45537 layer_factory.hpp:76] Creating layer conv51
I0712 18:26:35.953954 45537 net.cpp:106] Creating Layer conv51
I0712 18:26:35.953971 45537 net.cpp:454] conv51 <- pool4
I0712 18:26:35.953989 45537 net.cpp:411] conv51 -> conv51
I0712 18:26:35.963917 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:35.963963 45537 net.cpp:150] Setting up conv51
I0712 18:26:35.963999 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.964013 45537 net.cpp:165] Memory required for data: 7744771168
I0712 18:26:35.964043 45537 layer_factory.hpp:76] Creating layer relu51
I0712 18:26:35.964066 45537 net.cpp:106] Creating Layer relu51
I0712 18:26:35.964079 45537 net.cpp:454] relu51 <- conv51
I0712 18:26:35.964097 45537 net.cpp:397] relu51 -> conv51 (in-place)
I0712 18:26:35.964931 45537 net.cpp:150] Setting up relu51
I0712 18:26:35.964969 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.964984 45537 net.cpp:165] Memory required for data: 7777285216
I0712 18:26:35.964998 45537 layer_factory.hpp:76] Creating layer conv52
I0712 18:26:35.965024 45537 net.cpp:106] Creating Layer conv52
I0712 18:26:35.965044 45537 net.cpp:454] conv52 <- conv51
I0712 18:26:35.965062 45537 net.cpp:411] conv52 -> conv52
I0712 18:26:35.975733 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 18:26:35.975780 45537 net.cpp:150] Setting up conv52
I0712 18:26:35.975800 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.975813 45537 net.cpp:165] Memory required for data: 7809799264
I0712 18:26:35.975832 45537 layer_factory.hpp:76] Creating layer relu52
I0712 18:26:35.975854 45537 net.cpp:106] Creating Layer relu52
I0712 18:26:35.975869 45537 net.cpp:454] relu52 <- conv52
I0712 18:26:35.975886 45537 net.cpp:397] relu52 -> conv52 (in-place)
I0712 18:26:35.977668 45537 net.cpp:150] Setting up relu52
I0712 18:26:35.977695 45537 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:26:35.977710 45537 net.cpp:165] Memory required for data: 7842313312
I0712 18:26:35.977725 45537 layer_factory.hpp:76] Creating layer conv53
I0712 18:26:35.977756 45537 net.cpp:106] Creating Layer conv53
I0712 18:26:35.977771 45537 net.cpp:454] conv53 <- conv52
I0712 18:26:35.977797 45537 net.cpp:411] conv53 -> conv53
I0712 18:26:36.020885 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0712 18:26:36.021111 45537 net.cpp:150] Setting up conv53
I0712 18:26:36.021138 45537 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:26:36.021159 45537 net.cpp:165] Memory required for data: 7868929120
I0712 18:26:36.021181 45537 layer_factory.hpp:76] Creating layer relu53
I0712 18:26:36.021204 45537 net.cpp:106] Creating Layer relu53
I0712 18:26:36.021220 45537 net.cpp:454] relu53 <- conv53
I0712 18:26:36.021247 45537 net.cpp:397] relu53 -> conv53 (in-place)
I0712 18:26:36.022011 45537 net.cpp:150] Setting up relu53
I0712 18:26:36.022037 45537 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:26:36.022052 45537 net.cpp:165] Memory required for data: 7895544928
I0712 18:26:36.022065 45537 layer_factory.hpp:76] Creating layer conv54
I0712 18:26:36.022095 45537 net.cpp:106] Creating Layer conv54
I0712 18:26:36.022111 45537 net.cpp:454] conv54 <- conv53
I0712 18:26:36.022140 45537 net.cpp:411] conv54 -> conv54
I0712 18:26:36.027344 45537 net.cpp:150] Setting up conv54
I0712 18:26:36.027374 45537 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 18:26:36.027390 45537 net.cpp:165] Memory required for data: 7895752864
I0712 18:26:36.027410 45537 layer_factory.hpp:76] Creating layer interloss
I0712 18:26:36.027442 45537 net.cpp:106] Creating Layer interloss
I0712 18:26:36.027461 45537 net.cpp:454] interloss <- conv54
I0712 18:26:36.027478 45537 net.cpp:411] interloss -> interloss
I0712 18:26:36.029286 45537 net.cpp:150] Setting up interloss
I0712 18:26:36.029336 45537 net.cpp:157] Top shape: 8 2 57 57 (51984)
I0712 18:26:36.029351 45537 net.cpp:165] Memory required for data: 7895960800
I0712 18:26:36.029369 45537 layer_factory.hpp:76] Creating layer conv61
I0712 18:26:36.029399 45537 net.cpp:106] Creating Layer conv61
I0712 18:26:36.029417 45537 net.cpp:454] conv61 <- interloss
I0712 18:26:36.029434 45537 net.cpp:411] conv61 -> conv61
I0712 18:26:36.036170 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5614272
I0712 18:26:36.036427 45537 net.cpp:150] Setting up conv61
I0712 18:26:36.036453 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:36.036466 45537 net.cpp:165] Memory required for data: 7902614752
I0712 18:26:36.036487 45537 layer_factory.hpp:76] Creating layer relu61
I0712 18:26:36.036517 45537 net.cpp:106] Creating Layer relu61
I0712 18:26:36.036535 45537 net.cpp:454] relu61 <- conv61
I0712 18:26:36.036551 45537 net.cpp:397] relu61 -> conv61 (in-place)
I0712 18:26:36.037199 45537 net.cpp:150] Setting up relu61
I0712 18:26:36.037222 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:36.037236 45537 net.cpp:165] Memory required for data: 7909268704
I0712 18:26:36.037251 45537 layer_factory.hpp:76] Creating layer conv62
I0712 18:26:36.037295 45537 net.cpp:106] Creating Layer conv62
I0712 18:26:36.037314 45537 net.cpp:454] conv62 <- conv61
I0712 18:26:36.037335 45537 net.cpp:411] conv62 -> conv62
I0712 18:26:36.042103 45537 net.cpp:150] Setting up conv62
I0712 18:26:36.042135 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:36.042150 45537 net.cpp:165] Memory required for data: 7915922656
I0712 18:26:36.042171 45537 layer_factory.hpp:76] Creating layer relu62
I0712 18:26:36.042192 45537 net.cpp:106] Creating Layer relu62
I0712 18:26:36.042208 45537 net.cpp:454] relu62 <- conv62
I0712 18:26:36.042229 45537 net.cpp:397] relu62 -> conv62 (in-place)
I0712 18:26:36.044282 45537 net.cpp:150] Setting up relu62
I0712 18:26:36.044313 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:36.044328 45537 net.cpp:165] Memory required for data: 7922576608
I0712 18:26:36.044345 45537 layer_factory.hpp:76] Creating layer conv63
I0712 18:26:36.044373 45537 net.cpp:106] Creating Layer conv63
I0712 18:26:36.044389 45537 net.cpp:454] conv63 <- conv62
I0712 18:26:36.044414 45537 net.cpp:411] conv63 -> conv63
I0712 18:26:36.050525 45537 net.cpp:150] Setting up conv63
I0712 18:26:36.050559 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:36.050575 45537 net.cpp:165] Memory required for data: 7929230560
I0712 18:26:36.050595 45537 layer_factory.hpp:76] Creating layer relu63
I0712 18:26:36.050614 45537 net.cpp:106] Creating Layer relu63
I0712 18:26:36.050637 45537 net.cpp:454] relu63 <- conv63
I0712 18:26:36.050662 45537 net.cpp:397] relu63 -> conv63 (in-place)
I0712 18:26:36.053087 45537 net.cpp:150] Setting up relu63
I0712 18:26:36.053119 45537 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:26:36.053134 45537 net.cpp:165] Memory required for data: 7935884512
I0712 18:26:36.053149 45537 layer_factory.hpp:76] Creating layer pool5
I0712 18:26:36.053170 45537 net.cpp:106] Creating Layer pool5
I0712 18:26:36.053185 45537 net.cpp:454] pool5 <- conv63
I0712 18:26:36.053208 45537 net.cpp:411] pool5 -> pool5
I0712 18:26:36.054355 45537 net.cpp:150] Setting up pool5
I0712 18:26:36.054386 45537 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0712 18:26:36.054400 45537 net.cpp:165] Memory required for data: 7937606880
I0712 18:26:36.054415 45537 layer_factory.hpp:76] Creating layer conv71
I0712 18:26:36.054443 45537 net.cpp:106] Creating Layer conv71
I0712 18:26:36.054460 45537 net.cpp:454] conv71 <- pool5
I0712 18:26:36.054483 45537 net.cpp:411] conv71 -> conv71
I0712 18:26:36.060466 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:26:36.060534 45537 net.cpp:150] Setting up conv71
I0712 18:26:36.060554 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:36.060572 45537 net.cpp:165] Memory required for data: 7941051616
I0712 18:26:36.060595 45537 layer_factory.hpp:76] Creating layer relu71
I0712 18:26:36.060643 45537 net.cpp:106] Creating Layer relu71
I0712 18:26:36.060663 45537 net.cpp:454] relu71 <- conv71
I0712 18:26:36.060679 45537 net.cpp:397] relu71 -> conv71 (in-place)
I0712 18:26:36.062719 45537 net.cpp:150] Setting up relu71
I0712 18:26:36.062750 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:36.062764 45537 net.cpp:165] Memory required for data: 7944496352
I0712 18:26:36.062779 45537 layer_factory.hpp:76] Creating layer conv72
I0712 18:26:36.062803 45537 net.cpp:106] Creating Layer conv72
I0712 18:26:36.062819 45537 net.cpp:454] conv72 <- conv71
I0712 18:26:36.062841 45537 net.cpp:411] conv72 -> conv72
I0712 18:26:36.069911 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:36.069988 45537 net.cpp:150] Setting up conv72
I0712 18:26:36.070010 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:36.070024 45537 net.cpp:165] Memory required for data: 7947941088
I0712 18:26:36.070058 45537 layer_factory.hpp:76] Creating layer relu72
I0712 18:26:36.070082 45537 net.cpp:106] Creating Layer relu72
I0712 18:26:36.070097 45537 net.cpp:454] relu72 <- conv72
I0712 18:26:36.070113 45537 net.cpp:397] relu72 -> conv72 (in-place)
I0712 18:26:36.070940 45537 net.cpp:150] Setting up relu72
I0712 18:26:36.070981 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:36.070994 45537 net.cpp:165] Memory required for data: 7951385824
I0712 18:26:36.071008 45537 layer_factory.hpp:76] Creating layer conv73
I0712 18:26:36.071035 45537 net.cpp:106] Creating Layer conv73
I0712 18:26:36.071053 45537 net.cpp:454] conv73 <- conv72
I0712 18:26:36.071074 45537 net.cpp:411] conv73 -> conv73
I0712 18:26:36.077728 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:26:36.077785 45537 net.cpp:150] Setting up conv73
I0712 18:26:36.077807 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:36.077821 45537 net.cpp:165] Memory required for data: 7954830560
I0712 18:26:36.077841 45537 layer_factory.hpp:76] Creating layer relu73
I0712 18:26:36.077857 45537 net.cpp:106] Creating Layer relu73
I0712 18:26:36.077872 45537 net.cpp:454] relu73 <- conv73
I0712 18:26:36.077890 45537 net.cpp:397] relu73 -> conv73 (in-place)
I0712 18:26:36.079898 45537 net.cpp:150] Setting up relu73
I0712 18:26:36.079926 45537 net.cpp:157] Top shape: 8 128 29 29 (861184)
I0712 18:26:36.079939 45537 net.cpp:165] Memory required for data: 7958275296
I0712 18:26:36.079952 45537 layer_factory.hpp:76] Creating layer pool6
I0712 18:26:36.079973 45537 net.cpp:106] Creating Layer pool6
I0712 18:26:36.079987 45537 net.cpp:454] pool6 <- conv73
I0712 18:26:36.080001 45537 net.cpp:411] pool6 -> pool6
I0712 18:26:36.082265 45537 net.cpp:150] Setting up pool6
I0712 18:26:36.082298 45537 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:26:36.082311 45537 net.cpp:165] Memory required for data: 7959196896
I0712 18:26:36.082324 45537 layer_factory.hpp:76] Creating layer drop0
I0712 18:26:36.082340 45537 net.cpp:106] Creating Layer drop0
I0712 18:26:36.082353 45537 net.cpp:454] drop0 <- pool6
I0712 18:26:36.082367 45537 net.cpp:397] drop0 -> pool6 (in-place)
I0712 18:26:36.082422 45537 net.cpp:150] Setting up drop0
I0712 18:26:36.082442 45537 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:26:36.082454 45537 net.cpp:165] Memory required for data: 7960118496
I0712 18:26:36.082466 45537 layer_factory.hpp:76] Creating layer conv81
I0712 18:26:36.082494 45537 net.cpp:106] Creating Layer conv81
I0712 18:26:36.082506 45537 net.cpp:454] conv81 <- pool6
I0712 18:26:36.082526 45537 net.cpp:411] conv81 -> conv81
I0712 18:26:36.090528 45537 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345600
I0712 18:26:36.090586 45537 net.cpp:150] Setting up conv81
I0712 18:26:36.090603 45537 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:26:36.090612 45537 net.cpp:165] Memory required for data: 7960118592
I0712 18:26:36.090626 45537 layer_factory.hpp:76] Creating layer conv81_conv81_0_split
I0712 18:26:36.090651 45537 net.cpp:106] Creating Layer conv81_conv81_0_split
I0712 18:26:36.090683 45537 net.cpp:454] conv81_conv81_0_split <- conv81
I0712 18:26:36.090697 45537 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_0
I0712 18:26:36.090709 45537 net.cpp:411] conv81_conv81_0_split -> conv81_conv81_0_split_1
I0712 18:26:36.090770 45537 net.cpp:150] Setting up conv81_conv81_0_split
I0712 18:26:36.090783 45537 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:26:36.090793 45537 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:26:36.090801 45537 net.cpp:165] Memory required for data: 7960118784
I0712 18:26:36.090809 45537 layer_factory.hpp:76] Creating layer accuracy
I0712 18:26:36.090821 45537 net.cpp:106] Creating Layer accuracy
I0712 18:26:36.090831 45537 net.cpp:454] accuracy <- conv81_conv81_0_split_0
I0712 18:26:36.090839 45537 net.cpp:454] accuracy <- label_data_1_split_0
I0712 18:26:36.090852 45537 net.cpp:411] accuracy -> accuracy
I0712 18:26:36.090870 45537 net.cpp:150] Setting up accuracy
I0712 18:26:36.090885 45537 net.cpp:157] Top shape: (1)
I0712 18:26:36.090893 45537 net.cpp:165] Memory required for data: 7960118788
I0712 18:26:36.090901 45537 layer_factory.hpp:76] Creating layer loss
I0712 18:26:36.090921 45537 net.cpp:106] Creating Layer loss
I0712 18:26:36.090930 45537 net.cpp:454] loss <- conv81_conv81_0_split_1
I0712 18:26:36.090940 45537 net.cpp:454] loss <- label_data_1_split_1
I0712 18:26:36.090950 45537 net.cpp:411] loss -> loss
I0712 18:26:36.090963 45537 layer_factory.hpp:76] Creating layer loss
I0712 18:26:36.093058 45537 net.cpp:150] Setting up loss
I0712 18:26:36.093080 45537 net.cpp:157] Top shape: (1)
I0712 18:26:36.093088 45537 net.cpp:160]     with loss weight 1
I0712 18:26:36.093106 45537 net.cpp:165] Memory required for data: 7960118792
I0712 18:26:36.093114 45537 net.cpp:226] loss needs backward computation.
I0712 18:26:36.093123 45537 net.cpp:228] accuracy does not need backward computation.
I0712 18:26:36.093132 45537 net.cpp:226] conv81_conv81_0_split needs backward computation.
I0712 18:26:36.093140 45537 net.cpp:226] conv81 needs backward computation.
I0712 18:26:36.093148 45537 net.cpp:226] drop0 needs backward computation.
I0712 18:26:36.093156 45537 net.cpp:226] pool6 needs backward computation.
I0712 18:26:36.093164 45537 net.cpp:226] relu73 needs backward computation.
I0712 18:26:36.093173 45537 net.cpp:226] conv73 needs backward computation.
I0712 18:26:36.093180 45537 net.cpp:226] relu72 needs backward computation.
I0712 18:26:36.093189 45537 net.cpp:226] conv72 needs backward computation.
I0712 18:26:36.093196 45537 net.cpp:226] relu71 needs backward computation.
I0712 18:26:36.093204 45537 net.cpp:226] conv71 needs backward computation.
I0712 18:26:36.093214 45537 net.cpp:226] pool5 needs backward computation.
I0712 18:26:36.093221 45537 net.cpp:226] relu63 needs backward computation.
I0712 18:26:36.093230 45537 net.cpp:226] conv63 needs backward computation.
I0712 18:26:36.093237 45537 net.cpp:226] relu62 needs backward computation.
I0712 18:26:36.093245 45537 net.cpp:226] conv62 needs backward computation.
I0712 18:26:36.093252 45537 net.cpp:226] relu61 needs backward computation.
I0712 18:26:36.093261 45537 net.cpp:226] conv61 needs backward computation.
I0712 18:26:36.093268 45537 net.cpp:226] interloss needs backward computation.
I0712 18:26:36.093276 45537 net.cpp:226] conv54 needs backward computation.
I0712 18:26:36.093286 45537 net.cpp:228] relu53 does not need backward computation.
I0712 18:26:36.093293 45537 net.cpp:228] conv53 does not need backward computation.
I0712 18:26:36.093302 45537 net.cpp:228] relu52 does not need backward computation.
I0712 18:26:36.093309 45537 net.cpp:228] conv52 does not need backward computation.
I0712 18:26:36.093317 45537 net.cpp:228] relu51 does not need backward computation.
I0712 18:26:36.093325 45537 net.cpp:228] conv51 does not need backward computation.
I0712 18:26:36.093333 45537 net.cpp:228] pool4 does not need backward computation.
I0712 18:26:36.093343 45537 net.cpp:228] relu42 does not need backward computation.
I0712 18:26:36.093350 45537 net.cpp:228] conv42 does not need backward computation.
I0712 18:26:36.093370 45537 net.cpp:228] relu41 does not need backward computation.
I0712 18:26:36.093382 45537 net.cpp:228] conv41 does not need backward computation.
I0712 18:26:36.093390 45537 net.cpp:228] pool3 does not need backward computation.
I0712 18:26:36.093400 45537 net.cpp:228] relu32 does not need backward computation.
I0712 18:26:36.093407 45537 net.cpp:228] conv32 does not need backward computation.
I0712 18:26:36.093415 45537 net.cpp:228] relu31 does not need backward computation.
I0712 18:26:36.093423 45537 net.cpp:228] conv31 does not need backward computation.
I0712 18:26:36.093432 45537 net.cpp:228] pool2 does not need backward computation.
I0712 18:26:36.093441 45537 net.cpp:228] relu22 does not need backward computation.
I0712 18:26:36.093448 45537 net.cpp:228] conv22 does not need backward computation.
I0712 18:26:36.093456 45537 net.cpp:228] relu21 does not need backward computation.
I0712 18:26:36.093464 45537 net.cpp:228] conv21 does not need backward computation.
I0712 18:26:36.093472 45537 net.cpp:228] pool1 does not need backward computation.
I0712 18:26:36.093480 45537 net.cpp:228] relu12 does not need backward computation.
I0712 18:26:36.093488 45537 net.cpp:228] conv12 does not need backward computation.
I0712 18:26:36.093497 45537 net.cpp:228] relu11 does not need backward computation.
I0712 18:26:36.093505 45537 net.cpp:228] conv11 does not need backward computation.
I0712 18:26:36.093513 45537 net.cpp:228] label_data_1_split does not need backward computation.
I0712 18:26:36.093523 45537 net.cpp:228] data does not need backward computation.
I0712 18:26:36.093530 45537 net.cpp:270] This network produces output accuracy
I0712 18:26:36.093538 45537 net.cpp:270] This network produces output loss
I0712 18:26:36.093571 45537 net.cpp:283] Network initialization done.
I0712 18:26:36.093894 45537 solver.cpp:59] Solver scaffolding done.
I0712 18:26:36.095598 45537 caffe.cpp:128] Finetuning from models/cnn10_iter_217316.caffemodel
I0712 18:26:36.226343 45537 caffe.cpp:212] Starting Optimization
I0712 18:26:36.226441 45537 solver.cpp:287] Solving FaceNN
I0712 18:26:36.226461 45537 solver.cpp:288] Learning Rate Policy: step
I0712 18:26:37.057721 45537 solver.cpp:236] Iteration 0, loss = 1.12287
I0712 18:26:37.057781 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 18:26:37.057806 45537 solver.cpp:252]     Train net output #1: loss = 1.12287 (* 1 = 1.12287 loss)
I0712 18:26:37.057857 45537 sgd_solver.cpp:106] Iteration 0, lr = 0.015
I0712 18:26:38.181110 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 18:28:16.714740 45537 solver.cpp:236] Iteration 100, loss = 1.06263
I0712 18:28:16.731786 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:28:16.731809 45537 solver.cpp:252]     Train net output #1: loss = 1.01545 (* 1 = 1.01545 loss)
I0712 18:28:16.731822 45537 sgd_solver.cpp:106] Iteration 100, lr = 0.015
I0712 18:29:56.299134 45537 solver.cpp:236] Iteration 200, loss = 1.06896
I0712 18:29:56.299479 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:29:56.299515 45537 solver.cpp:252]     Train net output #1: loss = 1.04219 (* 1 = 1.04219 loss)
I0712 18:29:56.299526 45537 sgd_solver.cpp:106] Iteration 200, lr = 0.015
I0712 18:31:35.630610 45537 solver.cpp:236] Iteration 300, loss = 1.07219
I0712 18:31:35.630854 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:31:35.630875 45537 solver.cpp:252]     Train net output #1: loss = 1.04295 (* 1 = 1.04295 loss)
I0712 18:31:35.630890 45537 sgd_solver.cpp:106] Iteration 300, lr = 0.015
I0712 18:33:14.695649 45537 solver.cpp:236] Iteration 400, loss = 1.0695
I0712 18:33:14.695870 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:33:14.695893 45537 solver.cpp:252]     Train net output #1: loss = 1.09115 (* 1 = 1.09115 loss)
I0712 18:33:14.695911 45537 sgd_solver.cpp:106] Iteration 400, lr = 0.015
I0712 18:34:54.030241 45537 solver.cpp:236] Iteration 500, loss = 1.04391
I0712 18:34:54.030478 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 18:34:54.030506 45537 solver.cpp:252]     Train net output #1: loss = 0.962276 (* 1 = 0.962276 loss)
I0712 18:34:54.030526 45537 sgd_solver.cpp:106] Iteration 500, lr = 0.015
I0712 18:36:33.726704 45537 solver.cpp:236] Iteration 600, loss = 1.08601
I0712 18:36:33.726883 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:36:33.726903 45537 solver.cpp:252]     Train net output #1: loss = 1.09591 (* 1 = 1.09591 loss)
I0712 18:36:33.726919 45537 sgd_solver.cpp:106] Iteration 600, lr = 0.015
I0712 18:38:13.155560 45537 solver.cpp:236] Iteration 700, loss = 1.06849
I0712 18:38:13.155712 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 18:38:13.155735 45537 solver.cpp:252]     Train net output #1: loss = 1.01202 (* 1 = 1.01202 loss)
I0712 18:38:13.155748 45537 sgd_solver.cpp:106] Iteration 700, lr = 0.015
I0712 18:39:52.865643 45537 solver.cpp:236] Iteration 800, loss = 1.05615
I0712 18:39:52.865888 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 18:39:52.865913 45537 solver.cpp:252]     Train net output #1: loss = 0.974438 (* 1 = 0.974438 loss)
I0712 18:39:52.865936 45537 sgd_solver.cpp:106] Iteration 800, lr = 0.015
I0712 18:41:32.108590 45537 solver.cpp:236] Iteration 900, loss = 1.06253
I0712 18:41:32.108752 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:41:32.108785 45537 solver.cpp:252]     Train net output #1: loss = 1.198 (* 1 = 1.198 loss)
I0712 18:41:32.108804 45537 sgd_solver.cpp:106] Iteration 900, lr = 0.015
I0712 18:43:11.737974 45537 solver.cpp:236] Iteration 1000, loss = 1.07149
I0712 18:43:11.738123 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:43:11.738144 45537 solver.cpp:252]     Train net output #1: loss = 1.0175 (* 1 = 1.0175 loss)
I0712 18:43:11.738158 45537 sgd_solver.cpp:106] Iteration 1000, lr = 0.015
I0712 18:44:44.928470 45537 solver.cpp:236] Iteration 1100, loss = 1.0707
I0712 18:44:44.928644 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 18:44:44.928676 45537 solver.cpp:252]     Train net output #1: loss = 0.999221 (* 1 = 0.999221 loss)
I0712 18:44:44.928689 45537 sgd_solver.cpp:106] Iteration 1100, lr = 0.015
I0712 18:46:05.037955 45537 solver.cpp:236] Iteration 1200, loss = 1.05986
I0712 18:46:05.038094 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:46:05.038111 45537 solver.cpp:252]     Train net output #1: loss = 0.996537 (* 1 = 0.996537 loss)
I0712 18:46:05.038125 45537 sgd_solver.cpp:106] Iteration 1200, lr = 0.015
I0712 18:46:29.859414 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 18:47:28.939370 45537 solver.cpp:236] Iteration 1300, loss = 1.08487
I0712 18:47:28.939582 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:47:28.939616 45537 solver.cpp:252]     Train net output #1: loss = 1.10802 (* 1 = 1.10802 loss)
I0712 18:47:28.939630 45537 sgd_solver.cpp:106] Iteration 1300, lr = 0.015
I0712 18:48:49.078168 45537 solver.cpp:236] Iteration 1400, loss = 1.08256
I0712 18:48:49.078353 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:48:49.078374 45537 solver.cpp:252]     Train net output #1: loss = 1.08841 (* 1 = 1.08841 loss)
I0712 18:48:49.078392 45537 sgd_solver.cpp:106] Iteration 1400, lr = 0.015
I0712 18:50:08.428791 45537 solver.cpp:340] Iteration 1500, Testing net (#0)
I0712 18:51:25.995342 45537 solver.cpp:408]     Test net output #0: accuracy = 0.455
I0712 18:51:25.995514 45537 solver.cpp:408]     Test net output #1: loss = 1.06109 (* 1 = 1.06109 loss)
I0712 18:51:26.765548 45537 solver.cpp:236] Iteration 1500, loss = 1.07546
I0712 18:51:26.765601 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:51:26.765620 45537 solver.cpp:252]     Train net output #1: loss = 1.04893 (* 1 = 1.04893 loss)
I0712 18:51:26.765637 45537 sgd_solver.cpp:106] Iteration 1500, lr = 0.015
I0712 18:52:46.943019 45537 solver.cpp:236] Iteration 1600, loss = 1.06132
I0712 18:52:46.943331 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:52:46.943366 45537 solver.cpp:252]     Train net output #1: loss = 1.0956 (* 1 = 1.0956 loss)
I0712 18:52:46.943377 45537 sgd_solver.cpp:106] Iteration 1600, lr = 0.015
I0712 18:54:07.065320 45537 solver.cpp:236] Iteration 1700, loss = 1.06727
I0712 18:54:07.065457 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 18:54:07.065476 45537 solver.cpp:252]     Train net output #1: loss = 1.06124 (* 1 = 1.06124 loss)
I0712 18:54:07.065490 45537 sgd_solver.cpp:106] Iteration 1700, lr = 0.015
I0712 18:55:27.258299 45537 solver.cpp:236] Iteration 1800, loss = 1.07614
I0712 18:55:27.258496 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:55:27.258530 45537 solver.cpp:252]     Train net output #1: loss = 1.17436 (* 1 = 1.17436 loss)
I0712 18:55:27.258546 45537 sgd_solver.cpp:106] Iteration 1800, lr = 0.015
I0712 18:56:47.361110 45537 solver.cpp:236] Iteration 1900, loss = 1.08086
I0712 18:56:47.361289 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0712 18:56:47.361310 45537 solver.cpp:252]     Train net output #1: loss = 0.891597 (* 1 = 0.891597 loss)
I0712 18:56:47.361325 45537 sgd_solver.cpp:106] Iteration 1900, lr = 0.015
I0712 18:58:07.466501 45537 solver.cpp:236] Iteration 2000, loss = 1.063
I0712 18:58:07.466673 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:58:07.466694 45537 solver.cpp:252]     Train net output #1: loss = 1.13328 (* 1 = 1.13328 loss)
I0712 18:58:07.466708 45537 sgd_solver.cpp:106] Iteration 2000, lr = 0.015
I0712 18:59:27.696499 45537 solver.cpp:236] Iteration 2100, loss = 1.05268
I0712 18:59:27.696712 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:59:27.696729 45537 solver.cpp:252]     Train net output #1: loss = 1.10134 (* 1 = 1.10134 loss)
I0712 18:59:27.696744 45537 sgd_solver.cpp:106] Iteration 2100, lr = 0.015
I0712 19:00:03.824128 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 19:00:47.893934 45537 solver.cpp:236] Iteration 2200, loss = 1.06968
I0712 19:00:47.894111 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 19:00:47.894142 45537 solver.cpp:252]     Train net output #1: loss = 0.995614 (* 1 = 0.995614 loss)
I0712 19:00:47.894156 45537 sgd_solver.cpp:106] Iteration 2200, lr = 0.015
I0712 19:02:08.030244 45537 solver.cpp:236] Iteration 2300, loss = 1.0849
I0712 19:02:08.030411 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 19:02:08.030432 45537 solver.cpp:252]     Train net output #1: loss = 1.18019 (* 1 = 1.18019 loss)
I0712 19:02:08.030447 45537 sgd_solver.cpp:106] Iteration 2300, lr = 0.015
I0712 19:03:28.104362 45537 solver.cpp:236] Iteration 2400, loss = 1.08649
I0712 19:03:28.104559 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:03:28.104579 45537 solver.cpp:252]     Train net output #1: loss = 1.05456 (* 1 = 1.05456 loss)
I0712 19:03:28.104593 45537 sgd_solver.cpp:106] Iteration 2400, lr = 0.015
I0712 19:04:48.313580 45537 solver.cpp:236] Iteration 2500, loss = 1.08771
I0712 19:04:48.313781 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:04:48.313825 45537 solver.cpp:252]     Train net output #1: loss = 1.0487 (* 1 = 1.0487 loss)
I0712 19:04:48.313840 45537 sgd_solver.cpp:106] Iteration 2500, lr = 0.015
I0712 19:06:08.526219 45537 solver.cpp:236] Iteration 2600, loss = 1.05129
I0712 19:06:08.526371 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 19:06:08.526409 45537 solver.cpp:252]     Train net output #1: loss = 1.36638 (* 1 = 1.36638 loss)
I0712 19:06:08.526423 45537 sgd_solver.cpp:106] Iteration 2600, lr = 0.015
I0712 19:07:28.628809 45537 solver.cpp:236] Iteration 2700, loss = 1.08246
I0712 19:07:28.629067 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:07:28.629093 45537 solver.cpp:252]     Train net output #1: loss = 1.07996 (* 1 = 1.07996 loss)
I0712 19:07:28.629112 45537 sgd_solver.cpp:106] Iteration 2700, lr = 0.015
I0712 19:08:48.733588 45537 solver.cpp:236] Iteration 2800, loss = 1.07842
I0712 19:08:48.733880 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:08:48.733903 45537 solver.cpp:252]     Train net output #1: loss = 0.972618 (* 1 = 0.972618 loss)
I0712 19:08:48.733917 45537 sgd_solver.cpp:106] Iteration 2800, lr = 0.015
I0712 19:10:08.840257 45537 solver.cpp:236] Iteration 2900, loss = 1.06643
I0712 19:10:08.840409 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:10:08.840427 45537 solver.cpp:252]     Train net output #1: loss = 1.09444 (* 1 = 1.09444 loss)
I0712 19:10:08.840452 45537 sgd_solver.cpp:106] Iteration 2900, lr = 0.015
I0712 19:11:28.244225 45537 solver.cpp:340] Iteration 3000, Testing net (#0)
I0712 19:12:45.445917 45537 solver.cpp:408]     Test net output #0: accuracy = 0.47
I0712 19:12:45.446086 45537 solver.cpp:408]     Test net output #1: loss = 1.05738 (* 1 = 1.05738 loss)
I0712 19:12:46.213153 45537 solver.cpp:236] Iteration 3000, loss = 1.06761
I0712 19:12:46.213209 45537 solver.cpp:252]     Train net output #0: accuracy = 0
I0712 19:12:46.213227 45537 solver.cpp:252]     Train net output #1: loss = 1.26332 (* 1 = 1.26332 loss)
I0712 19:12:46.213243 45537 sgd_solver.cpp:106] Iteration 3000, lr = 0.015
I0712 19:14:06.349776 45537 solver.cpp:236] Iteration 3100, loss = 1.07193
I0712 19:14:06.349920 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:14:06.349938 45537 solver.cpp:252]     Train net output #1: loss = 1.06522 (* 1 = 1.06522 loss)
I0712 19:14:06.349961 45537 sgd_solver.cpp:106] Iteration 3100, lr = 0.015
I0712 19:15:26.454290 45537 solver.cpp:236] Iteration 3200, loss = 1.05254
I0712 19:15:26.454452 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:15:26.454471 45537 solver.cpp:252]     Train net output #1: loss = 1.09384 (* 1 = 1.09384 loss)
I0712 19:15:26.454486 45537 sgd_solver.cpp:106] Iteration 3200, lr = 0.015
I0712 19:16:46.572728 45537 solver.cpp:236] Iteration 3300, loss = 1.06553
I0712 19:16:46.572839 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:16:46.572857 45537 solver.cpp:252]     Train net output #1: loss = 1.1672 (* 1 = 1.1672 loss)
I0712 19:16:46.572871 45537 sgd_solver.cpp:106] Iteration 3300, lr = 0.015
I0712 19:18:06.681171 45537 solver.cpp:236] Iteration 3400, loss = 1.06744
I0712 19:18:06.681308 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:18:06.681327 45537 solver.cpp:252]     Train net output #1: loss = 1.23473 (* 1 = 1.23473 loss)
I0712 19:18:06.681341 45537 sgd_solver.cpp:106] Iteration 3400, lr = 0.015
I0712 19:19:26.782583 45537 solver.cpp:236] Iteration 3500, loss = 1.05161
I0712 19:19:26.782829 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 19:19:26.782857 45537 solver.cpp:252]     Train net output #1: loss = 0.92427 (* 1 = 0.92427 loss)
I0712 19:19:26.782868 45537 sgd_solver.cpp:106] Iteration 3500, lr = 0.015
I0712 19:20:46.892272 45537 solver.cpp:236] Iteration 3600, loss = 1.07181
I0712 19:20:46.892419 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:20:46.892441 45537 solver.cpp:252]     Train net output #1: loss = 1.10407 (* 1 = 1.10407 loss)
I0712 19:20:46.892458 45537 sgd_solver.cpp:106] Iteration 3600, lr = 0.015
I0712 19:22:07.004154 45537 solver.cpp:236] Iteration 3700, loss = 1.05985
I0712 19:22:07.004272 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:22:07.004290 45537 solver.cpp:252]     Train net output #1: loss = 1.01052 (* 1 = 1.01052 loss)
I0712 19:22:07.004304 45537 sgd_solver.cpp:106] Iteration 3700, lr = 0.015
I0712 19:23:27.104161 45537 solver.cpp:236] Iteration 3800, loss = 1.05342
I0712 19:23:27.104297 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:23:27.104316 45537 solver.cpp:252]     Train net output #1: loss = 1.00313 (* 1 = 1.00313 loss)
I0712 19:23:27.104329 45537 sgd_solver.cpp:106] Iteration 3800, lr = 0.015
I0712 19:24:47.206904 45537 solver.cpp:236] Iteration 3900, loss = 1.07608
I0712 19:24:47.207126 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:24:47.207152 45537 solver.cpp:252]     Train net output #1: loss = 1.1104 (* 1 = 1.1104 loss)
I0712 19:24:47.207166 45537 sgd_solver.cpp:106] Iteration 3900, lr = 0.015
I0712 19:26:07.320675 45537 solver.cpp:236] Iteration 4000, loss = 1.06702
I0712 19:26:07.320798 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:26:07.320817 45537 solver.cpp:252]     Train net output #1: loss = 1.09979 (* 1 = 1.09979 loss)
I0712 19:26:07.320830 45537 sgd_solver.cpp:106] Iteration 4000, lr = 0.015
I0712 19:27:27.435546 45537 solver.cpp:236] Iteration 4100, loss = 1.06406
I0712 19:27:27.435693 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:27:27.435713 45537 solver.cpp:252]     Train net output #1: loss = 1.04533 (* 1 = 1.04533 loss)
I0712 19:27:27.435727 45537 sgd_solver.cpp:106] Iteration 4100, lr = 0.015
I0712 19:28:47.531765 45537 solver.cpp:236] Iteration 4200, loss = 1.0505
I0712 19:28:47.531939 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:28:47.531972 45537 solver.cpp:252]     Train net output #1: loss = 1.1916 (* 1 = 1.1916 loss)
I0712 19:28:47.531993 45537 sgd_solver.cpp:106] Iteration 4200, lr = 0.015
I0712 19:29:52.424459 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 19:30:07.641800 45537 solver.cpp:236] Iteration 4300, loss = 1.05606
I0712 19:30:07.641862 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 19:30:07.641885 45537 solver.cpp:252]     Train net output #1: loss = 0.981681 (* 1 = 0.981681 loss)
I0712 19:30:07.641898 45537 sgd_solver.cpp:106] Iteration 4300, lr = 0.015
I0712 19:31:27.747705 45537 solver.cpp:236] Iteration 4400, loss = 1.07676
I0712 19:31:27.747840 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 19:31:27.747860 45537 solver.cpp:252]     Train net output #1: loss = 0.948623 (* 1 = 0.948623 loss)
I0712 19:31:27.747881 45537 sgd_solver.cpp:106] Iteration 4400, lr = 0.015
I0712 19:32:47.055526 45537 solver.cpp:340] Iteration 4500, Testing net (#0)
I0712 19:34:04.128374 45537 solver.cpp:408]     Test net output #0: accuracy = 0.46125
I0712 19:34:04.128516 45537 solver.cpp:408]     Test net output #1: loss = 1.06565 (* 1 = 1.06565 loss)
I0712 19:34:04.897672 45537 solver.cpp:236] Iteration 4500, loss = 1.08099
I0712 19:34:04.897721 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:34:04.897738 45537 solver.cpp:252]     Train net output #1: loss = 1.06208 (* 1 = 1.06208 loss)
I0712 19:34:04.897756 45537 sgd_solver.cpp:106] Iteration 4500, lr = 0.015
I0712 19:35:24.966976 45537 solver.cpp:236] Iteration 4600, loss = 1.07843
I0712 19:35:24.967113 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 19:35:24.967131 45537 solver.cpp:252]     Train net output #1: loss = 1.04936 (* 1 = 1.04936 loss)
I0712 19:35:24.967155 45537 sgd_solver.cpp:106] Iteration 4600, lr = 0.015
I0712 19:36:45.081521 45537 solver.cpp:236] Iteration 4700, loss = 1.08781
I0712 19:36:45.081666 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:36:45.081686 45537 solver.cpp:252]     Train net output #1: loss = 1.25101 (* 1 = 1.25101 loss)
I0712 19:36:45.081701 45537 sgd_solver.cpp:106] Iteration 4700, lr = 0.015
I0712 19:38:05.179118 45537 solver.cpp:236] Iteration 4800, loss = 1.05616
I0712 19:38:05.179256 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0712 19:38:05.179286 45537 solver.cpp:252]     Train net output #1: loss = 0.801514 (* 1 = 0.801514 loss)
I0712 19:38:05.179301 45537 sgd_solver.cpp:106] Iteration 4800, lr = 0.015
I0712 19:39:25.286126 45537 solver.cpp:236] Iteration 4900, loss = 1.09183
I0712 19:39:25.286249 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 19:39:25.286270 45537 solver.cpp:252]     Train net output #1: loss = 1.09016 (* 1 = 1.09016 loss)
I0712 19:39:25.286283 45537 sgd_solver.cpp:106] Iteration 4900, lr = 0.015
I0712 19:40:44.650478 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_5000.caffemodel
I0712 19:40:45.004146 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_5000.solverstate
I0712 19:40:45.799290 45537 solver.cpp:236] Iteration 5000, loss = 1.07297
I0712 19:40:45.799351 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:40:45.799368 45537 solver.cpp:252]     Train net output #1: loss = 1.15139 (* 1 = 1.15139 loss)
I0712 19:40:45.799381 45537 sgd_solver.cpp:106] Iteration 5000, lr = 0.015
I0712 19:42:05.890420 45537 solver.cpp:236] Iteration 5100, loss = 1.05469
I0712 19:42:05.890547 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:42:05.890565 45537 solver.cpp:252]     Train net output #1: loss = 1.04262 (* 1 = 1.04262 loss)
I0712 19:42:05.890578 45537 sgd_solver.cpp:106] Iteration 5100, lr = 0.015
I0712 19:43:26.006819 45537 solver.cpp:236] Iteration 5200, loss = 1.07958
I0712 19:43:26.006964 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 19:43:26.006984 45537 solver.cpp:252]     Train net output #1: loss = 1.05744 (* 1 = 1.05744 loss)
I0712 19:43:26.007001 45537 sgd_solver.cpp:106] Iteration 5200, lr = 0.015
I0712 19:44:46.109596 45537 solver.cpp:236] Iteration 5300, loss = 1.04654
I0712 19:44:46.109720 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:44:46.109738 45537 solver.cpp:252]     Train net output #1: loss = 1.01969 (* 1 = 1.01969 loss)
I0712 19:44:46.109751 45537 sgd_solver.cpp:106] Iteration 5300, lr = 0.015
I0712 19:46:06.220957 45537 solver.cpp:236] Iteration 5400, loss = 1.08715
I0712 19:46:06.221118 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:46:06.221138 45537 solver.cpp:252]     Train net output #1: loss = 1.15865 (* 1 = 1.15865 loss)
I0712 19:46:06.221153 45537 sgd_solver.cpp:106] Iteration 5400, lr = 0.015
I0712 19:47:26.331055 45537 solver.cpp:236] Iteration 5500, loss = 1.08043
I0712 19:47:26.331194 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:47:26.331212 45537 solver.cpp:252]     Train net output #1: loss = 1.0252 (* 1 = 1.0252 loss)
I0712 19:47:26.331228 45537 sgd_solver.cpp:106] Iteration 5500, lr = 0.015
I0712 19:48:46.423552 45537 solver.cpp:236] Iteration 5600, loss = 1.07489
I0712 19:48:46.423686 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:48:46.423703 45537 solver.cpp:252]     Train net output #1: loss = 1.13137 (* 1 = 1.13137 loss)
I0712 19:48:46.423725 45537 sgd_solver.cpp:106] Iteration 5600, lr = 0.015
I0712 19:50:06.530717 45537 solver.cpp:236] Iteration 5700, loss = 1.0797
I0712 19:50:06.530859 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 19:50:06.530879 45537 solver.cpp:252]     Train net output #1: loss = 1.17637 (* 1 = 1.17637 loss)
I0712 19:50:06.530892 45537 sgd_solver.cpp:106] Iteration 5700, lr = 0.015
I0712 19:50:21.752439 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 19:51:26.639289 45537 solver.cpp:236] Iteration 5800, loss = 1.04887
I0712 19:51:26.639518 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 19:51:26.639547 45537 solver.cpp:252]     Train net output #1: loss = 0.912141 (* 1 = 0.912141 loss)
I0712 19:51:26.639559 45537 sgd_solver.cpp:106] Iteration 5800, lr = 0.015
I0712 19:52:46.739842 45537 solver.cpp:236] Iteration 5900, loss = 1.07336
I0712 19:52:46.739948 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 19:52:46.739967 45537 solver.cpp:252]     Train net output #1: loss = 1.01662 (* 1 = 1.01662 loss)
I0712 19:52:46.739980 45537 sgd_solver.cpp:106] Iteration 5900, lr = 0.015
I0712 19:54:06.046389 45537 solver.cpp:340] Iteration 6000, Testing net (#0)
I0712 19:55:22.943130 45537 solver.cpp:408]     Test net output #0: accuracy = 0.44625
I0712 19:55:22.943337 45537 solver.cpp:408]     Test net output #1: loss = 1.07829 (* 1 = 1.07829 loss)
I0712 19:55:23.719321 45537 solver.cpp:236] Iteration 6000, loss = 1.06856
I0712 19:55:23.719373 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 19:55:23.719393 45537 solver.cpp:252]     Train net output #1: loss = 1.30104 (* 1 = 1.30104 loss)
I0712 19:55:23.719409 45537 sgd_solver.cpp:106] Iteration 6000, lr = 0.015
I0712 19:56:43.762111 45537 solver.cpp:236] Iteration 6100, loss = 1.04972
I0712 19:56:43.762374 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 19:56:43.762395 45537 solver.cpp:252]     Train net output #1: loss = 0.89524 (* 1 = 0.89524 loss)
I0712 19:56:43.762409 45537 sgd_solver.cpp:106] Iteration 6100, lr = 0.015
I0712 19:58:03.875527 45537 solver.cpp:236] Iteration 6200, loss = 1.05742
I0712 19:58:03.875651 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 19:58:03.875674 45537 solver.cpp:252]     Train net output #1: loss = 0.905611 (* 1 = 0.905611 loss)
I0712 19:58:03.875689 45537 sgd_solver.cpp:106] Iteration 6200, lr = 0.015
I0712 19:59:23.983228 45537 solver.cpp:236] Iteration 6300, loss = 1.08268
I0712 19:59:23.983357 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 19:59:23.983376 45537 solver.cpp:252]     Train net output #1: loss = 0.976311 (* 1 = 0.976311 loss)
I0712 19:59:23.983397 45537 sgd_solver.cpp:106] Iteration 6300, lr = 0.015
I0712 20:00:44.101984 45537 solver.cpp:236] Iteration 6400, loss = 1.08155
I0712 20:00:44.102202 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:00:44.102222 45537 solver.cpp:252]     Train net output #1: loss = 1.00522 (* 1 = 1.00522 loss)
I0712 20:00:44.102241 45537 sgd_solver.cpp:106] Iteration 6400, lr = 0.015
I0712 20:02:04.208745 45537 solver.cpp:236] Iteration 6500, loss = 1.0679
I0712 20:02:04.208894 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:02:04.208914 45537 solver.cpp:252]     Train net output #1: loss = 1.19529 (* 1 = 1.19529 loss)
I0712 20:02:04.208930 45537 sgd_solver.cpp:106] Iteration 6500, lr = 0.015
I0712 20:03:24.312543 45537 solver.cpp:236] Iteration 6600, loss = 1.08074
I0712 20:03:24.312707 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:03:24.312734 45537 solver.cpp:252]     Train net output #1: loss = 1.0628 (* 1 = 1.0628 loss)
I0712 20:03:24.312748 45537 sgd_solver.cpp:106] Iteration 6600, lr = 0.015
I0712 20:04:44.421769 45537 solver.cpp:236] Iteration 6700, loss = 1.07789
I0712 20:04:44.421919 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 20:04:44.421949 45537 solver.cpp:252]     Train net output #1: loss = 0.993555 (* 1 = 0.993555 loss)
I0712 20:04:44.421963 45537 sgd_solver.cpp:106] Iteration 6700, lr = 0.015
I0712 20:06:04.517447 45537 solver.cpp:236] Iteration 6800, loss = 1.04268
I0712 20:06:04.517595 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:06:04.517614 45537 solver.cpp:252]     Train net output #1: loss = 1.15693 (* 1 = 1.15693 loss)
I0712 20:06:04.517630 45537 sgd_solver.cpp:106] Iteration 6800, lr = 0.015
I0712 20:07:24.629302 45537 solver.cpp:236] Iteration 6900, loss = 1.08583
I0712 20:07:24.629438 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:07:24.629461 45537 solver.cpp:252]     Train net output #1: loss = 1.15223 (* 1 = 1.15223 loss)
I0712 20:07:24.629482 45537 sgd_solver.cpp:106] Iteration 6900, lr = 0.015
I0712 20:08:44.745604 45537 solver.cpp:236] Iteration 7000, loss = 1.08685
I0712 20:08:44.745733 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 20:08:44.745754 45537 solver.cpp:252]     Train net output #1: loss = 0.983665 (* 1 = 0.983665 loss)
I0712 20:08:44.745770 45537 sgd_solver.cpp:106] Iteration 7000, lr = 0.015
I0712 20:09:47.238713 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 20:10:04.853905 45537 solver.cpp:236] Iteration 7100, loss = 1.05397
I0712 20:10:04.853960 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:10:04.853976 45537 solver.cpp:252]     Train net output #1: loss = 1.06707 (* 1 = 1.06707 loss)
I0712 20:10:04.853989 45537 sgd_solver.cpp:106] Iteration 7100, lr = 0.015
I0712 20:11:24.948688 45537 solver.cpp:236] Iteration 7200, loss = 1.05849
I0712 20:11:24.948907 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:11:24.948931 45537 solver.cpp:252]     Train net output #1: loss = 1.11551 (* 1 = 1.11551 loss)
I0712 20:11:24.948950 45537 sgd_solver.cpp:106] Iteration 7200, lr = 0.015
I0712 20:12:45.058562 45537 solver.cpp:236] Iteration 7300, loss = 1.07106
I0712 20:12:45.058723 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:12:45.058744 45537 solver.cpp:252]     Train net output #1: loss = 0.992277 (* 1 = 0.992277 loss)
I0712 20:12:45.058764 45537 sgd_solver.cpp:106] Iteration 7300, lr = 0.015
I0712 20:14:05.174814 45537 solver.cpp:236] Iteration 7400, loss = 1.06017
I0712 20:14:05.174934 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:14:05.174954 45537 solver.cpp:252]     Train net output #1: loss = 1.14779 (* 1 = 1.14779 loss)
I0712 20:14:05.174968 45537 sgd_solver.cpp:106] Iteration 7400, lr = 0.015
I0712 20:15:24.477237 45537 solver.cpp:340] Iteration 7500, Testing net (#0)
I0712 20:16:41.477432 45537 solver.cpp:408]     Test net output #0: accuracy = 0.43375
I0712 20:16:41.477530 45537 solver.cpp:408]     Test net output #1: loss = 1.08352 (* 1 = 1.08352 loss)
I0712 20:16:42.254937 45537 solver.cpp:236] Iteration 7500, loss = 1.06501
I0712 20:16:42.254987 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:16:42.255004 45537 solver.cpp:252]     Train net output #1: loss = 1.00314 (* 1 = 1.00314 loss)
I0712 20:16:42.255020 45537 sgd_solver.cpp:106] Iteration 7500, lr = 0.015
I0712 20:18:02.293566 45537 solver.cpp:236] Iteration 7600, loss = 1.07847
I0712 20:18:02.293728 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 20:18:02.293763 45537 solver.cpp:252]     Train net output #1: loss = 1.32288 (* 1 = 1.32288 loss)
I0712 20:18:02.293777 45537 sgd_solver.cpp:106] Iteration 7600, lr = 0.015
I0712 20:19:22.393438 45537 solver.cpp:236] Iteration 7700, loss = 1.07791
I0712 20:19:22.393591 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:19:22.393611 45537 solver.cpp:252]     Train net output #1: loss = 1.01442 (* 1 = 1.01442 loss)
I0712 20:19:22.393625 45537 sgd_solver.cpp:106] Iteration 7700, lr = 0.015
I0712 20:20:42.506654 45537 solver.cpp:236] Iteration 7800, loss = 1.07055
I0712 20:20:42.506791 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:20:42.506814 45537 solver.cpp:252]     Train net output #1: loss = 1.01893 (* 1 = 1.01893 loss)
I0712 20:20:42.506834 45537 sgd_solver.cpp:106] Iteration 7800, lr = 0.015
I0712 20:22:02.620733 45537 solver.cpp:236] Iteration 7900, loss = 1.06886
I0712 20:22:02.620898 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:22:02.620929 45537 solver.cpp:252]     Train net output #1: loss = 1.11609 (* 1 = 1.11609 loss)
I0712 20:22:02.620944 45537 sgd_solver.cpp:106] Iteration 7900, lr = 0.015
I0712 20:23:22.725344 45537 solver.cpp:236] Iteration 8000, loss = 1.07334
I0712 20:23:22.725455 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:23:22.725473 45537 solver.cpp:252]     Train net output #1: loss = 1.05259 (* 1 = 1.05259 loss)
I0712 20:23:22.725486 45537 sgd_solver.cpp:106] Iteration 8000, lr = 0.015
I0712 20:24:42.830896 45537 solver.cpp:236] Iteration 8100, loss = 1.07774
I0712 20:24:42.831049 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:24:42.831070 45537 solver.cpp:252]     Train net output #1: loss = 1.21223 (* 1 = 1.21223 loss)
I0712 20:24:42.831086 45537 sgd_solver.cpp:106] Iteration 8100, lr = 0.015
I0712 20:26:02.957224 45537 solver.cpp:236] Iteration 8200, loss = 1.08676
I0712 20:26:02.957388 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:26:02.957415 45537 solver.cpp:252]     Train net output #1: loss = 1.1552 (* 1 = 1.1552 loss)
I0712 20:26:02.957429 45537 sgd_solver.cpp:106] Iteration 8200, lr = 0.015
I0712 20:27:23.058080 45537 solver.cpp:236] Iteration 8300, loss = 1.06851
I0712 20:27:23.058212 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:27:23.058249 45537 solver.cpp:252]     Train net output #1: loss = 1.07182 (* 1 = 1.07182 loss)
I0712 20:27:23.058264 45537 sgd_solver.cpp:106] Iteration 8300, lr = 0.015
I0712 20:27:38.280232 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 20:28:43.172920 45537 solver.cpp:236] Iteration 8400, loss = 1.0351
I0712 20:28:43.173075 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 20:28:43.173097 45537 solver.cpp:252]     Train net output #1: loss = 1.36805 (* 1 = 1.36805 loss)
I0712 20:28:43.173115 45537 sgd_solver.cpp:106] Iteration 8400, lr = 0.015
I0712 20:30:03.278723 45537 solver.cpp:236] Iteration 8500, loss = 1.06185
I0712 20:30:03.278941 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0712 20:30:03.278980 45537 solver.cpp:252]     Train net output #1: loss = 0.846637 (* 1 = 0.846637 loss)
I0712 20:30:03.278990 45537 sgd_solver.cpp:106] Iteration 8500, lr = 0.015
I0712 20:31:23.393079 45537 solver.cpp:236] Iteration 8600, loss = 1.0619
I0712 20:31:23.393204 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 20:31:23.393225 45537 solver.cpp:252]     Train net output #1: loss = 0.941983 (* 1 = 0.941983 loss)
I0712 20:31:23.393244 45537 sgd_solver.cpp:106] Iteration 8600, lr = 0.015
I0712 20:32:43.488656 45537 solver.cpp:236] Iteration 8700, loss = 1.08701
I0712 20:32:43.488816 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 20:32:43.488844 45537 solver.cpp:252]     Train net output #1: loss = 1.02861 (* 1 = 1.02861 loss)
I0712 20:32:43.488859 45537 sgd_solver.cpp:106] Iteration 8700, lr = 0.015
I0712 20:34:03.604879 45537 solver.cpp:236] Iteration 8800, loss = 1.05317
I0712 20:34:03.605034 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 20:34:03.605054 45537 solver.cpp:252]     Train net output #1: loss = 0.942788 (* 1 = 0.942788 loss)
I0712 20:34:03.605072 45537 sgd_solver.cpp:106] Iteration 8800, lr = 0.015
I0712 20:35:23.714213 45537 solver.cpp:236] Iteration 8900, loss = 1.06486
I0712 20:35:23.714357 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 20:35:23.714402 45537 solver.cpp:252]     Train net output #1: loss = 1.19084 (* 1 = 1.19084 loss)
I0712 20:35:23.714418 45537 sgd_solver.cpp:106] Iteration 8900, lr = 0.015
I0712 20:36:43.009024 45537 solver.cpp:340] Iteration 9000, Testing net (#0)
I0712 20:38:00.063807 45537 solver.cpp:408]     Test net output #0: accuracy = 0.48875
I0712 20:38:00.063942 45537 solver.cpp:408]     Test net output #1: loss = 1.04873 (* 1 = 1.04873 loss)
I0712 20:38:00.825073 45537 solver.cpp:236] Iteration 9000, loss = 1.05748
I0712 20:38:00.825124 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 20:38:00.825142 45537 solver.cpp:252]     Train net output #1: loss = 0.957736 (* 1 = 0.957736 loss)
I0712 20:38:00.825160 45537 sgd_solver.cpp:106] Iteration 9000, lr = 0.015
I0712 20:39:20.936574 45537 solver.cpp:236] Iteration 9100, loss = 1.06936
I0712 20:39:20.936775 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:39:20.936805 45537 solver.cpp:252]     Train net output #1: loss = 1.13492 (* 1 = 1.13492 loss)
I0712 20:39:20.936815 45537 sgd_solver.cpp:106] Iteration 9100, lr = 0.015
I0712 20:40:41.044601 45537 solver.cpp:236] Iteration 9200, loss = 1.08228
I0712 20:40:41.044751 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:40:41.044770 45537 solver.cpp:252]     Train net output #1: loss = 1.06287 (* 1 = 1.06287 loss)
I0712 20:40:41.044786 45537 sgd_solver.cpp:106] Iteration 9200, lr = 0.015
I0712 20:42:01.157662 45537 solver.cpp:236] Iteration 9300, loss = 1.08221
I0712 20:42:01.157785 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 20:42:01.157804 45537 solver.cpp:252]     Train net output #1: loss = 1.19522 (* 1 = 1.19522 loss)
I0712 20:42:01.157820 45537 sgd_solver.cpp:106] Iteration 9300, lr = 0.015
I0712 20:43:21.261605 45537 solver.cpp:236] Iteration 9400, loss = 1.03857
I0712 20:43:21.261871 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 20:43:21.261893 45537 solver.cpp:252]     Train net output #1: loss = 0.897661 (* 1 = 0.897661 loss)
I0712 20:43:21.261909 45537 sgd_solver.cpp:106] Iteration 9400, lr = 0.015
I0712 20:44:41.364835 45537 solver.cpp:236] Iteration 9500, loss = 1.08341
I0712 20:44:41.364970 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 20:44:41.365001 45537 solver.cpp:252]     Train net output #1: loss = 1.03743 (* 1 = 1.03743 loss)
I0712 20:44:41.365015 45537 sgd_solver.cpp:106] Iteration 9500, lr = 0.015
I0712 20:46:01.471904 45537 solver.cpp:236] Iteration 9600, loss = 1.06123
I0712 20:46:01.472091 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:46:01.472115 45537 solver.cpp:252]     Train net output #1: loss = 1.07736 (* 1 = 1.07736 loss)
I0712 20:46:01.472131 45537 sgd_solver.cpp:106] Iteration 9600, lr = 0.015
I0712 20:46:27.110803 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 20:47:21.581923 45537 solver.cpp:236] Iteration 9700, loss = 1.08014
I0712 20:47:21.582084 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:47:21.582106 45537 solver.cpp:252]     Train net output #1: loss = 1.15705 (* 1 = 1.15705 loss)
I0712 20:47:21.582132 45537 sgd_solver.cpp:106] Iteration 9700, lr = 0.015
I0712 20:48:41.694367 45537 solver.cpp:236] Iteration 9800, loss = 1.08568
I0712 20:48:41.694483 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:48:41.694501 45537 solver.cpp:252]     Train net output #1: loss = 1.0414 (* 1 = 1.0414 loss)
I0712 20:48:41.694515 45537 sgd_solver.cpp:106] Iteration 9800, lr = 0.015
I0712 20:50:01.794896 45537 solver.cpp:236] Iteration 9900, loss = 1.06187
I0712 20:50:01.795048 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:50:01.795080 45537 solver.cpp:252]     Train net output #1: loss = 0.996004 (* 1 = 0.996004 loss)
I0712 20:50:01.795094 45537 sgd_solver.cpp:106] Iteration 9900, lr = 0.015
I0712 20:51:21.116602 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_10000.caffemodel
I0712 20:51:21.246387 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_10000.solverstate
I0712 20:51:22.031847 45537 solver.cpp:236] Iteration 10000, loss = 1.06634
I0712 20:51:22.031913 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:51:22.031932 45537 solver.cpp:252]     Train net output #1: loss = 1.12238 (* 1 = 1.12238 loss)
I0712 20:51:22.031950 45537 sgd_solver.cpp:106] Iteration 10000, lr = 0.015
I0712 20:52:42.128204 45537 solver.cpp:236] Iteration 10100, loss = 1.07656
I0712 20:52:42.128355 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:52:42.128374 45537 solver.cpp:252]     Train net output #1: loss = 1.01659 (* 1 = 1.01659 loss)
I0712 20:52:42.128394 45537 sgd_solver.cpp:106] Iteration 10100, lr = 0.015
I0712 20:54:02.231344 45537 solver.cpp:236] Iteration 10200, loss = 1.08449
I0712 20:54:02.231515 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 20:54:02.231535 45537 solver.cpp:252]     Train net output #1: loss = 1.05302 (* 1 = 1.05302 loss)
I0712 20:54:02.231549 45537 sgd_solver.cpp:106] Iteration 10200, lr = 0.015
I0712 20:55:22.350733 45537 solver.cpp:236] Iteration 10300, loss = 1.05579
I0712 20:55:22.350917 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 20:55:22.350953 45537 solver.cpp:252]     Train net output #1: loss = 1.12643 (* 1 = 1.12643 loss)
I0712 20:55:22.350963 45537 sgd_solver.cpp:106] Iteration 10300, lr = 0.015
I0712 20:56:42.450603 45537 solver.cpp:236] Iteration 10400, loss = 1.08411
I0712 20:56:42.450737 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 20:56:42.450759 45537 solver.cpp:252]     Train net output #1: loss = 1.19526 (* 1 = 1.19526 loss)
I0712 20:56:42.450773 45537 sgd_solver.cpp:106] Iteration 10400, lr = 0.015
I0712 20:58:01.756973 45537 solver.cpp:340] Iteration 10500, Testing net (#0)
I0712 20:59:18.744527 45537 solver.cpp:408]     Test net output #0: accuracy = 0.48125
I0712 20:59:18.744650 45537 solver.cpp:408]     Test net output #1: loss = 1.04973 (* 1 = 1.04973 loss)
I0712 20:59:19.513030 45537 solver.cpp:236] Iteration 10500, loss = 1.0742
I0712 20:59:19.513082 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 20:59:19.513101 45537 solver.cpp:252]     Train net output #1: loss = 1.08285 (* 1 = 1.08285 loss)
I0712 20:59:19.513118 45537 sgd_solver.cpp:106] Iteration 10500, lr = 0.015
I0712 21:00:39.574858 45537 solver.cpp:236] Iteration 10600, loss = 1.05097
I0712 21:00:39.575047 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:00:39.575078 45537 solver.cpp:252]     Train net output #1: loss = 0.998746 (* 1 = 0.998746 loss)
I0712 21:00:39.575088 45537 sgd_solver.cpp:106] Iteration 10600, lr = 0.015
I0712 21:01:59.683141 45537 solver.cpp:236] Iteration 10700, loss = 1.07368
I0712 21:01:59.683298 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:01:59.683331 45537 solver.cpp:252]     Train net output #1: loss = 1.0604 (* 1 = 1.0604 loss)
I0712 21:01:59.683346 45537 sgd_solver.cpp:106] Iteration 10700, lr = 0.015
I0712 21:03:19.792426 45537 solver.cpp:236] Iteration 10800, loss = 1.08564
I0712 21:03:19.792595 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:03:19.792615 45537 solver.cpp:252]     Train net output #1: loss = 1.1862 (* 1 = 1.1862 loss)
I0712 21:03:19.792629 45537 sgd_solver.cpp:106] Iteration 10800, lr = 0.015
I0712 21:04:39.911375 45537 solver.cpp:236] Iteration 10900, loss = 1.07639
I0712 21:04:39.911556 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:04:39.911595 45537 solver.cpp:252]     Train net output #1: loss = 1.07008 (* 1 = 1.07008 loss)
I0712 21:04:39.911605 45537 sgd_solver.cpp:106] Iteration 10900, lr = 0.015
I0712 21:06:00.012689 45537 solver.cpp:236] Iteration 11000, loss = 1.06832
I0712 21:06:00.012840 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:06:00.012858 45537 solver.cpp:252]     Train net output #1: loss = 1.14257 (* 1 = 1.14257 loss)
I0712 21:06:00.012879 45537 sgd_solver.cpp:106] Iteration 11000, lr = 0.015
I0712 21:07:20.126582 45537 solver.cpp:236] Iteration 11100, loss = 1.0527
I0712 21:07:20.126749 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:07:20.126780 45537 solver.cpp:252]     Train net output #1: loss = 1.19925 (* 1 = 1.19925 loss)
I0712 21:07:20.126794 45537 sgd_solver.cpp:106] Iteration 11100, lr = 0.015
I0712 21:08:11.393040 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 21:08:40.244658 45537 solver.cpp:236] Iteration 11200, loss = 1.05239
I0712 21:08:40.244722 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:08:40.244740 45537 solver.cpp:252]     Train net output #1: loss = 1.0547 (* 1 = 1.0547 loss)
I0712 21:08:40.244755 45537 sgd_solver.cpp:106] Iteration 11200, lr = 0.015
I0712 21:10:00.346303 45537 solver.cpp:236] Iteration 11300, loss = 1.08142
I0712 21:10:00.346448 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:10:00.346483 45537 solver.cpp:252]     Train net output #1: loss = 1.12842 (* 1 = 1.12842 loss)
I0712 21:10:00.346501 45537 sgd_solver.cpp:106] Iteration 11300, lr = 0.015
I0712 21:11:20.443048 45537 solver.cpp:236] Iteration 11400, loss = 1.0765
I0712 21:11:20.443169 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:11:20.443189 45537 solver.cpp:252]     Train net output #1: loss = 1.18962 (* 1 = 1.18962 loss)
I0712 21:11:20.443207 45537 sgd_solver.cpp:106] Iteration 11400, lr = 0.015
I0712 21:12:40.554680 45537 solver.cpp:236] Iteration 11500, loss = 1.06509
I0712 21:12:40.554829 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 21:12:40.554849 45537 solver.cpp:252]     Train net output #1: loss = 0.86486 (* 1 = 0.86486 loss)
I0712 21:12:40.554865 45537 sgd_solver.cpp:106] Iteration 11500, lr = 0.015
I0712 21:14:00.665899 45537 solver.cpp:236] Iteration 11600, loss = 1.08549
I0712 21:14:00.666081 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:14:00.666103 45537 solver.cpp:252]     Train net output #1: loss = 1.09426 (* 1 = 1.09426 loss)
I0712 21:14:00.666116 45537 sgd_solver.cpp:106] Iteration 11600, lr = 0.015
I0712 21:15:20.772686 45537 solver.cpp:236] Iteration 11700, loss = 1.06609
I0712 21:15:20.772855 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 21:15:20.772877 45537 solver.cpp:252]     Train net output #1: loss = 1.32687 (* 1 = 1.32687 loss)
I0712 21:15:20.772896 45537 sgd_solver.cpp:106] Iteration 11700, lr = 0.015
I0712 21:16:40.889874 45537 solver.cpp:236] Iteration 11800, loss = 1.07807
I0712 21:16:40.890048 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:16:40.890080 45537 solver.cpp:252]     Train net output #1: loss = 1.04274 (* 1 = 1.04274 loss)
I0712 21:16:40.890096 45537 sgd_solver.cpp:106] Iteration 11800, lr = 0.015
I0712 21:18:00.998618 45537 solver.cpp:236] Iteration 11900, loss = 1.06911
I0712 21:18:00.998811 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:18:00.998843 45537 solver.cpp:252]     Train net output #1: loss = 1.08588 (* 1 = 1.08588 loss)
I0712 21:18:00.998857 45537 sgd_solver.cpp:106] Iteration 11900, lr = 0.015
I0712 21:19:20.292121 45537 solver.cpp:340] Iteration 12000, Testing net (#0)
I0712 21:20:37.231813 45537 solver.cpp:408]     Test net output #0: accuracy = 0.455
I0712 21:20:37.231955 45537 solver.cpp:408]     Test net output #1: loss = 1.07689 (* 1 = 1.07689 loss)
I0712 21:20:37.999037 45537 solver.cpp:236] Iteration 12000, loss = 1.05269
I0712 21:20:37.999089 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:20:37.999106 45537 solver.cpp:252]     Train net output #1: loss = 1.07213 (* 1 = 1.07213 loss)
I0712 21:20:37.999125 45537 sgd_solver.cpp:106] Iteration 12000, lr = 0.015
I0712 21:21:58.116070 45537 solver.cpp:236] Iteration 12100, loss = 1.06262
I0712 21:21:58.116227 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 21:21:58.116247 45537 solver.cpp:252]     Train net output #1: loss = 1.02228 (* 1 = 1.02228 loss)
I0712 21:21:58.116263 45537 sgd_solver.cpp:106] Iteration 12100, lr = 0.015
I0712 21:23:18.217782 45537 solver.cpp:236] Iteration 12200, loss = 1.0546
I0712 21:23:18.217969 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:23:18.217994 45537 solver.cpp:252]     Train net output #1: loss = 1.04737 (* 1 = 1.04737 loss)
I0712 21:23:18.218008 45537 sgd_solver.cpp:106] Iteration 12200, lr = 0.015
I0712 21:24:38.323566 45537 solver.cpp:236] Iteration 12300, loss = 1.06284
I0712 21:24:38.323681 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 21:24:38.323701 45537 solver.cpp:252]     Train net output #1: loss = 0.959877 (* 1 = 0.959877 loss)
I0712 21:24:38.323714 45537 sgd_solver.cpp:106] Iteration 12300, lr = 0.015
I0712 21:25:58.426648 45537 solver.cpp:236] Iteration 12400, loss = 1.08101
I0712 21:25:58.426837 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 21:25:58.426861 45537 solver.cpp:252]     Train net output #1: loss = 1.222 (* 1 = 1.222 loss)
I0712 21:25:58.426873 45537 sgd_solver.cpp:106] Iteration 12400, lr = 0.015
I0712 21:27:18.537277 45537 solver.cpp:236] Iteration 12500, loss = 1.0885
I0712 21:27:18.537437 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:27:18.537479 45537 solver.cpp:252]     Train net output #1: loss = 1.13913 (* 1 = 1.13913 loss)
I0712 21:27:18.537493 45537 sgd_solver.cpp:106] Iteration 12500, lr = 0.015
I0712 21:28:38.642298 45537 solver.cpp:236] Iteration 12600, loss = 1.05221
I0712 21:28:38.642441 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:28:38.642460 45537 solver.cpp:252]     Train net output #1: loss = 1.05486 (* 1 = 1.05486 loss)
I0712 21:28:38.642474 45537 sgd_solver.cpp:106] Iteration 12600, lr = 0.015
I0712 21:29:58.893450 45537 solver.cpp:236] Iteration 12700, loss = 1.07549
I0712 21:29:58.893641 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:29:58.893671 45537 solver.cpp:252]     Train net output #1: loss = 1.10185 (* 1 = 1.10185 loss)
I0712 21:29:58.893687 45537 sgd_solver.cpp:106] Iteration 12700, lr = 0.015
I0712 21:31:18.950825 45537 solver.cpp:236] Iteration 12800, loss = 1.08333
I0712 21:31:18.951005 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 21:31:18.951025 45537 solver.cpp:252]     Train net output #1: loss = 0.985643 (* 1 = 0.985643 loss)
I0712 21:31:18.951040 45537 sgd_solver.cpp:106] Iteration 12800, lr = 0.015
I0712 21:32:05.424551 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 21:32:39.065842 45537 solver.cpp:236] Iteration 12900, loss = 1.05432
I0712 21:32:39.065979 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 21:32:39.065999 45537 solver.cpp:252]     Train net output #1: loss = 1.09052 (* 1 = 1.09052 loss)
I0712 21:32:39.066014 45537 sgd_solver.cpp:106] Iteration 12900, lr = 0.015
I0712 21:33:59.175570 45537 solver.cpp:236] Iteration 13000, loss = 1.07385
I0712 21:33:59.175753 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:33:59.175787 45537 solver.cpp:252]     Train net output #1: loss = 1.02974 (* 1 = 1.02974 loss)
I0712 21:33:59.175807 45537 sgd_solver.cpp:106] Iteration 13000, lr = 0.015
I0712 21:35:19.276027 45537 solver.cpp:236] Iteration 13100, loss = 1.05243
I0712 21:35:19.276196 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:35:19.276221 45537 solver.cpp:252]     Train net output #1: loss = 1.16112 (* 1 = 1.16112 loss)
I0712 21:35:19.276234 45537 sgd_solver.cpp:106] Iteration 13100, lr = 0.015
I0712 21:36:39.382899 45537 solver.cpp:236] Iteration 13200, loss = 1.06957
I0712 21:36:39.383098 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:36:39.383123 45537 solver.cpp:252]     Train net output #1: loss = 1.25123 (* 1 = 1.25123 loss)
I0712 21:36:39.383134 45537 sgd_solver.cpp:106] Iteration 13200, lr = 0.015
I0712 21:37:59.501122 45537 solver.cpp:236] Iteration 13300, loss = 1.07078
I0712 21:37:59.501271 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:37:59.501291 45537 solver.cpp:252]     Train net output #1: loss = 1.06086 (* 1 = 1.06086 loss)
I0712 21:37:59.501305 45537 sgd_solver.cpp:106] Iteration 13300, lr = 0.015
I0712 21:39:19.601541 45537 solver.cpp:236] Iteration 13400, loss = 1.09091
I0712 21:39:19.601660 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 21:39:19.601678 45537 solver.cpp:252]     Train net output #1: loss = 1.05871 (* 1 = 1.05871 loss)
I0712 21:39:19.601692 45537 sgd_solver.cpp:106] Iteration 13400, lr = 0.015
I0712 21:40:38.915035 45537 solver.cpp:340] Iteration 13500, Testing net (#0)
I0712 21:41:55.860584 45537 solver.cpp:408]     Test net output #0: accuracy = 0.43375
I0712 21:41:55.860715 45537 solver.cpp:408]     Test net output #1: loss = 1.07335 (* 1 = 1.07335 loss)
I0712 21:41:56.627470 45537 solver.cpp:236] Iteration 13500, loss = 1.08068
I0712 21:41:56.627521 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:41:56.627538 45537 solver.cpp:252]     Train net output #1: loss = 1.11159 (* 1 = 1.11159 loss)
I0712 21:41:56.627554 45537 sgd_solver.cpp:106] Iteration 13500, lr = 0.015
I0712 21:43:16.717785 45537 solver.cpp:236] Iteration 13600, loss = 1.08342
I0712 21:43:16.717936 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 21:43:16.717954 45537 solver.cpp:252]     Train net output #1: loss = 0.989983 (* 1 = 0.989983 loss)
I0712 21:43:16.717972 45537 sgd_solver.cpp:106] Iteration 13600, lr = 0.015
I0712 21:44:36.832111 45537 solver.cpp:236] Iteration 13700, loss = 1.07054
I0712 21:44:36.832223 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:44:36.832242 45537 solver.cpp:252]     Train net output #1: loss = 1.01849 (* 1 = 1.01849 loss)
I0712 21:44:36.832257 45537 sgd_solver.cpp:106] Iteration 13700, lr = 0.015
I0712 21:45:56.941692 45537 solver.cpp:236] Iteration 13800, loss = 1.08178
I0712 21:45:56.941936 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:45:56.941957 45537 solver.cpp:252]     Train net output #1: loss = 1.07716 (* 1 = 1.07716 loss)
I0712 21:45:56.941972 45537 sgd_solver.cpp:106] Iteration 13800, lr = 0.015
I0712 21:47:17.058568 45537 solver.cpp:236] Iteration 13900, loss = 1.07777
I0712 21:47:17.058718 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:47:17.058746 45537 solver.cpp:252]     Train net output #1: loss = 1.04926 (* 1 = 1.04926 loss)
I0712 21:47:17.058760 45537 sgd_solver.cpp:106] Iteration 13900, lr = 0.015
I0712 21:48:37.163280 45537 solver.cpp:236] Iteration 14000, loss = 1.03865
I0712 21:48:37.163385 45537 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 21:48:37.163403 45537 solver.cpp:252]     Train net output #1: loss = 0.675224 (* 1 = 0.675224 loss)
I0712 21:48:37.163417 45537 sgd_solver.cpp:106] Iteration 14000, lr = 0.015
I0712 21:49:57.273898 45537 solver.cpp:236] Iteration 14100, loss = 1.03329
I0712 21:49:57.274047 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:49:57.274068 45537 solver.cpp:252]     Train net output #1: loss = 1.03459 (* 1 = 1.03459 loss)
I0712 21:49:57.274086 45537 sgd_solver.cpp:106] Iteration 14100, lr = 0.015
I0712 21:51:17.393038 45537 solver.cpp:236] Iteration 14200, loss = 1.06235
I0712 21:51:17.393179 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 21:51:17.393198 45537 solver.cpp:252]     Train net output #1: loss = 1.19776 (* 1 = 1.19776 loss)
I0712 21:51:17.393211 45537 sgd_solver.cpp:106] Iteration 14200, lr = 0.015
I0712 21:51:36.608865 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 21:52:37.498911 45537 solver.cpp:236] Iteration 14300, loss = 1.07793
I0712 21:52:37.499023 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:52:37.499043 45537 solver.cpp:252]     Train net output #1: loss = 1.16927 (* 1 = 1.16927 loss)
I0712 21:52:37.499058 45537 sgd_solver.cpp:106] Iteration 14300, lr = 0.015
I0712 21:53:57.605283 45537 solver.cpp:236] Iteration 14400, loss = 1.07609
I0712 21:53:57.605478 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 21:53:57.605509 45537 solver.cpp:252]     Train net output #1: loss = 0.911794 (* 1 = 0.911794 loss)
I0712 21:53:57.605525 45537 sgd_solver.cpp:106] Iteration 14400, lr = 0.015
I0712 21:55:17.714860 45537 solver.cpp:236] Iteration 14500, loss = 1.08116
I0712 21:55:17.715096 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:55:17.715126 45537 solver.cpp:252]     Train net output #1: loss = 1.05663 (* 1 = 1.05663 loss)
I0712 21:55:17.715136 45537 sgd_solver.cpp:106] Iteration 14500, lr = 0.015
I0712 21:56:37.818403 45537 solver.cpp:236] Iteration 14600, loss = 1.08712
I0712 21:56:37.818593 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 21:56:37.818625 45537 solver.cpp:252]     Train net output #1: loss = 1.13013 (* 1 = 1.13013 loss)
I0712 21:56:37.818655 45537 sgd_solver.cpp:106] Iteration 14600, lr = 0.015
I0712 21:57:57.923532 45537 solver.cpp:236] Iteration 14700, loss = 1.07763
I0712 21:57:57.923696 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 21:57:57.923717 45537 solver.cpp:252]     Train net output #1: loss = 0.980202 (* 1 = 0.980202 loss)
I0712 21:57:57.923732 45537 sgd_solver.cpp:106] Iteration 14700, lr = 0.015
I0712 21:59:18.032295 45537 solver.cpp:236] Iteration 14800, loss = 1.05395
I0712 21:59:18.032456 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 21:59:18.032482 45537 solver.cpp:252]     Train net output #1: loss = 0.868436 (* 1 = 0.868436 loss)
I0712 21:59:18.032495 45537 sgd_solver.cpp:106] Iteration 14800, lr = 0.015
I0712 22:00:38.138304 45537 solver.cpp:236] Iteration 14900, loss = 1.06597
I0712 22:00:38.138438 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 22:00:38.138460 45537 solver.cpp:252]     Train net output #1: loss = 0.883207 (* 1 = 0.883207 loss)
I0712 22:00:38.138473 45537 sgd_solver.cpp:106] Iteration 14900, lr = 0.015
I0712 22:01:57.453029 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_15000.caffemodel
I0712 22:01:57.790030 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_15000.solverstate
I0712 22:01:57.824908 45537 solver.cpp:340] Iteration 15000, Testing net (#0)
I0712 22:03:14.739814 45537 solver.cpp:408]     Test net output #0: accuracy = 0.45875
I0712 22:03:14.739960 45537 solver.cpp:408]     Test net output #1: loss = 1.08243 (* 1 = 1.08243 loss)
I0712 22:03:15.505028 45537 solver.cpp:236] Iteration 15000, loss = 1.08229
I0712 22:03:15.505079 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:03:15.505097 45537 solver.cpp:252]     Train net output #1: loss = 1.08294 (* 1 = 1.08294 loss)
I0712 22:03:15.505115 45537 sgd_solver.cpp:106] Iteration 15000, lr = 0.015
I0712 22:04:35.555239 45537 solver.cpp:236] Iteration 15100, loss = 1.04416
I0712 22:04:35.555467 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:04:35.555500 45537 solver.cpp:252]     Train net output #1: loss = 1.01372 (* 1 = 1.01372 loss)
I0712 22:04:35.555515 45537 sgd_solver.cpp:106] Iteration 15100, lr = 0.015
I0712 22:05:55.659914 45537 solver.cpp:236] Iteration 15200, loss = 1.07043
I0712 22:05:55.660058 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:05:55.660076 45537 solver.cpp:252]     Train net output #1: loss = 1.05433 (* 1 = 1.05433 loss)
I0712 22:05:55.660094 45537 sgd_solver.cpp:106] Iteration 15200, lr = 0.015
I0712 22:07:15.773026 45537 solver.cpp:236] Iteration 15300, loss = 1.08825
I0712 22:07:15.773190 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:07:15.773208 45537 solver.cpp:252]     Train net output #1: loss = 1.05905 (* 1 = 1.05905 loss)
I0712 22:07:15.773231 45537 sgd_solver.cpp:106] Iteration 15300, lr = 0.015
I0712 22:08:35.895073 45537 solver.cpp:236] Iteration 15400, loss = 1.0781
I0712 22:08:35.895200 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 22:08:35.895236 45537 solver.cpp:252]     Train net output #1: loss = 0.99165 (* 1 = 0.99165 loss)
I0712 22:08:35.895256 45537 sgd_solver.cpp:106] Iteration 15400, lr = 0.015
I0712 22:09:55.994065 45537 solver.cpp:236] Iteration 15500, loss = 1.07543
I0712 22:09:55.994209 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 22:09:55.994238 45537 solver.cpp:252]     Train net output #1: loss = 1.22586 (* 1 = 1.22586 loss)
I0712 22:09:55.994253 45537 sgd_solver.cpp:106] Iteration 15500, lr = 0.015
I0712 22:11:16.103099 45537 solver.cpp:236] Iteration 15600, loss = 1.06743
I0712 22:11:16.103266 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:11:16.103286 45537 solver.cpp:252]     Train net output #1: loss = 1.03464 (* 1 = 1.03464 loss)
I0712 22:11:16.103312 45537 sgd_solver.cpp:106] Iteration 15600, lr = 0.015
I0712 22:12:36.214916 45537 solver.cpp:236] Iteration 15700, loss = 1.08616
I0712 22:12:36.215016 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 22:12:36.215036 45537 solver.cpp:252]     Train net output #1: loss = 1.12795 (* 1 = 1.12795 loss)
I0712 22:12:36.215051 45537 sgd_solver.cpp:106] Iteration 15700, lr = 0.015
I0712 22:13:56.323046 45537 solver.cpp:236] Iteration 15800, loss = 1.0915
I0712 22:13:56.323163 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 22:13:56.323182 45537 solver.cpp:252]     Train net output #1: loss = 1.117 (* 1 = 1.117 loss)
I0712 22:13:56.323195 45537 sgd_solver.cpp:106] Iteration 15800, lr = 0.015
I0712 22:15:16.422591 45537 solver.cpp:236] Iteration 15900, loss = 1.08212
I0712 22:15:16.422821 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:15:16.422852 45537 solver.cpp:252]     Train net output #1: loss = 1.10036 (* 1 = 1.10036 loss)
I0712 22:15:16.422863 45537 sgd_solver.cpp:106] Iteration 15900, lr = 0.015
I0712 22:16:36.543215 45537 solver.cpp:236] Iteration 16000, loss = 1.05883
I0712 22:16:36.543360 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 22:16:36.543380 45537 solver.cpp:252]     Train net output #1: loss = 0.963991 (* 1 = 0.963991 loss)
I0712 22:16:36.543395 45537 sgd_solver.cpp:106] Iteration 16000, lr = 0.015
I0712 22:17:53.451186 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 22:17:56.653491 45537 solver.cpp:236] Iteration 16100, loss = 1.0786
I0712 22:17:56.653551 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 22:17:56.653568 45537 solver.cpp:252]     Train net output #1: loss = 1.00308 (* 1 = 1.00308 loss)
I0712 22:17:56.653580 45537 sgd_solver.cpp:106] Iteration 16100, lr = 0.015
I0712 22:19:16.764569 45537 solver.cpp:236] Iteration 16200, loss = 1.07331
I0712 22:19:16.764711 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 22:19:16.764730 45537 solver.cpp:252]     Train net output #1: loss = 1.20396 (* 1 = 1.20396 loss)
I0712 22:19:16.764744 45537 sgd_solver.cpp:106] Iteration 16200, lr = 0.015
I0712 22:20:36.967300 45537 solver.cpp:236] Iteration 16300, loss = 1.04324
I0712 22:20:36.967488 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:20:36.967525 45537 solver.cpp:252]     Train net output #1: loss = 1.04895 (* 1 = 1.04895 loss)
I0712 22:20:36.967536 45537 sgd_solver.cpp:106] Iteration 16300, lr = 0.015
I0712 22:21:57.127660 45537 solver.cpp:236] Iteration 16400, loss = 1.06295
I0712 22:21:57.127812 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:21:57.127851 45537 solver.cpp:252]     Train net output #1: loss = 1.02186 (* 1 = 1.02186 loss)
I0712 22:21:57.127868 45537 sgd_solver.cpp:106] Iteration 16400, lr = 0.015
I0712 22:23:17.078552 45537 solver.cpp:340] Iteration 16500, Testing net (#0)
I0712 22:24:34.014933 45537 solver.cpp:408]     Test net output #0: accuracy = 0.47
I0712 22:24:34.015084 45537 solver.cpp:408]     Test net output #1: loss = 1.06322 (* 1 = 1.06322 loss)
I0712 22:24:34.779500 45537 solver.cpp:236] Iteration 16500, loss = 1.0656
I0712 22:24:34.779557 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:24:34.779575 45537 solver.cpp:252]     Train net output #1: loss = 1.00804 (* 1 = 1.00804 loss)
I0712 22:24:34.779592 45537 sgd_solver.cpp:106] Iteration 16500, lr = 0.015
I0712 22:25:54.899966 45537 solver.cpp:236] Iteration 16600, loss = 1.06477
I0712 22:25:54.900105 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:25:54.900135 45537 solver.cpp:252]     Train net output #1: loss = 1.04747 (* 1 = 1.04747 loss)
I0712 22:25:54.900149 45537 sgd_solver.cpp:106] Iteration 16600, lr = 0.015
I0712 22:27:15.004994 45537 solver.cpp:236] Iteration 16700, loss = 1.08272
I0712 22:27:15.005141 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:27:15.005161 45537 solver.cpp:252]     Train net output #1: loss = 1.07577 (* 1 = 1.07577 loss)
I0712 22:27:15.005179 45537 sgd_solver.cpp:106] Iteration 16700, lr = 0.015
I0712 22:28:35.105448 45537 solver.cpp:236] Iteration 16800, loss = 1.06662
I0712 22:28:35.105612 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:28:35.105643 45537 solver.cpp:252]     Train net output #1: loss = 1.26125 (* 1 = 1.26125 loss)
I0712 22:28:35.105659 45537 sgd_solver.cpp:106] Iteration 16800, lr = 0.015
I0712 22:29:55.223155 45537 solver.cpp:236] Iteration 16900, loss = 1.08656
I0712 22:29:55.223318 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 22:29:55.223346 45537 solver.cpp:252]     Train net output #1: loss = 1.08511 (* 1 = 1.08511 loss)
I0712 22:29:55.223356 45537 sgd_solver.cpp:106] Iteration 16900, lr = 0.015
I0712 22:31:15.334385 45537 solver.cpp:236] Iteration 17000, loss = 1.08463
I0712 22:31:15.334516 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 22:31:15.334537 45537 solver.cpp:252]     Train net output #1: loss = 1.13812 (* 1 = 1.13812 loss)
I0712 22:31:15.334550 45537 sgd_solver.cpp:106] Iteration 17000, lr = 0.015
I0712 22:32:35.445045 45537 solver.cpp:236] Iteration 17100, loss = 1.06811
I0712 22:32:35.445204 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 22:32:35.445235 45537 solver.cpp:252]     Train net output #1: loss = 1.27886 (* 1 = 1.27886 loss)
I0712 22:32:35.445247 45537 sgd_solver.cpp:106] Iteration 17100, lr = 0.015
I0712 22:33:55.553474 45537 solver.cpp:236] Iteration 17200, loss = 1.08943
I0712 22:33:55.553691 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:33:55.553714 45537 solver.cpp:252]     Train net output #1: loss = 1.07394 (* 1 = 1.07394 loss)
I0712 22:33:55.553727 45537 sgd_solver.cpp:106] Iteration 17200, lr = 0.015
I0712 22:35:15.654844 45537 solver.cpp:236] Iteration 17300, loss = 1.07431
I0712 22:35:15.655035 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:35:15.655084 45537 solver.cpp:252]     Train net output #1: loss = 1.03183 (* 1 = 1.03183 loss)
I0712 22:35:15.655104 45537 sgd_solver.cpp:106] Iteration 17300, lr = 0.015
I0712 22:36:26.167985 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 22:36:35.768759 45537 solver.cpp:236] Iteration 17400, loss = 1.07198
I0712 22:36:35.768826 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 22:36:35.768847 45537 solver.cpp:252]     Train net output #1: loss = 1.11734 (* 1 = 1.11734 loss)
I0712 22:36:35.768865 45537 sgd_solver.cpp:106] Iteration 17400, lr = 0.015
I0712 22:37:55.873558 45537 solver.cpp:236] Iteration 17500, loss = 1.07425
I0712 22:37:55.873705 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:37:55.873735 45537 solver.cpp:252]     Train net output #1: loss = 1.05661 (* 1 = 1.05661 loss)
I0712 22:37:55.873749 45537 sgd_solver.cpp:106] Iteration 17500, lr = 0.015
I0712 22:39:15.987653 45537 solver.cpp:236] Iteration 17600, loss = 1.07599
I0712 22:39:15.987787 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:39:15.987819 45537 solver.cpp:252]     Train net output #1: loss = 1.06969 (* 1 = 1.06969 loss)
I0712 22:39:15.987833 45537 sgd_solver.cpp:106] Iteration 17600, lr = 0.015
I0712 22:40:36.200369 45537 solver.cpp:236] Iteration 17700, loss = 1.07293
I0712 22:40:36.200531 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:40:36.200567 45537 solver.cpp:252]     Train net output #1: loss = 1.04842 (* 1 = 1.04842 loss)
I0712 22:40:36.200584 45537 sgd_solver.cpp:106] Iteration 17700, lr = 0.015
I0712 22:41:56.293695 45537 solver.cpp:236] Iteration 17800, loss = 1.08047
I0712 22:41:56.293859 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:41:56.293887 45537 solver.cpp:252]     Train net output #1: loss = 1.02955 (* 1 = 1.02955 loss)
I0712 22:41:56.293902 45537 sgd_solver.cpp:106] Iteration 17800, lr = 0.015
I0712 22:43:16.410776 45537 solver.cpp:236] Iteration 17900, loss = 1.03562
I0712 22:43:16.410969 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:43:16.410998 45537 solver.cpp:252]     Train net output #1: loss = 1.10086 (* 1 = 1.10086 loss)
I0712 22:43:16.411008 45537 sgd_solver.cpp:106] Iteration 17900, lr = 0.015
I0712 22:44:35.705415 45537 solver.cpp:340] Iteration 18000, Testing net (#0)
I0712 22:45:52.685624 45537 solver.cpp:408]     Test net output #0: accuracy = 0.44375
I0712 22:45:52.685761 45537 solver.cpp:408]     Test net output #1: loss = 1.0705 (* 1 = 1.0705 loss)
I0712 22:45:53.455639 45537 solver.cpp:236] Iteration 18000, loss = 1.05154
I0712 22:45:53.455696 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 22:45:53.455714 45537 solver.cpp:252]     Train net output #1: loss = 0.869173 (* 1 = 0.869173 loss)
I0712 22:45:53.455732 45537 sgd_solver.cpp:106] Iteration 18000, lr = 0.015
I0712 22:47:13.528457 45537 solver.cpp:236] Iteration 18100, loss = 1.08019
I0712 22:47:13.528584 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 22:47:13.528602 45537 solver.cpp:252]     Train net output #1: loss = 1.10637 (* 1 = 1.10637 loss)
I0712 22:47:13.528619 45537 sgd_solver.cpp:106] Iteration 18100, lr = 0.015
I0712 22:48:33.627308 45537 solver.cpp:236] Iteration 18200, loss = 1.07063
I0712 22:48:33.627449 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 22:48:33.627478 45537 solver.cpp:252]     Train net output #1: loss = 1.16969 (* 1 = 1.16969 loss)
I0712 22:48:33.627492 45537 sgd_solver.cpp:106] Iteration 18200, lr = 0.015
I0712 22:49:53.726387 45537 solver.cpp:236] Iteration 18300, loss = 1.06756
I0712 22:49:53.726639 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:49:53.726666 45537 solver.cpp:252]     Train net output #1: loss = 1.07826 (* 1 = 1.07826 loss)
I0712 22:49:53.726681 45537 sgd_solver.cpp:106] Iteration 18300, lr = 0.015
I0712 22:51:13.839931 45537 solver.cpp:236] Iteration 18400, loss = 1.06617
I0712 22:51:13.840075 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:51:13.840092 45537 solver.cpp:252]     Train net output #1: loss = 1.11181 (* 1 = 1.11181 loss)
I0712 22:51:13.840111 45537 sgd_solver.cpp:106] Iteration 18400, lr = 0.015
I0712 22:52:33.940912 45537 solver.cpp:236] Iteration 18500, loss = 1.0693
I0712 22:52:33.941068 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 22:52:33.941087 45537 solver.cpp:252]     Train net output #1: loss = 1.23458 (* 1 = 1.23458 loss)
I0712 22:52:33.941103 45537 sgd_solver.cpp:106] Iteration 18500, lr = 0.015
I0712 22:53:54.034796 45537 solver.cpp:236] Iteration 18600, loss = 1.05542
I0712 22:53:54.034907 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 22:53:54.034926 45537 solver.cpp:252]     Train net output #1: loss = 1.32459 (* 1 = 1.32459 loss)
I0712 22:53:54.034940 45537 sgd_solver.cpp:106] Iteration 18600, lr = 0.015
I0712 22:55:14.145408 45537 solver.cpp:236] Iteration 18700, loss = 1.06637
I0712 22:55:14.145624 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:55:14.145651 45537 solver.cpp:252]     Train net output #1: loss = 1.11508 (* 1 = 1.11508 loss)
I0712 22:55:14.145661 45537 sgd_solver.cpp:106] Iteration 18700, lr = 0.015
I0712 22:56:34.258615 45537 solver.cpp:236] Iteration 18800, loss = 1.06674
I0712 22:56:34.258759 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:56:34.258788 45537 solver.cpp:252]     Train net output #1: loss = 1.01538 (* 1 = 1.01538 loss)
I0712 22:56:34.258802 45537 sgd_solver.cpp:106] Iteration 18800, lr = 0.015
I0712 22:57:54.370165 45537 solver.cpp:236] Iteration 18900, loss = 1.04445
I0712 22:57:54.370307 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 22:57:54.370328 45537 solver.cpp:252]     Train net output #1: loss = 0.999188 (* 1 = 0.999188 loss)
I0712 22:57:54.370347 45537 sgd_solver.cpp:106] Iteration 18900, lr = 0.015
I0712 22:59:14.478735 45537 solver.cpp:236] Iteration 19000, loss = 1.08215
I0712 22:59:14.478881 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 22:59:14.478899 45537 solver.cpp:252]     Train net output #1: loss = 1.09976 (* 1 = 1.09976 loss)
I0712 22:59:14.478915 45537 sgd_solver.cpp:106] Iteration 19000, lr = 0.015
I0712 23:00:05.747315 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 23:00:34.592450 45537 solver.cpp:236] Iteration 19100, loss = 1.08353
I0712 23:00:34.592509 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:00:34.592528 45537 solver.cpp:252]     Train net output #1: loss = 1.1445 (* 1 = 1.1445 loss)
I0712 23:00:34.592542 45537 sgd_solver.cpp:106] Iteration 19100, lr = 0.015
I0712 23:01:54.702947 45537 solver.cpp:236] Iteration 19200, loss = 1.05869
I0712 23:01:54.703085 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:01:54.703115 45537 solver.cpp:252]     Train net output #1: loss = 1.00405 (* 1 = 1.00405 loss)
I0712 23:01:54.703132 45537 sgd_solver.cpp:106] Iteration 19200, lr = 0.015
I0712 23:03:14.808270 45537 solver.cpp:236] Iteration 19300, loss = 1.06237
I0712 23:03:14.808437 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:03:14.808470 45537 solver.cpp:252]     Train net output #1: loss = 1.29866 (* 1 = 1.29866 loss)
I0712 23:03:14.808485 45537 sgd_solver.cpp:106] Iteration 19300, lr = 0.015
I0712 23:04:34.920024 45537 solver.cpp:236] Iteration 19400, loss = 1.06957
I0712 23:04:34.920213 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:04:34.920253 45537 solver.cpp:252]     Train net output #1: loss = 0.95785 (* 1 = 0.95785 loss)
I0712 23:04:34.920267 45537 sgd_solver.cpp:106] Iteration 19400, lr = 0.015
I0712 23:05:54.235811 45537 solver.cpp:340] Iteration 19500, Testing net (#0)
I0712 23:07:11.171244 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4675
I0712 23:07:11.171387 45537 solver.cpp:408]     Test net output #1: loss = 1.06178 (* 1 = 1.06178 loss)
I0712 23:07:11.934742 45537 solver.cpp:236] Iteration 19500, loss = 1.07715
I0712 23:07:11.934793 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0712 23:07:11.934811 45537 solver.cpp:252]     Train net output #1: loss = 0.926169 (* 1 = 0.926169 loss)
I0712 23:07:11.934828 45537 sgd_solver.cpp:106] Iteration 19500, lr = 0.015
I0712 23:08:32.058176 45537 solver.cpp:236] Iteration 19600, loss = 1.07169
I0712 23:08:32.058329 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:08:32.058370 45537 solver.cpp:252]     Train net output #1: loss = 1.11462 (* 1 = 1.11462 loss)
I0712 23:08:32.058385 45537 sgd_solver.cpp:106] Iteration 19600, lr = 0.015
I0712 23:09:52.165115 45537 solver.cpp:236] Iteration 19700, loss = 1.08803
I0712 23:09:52.165251 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:09:52.165269 45537 solver.cpp:252]     Train net output #1: loss = 1.13968 (* 1 = 1.13968 loss)
I0712 23:09:52.165282 45537 sgd_solver.cpp:106] Iteration 19700, lr = 0.015
I0712 23:11:12.277128 45537 solver.cpp:236] Iteration 19800, loss = 1.07542
I0712 23:11:12.277339 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:11:12.277359 45537 solver.cpp:252]     Train net output #1: loss = 1.02288 (* 1 = 1.02288 loss)
I0712 23:11:12.277374 45537 sgd_solver.cpp:106] Iteration 19800, lr = 0.015
I0712 23:12:32.377579 45537 solver.cpp:236] Iteration 19900, loss = 1.06343
I0712 23:12:32.377717 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 23:12:32.377737 45537 solver.cpp:252]     Train net output #1: loss = 0.914381 (* 1 = 0.914381 loss)
I0712 23:12:32.377750 45537 sgd_solver.cpp:106] Iteration 19900, lr = 0.015
I0712 23:13:51.997763 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_20000.caffemodel
I0712 23:13:52.427029 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_20000.solverstate
I0712 23:13:53.227581 45537 solver.cpp:236] Iteration 20000, loss = 1.07775
I0712 23:13:53.227645 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:13:53.227661 45537 solver.cpp:252]     Train net output #1: loss = 1.10019 (* 1 = 1.10019 loss)
I0712 23:13:53.227676 45537 sgd_solver.cpp:106] Iteration 20000, lr = 0.015
I0712 23:15:13.294174 45537 solver.cpp:236] Iteration 20100, loss = 1.10679
I0712 23:15:13.294354 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:15:13.294385 45537 solver.cpp:252]     Train net output #1: loss = 1.10746 (* 1 = 1.10746 loss)
I0712 23:15:13.294402 45537 sgd_solver.cpp:106] Iteration 20100, lr = 0.015
I0712 23:16:33.387470 45537 solver.cpp:236] Iteration 20200, loss = 1.07062
I0712 23:16:33.387594 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:16:33.387619 45537 solver.cpp:252]     Train net output #1: loss = 1.05515 (* 1 = 1.05515 loss)
I0712 23:16:33.387632 45537 sgd_solver.cpp:106] Iteration 20200, lr = 0.015
I0712 23:17:27.066486 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 23:17:53.502588 45537 solver.cpp:236] Iteration 20300, loss = 1.0581
I0712 23:17:53.502667 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:17:53.502684 45537 solver.cpp:252]     Train net output #1: loss = 1.0887 (* 1 = 1.0887 loss)
I0712 23:17:53.502697 45537 sgd_solver.cpp:106] Iteration 20300, lr = 0.015
I0712 23:19:13.611006 45537 solver.cpp:236] Iteration 20400, loss = 1.07374
I0712 23:19:13.611276 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:19:13.611305 45537 solver.cpp:252]     Train net output #1: loss = 1.04263 (* 1 = 1.04263 loss)
I0712 23:19:13.611316 45537 sgd_solver.cpp:106] Iteration 20400, lr = 0.015
I0712 23:20:33.715293 45537 solver.cpp:236] Iteration 20500, loss = 1.05664
I0712 23:20:33.715473 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:20:33.715493 45537 solver.cpp:252]     Train net output #1: loss = 1.05629 (* 1 = 1.05629 loss)
I0712 23:20:33.715513 45537 sgd_solver.cpp:106] Iteration 20500, lr = 0.015
I0712 23:21:53.839820 45537 solver.cpp:236] Iteration 20600, loss = 1.05542
I0712 23:21:53.839942 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:21:53.839962 45537 solver.cpp:252]     Train net output #1: loss = 1.13452 (* 1 = 1.13452 loss)
I0712 23:21:53.839975 45537 sgd_solver.cpp:106] Iteration 20600, lr = 0.015
I0712 23:23:13.950922 45537 solver.cpp:236] Iteration 20700, loss = 1.08288
I0712 23:23:13.951083 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:23:13.951103 45537 solver.cpp:252]     Train net output #1: loss = 1.18249 (* 1 = 1.18249 loss)
I0712 23:23:13.951118 45537 sgd_solver.cpp:106] Iteration 20700, lr = 0.015
I0712 23:24:34.053336 45537 solver.cpp:236] Iteration 20800, loss = 1.05093
I0712 23:24:34.053477 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:24:34.053508 45537 solver.cpp:252]     Train net output #1: loss = 1.12362 (* 1 = 1.12362 loss)
I0712 23:24:34.053522 45537 sgd_solver.cpp:106] Iteration 20800, lr = 0.015
I0712 23:25:54.157407 45537 solver.cpp:236] Iteration 20900, loss = 1.07082
I0712 23:25:54.157552 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:25:54.157591 45537 solver.cpp:252]     Train net output #1: loss = 0.986089 (* 1 = 0.986089 loss)
I0712 23:25:54.157605 45537 sgd_solver.cpp:106] Iteration 20900, lr = 0.015
I0712 23:27:13.469625 45537 solver.cpp:340] Iteration 21000, Testing net (#0)
I0712 23:28:30.425801 45537 solver.cpp:408]     Test net output #0: accuracy = 0.45
I0712 23:28:30.425951 45537 solver.cpp:408]     Test net output #1: loss = 1.07461 (* 1 = 1.07461 loss)
I0712 23:28:31.188701 45537 solver.cpp:236] Iteration 21000, loss = 1.07424
I0712 23:28:31.188756 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:28:31.188776 45537 solver.cpp:252]     Train net output #1: loss = 1.14461 (* 1 = 1.14461 loss)
I0712 23:28:31.188793 45537 sgd_solver.cpp:106] Iteration 21000, lr = 0.015
I0712 23:29:51.292572 45537 solver.cpp:236] Iteration 21100, loss = 1.06561
I0712 23:29:51.292788 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:29:51.292824 45537 solver.cpp:252]     Train net output #1: loss = 1.10869 (* 1 = 1.10869 loss)
I0712 23:29:51.292841 45537 sgd_solver.cpp:106] Iteration 21100, lr = 0.015
I0712 23:31:11.402057 45537 solver.cpp:236] Iteration 21200, loss = 1.07589
I0712 23:31:11.402210 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:31:11.402243 45537 solver.cpp:252]     Train net output #1: loss = 1.07247 (* 1 = 1.07247 loss)
I0712 23:31:11.402261 45537 sgd_solver.cpp:106] Iteration 21200, lr = 0.015
I0712 23:32:31.514780 45537 solver.cpp:236] Iteration 21300, loss = 1.05896
I0712 23:32:31.514932 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:32:31.514964 45537 solver.cpp:252]     Train net output #1: loss = 1.02409 (* 1 = 1.02409 loss)
I0712 23:32:31.514979 45537 sgd_solver.cpp:106] Iteration 21300, lr = 0.015
I0712 23:33:51.619002 45537 solver.cpp:236] Iteration 21400, loss = 1.07639
I0712 23:33:51.619132 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:33:51.619164 45537 solver.cpp:252]     Train net output #1: loss = 1.2142 (* 1 = 1.2142 loss)
I0712 23:33:51.619180 45537 sgd_solver.cpp:106] Iteration 21400, lr = 0.015
I0712 23:35:11.719717 45537 solver.cpp:236] Iteration 21500, loss = 1.04621
I0712 23:35:11.719847 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:35:11.719878 45537 solver.cpp:252]     Train net output #1: loss = 1.15354 (* 1 = 1.15354 loss)
I0712 23:35:11.719892 45537 sgd_solver.cpp:106] Iteration 21500, lr = 0.015
I0712 23:36:31.833411 45537 solver.cpp:236] Iteration 21600, loss = 1.05242
I0712 23:36:31.833616 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:36:31.833638 45537 solver.cpp:252]     Train net output #1: loss = 0.951111 (* 1 = 0.951111 loss)
I0712 23:36:31.833652 45537 sgd_solver.cpp:106] Iteration 21600, lr = 0.015
I0712 23:37:51.945447 45537 solver.cpp:236] Iteration 21700, loss = 1.07619
I0712 23:37:51.945621 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:37:51.945653 45537 solver.cpp:252]     Train net output #1: loss = 1.15525 (* 1 = 1.15525 loss)
I0712 23:37:51.945672 45537 sgd_solver.cpp:106] Iteration 21700, lr = 0.015
I0712 23:38:27.984551 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 23:39:12.056355 45537 solver.cpp:236] Iteration 21800, loss = 1.05886
I0712 23:39:12.056485 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:39:12.056505 45537 solver.cpp:252]     Train net output #1: loss = 1.02209 (* 1 = 1.02209 loss)
I0712 23:39:12.056519 45537 sgd_solver.cpp:106] Iteration 21800, lr = 0.015
I0712 23:40:32.367231 45537 solver.cpp:236] Iteration 21900, loss = 1.06937
I0712 23:40:32.367416 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:40:32.367460 45537 solver.cpp:252]     Train net output #1: loss = 1.02076 (* 1 = 1.02076 loss)
I0712 23:40:32.367473 45537 sgd_solver.cpp:106] Iteration 21900, lr = 0.015
I0712 23:41:52.883096 45537 solver.cpp:236] Iteration 22000, loss = 1.07732
I0712 23:41:52.883227 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:41:52.883254 45537 solver.cpp:252]     Train net output #1: loss = 1.02703 (* 1 = 1.02703 loss)
I0712 23:41:52.883270 45537 sgd_solver.cpp:106] Iteration 22000, lr = 0.015
I0712 23:43:13.179692 45537 solver.cpp:236] Iteration 22100, loss = 1.04925
I0712 23:43:13.179834 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:43:13.179862 45537 solver.cpp:252]     Train net output #1: loss = 0.940698 (* 1 = 0.940698 loss)
I0712 23:43:13.179882 45537 sgd_solver.cpp:106] Iteration 22100, lr = 0.015
I0712 23:44:33.382522 45537 solver.cpp:236] Iteration 22200, loss = 1.06832
I0712 23:44:33.382711 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:44:33.382743 45537 solver.cpp:252]     Train net output #1: loss = 1.09736 (* 1 = 1.09736 loss)
I0712 23:44:33.382760 45537 sgd_solver.cpp:106] Iteration 22200, lr = 0.015
I0712 23:45:53.492815 45537 solver.cpp:236] Iteration 22300, loss = 1.05581
I0712 23:45:53.492967 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:45:53.492988 45537 solver.cpp:252]     Train net output #1: loss = 0.967727 (* 1 = 0.967727 loss)
I0712 23:45:53.493001 45537 sgd_solver.cpp:106] Iteration 22300, lr = 0.015
I0712 23:47:14.010416 45537 solver.cpp:236] Iteration 22400, loss = 1.08924
I0712 23:47:14.010561 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:47:14.010592 45537 solver.cpp:252]     Train net output #1: loss = 1.00253 (* 1 = 1.00253 loss)
I0712 23:47:14.010606 45537 sgd_solver.cpp:106] Iteration 22400, lr = 0.015
I0712 23:48:33.308149 45537 solver.cpp:340] Iteration 22500, Testing net (#0)
I0712 23:49:50.225004 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4325
I0712 23:49:50.225141 45537 solver.cpp:408]     Test net output #1: loss = 1.07792 (* 1 = 1.07792 loss)
I0712 23:49:50.995872 45537 solver.cpp:236] Iteration 22500, loss = 1.09117
I0712 23:49:50.995923 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:49:50.995944 45537 solver.cpp:252]     Train net output #1: loss = 1.10623 (* 1 = 1.10623 loss)
I0712 23:49:50.995961 45537 sgd_solver.cpp:106] Iteration 22500, lr = 0.015
I0712 23:51:11.119643 45537 solver.cpp:236] Iteration 22600, loss = 1.06165
I0712 23:51:11.119794 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:51:11.119812 45537 solver.cpp:252]     Train net output #1: loss = 1.12359 (* 1 = 1.12359 loss)
I0712 23:51:11.119827 45537 sgd_solver.cpp:106] Iteration 22600, lr = 0.015
I0712 23:52:31.225147 45537 solver.cpp:236] Iteration 22700, loss = 1.07536
I0712 23:52:31.225334 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 23:52:31.225363 45537 solver.cpp:252]     Train net output #1: loss = 1.0712 (* 1 = 1.0712 loss)
I0712 23:52:31.225376 45537 sgd_solver.cpp:106] Iteration 22700, lr = 0.015
I0712 23:53:51.328785 45537 solver.cpp:236] Iteration 22800, loss = 1.06346
I0712 23:53:51.328909 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 23:53:51.328927 45537 solver.cpp:252]     Train net output #1: loss = 1.23356 (* 1 = 1.23356 loss)
I0712 23:53:51.328941 45537 sgd_solver.cpp:106] Iteration 22800, lr = 0.015
I0712 23:54:40.998553 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 23:55:11.439528 45537 solver.cpp:236] Iteration 22900, loss = 1.08278
I0712 23:55:11.439703 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 23:55:11.439733 45537 solver.cpp:252]     Train net output #1: loss = 1.14263 (* 1 = 1.14263 loss)
I0712 23:55:11.439743 45537 sgd_solver.cpp:106] Iteration 22900, lr = 0.015
I0712 23:56:31.555869 45537 solver.cpp:236] Iteration 23000, loss = 1.08703
I0712 23:56:31.555984 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:56:31.556000 45537 solver.cpp:252]     Train net output #1: loss = 0.966568 (* 1 = 0.966568 loss)
I0712 23:56:31.556015 45537 sgd_solver.cpp:106] Iteration 23000, lr = 0.015
I0712 23:57:51.656020 45537 solver.cpp:236] Iteration 23100, loss = 1.08977
I0712 23:57:51.656142 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 23:57:51.656162 45537 solver.cpp:252]     Train net output #1: loss = 1.02644 (* 1 = 1.02644 loss)
I0712 23:57:51.656178 45537 sgd_solver.cpp:106] Iteration 23100, lr = 0.015
I0712 23:59:11.761524 45537 solver.cpp:236] Iteration 23200, loss = 1.0643
I0712 23:59:11.761682 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0712 23:59:11.761701 45537 solver.cpp:252]     Train net output #1: loss = 1.01258 (* 1 = 1.01258 loss)
I0712 23:59:11.761716 45537 sgd_solver.cpp:106] Iteration 23200, lr = 0.015
I0713 00:00:32.036011 45537 solver.cpp:236] Iteration 23300, loss = 1.06215
I0713 00:00:32.036166 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 00:00:32.036188 45537 solver.cpp:252]     Train net output #1: loss = 0.896351 (* 1 = 0.896351 loss)
I0713 00:00:32.036201 45537 sgd_solver.cpp:106] Iteration 23300, lr = 0.015
I0713 00:01:52.283479 45537 solver.cpp:236] Iteration 23400, loss = 1.07817
I0713 00:01:52.283637 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:01:52.283670 45537 solver.cpp:252]     Train net output #1: loss = 1.06665 (* 1 = 1.06665 loss)
I0713 00:01:52.283687 45537 sgd_solver.cpp:106] Iteration 23400, lr = 0.015
I0713 00:03:12.385926 45537 solver.cpp:236] Iteration 23500, loss = 1.07988
I0713 00:03:12.386075 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:03:12.386093 45537 solver.cpp:252]     Train net output #1: loss = 1.0153 (* 1 = 1.0153 loss)
I0713 00:03:12.386107 45537 sgd_solver.cpp:106] Iteration 23500, lr = 0.015
I0713 00:04:32.499857 45537 solver.cpp:236] Iteration 23600, loss = 1.07632
I0713 00:04:32.500013 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:04:32.500049 45537 solver.cpp:252]     Train net output #1: loss = 0.971806 (* 1 = 0.971806 loss)
I0713 00:04:32.500062 45537 sgd_solver.cpp:106] Iteration 23600, lr = 0.015
I0713 00:05:52.612402 45537 solver.cpp:236] Iteration 23700, loss = 1.07845
I0713 00:05:52.612515 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:05:52.612534 45537 solver.cpp:252]     Train net output #1: loss = 1.04159 (* 1 = 1.04159 loss)
I0713 00:05:52.612548 45537 sgd_solver.cpp:106] Iteration 23700, lr = 0.015
I0713 00:07:12.712139 45537 solver.cpp:236] Iteration 23800, loss = 1.05296
I0713 00:07:12.712404 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:07:12.712425 45537 solver.cpp:252]     Train net output #1: loss = 1.04432 (* 1 = 1.04432 loss)
I0713 00:07:12.712445 45537 sgd_solver.cpp:106] Iteration 23800, lr = 0.015
I0713 00:08:02.386075 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 00:08:32.823585 45537 solver.cpp:236] Iteration 23900, loss = 1.07305
I0713 00:08:32.823703 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0713 00:08:32.823721 45537 solver.cpp:252]     Train net output #1: loss = 0.888946 (* 1 = 0.888946 loss)
I0713 00:08:32.823735 45537 sgd_solver.cpp:106] Iteration 23900, lr = 0.015
I0713 00:09:52.125318 45537 solver.cpp:340] Iteration 24000, Testing net (#0)
I0713 00:11:09.066568 45537 solver.cpp:408]     Test net output #0: accuracy = 0.48
I0713 00:11:09.066726 45537 solver.cpp:408]     Test net output #1: loss = 1.05262 (* 1 = 1.05262 loss)
I0713 00:11:09.836009 45537 solver.cpp:236] Iteration 24000, loss = 1.08747
I0713 00:11:09.836063 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 00:11:09.836081 45537 solver.cpp:252]     Train net output #1: loss = 1.20357 (* 1 = 1.20357 loss)
I0713 00:11:09.836097 45537 sgd_solver.cpp:106] Iteration 24000, lr = 0.015
I0713 00:12:29.954861 45537 solver.cpp:236] Iteration 24100, loss = 1.09257
I0713 00:12:29.955013 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 00:12:29.955035 45537 solver.cpp:252]     Train net output #1: loss = 1.05288 (* 1 = 1.05288 loss)
I0713 00:12:29.955054 45537 sgd_solver.cpp:106] Iteration 24100, lr = 0.015
I0713 00:13:50.059399 45537 solver.cpp:236] Iteration 24200, loss = 1.07296
I0713 00:13:50.059526 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:13:50.059545 45537 solver.cpp:252]     Train net output #1: loss = 1.10885 (* 1 = 1.10885 loss)
I0713 00:13:50.059559 45537 sgd_solver.cpp:106] Iteration 24200, lr = 0.015
I0713 00:15:10.170150 45537 solver.cpp:236] Iteration 24300, loss = 1.06756
I0713 00:15:10.170337 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:15:10.170356 45537 solver.cpp:252]     Train net output #1: loss = 0.98549 (* 1 = 0.98549 loss)
I0713 00:15:10.170370 45537 sgd_solver.cpp:106] Iteration 24300, lr = 0.015
I0713 00:16:30.369406 45537 solver.cpp:236] Iteration 24400, loss = 1.05822
I0713 00:16:30.369576 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:16:30.369601 45537 solver.cpp:252]     Train net output #1: loss = 1.20792 (* 1 = 1.20792 loss)
I0713 00:16:30.369616 45537 sgd_solver.cpp:106] Iteration 24400, lr = 0.015
I0713 00:17:50.485517 45537 solver.cpp:236] Iteration 24500, loss = 1.07984
I0713 00:17:50.485672 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:17:50.485692 45537 solver.cpp:252]     Train net output #1: loss = 1.09122 (* 1 = 1.09122 loss)
I0713 00:17:50.485707 45537 sgd_solver.cpp:106] Iteration 24500, lr = 0.015
I0713 00:19:10.588901 45537 solver.cpp:236] Iteration 24600, loss = 1.06233
I0713 00:19:10.589015 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:19:10.589035 45537 solver.cpp:252]     Train net output #1: loss = 1.08276 (* 1 = 1.08276 loss)
I0713 00:19:10.589048 45537 sgd_solver.cpp:106] Iteration 24600, lr = 0.015
I0713 00:20:30.688366 45537 solver.cpp:236] Iteration 24700, loss = 1.07716
I0713 00:20:30.688495 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:20:30.688514 45537 solver.cpp:252]     Train net output #1: loss = 0.981808 (* 1 = 0.981808 loss)
I0713 00:20:30.688529 45537 sgd_solver.cpp:106] Iteration 24700, lr = 0.015
I0713 00:21:50.802199 45537 solver.cpp:236] Iteration 24800, loss = 1.06743
I0713 00:21:50.802314 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:21:50.802335 45537 solver.cpp:252]     Train net output #1: loss = 0.953346 (* 1 = 0.953346 loss)
I0713 00:21:50.802352 45537 sgd_solver.cpp:106] Iteration 24800, lr = 0.015
I0713 00:23:10.904295 45537 solver.cpp:236] Iteration 24900, loss = 1.08328
I0713 00:23:10.904505 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:23:10.904525 45537 solver.cpp:252]     Train net output #1: loss = 1.0662 (* 1 = 1.0662 loss)
I0713 00:23:10.904539 45537 sgd_solver.cpp:106] Iteration 24900, lr = 0.015
I0713 00:24:30.203266 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_25000.caffemodel
I0713 00:24:30.486389 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_25000.solverstate
I0713 00:24:31.287391 45537 solver.cpp:236] Iteration 25000, loss = 1.05359
I0713 00:24:31.287452 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0713 00:24:31.287470 45537 solver.cpp:252]     Train net output #1: loss = 0.861022 (* 1 = 0.861022 loss)
I0713 00:24:31.287485 45537 sgd_solver.cpp:106] Iteration 25000, lr = 0.015
I0713 00:25:51.425168 45537 solver.cpp:236] Iteration 25100, loss = 1.04892
I0713 00:25:51.425317 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:25:51.425336 45537 solver.cpp:252]     Train net output #1: loss = 1.13153 (* 1 = 1.13153 loss)
I0713 00:25:51.425348 45537 sgd_solver.cpp:106] Iteration 25100, lr = 0.015
I0713 00:26:37.090473 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 00:27:11.527833 45537 solver.cpp:236] Iteration 25200, loss = 1.04159
I0713 00:27:11.527963 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 00:27:11.527993 45537 solver.cpp:252]     Train net output #1: loss = 1.31057 (* 1 = 1.31057 loss)
I0713 00:27:11.528015 45537 sgd_solver.cpp:106] Iteration 25200, lr = 0.015
I0713 00:28:31.820077 45537 solver.cpp:236] Iteration 25300, loss = 1.07538
I0713 00:28:31.820231 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:28:31.820273 45537 solver.cpp:252]     Train net output #1: loss = 1.07848 (* 1 = 1.07848 loss)
I0713 00:28:31.820286 45537 sgd_solver.cpp:106] Iteration 25300, lr = 0.015
I0713 00:29:52.960741 45537 solver.cpp:236] Iteration 25400, loss = 1.07747
I0713 00:29:52.960886 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:29:52.960919 45537 solver.cpp:252]     Train net output #1: loss = 1.10687 (* 1 = 1.10687 loss)
I0713 00:29:52.960940 45537 sgd_solver.cpp:106] Iteration 25400, lr = 0.015
I0713 00:31:12.755074 45537 solver.cpp:340] Iteration 25500, Testing net (#0)
I0713 00:32:29.799726 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4675
I0713 00:32:29.799868 45537 solver.cpp:408]     Test net output #1: loss = 1.05984 (* 1 = 1.05984 loss)
I0713 00:32:30.564923 45537 solver.cpp:236] Iteration 25500, loss = 1.07585
I0713 00:32:30.564981 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 00:32:30.565001 45537 solver.cpp:252]     Train net output #1: loss = 1.25603 (* 1 = 1.25603 loss)
I0713 00:32:30.565019 45537 sgd_solver.cpp:106] Iteration 25500, lr = 0.015
I0713 00:33:50.661510 45537 solver.cpp:236] Iteration 25600, loss = 1.06799
I0713 00:33:50.661648 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:33:50.661666 45537 solver.cpp:252]     Train net output #1: loss = 1.06773 (* 1 = 1.06773 loss)
I0713 00:33:50.661682 45537 sgd_solver.cpp:106] Iteration 25600, lr = 0.015
I0713 00:35:10.776696 45537 solver.cpp:236] Iteration 25700, loss = 1.06631
I0713 00:35:10.776886 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:35:10.776931 45537 solver.cpp:252]     Train net output #1: loss = 1.11761 (* 1 = 1.11761 loss)
I0713 00:35:10.776945 45537 sgd_solver.cpp:106] Iteration 25700, lr = 0.015
I0713 00:36:30.883379 45537 solver.cpp:236] Iteration 25800, loss = 1.06399
I0713 00:36:30.883579 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:36:30.883611 45537 solver.cpp:252]     Train net output #1: loss = 1.101 (* 1 = 1.101 loss)
I0713 00:36:30.883622 45537 sgd_solver.cpp:106] Iteration 25800, lr = 0.015
I0713 00:37:50.986039 45537 solver.cpp:236] Iteration 25900, loss = 1.0811
I0713 00:37:50.986297 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:37:50.986320 45537 solver.cpp:252]     Train net output #1: loss = 1.05691 (* 1 = 1.05691 loss)
I0713 00:37:50.986333 45537 sgd_solver.cpp:106] Iteration 25900, lr = 0.015
I0713 00:39:11.094990 45537 solver.cpp:236] Iteration 26000, loss = 1.07542
I0713 00:39:11.095093 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:39:11.095113 45537 solver.cpp:252]     Train net output #1: loss = 1.06261 (* 1 = 1.06261 loss)
I0713 00:39:11.095129 45537 sgd_solver.cpp:106] Iteration 26000, lr = 0.015
I0713 00:40:31.203593 45537 solver.cpp:236] Iteration 26100, loss = 1.08303
I0713 00:40:31.203703 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:40:31.203721 45537 solver.cpp:252]     Train net output #1: loss = 1.10404 (* 1 = 1.10404 loss)
I0713 00:40:31.203734 45537 sgd_solver.cpp:106] Iteration 26100, lr = 0.015
I0713 00:41:51.308686 45537 solver.cpp:236] Iteration 26200, loss = 1.06531
I0713 00:41:51.308826 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:41:51.308858 45537 solver.cpp:252]     Train net output #1: loss = 1.03442 (* 1 = 1.03442 loss)
I0713 00:41:51.308876 45537 sgd_solver.cpp:106] Iteration 26200, lr = 0.015
I0713 00:43:11.407773 45537 solver.cpp:236] Iteration 26300, loss = 1.08441
I0713 00:43:11.407879 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 00:43:11.407899 45537 solver.cpp:252]     Train net output #1: loss = 1.14522 (* 1 = 1.14522 loss)
I0713 00:43:11.407913 45537 sgd_solver.cpp:106] Iteration 26300, lr = 0.015
I0713 00:44:31.520025 45537 solver.cpp:236] Iteration 26400, loss = 1.06708
I0713 00:44:31.520195 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 00:44:31.520215 45537 solver.cpp:252]     Train net output #1: loss = 1.136 (* 1 = 1.136 loss)
I0713 00:44:31.520229 45537 sgd_solver.cpp:106] Iteration 26400, lr = 0.015
I0713 00:44:37.127346 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 00:45:51.618460 45537 solver.cpp:236] Iteration 26500, loss = 1.08109
I0713 00:45:51.618623 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 00:45:51.618665 45537 solver.cpp:252]     Train net output #1: loss = 1.15401 (* 1 = 1.15401 loss)
I0713 00:45:51.618685 45537 sgd_solver.cpp:106] Iteration 26500, lr = 0.015
I0713 00:47:11.726855 45537 solver.cpp:236] Iteration 26600, loss = 1.06931
I0713 00:47:11.726989 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:47:11.727020 45537 solver.cpp:252]     Train net output #1: loss = 1.01114 (* 1 = 1.01114 loss)
I0713 00:47:11.727033 45537 sgd_solver.cpp:106] Iteration 26600, lr = 0.015
I0713 00:48:31.838095 45537 solver.cpp:236] Iteration 26700, loss = 1.05222
I0713 00:48:31.838234 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:48:31.838255 45537 solver.cpp:252]     Train net output #1: loss = 1.11227 (* 1 = 1.11227 loss)
I0713 00:48:31.838273 45537 sgd_solver.cpp:106] Iteration 26700, lr = 0.015
I0713 00:49:51.945118 45537 solver.cpp:236] Iteration 26800, loss = 1.06799
I0713 00:49:51.945273 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:49:51.945294 45537 solver.cpp:252]     Train net output #1: loss = 1.02905 (* 1 = 1.02905 loss)
I0713 00:49:51.945310 45537 sgd_solver.cpp:106] Iteration 26800, lr = 0.015
I0713 00:51:12.044625 45537 solver.cpp:236] Iteration 26900, loss = 1.06399
I0713 00:51:12.044723 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 00:51:12.044742 45537 solver.cpp:252]     Train net output #1: loss = 1.25305 (* 1 = 1.25305 loss)
I0713 00:51:12.044755 45537 sgd_solver.cpp:106] Iteration 26900, lr = 0.015
I0713 00:52:31.368466 45537 solver.cpp:340] Iteration 27000, Testing net (#0)
I0713 00:53:48.329666 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4525
I0713 00:53:48.329802 45537 solver.cpp:408]     Test net output #1: loss = 1.06704 (* 1 = 1.06704 loss)
I0713 00:53:49.104567 45537 solver.cpp:236] Iteration 27000, loss = 1.0837
I0713 00:53:49.104619 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 00:53:49.104640 45537 solver.cpp:252]     Train net output #1: loss = 1.04366 (* 1 = 1.04366 loss)
I0713 00:53:49.104656 45537 sgd_solver.cpp:106] Iteration 27000, lr = 0.015
I0713 00:55:09.164072 45537 solver.cpp:236] Iteration 27100, loss = 1.08332
I0713 00:55:09.164301 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 00:55:09.164319 45537 solver.cpp:252]     Train net output #1: loss = 1.30279 (* 1 = 1.30279 loss)
I0713 00:55:09.164332 45537 sgd_solver.cpp:106] Iteration 27100, lr = 0.015
I0713 00:56:29.269660 45537 solver.cpp:236] Iteration 27200, loss = 1.07349
I0713 00:56:29.269798 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 00:56:29.269819 45537 solver.cpp:252]     Train net output #1: loss = 1.14991 (* 1 = 1.14991 loss)
I0713 00:56:29.269836 45537 sgd_solver.cpp:106] Iteration 27200, lr = 0.015
I0713 00:57:49.391108 45537 solver.cpp:236] Iteration 27300, loss = 1.09318
I0713 00:57:49.391257 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:57:49.391278 45537 solver.cpp:252]     Train net output #1: loss = 1.04683 (* 1 = 1.04683 loss)
I0713 00:57:49.391295 45537 sgd_solver.cpp:106] Iteration 27300, lr = 0.015
I0713 00:59:09.493620 45537 solver.cpp:236] Iteration 27400, loss = 1.0747
I0713 00:59:09.493752 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 00:59:09.493770 45537 solver.cpp:252]     Train net output #1: loss = 1.00787 (* 1 = 1.00787 loss)
I0713 00:59:09.493785 45537 sgd_solver.cpp:106] Iteration 27400, lr = 0.015
I0713 01:00:29.601107 45537 solver.cpp:236] Iteration 27500, loss = 1.05672
I0713 01:00:29.601243 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:00:29.601264 45537 solver.cpp:252]     Train net output #1: loss = 1.11071 (* 1 = 1.11071 loss)
I0713 01:00:29.601277 45537 sgd_solver.cpp:106] Iteration 27500, lr = 0.015
I0713 01:01:21.675585 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 01:01:49.712571 45537 solver.cpp:236] Iteration 27600, loss = 1.08684
I0713 01:01:49.712633 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:01:49.712649 45537 solver.cpp:252]     Train net output #1: loss = 1.10168 (* 1 = 1.10168 loss)
I0713 01:01:49.712663 45537 sgd_solver.cpp:106] Iteration 27600, lr = 0.015
I0713 01:03:09.813488 45537 solver.cpp:236] Iteration 27700, loss = 1.06615
I0713 01:03:09.813645 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 01:03:09.813675 45537 solver.cpp:252]     Train net output #1: loss = 1.01757 (* 1 = 1.01757 loss)
I0713 01:03:09.813689 45537 sgd_solver.cpp:106] Iteration 27700, lr = 0.015
I0713 01:04:29.930598 45537 solver.cpp:236] Iteration 27800, loss = 1.05503
I0713 01:04:29.930709 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:04:29.930727 45537 solver.cpp:252]     Train net output #1: loss = 1.22079 (* 1 = 1.22079 loss)
I0713 01:04:29.930742 45537 sgd_solver.cpp:106] Iteration 27800, lr = 0.015
I0713 01:05:50.040720 45537 solver.cpp:236] Iteration 27900, loss = 1.07637
I0713 01:05:50.040846 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:05:50.040863 45537 solver.cpp:252]     Train net output #1: loss = 1.08331 (* 1 = 1.08331 loss)
I0713 01:05:50.040877 45537 sgd_solver.cpp:106] Iteration 27900, lr = 0.015
I0713 01:07:10.313444 45537 solver.cpp:236] Iteration 28000, loss = 1.06415
I0713 01:07:10.313602 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 01:07:10.313642 45537 solver.cpp:252]     Train net output #1: loss = 1.29946 (* 1 = 1.29946 loss)
I0713 01:07:10.313659 45537 sgd_solver.cpp:106] Iteration 28000, lr = 0.015
I0713 01:08:31.305583 45537 solver.cpp:236] Iteration 28100, loss = 1.09213
I0713 01:08:31.305717 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:08:31.305742 45537 solver.cpp:252]     Train net output #1: loss = 1.12946 (* 1 = 1.12946 loss)
I0713 01:08:31.305763 45537 sgd_solver.cpp:106] Iteration 28100, lr = 0.015
I0713 01:09:51.365756 45537 solver.cpp:236] Iteration 28200, loss = 1.05723
I0713 01:09:51.366034 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:09:51.366055 45537 solver.cpp:252]     Train net output #1: loss = 1.02167 (* 1 = 1.02167 loss)
I0713 01:09:51.366070 45537 sgd_solver.cpp:106] Iteration 28200, lr = 0.015
I0713 01:11:11.475661 45537 solver.cpp:236] Iteration 28300, loss = 1.09554
I0713 01:11:11.475824 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:11:11.475842 45537 solver.cpp:252]     Train net output #1: loss = 1.13258 (* 1 = 1.13258 loss)
I0713 01:11:11.475863 45537 sgd_solver.cpp:106] Iteration 28300, lr = 0.015
I0713 01:12:31.584951 45537 solver.cpp:236] Iteration 28400, loss = 1.08468
I0713 01:12:31.585070 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 01:12:31.585089 45537 solver.cpp:252]     Train net output #1: loss = 1.21396 (* 1 = 1.21396 loss)
I0713 01:12:31.585103 45537 sgd_solver.cpp:106] Iteration 28400, lr = 0.015
I0713 01:13:50.889849 45537 solver.cpp:340] Iteration 28500, Testing net (#0)
I0713 01:15:07.853349 45537 solver.cpp:408]     Test net output #0: accuracy = 0.47625
I0713 01:15:07.853515 45537 solver.cpp:408]     Test net output #1: loss = 1.05478 (* 1 = 1.05478 loss)
I0713 01:15:08.619999 45537 solver.cpp:236] Iteration 28500, loss = 1.06327
I0713 01:15:08.620064 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 01:15:08.620087 45537 solver.cpp:252]     Train net output #1: loss = 0.95783 (* 1 = 0.95783 loss)
I0713 01:15:08.620110 45537 sgd_solver.cpp:106] Iteration 28500, lr = 0.015
I0713 01:16:28.695619 45537 solver.cpp:236] Iteration 28600, loss = 1.06802
I0713 01:16:28.695766 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:16:28.695797 45537 solver.cpp:252]     Train net output #1: loss = 1.04506 (* 1 = 1.04506 loss)
I0713 01:16:28.695814 45537 sgd_solver.cpp:106] Iteration 28600, lr = 0.015
I0713 01:17:48.809113 45537 solver.cpp:236] Iteration 28700, loss = 1.08322
I0713 01:17:48.809293 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:17:48.809329 45537 solver.cpp:252]     Train net output #1: loss = 1.13964 (* 1 = 1.13964 loss)
I0713 01:17:48.809350 45537 sgd_solver.cpp:106] Iteration 28700, lr = 0.015
I0713 01:19:08.921084 45537 solver.cpp:236] Iteration 28800, loss = 1.0796
I0713 01:19:08.921247 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 01:19:08.921277 45537 solver.cpp:252]     Train net output #1: loss = 0.932168 (* 1 = 0.932168 loss)
I0713 01:19:08.921291 45537 sgd_solver.cpp:106] Iteration 28800, lr = 0.015
I0713 01:20:29.030067 45537 solver.cpp:236] Iteration 28900, loss = 1.06095
I0713 01:20:29.030238 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:20:29.030262 45537 solver.cpp:252]     Train net output #1: loss = 1.04505 (* 1 = 1.04505 loss)
I0713 01:20:29.030279 45537 sgd_solver.cpp:106] Iteration 28900, lr = 0.015
I0713 01:20:45.845841 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 01:21:49.128201 45537 solver.cpp:236] Iteration 29000, loss = 1.06378
I0713 01:21:49.128309 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:21:49.128326 45537 solver.cpp:252]     Train net output #1: loss = 1.05917 (* 1 = 1.05917 loss)
I0713 01:21:49.128340 45537 sgd_solver.cpp:106] Iteration 29000, lr = 0.015
I0713 01:23:09.259263 45537 solver.cpp:236] Iteration 29100, loss = 1.07435
I0713 01:23:09.259418 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:23:09.259440 45537 solver.cpp:252]     Train net output #1: loss = 1.14259 (* 1 = 1.14259 loss)
I0713 01:23:09.259459 45537 sgd_solver.cpp:106] Iteration 29100, lr = 0.015
I0713 01:24:29.363675 45537 solver.cpp:236] Iteration 29200, loss = 1.0824
I0713 01:24:29.363822 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:24:29.363840 45537 solver.cpp:252]     Train net output #1: loss = 1.09271 (* 1 = 1.09271 loss)
I0713 01:24:29.363855 45537 sgd_solver.cpp:106] Iteration 29200, lr = 0.015
I0713 01:25:49.468722 45537 solver.cpp:236] Iteration 29300, loss = 1.07008
I0713 01:25:49.468889 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:25:49.468910 45537 solver.cpp:252]     Train net output #1: loss = 1.00108 (* 1 = 1.00108 loss)
I0713 01:25:49.468924 45537 sgd_solver.cpp:106] Iteration 29300, lr = 0.015
I0713 01:27:09.572846 45537 solver.cpp:236] Iteration 29400, loss = 1.09116
I0713 01:27:09.573036 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:27:09.573068 45537 solver.cpp:252]     Train net output #1: loss = 1.22285 (* 1 = 1.22285 loss)
I0713 01:27:09.573083 45537 sgd_solver.cpp:106] Iteration 29400, lr = 0.015
I0713 01:28:29.681321 45537 solver.cpp:236] Iteration 29500, loss = 1.08447
I0713 01:28:29.681475 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:28:29.681506 45537 solver.cpp:252]     Train net output #1: loss = 1.05525 (* 1 = 1.05525 loss)
I0713 01:28:29.681520 45537 sgd_solver.cpp:106] Iteration 29500, lr = 0.015
I0713 01:29:49.791782 45537 solver.cpp:236] Iteration 29600, loss = 1.05315
I0713 01:29:49.791899 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:29:49.791918 45537 solver.cpp:252]     Train net output #1: loss = 1.14291 (* 1 = 1.14291 loss)
I0713 01:29:49.791931 45537 sgd_solver.cpp:106] Iteration 29600, lr = 0.015
I0713 01:31:09.898586 45537 solver.cpp:236] Iteration 29700, loss = 1.07945
I0713 01:31:09.898723 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:31:09.898743 45537 solver.cpp:252]     Train net output #1: loss = 1.16661 (* 1 = 1.16661 loss)
I0713 01:31:09.898757 45537 sgd_solver.cpp:106] Iteration 29700, lr = 0.015
I0713 01:32:29.996675 45537 solver.cpp:236] Iteration 29800, loss = 1.08701
I0713 01:32:29.996841 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:32:29.996860 45537 solver.cpp:252]     Train net output #1: loss = 1.03429 (* 1 = 1.03429 loss)
I0713 01:32:29.996879 45537 sgd_solver.cpp:106] Iteration 29800, lr = 0.015
I0713 01:33:50.096839 45537 solver.cpp:236] Iteration 29900, loss = 1.06717
I0713 01:33:50.096936 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:33:50.096953 45537 solver.cpp:252]     Train net output #1: loss = 1.14433 (* 1 = 1.14433 loss)
I0713 01:33:50.096966 45537 sgd_solver.cpp:106] Iteration 29900, lr = 0.015
I0713 01:34:06.937366 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 01:35:09.422488 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_30000.caffemodel
I0713 01:35:09.608546 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_30000.solverstate
I0713 01:35:09.645133 45537 solver.cpp:340] Iteration 30000, Testing net (#0)
I0713 01:36:26.518810 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4175
I0713 01:36:26.518956 45537 solver.cpp:408]     Test net output #1: loss = 1.08136 (* 1 = 1.08136 loss)
I0713 01:36:27.286540 45537 solver.cpp:236] Iteration 30000, loss = 1.08499
I0713 01:36:27.286594 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 01:36:27.286612 45537 solver.cpp:252]     Train net output #1: loss = 1.01036 (* 1 = 1.01036 loss)
I0713 01:36:27.286639 45537 sgd_solver.cpp:106] Iteration 30000, lr = 0.015
I0713 01:37:47.417304 45537 solver.cpp:236] Iteration 30100, loss = 1.04157
I0713 01:37:47.417462 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:37:47.417486 45537 solver.cpp:252]     Train net output #1: loss = 1.14301 (* 1 = 1.14301 loss)
I0713 01:37:47.417500 45537 sgd_solver.cpp:106] Iteration 30100, lr = 0.015
I0713 01:39:07.521180 45537 solver.cpp:236] Iteration 30200, loss = 1.05586
I0713 01:39:07.521307 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:39:07.521327 45537 solver.cpp:252]     Train net output #1: loss = 1.06187 (* 1 = 1.06187 loss)
I0713 01:39:07.521342 45537 sgd_solver.cpp:106] Iteration 30200, lr = 0.015
I0713 01:40:27.638386 45537 solver.cpp:236] Iteration 30300, loss = 1.06505
I0713 01:40:27.638525 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:40:27.638566 45537 solver.cpp:252]     Train net output #1: loss = 1.04596 (* 1 = 1.04596 loss)
I0713 01:40:27.638584 45537 sgd_solver.cpp:106] Iteration 30300, lr = 0.015
I0713 01:41:47.741268 45537 solver.cpp:236] Iteration 30400, loss = 1.0687
I0713 01:41:47.741400 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:41:47.741420 45537 solver.cpp:252]     Train net output #1: loss = 1.11439 (* 1 = 1.11439 loss)
I0713 01:41:47.741433 45537 sgd_solver.cpp:106] Iteration 30400, lr = 0.015
I0713 01:43:07.850402 45537 solver.cpp:236] Iteration 30500, loss = 1.0895
I0713 01:43:07.850558 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 01:43:07.850591 45537 solver.cpp:252]     Train net output #1: loss = 1.05695 (* 1 = 1.05695 loss)
I0713 01:43:07.850605 45537 sgd_solver.cpp:106] Iteration 30500, lr = 0.015
I0713 01:44:27.975603 45537 solver.cpp:236] Iteration 30600, loss = 1.07518
I0713 01:44:27.975723 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 01:44:27.975744 45537 solver.cpp:252]     Train net output #1: loss = 1.21902 (* 1 = 1.21902 loss)
I0713 01:44:27.975761 45537 sgd_solver.cpp:106] Iteration 30600, lr = 0.015
I0713 01:45:48.081501 45537 solver.cpp:236] Iteration 30700, loss = 1.08022
I0713 01:45:48.081665 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:45:48.081687 45537 solver.cpp:252]     Train net output #1: loss = 1.07094 (* 1 = 1.07094 loss)
I0713 01:45:48.081701 45537 sgd_solver.cpp:106] Iteration 30700, lr = 0.015
I0713 01:47:08.186312 45537 solver.cpp:236] Iteration 30800, loss = 1.05517
I0713 01:47:08.186441 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:47:08.186473 45537 solver.cpp:252]     Train net output #1: loss = 1.02348 (* 1 = 1.02348 loss)
I0713 01:47:08.186491 45537 sgd_solver.cpp:106] Iteration 30800, lr = 0.015
I0713 01:48:28.297562 45537 solver.cpp:236] Iteration 30900, loss = 1.07033
I0713 01:48:28.297705 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:48:28.297725 45537 solver.cpp:252]     Train net output #1: loss = 1.14762 (* 1 = 1.14762 loss)
I0713 01:48:28.297740 45537 sgd_solver.cpp:106] Iteration 30900, lr = 0.015
I0713 01:49:48.408011 45537 solver.cpp:236] Iteration 31000, loss = 1.06253
I0713 01:49:48.408157 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 01:49:48.408190 45537 solver.cpp:252]     Train net output #1: loss = 0.941252 (* 1 = 0.941252 loss)
I0713 01:49:48.408205 45537 sgd_solver.cpp:106] Iteration 31000, lr = 0.015
I0713 01:51:08.506471 45537 solver.cpp:236] Iteration 31100, loss = 1.05302
I0713 01:51:08.506671 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 01:51:08.506705 45537 solver.cpp:252]     Train net output #1: loss = 0.926117 (* 1 = 0.926117 loss)
I0713 01:51:08.506716 45537 sgd_solver.cpp:106] Iteration 31100, lr = 0.015
I0713 01:52:28.622524 45537 solver.cpp:236] Iteration 31200, loss = 1.10023
I0713 01:52:28.622675 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 01:52:28.622700 45537 solver.cpp:252]     Train net output #1: loss = 1.10127 (* 1 = 1.10127 loss)
I0713 01:52:28.622714 45537 sgd_solver.cpp:106] Iteration 31200, lr = 0.015
I0713 01:53:48.731974 45537 solver.cpp:236] Iteration 31300, loss = 1.05237
I0713 01:53:48.732143 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 01:53:48.732177 45537 solver.cpp:252]     Train net output #1: loss = 0.915966 (* 1 = 0.915966 loss)
I0713 01:53:48.732192 45537 sgd_solver.cpp:106] Iteration 31300, lr = 0.015
I0713 01:55:08.830992 45537 solver.cpp:236] Iteration 31400, loss = 1.07233
I0713 01:55:08.831192 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 01:55:08.831223 45537 solver.cpp:252]     Train net output #1: loss = 1.15326 (* 1 = 1.15326 loss)
I0713 01:55:08.831233 45537 sgd_solver.cpp:106] Iteration 31400, lr = 0.015
I0713 01:56:28.136231 45537 solver.cpp:340] Iteration 31500, Testing net (#0)
I0713 01:57:45.072628 45537 solver.cpp:408]     Test net output #0: accuracy = 0.455
I0713 01:57:45.072749 45537 solver.cpp:408]     Test net output #1: loss = 1.06446 (* 1 = 1.06446 loss)
I0713 01:57:45.844892 45537 solver.cpp:236] Iteration 31500, loss = 1.0633
I0713 01:57:45.844944 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 01:57:45.844962 45537 solver.cpp:252]     Train net output #1: loss = 0.913765 (* 1 = 0.913765 loss)
I0713 01:57:45.844980 45537 sgd_solver.cpp:106] Iteration 31500, lr = 0.015
I0713 01:59:06.213980 45537 solver.cpp:236] Iteration 31600, loss = 1.09341
I0713 01:59:06.214140 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 01:59:06.214187 45537 solver.cpp:252]     Train net output #1: loss = 1.20752 (* 1 = 1.20752 loss)
I0713 01:59:06.214206 45537 sgd_solver.cpp:106] Iteration 31600, lr = 0.015
I0713 02:00:26.360345 45537 solver.cpp:236] Iteration 31700, loss = 1.06622
I0713 02:00:26.360471 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:00:26.360489 45537 solver.cpp:252]     Train net output #1: loss = 1.14164 (* 1 = 1.14164 loss)
I0713 02:00:26.360504 45537 sgd_solver.cpp:106] Iteration 31700, lr = 0.015
I0713 02:01:17.628476 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 02:01:46.477524 45537 solver.cpp:236] Iteration 31800, loss = 1.06407
I0713 02:01:46.477593 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:01:46.477622 45537 solver.cpp:252]     Train net output #1: loss = 1.1117 (* 1 = 1.1117 loss)
I0713 02:01:46.477641 45537 sgd_solver.cpp:106] Iteration 31800, lr = 0.015
I0713 02:03:06.573333 45537 solver.cpp:236] Iteration 31900, loss = 1.08286
I0713 02:03:06.573470 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:03:06.573489 45537 solver.cpp:252]     Train net output #1: loss = 0.989692 (* 1 = 0.989692 loss)
I0713 02:03:06.573504 45537 sgd_solver.cpp:106] Iteration 31900, lr = 0.015
I0713 02:04:26.685653 45537 solver.cpp:236] Iteration 32000, loss = 1.08134
I0713 02:04:26.685767 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 02:04:26.685786 45537 solver.cpp:252]     Train net output #1: loss = 1.20546 (* 1 = 1.20546 loss)
I0713 02:04:26.685801 45537 sgd_solver.cpp:106] Iteration 32000, lr = 0.015
I0713 02:05:46.795227 45537 solver.cpp:236] Iteration 32100, loss = 1.07239
I0713 02:05:46.795373 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:05:46.795392 45537 solver.cpp:252]     Train net output #1: loss = 1.02503 (* 1 = 1.02503 loss)
I0713 02:05:46.795413 45537 sgd_solver.cpp:106] Iteration 32100, lr = 0.015
I0713 02:07:06.900718 45537 solver.cpp:236] Iteration 32200, loss = 1.06492
I0713 02:07:06.900833 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:07:06.900852 45537 solver.cpp:252]     Train net output #1: loss = 1.11286 (* 1 = 1.11286 loss)
I0713 02:07:06.900866 45537 sgd_solver.cpp:106] Iteration 32200, lr = 0.015
I0713 02:08:27.008579 45537 solver.cpp:236] Iteration 32300, loss = 1.07534
I0713 02:08:27.008709 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:08:27.008730 45537 solver.cpp:252]     Train net output #1: loss = 1.11834 (* 1 = 1.11834 loss)
I0713 02:08:27.008744 45537 sgd_solver.cpp:106] Iteration 32300, lr = 0.015
I0713 02:09:47.126032 45537 solver.cpp:236] Iteration 32400, loss = 1.06235
I0713 02:09:47.126193 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:09:47.126215 45537 solver.cpp:252]     Train net output #1: loss = 1.09383 (* 1 = 1.09383 loss)
I0713 02:09:47.126233 45537 sgd_solver.cpp:106] Iteration 32400, lr = 0.015
I0713 02:11:07.232776 45537 solver.cpp:236] Iteration 32500, loss = 1.071
I0713 02:11:07.232939 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:11:07.232957 45537 solver.cpp:252]     Train net output #1: loss = 0.970806 (* 1 = 0.970806 loss)
I0713 02:11:07.232971 45537 sgd_solver.cpp:106] Iteration 32500, lr = 0.015
I0713 02:12:27.347510 45537 solver.cpp:236] Iteration 32600, loss = 1.07584
I0713 02:12:27.347700 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:12:27.347749 45537 solver.cpp:252]     Train net output #1: loss = 0.958703 (* 1 = 0.958703 loss)
I0713 02:12:27.347772 45537 sgd_solver.cpp:106] Iteration 32600, lr = 0.015
I0713 02:13:47.448465 45537 solver.cpp:236] Iteration 32700, loss = 1.05986
I0713 02:13:47.448626 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:13:47.448650 45537 solver.cpp:252]     Train net output #1: loss = 0.876395 (* 1 = 0.876395 loss)
I0713 02:13:47.448673 45537 sgd_solver.cpp:106] Iteration 32700, lr = 0.015
I0713 02:14:38.732656 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 02:15:07.571604 45537 solver.cpp:236] Iteration 32800, loss = 1.06011
I0713 02:15:07.571666 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 02:15:07.571684 45537 solver.cpp:252]     Train net output #1: loss = 0.984291 (* 1 = 0.984291 loss)
I0713 02:15:07.571699 45537 sgd_solver.cpp:106] Iteration 32800, lr = 0.015
I0713 02:16:27.674324 45537 solver.cpp:236] Iteration 32900, loss = 1.05691
I0713 02:16:27.674463 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:16:27.674480 45537 solver.cpp:252]     Train net output #1: loss = 0.92206 (* 1 = 0.92206 loss)
I0713 02:16:27.674495 45537 sgd_solver.cpp:106] Iteration 32900, lr = 0.015
I0713 02:17:46.982329 45537 solver.cpp:340] Iteration 33000, Testing net (#0)
I0713 02:19:03.990782 45537 solver.cpp:408]     Test net output #0: accuracy = 0.485
I0713 02:19:03.990984 45537 solver.cpp:408]     Test net output #1: loss = 1.05214 (* 1 = 1.05214 loss)
I0713 02:19:04.759665 45537 solver.cpp:236] Iteration 33000, loss = 1.07708
I0713 02:19:04.759726 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:19:04.759752 45537 solver.cpp:252]     Train net output #1: loss = 1.15766 (* 1 = 1.15766 loss)
I0713 02:19:04.759774 45537 sgd_solver.cpp:106] Iteration 33000, lr = 0.015
I0713 02:20:24.890458 45537 solver.cpp:236] Iteration 33100, loss = 1.08516
I0713 02:20:24.890597 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 02:20:24.890616 45537 solver.cpp:252]     Train net output #1: loss = 1.01187 (* 1 = 1.01187 loss)
I0713 02:20:24.890641 45537 sgd_solver.cpp:106] Iteration 33100, lr = 0.015
I0713 02:21:44.994731 45537 solver.cpp:236] Iteration 33200, loss = 1.09465
I0713 02:21:44.994892 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:21:44.994925 45537 solver.cpp:252]     Train net output #1: loss = 1.14768 (* 1 = 1.14768 loss)
I0713 02:21:44.994940 45537 sgd_solver.cpp:106] Iteration 33200, lr = 0.015
I0713 02:23:05.109499 45537 solver.cpp:236] Iteration 33300, loss = 1.05187
I0713 02:23:05.109601 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:23:05.109617 45537 solver.cpp:252]     Train net output #1: loss = 1.20717 (* 1 = 1.20717 loss)
I0713 02:23:05.109630 45537 sgd_solver.cpp:106] Iteration 33300, lr = 0.015
I0713 02:24:25.223155 45537 solver.cpp:236] Iteration 33400, loss = 1.08703
I0713 02:24:25.223280 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:24:25.223299 45537 solver.cpp:252]     Train net output #1: loss = 1.14736 (* 1 = 1.14736 loss)
I0713 02:24:25.223312 45537 sgd_solver.cpp:106] Iteration 33400, lr = 0.015
I0713 02:25:45.327113 45537 solver.cpp:236] Iteration 33500, loss = 1.07327
I0713 02:25:45.327260 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:25:45.327288 45537 solver.cpp:252]     Train net output #1: loss = 1.21531 (* 1 = 1.21531 loss)
I0713 02:25:45.327303 45537 sgd_solver.cpp:106] Iteration 33500, lr = 0.015
I0713 02:27:05.449471 45537 solver.cpp:236] Iteration 33600, loss = 1.03736
I0713 02:27:05.449654 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:27:05.449673 45537 solver.cpp:252]     Train net output #1: loss = 1.00976 (* 1 = 1.00976 loss)
I0713 02:27:05.449687 45537 sgd_solver.cpp:106] Iteration 33600, lr = 0.015
I0713 02:28:25.558666 45537 solver.cpp:236] Iteration 33700, loss = 1.06772
I0713 02:28:25.558861 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:28:25.558887 45537 solver.cpp:252]     Train net output #1: loss = 0.936224 (* 1 = 0.936224 loss)
I0713 02:28:25.558907 45537 sgd_solver.cpp:106] Iteration 33700, lr = 0.015
I0713 02:29:45.663036 45537 solver.cpp:236] Iteration 33800, loss = 1.07975
I0713 02:29:45.663164 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 02:29:45.663185 45537 solver.cpp:252]     Train net output #1: loss = 1.24305 (* 1 = 1.24305 loss)
I0713 02:29:45.663199 45537 sgd_solver.cpp:106] Iteration 33800, lr = 0.015
I0713 02:31:05.774212 45537 solver.cpp:236] Iteration 33900, loss = 1.06695
I0713 02:31:05.774348 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 02:31:05.774366 45537 solver.cpp:252]     Train net output #1: loss = 0.902757 (* 1 = 0.902757 loss)
I0713 02:31:05.774380 45537 sgd_solver.cpp:106] Iteration 33900, lr = 0.015
I0713 02:32:25.876121 45537 solver.cpp:236] Iteration 34000, loss = 1.088
I0713 02:32:25.876260 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:32:25.876279 45537 solver.cpp:252]     Train net output #1: loss = 1.03911 (* 1 = 1.03911 loss)
I0713 02:32:25.876293 45537 sgd_solver.cpp:106] Iteration 34000, lr = 0.015
I0713 02:33:45.981549 45537 solver.cpp:236] Iteration 34100, loss = 1.07751
I0713 02:33:45.981678 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 02:33:45.981698 45537 solver.cpp:252]     Train net output #1: loss = 0.972638 (* 1 = 0.972638 loss)
I0713 02:33:45.981711 45537 sgd_solver.cpp:106] Iteration 34100, lr = 0.015
I0713 02:35:06.098920 45537 solver.cpp:236] Iteration 34200, loss = 1.07526
I0713 02:35:06.099095 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:35:06.099122 45537 solver.cpp:252]     Train net output #1: loss = 1.04755 (* 1 = 1.04755 loss)
I0713 02:35:06.099136 45537 sgd_solver.cpp:106] Iteration 34200, lr = 0.015
I0713 02:36:02.160851 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 02:36:26.198567 45537 solver.cpp:236] Iteration 34300, loss = 1.07083
I0713 02:36:26.198642 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:36:26.198662 45537 solver.cpp:252]     Train net output #1: loss = 1.04338 (* 1 = 1.04338 loss)
I0713 02:36:26.198681 45537 sgd_solver.cpp:106] Iteration 34300, lr = 0.015
I0713 02:37:46.309819 45537 solver.cpp:236] Iteration 34400, loss = 1.07179
I0713 02:37:46.309954 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:37:46.309985 45537 solver.cpp:252]     Train net output #1: loss = 1.20973 (* 1 = 1.20973 loss)
I0713 02:37:46.309998 45537 sgd_solver.cpp:106] Iteration 34400, lr = 0.015
I0713 02:39:05.615211 45537 solver.cpp:340] Iteration 34500, Testing net (#0)
I0713 02:40:22.578438 45537 solver.cpp:408]     Test net output #0: accuracy = 0.46625
I0713 02:40:22.578573 45537 solver.cpp:408]     Test net output #1: loss = 1.05955 (* 1 = 1.05955 loss)
I0713 02:40:23.350522 45537 solver.cpp:236] Iteration 34500, loss = 1.06459
I0713 02:40:23.350584 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 02:40:23.350603 45537 solver.cpp:252]     Train net output #1: loss = 1.31785 (* 1 = 1.31785 loss)
I0713 02:40:23.350621 45537 sgd_solver.cpp:106] Iteration 34500, lr = 0.015
I0713 02:41:43.424995 45537 solver.cpp:236] Iteration 34600, loss = 1.06874
I0713 02:41:43.425153 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 02:41:43.425186 45537 solver.cpp:252]     Train net output #1: loss = 1.2944 (* 1 = 1.2944 loss)
I0713 02:41:43.425204 45537 sgd_solver.cpp:106] Iteration 34600, lr = 0.015
I0713 02:43:03.539871 45537 solver.cpp:236] Iteration 34700, loss = 1.0584
I0713 02:43:03.540007 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:43:03.540027 45537 solver.cpp:252]     Train net output #1: loss = 1.11434 (* 1 = 1.11434 loss)
I0713 02:43:03.540042 45537 sgd_solver.cpp:106] Iteration 34700, lr = 0.015
I0713 02:44:23.646821 45537 solver.cpp:236] Iteration 34800, loss = 1.08964
I0713 02:44:23.647050 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 02:44:23.647080 45537 solver.cpp:252]     Train net output #1: loss = 1.13179 (* 1 = 1.13179 loss)
I0713 02:44:23.647091 45537 sgd_solver.cpp:106] Iteration 34800, lr = 0.015
I0713 02:45:43.748086 45537 solver.cpp:236] Iteration 34900, loss = 1.07882
I0713 02:45:43.748239 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 02:45:43.748275 45537 solver.cpp:252]     Train net output #1: loss = 0.989872 (* 1 = 0.989872 loss)
I0713 02:45:43.748291 45537 sgd_solver.cpp:106] Iteration 34900, lr = 0.015
I0713 02:47:03.067600 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_35000.caffemodel
I0713 02:47:03.242992 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_35000.solverstate
I0713 02:47:04.020243 45537 solver.cpp:236] Iteration 35000, loss = 1.06995
I0713 02:47:04.020316 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:47:04.020334 45537 solver.cpp:252]     Train net output #1: loss = 1.04823 (* 1 = 1.04823 loss)
I0713 02:47:04.020349 45537 sgd_solver.cpp:106] Iteration 35000, lr = 0.015
I0713 02:48:24.062223 45537 solver.cpp:236] Iteration 35100, loss = 1.07741
I0713 02:48:24.062405 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:48:24.062438 45537 solver.cpp:252]     Train net output #1: loss = 1.024 (* 1 = 1.024 loss)
I0713 02:48:24.062458 45537 sgd_solver.cpp:106] Iteration 35100, lr = 0.015
I0713 02:49:44.161242 45537 solver.cpp:236] Iteration 35200, loss = 1.04612
I0713 02:49:44.161398 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:49:44.161419 45537 solver.cpp:252]     Train net output #1: loss = 1.03524 (* 1 = 1.03524 loss)
I0713 02:49:44.161437 45537 sgd_solver.cpp:106] Iteration 35200, lr = 0.015
I0713 02:51:04.279995 45537 solver.cpp:236] Iteration 35300, loss = 1.07495
I0713 02:51:04.280104 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:51:04.280123 45537 solver.cpp:252]     Train net output #1: loss = 1.05011 (* 1 = 1.05011 loss)
I0713 02:51:04.280136 45537 sgd_solver.cpp:106] Iteration 35300, lr = 0.015
I0713 02:52:24.387029 45537 solver.cpp:236] Iteration 35400, loss = 1.07739
I0713 02:52:24.387176 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:52:24.387197 45537 solver.cpp:252]     Train net output #1: loss = 1.11823 (* 1 = 1.11823 loss)
I0713 02:52:24.387212 45537 sgd_solver.cpp:106] Iteration 35400, lr = 0.015
I0713 02:53:44.494493 45537 solver.cpp:236] Iteration 35500, loss = 1.05466
I0713 02:53:44.494634 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 02:53:44.494655 45537 solver.cpp:252]     Train net output #1: loss = 0.950188 (* 1 = 0.950188 loss)
I0713 02:53:44.494671 45537 sgd_solver.cpp:106] Iteration 35500, lr = 0.015
I0713 02:55:04.593659 45537 solver.cpp:236] Iteration 35600, loss = 1.07999
I0713 02:55:04.593791 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 02:55:04.593822 45537 solver.cpp:252]     Train net output #1: loss = 1.06684 (* 1 = 1.06684 loss)
I0713 02:55:04.593834 45537 sgd_solver.cpp:106] Iteration 35600, lr = 0.015
I0713 02:56:24.706970 45537 solver.cpp:236] Iteration 35700, loss = 1.08342
I0713 02:56:24.707149 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:56:24.707177 45537 solver.cpp:252]     Train net output #1: loss = 1.05597 (* 1 = 1.05597 loss)
I0713 02:56:24.707195 45537 sgd_solver.cpp:106] Iteration 35700, lr = 0.015
I0713 02:56:57.565594 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 02:57:44.819530 45537 solver.cpp:236] Iteration 35800, loss = 1.07397
I0713 02:57:44.819737 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:57:44.819769 45537 solver.cpp:252]     Train net output #1: loss = 1.06864 (* 1 = 1.06864 loss)
I0713 02:57:44.819780 45537 sgd_solver.cpp:106] Iteration 35800, lr = 0.015
I0713 02:59:04.921183 45537 solver.cpp:236] Iteration 35900, loss = 1.08099
I0713 02:59:04.921341 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 02:59:04.921380 45537 solver.cpp:252]     Train net output #1: loss = 1.05339 (* 1 = 1.05339 loss)
I0713 02:59:04.921393 45537 sgd_solver.cpp:106] Iteration 35900, lr = 0.015
I0713 03:00:24.239961 45537 solver.cpp:340] Iteration 36000, Testing net (#0)
I0713 03:01:41.162011 45537 solver.cpp:408]     Test net output #0: accuracy = 0.43875
I0713 03:01:41.162117 45537 solver.cpp:408]     Test net output #1: loss = 1.07363 (* 1 = 1.07363 loss)
I0713 03:01:41.924587 45537 solver.cpp:236] Iteration 36000, loss = 1.0657
I0713 03:01:41.924641 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 03:01:41.924659 45537 solver.cpp:252]     Train net output #1: loss = 0.970571 (* 1 = 0.970571 loss)
I0713 03:01:41.924675 45537 sgd_solver.cpp:106] Iteration 36000, lr = 0.015
I0713 03:03:02.039633 45537 solver.cpp:236] Iteration 36100, loss = 1.0529
I0713 03:03:02.039763 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:03:02.039782 45537 solver.cpp:252]     Train net output #1: loss = 1.17737 (* 1 = 1.17737 loss)
I0713 03:03:02.039795 45537 sgd_solver.cpp:106] Iteration 36100, lr = 0.015
I0713 03:04:22.146407 45537 solver.cpp:236] Iteration 36200, loss = 1.07748
I0713 03:04:22.146553 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 03:04:22.146584 45537 solver.cpp:252]     Train net output #1: loss = 1.15912 (* 1 = 1.15912 loss)
I0713 03:04:22.146596 45537 sgd_solver.cpp:106] Iteration 36200, lr = 0.015
I0713 03:05:42.267671 45537 solver.cpp:236] Iteration 36300, loss = 1.06645
I0713 03:05:42.267814 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:05:42.267845 45537 solver.cpp:252]     Train net output #1: loss = 1.20088 (* 1 = 1.20088 loss)
I0713 03:05:42.267860 45537 sgd_solver.cpp:106] Iteration 36300, lr = 0.015
I0713 03:07:02.365991 45537 solver.cpp:236] Iteration 36400, loss = 1.06951
I0713 03:07:02.366142 45537 solver.cpp:252]     Train net output #0: accuracy = 0
I0713 03:07:02.366161 45537 solver.cpp:252]     Train net output #1: loss = 1.11164 (* 1 = 1.11164 loss)
I0713 03:07:02.366183 45537 sgd_solver.cpp:106] Iteration 36400, lr = 0.015
I0713 03:08:22.485016 45537 solver.cpp:236] Iteration 36500, loss = 1.0795
I0713 03:08:22.485162 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:08:22.485185 45537 solver.cpp:252]     Train net output #1: loss = 1.12678 (* 1 = 1.12678 loss)
I0713 03:08:22.485205 45537 sgd_solver.cpp:106] Iteration 36500, lr = 0.015
I0713 03:09:42.591433 45537 solver.cpp:236] Iteration 36600, loss = 1.0573
I0713 03:09:42.591558 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 03:09:42.591579 45537 solver.cpp:252]     Train net output #1: loss = 1.19849 (* 1 = 1.19849 loss)
I0713 03:09:42.591599 45537 sgd_solver.cpp:106] Iteration 36600, lr = 0.015
I0713 03:11:02.691701 45537 solver.cpp:236] Iteration 36700, loss = 1.0691
I0713 03:11:02.691866 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:11:02.691887 45537 solver.cpp:252]     Train net output #1: loss = 1.11285 (* 1 = 1.11285 loss)
I0713 03:11:02.691900 45537 sgd_solver.cpp:106] Iteration 36700, lr = 0.015
I0713 03:12:22.802285 45537 solver.cpp:236] Iteration 36800, loss = 1.08412
I0713 03:12:22.802425 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:12:22.802456 45537 solver.cpp:252]     Train net output #1: loss = 1.00144 (* 1 = 1.00144 loss)
I0713 03:12:22.802469 45537 sgd_solver.cpp:106] Iteration 36800, lr = 0.015
I0713 03:13:03.656913 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 03:13:43.012192 45537 solver.cpp:236] Iteration 36900, loss = 1.09319
I0713 03:13:43.012348 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:13:43.012390 45537 solver.cpp:252]     Train net output #1: loss = 1.06042 (* 1 = 1.06042 loss)
I0713 03:13:43.012428 45537 sgd_solver.cpp:106] Iteration 36900, lr = 0.015
I0713 03:15:03.131253 45537 solver.cpp:236] Iteration 37000, loss = 1.06132
I0713 03:15:03.131518 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 03:15:03.131539 45537 solver.cpp:252]     Train net output #1: loss = 0.902868 (* 1 = 0.902868 loss)
I0713 03:15:03.131556 45537 sgd_solver.cpp:106] Iteration 37000, lr = 0.015
I0713 03:16:23.231088 45537 solver.cpp:236] Iteration 37100, loss = 1.06263
I0713 03:16:23.231199 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 03:16:23.231218 45537 solver.cpp:252]     Train net output #1: loss = 0.879347 (* 1 = 0.879347 loss)
I0713 03:16:23.231231 45537 sgd_solver.cpp:106] Iteration 37100, lr = 0.015
I0713 03:17:43.337431 45537 solver.cpp:236] Iteration 37200, loss = 1.07195
I0713 03:17:43.337566 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 03:17:43.337585 45537 solver.cpp:252]     Train net output #1: loss = 0.985589 (* 1 = 0.985589 loss)
I0713 03:17:43.337599 45537 sgd_solver.cpp:106] Iteration 37200, lr = 0.015
I0713 03:19:03.442384 45537 solver.cpp:236] Iteration 37300, loss = 1.08752
I0713 03:19:03.442530 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:19:03.442548 45537 solver.cpp:252]     Train net output #1: loss = 1.08434 (* 1 = 1.08434 loss)
I0713 03:19:03.442562 45537 sgd_solver.cpp:106] Iteration 37300, lr = 0.015
I0713 03:20:23.550431 45537 solver.cpp:236] Iteration 37400, loss = 1.08942
I0713 03:20:23.550565 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:20:23.550586 45537 solver.cpp:252]     Train net output #1: loss = 1.08829 (* 1 = 1.08829 loss)
I0713 03:20:23.550607 45537 sgd_solver.cpp:106] Iteration 37400, lr = 0.015
I0713 03:21:44.255055 45537 solver.cpp:340] Iteration 37500, Testing net (#0)
I0713 03:23:01.246661 45537 solver.cpp:408]     Test net output #0: accuracy = 0.49625
I0713 03:23:01.246863 45537 solver.cpp:408]     Test net output #1: loss = 1.05681 (* 1 = 1.05681 loss)
I0713 03:23:02.022675 45537 solver.cpp:236] Iteration 37500, loss = 1.05297
I0713 03:23:02.022739 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:23:02.022769 45537 solver.cpp:252]     Train net output #1: loss = 1.24495 (* 1 = 1.24495 loss)
I0713 03:23:02.022785 45537 sgd_solver.cpp:106] Iteration 37500, lr = 0.015
I0713 03:24:22.070343 45537 solver.cpp:236] Iteration 37600, loss = 1.07907
I0713 03:24:22.070474 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:24:22.070494 45537 solver.cpp:252]     Train net output #1: loss = 1.04702 (* 1 = 1.04702 loss)
I0713 03:24:22.070509 45537 sgd_solver.cpp:106] Iteration 37600, lr = 0.015
I0713 03:25:42.180660 45537 solver.cpp:236] Iteration 37700, loss = 1.07303
I0713 03:25:42.180804 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 03:25:42.180824 45537 solver.cpp:252]     Train net output #1: loss = 1.17524 (* 1 = 1.17524 loss)
I0713 03:25:42.180837 45537 sgd_solver.cpp:106] Iteration 37700, lr = 0.015
I0713 03:27:02.289978 45537 solver.cpp:236] Iteration 37800, loss = 1.08191
I0713 03:27:02.290101 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 03:27:02.290119 45537 solver.cpp:252]     Train net output #1: loss = 0.950775 (* 1 = 0.950775 loss)
I0713 03:27:02.290132 45537 sgd_solver.cpp:106] Iteration 37800, lr = 0.015
I0713 03:28:22.403089 45537 solver.cpp:236] Iteration 37900, loss = 1.05245
I0713 03:28:22.403262 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:28:22.403295 45537 solver.cpp:252]     Train net output #1: loss = 1.13811 (* 1 = 1.13811 loss)
I0713 03:28:22.403311 45537 sgd_solver.cpp:106] Iteration 37900, lr = 0.015
I0713 03:29:42.513828 45537 solver.cpp:236] Iteration 38000, loss = 1.08994
I0713 03:29:42.513990 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:29:42.514014 45537 solver.cpp:252]     Train net output #1: loss = 1.05946 (* 1 = 1.05946 loss)
I0713 03:29:42.514031 45537 sgd_solver.cpp:106] Iteration 38000, lr = 0.015
I0713 03:31:02.633528 45537 solver.cpp:236] Iteration 38100, loss = 1.07453
I0713 03:31:02.633724 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:31:02.633750 45537 solver.cpp:252]     Train net output #1: loss = 1.13285 (* 1 = 1.13285 loss)
I0713 03:31:02.633766 45537 sgd_solver.cpp:106] Iteration 38100, lr = 0.015
I0713 03:32:22.739588 45537 solver.cpp:236] Iteration 38200, loss = 1.06978
I0713 03:32:22.739706 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:32:22.739725 45537 solver.cpp:252]     Train net output #1: loss = 1.02753 (* 1 = 1.02753 loss)
I0713 03:32:22.739738 45537 sgd_solver.cpp:106] Iteration 38200, lr = 0.015
I0713 03:33:42.851177 45537 solver.cpp:236] Iteration 38300, loss = 1.05579
I0713 03:33:42.851332 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 03:33:42.851351 45537 solver.cpp:252]     Train net output #1: loss = 0.963967 (* 1 = 0.963967 loss)
I0713 03:33:42.851372 45537 sgd_solver.cpp:106] Iteration 38300, lr = 0.015
I0713 03:35:02.960117 45537 solver.cpp:236] Iteration 38400, loss = 1.06324
I0713 03:35:02.960294 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:35:02.960314 45537 solver.cpp:252]     Train net output #1: loss = 1.09783 (* 1 = 1.09783 loss)
I0713 03:35:02.960330 45537 sgd_solver.cpp:106] Iteration 38400, lr = 0.015
I0713 03:36:23.060271 45537 solver.cpp:236] Iteration 38500, loss = 1.07118
I0713 03:36:23.060448 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:36:23.060470 45537 solver.cpp:252]     Train net output #1: loss = 1.08278 (* 1 = 1.08278 loss)
I0713 03:36:23.060487 45537 sgd_solver.cpp:106] Iteration 38500, lr = 0.015
I0713 03:37:43.157260 45537 solver.cpp:236] Iteration 38600, loss = 1.08433
I0713 03:37:43.157392 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:37:43.157423 45537 solver.cpp:252]     Train net output #1: loss = 1.08479 (* 1 = 1.08479 loss)
I0713 03:37:43.157438 45537 sgd_solver.cpp:106] Iteration 38600, lr = 0.015
I0713 03:38:19.207121 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 03:39:03.271703 45537 solver.cpp:236] Iteration 38700, loss = 1.07834
I0713 03:39:03.271808 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:39:03.271826 45537 solver.cpp:252]     Train net output #1: loss = 1.02717 (* 1 = 1.02717 loss)
I0713 03:39:03.271841 45537 sgd_solver.cpp:106] Iteration 38700, lr = 0.015
I0713 03:40:23.382203 45537 solver.cpp:236] Iteration 38800, loss = 1.07055
I0713 03:40:23.382345 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 03:40:23.382366 45537 solver.cpp:252]     Train net output #1: loss = 1.1584 (* 1 = 1.1584 loss)
I0713 03:40:23.382385 45537 sgd_solver.cpp:106] Iteration 38800, lr = 0.015
I0713 03:41:43.487440 45537 solver.cpp:236] Iteration 38900, loss = 1.05881
I0713 03:41:43.487596 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 03:41:43.487639 45537 solver.cpp:252]     Train net output #1: loss = 0.877515 (* 1 = 0.877515 loss)
I0713 03:41:43.487658 45537 sgd_solver.cpp:106] Iteration 38900, lr = 0.015
I0713 03:43:02.786746 45537 solver.cpp:340] Iteration 39000, Testing net (#0)
I0713 03:44:20.433018 45537 solver.cpp:408]     Test net output #0: accuracy = 0.45125
I0713 03:44:20.433182 45537 solver.cpp:408]     Test net output #1: loss = 1.07621 (* 1 = 1.07621 loss)
I0713 03:44:21.196480 45537 solver.cpp:236] Iteration 39000, loss = 1.05269
I0713 03:44:21.196540 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:44:21.196565 45537 solver.cpp:252]     Train net output #1: loss = 1.13198 (* 1 = 1.13198 loss)
I0713 03:44:21.196590 45537 sgd_solver.cpp:106] Iteration 39000, lr = 0.015
I0713 03:45:41.308732 45537 solver.cpp:236] Iteration 39100, loss = 1.04834
I0713 03:45:41.308892 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:45:41.308915 45537 solver.cpp:252]     Train net output #1: loss = 0.949945 (* 1 = 0.949945 loss)
I0713 03:45:41.308929 45537 sgd_solver.cpp:106] Iteration 39100, lr = 0.015
I0713 03:47:01.418388 45537 solver.cpp:236] Iteration 39200, loss = 1.09398
I0713 03:47:01.418598 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:47:01.418619 45537 solver.cpp:252]     Train net output #1: loss = 1.08839 (* 1 = 1.08839 loss)
I0713 03:47:01.418637 45537 sgd_solver.cpp:106] Iteration 39200, lr = 0.015
I0713 03:48:21.542500 45537 solver.cpp:236] Iteration 39300, loss = 1.08269
I0713 03:48:21.542642 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:48:21.542662 45537 solver.cpp:252]     Train net output #1: loss = 1.01882 (* 1 = 1.01882 loss)
I0713 03:48:21.542677 45537 sgd_solver.cpp:106] Iteration 39300, lr = 0.015
I0713 03:49:41.641583 45537 solver.cpp:236] Iteration 39400, loss = 1.03939
I0713 03:49:41.641727 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 03:49:41.641759 45537 solver.cpp:252]     Train net output #1: loss = 0.936108 (* 1 = 0.936108 loss)
I0713 03:49:41.641777 45537 sgd_solver.cpp:106] Iteration 39400, lr = 0.015
I0713 03:51:01.749181 45537 solver.cpp:236] Iteration 39500, loss = 1.08494
I0713 03:51:01.749337 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 03:51:01.749359 45537 solver.cpp:252]     Train net output #1: loss = 1.10455 (* 1 = 1.10455 loss)
I0713 03:51:01.749375 45537 sgd_solver.cpp:106] Iteration 39500, lr = 0.015
I0713 03:52:21.864748 45537 solver.cpp:236] Iteration 39600, loss = 1.07486
I0713 03:52:21.864892 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:52:21.864912 45537 solver.cpp:252]     Train net output #1: loss = 1.06269 (* 1 = 1.06269 loss)
I0713 03:52:21.864926 45537 sgd_solver.cpp:106] Iteration 39600, lr = 0.015
I0713 03:53:13.141722 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 03:53:41.988557 45537 solver.cpp:236] Iteration 39700, loss = 1.07771
I0713 03:53:41.988612 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 03:53:41.988627 45537 solver.cpp:252]     Train net output #1: loss = 0.917162 (* 1 = 0.917162 loss)
I0713 03:53:41.988641 45537 sgd_solver.cpp:106] Iteration 39700, lr = 0.015
I0713 03:55:02.104529 45537 solver.cpp:236] Iteration 39800, loss = 1.08545
I0713 03:55:02.104665 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 03:55:02.104696 45537 solver.cpp:252]     Train net output #1: loss = 1.16625 (* 1 = 1.16625 loss)
I0713 03:55:02.104709 45537 sgd_solver.cpp:106] Iteration 39800, lr = 0.015
I0713 03:56:22.216230 45537 solver.cpp:236] Iteration 39900, loss = 1.08973
I0713 03:56:22.216378 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:56:22.216408 45537 solver.cpp:252]     Train net output #1: loss = 1.0457 (* 1 = 1.0457 loss)
I0713 03:56:22.216423 45537 sgd_solver.cpp:106] Iteration 39900, lr = 0.015
I0713 03:57:41.525768 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_40000.caffemodel
I0713 03:57:41.940204 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_40000.solverstate
I0713 03:57:42.742545 45537 solver.cpp:236] Iteration 40000, loss = 1.08223
I0713 03:57:42.742612 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 03:57:42.742635 45537 solver.cpp:252]     Train net output #1: loss = 0.982496 (* 1 = 0.982496 loss)
I0713 03:57:42.742657 45537 sgd_solver.cpp:106] Iteration 40000, lr = 0.015
I0713 03:59:02.814312 45537 solver.cpp:236] Iteration 40100, loss = 1.07886
I0713 03:59:02.814442 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 03:59:02.814462 45537 solver.cpp:252]     Train net output #1: loss = 1.06331 (* 1 = 1.06331 loss)
I0713 03:59:02.814476 45537 sgd_solver.cpp:106] Iteration 40100, lr = 0.015
I0713 04:00:22.919735 45537 solver.cpp:236] Iteration 40200, loss = 1.09258
I0713 04:00:22.919889 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:00:22.919909 45537 solver.cpp:252]     Train net output #1: loss = 1.04208 (* 1 = 1.04208 loss)
I0713 04:00:22.919921 45537 sgd_solver.cpp:106] Iteration 40200, lr = 0.015
I0713 04:01:43.036003 45537 solver.cpp:236] Iteration 40300, loss = 1.06841
I0713 04:01:43.036238 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:01:43.036260 45537 solver.cpp:252]     Train net output #1: loss = 0.981201 (* 1 = 0.981201 loss)
I0713 04:01:43.036275 45537 sgd_solver.cpp:106] Iteration 40300, lr = 0.015
I0713 04:03:03.146205 45537 solver.cpp:236] Iteration 40400, loss = 1.07674
I0713 04:03:03.146358 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 04:03:03.146376 45537 solver.cpp:252]     Train net output #1: loss = 1.17613 (* 1 = 1.17613 loss)
I0713 04:03:03.146397 45537 sgd_solver.cpp:106] Iteration 40400, lr = 0.015
I0713 04:04:22.467751 45537 solver.cpp:340] Iteration 40500, Testing net (#0)
I0713 04:05:39.439343 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4525
I0713 04:05:39.439491 45537 solver.cpp:408]     Test net output #1: loss = 1.06644 (* 1 = 1.06644 loss)
I0713 04:05:40.213541 45537 solver.cpp:236] Iteration 40500, loss = 1.07394
I0713 04:05:40.213595 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:05:40.213615 45537 solver.cpp:252]     Train net output #1: loss = 1.02835 (* 1 = 1.02835 loss)
I0713 04:05:40.213634 45537 sgd_solver.cpp:106] Iteration 40500, lr = 0.015
I0713 04:07:00.264847 45537 solver.cpp:236] Iteration 40600, loss = 1.05631
I0713 04:07:00.264976 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:07:00.265019 45537 solver.cpp:252]     Train net output #1: loss = 1.12734 (* 1 = 1.12734 loss)
I0713 04:07:00.265035 45537 sgd_solver.cpp:106] Iteration 40600, lr = 0.015
I0713 04:08:20.370910 45537 solver.cpp:236] Iteration 40700, loss = 1.06856
I0713 04:08:20.371086 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:08:20.371114 45537 solver.cpp:252]     Train net output #1: loss = 1.13867 (* 1 = 1.13867 loss)
I0713 04:08:20.371124 45537 sgd_solver.cpp:106] Iteration 40700, lr = 0.015
I0713 04:09:15.647578 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 04:09:40.492241 45537 solver.cpp:236] Iteration 40800, loss = 1.07641
I0713 04:09:40.492312 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:09:40.492331 45537 solver.cpp:252]     Train net output #1: loss = 1.16397 (* 1 = 1.16397 loss)
I0713 04:09:40.492344 45537 sgd_solver.cpp:106] Iteration 40800, lr = 0.015
I0713 04:11:00.596045 45537 solver.cpp:236] Iteration 40900, loss = 1.0784
I0713 04:11:00.596202 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:11:00.596225 45537 solver.cpp:252]     Train net output #1: loss = 1.04958 (* 1 = 1.04958 loss)
I0713 04:11:00.596245 45537 sgd_solver.cpp:106] Iteration 40900, lr = 0.015
I0713 04:12:20.691815 45537 solver.cpp:236] Iteration 41000, loss = 1.05959
I0713 04:12:20.691934 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0713 04:12:20.691953 45537 solver.cpp:252]     Train net output #1: loss = 0.815213 (* 1 = 0.815213 loss)
I0713 04:12:20.691967 45537 sgd_solver.cpp:106] Iteration 41000, lr = 0.015
I0713 04:13:40.805073 45537 solver.cpp:236] Iteration 41100, loss = 1.08806
I0713 04:13:40.805205 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:13:40.805224 45537 solver.cpp:252]     Train net output #1: loss = 1.17391 (* 1 = 1.17391 loss)
I0713 04:13:40.805238 45537 sgd_solver.cpp:106] Iteration 41100, lr = 0.015
I0713 04:15:00.909744 45537 solver.cpp:236] Iteration 41200, loss = 1.07718
I0713 04:15:00.909895 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:15:00.909916 45537 solver.cpp:252]     Train net output #1: loss = 1.02493 (* 1 = 1.02493 loss)
I0713 04:15:00.909937 45537 sgd_solver.cpp:106] Iteration 41200, lr = 0.015
I0713 04:16:21.011359 45537 solver.cpp:236] Iteration 41300, loss = 1.05253
I0713 04:16:21.011540 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:16:21.011570 45537 solver.cpp:252]     Train net output #1: loss = 1.056 (* 1 = 1.056 loss)
I0713 04:16:21.011581 45537 sgd_solver.cpp:106] Iteration 41300, lr = 0.015
I0713 04:17:41.112179 45537 solver.cpp:236] Iteration 41400, loss = 1.07873
I0713 04:17:41.112448 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:17:41.112470 45537 solver.cpp:252]     Train net output #1: loss = 1.04884 (* 1 = 1.04884 loss)
I0713 04:17:41.112484 45537 sgd_solver.cpp:106] Iteration 41400, lr = 0.015
I0713 04:19:01.234269 45537 solver.cpp:236] Iteration 41500, loss = 1.08152
I0713 04:19:01.234446 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:19:01.234472 45537 solver.cpp:252]     Train net output #1: loss = 1.06142 (* 1 = 1.06142 loss)
I0713 04:19:01.234491 45537 sgd_solver.cpp:106] Iteration 41500, lr = 0.015
I0713 04:20:21.336508 45537 solver.cpp:236] Iteration 41600, loss = 1.07076
I0713 04:20:21.336622 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:20:21.336643 45537 solver.cpp:252]     Train net output #1: loss = 1.09749 (* 1 = 1.09749 loss)
I0713 04:20:21.336657 45537 sgd_solver.cpp:106] Iteration 41600, lr = 0.015
I0713 04:21:41.437227 45537 solver.cpp:236] Iteration 41700, loss = 1.08305
I0713 04:21:41.437360 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:21:41.437379 45537 solver.cpp:252]     Train net output #1: loss = 1.06499 (* 1 = 1.06499 loss)
I0713 04:21:41.437394 45537 sgd_solver.cpp:106] Iteration 41700, lr = 0.015
I0713 04:22:36.725244 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 04:23:01.557704 45537 solver.cpp:236] Iteration 41800, loss = 1.08863
I0713 04:23:01.557771 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:23:01.557792 45537 solver.cpp:252]     Train net output #1: loss = 1.08278 (* 1 = 1.08278 loss)
I0713 04:23:01.557808 45537 sgd_solver.cpp:106] Iteration 41800, lr = 0.015
I0713 04:24:21.671161 45537 solver.cpp:236] Iteration 41900, loss = 1.08681
I0713 04:24:21.671272 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 04:24:21.671290 45537 solver.cpp:252]     Train net output #1: loss = 1.21683 (* 1 = 1.21683 loss)
I0713 04:24:21.671303 45537 sgd_solver.cpp:106] Iteration 41900, lr = 0.015
I0713 04:25:40.974707 45537 solver.cpp:340] Iteration 42000, Testing net (#0)
I0713 04:26:58.016129 45537 solver.cpp:408]     Test net output #0: accuracy = 0.47
I0713 04:26:58.016263 45537 solver.cpp:408]     Test net output #1: loss = 1.06481 (* 1 = 1.06481 loss)
I0713 04:26:58.783393 45537 solver.cpp:236] Iteration 42000, loss = 1.08112
I0713 04:26:58.783447 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:26:58.783465 45537 solver.cpp:252]     Train net output #1: loss = 1.08995 (* 1 = 1.08995 loss)
I0713 04:26:58.783483 45537 sgd_solver.cpp:106] Iteration 42000, lr = 0.015
I0713 04:28:18.889071 45537 solver.cpp:236] Iteration 42100, loss = 1.06691
I0713 04:28:18.889230 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:28:18.889262 45537 solver.cpp:252]     Train net output #1: loss = 1.21145 (* 1 = 1.21145 loss)
I0713 04:28:18.889278 45537 sgd_solver.cpp:106] Iteration 42100, lr = 0.015
I0713 04:29:38.987435 45537 solver.cpp:236] Iteration 42200, loss = 1.07244
I0713 04:29:38.987619 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:29:38.987650 45537 solver.cpp:252]     Train net output #1: loss = 0.998383 (* 1 = 0.998383 loss)
I0713 04:29:38.987664 45537 sgd_solver.cpp:106] Iteration 42200, lr = 0.015
I0713 04:30:59.107460 45537 solver.cpp:236] Iteration 42300, loss = 1.0673
I0713 04:30:59.107583 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:30:59.107600 45537 solver.cpp:252]     Train net output #1: loss = 1.09871 (* 1 = 1.09871 loss)
I0713 04:30:59.107627 45537 sgd_solver.cpp:106] Iteration 42300, lr = 0.015
I0713 04:32:19.209522 45537 solver.cpp:236] Iteration 42400, loss = 1.06531
I0713 04:32:19.209676 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 04:32:19.209697 45537 solver.cpp:252]     Train net output #1: loss = 0.895943 (* 1 = 0.895943 loss)
I0713 04:32:19.209713 45537 sgd_solver.cpp:106] Iteration 42400, lr = 0.015
I0713 04:33:39.313340 45537 solver.cpp:236] Iteration 42500, loss = 1.07104
I0713 04:33:39.313524 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:33:39.313544 45537 solver.cpp:252]     Train net output #1: loss = 1.17 (* 1 = 1.17 loss)
I0713 04:33:39.313557 45537 sgd_solver.cpp:106] Iteration 42500, lr = 0.015
I0713 04:34:59.426290 45537 solver.cpp:236] Iteration 42600, loss = 1.08083
I0713 04:34:59.426442 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:34:59.426465 45537 solver.cpp:252]     Train net output #1: loss = 1.12727 (* 1 = 1.12727 loss)
I0713 04:34:59.426479 45537 sgd_solver.cpp:106] Iteration 42600, lr = 0.015
I0713 04:36:19.525017 45537 solver.cpp:236] Iteration 42700, loss = 1.08012
I0713 04:36:19.525192 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:36:19.525212 45537 solver.cpp:252]     Train net output #1: loss = 1.0466 (* 1 = 1.0466 loss)
I0713 04:36:19.525226 45537 sgd_solver.cpp:106] Iteration 42700, lr = 0.015
I0713 04:37:39.635313 45537 solver.cpp:236] Iteration 42800, loss = 1.08445
I0713 04:37:39.635414 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:37:39.635432 45537 solver.cpp:252]     Train net output #1: loss = 1.16862 (* 1 = 1.16862 loss)
I0713 04:37:39.635444 45537 sgd_solver.cpp:106] Iteration 42800, lr = 0.015
I0713 04:38:59.740785 45537 solver.cpp:236] Iteration 42900, loss = 1.06347
I0713 04:38:59.740918 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 04:38:59.740937 45537 solver.cpp:252]     Train net output #1: loss = 1.16511 (* 1 = 1.16511 loss)
I0713 04:38:59.740952 45537 sgd_solver.cpp:106] Iteration 42900, lr = 0.015
I0713 04:40:19.857100 45537 solver.cpp:236] Iteration 43000, loss = 1.06919
I0713 04:40:19.857257 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 04:40:19.857288 45537 solver.cpp:252]     Train net output #1: loss = 0.948009 (* 1 = 0.948009 loss)
I0713 04:40:19.857307 45537 sgd_solver.cpp:106] Iteration 43000, lr = 0.015
I0713 04:41:22.334080 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 04:41:39.962857 45537 solver.cpp:236] Iteration 43100, loss = 1.05917
I0713 04:41:39.962913 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:41:39.962930 45537 solver.cpp:252]     Train net output #1: loss = 1.08103 (* 1 = 1.08103 loss)
I0713 04:41:39.962944 45537 sgd_solver.cpp:106] Iteration 43100, lr = 0.015
I0713 04:43:00.071036 45537 solver.cpp:236] Iteration 43200, loss = 1.07227
I0713 04:43:00.071219 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:43:00.071240 45537 solver.cpp:252]     Train net output #1: loss = 1.03406 (* 1 = 1.03406 loss)
I0713 04:43:00.071259 45537 sgd_solver.cpp:106] Iteration 43200, lr = 0.015
I0713 04:44:20.175370 45537 solver.cpp:236] Iteration 43300, loss = 1.07252
I0713 04:44:20.175504 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:44:20.175523 45537 solver.cpp:252]     Train net output #1: loss = 1.01894 (* 1 = 1.01894 loss)
I0713 04:44:20.175534 45537 sgd_solver.cpp:106] Iteration 43300, lr = 0.015
I0713 04:45:40.294710 45537 solver.cpp:236] Iteration 43400, loss = 1.08664
I0713 04:45:40.294879 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:45:40.294901 45537 solver.cpp:252]     Train net output #1: loss = 1.06166 (* 1 = 1.06166 loss)
I0713 04:45:40.294919 45537 sgd_solver.cpp:106] Iteration 43400, lr = 0.015
I0713 04:46:59.587541 45537 solver.cpp:340] Iteration 43500, Testing net (#0)
I0713 04:48:16.567030 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4325
I0713 04:48:16.567235 45537 solver.cpp:408]     Test net output #1: loss = 1.09254 (* 1 = 1.09254 loss)
I0713 04:48:17.341121 45537 solver.cpp:236] Iteration 43500, loss = 1.05575
I0713 04:48:17.341183 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 04:48:17.341203 45537 solver.cpp:252]     Train net output #1: loss = 0.904525 (* 1 = 0.904525 loss)
I0713 04:48:17.341222 45537 sgd_solver.cpp:106] Iteration 43500, lr = 0.015
I0713 04:49:37.411593 45537 solver.cpp:236] Iteration 43600, loss = 1.07665
I0713 04:49:37.411754 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 04:49:37.411775 45537 solver.cpp:252]     Train net output #1: loss = 1.1235 (* 1 = 1.1235 loss)
I0713 04:49:37.411789 45537 sgd_solver.cpp:106] Iteration 43600, lr = 0.015
I0713 04:50:57.515321 45537 solver.cpp:236] Iteration 43700, loss = 1.06776
I0713 04:50:57.515460 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:50:57.515494 45537 solver.cpp:252]     Train net output #1: loss = 1.00664 (* 1 = 1.00664 loss)
I0713 04:50:57.515513 45537 sgd_solver.cpp:106] Iteration 43700, lr = 0.015
I0713 04:52:17.638507 45537 solver.cpp:236] Iteration 43800, loss = 1.08763
I0713 04:52:17.638689 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 04:52:17.638710 45537 solver.cpp:252]     Train net output #1: loss = 1.02208 (* 1 = 1.02208 loss)
I0713 04:52:17.638739 45537 sgd_solver.cpp:106] Iteration 43800, lr = 0.015
I0713 04:53:37.737570 45537 solver.cpp:236] Iteration 43900, loss = 1.05697
I0713 04:53:37.737725 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:53:37.737756 45537 solver.cpp:252]     Train net output #1: loss = 1.07845 (* 1 = 1.07845 loss)
I0713 04:53:37.737771 45537 sgd_solver.cpp:106] Iteration 43900, lr = 0.015
I0713 04:54:57.847060 45537 solver.cpp:236] Iteration 44000, loss = 1.08431
I0713 04:54:57.847178 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0713 04:54:57.847199 45537 solver.cpp:252]     Train net output #1: loss = 0.907341 (* 1 = 0.907341 loss)
I0713 04:54:57.847216 45537 sgd_solver.cpp:106] Iteration 44000, lr = 0.015
I0713 04:56:17.963378 45537 solver.cpp:236] Iteration 44100, loss = 1.07242
I0713 04:56:17.963510 45537 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0713 04:56:17.963529 45537 solver.cpp:252]     Train net output #1: loss = 0.903151 (* 1 = 0.903151 loss)
I0713 04:56:17.963544 45537 sgd_solver.cpp:106] Iteration 44100, lr = 0.015
I0713 04:56:34.774821 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 04:57:38.067474 45537 solver.cpp:236] Iteration 44200, loss = 1.03894
I0713 04:57:38.067590 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:57:38.067610 45537 solver.cpp:252]     Train net output #1: loss = 0.909579 (* 1 = 0.909579 loss)
I0713 04:57:38.067625 45537 sgd_solver.cpp:106] Iteration 44200, lr = 0.015
I0713 04:58:58.170979 45537 solver.cpp:236] Iteration 44300, loss = 1.06211
I0713 04:58:58.171113 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 04:58:58.171144 45537 solver.cpp:252]     Train net output #1: loss = 0.966724 (* 1 = 0.966724 loss)
I0713 04:58:58.171159 45537 sgd_solver.cpp:106] Iteration 44300, lr = 0.015
I0713 05:00:18.279486 45537 solver.cpp:236] Iteration 44400, loss = 1.08053
I0713 05:00:18.279655 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 05:00:18.279692 45537 solver.cpp:252]     Train net output #1: loss = 1.1318 (* 1 = 1.1318 loss)
I0713 05:00:18.279707 45537 sgd_solver.cpp:106] Iteration 44400, lr = 0.015
I0713 05:01:38.398154 45537 solver.cpp:236] Iteration 44500, loss = 1.04434
I0713 05:01:38.398310 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:01:38.398335 45537 solver.cpp:252]     Train net output #1: loss = 1.0443 (* 1 = 1.0443 loss)
I0713 05:01:38.398356 45537 sgd_solver.cpp:106] Iteration 44500, lr = 0.015
I0713 05:02:58.503765 45537 solver.cpp:236] Iteration 44600, loss = 1.09196
I0713 05:02:58.503876 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 05:02:58.503895 45537 solver.cpp:252]     Train net output #1: loss = 1.17686 (* 1 = 1.17686 loss)
I0713 05:02:58.503908 45537 sgd_solver.cpp:106] Iteration 44600, lr = 0.015
I0713 05:04:18.598479 45537 solver.cpp:236] Iteration 44700, loss = 1.07314
I0713 05:04:18.598649 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:04:18.598680 45537 solver.cpp:252]     Train net output #1: loss = 1.00464 (* 1 = 1.00464 loss)
I0713 05:04:18.598695 45537 sgd_solver.cpp:106] Iteration 44700, lr = 0.015
I0713 05:05:38.717418 45537 solver.cpp:236] Iteration 44800, loss = 1.07797
I0713 05:05:38.717677 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 05:05:38.717697 45537 solver.cpp:252]     Train net output #1: loss = 1.24105 (* 1 = 1.24105 loss)
I0713 05:05:38.717712 45537 sgd_solver.cpp:106] Iteration 44800, lr = 0.015
I0713 05:06:58.821708 45537 solver.cpp:236] Iteration 44900, loss = 1.09372
I0713 05:06:58.821815 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:06:58.821833 45537 solver.cpp:252]     Train net output #1: loss = 1.05993 (* 1 = 1.05993 loss)
I0713 05:06:58.821846 45537 sgd_solver.cpp:106] Iteration 44900, lr = 0.015
I0713 05:08:18.134896 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_45000.caffemodel
I0713 05:08:18.362769 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_45000.solverstate
I0713 05:08:18.401736 45537 solver.cpp:340] Iteration 45000, Testing net (#0)
I0713 05:09:35.278633 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4725
I0713 05:09:35.278831 45537 solver.cpp:408]     Test net output #1: loss = 1.05273 (* 1 = 1.05273 loss)
I0713 05:09:36.044749 45537 solver.cpp:236] Iteration 45000, loss = 1.05637
I0713 05:09:36.044818 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 05:09:36.044841 45537 solver.cpp:252]     Train net output #1: loss = 1.23251 (* 1 = 1.23251 loss)
I0713 05:09:36.044857 45537 sgd_solver.cpp:106] Iteration 45000, lr = 0.015
I0713 05:10:56.143401 45537 solver.cpp:236] Iteration 45100, loss = 1.07389
I0713 05:10:56.143532 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:10:56.143565 45537 solver.cpp:252]     Train net output #1: loss = 1.06502 (* 1 = 1.06502 loss)
I0713 05:10:56.143579 45537 sgd_solver.cpp:106] Iteration 45100, lr = 0.015
I0713 05:12:01.816071 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 05:12:16.243489 45537 solver.cpp:236] Iteration 45200, loss = 1.07849
I0713 05:12:16.243547 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:12:16.243566 45537 solver.cpp:252]     Train net output #1: loss = 1.00255 (* 1 = 1.00255 loss)
I0713 05:12:16.243579 45537 sgd_solver.cpp:106] Iteration 45200, lr = 0.015
I0713 05:13:36.354406 45537 solver.cpp:236] Iteration 45300, loss = 1.06379
I0713 05:13:36.354580 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:13:36.354604 45537 solver.cpp:252]     Train net output #1: loss = 0.951384 (* 1 = 0.951384 loss)
I0713 05:13:36.354624 45537 sgd_solver.cpp:106] Iteration 45300, lr = 0.015
I0713 05:14:56.460264 45537 solver.cpp:236] Iteration 45400, loss = 1.04423
I0713 05:14:56.460408 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:14:56.460440 45537 solver.cpp:252]     Train net output #1: loss = 1.29827 (* 1 = 1.29827 loss)
I0713 05:14:56.460455 45537 sgd_solver.cpp:106] Iteration 45400, lr = 0.015
I0713 05:16:16.565592 45537 solver.cpp:236] Iteration 45500, loss = 1.06576
I0713 05:16:16.565733 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:16:16.565753 45537 solver.cpp:252]     Train net output #1: loss = 1.09638 (* 1 = 1.09638 loss)
I0713 05:16:16.565768 45537 sgd_solver.cpp:106] Iteration 45500, lr = 0.015
I0713 05:17:36.673998 45537 solver.cpp:236] Iteration 45600, loss = 1.05449
I0713 05:17:36.674151 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:17:36.674187 45537 solver.cpp:252]     Train net output #1: loss = 1.15265 (* 1 = 1.15265 loss)
I0713 05:17:36.674202 45537 sgd_solver.cpp:106] Iteration 45600, lr = 0.015
I0713 05:18:56.779722 45537 solver.cpp:236] Iteration 45700, loss = 1.05324
I0713 05:18:56.779839 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:18:56.779856 45537 solver.cpp:252]     Train net output #1: loss = 1.09628 (* 1 = 1.09628 loss)
I0713 05:18:56.779870 45537 sgd_solver.cpp:106] Iteration 45700, lr = 0.015
I0713 05:20:16.885033 45537 solver.cpp:236] Iteration 45800, loss = 1.08078
I0713 05:20:16.885198 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 05:20:16.885231 45537 solver.cpp:252]     Train net output #1: loss = 1.21043 (* 1 = 1.21043 loss)
I0713 05:20:16.885242 45537 sgd_solver.cpp:106] Iteration 45800, lr = 0.015
I0713 05:21:36.993136 45537 solver.cpp:236] Iteration 45900, loss = 1.07733
I0713 05:21:36.993300 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:21:36.993320 45537 solver.cpp:252]     Train net output #1: loss = 0.942988 (* 1 = 0.942988 loss)
I0713 05:21:36.993335 45537 sgd_solver.cpp:106] Iteration 45900, lr = 0.015
I0713 05:22:57.107257 45537 solver.cpp:236] Iteration 46000, loss = 1.06046
I0713 05:22:57.107399 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:22:57.107426 45537 solver.cpp:252]     Train net output #1: loss = 1.15214 (* 1 = 1.15214 loss)
I0713 05:22:57.107442 45537 sgd_solver.cpp:106] Iteration 46000, lr = 0.015
I0713 05:24:17.208183 45537 solver.cpp:236] Iteration 46100, loss = 1.07901
I0713 05:24:17.208298 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 05:24:17.208319 45537 solver.cpp:252]     Train net output #1: loss = 1.1854 (* 1 = 1.1854 loss)
I0713 05:24:17.208333 45537 sgd_solver.cpp:106] Iteration 46100, lr = 0.015
I0713 05:25:22.897598 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 05:25:37.307190 45537 solver.cpp:236] Iteration 46200, loss = 1.06036
I0713 05:25:37.307253 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:25:37.307271 45537 solver.cpp:252]     Train net output #1: loss = 1.05232 (* 1 = 1.05232 loss)
I0713 05:25:37.307291 45537 sgd_solver.cpp:106] Iteration 46200, lr = 0.015
I0713 05:26:57.420753 45537 solver.cpp:236] Iteration 46300, loss = 1.0454
I0713 05:26:57.420929 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:26:57.420966 45537 solver.cpp:252]     Train net output #1: loss = 1.10766 (* 1 = 1.10766 loss)
I0713 05:26:57.420981 45537 sgd_solver.cpp:106] Iteration 46300, lr = 0.015
I0713 05:28:17.530627 45537 solver.cpp:236] Iteration 46400, loss = 1.07395
I0713 05:28:17.530778 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 05:28:17.530807 45537 solver.cpp:252]     Train net output #1: loss = 1.20247 (* 1 = 1.20247 loss)
I0713 05:28:17.530820 45537 sgd_solver.cpp:106] Iteration 46400, lr = 0.015
I0713 05:29:36.834342 45537 solver.cpp:340] Iteration 46500, Testing net (#0)
I0713 05:30:54.001202 45537 solver.cpp:408]     Test net output #0: accuracy = 0.44375
I0713 05:30:54.001323 45537 solver.cpp:408]     Test net output #1: loss = 1.07725 (* 1 = 1.07725 loss)
I0713 05:30:54.768867 45537 solver.cpp:236] Iteration 46500, loss = 1.08391
I0713 05:30:54.768919 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:30:54.768937 45537 solver.cpp:252]     Train net output #1: loss = 1.02213 (* 1 = 1.02213 loss)
I0713 05:30:54.768954 45537 sgd_solver.cpp:106] Iteration 46500, lr = 0.015
I0713 05:32:14.859906 45537 solver.cpp:236] Iteration 46600, loss = 1.0496
I0713 05:32:14.860055 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:32:14.860074 45537 solver.cpp:252]     Train net output #1: loss = 1.20319 (* 1 = 1.20319 loss)
I0713 05:32:14.860090 45537 sgd_solver.cpp:106] Iteration 46600, lr = 0.015
I0713 05:33:34.958571 45537 solver.cpp:236] Iteration 46700, loss = 1.07627
I0713 05:33:34.958736 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 05:33:34.958755 45537 solver.cpp:252]     Train net output #1: loss = 1.1288 (* 1 = 1.1288 loss)
I0713 05:33:34.958768 45537 sgd_solver.cpp:106] Iteration 46700, lr = 0.015
I0713 05:34:55.077337 45537 solver.cpp:236] Iteration 46800, loss = 1.08185
I0713 05:34:55.077494 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 05:34:55.077514 45537 solver.cpp:252]     Train net output #1: loss = 0.912914 (* 1 = 0.912914 loss)
I0713 05:34:55.077529 45537 sgd_solver.cpp:106] Iteration 46800, lr = 0.015
I0713 05:36:15.171141 45537 solver.cpp:236] Iteration 46900, loss = 1.07482
I0713 05:36:15.171375 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:36:15.171397 45537 solver.cpp:252]     Train net output #1: loss = 1.04873 (* 1 = 1.04873 loss)
I0713 05:36:15.171416 45537 sgd_solver.cpp:106] Iteration 46900, lr = 0.015
I0713 05:37:35.279156 45537 solver.cpp:236] Iteration 47000, loss = 1.08038
I0713 05:37:35.279275 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:37:35.279294 45537 solver.cpp:252]     Train net output #1: loss = 1.11378 (* 1 = 1.11378 loss)
I0713 05:37:35.279307 45537 sgd_solver.cpp:106] Iteration 47000, lr = 0.015
I0713 05:38:55.397399 45537 solver.cpp:236] Iteration 47100, loss = 1.07017
I0713 05:38:55.397562 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:38:55.397583 45537 solver.cpp:252]     Train net output #1: loss = 1.13078 (* 1 = 1.13078 loss)
I0713 05:38:55.397596 45537 sgd_solver.cpp:106] Iteration 47100, lr = 0.015
I0713 05:40:15.500669 45537 solver.cpp:236] Iteration 47200, loss = 1.07358
I0713 05:40:15.500793 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:40:15.500810 45537 solver.cpp:252]     Train net output #1: loss = 1.03297 (* 1 = 1.03297 loss)
I0713 05:40:15.500824 45537 sgd_solver.cpp:106] Iteration 47200, lr = 0.015
I0713 05:41:35.608832 45537 solver.cpp:236] Iteration 47300, loss = 1.07915
I0713 05:41:35.608999 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:41:35.609022 45537 solver.cpp:252]     Train net output #1: loss = 1.01733 (* 1 = 1.01733 loss)
I0713 05:41:35.609041 45537 sgd_solver.cpp:106] Iteration 47300, lr = 0.015
I0713 05:42:10.858923 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 05:42:55.714727 45537 solver.cpp:236] Iteration 47400, loss = 1.05574
I0713 05:42:55.714931 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:42:55.714949 45537 solver.cpp:252]     Train net output #1: loss = 1.05481 (* 1 = 1.05481 loss)
I0713 05:42:55.714965 45537 sgd_solver.cpp:106] Iteration 47400, lr = 0.015
I0713 05:44:15.836720 45537 solver.cpp:236] Iteration 47500, loss = 1.04766
I0713 05:44:15.836848 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:44:15.836869 45537 solver.cpp:252]     Train net output #1: loss = 1.01075 (* 1 = 1.01075 loss)
I0713 05:44:15.836882 45537 sgd_solver.cpp:106] Iteration 47500, lr = 0.015
I0713 05:45:35.935040 45537 solver.cpp:236] Iteration 47600, loss = 1.06781
I0713 05:45:35.935184 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 05:45:35.935204 45537 solver.cpp:252]     Train net output #1: loss = 1.1314 (* 1 = 1.1314 loss)
I0713 05:45:35.935225 45537 sgd_solver.cpp:106] Iteration 47600, lr = 0.015
I0713 05:46:56.042047 45537 solver.cpp:236] Iteration 47700, loss = 1.06869
I0713 05:46:56.042201 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:46:56.042220 45537 solver.cpp:252]     Train net output #1: loss = 1.16369 (* 1 = 1.16369 loss)
I0713 05:46:56.042234 45537 sgd_solver.cpp:106] Iteration 47700, lr = 0.015
I0713 05:48:16.157173 45537 solver.cpp:236] Iteration 47800, loss = 1.07034
I0713 05:48:16.157330 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:48:16.157349 45537 solver.cpp:252]     Train net output #1: loss = 1.15048 (* 1 = 1.15048 loss)
I0713 05:48:16.157363 45537 sgd_solver.cpp:106] Iteration 47800, lr = 0.015
I0713 05:49:36.279654 45537 solver.cpp:236] Iteration 47900, loss = 1.05469
I0713 05:49:36.279775 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 05:49:36.279793 45537 solver.cpp:252]     Train net output #1: loss = 1.08801 (* 1 = 1.08801 loss)
I0713 05:49:36.279808 45537 sgd_solver.cpp:106] Iteration 47900, lr = 0.015
I0713 05:50:55.588857 45537 solver.cpp:340] Iteration 48000, Testing net (#0)
I0713 05:52:12.491487 45537 solver.cpp:408]     Test net output #0: accuracy = 0.46625
I0713 05:52:12.491595 45537 solver.cpp:408]     Test net output #1: loss = 1.05805 (* 1 = 1.05805 loss)
I0713 05:52:13.259371 45537 solver.cpp:236] Iteration 48000, loss = 1.05968
I0713 05:52:13.259418 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:52:13.259434 45537 solver.cpp:252]     Train net output #1: loss = 1.00456 (* 1 = 1.00456 loss)
I0713 05:52:13.259451 45537 sgd_solver.cpp:106] Iteration 48000, lr = 0.015
I0713 05:53:33.392329 45537 solver.cpp:236] Iteration 48100, loss = 1.08326
I0713 05:53:33.392446 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 05:53:33.392465 45537 solver.cpp:252]     Train net output #1: loss = 0.882506 (* 1 = 0.882506 loss)
I0713 05:53:33.392479 45537 sgd_solver.cpp:106] Iteration 48100, lr = 0.015
I0713 05:54:53.500223 45537 solver.cpp:236] Iteration 48200, loss = 1.07
I0713 05:54:53.500385 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 05:54:53.500417 45537 solver.cpp:252]     Train net output #1: loss = 1.27921 (* 1 = 1.27921 loss)
I0713 05:54:53.500432 45537 sgd_solver.cpp:106] Iteration 48200, lr = 0.015
I0713 05:56:13.607163 45537 solver.cpp:236] Iteration 48300, loss = 1.06712
I0713 05:56:13.607317 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 05:56:13.607348 45537 solver.cpp:252]     Train net output #1: loss = 1.04446 (* 1 = 1.04446 loss)
I0713 05:56:13.607362 45537 sgd_solver.cpp:106] Iteration 48300, lr = 0.015
I0713 05:57:33.724076 45537 solver.cpp:236] Iteration 48400, loss = 1.07105
I0713 05:57:33.724220 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:57:33.724251 45537 solver.cpp:252]     Train net output #1: loss = 1.00033 (* 1 = 1.00033 loss)
I0713 05:57:33.724266 45537 sgd_solver.cpp:106] Iteration 48400, lr = 0.015
I0713 05:58:53.827867 45537 solver.cpp:236] Iteration 48500, loss = 1.07646
I0713 05:58:53.828001 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 05:58:53.828033 45537 solver.cpp:252]     Train net output #1: loss = 0.985146 (* 1 = 0.985146 loss)
I0713 05:58:53.828047 45537 sgd_solver.cpp:106] Iteration 48500, lr = 0.015
I0713 06:00:13.934911 45537 solver.cpp:236] Iteration 48600, loss = 1.06353
I0713 06:00:13.935108 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:00:13.935134 45537 solver.cpp:252]     Train net output #1: loss = 1.10015 (* 1 = 1.10015 loss)
I0713 06:00:13.935144 45537 sgd_solver.cpp:106] Iteration 48600, lr = 0.015
I0713 06:01:34.037689 45537 solver.cpp:236] Iteration 48700, loss = 1.07169
I0713 06:01:34.037853 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 06:01:34.037884 45537 solver.cpp:252]     Train net output #1: loss = 0.909588 (* 1 = 0.909588 loss)
I0713 06:01:34.037899 45537 sgd_solver.cpp:106] Iteration 48700, lr = 0.015
I0713 06:02:54.143091 45537 solver.cpp:236] Iteration 48800, loss = 1.08176
I0713 06:02:54.143203 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 06:02:54.143223 45537 solver.cpp:252]     Train net output #1: loss = 1.14983 (* 1 = 1.14983 loss)
I0713 06:02:54.143236 45537 sgd_solver.cpp:106] Iteration 48800, lr = 0.015
I0713 06:03:10.963384 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 06:04:14.247071 45537 solver.cpp:236] Iteration 48900, loss = 1.03898
I0713 06:04:14.247208 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:04:14.247227 45537 solver.cpp:252]     Train net output #1: loss = 0.923241 (* 1 = 0.923241 loss)
I0713 06:04:14.247242 45537 sgd_solver.cpp:106] Iteration 48900, lr = 0.015
I0713 06:05:34.359702 45537 solver.cpp:236] Iteration 49000, loss = 1.05598
I0713 06:05:34.359832 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:05:34.359851 45537 solver.cpp:252]     Train net output #1: loss = 1.09276 (* 1 = 1.09276 loss)
I0713 06:05:34.359870 45537 sgd_solver.cpp:106] Iteration 49000, lr = 0.015
I0713 06:06:54.470276 45537 solver.cpp:236] Iteration 49100, loss = 1.07671
I0713 06:06:54.470479 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:06:54.470499 45537 solver.cpp:252]     Train net output #1: loss = 1.03437 (* 1 = 1.03437 loss)
I0713 06:06:54.470513 45537 sgd_solver.cpp:106] Iteration 49100, lr = 0.015
I0713 06:08:14.576876 45537 solver.cpp:236] Iteration 49200, loss = 1.07068
I0713 06:08:14.577086 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:08:14.577107 45537 solver.cpp:252]     Train net output #1: loss = 0.950558 (* 1 = 0.950558 loss)
I0713 06:08:14.577122 45537 sgd_solver.cpp:106] Iteration 49200, lr = 0.015
I0713 06:09:34.673890 45537 solver.cpp:236] Iteration 49300, loss = 1.08398
I0713 06:09:34.674002 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 06:09:34.674020 45537 solver.cpp:252]     Train net output #1: loss = 1.18548 (* 1 = 1.18548 loss)
I0713 06:09:34.674033 45537 sgd_solver.cpp:106] Iteration 49300, lr = 0.015
I0713 06:10:54.789922 45537 solver.cpp:236] Iteration 49400, loss = 1.08686
I0713 06:10:54.790052 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:10:54.790082 45537 solver.cpp:252]     Train net output #1: loss = 1.12314 (* 1 = 1.12314 loss)
I0713 06:10:54.790096 45537 sgd_solver.cpp:106] Iteration 49400, lr = 0.015
I0713 06:12:14.097086 45537 solver.cpp:340] Iteration 49500, Testing net (#0)
I0713 06:13:31.057492 45537 solver.cpp:408]     Test net output #0: accuracy = 0.46125
I0713 06:13:31.057623 45537 solver.cpp:408]     Test net output #1: loss = 1.06796 (* 1 = 1.06796 loss)
I0713 06:13:31.836110 45537 solver.cpp:236] Iteration 49500, loss = 1.06444
I0713 06:13:31.836171 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:13:31.836189 45537 solver.cpp:252]     Train net output #1: loss = 1.14283 (* 1 = 1.14283 loss)
I0713 06:13:31.836210 45537 sgd_solver.cpp:106] Iteration 49500, lr = 0.015
I0713 06:14:51.909535 45537 solver.cpp:236] Iteration 49600, loss = 1.03356
I0713 06:14:51.909682 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:14:51.909703 45537 solver.cpp:252]     Train net output #1: loss = 1.1189 (* 1 = 1.1189 loss)
I0713 06:14:51.909718 45537 sgd_solver.cpp:106] Iteration 49600, lr = 0.015
I0713 06:16:12.005769 45537 solver.cpp:236] Iteration 49700, loss = 1.08671
I0713 06:16:12.005931 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:16:12.005964 45537 solver.cpp:252]     Train net output #1: loss = 1.09829 (* 1 = 1.09829 loss)
I0713 06:16:12.005981 45537 sgd_solver.cpp:106] Iteration 49700, lr = 0.015
I0713 06:17:32.112690 45537 solver.cpp:236] Iteration 49800, loss = 1.07128
I0713 06:17:32.112854 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:17:32.112874 45537 solver.cpp:252]     Train net output #1: loss = 1.0915 (* 1 = 1.0915 loss)
I0713 06:17:32.112893 45537 sgd_solver.cpp:106] Iteration 49800, lr = 0.015
I0713 06:18:52.231963 45537 solver.cpp:236] Iteration 49900, loss = 1.06707
I0713 06:18:52.232095 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:18:52.232115 45537 solver.cpp:252]     Train net output #1: loss = 1.04421 (* 1 = 1.04421 loss)
I0713 06:18:52.232130 45537 sgd_solver.cpp:106] Iteration 49900, lr = 0.015
I0713 06:20:11.563264 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_50000.caffemodel
I0713 06:20:11.924691 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_50000.solverstate
I0713 06:20:12.693145 45537 solver.cpp:236] Iteration 50000, loss = 1.06414
I0713 06:20:12.693202 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:20:12.693219 45537 solver.cpp:252]     Train net output #1: loss = 1.1347 (* 1 = 1.1347 loss)
I0713 06:20:12.693248 45537 sgd_solver.cpp:106] Iteration 50000, lr = 0.015
I0713 06:20:59.097324 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 06:21:32.742216 45537 solver.cpp:236] Iteration 50100, loss = 1.06637
I0713 06:21:32.742342 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:21:32.742363 45537 solver.cpp:252]     Train net output #1: loss = 1.11222 (* 1 = 1.11222 loss)
I0713 06:21:32.742377 45537 sgd_solver.cpp:106] Iteration 50100, lr = 0.015
I0713 06:22:52.858408 45537 solver.cpp:236] Iteration 50200, loss = 1.07874
I0713 06:22:52.858608 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:22:52.858638 45537 solver.cpp:252]     Train net output #1: loss = 1.1042 (* 1 = 1.1042 loss)
I0713 06:22:52.858660 45537 sgd_solver.cpp:106] Iteration 50200, lr = 0.015
I0713 06:24:12.966394 45537 solver.cpp:236] Iteration 50300, loss = 1.09054
I0713 06:24:12.966531 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:24:12.966563 45537 solver.cpp:252]     Train net output #1: loss = 1.09654 (* 1 = 1.09654 loss)
I0713 06:24:12.966580 45537 sgd_solver.cpp:106] Iteration 50300, lr = 0.015
I0713 06:25:33.079402 45537 solver.cpp:236] Iteration 50400, loss = 1.06229
I0713 06:25:33.079566 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:25:33.079597 45537 solver.cpp:252]     Train net output #1: loss = 0.98658 (* 1 = 0.98658 loss)
I0713 06:25:33.079612 45537 sgd_solver.cpp:106] Iteration 50400, lr = 0.015
I0713 06:26:53.175082 45537 solver.cpp:236] Iteration 50500, loss = 1.06628
I0713 06:26:53.175237 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:26:53.175269 45537 solver.cpp:252]     Train net output #1: loss = 1.14269 (* 1 = 1.14269 loss)
I0713 06:26:53.175285 45537 sgd_solver.cpp:106] Iteration 50500, lr = 0.015
I0713 06:28:13.297850 45537 solver.cpp:236] Iteration 50600, loss = 1.08196
I0713 06:28:13.297978 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:28:13.297999 45537 solver.cpp:252]     Train net output #1: loss = 1.05413 (* 1 = 1.05413 loss)
I0713 06:28:13.298014 45537 sgd_solver.cpp:106] Iteration 50600, lr = 0.015
I0713 06:29:33.402699 45537 solver.cpp:236] Iteration 50700, loss = 1.07207
I0713 06:29:33.402866 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:29:33.402901 45537 solver.cpp:252]     Train net output #1: loss = 1.03198 (* 1 = 1.03198 loss)
I0713 06:29:33.402917 45537 sgd_solver.cpp:106] Iteration 50700, lr = 0.015
I0713 06:30:53.511314 45537 solver.cpp:236] Iteration 50800, loss = 1.06369
I0713 06:30:53.511469 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:30:53.511502 45537 solver.cpp:252]     Train net output #1: loss = 0.961732 (* 1 = 0.961732 loss)
I0713 06:30:53.511515 45537 sgd_solver.cpp:106] Iteration 50800, lr = 0.015
I0713 06:32:13.627173 45537 solver.cpp:236] Iteration 50900, loss = 1.07751
I0713 06:32:13.627321 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 06:32:13.627346 45537 solver.cpp:252]     Train net output #1: loss = 1.14432 (* 1 = 1.14432 loss)
I0713 06:32:13.627358 45537 sgd_solver.cpp:106] Iteration 50900, lr = 0.015
I0713 06:33:32.918969 45537 solver.cpp:340] Iteration 51000, Testing net (#0)
I0713 06:34:49.885077 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4575
I0713 06:34:49.885210 45537 solver.cpp:408]     Test net output #1: loss = 1.07585 (* 1 = 1.07585 loss)
I0713 06:34:50.652070 45537 solver.cpp:236] Iteration 51000, loss = 1.08522
I0713 06:34:50.652117 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:34:50.652132 45537 solver.cpp:252]     Train net output #1: loss = 1.04105 (* 1 = 1.04105 loss)
I0713 06:34:50.652148 45537 sgd_solver.cpp:106] Iteration 51000, lr = 0.015
I0713 06:36:10.726330 45537 solver.cpp:236] Iteration 51100, loss = 1.09225
I0713 06:36:10.726482 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:36:10.726501 45537 solver.cpp:252]     Train net output #1: loss = 1.034 (* 1 = 1.034 loss)
I0713 06:36:10.726519 45537 sgd_solver.cpp:106] Iteration 51100, lr = 0.015
I0713 06:37:30.837087 45537 solver.cpp:236] Iteration 51200, loss = 1.07225
I0713 06:37:30.837260 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 06:37:30.837280 45537 solver.cpp:252]     Train net output #1: loss = 1.14673 (* 1 = 1.14673 loss)
I0713 06:37:30.837294 45537 sgd_solver.cpp:106] Iteration 51200, lr = 0.015
I0713 06:38:50.937754 45537 solver.cpp:236] Iteration 51300, loss = 1.07946
I0713 06:38:50.937942 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 06:38:50.937963 45537 solver.cpp:252]     Train net output #1: loss = 1.18103 (* 1 = 1.18103 loss)
I0713 06:38:50.937978 45537 sgd_solver.cpp:106] Iteration 51300, lr = 0.015
I0713 06:40:11.039515 45537 solver.cpp:236] Iteration 51400, loss = 1.08166
I0713 06:40:11.039621 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:40:11.039641 45537 solver.cpp:252]     Train net output #1: loss = 1.05526 (* 1 = 1.05526 loss)
I0713 06:40:11.039654 45537 sgd_solver.cpp:106] Iteration 51400, lr = 0.015
I0713 06:41:31.148954 45537 solver.cpp:236] Iteration 51500, loss = 1.05919
I0713 06:41:31.149109 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 06:41:31.149128 45537 solver.cpp:252]     Train net output #1: loss = 1.32154 (* 1 = 1.32154 loss)
I0713 06:41:31.149144 45537 sgd_solver.cpp:106] Iteration 51500, lr = 0.015
I0713 06:42:51.251898 45537 solver.cpp:236] Iteration 51600, loss = 1.05758
I0713 06:42:51.252045 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:42:51.252075 45537 solver.cpp:252]     Train net output #1: loss = 1.14053 (* 1 = 1.14053 loss)
I0713 06:42:51.252089 45537 sgd_solver.cpp:106] Iteration 51600, lr = 0.015
I0713 06:44:11.367245 45537 solver.cpp:236] Iteration 51700, loss = 1.07424
I0713 06:44:11.367346 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:44:11.367363 45537 solver.cpp:252]     Train net output #1: loss = 0.961671 (* 1 = 0.961671 loss)
I0713 06:44:11.367377 45537 sgd_solver.cpp:106] Iteration 51700, lr = 0.015
I0713 06:45:31.477651 45537 solver.cpp:236] Iteration 51800, loss = 1.06069
I0713 06:45:31.477841 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:45:31.477870 45537 solver.cpp:252]     Train net output #1: loss = 1.06052 (* 1 = 1.06052 loss)
I0713 06:45:31.477885 45537 sgd_solver.cpp:106] Iteration 51800, lr = 0.015
I0713 06:45:40.295251 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 06:46:51.588428 45537 solver.cpp:236] Iteration 51900, loss = 1.06862
I0713 06:46:51.588630 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 06:46:51.588661 45537 solver.cpp:252]     Train net output #1: loss = 0.911886 (* 1 = 0.911886 loss)
I0713 06:46:51.588677 45537 sgd_solver.cpp:106] Iteration 51900, lr = 0.015
I0713 06:48:11.701217 45537 solver.cpp:236] Iteration 52000, loss = 1.03578
I0713 06:48:11.701340 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 06:48:11.701359 45537 solver.cpp:252]     Train net output #1: loss = 1.00474 (* 1 = 1.00474 loss)
I0713 06:48:11.701372 45537 sgd_solver.cpp:106] Iteration 52000, lr = 0.015
I0713 06:49:31.813858 45537 solver.cpp:236] Iteration 52100, loss = 1.07224
I0713 06:49:31.813992 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:49:31.814012 45537 solver.cpp:252]     Train net output #1: loss = 1.14004 (* 1 = 1.14004 loss)
I0713 06:49:31.814029 45537 sgd_solver.cpp:106] Iteration 52100, lr = 0.015
I0713 06:50:52.059125 45537 solver.cpp:236] Iteration 52200, loss = 1.08048
I0713 06:50:52.059236 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:50:52.059255 45537 solver.cpp:252]     Train net output #1: loss = 1.05813 (* 1 = 1.05813 loss)
I0713 06:50:52.059268 45537 sgd_solver.cpp:106] Iteration 52200, lr = 0.015
I0713 06:52:12.241039 45537 solver.cpp:236] Iteration 52300, loss = 1.08241
I0713 06:52:12.241248 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 06:52:12.241276 45537 solver.cpp:252]     Train net output #1: loss = 1.14561 (* 1 = 1.14561 loss)
I0713 06:52:12.241297 45537 sgd_solver.cpp:106] Iteration 52300, lr = 0.015
I0713 06:53:37.872292 45537 solver.cpp:236] Iteration 52400, loss = 1.07708
I0713 06:53:37.872511 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 06:53:37.872553 45537 solver.cpp:252]     Train net output #1: loss = 1.09887 (* 1 = 1.09887 loss)
I0713 06:53:37.872576 45537 sgd_solver.cpp:106] Iteration 52400, lr = 0.015
I0713 06:55:00.958791 45537 solver.cpp:340] Iteration 52500, Testing net (#0)
I0713 06:56:18.543673 45537 solver.cpp:408]     Test net output #0: accuracy = 0.44375
I0713 06:56:18.543855 45537 solver.cpp:408]     Test net output #1: loss = 1.06424 (* 1 = 1.06424 loss)
I0713 06:56:19.340766 45537 solver.cpp:236] Iteration 52500, loss = 1.05524
I0713 06:56:19.340845 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:56:19.340867 45537 solver.cpp:252]     Train net output #1: loss = 1.05173 (* 1 = 1.05173 loss)
I0713 06:56:19.340883 45537 sgd_solver.cpp:106] Iteration 52500, lr = 0.015
I0713 06:57:39.757495 45537 solver.cpp:236] Iteration 52600, loss = 1.04895
I0713 06:57:39.757642 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:57:39.757661 45537 solver.cpp:252]     Train net output #1: loss = 1.05871 (* 1 = 1.05871 loss)
I0713 06:57:39.757676 45537 sgd_solver.cpp:106] Iteration 52600, lr = 0.015
I0713 06:58:59.998126 45537 solver.cpp:236] Iteration 52700, loss = 1.06407
I0713 06:58:59.998296 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 06:58:59.998325 45537 solver.cpp:252]     Train net output #1: loss = 1.04791 (* 1 = 1.04791 loss)
I0713 06:58:59.998337 45537 sgd_solver.cpp:106] Iteration 52700, lr = 0.015
I0713 07:00:20.111631 45537 solver.cpp:236] Iteration 52800, loss = 1.08021
I0713 07:00:20.111771 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:00:20.111802 45537 solver.cpp:252]     Train net output #1: loss = 1.12965 (* 1 = 1.12965 loss)
I0713 07:00:20.111820 45537 sgd_solver.cpp:106] Iteration 52800, lr = 0.015
I0713 07:01:40.336339 45537 solver.cpp:236] Iteration 52900, loss = 1.07335
I0713 07:01:40.336501 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 07:01:40.336534 45537 solver.cpp:252]     Train net output #1: loss = 0.960528 (* 1 = 0.960528 loss)
I0713 07:01:40.336550 45537 sgd_solver.cpp:106] Iteration 52900, lr = 0.015
I0713 07:03:00.713397 45537 solver.cpp:236] Iteration 53000, loss = 1.05309
I0713 07:03:00.713491 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:03:00.713513 45537 solver.cpp:252]     Train net output #1: loss = 1.20157 (* 1 = 1.20157 loss)
I0713 07:03:00.713528 45537 sgd_solver.cpp:106] Iteration 53000, lr = 0.015
I0713 07:04:03.233167 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 07:04:20.922612 45537 solver.cpp:236] Iteration 53100, loss = 1.0645
I0713 07:04:20.922691 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:04:20.922716 45537 solver.cpp:252]     Train net output #1: loss = 1.11936 (* 1 = 1.11936 loss)
I0713 07:04:20.922731 45537 sgd_solver.cpp:106] Iteration 53100, lr = 0.015
I0713 07:05:41.115094 45537 solver.cpp:236] Iteration 53200, loss = 1.0734
I0713 07:05:41.115252 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:05:41.115283 45537 solver.cpp:252]     Train net output #1: loss = 1.07298 (* 1 = 1.07298 loss)
I0713 07:05:41.115301 45537 sgd_solver.cpp:106] Iteration 53200, lr = 0.015
I0713 07:07:01.447024 45537 solver.cpp:236] Iteration 53300, loss = 1.05655
I0713 07:07:01.447159 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:07:01.447190 45537 solver.cpp:252]     Train net output #1: loss = 1.04076 (* 1 = 1.04076 loss)
I0713 07:07:01.447204 45537 sgd_solver.cpp:106] Iteration 53300, lr = 0.015
I0713 07:08:21.733973 45537 solver.cpp:236] Iteration 53400, loss = 1.05448
I0713 07:08:21.734133 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:08:21.734161 45537 solver.cpp:252]     Train net output #1: loss = 1.20445 (* 1 = 1.20445 loss)
I0713 07:08:21.734176 45537 sgd_solver.cpp:106] Iteration 53400, lr = 0.015
I0713 07:09:41.934522 45537 solver.cpp:236] Iteration 53500, loss = 1.05762
I0713 07:09:41.934774 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 07:09:41.934797 45537 solver.cpp:252]     Train net output #1: loss = 0.942956 (* 1 = 0.942956 loss)
I0713 07:09:41.934810 45537 sgd_solver.cpp:106] Iteration 53500, lr = 0.015
I0713 07:11:02.038625 45537 solver.cpp:236] Iteration 53600, loss = 1.08707
I0713 07:11:02.038889 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:11:02.038909 45537 solver.cpp:252]     Train net output #1: loss = 1.0987 (* 1 = 1.0987 loss)
I0713 07:11:02.038936 45537 sgd_solver.cpp:106] Iteration 53600, lr = 0.015
I0713 07:12:22.248694 45537 solver.cpp:236] Iteration 53700, loss = 1.09874
I0713 07:12:22.248848 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 07:12:22.248869 45537 solver.cpp:252]     Train net output #1: loss = 1.06242 (* 1 = 1.06242 loss)
I0713 07:12:22.248884 45537 sgd_solver.cpp:106] Iteration 53700, lr = 0.015
I0713 07:13:42.364718 45537 solver.cpp:236] Iteration 53800, loss = 1.0973
I0713 07:13:42.364851 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:13:42.364871 45537 solver.cpp:252]     Train net output #1: loss = 1.07178 (* 1 = 1.07178 loss)
I0713 07:13:42.364886 45537 sgd_solver.cpp:106] Iteration 53800, lr = 0.015
I0713 07:15:02.681345 45537 solver.cpp:236] Iteration 53900, loss = 1.07174
I0713 07:15:02.681486 45537 solver.cpp:252]     Train net output #0: accuracy = 0
I0713 07:15:02.681505 45537 solver.cpp:252]     Train net output #1: loss = 1.40788 (* 1 = 1.40788 loss)
I0713 07:15:02.681519 45537 sgd_solver.cpp:106] Iteration 53900, lr = 0.015
I0713 07:16:22.251616 45537 solver.cpp:340] Iteration 54000, Testing net (#0)
I0713 07:17:39.841670 45537 solver.cpp:408]     Test net output #0: accuracy = 0.47875
I0713 07:17:39.841820 45537 solver.cpp:408]     Test net output #1: loss = 1.05548 (* 1 = 1.05548 loss)
I0713 07:17:40.618191 45537 solver.cpp:236] Iteration 54000, loss = 1.05294
I0713 07:17:40.618242 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:17:40.618259 45537 solver.cpp:252]     Train net output #1: loss = 1.21938 (* 1 = 1.21938 loss)
I0713 07:17:40.618276 45537 sgd_solver.cpp:106] Iteration 54000, lr = 0.015
I0713 07:19:00.811127 45537 solver.cpp:236] Iteration 54100, loss = 1.09003
I0713 07:19:00.811322 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:19:00.811352 45537 solver.cpp:252]     Train net output #1: loss = 1.05177 (* 1 = 1.05177 loss)
I0713 07:19:00.811362 45537 sgd_solver.cpp:106] Iteration 54100, lr = 0.015
I0713 07:20:21.137269 45537 solver.cpp:236] Iteration 54200, loss = 1.04742
I0713 07:20:21.137441 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 07:20:21.137477 45537 solver.cpp:252]     Train net output #1: loss = 1.43975 (* 1 = 1.43975 loss)
I0713 07:20:21.137495 45537 sgd_solver.cpp:106] Iteration 54200, lr = 0.015
I0713 07:21:31.856606 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 07:21:41.498071 45537 solver.cpp:236] Iteration 54300, loss = 1.07037
I0713 07:21:41.498142 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:21:41.498159 45537 solver.cpp:252]     Train net output #1: loss = 1.18684 (* 1 = 1.18684 loss)
I0713 07:21:41.498174 45537 sgd_solver.cpp:106] Iteration 54300, lr = 0.015
I0713 07:23:01.751958 45537 solver.cpp:236] Iteration 54400, loss = 1.06941
I0713 07:23:01.752100 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:23:01.752121 45537 solver.cpp:252]     Train net output #1: loss = 1.20765 (* 1 = 1.20765 loss)
I0713 07:23:01.752136 45537 sgd_solver.cpp:106] Iteration 54400, lr = 0.015
I0713 07:24:22.099038 45537 solver.cpp:236] Iteration 54500, loss = 1.0725
I0713 07:24:22.099153 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:24:22.099170 45537 solver.cpp:252]     Train net output #1: loss = 1.08006 (* 1 = 1.08006 loss)
I0713 07:24:22.099184 45537 sgd_solver.cpp:106] Iteration 54500, lr = 0.015
I0713 07:25:42.324775 45537 solver.cpp:236] Iteration 54600, loss = 1.06855
I0713 07:25:42.324985 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:25:42.325006 45537 solver.cpp:252]     Train net output #1: loss = 1.12391 (* 1 = 1.12391 loss)
I0713 07:25:42.325019 45537 sgd_solver.cpp:106] Iteration 54600, lr = 0.015
I0713 07:27:02.619837 45537 solver.cpp:236] Iteration 54700, loss = 1.08089
I0713 07:27:02.619974 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:27:02.619993 45537 solver.cpp:252]     Train net output #1: loss = 1.18211 (* 1 = 1.18211 loss)
I0713 07:27:02.620008 45537 sgd_solver.cpp:106] Iteration 54700, lr = 0.015
I0713 07:28:22.923316 45537 solver.cpp:236] Iteration 54800, loss = 1.07266
I0713 07:28:22.923470 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:28:22.923506 45537 solver.cpp:252]     Train net output #1: loss = 1.09562 (* 1 = 1.09562 loss)
I0713 07:28:22.923529 45537 sgd_solver.cpp:106] Iteration 54800, lr = 0.015
I0713 07:29:43.144122 45537 solver.cpp:236] Iteration 54900, loss = 1.05688
I0713 07:29:43.144279 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:29:43.144304 45537 solver.cpp:252]     Train net output #1: loss = 1.04746 (* 1 = 1.04746 loss)
I0713 07:29:43.144318 45537 sgd_solver.cpp:106] Iteration 54900, lr = 0.015
I0713 07:31:02.557126 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_55000.caffemodel
I0713 07:31:02.726073 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_55000.solverstate
I0713 07:31:03.512059 45537 solver.cpp:236] Iteration 55000, loss = 1.0757
I0713 07:31:03.512126 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:31:03.512145 45537 solver.cpp:252]     Train net output #1: loss = 1.06674 (* 1 = 1.06674 loss)
I0713 07:31:03.512159 45537 sgd_solver.cpp:106] Iteration 55000, lr = 0.015
I0713 07:32:23.831948 45537 solver.cpp:236] Iteration 55100, loss = 1.05479
I0713 07:32:23.832175 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:32:23.832212 45537 solver.cpp:252]     Train net output #1: loss = 1.08077 (* 1 = 1.08077 loss)
I0713 07:32:23.832224 45537 sgd_solver.cpp:106] Iteration 55100, lr = 0.015
I0713 07:33:44.183164 45537 solver.cpp:236] Iteration 55200, loss = 1.06912
I0713 07:33:44.183336 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:33:44.183357 45537 solver.cpp:252]     Train net output #1: loss = 1.00531 (* 1 = 1.00531 loss)
I0713 07:33:44.183370 45537 sgd_solver.cpp:106] Iteration 55200, lr = 0.015
I0713 07:34:55.659221 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 07:35:04.483639 45537 solver.cpp:236] Iteration 55300, loss = 1.05014
I0713 07:35:04.483703 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:35:04.483719 45537 solver.cpp:252]     Train net output #1: loss = 1.10017 (* 1 = 1.10017 loss)
I0713 07:35:04.483733 45537 sgd_solver.cpp:106] Iteration 55300, lr = 0.015
I0713 07:36:24.763228 45537 solver.cpp:236] Iteration 55400, loss = 1.05258
I0713 07:36:24.763375 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 07:36:24.763396 45537 solver.cpp:252]     Train net output #1: loss = 1.23679 (* 1 = 1.23679 loss)
I0713 07:36:24.763411 45537 sgd_solver.cpp:106] Iteration 55400, lr = 0.015
I0713 07:37:44.194496 45537 solver.cpp:340] Iteration 55500, Testing net (#0)
I0713 07:39:01.795761 45537 solver.cpp:408]     Test net output #0: accuracy = 0.41875
I0713 07:39:01.795894 45537 solver.cpp:408]     Test net output #1: loss = 1.08839 (* 1 = 1.08839 loss)
I0713 07:39:02.563766 45537 solver.cpp:236] Iteration 55500, loss = 1.04164
I0713 07:39:02.563822 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 07:39:02.563839 45537 solver.cpp:252]     Train net output #1: loss = 0.960955 (* 1 = 0.960955 loss)
I0713 07:39:02.563855 45537 sgd_solver.cpp:106] Iteration 55500, lr = 0.015
I0713 07:40:22.891134 45537 solver.cpp:236] Iteration 55600, loss = 1.07184
I0713 07:40:22.891304 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:40:22.891332 45537 solver.cpp:252]     Train net output #1: loss = 1.09265 (* 1 = 1.09265 loss)
I0713 07:40:22.891347 45537 sgd_solver.cpp:106] Iteration 55600, lr = 0.015
I0713 07:41:43.187965 45537 solver.cpp:236] Iteration 55700, loss = 1.08065
I0713 07:41:43.188163 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:41:43.188182 45537 solver.cpp:252]     Train net output #1: loss = 1.03452 (* 1 = 1.03452 loss)
I0713 07:41:43.188195 45537 sgd_solver.cpp:106] Iteration 55700, lr = 0.015
I0713 07:43:03.414070 45537 solver.cpp:236] Iteration 55800, loss = 1.09511
I0713 07:43:03.414211 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 07:43:03.414229 45537 solver.cpp:252]     Train net output #1: loss = 1.0227 (* 1 = 1.0227 loss)
I0713 07:43:03.414243 45537 sgd_solver.cpp:106] Iteration 55800, lr = 0.015
I0713 07:44:24.403641 45537 solver.cpp:236] Iteration 55900, loss = 1.08351
I0713 07:44:24.403792 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:44:24.403831 45537 solver.cpp:252]     Train net output #1: loss = 1.06472 (* 1 = 1.06472 loss)
I0713 07:44:24.403849 45537 sgd_solver.cpp:106] Iteration 55900, lr = 0.015
I0713 07:45:44.715088 45537 solver.cpp:236] Iteration 56000, loss = 1.06343
I0713 07:45:44.715191 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 07:45:44.715211 45537 solver.cpp:252]     Train net output #1: loss = 1.02756 (* 1 = 1.02756 loss)
I0713 07:45:44.715225 45537 sgd_solver.cpp:106] Iteration 56000, lr = 0.015
I0713 07:47:04.952860 45537 solver.cpp:236] Iteration 56100, loss = 1.07923
I0713 07:47:04.953006 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:47:04.953038 45537 solver.cpp:252]     Train net output #1: loss = 1.10161 (* 1 = 1.10161 loss)
I0713 07:47:04.953052 45537 sgd_solver.cpp:106] Iteration 56100, lr = 0.015
I0713 07:48:25.230458 45537 solver.cpp:236] Iteration 56200, loss = 1.06011
I0713 07:48:25.230612 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 07:48:25.230643 45537 solver.cpp:252]     Train net output #1: loss = 1.21737 (* 1 = 1.21737 loss)
I0713 07:48:25.230659 45537 sgd_solver.cpp:106] Iteration 56200, lr = 0.015
I0713 07:49:45.434854 45537 solver.cpp:236] Iteration 56300, loss = 1.08418
I0713 07:49:45.434969 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:49:45.434988 45537 solver.cpp:252]     Train net output #1: loss = 1.11355 (* 1 = 1.11355 loss)
I0713 07:49:45.435003 45537 sgd_solver.cpp:106] Iteration 56300, lr = 0.015
I0713 07:50:28.791903 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 07:51:05.659034 45537 solver.cpp:236] Iteration 56400, loss = 1.08822
I0713 07:51:05.659185 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 07:51:05.659206 45537 solver.cpp:252]     Train net output #1: loss = 0.981479 (* 1 = 0.981479 loss)
I0713 07:51:05.659221 45537 sgd_solver.cpp:106] Iteration 56400, lr = 0.015
I0713 07:52:26.042692 45537 solver.cpp:236] Iteration 56500, loss = 1.07836
I0713 07:52:26.042901 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 07:52:26.042930 45537 solver.cpp:252]     Train net output #1: loss = 1.0038 (* 1 = 1.0038 loss)
I0713 07:52:26.042942 45537 sgd_solver.cpp:106] Iteration 56500, lr = 0.015
I0713 07:53:46.259763 45537 solver.cpp:236] Iteration 56600, loss = 1.09615
I0713 07:53:46.259903 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 07:53:46.259923 45537 solver.cpp:252]     Train net output #1: loss = 1.13518 (* 1 = 1.13518 loss)
I0713 07:53:46.259938 45537 sgd_solver.cpp:106] Iteration 56600, lr = 0.015
I0713 07:55:06.468137 45537 solver.cpp:236] Iteration 56700, loss = 1.07049
I0713 07:55:06.468291 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:55:06.468312 45537 solver.cpp:252]     Train net output #1: loss = 1.19665 (* 1 = 1.19665 loss)
I0713 07:55:06.468327 45537 sgd_solver.cpp:106] Iteration 56700, lr = 0.015
I0713 07:56:26.662467 45537 solver.cpp:236] Iteration 56800, loss = 1.07754
I0713 07:56:26.662684 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 07:56:26.662706 45537 solver.cpp:252]     Train net output #1: loss = 1.16107 (* 1 = 1.16107 loss)
I0713 07:56:26.662722 45537 sgd_solver.cpp:106] Iteration 56800, lr = 0.015
I0713 07:57:46.965364 45537 solver.cpp:236] Iteration 56900, loss = 1.07771
I0713 07:57:46.965497 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 07:57:46.965517 45537 solver.cpp:252]     Train net output #1: loss = 1.10168 (* 1 = 1.10168 loss)
I0713 07:57:46.965538 45537 sgd_solver.cpp:106] Iteration 56900, lr = 0.015
I0713 07:59:06.372406 45537 solver.cpp:340] Iteration 57000, Testing net (#0)
I0713 08:00:23.905532 45537 solver.cpp:408]     Test net output #0: accuracy = 0.46625
I0713 08:00:23.905627 45537 solver.cpp:408]     Test net output #1: loss = 1.05933 (* 1 = 1.05933 loss)
I0713 08:00:24.672935 45537 solver.cpp:236] Iteration 57000, loss = 1.0779
I0713 08:00:24.672986 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:00:24.673003 45537 solver.cpp:252]     Train net output #1: loss = 1.11729 (* 1 = 1.11729 loss)
I0713 08:00:24.673020 45537 sgd_solver.cpp:106] Iteration 57000, lr = 0.015
I0713 08:01:44.890224 45537 solver.cpp:236] Iteration 57100, loss = 1.0916
I0713 08:01:44.890365 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:01:44.890384 45537 solver.cpp:252]     Train net output #1: loss = 1.08618 (* 1 = 1.08618 loss)
I0713 08:01:44.890399 45537 sgd_solver.cpp:106] Iteration 57100, lr = 0.015
I0713 08:03:05.084830 45537 solver.cpp:236] Iteration 57200, loss = 1.06493
I0713 08:03:05.085011 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 08:03:05.085043 45537 solver.cpp:252]     Train net output #1: loss = 1.25413 (* 1 = 1.25413 loss)
I0713 08:03:05.085064 45537 sgd_solver.cpp:106] Iteration 57200, lr = 0.015
I0713 08:04:25.387343 45537 solver.cpp:236] Iteration 57300, loss = 1.07886
I0713 08:04:25.387487 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:04:25.387506 45537 solver.cpp:252]     Train net output #1: loss = 1.01949 (* 1 = 1.01949 loss)
I0713 08:04:25.387519 45537 sgd_solver.cpp:106] Iteration 57300, lr = 0.015
I0713 08:05:45.649637 45537 solver.cpp:236] Iteration 57400, loss = 1.07457
I0713 08:05:45.649785 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:05:45.649816 45537 solver.cpp:252]     Train net output #1: loss = 1.03211 (* 1 = 1.03211 loss)
I0713 08:05:45.649828 45537 sgd_solver.cpp:106] Iteration 57400, lr = 0.015
I0713 08:07:05.901974 45537 solver.cpp:236] Iteration 57500, loss = 1.08599
I0713 08:07:05.902127 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:07:05.902158 45537 solver.cpp:252]     Train net output #1: loss = 1.17286 (* 1 = 1.17286 loss)
I0713 08:07:05.902173 45537 sgd_solver.cpp:106] Iteration 57500, lr = 0.015
I0713 08:08:26.115852 45537 solver.cpp:236] Iteration 57600, loss = 1.0608
I0713 08:08:26.115962 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:08:26.115979 45537 solver.cpp:252]     Train net output #1: loss = 1.10123 (* 1 = 1.10123 loss)
I0713 08:08:26.115993 45537 sgd_solver.cpp:106] Iteration 57600, lr = 0.015
I0713 08:09:46.320132 45537 solver.cpp:236] Iteration 57700, loss = 1.08394
I0713 08:09:46.320291 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 08:09:46.320312 45537 solver.cpp:252]     Train net output #1: loss = 1.03847 (* 1 = 1.03847 loss)
I0713 08:09:46.320325 45537 sgd_solver.cpp:106] Iteration 57700, lr = 0.015
I0713 08:11:06.598076 45537 solver.cpp:236] Iteration 57800, loss = 1.05406
I0713 08:11:06.598279 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 08:11:06.598299 45537 solver.cpp:252]     Train net output #1: loss = 0.919071 (* 1 = 0.919071 loss)
I0713 08:11:06.598315 45537 sgd_solver.cpp:106] Iteration 57800, lr = 0.015
I0713 08:12:26.839071 45537 solver.cpp:236] Iteration 57900, loss = 1.07105
I0713 08:12:26.839301 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:12:26.839331 45537 solver.cpp:252]     Train net output #1: loss = 1.11993 (* 1 = 1.11993 loss)
I0713 08:12:26.839346 45537 sgd_solver.cpp:106] Iteration 57900, lr = 0.015
I0713 08:13:47.089967 45537 solver.cpp:236] Iteration 58000, loss = 1.06724
I0713 08:13:47.090111 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 08:13:47.090132 45537 solver.cpp:252]     Train net output #1: loss = 0.975916 (* 1 = 0.975916 loss)
I0713 08:13:47.090145 45537 sgd_solver.cpp:106] Iteration 58000, lr = 0.015
I0713 08:15:07.355531 45537 solver.cpp:236] Iteration 58100, loss = 1.06711
I0713 08:15:07.355697 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 08:15:07.355727 45537 solver.cpp:252]     Train net output #1: loss = 0.906364 (* 1 = 0.906364 loss)
I0713 08:15:07.355741 45537 sgd_solver.cpp:106] Iteration 58100, lr = 0.015
I0713 08:16:27.547984 45537 solver.cpp:236] Iteration 58200, loss = 1.07015
I0713 08:16:27.548152 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 08:16:27.548178 45537 solver.cpp:252]     Train net output #1: loss = 1.22472 (* 1 = 1.22472 loss)
I0713 08:16:27.548193 45537 sgd_solver.cpp:106] Iteration 58200, lr = 0.015
I0713 08:17:47.658399 45537 solver.cpp:236] Iteration 58300, loss = 1.0883
I0713 08:17:47.658558 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:17:47.658589 45537 solver.cpp:252]     Train net output #1: loss = 1.11058 (* 1 = 1.11058 loss)
I0713 08:17:47.658607 45537 sgd_solver.cpp:106] Iteration 58300, lr = 0.015
I0713 08:19:07.766803 45537 solver.cpp:236] Iteration 58400, loss = 1.08061
I0713 08:19:07.766911 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:19:07.766930 45537 solver.cpp:252]     Train net output #1: loss = 1.0566 (* 1 = 1.0566 loss)
I0713 08:19:07.766943 45537 sgd_solver.cpp:106] Iteration 58400, lr = 0.015
I0713 08:19:37.503489 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 08:20:27.174198 45537 solver.cpp:340] Iteration 58500, Testing net (#0)
I0713 08:21:44.586613 45537 solver.cpp:408]     Test net output #0: accuracy = 0.49375
I0713 08:21:44.586722 45537 solver.cpp:408]     Test net output #1: loss = 1.04815 (* 1 = 1.04815 loss)
I0713 08:21:45.357628 45537 solver.cpp:236] Iteration 58500, loss = 1.06778
I0713 08:21:45.357681 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 08:21:45.357699 45537 solver.cpp:252]     Train net output #1: loss = 0.935977 (* 1 = 0.935977 loss)
I0713 08:21:45.357715 45537 sgd_solver.cpp:106] Iteration 58500, lr = 0.015
I0713 08:23:05.492733 45537 solver.cpp:236] Iteration 58600, loss = 1.08188
I0713 08:23:05.492856 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:23:05.492877 45537 solver.cpp:252]     Train net output #1: loss = 1.03712 (* 1 = 1.03712 loss)
I0713 08:23:05.492892 45537 sgd_solver.cpp:106] Iteration 58600, lr = 0.015
I0713 08:24:25.598343 45537 solver.cpp:236] Iteration 58700, loss = 1.07494
I0713 08:24:25.598481 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:24:25.598502 45537 solver.cpp:252]     Train net output #1: loss = 0.966701 (* 1 = 0.966701 loss)
I0713 08:24:25.598517 45537 sgd_solver.cpp:106] Iteration 58700, lr = 0.015
I0713 08:25:45.704715 45537 solver.cpp:236] Iteration 58800, loss = 1.0608
I0713 08:25:45.704861 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:25:45.704892 45537 solver.cpp:252]     Train net output #1: loss = 0.990412 (* 1 = 0.990412 loss)
I0713 08:25:45.704910 45537 sgd_solver.cpp:106] Iteration 58800, lr = 0.015
I0713 08:27:05.807363 45537 solver.cpp:236] Iteration 58900, loss = 1.06722
I0713 08:27:05.807492 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 08:27:05.807512 45537 solver.cpp:252]     Train net output #1: loss = 1.26172 (* 1 = 1.26172 loss)
I0713 08:27:05.807525 45537 sgd_solver.cpp:106] Iteration 58900, lr = 0.015
I0713 08:28:25.928937 45537 solver.cpp:236] Iteration 59000, loss = 1.076
I0713 08:28:25.929113 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 08:28:25.929136 45537 solver.cpp:252]     Train net output #1: loss = 1.20809 (* 1 = 1.20809 loss)
I0713 08:28:25.929149 45537 sgd_solver.cpp:106] Iteration 59000, lr = 0.015
I0713 08:29:46.018043 45537 solver.cpp:236] Iteration 59100, loss = 1.08157
I0713 08:29:46.018169 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 08:29:46.018189 45537 solver.cpp:252]     Train net output #1: loss = 1.00146 (* 1 = 1.00146 loss)
I0713 08:29:46.018204 45537 sgd_solver.cpp:106] Iteration 59100, lr = 0.015
I0713 08:31:06.119037 45537 solver.cpp:236] Iteration 59200, loss = 1.06462
I0713 08:31:06.119169 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:31:06.119189 45537 solver.cpp:252]     Train net output #1: loss = 1.0017 (* 1 = 1.0017 loss)
I0713 08:31:06.119204 45537 sgd_solver.cpp:106] Iteration 59200, lr = 0.015
I0713 08:32:26.222996 45537 solver.cpp:236] Iteration 59300, loss = 1.05051
I0713 08:32:26.223134 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:32:26.223156 45537 solver.cpp:252]     Train net output #1: loss = 1.04877 (* 1 = 1.04877 loss)
I0713 08:32:26.223168 45537 sgd_solver.cpp:106] Iteration 59300, lr = 0.015
I0713 08:33:46.327062 45537 solver.cpp:236] Iteration 59400, loss = 1.06374
I0713 08:33:46.327235 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 08:33:46.327256 45537 solver.cpp:252]     Train net output #1: loss = 1.32083 (* 1 = 1.32083 loss)
I0713 08:33:46.327275 45537 sgd_solver.cpp:106] Iteration 59400, lr = 0.015
I0713 08:35:06.443156 45537 solver.cpp:236] Iteration 59500, loss = 1.07498
I0713 08:35:06.443336 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 08:35:06.443368 45537 solver.cpp:252]     Train net output #1: loss = 1.01736 (* 1 = 1.01736 loss)
I0713 08:35:06.443383 45537 sgd_solver.cpp:106] Iteration 59500, lr = 0.015
I0713 08:36:26.540751 45537 solver.cpp:236] Iteration 59600, loss = 1.0756
I0713 08:36:26.540858 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 08:36:26.540879 45537 solver.cpp:252]     Train net output #1: loss = 1.06745 (* 1 = 1.06745 loss)
I0713 08:36:26.540892 45537 sgd_solver.cpp:106] Iteration 59600, lr = 0.015
I0713 08:37:25.012212 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 08:37:46.642429 45537 solver.cpp:236] Iteration 59700, loss = 1.06264
I0713 08:37:46.642493 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 08:37:46.642513 45537 solver.cpp:252]     Train net output #1: loss = 0.849849 (* 1 = 0.849849 loss)
I0713 08:37:46.642527 45537 sgd_solver.cpp:106] Iteration 59700, lr = 0.015
I0713 08:39:06.750211 45537 solver.cpp:236] Iteration 59800, loss = 1.07592
I0713 08:39:06.750336 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 08:39:06.750356 45537 solver.cpp:252]     Train net output #1: loss = 0.970658 (* 1 = 0.970658 loss)
I0713 08:39:06.750371 45537 sgd_solver.cpp:106] Iteration 59800, lr = 0.015
I0713 08:40:26.858541 45537 solver.cpp:236] Iteration 59900, loss = 1.07174
I0713 08:40:26.858659 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 08:40:26.858678 45537 solver.cpp:252]     Train net output #1: loss = 1.1927 (* 1 = 1.1927 loss)
I0713 08:40:26.858691 45537 sgd_solver.cpp:106] Iteration 59900, lr = 0.015
I0713 08:41:46.168279 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_60000.caffemodel
I0713 08:41:46.560729 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_60000.solverstate
I0713 08:41:46.597904 45537 solver.cpp:340] Iteration 60000, Testing net (#0)
I0713 08:43:03.893137 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4525
I0713 08:43:03.893275 45537 solver.cpp:408]     Test net output #1: loss = 1.06736 (* 1 = 1.06736 loss)
I0713 08:43:04.661573 45537 solver.cpp:236] Iteration 60000, loss = 1.0651
I0713 08:43:04.661633 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 08:43:04.661653 45537 solver.cpp:252]     Train net output #1: loss = 0.982933 (* 1 = 0.982933 loss)
I0713 08:43:04.661669 45537 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0713 08:44:24.765092 45537 solver.cpp:236] Iteration 60100, loss = 1.06302
I0713 08:44:24.765358 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:44:24.765382 45537 solver.cpp:252]     Train net output #1: loss = 1.09671 (* 1 = 1.09671 loss)
I0713 08:44:24.765398 45537 sgd_solver.cpp:106] Iteration 60100, lr = 0.0015
I0713 08:45:44.865501 45537 solver.cpp:236] Iteration 60200, loss = 1.09202
I0713 08:45:44.865630 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:45:44.865650 45537 solver.cpp:252]     Train net output #1: loss = 1.11698 (* 1 = 1.11698 loss)
I0713 08:45:44.865664 45537 sgd_solver.cpp:106] Iteration 60200, lr = 0.0015
I0713 08:47:05.109297 45537 solver.cpp:236] Iteration 60300, loss = 1.04046
I0713 08:47:05.109452 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:47:05.109488 45537 solver.cpp:252]     Train net output #1: loss = 1.01765 (* 1 = 1.01765 loss)
I0713 08:47:05.109504 45537 sgd_solver.cpp:106] Iteration 60300, lr = 0.0015
I0713 08:48:26.124949 45537 solver.cpp:236] Iteration 60400, loss = 1.06346
I0713 08:48:26.125093 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 08:48:26.125129 45537 solver.cpp:252]     Train net output #1: loss = 0.987301 (* 1 = 0.987301 loss)
I0713 08:48:26.125149 45537 sgd_solver.cpp:106] Iteration 60400, lr = 0.0015
I0713 08:49:46.276814 45537 solver.cpp:236] Iteration 60500, loss = 1.06896
I0713 08:49:46.276926 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:49:46.276942 45537 solver.cpp:252]     Train net output #1: loss = 1.09324 (* 1 = 1.09324 loss)
I0713 08:49:46.276955 45537 sgd_solver.cpp:106] Iteration 60500, lr = 0.0015
I0713 08:51:06.389715 45537 solver.cpp:236] Iteration 60600, loss = 1.05386
I0713 08:51:06.389856 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 08:51:06.389875 45537 solver.cpp:252]     Train net output #1: loss = 0.921024 (* 1 = 0.921024 loss)
I0713 08:51:06.389894 45537 sgd_solver.cpp:106] Iteration 60600, lr = 0.0015
I0713 08:52:26.495484 45537 solver.cpp:236] Iteration 60700, loss = 1.09046
I0713 08:52:26.495599 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:52:26.495617 45537 solver.cpp:252]     Train net output #1: loss = 1.16509 (* 1 = 1.16509 loss)
I0713 08:52:26.495631 45537 sgd_solver.cpp:106] Iteration 60700, lr = 0.0015
I0713 08:52:44.129562 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 08:53:46.601440 45537 solver.cpp:236] Iteration 60800, loss = 1.07148
I0713 08:53:46.601629 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 08:53:46.601649 45537 solver.cpp:252]     Train net output #1: loss = 1.19382 (* 1 = 1.19382 loss)
I0713 08:53:46.601662 45537 sgd_solver.cpp:106] Iteration 60800, lr = 0.0015
I0713 08:55:06.702771 45537 solver.cpp:236] Iteration 60900, loss = 1.06561
I0713 08:55:06.703006 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:55:06.703035 45537 solver.cpp:252]     Train net output #1: loss = 1.12778 (* 1 = 1.12778 loss)
I0713 08:55:06.703045 45537 sgd_solver.cpp:106] Iteration 60900, lr = 0.0015
I0713 08:56:26.811630 45537 solver.cpp:236] Iteration 61000, loss = 1.05386
I0713 08:56:26.811780 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:56:26.811813 45537 solver.cpp:252]     Train net output #1: loss = 1.13106 (* 1 = 1.13106 loss)
I0713 08:56:26.811830 45537 sgd_solver.cpp:106] Iteration 61000, lr = 0.0015
I0713 08:57:46.914324 45537 solver.cpp:236] Iteration 61100, loss = 1.07329
I0713 08:57:46.914474 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 08:57:46.914520 45537 solver.cpp:252]     Train net output #1: loss = 1.06112 (* 1 = 1.06112 loss)
I0713 08:57:46.914533 45537 sgd_solver.cpp:106] Iteration 61100, lr = 0.0015
I0713 08:59:07.018156 45537 solver.cpp:236] Iteration 61200, loss = 1.09627
I0713 08:59:07.018349 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 08:59:07.018373 45537 solver.cpp:252]     Train net output #1: loss = 1.25388 (* 1 = 1.25388 loss)
I0713 08:59:07.018396 45537 sgd_solver.cpp:106] Iteration 61200, lr = 0.0015
I0713 09:00:27.137068 45537 solver.cpp:236] Iteration 61300, loss = 1.07972
I0713 09:00:27.137181 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:00:27.137197 45537 solver.cpp:252]     Train net output #1: loss = 1.11998 (* 1 = 1.11998 loss)
I0713 09:00:27.137210 45537 sgd_solver.cpp:106] Iteration 61300, lr = 0.0015
I0713 09:01:47.239372 45537 solver.cpp:236] Iteration 61400, loss = 1.08009
I0713 09:01:47.239517 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:01:47.239537 45537 solver.cpp:252]     Train net output #1: loss = 1.0907 (* 1 = 1.0907 loss)
I0713 09:01:47.239552 45537 sgd_solver.cpp:106] Iteration 61400, lr = 0.0015
I0713 09:03:06.538065 45537 solver.cpp:340] Iteration 61500, Testing net (#0)
I0713 09:04:23.384886 45537 solver.cpp:408]     Test net output #0: accuracy = 0.48375
I0713 09:04:23.385005 45537 solver.cpp:408]     Test net output #1: loss = 1.05006 (* 1 = 1.05006 loss)
I0713 09:04:24.152541 45537 solver.cpp:236] Iteration 61500, loss = 1.05955
I0713 09:04:24.152591 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:04:24.152609 45537 solver.cpp:252]     Train net output #1: loss = 0.975197 (* 1 = 0.975197 loss)
I0713 09:04:24.152626 45537 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0713 09:05:44.243443 45537 solver.cpp:236] Iteration 61600, loss = 1.0494
I0713 09:05:44.243587 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:05:44.243640 45537 solver.cpp:252]     Train net output #1: loss = 1.17415 (* 1 = 1.17415 loss)
I0713 09:05:44.243655 45537 sgd_solver.cpp:106] Iteration 61600, lr = 0.0015
I0713 09:07:04.360450 45537 solver.cpp:236] Iteration 61700, loss = 1.07129
I0713 09:07:04.360605 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:07:04.360640 45537 solver.cpp:252]     Train net output #1: loss = 1.10242 (* 1 = 1.10242 loss)
I0713 09:07:04.360663 45537 sgd_solver.cpp:106] Iteration 61700, lr = 0.0015
I0713 09:08:24.467509 45537 solver.cpp:236] Iteration 61800, loss = 1.05254
I0713 09:08:24.467703 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:08:24.467726 45537 solver.cpp:252]     Train net output #1: loss = 1.09983 (* 1 = 1.09983 loss)
I0713 09:08:24.467741 45537 sgd_solver.cpp:106] Iteration 61800, lr = 0.0015
I0713 09:09:14.137828 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:09:44.681391 45537 solver.cpp:236] Iteration 61900, loss = 1.05833
I0713 09:09:44.681583 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:09:44.681612 45537 solver.cpp:252]     Train net output #1: loss = 0.909741 (* 1 = 0.909741 loss)
I0713 09:09:44.681627 45537 sgd_solver.cpp:106] Iteration 61900, lr = 0.0015
I0713 09:11:04.986322 45537 solver.cpp:236] Iteration 62000, loss = 1.06423
I0713 09:11:04.986511 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:11:04.986531 45537 solver.cpp:252]     Train net output #1: loss = 1.00539 (* 1 = 1.00539 loss)
I0713 09:11:04.986548 45537 sgd_solver.cpp:106] Iteration 62000, lr = 0.0015
I0713 09:12:25.106917 45537 solver.cpp:236] Iteration 62100, loss = 1.04116
I0713 09:12:25.107113 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:12:25.107143 45537 solver.cpp:252]     Train net output #1: loss = 1.04489 (* 1 = 1.04489 loss)
I0713 09:12:25.107154 45537 sgd_solver.cpp:106] Iteration 62100, lr = 0.0015
I0713 09:13:45.422615 45537 solver.cpp:236] Iteration 62200, loss = 1.07853
I0713 09:13:45.422840 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 09:13:45.422886 45537 solver.cpp:252]     Train net output #1: loss = 1.30379 (* 1 = 1.30379 loss)
I0713 09:13:45.422902 45537 sgd_solver.cpp:106] Iteration 62200, lr = 0.0015
I0713 09:15:05.515839 45537 solver.cpp:236] Iteration 62300, loss = 1.08146
I0713 09:15:05.516031 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:15:05.516062 45537 solver.cpp:252]     Train net output #1: loss = 1.09418 (* 1 = 1.09418 loss)
I0713 09:15:05.516075 45537 sgd_solver.cpp:106] Iteration 62300, lr = 0.0015
I0713 09:16:25.616221 45537 solver.cpp:236] Iteration 62400, loss = 1.07311
I0713 09:16:25.616411 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:16:25.616441 45537 solver.cpp:252]     Train net output #1: loss = 1.0958 (* 1 = 1.0958 loss)
I0713 09:16:25.616456 45537 sgd_solver.cpp:106] Iteration 62400, lr = 0.0015
I0713 09:17:45.735997 45537 solver.cpp:236] Iteration 62500, loss = 1.06378
I0713 09:17:45.736264 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:17:45.736286 45537 solver.cpp:252]     Train net output #1: loss = 1.0669 (* 1 = 1.0669 loss)
I0713 09:17:45.736302 45537 sgd_solver.cpp:106] Iteration 62500, lr = 0.0015
I0713 09:19:05.927930 45537 solver.cpp:236] Iteration 62600, loss = 1.06723
I0713 09:19:05.928097 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:19:05.928119 45537 solver.cpp:252]     Train net output #1: loss = 1.02465 (* 1 = 1.02465 loss)
I0713 09:19:05.928139 45537 sgd_solver.cpp:106] Iteration 62600, lr = 0.0015
I0713 09:20:26.135886 45537 solver.cpp:236] Iteration 62700, loss = 1.05629
I0713 09:20:26.136133 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:20:26.136162 45537 solver.cpp:252]     Train net output #1: loss = 1.04614 (* 1 = 1.04614 loss)
I0713 09:20:26.136178 45537 sgd_solver.cpp:106] Iteration 62700, lr = 0.0015
I0713 09:21:46.241711 45537 solver.cpp:236] Iteration 62800, loss = 1.08041
I0713 09:21:46.241897 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:21:46.241921 45537 solver.cpp:252]     Train net output #1: loss = 0.956464 (* 1 = 0.956464 loss)
I0713 09:21:46.241935 45537 sgd_solver.cpp:106] Iteration 62800, lr = 0.0015
I0713 09:22:35.908723 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:23:06.352115 45537 solver.cpp:236] Iteration 62900, loss = 1.09265
I0713 09:23:06.352277 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:23:06.352298 45537 solver.cpp:252]     Train net output #1: loss = 1.11677 (* 1 = 1.11677 loss)
I0713 09:23:06.352311 45537 sgd_solver.cpp:106] Iteration 62900, lr = 0.0015
I0713 09:24:25.649610 45537 solver.cpp:340] Iteration 63000, Testing net (#0)
I0713 09:25:43.384955 45537 solver.cpp:408]     Test net output #0: accuracy = 0.44375
I0713 09:25:43.385144 45537 solver.cpp:408]     Test net output #1: loss = 1.06583 (* 1 = 1.06583 loss)
I0713 09:25:44.144429 45537 solver.cpp:236] Iteration 63000, loss = 1.03829
I0713 09:25:44.144485 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:25:44.144508 45537 solver.cpp:252]     Train net output #1: loss = 1.04966 (* 1 = 1.04966 loss)
I0713 09:25:44.144525 45537 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0713 09:27:04.267812 45537 solver.cpp:236] Iteration 63100, loss = 1.06644
I0713 09:27:04.268020 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:27:04.268043 45537 solver.cpp:252]     Train net output #1: loss = 1.09116 (* 1 = 1.09116 loss)
I0713 09:27:04.268056 45537 sgd_solver.cpp:106] Iteration 63100, lr = 0.0015
I0713 09:28:24.370718 45537 solver.cpp:236] Iteration 63200, loss = 1.09898
I0713 09:28:24.370932 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:28:24.370967 45537 solver.cpp:252]     Train net output #1: loss = 1.06041 (* 1 = 1.06041 loss)
I0713 09:28:24.370977 45537 sgd_solver.cpp:106] Iteration 63200, lr = 0.0015
I0713 09:29:44.485749 45537 solver.cpp:236] Iteration 63300, loss = 1.05775
I0713 09:29:44.485918 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:29:44.485939 45537 solver.cpp:252]     Train net output #1: loss = 1.19961 (* 1 = 1.19961 loss)
I0713 09:29:44.485952 45537 sgd_solver.cpp:106] Iteration 63300, lr = 0.0015
I0713 09:31:04.581540 45537 solver.cpp:236] Iteration 63400, loss = 1.07162
I0713 09:31:04.581754 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:31:04.581779 45537 solver.cpp:252]     Train net output #1: loss = 1.09579 (* 1 = 1.09579 loss)
I0713 09:31:04.581794 45537 sgd_solver.cpp:106] Iteration 63400, lr = 0.0015
I0713 09:32:24.691218 45537 solver.cpp:236] Iteration 63500, loss = 1.06045
I0713 09:32:24.691393 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:32:24.691427 45537 solver.cpp:252]     Train net output #1: loss = 1.05292 (* 1 = 1.05292 loss)
I0713 09:32:24.691440 45537 sgd_solver.cpp:106] Iteration 63500, lr = 0.0015
I0713 09:33:44.803616 45537 solver.cpp:236] Iteration 63600, loss = 1.06089
I0713 09:33:44.803820 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:33:44.803841 45537 solver.cpp:252]     Train net output #1: loss = 0.964306 (* 1 = 0.964306 loss)
I0713 09:33:44.803859 45537 sgd_solver.cpp:106] Iteration 63600, lr = 0.0015
I0713 09:35:05.011013 45537 solver.cpp:236] Iteration 63700, loss = 1.08271
I0713 09:35:05.011252 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:35:05.011286 45537 solver.cpp:252]     Train net output #1: loss = 1.19483 (* 1 = 1.19483 loss)
I0713 09:35:05.011297 45537 sgd_solver.cpp:106] Iteration 63700, lr = 0.0015
I0713 09:36:03.942121 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:36:32.529738 45537 solver.cpp:236] Iteration 63800, loss = 1.067
I0713 09:36:32.529798 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:36:32.529815 45537 solver.cpp:252]     Train net output #1: loss = 1.01818 (* 1 = 1.01818 loss)
I0713 09:36:32.529829 45537 sgd_solver.cpp:106] Iteration 63800, lr = 0.0015
I0713 09:37:55.060020 45537 solver.cpp:236] Iteration 63900, loss = 1.06208
I0713 09:37:55.060219 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:37:55.060243 45537 solver.cpp:252]     Train net output #1: loss = 1.02102 (* 1 = 1.02102 loss)
I0713 09:37:55.060258 45537 sgd_solver.cpp:106] Iteration 63900, lr = 0.0015
I0713 09:39:16.509567 45537 solver.cpp:236] Iteration 64000, loss = 1.05336
I0713 09:39:16.509768 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:39:16.509788 45537 solver.cpp:252]     Train net output #1: loss = 1.20493 (* 1 = 1.20493 loss)
I0713 09:39:16.509805 45537 sgd_solver.cpp:106] Iteration 64000, lr = 0.0015
I0713 09:40:37.844497 45537 solver.cpp:236] Iteration 64100, loss = 1.05424
I0713 09:40:37.844728 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:40:37.844758 45537 solver.cpp:252]     Train net output #1: loss = 0.940425 (* 1 = 0.940425 loss)
I0713 09:40:37.844786 45537 sgd_solver.cpp:106] Iteration 64100, lr = 0.0015
I0713 09:41:59.281134 45537 solver.cpp:236] Iteration 64200, loss = 1.04685
I0713 09:41:59.281298 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:41:59.281327 45537 solver.cpp:252]     Train net output #1: loss = 1.10042 (* 1 = 1.10042 loss)
I0713 09:41:59.281339 45537 sgd_solver.cpp:106] Iteration 64200, lr = 0.0015
I0713 09:43:20.723451 45537 solver.cpp:236] Iteration 64300, loss = 1.05891
I0713 09:43:20.723666 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:43:20.723698 45537 solver.cpp:252]     Train net output #1: loss = 0.879852 (* 1 = 0.879852 loss)
I0713 09:43:20.723708 45537 sgd_solver.cpp:106] Iteration 64300, lr = 0.0015
I0713 09:44:41.764590 45537 solver.cpp:236] Iteration 64400, loss = 1.06623
I0713 09:44:41.764807 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:44:41.764834 45537 solver.cpp:252]     Train net output #1: loss = 1.06988 (* 1 = 1.06988 loss)
I0713 09:44:41.764854 45537 sgd_solver.cpp:106] Iteration 64400, lr = 0.0015
I0713 09:46:01.987853 45537 solver.cpp:340] Iteration 64500, Testing net (#0)
I0713 09:47:22.603268 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4525
I0713 09:47:22.603628 45537 solver.cpp:408]     Test net output #1: loss = 1.06525 (* 1 = 1.06525 loss)
I0713 09:47:23.369771 45537 solver.cpp:236] Iteration 64500, loss = 1.06913
I0713 09:47:23.369845 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:47:23.369873 45537 solver.cpp:252]     Train net output #1: loss = 1.0298 (* 1 = 1.0298 loss)
I0713 09:47:23.369897 45537 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0713 09:48:44.700745 45537 solver.cpp:236] Iteration 64600, loss = 1.07468
I0713 09:48:44.700964 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:48:44.700984 45537 solver.cpp:252]     Train net output #1: loss = 1.0656 (* 1 = 1.0656 loss)
I0713 09:48:44.700996 45537 sgd_solver.cpp:106] Iteration 64600, lr = 0.0015
I0713 09:49:49.816087 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:50:06.204061 45537 solver.cpp:236] Iteration 64700, loss = 1.07245
I0713 09:50:06.204118 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:50:06.204138 45537 solver.cpp:252]     Train net output #1: loss = 1.0792 (* 1 = 1.0792 loss)
I0713 09:50:06.204150 45537 sgd_solver.cpp:106] Iteration 64700, lr = 0.0015
I0713 09:51:27.542835 45537 solver.cpp:236] Iteration 64800, loss = 1.08202
I0713 09:51:27.543053 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:51:27.543073 45537 solver.cpp:252]     Train net output #1: loss = 0.984092 (* 1 = 0.984092 loss)
I0713 09:51:27.543092 45537 sgd_solver.cpp:106] Iteration 64800, lr = 0.0015
I0713 09:52:47.830637 45537 solver.cpp:236] Iteration 64900, loss = 1.07928
I0713 09:52:47.831120 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:52:47.831166 45537 solver.cpp:252]     Train net output #1: loss = 1.09094 (* 1 = 1.09094 loss)
I0713 09:52:47.831184 45537 sgd_solver.cpp:106] Iteration 64900, lr = 0.0015
I0713 09:54:07.537012 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_65000.caffemodel
I0713 09:54:07.973538 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_65000.solverstate
I0713 09:54:08.768906 45537 solver.cpp:236] Iteration 65000, loss = 1.08533
I0713 09:54:08.768965 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:54:08.768986 45537 solver.cpp:252]     Train net output #1: loss = 1.15546 (* 1 = 1.15546 loss)
I0713 09:54:08.769004 45537 sgd_solver.cpp:106] Iteration 65000, lr = 0.0015
I0713 09:55:29.367081 45537 solver.cpp:236] Iteration 65100, loss = 1.07398
I0713 09:55:29.367269 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:55:29.367302 45537 solver.cpp:252]     Train net output #1: loss = 1.05239 (* 1 = 1.05239 loss)
I0713 09:55:29.367316 45537 sgd_solver.cpp:106] Iteration 65100, lr = 0.0015
I0713 09:56:50.457451 45537 solver.cpp:236] Iteration 65200, loss = 1.06791
I0713 09:56:50.457603 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:56:50.457624 45537 solver.cpp:252]     Train net output #1: loss = 0.965097 (* 1 = 0.965097 loss)
I0713 09:56:50.457639 45537 sgd_solver.cpp:106] Iteration 65200, lr = 0.0015
I0713 09:58:11.908910 45537 solver.cpp:236] Iteration 65300, loss = 1.07869
I0713 09:58:11.909054 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:58:11.909075 45537 solver.cpp:252]     Train net output #1: loss = 0.934307 (* 1 = 0.934307 loss)
I0713 09:58:11.909088 45537 sgd_solver.cpp:106] Iteration 65300, lr = 0.0015
I0713 09:59:32.745360 45537 solver.cpp:236] Iteration 65400, loss = 1.07854
I0713 09:59:32.745540 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:59:32.745564 45537 solver.cpp:252]     Train net output #1: loss = 1.19161 (* 1 = 1.19161 loss)
I0713 09:59:32.745580 45537 sgd_solver.cpp:106] Iteration 65400, lr = 0.0015
I0713 10:00:53.162724 45537 solver.cpp:236] Iteration 65500, loss = 1.07574
I0713 10:00:53.162914 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:00:53.162950 45537 solver.cpp:252]     Train net output #1: loss = 1.12511 (* 1 = 1.12511 loss)
I0713 10:00:53.162966 45537 sgd_solver.cpp:106] Iteration 65500, lr = 0.0015
I0713 10:02:14.094111 45537 solver.cpp:236] Iteration 65600, loss = 1.07942
I0713 10:02:14.094358 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:02:14.094388 45537 solver.cpp:252]     Train net output #1: loss = 1.06773 (* 1 = 1.06773 loss)
I0713 10:02:14.094410 45537 sgd_solver.cpp:106] Iteration 65600, lr = 0.0015
I0713 10:03:19.642845 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:03:35.101719 45537 solver.cpp:236] Iteration 65700, loss = 1.0575
I0713 10:03:35.101814 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:03:35.101836 45537 solver.cpp:252]     Train net output #1: loss = 0.951607 (* 1 = 0.951607 loss)
I0713 10:03:35.101853 45537 sgd_solver.cpp:106] Iteration 65700, lr = 0.0015
I0713 10:04:56.219074 45537 solver.cpp:236] Iteration 65800, loss = 1.06554
I0713 10:04:56.219295 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:04:56.219316 45537 solver.cpp:252]     Train net output #1: loss = 0.976943 (* 1 = 0.976943 loss)
I0713 10:04:56.219331 45537 sgd_solver.cpp:106] Iteration 65800, lr = 0.0015
I0713 10:06:17.601955 45537 solver.cpp:236] Iteration 65900, loss = 1.03518
I0713 10:06:17.602390 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:06:17.602412 45537 solver.cpp:252]     Train net output #1: loss = 1.04779 (* 1 = 1.04779 loss)
I0713 10:06:17.602427 45537 sgd_solver.cpp:106] Iteration 65900, lr = 0.0015
I0713 10:07:37.508669 45537 solver.cpp:340] Iteration 66000, Testing net (#0)
I0713 10:08:55.926928 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4525
I0713 10:08:55.927100 45537 solver.cpp:408]     Test net output #1: loss = 1.0635 (* 1 = 1.0635 loss)
I0713 10:08:56.700656 45537 solver.cpp:236] Iteration 66000, loss = 1.04989
I0713 10:08:56.700713 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 10:08:56.700732 45537 solver.cpp:252]     Train net output #1: loss = 1.19262 (* 1 = 1.19262 loss)
I0713 10:08:56.700747 45537 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0713 10:10:18.251746 45537 solver.cpp:236] Iteration 66100, loss = 1.07627
I0713 10:10:18.251929 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:10:18.251950 45537 solver.cpp:252]     Train net output #1: loss = 1.07448 (* 1 = 1.07448 loss)
I0713 10:10:18.251965 45537 sgd_solver.cpp:106] Iteration 66100, lr = 0.0015
I0713 10:11:39.540614 45537 solver.cpp:236] Iteration 66200, loss = 1.07898
I0713 10:11:39.540896 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:11:39.540927 45537 solver.cpp:252]     Train net output #1: loss = 1.04789 (* 1 = 1.04789 loss)
I0713 10:11:39.540951 45537 sgd_solver.cpp:106] Iteration 66200, lr = 0.0015
I0713 10:13:00.084877 45537 solver.cpp:236] Iteration 66300, loss = 1.05538
I0713 10:13:00.085019 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:13:00.085042 45537 solver.cpp:252]     Train net output #1: loss = 1.12722 (* 1 = 1.12722 loss)
I0713 10:13:00.085057 45537 sgd_solver.cpp:106] Iteration 66300, lr = 0.0015
I0713 10:14:20.558459 45537 solver.cpp:236] Iteration 66400, loss = 1.06563
I0713 10:14:20.562718 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:14:20.562752 45537 solver.cpp:252]     Train net output #1: loss = 1.13629 (* 1 = 1.13629 loss)
I0713 10:14:20.562767 45537 sgd_solver.cpp:106] Iteration 66400, lr = 0.0015
I0713 10:15:41.161519 45537 solver.cpp:236] Iteration 66500, loss = 1.03987
I0713 10:15:41.161656 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:15:41.161679 45537 solver.cpp:252]     Train net output #1: loss = 0.961954 (* 1 = 0.961954 loss)
I0713 10:15:41.161691 45537 sgd_solver.cpp:106] Iteration 66500, lr = 0.0015
I0713 10:16:53.751982 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:17:01.858695 45537 solver.cpp:236] Iteration 66600, loss = 1.07706
I0713 10:17:01.858775 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:17:01.858795 45537 solver.cpp:252]     Train net output #1: loss = 1.18124 (* 1 = 1.18124 loss)
I0713 10:17:01.858808 45537 sgd_solver.cpp:106] Iteration 66600, lr = 0.0015
I0713 10:18:23.205767 45537 solver.cpp:236] Iteration 66700, loss = 1.08459
I0713 10:18:23.205922 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:18:23.205947 45537 solver.cpp:252]     Train net output #1: loss = 0.996686 (* 1 = 0.996686 loss)
I0713 10:18:23.205965 45537 sgd_solver.cpp:106] Iteration 66700, lr = 0.0015
I0713 10:19:44.609488 45537 solver.cpp:236] Iteration 66800, loss = 1.06929
I0713 10:19:44.617733 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:19:44.617768 45537 solver.cpp:252]     Train net output #1: loss = 1.15237 (* 1 = 1.15237 loss)
I0713 10:19:44.617780 45537 sgd_solver.cpp:106] Iteration 66800, lr = 0.0015
I0713 10:21:05.191169 45537 solver.cpp:236] Iteration 66900, loss = 1.06169
I0713 10:21:05.210222 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:21:05.210247 45537 solver.cpp:252]     Train net output #1: loss = 0.971282 (* 1 = 0.971282 loss)
I0713 10:21:05.210263 45537 sgd_solver.cpp:106] Iteration 66900, lr = 0.0015
I0713 10:22:25.973827 45537 solver.cpp:236] Iteration 67000, loss = 1.05594
I0713 10:22:25.985931 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:22:25.985956 45537 solver.cpp:252]     Train net output #1: loss = 0.934617 (* 1 = 0.934617 loss)
I0713 10:22:25.985971 45537 sgd_solver.cpp:106] Iteration 67000, lr = 0.0015
I0713 10:23:46.812353 45537 solver.cpp:236] Iteration 67100, loss = 1.07718
I0713 10:23:46.819913 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:23:46.819941 45537 solver.cpp:252]     Train net output #1: loss = 0.96805 (* 1 = 0.96805 loss)
I0713 10:23:46.819955 45537 sgd_solver.cpp:106] Iteration 67100, lr = 0.0015
I0713 10:25:07.219892 45537 solver.cpp:236] Iteration 67200, loss = 1.08356
I0713 10:25:07.220120 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:25:07.220152 45537 solver.cpp:252]     Train net output #1: loss = 1.20914 (* 1 = 1.20914 loss)
I0713 10:25:07.220177 45537 sgd_solver.cpp:106] Iteration 67200, lr = 0.0015
I0713 10:26:28.218353 45537 solver.cpp:236] Iteration 67300, loss = 1.07474
I0713 10:26:28.218502 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:26:28.218523 45537 solver.cpp:252]     Train net output #1: loss = 1.1108 (* 1 = 1.1108 loss)
I0713 10:26:28.218535 45537 sgd_solver.cpp:106] Iteration 67300, lr = 0.0015
I0713 10:27:48.578994 45537 solver.cpp:236] Iteration 67400, loss = 1.08589
I0713 10:27:48.579172 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:27:48.579198 45537 solver.cpp:252]     Train net output #1: loss = 1.17006 (* 1 = 1.17006 loss)
I0713 10:27:48.579210 45537 sgd_solver.cpp:106] Iteration 67400, lr = 0.0015
I0713 10:29:09.234933 45537 solver.cpp:340] Iteration 67500, Testing net (#0)
I0713 10:30:27.408676 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:30:28.983901 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4475
I0713 10:30:28.983978 45537 solver.cpp:408]     Test net output #1: loss = 1.06894 (* 1 = 1.06894 loss)
I0713 10:30:29.746567 45537 solver.cpp:236] Iteration 67500, loss = 1.04877
I0713 10:30:29.746647 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:30:29.746682 45537 solver.cpp:252]     Train net output #1: loss = 0.980117 (* 1 = 0.980117 loss)
I0713 10:30:29.746706 45537 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0713 10:31:51.178014 45537 solver.cpp:236] Iteration 67600, loss = 1.07141
I0713 10:31:51.178207 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:31:51.178237 45537 solver.cpp:252]     Train net output #1: loss = 1.04368 (* 1 = 1.04368 loss)
I0713 10:31:51.178253 45537 sgd_solver.cpp:106] Iteration 67600, lr = 0.0015
I0713 10:33:12.355944 45537 solver.cpp:236] Iteration 67700, loss = 1.04028
I0713 10:33:12.356122 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:33:12.356155 45537 solver.cpp:252]     Train net output #1: loss = 1.04413 (* 1 = 1.04413 loss)
I0713 10:33:12.356168 45537 sgd_solver.cpp:106] Iteration 67700, lr = 0.0015
I0713 10:34:32.780488 45537 solver.cpp:236] Iteration 67800, loss = 1.08589
I0713 10:34:32.792419 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:34:32.792444 45537 solver.cpp:252]     Train net output #1: loss = 1.01271 (* 1 = 1.01271 loss)
I0713 10:34:32.792464 45537 sgd_solver.cpp:106] Iteration 67800, lr = 0.0015
I0713 10:35:53.084170 45537 solver.cpp:236] Iteration 67900, loss = 1.06574
I0713 10:35:53.101917 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:35:53.101958 45537 solver.cpp:252]     Train net output #1: loss = 1.1239 (* 1 = 1.1239 loss)
I0713 10:35:53.101982 45537 sgd_solver.cpp:106] Iteration 67900, lr = 0.0015
I0713 10:37:13.679580 45537 solver.cpp:236] Iteration 68000, loss = 1.06462
I0713 10:37:13.679801 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:37:13.679822 45537 solver.cpp:252]     Train net output #1: loss = 0.967927 (* 1 = 0.967927 loss)
I0713 10:37:13.679844 45537 sgd_solver.cpp:106] Iteration 68000, lr = 0.0015
I0713 10:38:34.000335 45537 solver.cpp:236] Iteration 68100, loss = 1.07439
I0713 10:38:34.000541 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:38:34.000566 45537 solver.cpp:252]     Train net output #1: loss = 1.06877 (* 1 = 1.06877 loss)
I0713 10:38:34.000581 45537 sgd_solver.cpp:106] Iteration 68100, lr = 0.0015
I0713 10:39:56.875344 45537 solver.cpp:236] Iteration 68200, loss = 1.07139
I0713 10:39:56.875531 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:39:56.875557 45537 solver.cpp:252]     Train net output #1: loss = 1.14969 (* 1 = 1.14969 loss)
I0713 10:39:56.875578 45537 sgd_solver.cpp:106] Iteration 68200, lr = 0.0015
I0713 10:41:22.094461 45537 solver.cpp:236] Iteration 68300, loss = 1.05989
I0713 10:41:22.094609 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:41:22.094647 45537 solver.cpp:252]     Train net output #1: loss = 1.01877 (* 1 = 1.01877 loss)
I0713 10:41:22.094663 45537 sgd_solver.cpp:106] Iteration 68300, lr = 0.0015
I0713 10:42:48.328788 45537 solver.cpp:236] Iteration 68400, loss = 1.06426
I0713 10:42:48.328940 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:42:48.328970 45537 solver.cpp:252]     Train net output #1: loss = 1.04709 (* 1 = 1.04709 loss)
I0713 10:42:48.328994 45537 sgd_solver.cpp:106] Iteration 68400, lr = 0.0015
I0713 10:44:12.838002 45537 solver.cpp:236] Iteration 68500, loss = 1.06522
I0713 10:44:12.838214 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:44:12.838258 45537 solver.cpp:252]     Train net output #1: loss = 1.01511 (* 1 = 1.01511 loss)
I0713 10:44:12.838284 45537 sgd_solver.cpp:106] Iteration 68500, lr = 0.0015
I0713 10:44:14.596494 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:45:37.579509 45537 solver.cpp:236] Iteration 68600, loss = 1.04857
I0713 10:45:37.579681 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:45:37.579715 45537 solver.cpp:252]     Train net output #1: loss = 1.06588 (* 1 = 1.06588 loss)
I0713 10:45:37.579735 45537 sgd_solver.cpp:106] Iteration 68600, lr = 0.0015
I0713 10:47:00.473907 45537 solver.cpp:236] Iteration 68700, loss = 1.07316
I0713 10:47:00.474191 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:47:00.474247 45537 solver.cpp:252]     Train net output #1: loss = 1.12858 (* 1 = 1.12858 loss)
I0713 10:47:00.474295 45537 sgd_solver.cpp:106] Iteration 68700, lr = 0.0015
I0713 10:48:22.098858 45537 solver.cpp:236] Iteration 68800, loss = 1.06373
I0713 10:48:22.099041 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:48:22.099082 45537 solver.cpp:252]     Train net output #1: loss = 1.0492 (* 1 = 1.0492 loss)
I0713 10:48:22.099102 45537 sgd_solver.cpp:106] Iteration 68800, lr = 0.0015
I0713 10:49:44.415591 45537 solver.cpp:236] Iteration 68900, loss = 1.0547
I0713 10:49:44.415779 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:49:44.415808 45537 solver.cpp:252]     Train net output #1: loss = 1.0519 (* 1 = 1.0519 loss)
I0713 10:49:44.415822 45537 sgd_solver.cpp:106] Iteration 68900, lr = 0.0015
I0713 10:51:07.178186 45537 solver.cpp:340] Iteration 69000, Testing net (#0)
I0713 10:52:31.772305 45537 solver.cpp:408]     Test net output #0: accuracy = 0.4625
I0713 10:52:31.772505 45537 solver.cpp:408]     Test net output #1: loss = 1.06512 (* 1 = 1.06512 loss)
I0713 10:52:32.544034 45537 solver.cpp:236] Iteration 69000, loss = 1.0839
I0713 10:52:32.544091 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:52:32.544111 45537 solver.cpp:252]     Train net output #1: loss = 1.21321 (* 1 = 1.21321 loss)
I0713 10:52:32.544128 45537 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0713 10:53:55.806248 45537 solver.cpp:236] Iteration 69100, loss = 1.07426
I0713 10:53:55.806434 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:53:55.806460 45537 solver.cpp:252]     Train net output #1: loss = 1.13851 (* 1 = 1.13851 loss)
I0713 10:53:55.806480 45537 sgd_solver.cpp:106] Iteration 69100, lr = 0.0015
I0713 10:55:20.316689 45537 solver.cpp:236] Iteration 69200, loss = 1.07354
I0713 10:55:20.316925 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:55:20.316952 45537 solver.cpp:252]     Train net output #1: loss = 1.08098 (* 1 = 1.08098 loss)
I0713 10:55:20.316970 45537 sgd_solver.cpp:106] Iteration 69200, lr = 0.0015
I0713 10:56:47.417098 45537 solver.cpp:236] Iteration 69300, loss = 1.0656
I0713 10:56:47.417237 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 10:56:47.417258 45537 solver.cpp:252]     Train net output #1: loss = 0.900439 (* 1 = 0.900439 loss)
I0713 10:56:47.417270 45537 sgd_solver.cpp:106] Iteration 69300, lr = 0.0015
I0713 10:58:12.396576 45537 solver.cpp:236] Iteration 69400, loss = 1.0647
I0713 10:58:12.396713 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:58:12.396739 45537 solver.cpp:252]     Train net output #1: loss = 1.0458 (* 1 = 1.0458 loss)
I0713 10:58:12.396754 45537 sgd_solver.cpp:106] Iteration 69400, lr = 0.0015
I0713 10:58:22.283567 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:59:37.536420 45537 solver.cpp:236] Iteration 69500, loss = 1.06903
I0713 10:59:37.537710 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:59:37.537741 45537 solver.cpp:252]     Train net output #1: loss = 1.04966 (* 1 = 1.04966 loss)
I0713 10:59:37.537757 45537 sgd_solver.cpp:106] Iteration 69500, lr = 0.0015
I0713 11:01:04.481127 45537 solver.cpp:236] Iteration 69600, loss = 1.05127
I0713 11:01:04.481829 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:01:04.481855 45537 solver.cpp:252]     Train net output #1: loss = 1.0446 (* 1 = 1.0446 loss)
I0713 11:01:04.481873 45537 sgd_solver.cpp:106] Iteration 69600, lr = 0.0015
I0713 11:02:31.417421 45537 solver.cpp:236] Iteration 69700, loss = 1.06462
I0713 11:02:31.417573 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:02:31.417608 45537 solver.cpp:252]     Train net output #1: loss = 1.01539 (* 1 = 1.01539 loss)
I0713 11:02:31.417630 45537 sgd_solver.cpp:106] Iteration 69700, lr = 0.0015
I0713 11:03:59.180891 45537 solver.cpp:236] Iteration 69800, loss = 1.06239
I0713 11:03:59.181025 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:03:59.181057 45537 solver.cpp:252]     Train net output #1: loss = 1.06178 (* 1 = 1.06178 loss)
I0713 11:03:59.181072 45537 sgd_solver.cpp:106] Iteration 69800, lr = 0.0015
I0713 11:05:24.235852 45537 solver.cpp:236] Iteration 69900, loss = 1.08093
I0713 11:05:24.236068 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:05:24.236093 45537 solver.cpp:252]     Train net output #1: loss = 1.14582 (* 1 = 1.14582 loss)
I0713 11:05:24.236106 45537 sgd_solver.cpp:106] Iteration 69900, lr = 0.0015
I0713 11:06:48.609166 45537 solver.cpp:461] Snapshotting to binary proto file models/resultlayer_iter_70000.caffemodel
I0713 11:06:48.782295 45537 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/resultlayer_iter_70000.solverstate
I0713 11:06:49.554978 45537 solver.cpp:236] Iteration 70000, loss = 1.06691
I0713 11:06:49.555071 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:06:49.555091 45537 solver.cpp:252]     Train net output #1: loss = 1.12037 (* 1 = 1.12037 loss)
I0713 11:06:49.555106 45537 sgd_solver.cpp:106] Iteration 70000, lr = 0.0015
I0713 11:08:15.069010 45537 solver.cpp:236] Iteration 70100, loss = 1.06868
I0713 11:08:15.069164 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:08:15.069198 45537 solver.cpp:252]     Train net output #1: loss = 1.07094 (* 1 = 1.07094 loss)
I0713 11:08:15.069216 45537 sgd_solver.cpp:106] Iteration 70100, lr = 0.0015
I0713 11:09:48.645828 45537 solver.cpp:236] Iteration 70200, loss = 1.07426
I0713 11:09:48.646024 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:09:48.646049 45537 solver.cpp:252]     Train net output #1: loss = 1.06451 (* 1 = 1.06451 loss)
I0713 11:09:48.646064 45537 sgd_solver.cpp:106] Iteration 70200, lr = 0.0015
I0713 11:11:29.511865 45537 solver.cpp:236] Iteration 70300, loss = 1.06824
I0713 11:11:29.512027 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:11:29.512048 45537 solver.cpp:252]     Train net output #1: loss = 1.1181 (* 1 = 1.1181 loss)
I0713 11:11:29.512063 45537 sgd_solver.cpp:106] Iteration 70300, lr = 0.0015
I0713 11:13:09.708312 45537 solver.cpp:236] Iteration 70400, loss = 1.08528
I0713 11:13:09.709314 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:13:09.709339 45537 solver.cpp:252]     Train net output #1: loss = 1.0247 (* 1 = 1.0247 loss)
I0713 11:13:09.709353 45537 sgd_solver.cpp:106] Iteration 70400, lr = 0.0015
I0713 11:13:21.571128 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:14:44.595532 45537 solver.cpp:340] Iteration 70500, Testing net (#0)
I0713 11:16:24.058827 45537 solver.cpp:408]     Test net output #0: accuracy = 0.465
I0713 11:16:24.059053 45537 solver.cpp:408]     Test net output #1: loss = 1.0619 (* 1 = 1.0619 loss)
I0713 11:16:24.818287 45537 solver.cpp:236] Iteration 70500, loss = 1.07778
I0713 11:16:24.818325 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:16:24.818338 45537 solver.cpp:252]     Train net output #1: loss = 0.985774 (* 1 = 0.985774 loss)
I0713 11:16:24.818351 45537 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0713 11:17:57.896965 45537 solver.cpp:236] Iteration 70600, loss = 1.07982
I0713 11:17:57.897137 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:17:57.897158 45537 solver.cpp:252]     Train net output #1: loss = 1.05586 (* 1 = 1.05586 loss)
I0713 11:17:57.897176 45537 sgd_solver.cpp:106] Iteration 70600, lr = 0.0015
I0713 11:19:31.831709 45537 solver.cpp:236] Iteration 70700, loss = 1.077
I0713 11:19:31.831852 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:19:31.831892 45537 solver.cpp:252]     Train net output #1: loss = 1.12063 (* 1 = 1.12063 loss)
I0713 11:19:31.831905 45537 sgd_solver.cpp:106] Iteration 70700, lr = 0.0015
I0713 11:21:05.782851 45537 solver.cpp:236] Iteration 70800, loss = 1.08317
I0713 11:21:05.790717 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 11:21:05.790761 45537 solver.cpp:252]     Train net output #1: loss = 0.94957 (* 1 = 0.94957 loss)
I0713 11:21:05.790777 45537 sgd_solver.cpp:106] Iteration 70800, lr = 0.0015
I0713 11:22:46.061779 45537 solver.cpp:236] Iteration 70900, loss = 1.0572
I0713 11:22:46.061957 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 11:22:46.061995 45537 solver.cpp:252]     Train net output #1: loss = 1.18552 (* 1 = 1.18552 loss)
I0713 11:22:46.062007 45537 sgd_solver.cpp:106] Iteration 70900, lr = 0.0015
I0713 11:24:19.472592 45537 solver.cpp:236] Iteration 71000, loss = 1.04457
I0713 11:24:19.472821 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:24:19.472847 45537 solver.cpp:252]     Train net output #1: loss = 1.08163 (* 1 = 1.08163 loss)
I0713 11:24:19.472862 45537 sgd_solver.cpp:106] Iteration 71000, lr = 0.0015
I0713 11:25:46.452997 45537 solver.cpp:236] Iteration 71100, loss = 1.05163
I0713 11:25:46.453125 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:25:46.453150 45537 solver.cpp:252]     Train net output #1: loss = 0.979321 (* 1 = 0.979321 loss)
I0713 11:25:46.453166 45537 sgd_solver.cpp:106] Iteration 71100, lr = 0.0015
I0713 11:27:15.299504 45537 solver.cpp:236] Iteration 71200, loss = 1.06751
I0713 11:27:15.299707 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:27:15.299733 45537 solver.cpp:252]     Train net output #1: loss = 0.966097 (* 1 = 0.966097 loss)
I0713 11:27:15.299747 45537 sgd_solver.cpp:106] Iteration 71200, lr = 0.0015
I0713 11:28:43.916530 45537 solver.cpp:236] Iteration 71300, loss = 1.07682
I0713 11:28:43.916690 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:28:43.916715 45537 solver.cpp:252]     Train net output #1: loss = 1.06218 (* 1 = 1.06218 loss)
I0713 11:28:43.916731 45537 sgd_solver.cpp:106] Iteration 71300, lr = 0.0015
I0713 11:29:01.999572 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:30:11.090107 45537 solver.cpp:236] Iteration 71400, loss = 1.07192
I0713 11:30:11.090319 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:30:11.090344 45537 solver.cpp:252]     Train net output #1: loss = 1.01895 (* 1 = 1.01895 loss)
I0713 11:30:11.090363 45537 sgd_solver.cpp:106] Iteration 71400, lr = 0.0015
I0713 11:31:38.651224 45537 solver.cpp:236] Iteration 71500, loss = 1.08109
I0713 11:31:38.651407 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:31:38.651446 45537 solver.cpp:252]     Train net output #1: loss = 1.12764 (* 1 = 1.12764 loss)
I0713 11:31:38.651456 45537 sgd_solver.cpp:106] Iteration 71500, lr = 0.0015
I0713 11:33:07.960650 45537 solver.cpp:236] Iteration 71600, loss = 1.05682
I0713 11:33:07.960840 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:33:07.960861 45537 solver.cpp:252]     Train net output #1: loss = 0.9691 (* 1 = 0.9691 loss)
I0713 11:33:07.960875 45537 sgd_solver.cpp:106] Iteration 71600, lr = 0.0015
I0713 11:34:37.850313 45537 solver.cpp:236] Iteration 71700, loss = 1.05107
I0713 11:34:37.850476 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:34:37.850497 45537 solver.cpp:252]     Train net output #1: loss = 1.14939 (* 1 = 1.14939 loss)
I0713 11:34:37.850512 45537 sgd_solver.cpp:106] Iteration 71700, lr = 0.0015
I0713 11:36:04.380053 45537 solver.cpp:236] Iteration 71800, loss = 1.06372
I0713 11:36:04.380265 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:36:04.380285 45537 solver.cpp:252]     Train net output #1: loss = 1.05114 (* 1 = 1.05114 loss)
I0713 11:36:04.380300 45537 sgd_solver.cpp:106] Iteration 71800, lr = 0.0015
I0713 11:37:31.780598 45537 solver.cpp:236] Iteration 71900, loss = 1.08405
I0713 11:37:31.780748 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:37:31.780769 45537 solver.cpp:252]     Train net output #1: loss = 1.12226 (* 1 = 1.12226 loss)
I0713 11:37:31.780783 45537 sgd_solver.cpp:106] Iteration 71900, lr = 0.0015
I0713 11:38:56.329169 45537 solver.cpp:340] Iteration 72000, Testing net (#0)
I0713 11:40:22.186444 45537 solver.cpp:408]     Test net output #0: accuracy = 0.44375
I0713 11:40:22.186586 45537 solver.cpp:408]     Test net output #1: loss = 1.07303 (* 1 = 1.07303 loss)
I0713 11:40:22.952435 45537 solver.cpp:236] Iteration 72000, loss = 1.07255
I0713 11:40:22.952517 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:40:22.952546 45537 solver.cpp:252]     Train net output #1: loss = 1.0809 (* 1 = 1.0809 loss)
I0713 11:40:22.952570 45537 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0713 11:41:51.129590 45537 solver.cpp:236] Iteration 72100, loss = 1.06874
I0713 11:41:51.129817 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:41:51.129837 45537 solver.cpp:252]     Train net output #1: loss = 1.06842 (* 1 = 1.06842 loss)
I0713 11:41:51.129853 45537 sgd_solver.cpp:106] Iteration 72100, lr = 0.0015
I0713 11:43:15.626243 45537 solver.cpp:236] Iteration 72200, loss = 1.07922
I0713 11:43:15.626453 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:43:15.626482 45537 solver.cpp:252]     Train net output #1: loss = 1.04806 (* 1 = 1.04806 loss)
I0713 11:43:15.626531 45537 sgd_solver.cpp:106] Iteration 72200, lr = 0.0015
I0713 11:43:38.951035 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:44:36.040195 45537 solver.cpp:236] Iteration 72300, loss = 1.05097
I0713 11:44:36.040407 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:44:36.040429 45537 solver.cpp:252]     Train net output #1: loss = 1.04668 (* 1 = 1.04668 loss)
I0713 11:44:36.040448 45537 sgd_solver.cpp:106] Iteration 72300, lr = 0.0015
I0713 11:45:56.643936 45537 solver.cpp:236] Iteration 72400, loss = 1.07249
I0713 11:45:56.644191 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:45:56.644210 45537 solver.cpp:252]     Train net output #1: loss = 0.97511 (* 1 = 0.97511 loss)
I0713 11:45:56.644227 45537 sgd_solver.cpp:106] Iteration 72400, lr = 0.0015
I0713 11:47:17.699301 45537 solver.cpp:236] Iteration 72500, loss = 1.06333
I0713 11:47:17.699477 45537 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:47:17.699497 45537 solver.cpp:252]     Train net output #1: loss = 1.17103 (* 1 = 1.17103 loss)
I0713 11:47:17.699511 45537 sgd_solver.cpp:106] Iteration 72500, lr = 0.0015
I0713 11:48:38.322234 45537 solver.cpp:236] Iteration 72600, loss = 1.07805
I0713 11:48:38.322433 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:48:38.322453 45537 solver.cpp:252]     Train net output #1: loss = 1.04733 (* 1 = 1.04733 loss)
I0713 11:48:38.322469 45537 sgd_solver.cpp:106] Iteration 72600, lr = 0.0015
I0713 11:49:58.906255 45537 solver.cpp:236] Iteration 72700, loss = 1.07263
I0713 11:49:58.906399 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:49:58.906421 45537 solver.cpp:252]     Train net output #1: loss = 1.12174 (* 1 = 1.12174 loss)
I0713 11:49:58.906438 45537 sgd_solver.cpp:106] Iteration 72700, lr = 0.0015
I0713 11:51:19.627341 45537 solver.cpp:236] Iteration 72800, loss = 1.07565
I0713 11:51:19.627512 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:51:19.627547 45537 solver.cpp:252]     Train net output #1: loss = 1.12492 (* 1 = 1.12492 loss)
I0713 11:51:19.627559 45537 sgd_solver.cpp:106] Iteration 72800, lr = 0.0015
I0713 11:52:40.568796 45537 solver.cpp:236] Iteration 72900, loss = 1.08644
I0713 11:52:40.568980 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:52:40.569013 45537 solver.cpp:252]     Train net output #1: loss = 1.05678 (* 1 = 1.05678 loss)
I0713 11:52:40.569036 45537 sgd_solver.cpp:106] Iteration 72900, lr = 0.0015
I0713 11:54:04.176867 45537 solver.cpp:236] Iteration 73000, loss = 1.06855
I0713 11:54:04.177050 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:54:04.177088 45537 solver.cpp:252]     Train net output #1: loss = 1.01887 (* 1 = 1.01887 loss)
I0713 11:54:04.177098 45537 sgd_solver.cpp:106] Iteration 73000, lr = 0.0015
I0713 11:55:24.705334 45537 solver.cpp:236] Iteration 73100, loss = 1.05113
I0713 11:55:24.705548 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:55:24.705580 45537 solver.cpp:252]     Train net output #1: loss = 1.07445 (* 1 = 1.07445 loss)
I0713 11:55:24.705603 45537 sgd_solver.cpp:106] Iteration 73100, lr = 0.0015
I0713 11:56:45.321432 45537 solver.cpp:236] Iteration 73200, loss = 1.08319
I0713 11:56:45.321666 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:56:45.321687 45537 solver.cpp:252]     Train net output #1: loss = 1.02128 (* 1 = 1.02128 loss)
I0713 11:56:45.321702 45537 sgd_solver.cpp:106] Iteration 73200, lr = 0.0015
I0713 11:57:08.741596 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:58:06.111156 45537 solver.cpp:236] Iteration 73300, loss = 1.0834
I0713 11:58:06.111433 45537 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 11:58:06.111461 45537 solver.cpp:252]     Train net output #1: loss = 0.959591 (* 1 = 0.959591 loss)
I0713 11:58:06.111475 45537 sgd_solver.cpp:106] Iteration 73300, lr = 0.0015
I0713 11:59:26.755199 45537 solver.cpp:236] Iteration 73400, loss = 1.05612
I0713 11:59:26.755424 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:59:26.755463 45537 solver.cpp:252]     Train net output #1: loss = 1.09949 (* 1 = 1.09949 loss)
I0713 11:59:26.755475 45537 sgd_solver.cpp:106] Iteration 73400, lr = 0.0015
I0713 12:00:46.498651 45537 solver.cpp:340] Iteration 73500, Testing net (#0)
I0713 12:02:07.360311 45537 solver.cpp:408]     Test net output #0: accuracy = 0.475
I0713 12:02:07.360648 45537 solver.cpp:408]     Test net output #1: loss = 1.05038 (* 1 = 1.05038 loss)
I0713 12:02:08.123657 45537 solver.cpp:236] Iteration 73500, loss = 1.07026
I0713 12:02:08.123708 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 12:02:08.123724 45537 solver.cpp:252]     Train net output #1: loss = 1.20884 (* 1 = 1.20884 loss)
I0713 12:02:08.123744 45537 sgd_solver.cpp:106] Iteration 73500, lr = 0.0015
I0713 12:03:29.645954 45537 solver.cpp:236] Iteration 73600, loss = 1.05263
I0713 12:03:29.646190 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:03:29.646211 45537 solver.cpp:252]     Train net output #1: loss = 1.07885 (* 1 = 1.07885 loss)
I0713 12:03:29.646226 45537 sgd_solver.cpp:106] Iteration 73600, lr = 0.0015
I0713 12:04:49.956153 45537 solver.cpp:236] Iteration 73700, loss = 1.07569
I0713 12:04:49.956322 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:04:49.956343 45537 solver.cpp:252]     Train net output #1: loss = 1.11192 (* 1 = 1.11192 loss)
I0713 12:04:49.956363 45537 sgd_solver.cpp:106] Iteration 73700, lr = 0.0015
I0713 12:06:10.159909 45537 solver.cpp:236] Iteration 73800, loss = 1.06135
I0713 12:06:10.160148 45537 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:06:10.160178 45537 solver.cpp:252]     Train net output #1: loss = 1.04671 (* 1 = 1.04671 loss)
I0713 12:06:10.160192 45537 sgd_solver.cpp:106] Iteration 73800, lr = 0.0015
I0713 12:07:30.567585 45537 solver.cpp:236] Iteration 73900, loss = 1.06538
I0713 12:07:30.567816 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 12:07:30.567837 45537 solver.cpp:252]     Train net output #1: loss = 1.06463 (* 1 = 1.06463 loss)
I0713 12:07:30.567852 45537 sgd_solver.cpp:106] Iteration 73900, lr = 0.0015
I0713 12:08:51.090598 45537 solver.cpp:236] Iteration 74000, loss = 1.06008
I0713 12:08:51.090867 45537 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 12:08:51.090894 45537 solver.cpp:252]     Train net output #1: loss = 0.968786 (* 1 = 0.968786 loss)
I0713 12:08:51.090904 45537 sgd_solver.cpp:106] Iteration 74000, lr = 0.0015
I0713 12:10:11.484158 45537 solver.cpp:236] Iteration 74100, loss = 1.09301
I0713 12:10:11.484410 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 12:10:11.484427 45537 solver.cpp:252]     Train net output #1: loss = 1.09321 (* 1 = 1.09321 loss)
I0713 12:10:11.484443 45537 sgd_solver.cpp:106] Iteration 74100, lr = 0.0015
I0713 12:10:41.428241 45537 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 12:11:32.414268 45537 solver.cpp:236] Iteration 74200, loss = 1.07199
I0713 12:11:32.414484 45537 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 12:11:32.414512 45537 solver.cpp:252]     Train net output #1: loss = 1.05309 (* 1 = 1.05309 loss)
I0713 12:11:32.414542 45537 sgd_solver.cpp:106] Iteration 74200, lr = 0.0015
I0713 12:12:53.347661 45537 solver.cpp:236] Iteration 74300, loss = 1.10397
I0713 12:12:53.347815 45537 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 12:12:53.347846 45537 solver.cpp:252]     Train net output #1: loss = 1.15716 (* 1 = 1.15716 loss)
I0713 12:12:53.347859 45537 sgd_solver.cpp:106] Iteration 74300, lr = 0.0015
F0713 12:12:57.958665 45539 data_transformer.cpp:240] Check failed: height <= img_height (1000 vs. 56) 
