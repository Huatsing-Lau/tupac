Log file created at: 2016/07/13 09:13:13
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0713 09:13:13.053930 47888 caffe.cpp:184] Using GPUs 1
I0713 09:13:13.356842 47888 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 1500
base_lr: 0.02
display: 100
max_iter: 500000
lr_policy: "step"
gamma: 0.1
momentum: 0.85
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/featurelayer3"
solver_mode: GPU
device_id: 1
net: "train_val-featurelayer-3stack.prototxt"
test_initialization: false
average_loss: 50
I0713 09:13:13.357085 47888 solver.cpp:90] Creating training net from net file: train_val-featurelayer-3stack.prototxt
I0713 09:13:13.358151 47888 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0713 09:13:13.358461 47888 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "conv53"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0713 09:13:13.360890 47888 layer_factory.hpp:76] Creating layer data
I0713 09:13:13.360937 47888 net.cpp:106] Creating Layer data
I0713 09:13:13.360954 47888 net.cpp:411] data -> data
I0713 09:13:13.360990 47888 net.cpp:411] data -> label
I0713 09:13:13.361438 47888 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0713 09:13:13.375280 47888 image_data_layer.cpp:46] Shuffling data
I0713 09:13:13.378330 47888 image_data_layer.cpp:51] A total of 23544 images.
I0713 09:13:13.436801 47888 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0713 09:13:13.721881 47888 net.cpp:150] Setting up data
I0713 09:13:13.721937 47888 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0713 09:13:13.721951 47888 net.cpp:157] Top shape: 8 (8)
I0713 09:13:13.721961 47888 net.cpp:165] Memory required for data: 96000032
I0713 09:13:13.721976 47888 layer_factory.hpp:76] Creating layer label_data_1_split
I0713 09:13:13.721997 47888 net.cpp:106] Creating Layer label_data_1_split
I0713 09:13:13.722010 47888 net.cpp:454] label_data_1_split <- label
I0713 09:13:13.722030 47888 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0713 09:13:13.722045 47888 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0713 09:13:13.722110 47888 net.cpp:150] Setting up label_data_1_split
I0713 09:13:13.722123 47888 net.cpp:157] Top shape: 8 (8)
I0713 09:13:13.722132 47888 net.cpp:157] Top shape: 8 (8)
I0713 09:13:13.722141 47888 net.cpp:165] Memory required for data: 96000096
I0713 09:13:13.722149 47888 layer_factory.hpp:76] Creating layer conv11
I0713 09:13:13.722175 47888 net.cpp:106] Creating Layer conv11
I0713 09:13:13.722185 47888 net.cpp:454] conv11 <- data
I0713 09:13:13.722199 47888 net.cpp:411] conv11 -> conv11
I0713 09:13:13.882925 47888 net.cpp:150] Setting up conv11
I0713 09:13:13.882977 47888 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:13.883020 47888 net.cpp:165] Memory required for data: 1120000096
I0713 09:13:13.883054 47888 layer_factory.hpp:76] Creating layer relu11
I0713 09:13:13.883074 47888 net.cpp:106] Creating Layer relu11
I0713 09:13:13.883085 47888 net.cpp:454] relu11 <- conv11
I0713 09:13:13.883096 47888 net.cpp:397] relu11 -> conv11 (in-place)
I0713 09:13:13.883297 47888 net.cpp:150] Setting up relu11
I0713 09:13:13.883316 47888 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:13.883324 47888 net.cpp:165] Memory required for data: 2144000096
I0713 09:13:13.883333 47888 layer_factory.hpp:76] Creating layer conv12
I0713 09:13:13.883355 47888 net.cpp:106] Creating Layer conv12
I0713 09:13:13.883364 47888 net.cpp:454] conv12 <- conv11
I0713 09:13:13.883375 47888 net.cpp:411] conv12 -> conv12
I0713 09:13:13.887977 47888 net.cpp:150] Setting up conv12
I0713 09:13:13.888005 47888 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:13.888015 47888 net.cpp:165] Memory required for data: 3168000096
I0713 09:13:13.888031 47888 layer_factory.hpp:76] Creating layer relu12
I0713 09:13:13.888044 47888 net.cpp:106] Creating Layer relu12
I0713 09:13:13.888053 47888 net.cpp:454] relu12 <- conv12
I0713 09:13:13.888067 47888 net.cpp:397] relu12 -> conv12 (in-place)
I0713 09:13:13.888413 47888 net.cpp:150] Setting up relu12
I0713 09:13:13.888434 47888 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0713 09:13:13.888443 47888 net.cpp:165] Memory required for data: 4192000096
I0713 09:13:13.888453 47888 layer_factory.hpp:76] Creating layer pool1
I0713 09:13:13.888471 47888 net.cpp:106] Creating Layer pool1
I0713 09:13:13.888480 47888 net.cpp:454] pool1 <- conv12
I0713 09:13:13.888491 47888 net.cpp:411] pool1 -> pool1
I0713 09:13:13.888731 47888 net.cpp:150] Setting up pool1
I0713 09:13:13.888751 47888 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0713 09:13:13.888759 47888 net.cpp:165] Memory required for data: 4448000096
I0713 09:13:13.888768 47888 layer_factory.hpp:76] Creating layer conv21
I0713 09:13:13.888787 47888 net.cpp:106] Creating Layer conv21
I0713 09:13:13.888795 47888 net.cpp:454] conv21 <- pool1
I0713 09:13:13.888806 47888 net.cpp:411] conv21 -> conv21
I0713 09:13:13.895207 47888 net.cpp:150] Setting up conv21
I0713 09:13:13.895239 47888 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:13.895251 47888 net.cpp:165] Memory required for data: 4960000096
I0713 09:13:13.895267 47888 layer_factory.hpp:76] Creating layer relu21
I0713 09:13:13.895282 47888 net.cpp:106] Creating Layer relu21
I0713 09:13:13.895292 47888 net.cpp:454] relu21 <- conv21
I0713 09:13:13.895305 47888 net.cpp:397] relu21 -> conv21 (in-place)
I0713 09:13:13.896445 47888 net.cpp:150] Setting up relu21
I0713 09:13:13.896467 47888 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:13.896476 47888 net.cpp:165] Memory required for data: 5472000096
I0713 09:13:13.896486 47888 layer_factory.hpp:76] Creating layer conv22
I0713 09:13:13.896503 47888 net.cpp:106] Creating Layer conv22
I0713 09:13:13.896512 47888 net.cpp:454] conv22 <- conv21
I0713 09:13:13.896527 47888 net.cpp:411] conv22 -> conv22
I0713 09:13:13.904320 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:13.904564 47888 net.cpp:150] Setting up conv22
I0713 09:13:13.904589 47888 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:13.904598 47888 net.cpp:165] Memory required for data: 5984000096
I0713 09:13:13.904613 47888 layer_factory.hpp:76] Creating layer relu22
I0713 09:13:13.904626 47888 net.cpp:106] Creating Layer relu22
I0713 09:13:13.904635 47888 net.cpp:454] relu22 <- conv22
I0713 09:13:13.904647 47888 net.cpp:397] relu22 -> conv22 (in-place)
I0713 09:13:13.905475 47888 net.cpp:150] Setting up relu22
I0713 09:13:13.905496 47888 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0713 09:13:13.905505 47888 net.cpp:165] Memory required for data: 6496000096
I0713 09:13:13.905515 47888 layer_factory.hpp:76] Creating layer pool2
I0713 09:13:13.905529 47888 net.cpp:106] Creating Layer pool2
I0713 09:13:13.905573 47888 net.cpp:454] pool2 <- conv22
I0713 09:13:13.905588 47888 net.cpp:411] pool2 -> pool2
I0713 09:13:13.907759 47888 net.cpp:150] Setting up pool2
I0713 09:13:13.907779 47888 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0713 09:13:13.907789 47888 net.cpp:165] Memory required for data: 6624000096
I0713 09:13:13.907799 47888 layer_factory.hpp:76] Creating layer conv31
I0713 09:13:13.907816 47888 net.cpp:106] Creating Layer conv31
I0713 09:13:13.907824 47888 net.cpp:454] conv31 <- pool2
I0713 09:13:13.907838 47888 net.cpp:411] conv31 -> conv31
I0713 09:13:13.914681 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:13.914721 47888 net.cpp:150] Setting up conv31
I0713 09:13:13.914736 47888 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:13.914744 47888 net.cpp:165] Memory required for data: 6816000096
I0713 09:13:13.914762 47888 layer_factory.hpp:76] Creating layer relu31
I0713 09:13:13.914777 47888 net.cpp:106] Creating Layer relu31
I0713 09:13:13.914785 47888 net.cpp:454] relu31 <- conv31
I0713 09:13:13.914795 47888 net.cpp:397] relu31 -> conv31 (in-place)
I0713 09:13:13.916748 47888 net.cpp:150] Setting up relu31
I0713 09:13:13.916769 47888 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:13.916779 47888 net.cpp:165] Memory required for data: 7008000096
I0713 09:13:13.916787 47888 layer_factory.hpp:76] Creating layer conv32
I0713 09:13:13.916805 47888 net.cpp:106] Creating Layer conv32
I0713 09:13:13.916813 47888 net.cpp:454] conv32 <- conv31
I0713 09:13:13.916826 47888 net.cpp:411] conv32 -> conv32
I0713 09:13:13.923684 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:13.923724 47888 net.cpp:150] Setting up conv32
I0713 09:13:13.923738 47888 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:13.923746 47888 net.cpp:165] Memory required for data: 7200000096
I0713 09:13:13.923760 47888 layer_factory.hpp:76] Creating layer relu32
I0713 09:13:13.923773 47888 net.cpp:106] Creating Layer relu32
I0713 09:13:13.923781 47888 net.cpp:454] relu32 <- conv32
I0713 09:13:13.923794 47888 net.cpp:397] relu32 -> conv32 (in-place)
I0713 09:13:13.925706 47888 net.cpp:150] Setting up relu32
I0713 09:13:13.925725 47888 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0713 09:13:13.925734 47888 net.cpp:165] Memory required for data: 7392000096
I0713 09:13:13.925742 47888 layer_factory.hpp:76] Creating layer pool3
I0713 09:13:13.925757 47888 net.cpp:106] Creating Layer pool3
I0713 09:13:13.925765 47888 net.cpp:454] pool3 <- conv32
I0713 09:13:13.925778 47888 net.cpp:411] pool3 -> pool3
I0713 09:13:13.927968 47888 net.cpp:150] Setting up pool3
I0713 09:13:13.928002 47888 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0713 09:13:13.928019 47888 net.cpp:165] Memory required for data: 7440000096
I0713 09:13:13.928032 47888 layer_factory.hpp:76] Creating layer conv41
I0713 09:13:13.928058 47888 net.cpp:106] Creating Layer conv41
I0713 09:13:13.928073 47888 net.cpp:454] conv41 <- pool3
I0713 09:13:13.928098 47888 net.cpp:411] conv41 -> conv41
I0713 09:13:13.934224 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:13.934276 47888 net.cpp:150] Setting up conv41
I0713 09:13:13.934290 47888 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:13.934298 47888 net.cpp:165] Memory required for data: 7504000096
I0713 09:13:13.934310 47888 layer_factory.hpp:76] Creating layer relu41
I0713 09:13:13.934322 47888 net.cpp:106] Creating Layer relu41
I0713 09:13:13.934331 47888 net.cpp:454] relu41 <- conv41
I0713 09:13:13.934341 47888 net.cpp:397] relu41 -> conv41 (in-place)
I0713 09:13:13.936028 47888 net.cpp:150] Setting up relu41
I0713 09:13:13.936061 47888 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:13.936071 47888 net.cpp:165] Memory required for data: 7568000096
I0713 09:13:13.936080 47888 layer_factory.hpp:76] Creating layer conv42
I0713 09:13:13.936099 47888 net.cpp:106] Creating Layer conv42
I0713 09:13:13.936108 47888 net.cpp:454] conv42 <- conv41
I0713 09:13:13.936120 47888 net.cpp:411] conv42 -> conv42
I0713 09:13:13.943220 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:13.943269 47888 net.cpp:150] Setting up conv42
I0713 09:13:13.943282 47888 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:13.943291 47888 net.cpp:165] Memory required for data: 7632000096
I0713 09:13:13.943303 47888 layer_factory.hpp:76] Creating layer relu42
I0713 09:13:13.943318 47888 net.cpp:106] Creating Layer relu42
I0713 09:13:13.943328 47888 net.cpp:454] relu42 <- conv42
I0713 09:13:13.943338 47888 net.cpp:397] relu42 -> conv42 (in-place)
I0713 09:13:13.945396 47888 net.cpp:150] Setting up relu42
I0713 09:13:13.945426 47888 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0713 09:13:13.945436 47888 net.cpp:165] Memory required for data: 7696000096
I0713 09:13:13.945444 47888 layer_factory.hpp:76] Creating layer pool4
I0713 09:13:13.945456 47888 net.cpp:106] Creating Layer pool4
I0713 09:13:13.945466 47888 net.cpp:454] pool4 <- conv42
I0713 09:13:13.945477 47888 net.cpp:411] pool4 -> pool4
I0713 09:13:13.947921 47888 net.cpp:150] Setting up pool4
I0713 09:13:13.947953 47888 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0713 09:13:13.947963 47888 net.cpp:165] Memory required for data: 7712257120
I0713 09:13:13.947971 47888 layer_factory.hpp:76] Creating layer conv51
I0713 09:13:13.947988 47888 net.cpp:106] Creating Layer conv51
I0713 09:13:13.947998 47888 net.cpp:454] conv51 <- pool4
I0713 09:13:13.948010 47888 net.cpp:411] conv51 -> conv51
I0713 09:13:13.956393 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:13.956441 47888 net.cpp:150] Setting up conv51
I0713 09:13:13.956456 47888 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:13.956465 47888 net.cpp:165] Memory required for data: 7744771168
I0713 09:13:13.956481 47888 layer_factory.hpp:76] Creating layer relu51
I0713 09:13:13.956496 47888 net.cpp:106] Creating Layer relu51
I0713 09:13:13.956506 47888 net.cpp:454] relu51 <- conv51
I0713 09:13:13.956516 47888 net.cpp:397] relu51 -> conv51 (in-place)
I0713 09:13:13.958044 47888 net.cpp:150] Setting up relu51
I0713 09:13:13.958072 47888 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:13.958082 47888 net.cpp:165] Memory required for data: 7777285216
I0713 09:13:13.958091 47888 layer_factory.hpp:76] Creating layer conv52
I0713 09:13:13.958107 47888 net.cpp:106] Creating Layer conv52
I0713 09:13:13.958117 47888 net.cpp:454] conv52 <- conv51
I0713 09:13:13.958127 47888 net.cpp:411] conv52 -> conv52
I0713 09:13:13.968782 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0713 09:13:13.968845 47888 net.cpp:150] Setting up conv52
I0713 09:13:13.968863 47888 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:13.968871 47888 net.cpp:165] Memory required for data: 7809799264
I0713 09:13:13.968886 47888 layer_factory.hpp:76] Creating layer relu52
I0713 09:13:13.968905 47888 net.cpp:106] Creating Layer relu52
I0713 09:13:13.968917 47888 net.cpp:454] relu52 <- conv52
I0713 09:13:13.968930 47888 net.cpp:397] relu52 -> conv52 (in-place)
I0713 09:13:13.971194 47888 net.cpp:150] Setting up relu52
I0713 09:13:13.971226 47888 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0713 09:13:13.971238 47888 net.cpp:165] Memory required for data: 7842313312
I0713 09:13:13.971247 47888 layer_factory.hpp:76] Creating layer conv53
I0713 09:13:13.971263 47888 net.cpp:106] Creating Layer conv53
I0713 09:13:13.971272 47888 net.cpp:454] conv53 <- conv52
I0713 09:13:13.971287 47888 net.cpp:411] conv53 -> conv53
I0713 09:13:14.010624 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0713 09:13:14.010963 47888 net.cpp:150] Setting up conv53
I0713 09:13:14.011003 47888 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0713 09:13:14.011019 47888 net.cpp:165] Memory required for data: 7868929120
I0713 09:13:14.011044 47888 layer_factory.hpp:76] Creating layer relu53
I0713 09:13:14.011065 47888 net.cpp:106] Creating Layer relu53
I0713 09:13:14.011096 47888 net.cpp:454] relu53 <- conv53
I0713 09:13:14.011131 47888 net.cpp:397] relu53 -> conv53 (in-place)
I0713 09:13:14.012871 47888 net.cpp:150] Setting up relu53
I0713 09:13:14.012909 47888 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0713 09:13:14.012925 47888 net.cpp:165] Memory required for data: 7895544928
I0713 09:13:14.012939 47888 layer_factory.hpp:76] Creating layer conv61
I0713 09:13:14.012966 47888 net.cpp:106] Creating Layer conv61
I0713 09:13:14.012995 47888 net.cpp:454] conv61 <- conv53
I0713 09:13:14.013018 47888 net.cpp:411] conv61 -> conv61
I0713 09:13:14.019018 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0713 09:13:14.019093 47888 net.cpp:150] Setting up conv61
I0713 09:13:14.019114 47888 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:14.019129 47888 net.cpp:165] Memory required for data: 7902198880
I0713 09:13:14.019151 47888 layer_factory.hpp:76] Creating layer relu61
I0713 09:13:14.019189 47888 net.cpp:106] Creating Layer relu61
I0713 09:13:14.019207 47888 net.cpp:454] relu61 <- conv61
I0713 09:13:14.019239 47888 net.cpp:397] relu61 -> conv61 (in-place)
I0713 09:13:14.021040 47888 net.cpp:150] Setting up relu61
I0713 09:13:14.021078 47888 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:14.021093 47888 net.cpp:165] Memory required for data: 7908852832
I0713 09:13:14.021108 47888 layer_factory.hpp:76] Creating layer conv62
I0713 09:13:14.021131 47888 net.cpp:106] Creating Layer conv62
I0713 09:13:14.021159 47888 net.cpp:454] conv62 <- conv61
I0713 09:13:14.021183 47888 net.cpp:411] conv62 -> conv62
I0713 09:13:14.025854 47888 net.cpp:150] Setting up conv62
I0713 09:13:14.025900 47888 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:14.025916 47888 net.cpp:165] Memory required for data: 7915506784
I0713 09:13:14.025938 47888 layer_factory.hpp:76] Creating layer relu62
I0713 09:13:14.025956 47888 net.cpp:106] Creating Layer relu62
I0713 09:13:14.025990 47888 net.cpp:454] relu62 <- conv62
I0713 09:13:14.026007 47888 net.cpp:397] relu62 -> conv62 (in-place)
I0713 09:13:14.028059 47888 net.cpp:150] Setting up relu62
I0713 09:13:14.028098 47888 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0713 09:13:14.028113 47888 net.cpp:165] Memory required for data: 7922160736
I0713 09:13:14.028127 47888 layer_factory.hpp:76] Creating layer pool5
I0713 09:13:14.028156 47888 net.cpp:106] Creating Layer pool5
I0713 09:13:14.028173 47888 net.cpp:454] pool5 <- conv62
I0713 09:13:14.028190 47888 net.cpp:411] pool5 -> pool5
I0713 09:13:14.029229 47888 net.cpp:150] Setting up pool5
I0713 09:13:14.029265 47888 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0713 09:13:14.029280 47888 net.cpp:165] Memory required for data: 7923883104
I0713 09:13:14.029294 47888 layer_factory.hpp:76] Creating layer conv71
I0713 09:13:14.029315 47888 net.cpp:106] Creating Layer conv71
I0713 09:13:14.029343 47888 net.cpp:454] conv71 <- pool5
I0713 09:13:14.029363 47888 net.cpp:411] conv71 -> conv71
I0713 09:13:14.034042 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:14.034099 47888 net.cpp:150] Setting up conv71
I0713 09:13:14.034121 47888 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:14.034148 47888 net.cpp:165] Memory required for data: 7926466656
I0713 09:13:14.034168 47888 layer_factory.hpp:76] Creating layer relu71
I0713 09:13:14.034198 47888 net.cpp:106] Creating Layer relu71
I0713 09:13:14.034211 47888 net.cpp:454] relu71 <- conv71
I0713 09:13:14.034226 47888 net.cpp:397] relu71 -> conv71 (in-place)
I0713 09:13:14.037569 47888 net.cpp:150] Setting up relu71
I0713 09:13:14.037608 47888 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:14.037623 47888 net.cpp:165] Memory required for data: 7929050208
I0713 09:13:14.037636 47888 layer_factory.hpp:76] Creating layer conv72
I0713 09:13:14.037659 47888 net.cpp:106] Creating Layer conv72
I0713 09:13:14.037688 47888 net.cpp:454] conv72 <- conv71
I0713 09:13:14.037709 47888 net.cpp:411] conv72 -> conv72
I0713 09:13:14.045153 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:14.045217 47888 net.cpp:150] Setting up conv72
I0713 09:13:14.045272 47888 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:14.045287 47888 net.cpp:165] Memory required for data: 7931633760
I0713 09:13:14.045306 47888 layer_factory.hpp:76] Creating layer relu72
I0713 09:13:14.045337 47888 net.cpp:106] Creating Layer relu72
I0713 09:13:14.045367 47888 net.cpp:454] relu72 <- conv72
I0713 09:13:14.045382 47888 net.cpp:397] relu72 -> conv72 (in-place)
I0713 09:13:14.047615 47888 net.cpp:150] Setting up relu72
I0713 09:13:14.047653 47888 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0713 09:13:14.047668 47888 net.cpp:165] Memory required for data: 7934217312
I0713 09:13:14.047683 47888 layer_factory.hpp:76] Creating layer pool6
I0713 09:13:14.047703 47888 net.cpp:106] Creating Layer pool6
I0713 09:13:14.047732 47888 net.cpp:454] pool6 <- conv72
I0713 09:13:14.047751 47888 net.cpp:411] pool6 -> pool6
I0713 09:13:14.050420 47888 net.cpp:150] Setting up pool6
I0713 09:13:14.050456 47888 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0713 09:13:14.050469 47888 net.cpp:165] Memory required for data: 7934908512
I0713 09:13:14.050483 47888 layer_factory.hpp:76] Creating layer conv81
I0713 09:13:14.050508 47888 net.cpp:106] Creating Layer conv81
I0713 09:13:14.050536 47888 net.cpp:454] conv81 <- pool6
I0713 09:13:14.050554 47888 net.cpp:411] conv81 -> conv81
I0713 09:13:14.057209 47888 net.cpp:150] Setting up conv81
I0713 09:13:14.057238 47888 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:14.057252 47888 net.cpp:165] Memory required for data: 7935830112
I0713 09:13:14.057272 47888 layer_factory.hpp:76] Creating layer relu81
I0713 09:13:14.057289 47888 net.cpp:106] Creating Layer relu81
I0713 09:13:14.057303 47888 net.cpp:454] relu81 <- conv81
I0713 09:13:14.057322 47888 net.cpp:397] relu81 -> conv81 (in-place)
I0713 09:13:14.059026 47888 net.cpp:150] Setting up relu81
I0713 09:13:14.059052 47888 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:14.059067 47888 net.cpp:165] Memory required for data: 7936751712
I0713 09:13:14.059080 47888 layer_factory.hpp:76] Creating layer conv82
I0713 09:13:14.059103 47888 net.cpp:106] Creating Layer conv82
I0713 09:13:14.059116 47888 net.cpp:454] conv82 <- conv81
I0713 09:13:14.059137 47888 net.cpp:411] conv82 -> conv82
I0713 09:13:14.066992 47888 net.cpp:150] Setting up conv82
I0713 09:13:14.067023 47888 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:14.067036 47888 net.cpp:165] Memory required for data: 7937673312
I0713 09:13:14.067068 47888 layer_factory.hpp:76] Creating layer relu82
I0713 09:13:14.067086 47888 net.cpp:106] Creating Layer relu82
I0713 09:13:14.067101 47888 net.cpp:454] relu82 <- conv82
I0713 09:13:14.067118 47888 net.cpp:397] relu82 -> conv82 (in-place)
I0713 09:13:14.069131 47888 net.cpp:150] Setting up relu82
I0713 09:13:14.069159 47888 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0713 09:13:14.069174 47888 net.cpp:165] Memory required for data: 7938594912
I0713 09:13:14.069186 47888 layer_factory.hpp:76] Creating layer pool7
I0713 09:13:14.069205 47888 net.cpp:106] Creating Layer pool7
I0713 09:13:14.069218 47888 net.cpp:454] pool7 <- conv82
I0713 09:13:14.069237 47888 net.cpp:411] pool7 -> pool7
I0713 09:13:14.071351 47888 net.cpp:150] Setting up pool7
I0713 09:13:14.071379 47888 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0713 09:13:14.071393 47888 net.cpp:165] Memory required for data: 7938857056
I0713 09:13:14.071406 47888 layer_factory.hpp:76] Creating layer drop0
I0713 09:13:14.071429 47888 net.cpp:106] Creating Layer drop0
I0713 09:13:14.071444 47888 net.cpp:454] drop0 <- pool7
I0713 09:13:14.071462 47888 net.cpp:397] drop0 -> pool7 (in-place)
I0713 09:13:14.071516 47888 net.cpp:150] Setting up drop0
I0713 09:13:14.071535 47888 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0713 09:13:14.071548 47888 net.cpp:165] Memory required for data: 7939119200
I0713 09:13:14.071562 47888 layer_factory.hpp:76] Creating layer conv91
I0713 09:13:14.071586 47888 net.cpp:106] Creating Layer conv91
I0713 09:13:14.071600 47888 net.cpp:454] conv91 <- pool7
I0713 09:13:14.071619 47888 net.cpp:411] conv91 -> conv91
I0713 09:13:14.077291 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0713 09:13:14.077335 47888 net.cpp:150] Setting up conv91
I0713 09:13:14.077353 47888 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:14.077368 47888 net.cpp:165] Memory required for data: 7939119296
I0713 09:13:14.077385 47888 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0713 09:13:14.077407 47888 net.cpp:106] Creating Layer conv91_conv91_0_split
I0713 09:13:14.077421 47888 net.cpp:454] conv91_conv91_0_split <- conv91
I0713 09:13:14.077438 47888 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0713 09:13:14.077456 47888 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0713 09:13:14.077529 47888 net.cpp:150] Setting up conv91_conv91_0_split
I0713 09:13:14.077550 47888 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:14.077565 47888 net.cpp:157] Top shape: 8 3 1 1 (24)
I0713 09:13:14.077577 47888 net.cpp:165] Memory required for data: 7939119488
I0713 09:13:14.077591 47888 layer_factory.hpp:76] Creating layer accuracy
I0713 09:13:14.077612 47888 net.cpp:106] Creating Layer accuracy
I0713 09:13:14.077625 47888 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0713 09:13:14.077641 47888 net.cpp:454] accuracy <- label_data_1_split_0
I0713 09:13:14.077656 47888 net.cpp:411] accuracy -> accuracy
I0713 09:13:14.077683 47888 net.cpp:150] Setting up accuracy
I0713 09:13:14.077700 47888 net.cpp:157] Top shape: (1)
I0713 09:13:14.077713 47888 net.cpp:165] Memory required for data: 7939119492
I0713 09:13:14.077725 47888 layer_factory.hpp:76] Creating layer loss
I0713 09:13:14.077745 47888 net.cpp:106] Creating Layer loss
I0713 09:13:14.077759 47888 net.cpp:454] loss <- conv91_conv91_0_split_1
I0713 09:13:14.077775 47888 net.cpp:454] loss <- label_data_1_split_1
I0713 09:13:14.077790 47888 net.cpp:411] loss -> loss
I0713 09:13:14.077824 47888 layer_factory.hpp:76] Creating layer loss
I0713 09:13:14.078709 47888 net.cpp:150] Setting up loss
I0713 09:13:14.078738 47888 net.cpp:157] Top shape: (1)
I0713 09:13:14.078752 47888 net.cpp:160]     with loss weight 1
I0713 09:13:14.078793 47888 net.cpp:165] Memory required for data: 7939119496
I0713 09:13:14.078806 47888 net.cpp:226] loss needs backward computation.
I0713 09:13:14.078821 47888 net.cpp:228] accuracy does not need backward computation.
I0713 09:13:14.078837 47888 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0713 09:13:14.078850 47888 net.cpp:226] conv91 needs backward computation.
I0713 09:13:14.078862 47888 net.cpp:226] drop0 needs backward computation.
I0713 09:13:14.078876 47888 net.cpp:226] pool7 needs backward computation.
I0713 09:13:14.078887 47888 net.cpp:226] relu82 needs backward computation.
I0713 09:13:14.078901 47888 net.cpp:226] conv82 needs backward computation.
I0713 09:13:14.078913 47888 net.cpp:226] relu81 needs backward computation.
I0713 09:13:14.078925 47888 net.cpp:226] conv81 needs backward computation.
I0713 09:13:14.078938 47888 net.cpp:226] pool6 needs backward computation.
I0713 09:13:14.078951 47888 net.cpp:226] relu72 needs backward computation.
I0713 09:13:14.078963 47888 net.cpp:226] conv72 needs backward computation.
I0713 09:13:14.078976 47888 net.cpp:226] relu71 needs backward computation.
I0713 09:13:14.078989 47888 net.cpp:226] conv71 needs backward computation.
I0713 09:13:14.079000 47888 net.cpp:226] pool5 needs backward computation.
I0713 09:13:14.079015 47888 net.cpp:226] relu62 needs backward computation.
I0713 09:13:14.079030 47888 net.cpp:226] conv62 needs backward computation.
I0713 09:13:14.079043 47888 net.cpp:226] relu61 needs backward computation.
I0713 09:13:14.079056 47888 net.cpp:226] conv61 needs backward computation.
I0713 09:13:14.079068 47888 net.cpp:228] relu53 does not need backward computation.
I0713 09:13:14.079082 47888 net.cpp:228] conv53 does not need backward computation.
I0713 09:13:14.079094 47888 net.cpp:228] relu52 does not need backward computation.
I0713 09:13:14.079107 47888 net.cpp:228] conv52 does not need backward computation.
I0713 09:13:14.079120 47888 net.cpp:228] relu51 does not need backward computation.
I0713 09:13:14.079149 47888 net.cpp:228] conv51 does not need backward computation.
I0713 09:13:14.079164 47888 net.cpp:228] pool4 does not need backward computation.
I0713 09:13:14.079176 47888 net.cpp:228] relu42 does not need backward computation.
I0713 09:13:14.079190 47888 net.cpp:228] conv42 does not need backward computation.
I0713 09:13:14.079203 47888 net.cpp:228] relu41 does not need backward computation.
I0713 09:13:14.079216 47888 net.cpp:228] conv41 does not need backward computation.
I0713 09:13:14.079231 47888 net.cpp:228] pool3 does not need backward computation.
I0713 09:13:14.079244 47888 net.cpp:228] relu32 does not need backward computation.
I0713 09:13:14.079257 47888 net.cpp:228] conv32 does not need backward computation.
I0713 09:13:14.079270 47888 net.cpp:228] relu31 does not need backward computation.
I0713 09:13:14.079283 47888 net.cpp:228] conv31 does not need backward computation.
I0713 09:13:14.079296 47888 net.cpp:228] pool2 does not need backward computation.
I0713 09:13:14.079310 47888 net.cpp:228] relu22 does not need backward computation.
I0713 09:13:14.079322 47888 net.cpp:228] conv22 does not need backward computation.
I0713 09:13:14.079336 47888 net.cpp:228] relu21 does not need backward computation.
I0713 09:13:14.079349 47888 net.cpp:228] conv21 does not need backward computation.
I0713 09:13:14.079362 47888 net.cpp:228] pool1 does not need backward computation.
I0713 09:13:14.079376 47888 net.cpp:228] relu12 does not need backward computation.
I0713 09:13:14.079388 47888 net.cpp:228] conv12 does not need backward computation.
I0713 09:13:14.079402 47888 net.cpp:228] relu11 does not need backward computation.
I0713 09:13:14.079414 47888 net.cpp:228] conv11 does not need backward computation.
I0713 09:13:14.079429 47888 net.cpp:228] label_data_1_split does not need backward computation.
I0713 09:13:14.079443 47888 net.cpp:228] data does not need backward computation.
I0713 09:13:14.079455 47888 net.cpp:270] This network produces output accuracy
I0713 09:13:14.079468 47888 net.cpp:270] This network produces output loss
I0713 09:13:14.079519 47888 net.cpp:283] Network initialization done.
I0713 09:13:14.081147 47888 solver.cpp:180] Creating test net (#0) specified by net file: train_val-featurelayer-3stack.prototxt
I0713 09:13:14.081259 47888 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0713 09:13:14.081713 47888 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 6
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "conv53"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0713 09:13:14.085245 47888 layer_factory.hpp:76] Creating layer data
I0713 09:13:14.085299 47888 net.cpp:106] Creating Layer data
I0713 09:13:14.085316 47888 net.cpp:411] data -> data
I0713 09:13:14.085338 47888 net.cpp:411] data -> label
I0713 09:13:14.085361 47888 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0713 09:13:14.110486 47888 image_data_layer.cpp:46] Shuffling data
I0713 09:13:14.110842 47888 image_data_layer.cpp:51] A total of 2617 images.
I0713 09:13:14.197194 47888 image_data_layer.cpp:78] output data size: 6,3,1000,1000
I0713 09:13:14.394043 47888 net.cpp:150] Setting up data
I0713 09:13:14.394110 47888 net.cpp:157] Top shape: 6 3 1000 1000 (18000000)
I0713 09:13:14.394130 47888 net.cpp:157] Top shape: 6 (6)
I0713 09:13:14.394145 47888 net.cpp:165] Memory required for data: 72000024
I0713 09:13:14.394162 47888 layer_factory.hpp:76] Creating layer label_data_1_split
I0713 09:13:14.394189 47888 net.cpp:106] Creating Layer label_data_1_split
I0713 09:13:14.394204 47888 net.cpp:454] label_data_1_split <- label
I0713 09:13:14.394224 47888 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0713 09:13:14.394248 47888 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0713 09:13:14.394351 47888 net.cpp:150] Setting up label_data_1_split
I0713 09:13:14.394374 47888 net.cpp:157] Top shape: 6 (6)
I0713 09:13:14.394390 47888 net.cpp:157] Top shape: 6 (6)
I0713 09:13:14.394404 47888 net.cpp:165] Memory required for data: 72000072
I0713 09:13:14.394418 47888 layer_factory.hpp:76] Creating layer conv11
I0713 09:13:14.394443 47888 net.cpp:106] Creating Layer conv11
I0713 09:13:14.394459 47888 net.cpp:454] conv11 <- data
I0713 09:13:14.394476 47888 net.cpp:411] conv11 -> conv11
I0713 09:13:14.399827 47888 net.cpp:150] Setting up conv11
I0713 09:13:14.399881 47888 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0713 09:13:14.399898 47888 net.cpp:165] Memory required for data: 840000072
I0713 09:13:14.399927 47888 layer_factory.hpp:76] Creating layer relu11
I0713 09:13:14.399952 47888 net.cpp:106] Creating Layer relu11
I0713 09:13:14.399969 47888 net.cpp:454] relu11 <- conv11
I0713 09:13:14.399986 47888 net.cpp:397] relu11 -> conv11 (in-place)
I0713 09:13:14.400316 47888 net.cpp:150] Setting up relu11
I0713 09:13:14.400343 47888 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0713 09:13:14.400357 47888 net.cpp:165] Memory required for data: 1608000072
I0713 09:13:14.400372 47888 layer_factory.hpp:76] Creating layer conv12
I0713 09:13:14.400398 47888 net.cpp:106] Creating Layer conv12
I0713 09:13:14.400413 47888 net.cpp:454] conv12 <- conv11
I0713 09:13:14.400434 47888 net.cpp:411] conv12 -> conv12
I0713 09:13:14.406092 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3456
I0713 09:13:14.406493 47888 net.cpp:150] Setting up conv12
I0713 09:13:14.406527 47888 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0713 09:13:14.406543 47888 net.cpp:165] Memory required for data: 2376000072
I0713 09:13:14.406574 47888 layer_factory.hpp:76] Creating layer relu12
I0713 09:13:14.406596 47888 net.cpp:106] Creating Layer relu12
I0713 09:13:14.406612 47888 net.cpp:454] relu12 <- conv12
I0713 09:13:14.406639 47888 net.cpp:397] relu12 -> conv12 (in-place)
I0713 09:13:14.407080 47888 net.cpp:150] Setting up relu12
I0713 09:13:14.407102 47888 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0713 09:13:14.407112 47888 net.cpp:165] Memory required for data: 3144000072
I0713 09:13:14.407121 47888 layer_factory.hpp:76] Creating layer pool1
I0713 09:13:14.407135 47888 net.cpp:106] Creating Layer pool1
I0713 09:13:14.407145 47888 net.cpp:454] pool1 <- conv12
I0713 09:13:14.407155 47888 net.cpp:411] pool1 -> pool1
I0713 09:13:14.407398 47888 net.cpp:150] Setting up pool1
I0713 09:13:14.407418 47888 net.cpp:157] Top shape: 6 32 500 500 (48000000)
I0713 09:13:14.407426 47888 net.cpp:165] Memory required for data: 3336000072
I0713 09:13:14.407434 47888 layer_factory.hpp:76] Creating layer conv21
I0713 09:13:14.407451 47888 net.cpp:106] Creating Layer conv21
I0713 09:13:14.407459 47888 net.cpp:454] conv21 <- pool1
I0713 09:13:14.407511 47888 net.cpp:411] conv21 -> conv21
I0713 09:13:14.409801 47888 net.cpp:150] Setting up conv21
I0713 09:13:14.409826 47888 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0713 09:13:14.409837 47888 net.cpp:165] Memory required for data: 3720000072
I0713 09:13:14.409852 47888 layer_factory.hpp:76] Creating layer relu21
I0713 09:13:14.409868 47888 net.cpp:106] Creating Layer relu21
I0713 09:13:14.409876 47888 net.cpp:454] relu21 <- conv21
I0713 09:13:14.409888 47888 net.cpp:397] relu21 -> conv21 (in-place)
I0713 09:13:14.410274 47888 net.cpp:150] Setting up relu21
I0713 09:13:14.410295 47888 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0713 09:13:14.410305 47888 net.cpp:165] Memory required for data: 4104000072
I0713 09:13:14.410313 47888 layer_factory.hpp:76] Creating layer conv22
I0713 09:13:14.410328 47888 net.cpp:106] Creating Layer conv22
I0713 09:13:14.410337 47888 net.cpp:454] conv22 <- conv21
I0713 09:13:14.410348 47888 net.cpp:411] conv22 -> conv22
I0713 09:13:14.412875 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:14.412935 47888 net.cpp:150] Setting up conv22
I0713 09:13:14.412950 47888 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0713 09:13:14.412960 47888 net.cpp:165] Memory required for data: 4488000072
I0713 09:13:14.412973 47888 layer_factory.hpp:76] Creating layer relu22
I0713 09:13:14.412986 47888 net.cpp:106] Creating Layer relu22
I0713 09:13:14.412995 47888 net.cpp:454] relu22 <- conv22
I0713 09:13:14.413007 47888 net.cpp:397] relu22 -> conv22 (in-place)
I0713 09:13:14.413388 47888 net.cpp:150] Setting up relu22
I0713 09:13:14.413409 47888 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0713 09:13:14.413419 47888 net.cpp:165] Memory required for data: 4872000072
I0713 09:13:14.413429 47888 layer_factory.hpp:76] Creating layer pool2
I0713 09:13:14.413442 47888 net.cpp:106] Creating Layer pool2
I0713 09:13:14.413451 47888 net.cpp:454] pool2 <- conv22
I0713 09:13:14.413462 47888 net.cpp:411] pool2 -> pool2
I0713 09:13:14.413681 47888 net.cpp:150] Setting up pool2
I0713 09:13:14.413699 47888 net.cpp:157] Top shape: 6 64 250 250 (24000000)
I0713 09:13:14.413708 47888 net.cpp:165] Memory required for data: 4968000072
I0713 09:13:14.413717 47888 layer_factory.hpp:76] Creating layer conv31
I0713 09:13:14.413733 47888 net.cpp:106] Creating Layer conv31
I0713 09:13:14.413740 47888 net.cpp:454] conv31 <- pool2
I0713 09:13:14.413753 47888 net.cpp:411] conv31 -> conv31
I0713 09:13:14.416347 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:14.416409 47888 net.cpp:150] Setting up conv31
I0713 09:13:14.416424 47888 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0713 09:13:14.416434 47888 net.cpp:165] Memory required for data: 5112000072
I0713 09:13:14.416452 47888 layer_factory.hpp:76] Creating layer relu31
I0713 09:13:14.416467 47888 net.cpp:106] Creating Layer relu31
I0713 09:13:14.416477 47888 net.cpp:454] relu31 <- conv31
I0713 09:13:14.416488 47888 net.cpp:397] relu31 -> conv31 (in-place)
I0713 09:13:14.416846 47888 net.cpp:150] Setting up relu31
I0713 09:13:14.416868 47888 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0713 09:13:14.416877 47888 net.cpp:165] Memory required for data: 5256000072
I0713 09:13:14.416887 47888 layer_factory.hpp:76] Creating layer conv32
I0713 09:13:14.416903 47888 net.cpp:106] Creating Layer conv32
I0713 09:13:14.416911 47888 net.cpp:454] conv32 <- conv31
I0713 09:13:14.416923 47888 net.cpp:411] conv32 -> conv32
I0713 09:13:14.418655 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:14.418696 47888 net.cpp:150] Setting up conv32
I0713 09:13:14.418710 47888 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0713 09:13:14.418718 47888 net.cpp:165] Memory required for data: 5400000072
I0713 09:13:14.418731 47888 layer_factory.hpp:76] Creating layer relu32
I0713 09:13:14.418745 47888 net.cpp:106] Creating Layer relu32
I0713 09:13:14.418752 47888 net.cpp:454] relu32 <- conv32
I0713 09:13:14.418763 47888 net.cpp:397] relu32 -> conv32 (in-place)
I0713 09:13:14.419103 47888 net.cpp:150] Setting up relu32
I0713 09:13:14.419163 47888 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0713 09:13:14.419173 47888 net.cpp:165] Memory required for data: 5544000072
I0713 09:13:14.419183 47888 layer_factory.hpp:76] Creating layer pool3
I0713 09:13:14.419199 47888 net.cpp:106] Creating Layer pool3
I0713 09:13:14.419209 47888 net.cpp:454] pool3 <- conv32
I0713 09:13:14.419219 47888 net.cpp:411] pool3 -> pool3
I0713 09:13:14.419440 47888 net.cpp:150] Setting up pool3
I0713 09:13:14.419458 47888 net.cpp:157] Top shape: 6 96 125 125 (9000000)
I0713 09:13:14.419467 47888 net.cpp:165] Memory required for data: 5580000072
I0713 09:13:14.419476 47888 layer_factory.hpp:76] Creating layer conv41
I0713 09:13:14.419491 47888 net.cpp:106] Creating Layer conv41
I0713 09:13:14.419499 47888 net.cpp:454] conv41 <- pool3
I0713 09:13:14.419512 47888 net.cpp:411] conv41 -> conv41
I0713 09:13:14.421983 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:14.422026 47888 net.cpp:150] Setting up conv41
I0713 09:13:14.422040 47888 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0713 09:13:14.422049 47888 net.cpp:165] Memory required for data: 5628000072
I0713 09:13:14.422060 47888 layer_factory.hpp:76] Creating layer relu41
I0713 09:13:14.422073 47888 net.cpp:106] Creating Layer relu41
I0713 09:13:14.422081 47888 net.cpp:454] relu41 <- conv41
I0713 09:13:14.422092 47888 net.cpp:397] relu41 -> conv41 (in-place)
I0713 09:13:14.422452 47888 net.cpp:150] Setting up relu41
I0713 09:13:14.422472 47888 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0713 09:13:14.422482 47888 net.cpp:165] Memory required for data: 5676000072
I0713 09:13:14.422490 47888 layer_factory.hpp:76] Creating layer conv42
I0713 09:13:14.422505 47888 net.cpp:106] Creating Layer conv42
I0713 09:13:14.422514 47888 net.cpp:454] conv42 <- conv41
I0713 09:13:14.422526 47888 net.cpp:411] conv42 -> conv42
I0713 09:13:14.424691 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0713 09:13:14.424743 47888 net.cpp:150] Setting up conv42
I0713 09:13:14.424757 47888 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0713 09:13:14.424765 47888 net.cpp:165] Memory required for data: 5724000072
I0713 09:13:14.424778 47888 layer_factory.hpp:76] Creating layer relu42
I0713 09:13:14.424790 47888 net.cpp:106] Creating Layer relu42
I0713 09:13:14.424799 47888 net.cpp:454] relu42 <- conv42
I0713 09:13:14.424809 47888 net.cpp:397] relu42 -> conv42 (in-place)
I0713 09:13:14.424993 47888 net.cpp:150] Setting up relu42
I0713 09:13:14.425009 47888 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0713 09:13:14.425019 47888 net.cpp:165] Memory required for data: 5772000072
I0713 09:13:14.425040 47888 layer_factory.hpp:76] Creating layer pool4
I0713 09:13:14.425052 47888 net.cpp:106] Creating Layer pool4
I0713 09:13:14.425061 47888 net.cpp:454] pool4 <- conv42
I0713 09:13:14.425071 47888 net.cpp:411] pool4 -> pool4
I0713 09:13:14.425472 47888 net.cpp:150] Setting up pool4
I0713 09:13:14.425493 47888 net.cpp:157] Top shape: 6 128 63 63 (3048192)
I0713 09:13:14.425501 47888 net.cpp:165] Memory required for data: 5784192840
I0713 09:13:14.425510 47888 layer_factory.hpp:76] Creating layer conv51
I0713 09:13:14.425524 47888 net.cpp:106] Creating Layer conv51
I0713 09:13:14.425534 47888 net.cpp:454] conv51 <- pool4
I0713 09:13:14.425544 47888 net.cpp:411] conv51 -> conv51
I0713 09:13:14.432454 47888 net.cpp:150] Setting up conv51
I0713 09:13:14.432494 47888 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0713 09:13:14.432505 47888 net.cpp:165] Memory required for data: 5808578376
I0713 09:13:14.432524 47888 layer_factory.hpp:76] Creating layer relu51
I0713 09:13:14.432539 47888 net.cpp:106] Creating Layer relu51
I0713 09:13:14.432551 47888 net.cpp:454] relu51 <- conv51
I0713 09:13:14.432562 47888 net.cpp:397] relu51 -> conv51 (in-place)
I0713 09:13:14.432904 47888 net.cpp:150] Setting up relu51
I0713 09:13:14.432924 47888 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0713 09:13:14.432934 47888 net.cpp:165] Memory required for data: 5832963912
I0713 09:13:14.432984 47888 layer_factory.hpp:76] Creating layer conv52
I0713 09:13:14.433001 47888 net.cpp:106] Creating Layer conv52
I0713 09:13:14.433012 47888 net.cpp:454] conv52 <- conv51
I0713 09:13:14.433023 47888 net.cpp:411] conv52 -> conv52
I0713 09:13:14.442127 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0713 09:13:14.442200 47888 net.cpp:150] Setting up conv52
I0713 09:13:14.442219 47888 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0713 09:13:14.442229 47888 net.cpp:165] Memory required for data: 5857349448
I0713 09:13:14.442251 47888 layer_factory.hpp:76] Creating layer relu52
I0713 09:13:14.442273 47888 net.cpp:106] Creating Layer relu52
I0713 09:13:14.442294 47888 net.cpp:454] relu52 <- conv52
I0713 09:13:14.442311 47888 net.cpp:397] relu52 -> conv52 (in-place)
I0713 09:13:14.442778 47888 net.cpp:150] Setting up relu52
I0713 09:13:14.442802 47888 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0713 09:13:14.442812 47888 net.cpp:165] Memory required for data: 5881734984
I0713 09:13:14.442822 47888 layer_factory.hpp:76] Creating layer conv53
I0713 09:13:14.442843 47888 net.cpp:106] Creating Layer conv53
I0713 09:13:14.442857 47888 net.cpp:454] conv53 <- conv52
I0713 09:13:14.442873 47888 net.cpp:411] conv53 -> conv53
I0713 09:13:14.480958 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0713 09:13:14.481070 47888 net.cpp:150] Setting up conv53
I0713 09:13:14.481096 47888 net.cpp:157] Top shape: 6 256 57 57 (4990464)
I0713 09:13:14.481111 47888 net.cpp:165] Memory required for data: 5901696840
I0713 09:13:14.481135 47888 layer_factory.hpp:76] Creating layer relu53
I0713 09:13:14.481158 47888 net.cpp:106] Creating Layer relu53
I0713 09:13:14.481175 47888 net.cpp:454] relu53 <- conv53
I0713 09:13:14.481195 47888 net.cpp:397] relu53 -> conv53 (in-place)
I0713 09:13:14.481663 47888 net.cpp:150] Setting up relu53
I0713 09:13:14.481693 47888 net.cpp:157] Top shape: 6 256 57 57 (4990464)
I0713 09:13:14.481708 47888 net.cpp:165] Memory required for data: 5921658696
I0713 09:13:14.481722 47888 layer_factory.hpp:76] Creating layer conv61
I0713 09:13:14.481748 47888 net.cpp:106] Creating Layer conv61
I0713 09:13:14.481763 47888 net.cpp:454] conv61 <- conv53
I0713 09:13:14.481784 47888 net.cpp:411] conv61 -> conv61
I0713 09:13:14.485501 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0713 09:13:14.485549 47888 net.cpp:150] Setting up conv61
I0713 09:13:14.485569 47888 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0713 09:13:14.485584 47888 net.cpp:165] Memory required for data: 5926649160
I0713 09:13:14.485604 47888 layer_factory.hpp:76] Creating layer relu61
I0713 09:13:14.485622 47888 net.cpp:106] Creating Layer relu61
I0713 09:13:14.485636 47888 net.cpp:454] relu61 <- conv61
I0713 09:13:14.485656 47888 net.cpp:397] relu61 -> conv61 (in-place)
I0713 09:13:14.486114 47888 net.cpp:150] Setting up relu61
I0713 09:13:14.486141 47888 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0713 09:13:14.486156 47888 net.cpp:165] Memory required for data: 5931639624
I0713 09:13:14.486171 47888 layer_factory.hpp:76] Creating layer conv62
I0713 09:13:14.486196 47888 net.cpp:106] Creating Layer conv62
I0713 09:13:14.486212 47888 net.cpp:454] conv62 <- conv61
I0713 09:13:14.486238 47888 net.cpp:411] conv62 -> conv62
I0713 09:13:14.488270 47888 net.cpp:150] Setting up conv62
I0713 09:13:14.488301 47888 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0713 09:13:14.488317 47888 net.cpp:165] Memory required for data: 5936630088
I0713 09:13:14.488337 47888 layer_factory.hpp:76] Creating layer relu62
I0713 09:13:14.488358 47888 net.cpp:106] Creating Layer relu62
I0713 09:13:14.488373 47888 net.cpp:454] relu62 <- conv62
I0713 09:13:14.488391 47888 net.cpp:397] relu62 -> conv62 (in-place)
I0713 09:13:14.488662 47888 net.cpp:150] Setting up relu62
I0713 09:13:14.488687 47888 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0713 09:13:14.488700 47888 net.cpp:165] Memory required for data: 5941620552
I0713 09:13:14.488714 47888 layer_factory.hpp:76] Creating layer pool5
I0713 09:13:14.488796 47888 net.cpp:106] Creating Layer pool5
I0713 09:13:14.488813 47888 net.cpp:454] pool5 <- conv62
I0713 09:13:14.488833 47888 net.cpp:411] pool5 -> pool5
I0713 09:13:14.489367 47888 net.cpp:150] Setting up pool5
I0713 09:13:14.489395 47888 net.cpp:157] Top shape: 6 64 29 29 (322944)
I0713 09:13:14.489409 47888 net.cpp:165] Memory required for data: 5942912328
I0713 09:13:14.489424 47888 layer_factory.hpp:76] Creating layer conv71
I0713 09:13:14.489447 47888 net.cpp:106] Creating Layer conv71
I0713 09:13:14.489461 47888 net.cpp:454] conv71 <- pool5
I0713 09:13:14.489481 47888 net.cpp:411] conv71 -> conv71
I0713 09:13:14.491665 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0713 09:13:14.491749 47888 net.cpp:150] Setting up conv71
I0713 09:13:14.491771 47888 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0713 09:13:14.491786 47888 net.cpp:165] Memory required for data: 5944849992
I0713 09:13:14.491804 47888 layer_factory.hpp:76] Creating layer relu71
I0713 09:13:14.491827 47888 net.cpp:106] Creating Layer relu71
I0713 09:13:14.491842 47888 net.cpp:454] relu71 <- conv71
I0713 09:13:14.491859 47888 net.cpp:397] relu71 -> conv71 (in-place)
I0713 09:13:14.492133 47888 net.cpp:150] Setting up relu71
I0713 09:13:14.492157 47888 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0713 09:13:14.492172 47888 net.cpp:165] Memory required for data: 5946787656
I0713 09:13:14.492185 47888 layer_factory.hpp:76] Creating layer conv72
I0713 09:13:14.492208 47888 net.cpp:106] Creating Layer conv72
I0713 09:13:14.492223 47888 net.cpp:454] conv72 <- conv71
I0713 09:13:14.492243 47888 net.cpp:411] conv72 -> conv72
I0713 09:13:14.494735 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0713 09:13:14.494802 47888 net.cpp:150] Setting up conv72
I0713 09:13:14.494823 47888 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0713 09:13:14.494837 47888 net.cpp:165] Memory required for data: 5948725320
I0713 09:13:14.494858 47888 layer_factory.hpp:76] Creating layer relu72
I0713 09:13:14.494877 47888 net.cpp:106] Creating Layer relu72
I0713 09:13:14.494892 47888 net.cpp:454] relu72 <- conv72
I0713 09:13:14.494911 47888 net.cpp:397] relu72 -> conv72 (in-place)
I0713 09:13:14.495395 47888 net.cpp:150] Setting up relu72
I0713 09:13:14.495424 47888 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0713 09:13:14.495437 47888 net.cpp:165] Memory required for data: 5950662984
I0713 09:13:14.495452 47888 layer_factory.hpp:76] Creating layer pool6
I0713 09:13:14.495476 47888 net.cpp:106] Creating Layer pool6
I0713 09:13:14.495491 47888 net.cpp:454] pool6 <- conv72
I0713 09:13:14.495508 47888 net.cpp:411] pool6 -> pool6
I0713 09:13:14.495867 47888 net.cpp:150] Setting up pool6
I0713 09:13:14.495893 47888 net.cpp:157] Top shape: 6 96 15 15 (129600)
I0713 09:13:14.495906 47888 net.cpp:165] Memory required for data: 5951181384
I0713 09:13:14.495919 47888 layer_factory.hpp:76] Creating layer conv81
I0713 09:13:14.495946 47888 net.cpp:106] Creating Layer conv81
I0713 09:13:14.495960 47888 net.cpp:454] conv81 <- pool6
I0713 09:13:14.495978 47888 net.cpp:411] conv81 -> conv81
I0713 09:13:14.499647 47888 net.cpp:150] Setting up conv81
I0713 09:13:14.499682 47888 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0713 09:13:14.499696 47888 net.cpp:165] Memory required for data: 5951872584
I0713 09:13:14.499716 47888 layer_factory.hpp:76] Creating layer relu81
I0713 09:13:14.499737 47888 net.cpp:106] Creating Layer relu81
I0713 09:13:14.499750 47888 net.cpp:454] relu81 <- conv81
I0713 09:13:14.499781 47888 net.cpp:397] relu81 -> conv81 (in-place)
I0713 09:13:14.500061 47888 net.cpp:150] Setting up relu81
I0713 09:13:14.500085 47888 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0713 09:13:14.500098 47888 net.cpp:165] Memory required for data: 5952563784
I0713 09:13:14.500111 47888 layer_factory.hpp:76] Creating layer conv82
I0713 09:13:14.500151 47888 net.cpp:106] Creating Layer conv82
I0713 09:13:14.500166 47888 net.cpp:454] conv82 <- conv81
I0713 09:13:14.500186 47888 net.cpp:411] conv82 -> conv82
I0713 09:13:14.503137 47888 net.cpp:150] Setting up conv82
I0713 09:13:14.503199 47888 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0713 09:13:14.503213 47888 net.cpp:165] Memory required for data: 5953254984
I0713 09:13:14.503248 47888 layer_factory.hpp:76] Creating layer relu82
I0713 09:13:14.503283 47888 net.cpp:106] Creating Layer relu82
I0713 09:13:14.503296 47888 net.cpp:454] relu82 <- conv82
I0713 09:13:14.503314 47888 net.cpp:397] relu82 -> conv82 (in-place)
I0713 09:13:14.503816 47888 net.cpp:150] Setting up relu82
I0713 09:13:14.503844 47888 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0713 09:13:14.503856 47888 net.cpp:165] Memory required for data: 5953946184
I0713 09:13:14.503903 47888 layer_factory.hpp:76] Creating layer pool7
I0713 09:13:14.503931 47888 net.cpp:106] Creating Layer pool7
I0713 09:13:14.503938 47888 net.cpp:454] pool7 <- conv82
I0713 09:13:14.503947 47888 net.cpp:411] pool7 -> pool7
I0713 09:13:14.504559 47888 net.cpp:150] Setting up pool7
I0713 09:13:14.504571 47888 net.cpp:157] Top shape: 6 128 8 8 (49152)
I0713 09:13:14.504576 47888 net.cpp:165] Memory required for data: 5954142792
I0713 09:13:14.504581 47888 layer_factory.hpp:76] Creating layer drop0
I0713 09:13:14.504591 47888 net.cpp:106] Creating Layer drop0
I0713 09:13:14.504596 47888 net.cpp:454] drop0 <- pool7
I0713 09:13:14.504602 47888 net.cpp:397] drop0 -> pool7 (in-place)
I0713 09:13:14.504647 47888 net.cpp:150] Setting up drop0
I0713 09:13:14.504654 47888 net.cpp:157] Top shape: 6 128 8 8 (49152)
I0713 09:13:14.504658 47888 net.cpp:165] Memory required for data: 5954339400
I0713 09:13:14.504662 47888 layer_factory.hpp:76] Creating layer conv91
I0713 09:13:14.504686 47888 net.cpp:106] Creating Layer conv91
I0713 09:13:14.504693 47888 net.cpp:454] conv91 <- pool7
I0713 09:13:14.504700 47888 net.cpp:411] conv91 -> conv91
I0713 09:13:14.506008 47888 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0713 09:13:14.506041 47888 net.cpp:150] Setting up conv91
I0713 09:13:14.506048 47888 net.cpp:157] Top shape: 6 3 1 1 (18)
I0713 09:13:14.506052 47888 net.cpp:165] Memory required for data: 5954339472
I0713 09:13:14.506062 47888 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0713 09:13:14.506072 47888 net.cpp:106] Creating Layer conv91_conv91_0_split
I0713 09:13:14.506088 47888 net.cpp:454] conv91_conv91_0_split <- conv91
I0713 09:13:14.506095 47888 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0713 09:13:14.506103 47888 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0713 09:13:14.506167 47888 net.cpp:150] Setting up conv91_conv91_0_split
I0713 09:13:14.506175 47888 net.cpp:157] Top shape: 6 3 1 1 (18)
I0713 09:13:14.506180 47888 net.cpp:157] Top shape: 6 3 1 1 (18)
I0713 09:13:14.506183 47888 net.cpp:165] Memory required for data: 5954339616
I0713 09:13:14.506187 47888 layer_factory.hpp:76] Creating layer accuracy
I0713 09:13:14.506194 47888 net.cpp:106] Creating Layer accuracy
I0713 09:13:14.506198 47888 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0713 09:13:14.506204 47888 net.cpp:454] accuracy <- label_data_1_split_0
I0713 09:13:14.506211 47888 net.cpp:411] accuracy -> accuracy
I0713 09:13:14.506219 47888 net.cpp:150] Setting up accuracy
I0713 09:13:14.506224 47888 net.cpp:157] Top shape: (1)
I0713 09:13:14.506228 47888 net.cpp:165] Memory required for data: 5954339620
I0713 09:13:14.506232 47888 layer_factory.hpp:76] Creating layer loss
I0713 09:13:14.506242 47888 net.cpp:106] Creating Layer loss
I0713 09:13:14.506247 47888 net.cpp:454] loss <- conv91_conv91_0_split_1
I0713 09:13:14.506252 47888 net.cpp:454] loss <- label_data_1_split_1
I0713 09:13:14.506258 47888 net.cpp:411] loss -> loss
I0713 09:13:14.506273 47888 layer_factory.hpp:76] Creating layer loss
I0713 09:13:14.506769 47888 net.cpp:150] Setting up loss
I0713 09:13:14.506781 47888 net.cpp:157] Top shape: (1)
I0713 09:13:14.506785 47888 net.cpp:160]     with loss weight 1
I0713 09:13:14.506798 47888 net.cpp:165] Memory required for data: 5954339624
I0713 09:13:14.506803 47888 net.cpp:226] loss needs backward computation.
I0713 09:13:14.506829 47888 net.cpp:228] accuracy does not need backward computation.
I0713 09:13:14.506834 47888 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0713 09:13:14.506837 47888 net.cpp:226] conv91 needs backward computation.
I0713 09:13:14.506842 47888 net.cpp:226] drop0 needs backward computation.
I0713 09:13:14.506845 47888 net.cpp:226] pool7 needs backward computation.
I0713 09:13:14.506850 47888 net.cpp:226] relu82 needs backward computation.
I0713 09:13:14.506855 47888 net.cpp:226] conv82 needs backward computation.
I0713 09:13:14.506858 47888 net.cpp:226] relu81 needs backward computation.
I0713 09:13:14.506862 47888 net.cpp:226] conv81 needs backward computation.
I0713 09:13:14.506866 47888 net.cpp:226] pool6 needs backward computation.
I0713 09:13:14.506870 47888 net.cpp:226] relu72 needs backward computation.
I0713 09:13:14.506875 47888 net.cpp:226] conv72 needs backward computation.
I0713 09:13:14.506880 47888 net.cpp:226] relu71 needs backward computation.
I0713 09:13:14.506882 47888 net.cpp:226] conv71 needs backward computation.
I0713 09:13:14.506887 47888 net.cpp:226] pool5 needs backward computation.
I0713 09:13:14.506892 47888 net.cpp:226] relu62 needs backward computation.
I0713 09:13:14.506896 47888 net.cpp:226] conv62 needs backward computation.
I0713 09:13:14.506901 47888 net.cpp:226] relu61 needs backward computation.
I0713 09:13:14.506904 47888 net.cpp:226] conv61 needs backward computation.
I0713 09:13:14.506909 47888 net.cpp:228] relu53 does not need backward computation.
I0713 09:13:14.506913 47888 net.cpp:228] conv53 does not need backward computation.
I0713 09:13:14.506917 47888 net.cpp:228] relu52 does not need backward computation.
I0713 09:13:14.506924 47888 net.cpp:228] conv52 does not need backward computation.
I0713 09:13:14.506929 47888 net.cpp:228] relu51 does not need backward computation.
I0713 09:13:14.506933 47888 net.cpp:228] conv51 does not need backward computation.
I0713 09:13:14.506938 47888 net.cpp:228] pool4 does not need backward computation.
I0713 09:13:14.506942 47888 net.cpp:228] relu42 does not need backward computation.
I0713 09:13:14.506947 47888 net.cpp:228] conv42 does not need backward computation.
I0713 09:13:14.506953 47888 net.cpp:228] relu41 does not need backward computation.
I0713 09:13:14.506956 47888 net.cpp:228] conv41 does not need backward computation.
I0713 09:13:14.506961 47888 net.cpp:228] pool3 does not need backward computation.
I0713 09:13:14.506966 47888 net.cpp:228] relu32 does not need backward computation.
I0713 09:13:14.506970 47888 net.cpp:228] conv32 does not need backward computation.
I0713 09:13:14.506975 47888 net.cpp:228] relu31 does not need backward computation.
I0713 09:13:14.506979 47888 net.cpp:228] conv31 does not need backward computation.
I0713 09:13:14.506984 47888 net.cpp:228] pool2 does not need backward computation.
I0713 09:13:14.506989 47888 net.cpp:228] relu22 does not need backward computation.
I0713 09:13:14.506994 47888 net.cpp:228] conv22 does not need backward computation.
I0713 09:13:14.506997 47888 net.cpp:228] relu21 does not need backward computation.
I0713 09:13:14.507010 47888 net.cpp:228] conv21 does not need backward computation.
I0713 09:13:14.507015 47888 net.cpp:228] pool1 does not need backward computation.
I0713 09:13:14.507026 47888 net.cpp:228] relu12 does not need backward computation.
I0713 09:13:14.507031 47888 net.cpp:228] conv12 does not need backward computation.
I0713 09:13:14.507045 47888 net.cpp:228] relu11 does not need backward computation.
I0713 09:13:14.507050 47888 net.cpp:228] conv11 does not need backward computation.
I0713 09:13:14.507055 47888 net.cpp:228] label_data_1_split does not need backward computation.
I0713 09:13:14.507061 47888 net.cpp:228] data does not need backward computation.
I0713 09:13:14.507063 47888 net.cpp:270] This network produces output accuracy
I0713 09:13:14.507068 47888 net.cpp:270] This network produces output loss
I0713 09:13:14.507097 47888 net.cpp:283] Network initialization done.
I0713 09:13:14.507386 47888 solver.cpp:59] Solver scaffolding done.
I0713 09:13:14.508908 47888 caffe.cpp:128] Finetuning from models/cnn10_iter_217316.caffemodel
I0713 09:13:14.612555 47888 caffe.cpp:212] Starting Optimization
I0713 09:13:14.612606 47888 solver.cpp:287] Solving FaceNN
I0713 09:13:14.612617 47888 solver.cpp:288] Learning Rate Policy: step
I0713 09:13:15.662782 47888 solver.cpp:236] Iteration 0, loss = 1.0746
I0713 09:13:15.662843 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:13:15.662863 47888 solver.cpp:252]     Train net output #1: loss = 1.0746 (* 1 = 1.0746 loss)
I0713 09:13:15.662890 47888 sgd_solver.cpp:106] Iteration 0, lr = 0.02
I0713 09:13:16.487653 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:14:54.422253 47888 solver.cpp:236] Iteration 100, loss = 1.07358
I0713 09:14:54.435168 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:14:54.435187 47888 solver.cpp:252]     Train net output #1: loss = 1.09589 (* 1 = 1.09589 loss)
I0713 09:14:54.435200 47888 sgd_solver.cpp:106] Iteration 100, lr = 0.02
I0713 09:16:31.155454 47888 solver.cpp:236] Iteration 200, loss = 1.08556
I0713 09:16:31.155613 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:16:31.155647 47888 solver.cpp:252]     Train net output #1: loss = 0.903602 (* 1 = 0.903602 loss)
I0713 09:16:31.155661 47888 sgd_solver.cpp:106] Iteration 200, lr = 0.02
I0713 09:18:08.798312 47888 solver.cpp:236] Iteration 300, loss = 1.07743
I0713 09:18:08.798454 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:18:08.798487 47888 solver.cpp:252]     Train net output #1: loss = 1.1008 (* 1 = 1.1008 loss)
I0713 09:18:08.798501 47888 sgd_solver.cpp:106] Iteration 300, lr = 0.02
I0713 09:19:45.604293 47888 solver.cpp:236] Iteration 400, loss = 1.06528
I0713 09:19:45.604444 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:19:45.604480 47888 solver.cpp:252]     Train net output #1: loss = 0.973749 (* 1 = 0.973749 loss)
I0713 09:19:45.604495 47888 sgd_solver.cpp:106] Iteration 400, lr = 0.02
I0713 09:21:21.673861 47888 solver.cpp:236] Iteration 500, loss = 1.06779
I0713 09:21:21.674093 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:21:21.674129 47888 solver.cpp:252]     Train net output #1: loss = 1.11503 (* 1 = 1.11503 loss)
I0713 09:21:21.674142 47888 sgd_solver.cpp:106] Iteration 500, lr = 0.02
I0713 09:22:58.293243 47888 solver.cpp:236] Iteration 600, loss = 1.0832
I0713 09:22:58.293424 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:22:58.293467 47888 solver.cpp:252]     Train net output #1: loss = 0.958325 (* 1 = 0.958325 loss)
I0713 09:22:58.293479 47888 sgd_solver.cpp:106] Iteration 600, lr = 0.02
I0713 09:24:35.069257 47888 solver.cpp:236] Iteration 700, loss = 1.06783
I0713 09:24:35.069433 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:24:35.069453 47888 solver.cpp:252]     Train net output #1: loss = 0.895247 (* 1 = 0.895247 loss)
I0713 09:24:35.069465 47888 sgd_solver.cpp:106] Iteration 700, lr = 0.02
I0713 09:26:12.032121 47888 solver.cpp:236] Iteration 800, loss = 1.08151
I0713 09:26:12.032313 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:26:12.032346 47888 solver.cpp:252]     Train net output #1: loss = 0.995862 (* 1 = 0.995862 loss)
I0713 09:26:12.032361 47888 sgd_solver.cpp:106] Iteration 800, lr = 0.02
I0713 09:27:49.158285 47888 solver.cpp:236] Iteration 900, loss = 1.08962
I0713 09:27:49.158424 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:27:49.158473 47888 solver.cpp:252]     Train net output #1: loss = 1.03324 (* 1 = 1.03324 loss)
I0713 09:27:49.158484 47888 sgd_solver.cpp:106] Iteration 900, lr = 0.02
I0713 09:29:26.497553 47888 solver.cpp:236] Iteration 1000, loss = 1.08023
I0713 09:29:26.497750 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:29:26.497778 47888 solver.cpp:252]     Train net output #1: loss = 0.916674 (* 1 = 0.916674 loss)
I0713 09:29:26.497792 47888 sgd_solver.cpp:106] Iteration 1000, lr = 0.02
I0713 09:31:03.298007 47888 solver.cpp:236] Iteration 1100, loss = 1.07421
I0713 09:31:03.298203 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:31:03.298234 47888 solver.cpp:252]     Train net output #1: loss = 1.24199 (* 1 = 1.24199 loss)
I0713 09:31:03.298248 47888 sgd_solver.cpp:106] Iteration 1100, lr = 0.02
I0713 09:32:40.336069 47888 solver.cpp:236] Iteration 1200, loss = 1.06241
I0713 09:32:40.352993 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:32:40.353013 47888 solver.cpp:252]     Train net output #1: loss = 1.14969 (* 1 = 1.14969 loss)
I0713 09:32:40.353023 47888 sgd_solver.cpp:106] Iteration 1200, lr = 0.02
I0713 09:34:17.169877 47888 solver.cpp:236] Iteration 1300, loss = 1.04818
I0713 09:34:17.170042 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:34:17.170063 47888 solver.cpp:252]     Train net output #1: loss = 1.04829 (* 1 = 1.04829 loss)
I0713 09:34:17.170076 47888 sgd_solver.cpp:106] Iteration 1300, lr = 0.02
I0713 09:35:35.184303 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:35:55.255287 47888 solver.cpp:236] Iteration 1400, loss = 1.07233
I0713 09:35:55.255343 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:35:55.255363 47888 solver.cpp:252]     Train net output #1: loss = 1.05564 (* 1 = 1.05564 loss)
I0713 09:35:55.255376 47888 sgd_solver.cpp:106] Iteration 1400, lr = 0.02
I0713 09:37:36.965701 47888 solver.cpp:340] Iteration 1500, Testing net (#0)
I0713 09:38:48.340076 47888 solver.cpp:408]     Test net output #0: accuracy = 0.483333
I0713 09:38:48.340277 47888 solver.cpp:408]     Test net output #1: loss = 1.04709 (* 1 = 1.04709 loss)
I0713 09:38:49.103705 47888 solver.cpp:236] Iteration 1500, loss = 1.05261
I0713 09:38:49.103756 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:38:49.103776 47888 solver.cpp:252]     Train net output #1: loss = 1.20245 (* 1 = 1.20245 loss)
I0713 09:38:49.103791 47888 sgd_solver.cpp:106] Iteration 1500, lr = 0.02
I0713 09:40:26.650117 47888 solver.cpp:236] Iteration 1600, loss = 1.08037
I0713 09:40:26.650255 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:40:26.650277 47888 solver.cpp:252]     Train net output #1: loss = 1.14415 (* 1 = 1.14415 loss)
I0713 09:40:26.650292 47888 sgd_solver.cpp:106] Iteration 1600, lr = 0.02
I0713 09:42:03.189870 47888 solver.cpp:236] Iteration 1700, loss = 1.07947
I0713 09:42:03.190076 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 09:42:03.190107 47888 solver.cpp:252]     Train net output #1: loss = 0.963106 (* 1 = 0.963106 loss)
I0713 09:42:03.190135 47888 sgd_solver.cpp:106] Iteration 1700, lr = 0.02
I0713 09:43:40.775205 47888 solver.cpp:236] Iteration 1800, loss = 1.06324
I0713 09:43:40.775444 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:43:40.775478 47888 solver.cpp:252]     Train net output #1: loss = 0.917098 (* 1 = 0.917098 loss)
I0713 09:43:40.775491 47888 sgd_solver.cpp:106] Iteration 1800, lr = 0.02
I0713 09:45:18.027643 47888 solver.cpp:236] Iteration 1900, loss = 1.0721
I0713 09:45:18.027817 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 09:45:18.027837 47888 solver.cpp:252]     Train net output #1: loss = 1.15639 (* 1 = 1.15639 loss)
I0713 09:45:18.027849 47888 sgd_solver.cpp:106] Iteration 1900, lr = 0.02
I0713 09:46:54.900322 47888 solver.cpp:236] Iteration 2000, loss = 1.08413
I0713 09:46:54.900485 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:46:54.900507 47888 solver.cpp:252]     Train net output #1: loss = 1.11889 (* 1 = 1.11889 loss)
I0713 09:46:54.900521 47888 sgd_solver.cpp:106] Iteration 2000, lr = 0.02
I0713 09:48:32.305275 47888 solver.cpp:236] Iteration 2100, loss = 1.06393
I0713 09:48:32.305480 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:48:32.305505 47888 solver.cpp:252]     Train net output #1: loss = 0.990087 (* 1 = 0.990087 loss)
I0713 09:48:32.305516 47888 sgd_solver.cpp:106] Iteration 2100, lr = 0.02
I0713 09:50:09.208533 47888 solver.cpp:236] Iteration 2200, loss = 1.05078
I0713 09:50:09.208727 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 09:50:09.208750 47888 solver.cpp:252]     Train net output #1: loss = 1.07917 (* 1 = 1.07917 loss)
I0713 09:50:09.208765 47888 sgd_solver.cpp:106] Iteration 2200, lr = 0.02
I0713 09:51:46.390465 47888 solver.cpp:236] Iteration 2300, loss = 1.081
I0713 09:51:46.390614 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:51:46.390640 47888 solver.cpp:252]     Train net output #1: loss = 1.0215 (* 1 = 1.0215 loss)
I0713 09:51:46.390655 47888 sgd_solver.cpp:106] Iteration 2300, lr = 0.02
I0713 09:53:23.426511 47888 solver.cpp:236] Iteration 2400, loss = 1.0781
I0713 09:53:23.430704 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:53:23.430727 47888 solver.cpp:252]     Train net output #1: loss = 1.02064 (* 1 = 1.02064 loss)
I0713 09:53:23.430742 47888 sgd_solver.cpp:106] Iteration 2400, lr = 0.02
I0713 09:54:59.566674 47888 solver.cpp:236] Iteration 2500, loss = 1.07386
I0713 09:54:59.566860 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:54:59.566890 47888 solver.cpp:252]     Train net output #1: loss = 1.08629 (* 1 = 1.08629 loss)
I0713 09:54:59.566906 47888 sgd_solver.cpp:106] Iteration 2500, lr = 0.02
I0713 09:56:36.661064 47888 solver.cpp:236] Iteration 2600, loss = 1.05852
I0713 09:56:36.661227 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 09:56:36.661260 47888 solver.cpp:252]     Train net output #1: loss = 1.12632 (* 1 = 1.12632 loss)
I0713 09:56:36.661274 47888 sgd_solver.cpp:106] Iteration 2600, lr = 0.02
I0713 09:56:54.887959 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 09:58:13.553325 47888 solver.cpp:236] Iteration 2700, loss = 1.09318
I0713 09:58:13.553468 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 09:58:13.553488 47888 solver.cpp:252]     Train net output #1: loss = 1.05321 (* 1 = 1.05321 loss)
I0713 09:58:13.553503 47888 sgd_solver.cpp:106] Iteration 2700, lr = 0.02
I0713 09:59:51.176698 47888 solver.cpp:236] Iteration 2800, loss = 1.09024
I0713 09:59:51.176861 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 09:59:51.176882 47888 solver.cpp:252]     Train net output #1: loss = 0.990615 (* 1 = 0.990615 loss)
I0713 09:59:51.176894 47888 sgd_solver.cpp:106] Iteration 2800, lr = 0.02
I0713 10:01:28.051147 47888 solver.cpp:236] Iteration 2900, loss = 1.08697
I0713 10:01:28.051338 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 10:01:28.051367 47888 solver.cpp:252]     Train net output #1: loss = 1.20237 (* 1 = 1.20237 loss)
I0713 10:01:28.051378 47888 sgd_solver.cpp:106] Iteration 2900, lr = 0.02
I0713 10:03:03.418323 47888 solver.cpp:340] Iteration 3000, Testing net (#0)
I0713 10:04:14.829884 47888 solver.cpp:408]     Test net output #0: accuracy = 0.475
I0713 10:04:14.830083 47888 solver.cpp:408]     Test net output #1: loss = 1.06194 (* 1 = 1.06194 loss)
I0713 10:04:15.903681 47888 solver.cpp:236] Iteration 3000, loss = 1.05114
I0713 10:04:15.903738 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 10:04:15.903758 47888 solver.cpp:252]     Train net output #1: loss = 0.942175 (* 1 = 0.942175 loss)
I0713 10:04:15.903772 47888 sgd_solver.cpp:106] Iteration 3000, lr = 0.02
I0713 10:05:52.350980 47888 solver.cpp:236] Iteration 3100, loss = 1.08019
I0713 10:05:52.351181 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:05:52.351202 47888 solver.cpp:252]     Train net output #1: loss = 1.17364 (* 1 = 1.17364 loss)
I0713 10:05:52.351215 47888 sgd_solver.cpp:106] Iteration 3100, lr = 0.02
I0713 10:07:28.992568 47888 solver.cpp:236] Iteration 3200, loss = 1.106
I0713 10:07:28.992753 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 10:07:28.992781 47888 solver.cpp:252]     Train net output #1: loss = 1.19401 (* 1 = 1.19401 loss)
I0713 10:07:28.992801 47888 sgd_solver.cpp:106] Iteration 3200, lr = 0.02
I0713 10:09:05.256463 47888 solver.cpp:236] Iteration 3300, loss = 1.07232
I0713 10:09:05.256655 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:09:05.256681 47888 solver.cpp:252]     Train net output #1: loss = 1.1616 (* 1 = 1.1616 loss)
I0713 10:09:05.256695 47888 sgd_solver.cpp:106] Iteration 3300, lr = 0.02
I0713 10:10:42.091099 47888 solver.cpp:236] Iteration 3400, loss = 1.06418
I0713 10:10:42.091264 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:10:42.091295 47888 solver.cpp:252]     Train net output #1: loss = 1.07012 (* 1 = 1.07012 loss)
I0713 10:10:42.091308 47888 sgd_solver.cpp:106] Iteration 3400, lr = 0.02
I0713 10:12:19.027181 47888 solver.cpp:236] Iteration 3500, loss = 1.06582
I0713 10:12:19.027355 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:12:19.027393 47888 solver.cpp:252]     Train net output #1: loss = 1.04554 (* 1 = 1.04554 loss)
I0713 10:12:19.027403 47888 sgd_solver.cpp:106] Iteration 3500, lr = 0.02
I0713 10:13:55.349884 47888 solver.cpp:236] Iteration 3600, loss = 1.06428
I0713 10:13:55.350106 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:13:55.350152 47888 solver.cpp:252]     Train net output #1: loss = 1.20626 (* 1 = 1.20626 loss)
I0713 10:13:55.350172 47888 sgd_solver.cpp:106] Iteration 3600, lr = 0.02
I0713 10:15:32.341974 47888 solver.cpp:236] Iteration 3700, loss = 1.08202
I0713 10:15:32.342182 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:15:32.342206 47888 solver.cpp:252]     Train net output #1: loss = 1.08853 (* 1 = 1.08853 loss)
I0713 10:15:32.342221 47888 sgd_solver.cpp:106] Iteration 3700, lr = 0.02
I0713 10:17:09.267014 47888 solver.cpp:236] Iteration 3800, loss = 1.07795
I0713 10:17:09.270714 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:17:09.270740 47888 solver.cpp:252]     Train net output #1: loss = 0.974747 (* 1 = 0.974747 loss)
I0713 10:17:09.270755 47888 sgd_solver.cpp:106] Iteration 3800, lr = 0.02
I0713 10:18:25.410087 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:18:46.638615 47888 solver.cpp:236] Iteration 3900, loss = 1.08705
I0713 10:18:46.638684 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:18:46.638702 47888 solver.cpp:252]     Train net output #1: loss = 1.13593 (* 1 = 1.13593 loss)
I0713 10:18:46.638716 47888 sgd_solver.cpp:106] Iteration 3900, lr = 0.02
I0713 10:20:24.057039 47888 solver.cpp:236] Iteration 4000, loss = 1.07215
I0713 10:20:24.057209 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:20:24.057229 47888 solver.cpp:252]     Train net output #1: loss = 1.19489 (* 1 = 1.19489 loss)
I0713 10:20:24.057243 47888 sgd_solver.cpp:106] Iteration 4000, lr = 0.02
I0713 10:22:01.122609 47888 solver.cpp:236] Iteration 4100, loss = 1.07437
I0713 10:22:01.122779 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:22:01.122817 47888 solver.cpp:252]     Train net output #1: loss = 1.045 (* 1 = 1.045 loss)
I0713 10:22:01.122828 47888 sgd_solver.cpp:106] Iteration 4100, lr = 0.02
I0713 10:23:38.005760 47888 solver.cpp:236] Iteration 4200, loss = 1.08605
I0713 10:23:38.005960 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:23:38.005982 47888 solver.cpp:252]     Train net output #1: loss = 1.03885 (* 1 = 1.03885 loss)
I0713 10:23:38.005996 47888 sgd_solver.cpp:106] Iteration 4200, lr = 0.02
I0713 10:25:14.335819 47888 solver.cpp:236] Iteration 4300, loss = 1.08034
I0713 10:25:14.335988 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:25:14.336012 47888 solver.cpp:252]     Train net output #1: loss = 1.03559 (* 1 = 1.03559 loss)
I0713 10:25:14.336031 47888 sgd_solver.cpp:106] Iteration 4300, lr = 0.02
I0713 10:26:50.833174 47888 solver.cpp:236] Iteration 4400, loss = 1.03654
I0713 10:26:50.833336 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:26:50.833358 47888 solver.cpp:252]     Train net output #1: loss = 0.979471 (* 1 = 0.979471 loss)
I0713 10:26:50.833370 47888 sgd_solver.cpp:106] Iteration 4400, lr = 0.02
I0713 10:28:26.725697 47888 solver.cpp:340] Iteration 4500, Testing net (#0)
I0713 10:29:39.026556 47888 solver.cpp:408]     Test net output #0: accuracy = 0.43
I0713 10:29:39.026742 47888 solver.cpp:408]     Test net output #1: loss = 1.08118 (* 1 = 1.08118 loss)
I0713 10:29:39.849268 47888 solver.cpp:236] Iteration 4500, loss = 1.08014
I0713 10:29:39.849313 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:29:39.849335 47888 solver.cpp:252]     Train net output #1: loss = 1.05883 (* 1 = 1.05883 loss)
I0713 10:29:39.849349 47888 sgd_solver.cpp:106] Iteration 4500, lr = 0.02
I0713 10:31:16.986678 47888 solver.cpp:236] Iteration 4600, loss = 1.04582
I0713 10:31:16.986871 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:31:16.986927 47888 solver.cpp:252]     Train net output #1: loss = 1.09854 (* 1 = 1.09854 loss)
I0713 10:31:16.986945 47888 sgd_solver.cpp:106] Iteration 4600, lr = 0.02
I0713 10:32:53.480523 47888 solver.cpp:236] Iteration 4700, loss = 1.06561
I0713 10:32:53.480690 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:32:53.480711 47888 solver.cpp:252]     Train net output #1: loss = 1.10272 (* 1 = 1.10272 loss)
I0713 10:32:53.480725 47888 sgd_solver.cpp:106] Iteration 4700, lr = 0.02
I0713 10:34:30.488273 47888 solver.cpp:236] Iteration 4800, loss = 1.08211
I0713 10:34:30.488458 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 10:34:30.488484 47888 solver.cpp:252]     Train net output #1: loss = 1.25281 (* 1 = 1.25281 loss)
I0713 10:34:30.488500 47888 sgd_solver.cpp:106] Iteration 4800, lr = 0.02
I0713 10:36:07.174007 47888 solver.cpp:236] Iteration 4900, loss = 1.07049
I0713 10:36:07.174188 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:36:07.174229 47888 solver.cpp:252]     Train net output #1: loss = 1.0843 (* 1 = 1.0843 loss)
I0713 10:36:07.174242 47888 sgd_solver.cpp:106] Iteration 4900, lr = 0.02
I0713 10:37:43.160729 47888 solver.cpp:461] Snapshotting to binary proto file models/featurelayer3_iter_5000.caffemodel
I0713 10:37:43.559594 47888 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/featurelayer3_iter_5000.solverstate
I0713 10:37:44.681243 47888 solver.cpp:236] Iteration 5000, loss = 1.07629
I0713 10:37:44.681279 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:37:44.681293 47888 solver.cpp:252]     Train net output #1: loss = 1.14158 (* 1 = 1.14158 loss)
I0713 10:37:44.681300 47888 sgd_solver.cpp:106] Iteration 5000, lr = 0.02
I0713 10:39:21.770536 47888 solver.cpp:236] Iteration 5100, loss = 1.08841
I0713 10:39:21.770731 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:39:21.770759 47888 solver.cpp:252]     Train net output #1: loss = 1.1945 (* 1 = 1.1945 loss)
I0713 10:39:21.770772 47888 sgd_solver.cpp:106] Iteration 5100, lr = 0.02
I0713 10:40:10.346771 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 10:40:58.933096 47888 solver.cpp:236] Iteration 5200, loss = 1.08506
I0713 10:40:58.933241 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:40:58.933262 47888 solver.cpp:252]     Train net output #1: loss = 1.12369 (* 1 = 1.12369 loss)
I0713 10:40:58.933275 47888 sgd_solver.cpp:106] Iteration 5200, lr = 0.02
I0713 10:42:35.944797 47888 solver.cpp:236] Iteration 5300, loss = 1.07187
I0713 10:42:35.944964 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 10:42:35.945003 47888 solver.cpp:252]     Train net output #1: loss = 1.09981 (* 1 = 1.09981 loss)
I0713 10:42:35.945015 47888 sgd_solver.cpp:106] Iteration 5300, lr = 0.02
I0713 10:44:12.375133 47888 solver.cpp:236] Iteration 5400, loss = 1.07139
I0713 10:44:12.375339 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:44:12.375367 47888 solver.cpp:252]     Train net output #1: loss = 1.19401 (* 1 = 1.19401 loss)
I0713 10:44:12.375385 47888 sgd_solver.cpp:106] Iteration 5400, lr = 0.02
I0713 10:45:49.144101 47888 solver.cpp:236] Iteration 5500, loss = 1.07199
I0713 10:45:49.144343 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:45:49.144376 47888 solver.cpp:252]     Train net output #1: loss = 1.01284 (* 1 = 1.01284 loss)
I0713 10:45:49.144399 47888 sgd_solver.cpp:106] Iteration 5500, lr = 0.02
I0713 10:47:25.745304 47888 solver.cpp:236] Iteration 5600, loss = 1.07907
I0713 10:47:25.745457 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:47:25.745478 47888 solver.cpp:252]     Train net output #1: loss = 1.27781 (* 1 = 1.27781 loss)
I0713 10:47:25.745491 47888 sgd_solver.cpp:106] Iteration 5600, lr = 0.02
I0713 10:49:02.449587 47888 solver.cpp:236] Iteration 5700, loss = 1.07843
I0713 10:49:02.454684 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:49:02.454715 47888 solver.cpp:252]     Train net output #1: loss = 1.04701 (* 1 = 1.04701 loss)
I0713 10:49:02.454730 47888 sgd_solver.cpp:106] Iteration 5700, lr = 0.02
I0713 10:50:39.633018 47888 solver.cpp:236] Iteration 5800, loss = 1.04855
I0713 10:50:39.638694 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 10:50:39.638725 47888 solver.cpp:252]     Train net output #1: loss = 1.29507 (* 1 = 1.29507 loss)
I0713 10:50:39.638757 47888 sgd_solver.cpp:106] Iteration 5800, lr = 0.02
I0713 10:52:16.206902 47888 solver.cpp:236] Iteration 5900, loss = 1.06269
I0713 10:52:16.207059 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:52:16.207104 47888 solver.cpp:252]     Train net output #1: loss = 1.04166 (* 1 = 1.04166 loss)
I0713 10:52:16.207118 47888 sgd_solver.cpp:106] Iteration 5900, lr = 0.02
I0713 10:53:52.404664 47888 solver.cpp:340] Iteration 6000, Testing net (#0)
I0713 10:55:05.417803 47888 solver.cpp:408]     Test net output #0: accuracy = 0.436667
I0713 10:55:05.417984 47888 solver.cpp:408]     Test net output #1: loss = 1.0981 (* 1 = 1.0981 loss)
I0713 10:55:06.520898 47888 solver.cpp:236] Iteration 6000, loss = 1.05495
I0713 10:55:06.520956 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:55:06.520977 47888 solver.cpp:252]     Train net output #1: loss = 1.06193 (* 1 = 1.06193 loss)
I0713 10:55:06.520993 47888 sgd_solver.cpp:106] Iteration 6000, lr = 0.02
I0713 10:56:43.415881 47888 solver.cpp:236] Iteration 6100, loss = 1.06172
I0713 10:56:43.416065 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 10:56:43.416095 47888 solver.cpp:252]     Train net output #1: loss = 1.12465 (* 1 = 1.12465 loss)
I0713 10:56:43.416117 47888 sgd_solver.cpp:106] Iteration 6100, lr = 0.02
I0713 10:58:21.526897 47888 solver.cpp:236] Iteration 6200, loss = 1.06361
I0713 10:58:21.530711 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 10:58:21.530728 47888 solver.cpp:252]     Train net output #1: loss = 0.983654 (* 1 = 0.983654 loss)
I0713 10:58:21.530738 47888 sgd_solver.cpp:106] Iteration 6200, lr = 0.02
I0713 10:59:58.906440 47888 solver.cpp:236] Iteration 6300, loss = 1.06178
I0713 10:59:58.906596 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 10:59:58.906648 47888 solver.cpp:252]     Train net output #1: loss = 1.0205 (* 1 = 1.0205 loss)
I0713 10:59:58.906669 47888 sgd_solver.cpp:106] Iteration 6300, lr = 0.02
I0713 11:01:26.430124 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:01:37.149898 47888 solver.cpp:236] Iteration 6400, loss = 1.07282
I0713 11:01:37.149960 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:01:37.149978 47888 solver.cpp:252]     Train net output #1: loss = 1.23927 (* 1 = 1.23927 loss)
I0713 11:01:37.149996 47888 sgd_solver.cpp:106] Iteration 6400, lr = 0.02
I0713 11:03:17.064720 47888 solver.cpp:236] Iteration 6500, loss = 1.09566
I0713 11:03:17.064911 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:03:17.064950 47888 solver.cpp:252]     Train net output #1: loss = 1.10123 (* 1 = 1.10123 loss)
I0713 11:03:17.064965 47888 sgd_solver.cpp:106] Iteration 6500, lr = 0.02
I0713 11:04:55.307904 47888 solver.cpp:236] Iteration 6600, loss = 1.07043
I0713 11:04:55.308094 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:04:55.308130 47888 solver.cpp:252]     Train net output #1: loss = 1.16777 (* 1 = 1.16777 loss)
I0713 11:04:55.308146 47888 sgd_solver.cpp:106] Iteration 6600, lr = 0.02
I0713 11:06:32.600041 47888 solver.cpp:236] Iteration 6700, loss = 1.08184
I0713 11:06:32.605754 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:06:32.605805 47888 solver.cpp:252]     Train net output #1: loss = 1.17153 (* 1 = 1.17153 loss)
I0713 11:06:32.605818 47888 sgd_solver.cpp:106] Iteration 6700, lr = 0.02
I0713 11:08:10.291465 47888 solver.cpp:236] Iteration 6800, loss = 1.05985
I0713 11:08:10.297878 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:08:10.297911 47888 solver.cpp:252]     Train net output #1: loss = 1.10373 (* 1 = 1.10373 loss)
I0713 11:08:10.297925 47888 sgd_solver.cpp:106] Iteration 6800, lr = 0.02
I0713 11:09:52.440235 47888 solver.cpp:236] Iteration 6900, loss = 1.08649
I0713 11:09:52.446090 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:09:52.446120 47888 solver.cpp:252]     Train net output #1: loss = 1.1225 (* 1 = 1.1225 loss)
I0713 11:09:52.446153 47888 sgd_solver.cpp:106] Iteration 6900, lr = 0.02
I0713 11:11:35.667518 47888 solver.cpp:236] Iteration 7000, loss = 1.05034
I0713 11:11:35.677104 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:11:35.677132 47888 solver.cpp:252]     Train net output #1: loss = 0.932102 (* 1 = 0.932102 loss)
I0713 11:11:35.677151 47888 sgd_solver.cpp:106] Iteration 7000, lr = 0.02
I0713 11:13:17.100713 47888 solver.cpp:236] Iteration 7100, loss = 1.07981
I0713 11:13:17.109050 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:13:17.109084 47888 solver.cpp:252]     Train net output #1: loss = 1.08271 (* 1 = 1.08271 loss)
I0713 11:13:17.109104 47888 sgd_solver.cpp:106] Iteration 7100, lr = 0.02
I0713 11:14:57.137708 47888 solver.cpp:236] Iteration 7200, loss = 1.06676
I0713 11:14:57.142714 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:14:57.142736 47888 solver.cpp:252]     Train net output #1: loss = 1.10917 (* 1 = 1.10917 loss)
I0713 11:14:57.142756 47888 sgd_solver.cpp:106] Iteration 7200, lr = 0.02
I0713 11:16:42.602246 47888 solver.cpp:236] Iteration 7300, loss = 1.06266
I0713 11:16:42.602449 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:16:42.602483 47888 solver.cpp:252]     Train net output #1: loss = 1.04514 (* 1 = 1.04514 loss)
I0713 11:16:42.602496 47888 sgd_solver.cpp:106] Iteration 7300, lr = 0.02
I0713 11:18:24.521939 47888 solver.cpp:236] Iteration 7400, loss = 1.07951
I0713 11:18:24.522086 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:18:24.522109 47888 solver.cpp:252]     Train net output #1: loss = 0.990038 (* 1 = 0.990038 loss)
I0713 11:18:24.522121 47888 sgd_solver.cpp:106] Iteration 7400, lr = 0.02
I0713 11:20:05.978989 47888 solver.cpp:340] Iteration 7500, Testing net (#0)
I0713 11:21:24.448294 47888 solver.cpp:408]     Test net output #0: accuracy = 0.461667
I0713 11:21:24.448477 47888 solver.cpp:408]     Test net output #1: loss = 1.06406 (* 1 = 1.06406 loss)
I0713 11:21:25.551050 47888 solver.cpp:236] Iteration 7500, loss = 1.08309
I0713 11:21:25.551129 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:21:25.551151 47888 solver.cpp:252]     Train net output #1: loss = 1.11991 (* 1 = 1.11991 loss)
I0713 11:21:25.551169 47888 sgd_solver.cpp:106] Iteration 7500, lr = 0.02
I0713 11:22:18.983428 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:23:11.728782 47888 solver.cpp:236] Iteration 7600, loss = 1.08084
I0713 11:23:11.728938 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:23:11.728958 47888 solver.cpp:252]     Train net output #1: loss = 1.0947 (* 1 = 1.0947 loss)
I0713 11:23:11.728971 47888 sgd_solver.cpp:106] Iteration 7600, lr = 0.02
I0713 11:24:51.933367 47888 solver.cpp:236] Iteration 7700, loss = 1.08585
I0713 11:24:51.933560 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:24:51.933611 47888 solver.cpp:252]     Train net output #1: loss = 1.07134 (* 1 = 1.07134 loss)
I0713 11:24:51.933630 47888 sgd_solver.cpp:106] Iteration 7700, lr = 0.02
I0713 11:26:32.045083 47888 solver.cpp:236] Iteration 7800, loss = 1.0471
I0713 11:26:32.045326 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:26:32.045358 47888 solver.cpp:252]     Train net output #1: loss = 1.12281 (* 1 = 1.12281 loss)
I0713 11:26:32.045379 47888 sgd_solver.cpp:106] Iteration 7800, lr = 0.02
I0713 11:28:13.393884 47888 solver.cpp:236] Iteration 7900, loss = 1.08189
I0713 11:28:13.394029 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 11:28:13.394050 47888 solver.cpp:252]     Train net output #1: loss = 0.94463 (* 1 = 0.94463 loss)
I0713 11:28:13.394065 47888 sgd_solver.cpp:106] Iteration 7900, lr = 0.02
I0713 11:29:54.244496 47888 solver.cpp:236] Iteration 8000, loss = 1.07222
I0713 11:29:54.244648 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:29:54.244678 47888 solver.cpp:252]     Train net output #1: loss = 1.0816 (* 1 = 1.0816 loss)
I0713 11:29:54.244698 47888 sgd_solver.cpp:106] Iteration 8000, lr = 0.02
I0713 11:31:34.003123 47888 solver.cpp:236] Iteration 8100, loss = 1.0685
I0713 11:31:34.003283 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:31:34.003324 47888 solver.cpp:252]     Train net output #1: loss = 1.09219 (* 1 = 1.09219 loss)
I0713 11:31:34.003336 47888 sgd_solver.cpp:106] Iteration 8100, lr = 0.02
I0713 11:33:14.307443 47888 solver.cpp:236] Iteration 8200, loss = 1.07555
I0713 11:33:14.310716 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:33:14.310739 47888 solver.cpp:252]     Train net output #1: loss = 1.01716 (* 1 = 1.01716 loss)
I0713 11:33:14.310755 47888 sgd_solver.cpp:106] Iteration 8200, lr = 0.02
I0713 11:34:56.479117 47888 solver.cpp:236] Iteration 8300, loss = 1.06955
I0713 11:34:56.479276 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:34:56.479310 47888 solver.cpp:252]     Train net output #1: loss = 1.11053 (* 1 = 1.11053 loss)
I0713 11:34:56.479322 47888 sgd_solver.cpp:106] Iteration 8300, lr = 0.02
I0713 11:36:36.659006 47888 solver.cpp:236] Iteration 8400, loss = 1.05364
I0713 11:36:36.662727 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:36:36.662763 47888 solver.cpp:252]     Train net output #1: loss = 1.12122 (* 1 = 1.12122 loss)
I0713 11:36:36.662786 47888 sgd_solver.cpp:106] Iteration 8400, lr = 0.02
I0713 11:38:16.052626 47888 solver.cpp:236] Iteration 8500, loss = 1.07647
I0713 11:38:16.058699 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:38:16.058733 47888 solver.cpp:252]     Train net output #1: loss = 1.14547 (* 1 = 1.14547 loss)
I0713 11:38:16.058754 47888 sgd_solver.cpp:106] Iteration 8500, lr = 0.02
I0713 11:39:56.052206 47888 solver.cpp:236] Iteration 8600, loss = 1.09675
I0713 11:39:56.052373 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:39:56.052410 47888 solver.cpp:252]     Train net output #1: loss = 1.07822 (* 1 = 1.07822 loss)
I0713 11:39:56.052423 47888 sgd_solver.cpp:106] Iteration 8600, lr = 0.02
I0713 11:41:36.901386 47888 solver.cpp:236] Iteration 8700, loss = 1.07862
I0713 11:41:36.906713 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:41:36.906736 47888 solver.cpp:252]     Train net output #1: loss = 1.03586 (* 1 = 1.03586 loss)
I0713 11:41:36.906762 47888 sgd_solver.cpp:106] Iteration 8700, lr = 0.02
I0713 11:43:17.064144 47888 solver.cpp:236] Iteration 8800, loss = 1.07908
I0713 11:43:17.064285 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:43:17.064318 47888 solver.cpp:252]     Train net output #1: loss = 1.11804 (* 1 = 1.11804 loss)
I0713 11:43:17.064330 47888 sgd_solver.cpp:106] Iteration 8800, lr = 0.02
I0713 11:44:53.904369 47888 solver.cpp:236] Iteration 8900, loss = 1.0583
I0713 11:44:53.906738 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:44:53.906775 47888 solver.cpp:252]     Train net output #1: loss = 1.27033 (* 1 = 1.27033 loss)
I0713 11:44:53.906786 47888 sgd_solver.cpp:106] Iteration 8900, lr = 0.02
I0713 11:45:18.911597 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 11:46:29.626312 47888 solver.cpp:340] Iteration 9000, Testing net (#0)
I0713 11:47:39.739207 47888 solver.cpp:408]     Test net output #0: accuracy = 0.44
I0713 11:47:39.746870 47888 solver.cpp:408]     Test net output #1: loss = 1.0777 (* 1 = 1.0777 loss)
I0713 11:47:40.838898 47888 solver.cpp:236] Iteration 9000, loss = 1.07337
I0713 11:47:40.838955 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:47:40.838973 47888 solver.cpp:252]     Train net output #1: loss = 1.10375 (* 1 = 1.10375 loss)
I0713 11:47:40.838990 47888 sgd_solver.cpp:106] Iteration 9000, lr = 0.02
I0713 11:49:17.433246 47888 solver.cpp:236] Iteration 9100, loss = 1.07414
I0713 11:49:17.447309 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 11:49:17.447345 47888 solver.cpp:252]     Train net output #1: loss = 1.02691 (* 1 = 1.02691 loss)
I0713 11:49:17.447365 47888 sgd_solver.cpp:106] Iteration 9100, lr = 0.02
I0713 11:50:53.965193 47888 solver.cpp:236] Iteration 9200, loss = 1.08219
I0713 11:50:53.981700 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 11:50:53.981755 47888 solver.cpp:252]     Train net output #1: loss = 1.14135 (* 1 = 1.14135 loss)
I0713 11:50:53.981781 47888 sgd_solver.cpp:106] Iteration 9200, lr = 0.02
I0713 11:52:30.592806 47888 solver.cpp:236] Iteration 9300, loss = 1.05252
I0713 11:52:30.607707 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 11:52:30.607748 47888 solver.cpp:252]     Train net output #1: loss = 0.948608 (* 1 = 0.948608 loss)
I0713 11:52:30.607756 47888 sgd_solver.cpp:106] Iteration 9300, lr = 0.02
I0713 11:54:08.026773 47888 solver.cpp:236] Iteration 9400, loss = 1.07709
I0713 11:54:08.041646 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 11:54:08.041697 47888 solver.cpp:252]     Train net output #1: loss = 1.12071 (* 1 = 1.12071 loss)
I0713 11:54:08.041712 47888 sgd_solver.cpp:106] Iteration 9400, lr = 0.02
I0713 11:55:44.723021 47888 solver.cpp:236] Iteration 9500, loss = 1.06812
I0713 11:55:44.734304 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:55:44.734335 47888 solver.cpp:252]     Train net output #1: loss = 1.19688 (* 1 = 1.19688 loss)
I0713 11:55:44.734364 47888 sgd_solver.cpp:106] Iteration 9500, lr = 0.02
I0713 11:57:21.683143 47888 solver.cpp:236] Iteration 9600, loss = 1.08936
I0713 11:57:21.701766 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 11:57:21.701813 47888 solver.cpp:252]     Train net output #1: loss = 1.23395 (* 1 = 1.23395 loss)
I0713 11:57:21.701835 47888 sgd_solver.cpp:106] Iteration 9600, lr = 0.02
I0713 11:58:58.140981 47888 solver.cpp:236] Iteration 9700, loss = 1.07329
I0713 11:58:58.152849 47888 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0713 11:58:58.152878 47888 solver.cpp:252]     Train net output #1: loss = 1.17494 (* 1 = 1.17494 loss)
I0713 11:58:58.152899 47888 sgd_solver.cpp:106] Iteration 9700, lr = 0.02
I0713 12:00:34.765249 47888 solver.cpp:236] Iteration 9800, loss = 1.06978
I0713 12:00:34.778957 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:00:34.778985 47888 solver.cpp:252]     Train net output #1: loss = 1.04221 (* 1 = 1.04221 loss)
I0713 12:00:34.778995 47888 sgd_solver.cpp:106] Iteration 9800, lr = 0.02
I0713 12:02:11.499948 47888 solver.cpp:236] Iteration 9900, loss = 1.07546
I0713 12:02:11.521487 47888 solver.cpp:252]     Train net output #0: accuracy = 0
I0713 12:02:11.521528 47888 solver.cpp:252]     Train net output #1: loss = 1.3402 (* 1 = 1.3402 loss)
I0713 12:02:11.521543 47888 sgd_solver.cpp:106] Iteration 9900, lr = 0.02
I0713 12:03:47.667356 47888 solver.cpp:461] Snapshotting to binary proto file models/featurelayer3_iter_10000.caffemodel
I0713 12:03:47.808614 47888 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models/featurelayer3_iter_10000.solverstate
I0713 12:03:48.648726 47888 solver.cpp:236] Iteration 10000, loss = 1.06406
I0713 12:03:48.648844 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 12:03:48.648874 47888 solver.cpp:252]     Train net output #1: loss = 1.05745 (* 1 = 1.05745 loss)
I0713 12:03:48.648895 47888 sgd_solver.cpp:106] Iteration 10000, lr = 0.02
I0713 12:05:25.567190 47888 solver.cpp:236] Iteration 10100, loss = 1.06463
I0713 12:05:25.581539 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 12:05:25.581596 47888 solver.cpp:252]     Train net output #1: loss = 0.924802 (* 1 = 0.924802 loss)
I0713 12:05:25.581621 47888 sgd_solver.cpp:106] Iteration 10100, lr = 0.02
I0713 12:07:02.165805 47888 solver.cpp:236] Iteration 10200, loss = 1.05719
I0713 12:07:02.174147 47888 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0713 12:07:02.174186 47888 solver.cpp:252]     Train net output #1: loss = 0.965465 (* 1 = 0.965465 loss)
I0713 12:07:02.174202 47888 sgd_solver.cpp:106] Iteration 10200, lr = 0.02
I0713 12:08:24.101580 47888 blocking_queue.cpp:50] Data layer prefetch queue empty
I0713 12:08:38.717797 47888 solver.cpp:236] Iteration 10300, loss = 1.062
I0713 12:08:38.717907 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 12:08:38.717953 47888 solver.cpp:252]     Train net output #1: loss = 1.19911 (* 1 = 1.19911 loss)
I0713 12:08:38.717988 47888 sgd_solver.cpp:106] Iteration 10300, lr = 0.02
I0713 12:10:15.404873 47888 solver.cpp:236] Iteration 10400, loss = 1.0447
I0713 12:10:15.417806 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:10:15.417840 47888 solver.cpp:252]     Train net output #1: loss = 1.001 (* 1 = 1.001 loss)
I0713 12:10:15.417852 47888 sgd_solver.cpp:106] Iteration 10400, lr = 0.02
I0713 12:11:50.396028 47888 solver.cpp:340] Iteration 10500, Testing net (#0)
I0713 12:13:00.772541 47888 solver.cpp:408]     Test net output #0: accuracy = 0.443333
I0713 12:13:00.783962 47888 solver.cpp:408]     Test net output #1: loss = 1.08772 (* 1 = 1.08772 loss)
I0713 12:13:01.806337 47888 solver.cpp:236] Iteration 10500, loss = 1.04444
I0713 12:13:01.806387 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:13:01.806406 47888 solver.cpp:252]     Train net output #1: loss = 1.04137 (* 1 = 1.04137 loss)
I0713 12:13:01.806421 47888 sgd_solver.cpp:106] Iteration 10500, lr = 0.02
I0713 12:14:38.767366 47888 solver.cpp:236] Iteration 10600, loss = 1.07333
I0713 12:14:38.784278 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:14:38.784323 47888 solver.cpp:252]     Train net output #1: loss = 1.0243 (* 1 = 1.0243 loss)
I0713 12:14:38.784337 47888 sgd_solver.cpp:106] Iteration 10600, lr = 0.02
I0713 12:16:18.684094 47888 solver.cpp:236] Iteration 10700, loss = 1.07948
I0713 12:16:18.708605 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:16:18.708642 47888 solver.cpp:252]     Train net output #1: loss = 1.02754 (* 1 = 1.02754 loss)
I0713 12:16:18.708658 47888 sgd_solver.cpp:106] Iteration 10700, lr = 0.02
I0713 12:18:00.290354 47888 solver.cpp:236] Iteration 10800, loss = 1.08578
I0713 12:18:00.307085 47888 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0713 12:18:00.307121 47888 solver.cpp:252]     Train net output #1: loss = 1.05293 (* 1 = 1.05293 loss)
I0713 12:18:00.307135 47888 sgd_solver.cpp:106] Iteration 10800, lr = 0.02
I0713 12:19:42.672811 47888 solver.cpp:236] Iteration 10900, loss = 1.0792
I0713 12:19:42.672966 47888 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0713 12:19:42.672996 47888 solver.cpp:252]     Train net output #1: loss = 1.2139 (* 1 = 1.2139 loss)
I0713 12:19:42.673013 47888 sgd_solver.cpp:106] Iteration 10900, lr = 0.02
I0713 12:21:23.081725 47888 solver.cpp:236] Iteration 11000, loss = 1.07412
I0713 12:21:23.081904 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 12:21:23.081924 47888 solver.cpp:252]     Train net output #1: loss = 1.13031 (* 1 = 1.13031 loss)
I0713 12:21:23.081938 47888 sgd_solver.cpp:106] Iteration 11000, lr = 0.02
I0713 12:23:05.047508 47888 solver.cpp:236] Iteration 11100, loss = 1.06327
I0713 12:23:05.069363 47888 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0713 12:23:05.069418 47888 solver.cpp:252]     Train net output #1: loss = 1.09202 (* 1 = 1.09202 loss)
I0713 12:23:05.069433 47888 sgd_solver.cpp:106] Iteration 11100, lr = 0.02
I0713 12:24:44.854902 47888 solver.cpp:236] Iteration 11200, loss = 1.05482
I0713 12:24:44.855139 47888 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0713 12:24:44.855175 47888 solver.cpp:252]     Train net output #1: loss = 0.940118 (* 1 = 0.940118 loss)
I0713 12:24:44.855185 47888 sgd_solver.cpp:106] Iteration 11200, lr = 0.02
F0713 12:25:46.934468 47890 data_transformer.cpp:240] Check failed: height <= img_height (1000 vs. 56) 
