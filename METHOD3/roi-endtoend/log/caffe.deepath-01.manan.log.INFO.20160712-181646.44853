Log file created at: 2016/07/12 18:16:46
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0712 18:16:46.276860 44853 caffe.cpp:184] Using GPUs 1
I0712 18:16:46.597744 44853 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 1500
base_lr: 0.015
display: 100
max_iter: 500000
lr_policy: "step"
gamma: 0.1
momentum: 0.85
weight_decay: 0.015
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models/featurelayer3"
solver_mode: GPU
device_id: 1
net: "train_val-featurelayer-3stack.prototxt"
test_initialization: false
average_loss: 50
I0712 18:16:46.598042 44853 solver.cpp:90] Creating training net from net file: train_val-featurelayer-3stack.prototxt
I0712 18:16:46.599180 44853 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0712 18:16:46.599530 44853 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "conv53"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0712 18:16:46.603431 44853 layer_factory.hpp:76] Creating layer data
I0712 18:16:46.603502 44853 net.cpp:106] Creating Layer data
I0712 18:16:46.603533 44853 net.cpp:411] data -> data
I0712 18:16:46.603588 44853 net.cpp:411] data -> label
I0712 18:16:46.604068 44853 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0712 18:16:46.618065 44853 image_data_layer.cpp:46] Shuffling data
I0712 18:16:46.620798 44853 image_data_layer.cpp:51] A total of 23544 images.
I0712 18:16:46.738462 44853 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0712 18:16:47.068917 44853 net.cpp:150] Setting up data
I0712 18:16:47.068994 44853 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0712 18:16:47.069006 44853 net.cpp:157] Top shape: 8 (8)
I0712 18:16:47.069016 44853 net.cpp:165] Memory required for data: 96000032
I0712 18:16:47.069033 44853 layer_factory.hpp:76] Creating layer label_data_1_split
I0712 18:16:47.069061 44853 net.cpp:106] Creating Layer label_data_1_split
I0712 18:16:47.069073 44853 net.cpp:454] label_data_1_split <- label
I0712 18:16:47.069094 44853 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0712 18:16:47.069111 44853 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0712 18:16:47.069185 44853 net.cpp:150] Setting up label_data_1_split
I0712 18:16:47.069200 44853 net.cpp:157] Top shape: 8 (8)
I0712 18:16:47.069210 44853 net.cpp:157] Top shape: 8 (8)
I0712 18:16:47.069218 44853 net.cpp:165] Memory required for data: 96000096
I0712 18:16:47.069227 44853 layer_factory.hpp:76] Creating layer conv11
I0712 18:16:47.069258 44853 net.cpp:106] Creating Layer conv11
I0712 18:16:47.069269 44853 net.cpp:454] conv11 <- data
I0712 18:16:47.069281 44853 net.cpp:411] conv11 -> conv11
I0712 18:16:47.271404 44853 net.cpp:150] Setting up conv11
I0712 18:16:47.271456 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.271497 44853 net.cpp:165] Memory required for data: 1120000096
I0712 18:16:47.271528 44853 layer_factory.hpp:76] Creating layer relu11
I0712 18:16:47.271550 44853 net.cpp:106] Creating Layer relu11
I0712 18:16:47.271561 44853 net.cpp:454] relu11 <- conv11
I0712 18:16:47.271574 44853 net.cpp:397] relu11 -> conv11 (in-place)
I0712 18:16:47.271822 44853 net.cpp:150] Setting up relu11
I0712 18:16:47.271842 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.271852 44853 net.cpp:165] Memory required for data: 2144000096
I0712 18:16:47.271860 44853 layer_factory.hpp:76] Creating layer conv12
I0712 18:16:47.271883 44853 net.cpp:106] Creating Layer conv12
I0712 18:16:47.271894 44853 net.cpp:454] conv12 <- conv11
I0712 18:16:47.271906 44853 net.cpp:411] conv12 -> conv12
I0712 18:16:47.277235 44853 net.cpp:150] Setting up conv12
I0712 18:16:47.277282 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.277293 44853 net.cpp:165] Memory required for data: 3168000096
I0712 18:16:47.277315 44853 layer_factory.hpp:76] Creating layer relu12
I0712 18:16:47.277333 44853 net.cpp:106] Creating Layer relu12
I0712 18:16:47.277343 44853 net.cpp:454] relu12 <- conv12
I0712 18:16:47.277355 44853 net.cpp:397] relu12 -> conv12 (in-place)
I0712 18:16:47.277776 44853 net.cpp:150] Setting up relu12
I0712 18:16:47.277797 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.277807 44853 net.cpp:165] Memory required for data: 4192000096
I0712 18:16:47.277817 44853 layer_factory.hpp:76] Creating layer pool1
I0712 18:16:47.277830 44853 net.cpp:106] Creating Layer pool1
I0712 18:16:47.277840 44853 net.cpp:454] pool1 <- conv12
I0712 18:16:47.277854 44853 net.cpp:411] pool1 -> pool1
I0712 18:16:47.278117 44853 net.cpp:150] Setting up pool1
I0712 18:16:47.278137 44853 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0712 18:16:47.278146 44853 net.cpp:165] Memory required for data: 4448000096
I0712 18:16:47.278156 44853 layer_factory.hpp:76] Creating layer conv21
I0712 18:16:47.278175 44853 net.cpp:106] Creating Layer conv21
I0712 18:16:47.278185 44853 net.cpp:454] conv21 <- pool1
I0712 18:16:47.278200 44853 net.cpp:411] conv21 -> conv21
I0712 18:16:47.281194 44853 net.cpp:150] Setting up conv21
I0712 18:16:47.281229 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.281242 44853 net.cpp:165] Memory required for data: 4960000096
I0712 18:16:47.281260 44853 layer_factory.hpp:76] Creating layer relu21
I0712 18:16:47.281276 44853 net.cpp:106] Creating Layer relu21
I0712 18:16:47.281286 44853 net.cpp:454] relu21 <- conv21
I0712 18:16:47.281297 44853 net.cpp:397] relu21 -> conv21 (in-place)
I0712 18:16:47.281639 44853 net.cpp:150] Setting up relu21
I0712 18:16:47.281661 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.281672 44853 net.cpp:165] Memory required for data: 5472000096
I0712 18:16:47.281680 44853 layer_factory.hpp:76] Creating layer conv22
I0712 18:16:47.281699 44853 net.cpp:106] Creating Layer conv22
I0712 18:16:47.281708 44853 net.cpp:454] conv22 <- conv21
I0712 18:16:47.281720 44853 net.cpp:411] conv22 -> conv22
I0712 18:16:47.283877 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:16:47.284102 44853 net.cpp:150] Setting up conv22
I0712 18:16:47.284123 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.284133 44853 net.cpp:165] Memory required for data: 5984000096
I0712 18:16:47.284147 44853 layer_factory.hpp:76] Creating layer relu22
I0712 18:16:47.284163 44853 net.cpp:106] Creating Layer relu22
I0712 18:16:47.284173 44853 net.cpp:454] relu22 <- conv22
I0712 18:16:47.284184 44853 net.cpp:397] relu22 -> conv22 (in-place)
I0712 18:16:47.284519 44853 net.cpp:150] Setting up relu22
I0712 18:16:47.284541 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.284551 44853 net.cpp:165] Memory required for data: 6496000096
I0712 18:16:47.284560 44853 layer_factory.hpp:76] Creating layer pool2
I0712 18:16:47.284577 44853 net.cpp:106] Creating Layer pool2
I0712 18:16:47.284611 44853 net.cpp:454] pool2 <- conv22
I0712 18:16:47.284626 44853 net.cpp:411] pool2 -> pool2
I0712 18:16:47.284847 44853 net.cpp:150] Setting up pool2
I0712 18:16:47.284868 44853 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0712 18:16:47.284876 44853 net.cpp:165] Memory required for data: 6624000096
I0712 18:16:47.284886 44853 layer_factory.hpp:76] Creating layer conv31
I0712 18:16:47.284904 44853 net.cpp:106] Creating Layer conv31
I0712 18:16:47.284914 44853 net.cpp:454] conv31 <- pool2
I0712 18:16:47.284925 44853 net.cpp:411] conv31 -> conv31
I0712 18:16:47.286489 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:16:47.286530 44853 net.cpp:150] Setting up conv31
I0712 18:16:47.286545 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.286553 44853 net.cpp:165] Memory required for data: 6816000096
I0712 18:16:47.286571 44853 layer_factory.hpp:76] Creating layer relu31
I0712 18:16:47.286582 44853 net.cpp:106] Creating Layer relu31
I0712 18:16:47.286592 44853 net.cpp:454] relu31 <- conv31
I0712 18:16:47.286607 44853 net.cpp:397] relu31 -> conv31 (in-place)
I0712 18:16:47.286945 44853 net.cpp:150] Setting up relu31
I0712 18:16:47.286967 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.286977 44853 net.cpp:165] Memory required for data: 7008000096
I0712 18:16:47.286986 44853 layer_factory.hpp:76] Creating layer conv32
I0712 18:16:47.287003 44853 net.cpp:106] Creating Layer conv32
I0712 18:16:47.287014 44853 net.cpp:454] conv32 <- conv31
I0712 18:16:47.287027 44853 net.cpp:411] conv32 -> conv32
I0712 18:16:47.289594 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:16:47.289641 44853 net.cpp:150] Setting up conv32
I0712 18:16:47.289655 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.289665 44853 net.cpp:165] Memory required for data: 7200000096
I0712 18:16:47.289679 44853 layer_factory.hpp:76] Creating layer relu32
I0712 18:16:47.289692 44853 net.cpp:106] Creating Layer relu32
I0712 18:16:47.289701 44853 net.cpp:454] relu32 <- conv32
I0712 18:16:47.289712 44853 net.cpp:397] relu32 -> conv32 (in-place)
I0712 18:16:47.289904 44853 net.cpp:150] Setting up relu32
I0712 18:16:47.289922 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.289932 44853 net.cpp:165] Memory required for data: 7392000096
I0712 18:16:47.289942 44853 layer_factory.hpp:76] Creating layer pool3
I0712 18:16:47.289960 44853 net.cpp:106] Creating Layer pool3
I0712 18:16:47.289969 44853 net.cpp:454] pool3 <- conv32
I0712 18:16:47.289981 44853 net.cpp:411] pool3 -> pool3
I0712 18:16:47.290354 44853 net.cpp:150] Setting up pool3
I0712 18:16:47.290376 44853 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0712 18:16:47.290385 44853 net.cpp:165] Memory required for data: 7440000096
I0712 18:16:47.290395 44853 layer_factory.hpp:76] Creating layer conv41
I0712 18:16:47.290410 44853 net.cpp:106] Creating Layer conv41
I0712 18:16:47.290418 44853 net.cpp:454] conv41 <- pool3
I0712 18:16:47.290432 44853 net.cpp:411] conv41 -> conv41
I0712 18:16:47.292184 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:16:47.292222 44853 net.cpp:150] Setting up conv41
I0712 18:16:47.292237 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.292245 44853 net.cpp:165] Memory required for data: 7504000096
I0712 18:16:47.292258 44853 layer_factory.hpp:76] Creating layer relu41
I0712 18:16:47.292273 44853 net.cpp:106] Creating Layer relu41
I0712 18:16:47.292281 44853 net.cpp:454] relu41 <- conv41
I0712 18:16:47.292292 44853 net.cpp:397] relu41 -> conv41 (in-place)
I0712 18:16:47.292805 44853 net.cpp:150] Setting up relu41
I0712 18:16:47.292825 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.292835 44853 net.cpp:165] Memory required for data: 7568000096
I0712 18:16:47.292845 44853 layer_factory.hpp:76] Creating layer conv42
I0712 18:16:47.292861 44853 net.cpp:106] Creating Layer conv42
I0712 18:16:47.292871 44853 net.cpp:454] conv42 <- conv41
I0712 18:16:47.292884 44853 net.cpp:411] conv42 -> conv42
I0712 18:16:47.295820 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:16:47.295866 44853 net.cpp:150] Setting up conv42
I0712 18:16:47.295881 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.295891 44853 net.cpp:165] Memory required for data: 7632000096
I0712 18:16:47.295902 44853 layer_factory.hpp:76] Creating layer relu42
I0712 18:16:47.295914 44853 net.cpp:106] Creating Layer relu42
I0712 18:16:47.295924 44853 net.cpp:454] relu42 <- conv42
I0712 18:16:47.295938 44853 net.cpp:397] relu42 -> conv42 (in-place)
I0712 18:16:47.296151 44853 net.cpp:150] Setting up relu42
I0712 18:16:47.296174 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.296182 44853 net.cpp:165] Memory required for data: 7696000096
I0712 18:16:47.296192 44853 layer_factory.hpp:76] Creating layer pool4
I0712 18:16:47.296205 44853 net.cpp:106] Creating Layer pool4
I0712 18:16:47.296214 44853 net.cpp:454] pool4 <- conv42
I0712 18:16:47.296226 44853 net.cpp:411] pool4 -> pool4
I0712 18:16:47.296586 44853 net.cpp:150] Setting up pool4
I0712 18:16:47.296607 44853 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0712 18:16:47.296617 44853 net.cpp:165] Memory required for data: 7712257120
I0712 18:16:47.296627 44853 layer_factory.hpp:76] Creating layer conv51
I0712 18:16:47.296643 44853 net.cpp:106] Creating Layer conv51
I0712 18:16:47.296653 44853 net.cpp:454] conv51 <- pool4
I0712 18:16:47.296664 44853 net.cpp:411] conv51 -> conv51
I0712 18:16:47.301728 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:16:47.301782 44853 net.cpp:150] Setting up conv51
I0712 18:16:47.301805 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.301813 44853 net.cpp:165] Memory required for data: 7744771168
I0712 18:16:47.301842 44853 layer_factory.hpp:76] Creating layer relu51
I0712 18:16:47.301859 44853 net.cpp:106] Creating Layer relu51
I0712 18:16:47.301872 44853 net.cpp:454] relu51 <- conv51
I0712 18:16:47.301887 44853 net.cpp:397] relu51 -> conv51 (in-place)
I0712 18:16:47.302124 44853 net.cpp:150] Setting up relu51
I0712 18:16:47.302142 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.302152 44853 net.cpp:165] Memory required for data: 7777285216
I0712 18:16:47.302161 44853 layer_factory.hpp:76] Creating layer conv52
I0712 18:16:47.302183 44853 net.cpp:106] Creating Layer conv52
I0712 18:16:47.302193 44853 net.cpp:454] conv52 <- conv51
I0712 18:16:47.302207 44853 net.cpp:411] conv52 -> conv52
I0712 18:16:47.310044 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 18:16:47.310104 44853 net.cpp:150] Setting up conv52
I0712 18:16:47.310122 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.310132 44853 net.cpp:165] Memory required for data: 7809799264
I0712 18:16:47.310149 44853 layer_factory.hpp:76] Creating layer relu52
I0712 18:16:47.310168 44853 net.cpp:106] Creating Layer relu52
I0712 18:16:47.310180 44853 net.cpp:454] relu52 <- conv52
I0712 18:16:47.310195 44853 net.cpp:397] relu52 -> conv52 (in-place)
I0712 18:16:47.310537 44853 net.cpp:150] Setting up relu52
I0712 18:16:47.310559 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.310570 44853 net.cpp:165] Memory required for data: 7842313312
I0712 18:16:47.310578 44853 layer_factory.hpp:76] Creating layer conv53
I0712 18:16:47.310598 44853 net.cpp:106] Creating Layer conv53
I0712 18:16:47.310608 44853 net.cpp:454] conv53 <- conv52
I0712 18:16:47.310621 44853 net.cpp:411] conv53 -> conv53
I0712 18:16:47.352341 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0712 18:16:47.352602 44853 net.cpp:150] Setting up conv53
I0712 18:16:47.352630 44853 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:16:47.352643 44853 net.cpp:165] Memory required for data: 7868929120
I0712 18:16:47.352677 44853 layer_factory.hpp:76] Creating layer relu53
I0712 18:16:47.352705 44853 net.cpp:106] Creating Layer relu53
I0712 18:16:47.352731 44853 net.cpp:454] relu53 <- conv53
I0712 18:16:47.352747 44853 net.cpp:397] relu53 -> conv53 (in-place)
I0712 18:16:47.354449 44853 net.cpp:150] Setting up relu53
I0712 18:16:47.354471 44853 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:16:47.354481 44853 net.cpp:165] Memory required for data: 7895544928
I0712 18:16:47.354495 44853 layer_factory.hpp:76] Creating layer conv61
I0712 18:16:47.354521 44853 net.cpp:106] Creating Layer conv61
I0712 18:16:47.354532 44853 net.cpp:454] conv61 <- conv53
I0712 18:16:47.354543 44853 net.cpp:411] conv61 -> conv61
I0712 18:16:47.361333 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 18:16:47.361380 44853 net.cpp:150] Setting up conv61
I0712 18:16:47.361394 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.361404 44853 net.cpp:165] Memory required for data: 7902198880
I0712 18:16:47.361418 44853 layer_factory.hpp:76] Creating layer relu61
I0712 18:16:47.361431 44853 net.cpp:106] Creating Layer relu61
I0712 18:16:47.361443 44853 net.cpp:454] relu61 <- conv61
I0712 18:16:47.361454 44853 net.cpp:397] relu61 -> conv61 (in-place)
I0712 18:16:47.363481 44853 net.cpp:150] Setting up relu61
I0712 18:16:47.363512 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.363533 44853 net.cpp:165] Memory required for data: 7908852832
I0712 18:16:47.363543 44853 layer_factory.hpp:76] Creating layer conv62
I0712 18:16:47.363564 44853 net.cpp:106] Creating Layer conv62
I0712 18:16:47.363574 44853 net.cpp:454] conv62 <- conv61
I0712 18:16:47.363590 44853 net.cpp:411] conv62 -> conv62
I0712 18:16:47.369768 44853 net.cpp:150] Setting up conv62
I0712 18:16:47.369802 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.369812 44853 net.cpp:165] Memory required for data: 7915506784
I0712 18:16:47.369824 44853 layer_factory.hpp:76] Creating layer relu62
I0712 18:16:47.369840 44853 net.cpp:106] Creating Layer relu62
I0712 18:16:47.369849 44853 net.cpp:454] relu62 <- conv62
I0712 18:16:47.369860 44853 net.cpp:397] relu62 -> conv62 (in-place)
I0712 18:16:47.371650 44853 net.cpp:150] Setting up relu62
I0712 18:16:47.371682 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.371692 44853 net.cpp:165] Memory required for data: 7922160736
I0712 18:16:47.371704 44853 layer_factory.hpp:76] Creating layer pool5
I0712 18:16:47.371758 44853 net.cpp:106] Creating Layer pool5
I0712 18:16:47.371769 44853 net.cpp:454] pool5 <- conv62
I0712 18:16:47.371780 44853 net.cpp:411] pool5 -> pool5
I0712 18:16:47.373898 44853 net.cpp:150] Setting up pool5
I0712 18:16:47.373929 44853 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0712 18:16:47.373939 44853 net.cpp:165] Memory required for data: 7923883104
I0712 18:16:47.373949 44853 layer_factory.hpp:76] Creating layer conv71
I0712 18:16:47.373970 44853 net.cpp:106] Creating Layer conv71
I0712 18:16:47.373980 44853 net.cpp:454] conv71 <- pool5
I0712 18:16:47.373991 44853 net.cpp:411] conv71 -> conv71
I0712 18:16:47.380429 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:16:47.380511 44853 net.cpp:150] Setting up conv71
I0712 18:16:47.380525 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.380534 44853 net.cpp:165] Memory required for data: 7926466656
I0712 18:16:47.380548 44853 layer_factory.hpp:76] Creating layer relu71
I0712 18:16:47.380563 44853 net.cpp:106] Creating Layer relu71
I0712 18:16:47.380573 44853 net.cpp:454] relu71 <- conv71
I0712 18:16:47.380583 44853 net.cpp:397] relu71 -> conv71 (in-place)
I0712 18:16:47.382179 44853 net.cpp:150] Setting up relu71
I0712 18:16:47.382213 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.382223 44853 net.cpp:165] Memory required for data: 7929050208
I0712 18:16:47.382232 44853 layer_factory.hpp:76] Creating layer conv72
I0712 18:16:47.382253 44853 net.cpp:106] Creating Layer conv72
I0712 18:16:47.382263 44853 net.cpp:454] conv72 <- conv71
I0712 18:16:47.382277 44853 net.cpp:411] conv72 -> conv72
I0712 18:16:47.387235 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:16:47.387284 44853 net.cpp:150] Setting up conv72
I0712 18:16:47.387326 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.387336 44853 net.cpp:165] Memory required for data: 7931633760
I0712 18:16:47.387351 44853 layer_factory.hpp:76] Creating layer relu72
I0712 18:16:47.387367 44853 net.cpp:106] Creating Layer relu72
I0712 18:16:47.387377 44853 net.cpp:454] relu72 <- conv72
I0712 18:16:47.387389 44853 net.cpp:397] relu72 -> conv72 (in-place)
I0712 18:16:47.389719 44853 net.cpp:150] Setting up relu72
I0712 18:16:47.389750 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.389760 44853 net.cpp:165] Memory required for data: 7934217312
I0712 18:16:47.389770 44853 layer_factory.hpp:76] Creating layer pool6
I0712 18:16:47.389786 44853 net.cpp:106] Creating Layer pool6
I0712 18:16:47.389796 44853 net.cpp:454] pool6 <- conv72
I0712 18:16:47.389809 44853 net.cpp:411] pool6 -> pool6
I0712 18:16:47.392374 44853 net.cpp:150] Setting up pool6
I0712 18:16:47.392396 44853 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0712 18:16:47.392406 44853 net.cpp:165] Memory required for data: 7934908512
I0712 18:16:47.392416 44853 layer_factory.hpp:76] Creating layer conv81
I0712 18:16:47.392433 44853 net.cpp:106] Creating Layer conv81
I0712 18:16:47.392443 44853 net.cpp:454] conv81 <- pool6
I0712 18:16:47.392457 44853 net.cpp:411] conv81 -> conv81
I0712 18:16:47.399916 44853 net.cpp:150] Setting up conv81
I0712 18:16:47.399943 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.399953 44853 net.cpp:165] Memory required for data: 7935830112
I0712 18:16:47.399967 44853 layer_factory.hpp:76] Creating layer relu81
I0712 18:16:47.399988 44853 net.cpp:106] Creating Layer relu81
I0712 18:16:47.399999 44853 net.cpp:454] relu81 <- conv81
I0712 18:16:47.400010 44853 net.cpp:397] relu81 -> conv81 (in-place)
I0712 18:16:47.402307 44853 net.cpp:150] Setting up relu81
I0712 18:16:47.402328 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.402338 44853 net.cpp:165] Memory required for data: 7936751712
I0712 18:16:47.402350 44853 layer_factory.hpp:76] Creating layer conv82
I0712 18:16:47.402374 44853 net.cpp:106] Creating Layer conv82
I0712 18:16:47.402384 44853 net.cpp:454] conv82 <- conv81
I0712 18:16:47.402396 44853 net.cpp:411] conv82 -> conv82
I0712 18:16:47.410095 44853 net.cpp:150] Setting up conv82
I0712 18:16:47.410120 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.410130 44853 net.cpp:165] Memory required for data: 7937673312
I0712 18:16:47.410163 44853 layer_factory.hpp:76] Creating layer relu82
I0712 18:16:47.410177 44853 net.cpp:106] Creating Layer relu82
I0712 18:16:47.410187 44853 net.cpp:454] relu82 <- conv82
I0712 18:16:47.410197 44853 net.cpp:397] relu82 -> conv82 (in-place)
I0712 18:16:47.412583 44853 net.cpp:150] Setting up relu82
I0712 18:16:47.412606 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.412614 44853 net.cpp:165] Memory required for data: 7938594912
I0712 18:16:47.412623 44853 layer_factory.hpp:76] Creating layer pool7
I0712 18:16:47.412641 44853 net.cpp:106] Creating Layer pool7
I0712 18:16:47.412650 44853 net.cpp:454] pool7 <- conv82
I0712 18:16:47.412660 44853 net.cpp:411] pool7 -> pool7
I0712 18:16:47.415087 44853 net.cpp:150] Setting up pool7
I0712 18:16:47.415107 44853 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0712 18:16:47.415117 44853 net.cpp:165] Memory required for data: 7938857056
I0712 18:16:47.415124 44853 layer_factory.hpp:76] Creating layer drop0
I0712 18:16:47.415144 44853 net.cpp:106] Creating Layer drop0
I0712 18:16:47.415153 44853 net.cpp:454] drop0 <- pool7
I0712 18:16:47.415163 44853 net.cpp:397] drop0 -> pool7 (in-place)
I0712 18:16:47.415211 44853 net.cpp:150] Setting up drop0
I0712 18:16:47.415225 44853 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0712 18:16:47.415232 44853 net.cpp:165] Memory required for data: 7939119200
I0712 18:16:47.415241 44853 layer_factory.hpp:76] Creating layer conv91
I0712 18:16:47.415257 44853 net.cpp:106] Creating Layer conv91
I0712 18:16:47.415266 44853 net.cpp:454] conv91 <- pool7
I0712 18:16:47.415279 44853 net.cpp:411] conv91 -> conv91
I0712 18:16:47.422536 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0712 18:16:47.422572 44853 net.cpp:150] Setting up conv91
I0712 18:16:47.422588 44853 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:16:47.422597 44853 net.cpp:165] Memory required for data: 7939119296
I0712 18:16:47.422610 44853 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0712 18:16:47.422622 44853 net.cpp:106] Creating Layer conv91_conv91_0_split
I0712 18:16:47.422647 44853 net.cpp:454] conv91_conv91_0_split <- conv91
I0712 18:16:47.422663 44853 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0712 18:16:47.422677 44853 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0712 18:16:47.422739 44853 net.cpp:150] Setting up conv91_conv91_0_split
I0712 18:16:47.422750 44853 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:16:47.422765 44853 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:16:47.422775 44853 net.cpp:165] Memory required for data: 7939119488
I0712 18:16:47.422783 44853 layer_factory.hpp:76] Creating layer accuracy
I0712 18:16:47.422806 44853 net.cpp:106] Creating Layer accuracy
I0712 18:16:47.422814 44853 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0712 18:16:47.422824 44853 net.cpp:454] accuracy <- label_data_1_split_0
I0712 18:16:47.422835 44853 net.cpp:411] accuracy -> accuracy
I0712 18:16:47.422850 44853 net.cpp:150] Setting up accuracy
I0712 18:16:47.422860 44853 net.cpp:157] Top shape: (1)
I0712 18:16:47.422869 44853 net.cpp:165] Memory required for data: 7939119492
I0712 18:16:47.422878 44853 layer_factory.hpp:76] Creating layer loss
I0712 18:16:47.422889 44853 net.cpp:106] Creating Layer loss
I0712 18:16:47.422899 44853 net.cpp:454] loss <- conv91_conv91_0_split_1
I0712 18:16:47.422910 44853 net.cpp:454] loss <- label_data_1_split_1
I0712 18:16:47.422920 44853 net.cpp:411] loss -> loss
I0712 18:16:47.422945 44853 layer_factory.hpp:76] Creating layer loss
I0712 18:16:47.425127 44853 net.cpp:150] Setting up loss
I0712 18:16:47.425150 44853 net.cpp:157] Top shape: (1)
I0712 18:16:47.425160 44853 net.cpp:160]     with loss weight 1
I0712 18:16:47.425215 44853 net.cpp:165] Memory required for data: 7939119496
I0712 18:16:47.425225 44853 net.cpp:226] loss needs backward computation.
I0712 18:16:47.425235 44853 net.cpp:228] accuracy does not need backward computation.
I0712 18:16:47.425243 44853 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0712 18:16:47.425252 44853 net.cpp:226] conv91 needs backward computation.
I0712 18:16:47.425261 44853 net.cpp:226] drop0 needs backward computation.
I0712 18:16:47.425269 44853 net.cpp:226] pool7 needs backward computation.
I0712 18:16:47.425277 44853 net.cpp:226] relu82 needs backward computation.
I0712 18:16:47.425285 44853 net.cpp:226] conv82 needs backward computation.
I0712 18:16:47.425304 44853 net.cpp:226] relu81 needs backward computation.
I0712 18:16:47.425312 44853 net.cpp:226] conv81 needs backward computation.
I0712 18:16:47.425333 44853 net.cpp:226] pool6 needs backward computation.
I0712 18:16:47.425343 44853 net.cpp:226] relu72 needs backward computation.
I0712 18:16:47.425350 44853 net.cpp:226] conv72 needs backward computation.
I0712 18:16:47.425360 44853 net.cpp:226] relu71 needs backward computation.
I0712 18:16:47.425369 44853 net.cpp:226] conv71 needs backward computation.
I0712 18:16:47.425377 44853 net.cpp:226] pool5 needs backward computation.
I0712 18:16:47.425405 44853 net.cpp:226] relu62 needs backward computation.
I0712 18:16:47.425427 44853 net.cpp:226] conv62 needs backward computation.
I0712 18:16:47.425436 44853 net.cpp:226] relu61 needs backward computation.
I0712 18:16:47.425444 44853 net.cpp:226] conv61 needs backward computation.
I0712 18:16:47.425456 44853 net.cpp:228] relu53 does not need backward computation.
I0712 18:16:47.425464 44853 net.cpp:228] conv53 does not need backward computation.
I0712 18:16:47.425473 44853 net.cpp:228] relu52 does not need backward computation.
I0712 18:16:47.425487 44853 net.cpp:228] conv52 does not need backward computation.
I0712 18:16:47.425496 44853 net.cpp:228] relu51 does not need backward computation.
I0712 18:16:47.425523 44853 net.cpp:228] conv51 does not need backward computation.
I0712 18:16:47.425532 44853 net.cpp:228] pool4 does not need backward computation.
I0712 18:16:47.425541 44853 net.cpp:228] relu42 does not need backward computation.
I0712 18:16:47.425550 44853 net.cpp:228] conv42 does not need backward computation.
I0712 18:16:47.425559 44853 net.cpp:228] relu41 does not need backward computation.
I0712 18:16:47.425570 44853 net.cpp:228] conv41 does not need backward computation.
I0712 18:16:47.425581 44853 net.cpp:228] pool3 does not need backward computation.
I0712 18:16:47.425591 44853 net.cpp:228] relu32 does not need backward computation.
I0712 18:16:47.425601 44853 net.cpp:228] conv32 does not need backward computation.
I0712 18:16:47.425611 44853 net.cpp:228] relu31 does not need backward computation.
I0712 18:16:47.425624 44853 net.cpp:228] conv31 does not need backward computation.
I0712 18:16:47.425635 44853 net.cpp:228] pool2 does not need backward computation.
I0712 18:16:47.425645 44853 net.cpp:228] relu22 does not need backward computation.
I0712 18:16:47.425654 44853 net.cpp:228] conv22 does not need backward computation.
I0712 18:16:47.425663 44853 net.cpp:228] relu21 does not need backward computation.
I0712 18:16:47.425675 44853 net.cpp:228] conv21 does not need backward computation.
I0712 18:16:47.425685 44853 net.cpp:228] pool1 does not need backward computation.
I0712 18:16:47.425694 44853 net.cpp:228] relu12 does not need backward computation.
I0712 18:16:47.425704 44853 net.cpp:228] conv12 does not need backward computation.
I0712 18:16:47.425714 44853 net.cpp:228] relu11 does not need backward computation.
I0712 18:16:47.425721 44853 net.cpp:228] conv11 does not need backward computation.
I0712 18:16:47.425731 44853 net.cpp:228] label_data_1_split does not need backward computation.
I0712 18:16:47.425741 44853 net.cpp:228] data does not need backward computation.
I0712 18:16:47.425750 44853 net.cpp:270] This network produces output accuracy
I0712 18:16:47.425758 44853 net.cpp:270] This network produces output loss
I0712 18:16:47.425794 44853 net.cpp:283] Network initialization done.
I0712 18:16:47.427033 44853 solver.cpp:180] Creating test net (#0) specified by net file: train_val-featurelayer-3stack.prototxt
I0712 18:16:47.427104 44853 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0712 18:16:47.427434 44853 net.cpp:49] Initializing net from parameters: 
name: "FaceNN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 8
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "conv53"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0712 18:16:47.429671 44853 layer_factory.hpp:76] Creating layer data
I0712 18:16:47.429704 44853 net.cpp:106] Creating Layer data
I0712 18:16:47.429716 44853 net.cpp:411] data -> data
I0712 18:16:47.429730 44853 net.cpp:411] data -> label
I0712 18:16:47.429746 44853 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0712 18:16:47.431398 44853 image_data_layer.cpp:46] Shuffling data
I0712 18:16:47.431659 44853 image_data_layer.cpp:51] A total of 2617 images.
I0712 18:16:47.518270 44853 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0712 18:16:47.872220 44853 net.cpp:150] Setting up data
I0712 18:16:47.872269 44853 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0712 18:16:47.872283 44853 net.cpp:157] Top shape: 8 (8)
I0712 18:16:47.872292 44853 net.cpp:165] Memory required for data: 96000032
I0712 18:16:47.872305 44853 layer_factory.hpp:76] Creating layer label_data_1_split
I0712 18:16:47.872326 44853 net.cpp:106] Creating Layer label_data_1_split
I0712 18:16:47.872339 44853 net.cpp:454] label_data_1_split <- label
I0712 18:16:47.872352 44853 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0712 18:16:47.872370 44853 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0712 18:16:47.872469 44853 net.cpp:150] Setting up label_data_1_split
I0712 18:16:47.872493 44853 net.cpp:157] Top shape: 8 (8)
I0712 18:16:47.872503 44853 net.cpp:157] Top shape: 8 (8)
I0712 18:16:47.872512 44853 net.cpp:165] Memory required for data: 96000096
I0712 18:16:47.872522 44853 layer_factory.hpp:76] Creating layer conv11
I0712 18:16:47.872541 44853 net.cpp:106] Creating Layer conv11
I0712 18:16:47.872550 44853 net.cpp:454] conv11 <- data
I0712 18:16:47.872563 44853 net.cpp:411] conv11 -> conv11
I0712 18:16:47.877040 44853 net.cpp:150] Setting up conv11
I0712 18:16:47.877074 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.877085 44853 net.cpp:165] Memory required for data: 1120000096
I0712 18:16:47.877115 44853 layer_factory.hpp:76] Creating layer relu11
I0712 18:16:47.877133 44853 net.cpp:106] Creating Layer relu11
I0712 18:16:47.877145 44853 net.cpp:454] relu11 <- conv11
I0712 18:16:47.877156 44853 net.cpp:397] relu11 -> conv11 (in-place)
I0712 18:16:47.877377 44853 net.cpp:150] Setting up relu11
I0712 18:16:47.877395 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.877405 44853 net.cpp:165] Memory required for data: 2144000096
I0712 18:16:47.877414 44853 layer_factory.hpp:76] Creating layer conv12
I0712 18:16:47.877432 44853 net.cpp:106] Creating Layer conv12
I0712 18:16:47.877441 44853 net.cpp:454] conv12 <- conv11
I0712 18:16:47.877454 44853 net.cpp:411] conv12 -> conv12
I0712 18:16:47.882123 44853 net.cpp:150] Setting up conv12
I0712 18:16:47.882169 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.882180 44853 net.cpp:165] Memory required for data: 3168000096
I0712 18:16:47.882205 44853 layer_factory.hpp:76] Creating layer relu12
I0712 18:16:47.882221 44853 net.cpp:106] Creating Layer relu12
I0712 18:16:47.882232 44853 net.cpp:454] relu12 <- conv12
I0712 18:16:47.882246 44853 net.cpp:397] relu12 -> conv12 (in-place)
I0712 18:16:47.882730 44853 net.cpp:150] Setting up relu12
I0712 18:16:47.882752 44853 net.cpp:157] Top shape: 8 32 1000 1000 (256000000)
I0712 18:16:47.882762 44853 net.cpp:165] Memory required for data: 4192000096
I0712 18:16:47.882771 44853 layer_factory.hpp:76] Creating layer pool1
I0712 18:16:47.882786 44853 net.cpp:106] Creating Layer pool1
I0712 18:16:47.882796 44853 net.cpp:454] pool1 <- conv12
I0712 18:16:47.882807 44853 net.cpp:411] pool1 -> pool1
I0712 18:16:47.883062 44853 net.cpp:150] Setting up pool1
I0712 18:16:47.883081 44853 net.cpp:157] Top shape: 8 32 500 500 (64000000)
I0712 18:16:47.883091 44853 net.cpp:165] Memory required for data: 4448000096
I0712 18:16:47.883100 44853 layer_factory.hpp:76] Creating layer conv21
I0712 18:16:47.883118 44853 net.cpp:106] Creating Layer conv21
I0712 18:16:47.883128 44853 net.cpp:454] conv21 <- pool1
I0712 18:16:47.883141 44853 net.cpp:411] conv21 -> conv21
I0712 18:16:47.885387 44853 net.cpp:150] Setting up conv21
I0712 18:16:47.885437 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.885448 44853 net.cpp:165] Memory required for data: 4960000096
I0712 18:16:47.885464 44853 layer_factory.hpp:76] Creating layer relu21
I0712 18:16:47.885481 44853 net.cpp:106] Creating Layer relu21
I0712 18:16:47.885491 44853 net.cpp:454] relu21 <- conv21
I0712 18:16:47.885504 44853 net.cpp:397] relu21 -> conv21 (in-place)
I0712 18:16:47.885877 44853 net.cpp:150] Setting up relu21
I0712 18:16:47.885898 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.885908 44853 net.cpp:165] Memory required for data: 5472000096
I0712 18:16:47.885917 44853 layer_factory.hpp:76] Creating layer conv22
I0712 18:16:47.885933 44853 net.cpp:106] Creating Layer conv22
I0712 18:16:47.885943 44853 net.cpp:454] conv22 <- conv21
I0712 18:16:47.885957 44853 net.cpp:411] conv22 -> conv22
I0712 18:16:47.888259 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:16:47.888314 44853 net.cpp:150] Setting up conv22
I0712 18:16:47.888331 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.888340 44853 net.cpp:165] Memory required for data: 5984000096
I0712 18:16:47.888353 44853 layer_factory.hpp:76] Creating layer relu22
I0712 18:16:47.888366 44853 net.cpp:106] Creating Layer relu22
I0712 18:16:47.888376 44853 net.cpp:454] relu22 <- conv22
I0712 18:16:47.888388 44853 net.cpp:397] relu22 -> conv22 (in-place)
I0712 18:16:47.888728 44853 net.cpp:150] Setting up relu22
I0712 18:16:47.888751 44853 net.cpp:157] Top shape: 8 64 500 500 (128000000)
I0712 18:16:47.888759 44853 net.cpp:165] Memory required for data: 6496000096
I0712 18:16:47.888769 44853 layer_factory.hpp:76] Creating layer pool2
I0712 18:16:47.888782 44853 net.cpp:106] Creating Layer pool2
I0712 18:16:47.888792 44853 net.cpp:454] pool2 <- conv22
I0712 18:16:47.888803 44853 net.cpp:411] pool2 -> pool2
I0712 18:16:47.889048 44853 net.cpp:150] Setting up pool2
I0712 18:16:47.889070 44853 net.cpp:157] Top shape: 8 64 250 250 (32000000)
I0712 18:16:47.889089 44853 net.cpp:165] Memory required for data: 6624000096
I0712 18:16:47.889098 44853 layer_factory.hpp:76] Creating layer conv31
I0712 18:16:47.889114 44853 net.cpp:106] Creating Layer conv31
I0712 18:16:47.889124 44853 net.cpp:454] conv31 <- pool2
I0712 18:16:47.889137 44853 net.cpp:411] conv31 -> conv31
I0712 18:16:47.891515 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:16:47.891567 44853 net.cpp:150] Setting up conv31
I0712 18:16:47.891584 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.891593 44853 net.cpp:165] Memory required for data: 6816000096
I0712 18:16:47.891613 44853 layer_factory.hpp:76] Creating layer relu31
I0712 18:16:47.891628 44853 net.cpp:106] Creating Layer relu31
I0712 18:16:47.891636 44853 net.cpp:454] relu31 <- conv31
I0712 18:16:47.891649 44853 net.cpp:397] relu31 -> conv31 (in-place)
I0712 18:16:47.891988 44853 net.cpp:150] Setting up relu31
I0712 18:16:47.892010 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.892020 44853 net.cpp:165] Memory required for data: 7008000096
I0712 18:16:47.892030 44853 layer_factory.hpp:76] Creating layer conv32
I0712 18:16:47.892045 44853 net.cpp:106] Creating Layer conv32
I0712 18:16:47.892055 44853 net.cpp:454] conv32 <- conv31
I0712 18:16:47.892067 44853 net.cpp:411] conv32 -> conv32
I0712 18:16:47.893811 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:16:47.893856 44853 net.cpp:150] Setting up conv32
I0712 18:16:47.893870 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.893879 44853 net.cpp:165] Memory required for data: 7200000096
I0712 18:16:47.893893 44853 layer_factory.hpp:76] Creating layer relu32
I0712 18:16:47.893906 44853 net.cpp:106] Creating Layer relu32
I0712 18:16:47.893915 44853 net.cpp:454] relu32 <- conv32
I0712 18:16:47.893928 44853 net.cpp:397] relu32 -> conv32 (in-place)
I0712 18:16:47.894256 44853 net.cpp:150] Setting up relu32
I0712 18:16:47.894279 44853 net.cpp:157] Top shape: 8 96 250 250 (48000000)
I0712 18:16:47.894311 44853 net.cpp:165] Memory required for data: 7392000096
I0712 18:16:47.894321 44853 layer_factory.hpp:76] Creating layer pool3
I0712 18:16:47.894338 44853 net.cpp:106] Creating Layer pool3
I0712 18:16:47.894347 44853 net.cpp:454] pool3 <- conv32
I0712 18:16:47.894359 44853 net.cpp:411] pool3 -> pool3
I0712 18:16:47.894579 44853 net.cpp:150] Setting up pool3
I0712 18:16:47.894598 44853 net.cpp:157] Top shape: 8 96 125 125 (12000000)
I0712 18:16:47.894608 44853 net.cpp:165] Memory required for data: 7440000096
I0712 18:16:47.894618 44853 layer_factory.hpp:76] Creating layer conv41
I0712 18:16:47.894637 44853 net.cpp:106] Creating Layer conv41
I0712 18:16:47.894647 44853 net.cpp:454] conv41 <- pool3
I0712 18:16:47.894660 44853 net.cpp:411] conv41 -> conv41
I0712 18:16:47.897338 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:16:47.897382 44853 net.cpp:150] Setting up conv41
I0712 18:16:47.897397 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.897406 44853 net.cpp:165] Memory required for data: 7504000096
I0712 18:16:47.897419 44853 layer_factory.hpp:76] Creating layer relu41
I0712 18:16:47.897433 44853 net.cpp:106] Creating Layer relu41
I0712 18:16:47.897442 44853 net.cpp:454] relu41 <- conv41
I0712 18:16:47.897454 44853 net.cpp:397] relu41 -> conv41 (in-place)
I0712 18:16:47.897802 44853 net.cpp:150] Setting up relu41
I0712 18:16:47.897825 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.897835 44853 net.cpp:165] Memory required for data: 7568000096
I0712 18:16:47.897845 44853 layer_factory.hpp:76] Creating layer conv42
I0712 18:16:47.897860 44853 net.cpp:106] Creating Layer conv42
I0712 18:16:47.897868 44853 net.cpp:454] conv42 <- conv41
I0712 18:16:47.897881 44853 net.cpp:411] conv42 -> conv42
I0712 18:16:47.900087 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:16:47.900133 44853 net.cpp:150] Setting up conv42
I0712 18:16:47.900147 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.900157 44853 net.cpp:165] Memory required for data: 7632000096
I0712 18:16:47.900171 44853 layer_factory.hpp:76] Creating layer relu42
I0712 18:16:47.900182 44853 net.cpp:106] Creating Layer relu42
I0712 18:16:47.900192 44853 net.cpp:454] relu42 <- conv42
I0712 18:16:47.900203 44853 net.cpp:397] relu42 -> conv42 (in-place)
I0712 18:16:47.900385 44853 net.cpp:150] Setting up relu42
I0712 18:16:47.900403 44853 net.cpp:157] Top shape: 8 128 125 125 (16000000)
I0712 18:16:47.900413 44853 net.cpp:165] Memory required for data: 7696000096
I0712 18:16:47.900423 44853 layer_factory.hpp:76] Creating layer pool4
I0712 18:16:47.900435 44853 net.cpp:106] Creating Layer pool4
I0712 18:16:47.900444 44853 net.cpp:454] pool4 <- conv42
I0712 18:16:47.900455 44853 net.cpp:411] pool4 -> pool4
I0712 18:16:47.900825 44853 net.cpp:150] Setting up pool4
I0712 18:16:47.900846 44853 net.cpp:157] Top shape: 8 128 63 63 (4064256)
I0712 18:16:47.900856 44853 net.cpp:165] Memory required for data: 7712257120
I0712 18:16:47.900866 44853 layer_factory.hpp:76] Creating layer conv51
I0712 18:16:47.900879 44853 net.cpp:106] Creating Layer conv51
I0712 18:16:47.900889 44853 net.cpp:454] conv51 <- pool4
I0712 18:16:47.900902 44853 net.cpp:411] conv51 -> conv51
I0712 18:16:47.905899 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0712 18:16:47.905956 44853 net.cpp:150] Setting up conv51
I0712 18:16:47.905979 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.905994 44853 net.cpp:165] Memory required for data: 7744771168
I0712 18:16:47.906023 44853 layer_factory.hpp:76] Creating layer relu51
I0712 18:16:47.906044 44853 net.cpp:106] Creating Layer relu51
I0712 18:16:47.906059 44853 net.cpp:454] relu51 <- conv51
I0712 18:16:47.906076 44853 net.cpp:397] relu51 -> conv51 (in-place)
I0712 18:16:47.906520 44853 net.cpp:150] Setting up relu51
I0712 18:16:47.906551 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.906565 44853 net.cpp:165] Memory required for data: 7777285216
I0712 18:16:47.906611 44853 layer_factory.hpp:76] Creating layer conv52
I0712 18:16:47.906641 44853 net.cpp:106] Creating Layer conv52
I0712 18:16:47.906666 44853 net.cpp:454] conv52 <- conv51
I0712 18:16:47.906687 44853 net.cpp:411] conv52 -> conv52
I0712 18:16:47.916733 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 18:16:47.916811 44853 net.cpp:150] Setting up conv52
I0712 18:16:47.916838 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.916854 44853 net.cpp:165] Memory required for data: 7809799264
I0712 18:16:47.916879 44853 layer_factory.hpp:76] Creating layer relu52
I0712 18:16:47.916905 44853 net.cpp:106] Creating Layer relu52
I0712 18:16:47.916923 44853 net.cpp:454] relu52 <- conv52
I0712 18:16:47.916944 44853 net.cpp:397] relu52 -> conv52 (in-place)
I0712 18:16:47.917479 44853 net.cpp:150] Setting up relu52
I0712 18:16:47.917508 44853 net.cpp:157] Top shape: 8 256 63 63 (8128512)
I0712 18:16:47.917523 44853 net.cpp:165] Memory required for data: 7842313312
I0712 18:16:47.917538 44853 layer_factory.hpp:76] Creating layer conv53
I0712 18:16:47.917564 44853 net.cpp:106] Creating Layer conv53
I0712 18:16:47.917579 44853 net.cpp:454] conv53 <- conv52
I0712 18:16:47.917599 44853 net.cpp:411] conv53 -> conv53
I0712 18:16:47.964746 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0712 18:16:47.964809 44853 net.cpp:150] Setting up conv53
I0712 18:16:47.964828 44853 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:16:47.964838 44853 net.cpp:165] Memory required for data: 7868929120
I0712 18:16:47.964854 44853 layer_factory.hpp:76] Creating layer relu53
I0712 18:16:47.964872 44853 net.cpp:106] Creating Layer relu53
I0712 18:16:47.964885 44853 net.cpp:454] relu53 <- conv53
I0712 18:16:47.964900 44853 net.cpp:397] relu53 -> conv53 (in-place)
I0712 18:16:47.965245 44853 net.cpp:150] Setting up relu53
I0712 18:16:47.965267 44853 net.cpp:157] Top shape: 8 256 57 57 (6653952)
I0712 18:16:47.965276 44853 net.cpp:165] Memory required for data: 7895544928
I0712 18:16:47.965286 44853 layer_factory.hpp:76] Creating layer conv61
I0712 18:16:47.965303 44853 net.cpp:106] Creating Layer conv61
I0712 18:16:47.965312 44853 net.cpp:454] conv61 <- conv53
I0712 18:16:47.965325 44853 net.cpp:411] conv61 -> conv61
I0712 18:16:47.968232 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0712 18:16:47.968271 44853 net.cpp:150] Setting up conv61
I0712 18:16:47.968286 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.968296 44853 net.cpp:165] Memory required for data: 7902198880
I0712 18:16:47.968310 44853 layer_factory.hpp:76] Creating layer relu61
I0712 18:16:47.968325 44853 net.cpp:106] Creating Layer relu61
I0712 18:16:47.968335 44853 net.cpp:454] relu61 <- conv61
I0712 18:16:47.968348 44853 net.cpp:397] relu61 -> conv61 (in-place)
I0712 18:16:47.968763 44853 net.cpp:150] Setting up relu61
I0712 18:16:47.968793 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.968809 44853 net.cpp:165] Memory required for data: 7908852832
I0712 18:16:47.968824 44853 layer_factory.hpp:76] Creating layer conv62
I0712 18:16:47.968848 44853 net.cpp:106] Creating Layer conv62
I0712 18:16:47.968863 44853 net.cpp:454] conv62 <- conv61
I0712 18:16:47.968883 44853 net.cpp:411] conv62 -> conv62
I0712 18:16:47.970855 44853 net.cpp:150] Setting up conv62
I0712 18:16:47.970881 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.970891 44853 net.cpp:165] Memory required for data: 7915506784
I0712 18:16:47.970904 44853 layer_factory.hpp:76] Creating layer relu62
I0712 18:16:47.970918 44853 net.cpp:106] Creating Layer relu62
I0712 18:16:47.970928 44853 net.cpp:454] relu62 <- conv62
I0712 18:16:47.970940 44853 net.cpp:397] relu62 -> conv62 (in-place)
I0712 18:16:47.971127 44853 net.cpp:150] Setting up relu62
I0712 18:16:47.971145 44853 net.cpp:157] Top shape: 8 64 57 57 (1663488)
I0712 18:16:47.971154 44853 net.cpp:165] Memory required for data: 7922160736
I0712 18:16:47.971163 44853 layer_factory.hpp:76] Creating layer pool5
I0712 18:16:47.971220 44853 net.cpp:106] Creating Layer pool5
I0712 18:16:47.971231 44853 net.cpp:454] pool5 <- conv62
I0712 18:16:47.971243 44853 net.cpp:411] pool5 -> pool5
I0712 18:16:47.971628 44853 net.cpp:150] Setting up pool5
I0712 18:16:47.971652 44853 net.cpp:157] Top shape: 8 64 29 29 (430592)
I0712 18:16:47.971660 44853 net.cpp:165] Memory required for data: 7923883104
I0712 18:16:47.971670 44853 layer_factory.hpp:76] Creating layer conv71
I0712 18:16:47.971685 44853 net.cpp:106] Creating Layer conv71
I0712 18:16:47.971694 44853 net.cpp:454] conv71 <- pool5
I0712 18:16:47.971707 44853 net.cpp:411] conv71 -> conv71
I0712 18:16:47.973264 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0712 18:16:47.973309 44853 net.cpp:150] Setting up conv71
I0712 18:16:47.973323 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.973332 44853 net.cpp:165] Memory required for data: 7926466656
I0712 18:16:47.973346 44853 layer_factory.hpp:76] Creating layer relu71
I0712 18:16:47.973358 44853 net.cpp:106] Creating Layer relu71
I0712 18:16:47.973368 44853 net.cpp:454] relu71 <- conv71
I0712 18:16:47.973381 44853 net.cpp:397] relu71 -> conv71 (in-place)
I0712 18:16:47.973567 44853 net.cpp:150] Setting up relu71
I0712 18:16:47.973585 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.973594 44853 net.cpp:165] Memory required for data: 7929050208
I0712 18:16:47.973603 44853 layer_factory.hpp:76] Creating layer conv72
I0712 18:16:47.973618 44853 net.cpp:106] Creating Layer conv72
I0712 18:16:47.973628 44853 net.cpp:454] conv72 <- conv71
I0712 18:16:47.973639 44853 net.cpp:411] conv72 -> conv72
I0712 18:16:47.975419 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0712 18:16:47.975466 44853 net.cpp:150] Setting up conv72
I0712 18:16:47.975481 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.975489 44853 net.cpp:165] Memory required for data: 7931633760
I0712 18:16:47.975502 44853 layer_factory.hpp:76] Creating layer relu72
I0712 18:16:47.975515 44853 net.cpp:106] Creating Layer relu72
I0712 18:16:47.975525 44853 net.cpp:454] relu72 <- conv72
I0712 18:16:47.975536 44853 net.cpp:397] relu72 -> conv72 (in-place)
I0712 18:16:47.975872 44853 net.cpp:150] Setting up relu72
I0712 18:16:47.975893 44853 net.cpp:157] Top shape: 8 96 29 29 (645888)
I0712 18:16:47.975903 44853 net.cpp:165] Memory required for data: 7934217312
I0712 18:16:47.975913 44853 layer_factory.hpp:76] Creating layer pool6
I0712 18:16:47.975925 44853 net.cpp:106] Creating Layer pool6
I0712 18:16:47.975935 44853 net.cpp:454] pool6 <- conv72
I0712 18:16:47.975946 44853 net.cpp:411] pool6 -> pool6
I0712 18:16:47.976181 44853 net.cpp:150] Setting up pool6
I0712 18:16:47.976200 44853 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0712 18:16:47.976209 44853 net.cpp:165] Memory required for data: 7934908512
I0712 18:16:47.976218 44853 layer_factory.hpp:76] Creating layer conv81
I0712 18:16:47.976234 44853 net.cpp:106] Creating Layer conv81
I0712 18:16:47.976244 44853 net.cpp:454] conv81 <- pool6
I0712 18:16:47.976258 44853 net.cpp:411] conv81 -> conv81
I0712 18:16:47.979049 44853 net.cpp:150] Setting up conv81
I0712 18:16:47.979079 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.979090 44853 net.cpp:165] Memory required for data: 7935830112
I0712 18:16:47.979104 44853 layer_factory.hpp:76] Creating layer relu81
I0712 18:16:47.979117 44853 net.cpp:106] Creating Layer relu81
I0712 18:16:47.979127 44853 net.cpp:454] relu81 <- conv81
I0712 18:16:47.979138 44853 net.cpp:397] relu81 -> conv81 (in-place)
I0712 18:16:47.979341 44853 net.cpp:150] Setting up relu81
I0712 18:16:47.979359 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.979368 44853 net.cpp:165] Memory required for data: 7936751712
I0712 18:16:47.979377 44853 layer_factory.hpp:76] Creating layer conv82
I0712 18:16:47.979395 44853 net.cpp:106] Creating Layer conv82
I0712 18:16:47.979405 44853 net.cpp:454] conv82 <- conv81
I0712 18:16:47.979423 44853 net.cpp:411] conv82 -> conv82
I0712 18:16:47.981679 44853 net.cpp:150] Setting up conv82
I0712 18:16:47.981726 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.981737 44853 net.cpp:165] Memory required for data: 7937673312
I0712 18:16:47.981760 44853 layer_factory.hpp:76] Creating layer relu82
I0712 18:16:47.981773 44853 net.cpp:106] Creating Layer relu82
I0712 18:16:47.981783 44853 net.cpp:454] relu82 <- conv82
I0712 18:16:47.981794 44853 net.cpp:397] relu82 -> conv82 (in-place)
I0712 18:16:47.982147 44853 net.cpp:150] Setting up relu82
I0712 18:16:47.982168 44853 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0712 18:16:47.982177 44853 net.cpp:165] Memory required for data: 7938594912
I0712 18:16:47.982187 44853 layer_factory.hpp:76] Creating layer pool7
I0712 18:16:47.982203 44853 net.cpp:106] Creating Layer pool7
I0712 18:16:47.982211 44853 net.cpp:454] pool7 <- conv82
I0712 18:16:47.982225 44853 net.cpp:411] pool7 -> pool7
I0712 18:16:47.982642 44853 net.cpp:150] Setting up pool7
I0712 18:16:47.982663 44853 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0712 18:16:47.982676 44853 net.cpp:165] Memory required for data: 7938857056
I0712 18:16:47.982686 44853 layer_factory.hpp:76] Creating layer drop0
I0712 18:16:47.982702 44853 net.cpp:106] Creating Layer drop0
I0712 18:16:47.982712 44853 net.cpp:454] drop0 <- pool7
I0712 18:16:47.982722 44853 net.cpp:397] drop0 -> pool7 (in-place)
I0712 18:16:47.982764 44853 net.cpp:150] Setting up drop0
I0712 18:16:47.982776 44853 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0712 18:16:47.982785 44853 net.cpp:165] Memory required for data: 7939119200
I0712 18:16:47.982795 44853 layer_factory.hpp:76] Creating layer conv91
I0712 18:16:47.982810 44853 net.cpp:106] Creating Layer conv91
I0712 18:16:47.982820 44853 net.cpp:454] conv91 <- pool7
I0712 18:16:47.982831 44853 net.cpp:411] conv91 -> conv91
I0712 18:16:47.984185 44853 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0712 18:16:47.984228 44853 net.cpp:150] Setting up conv91
I0712 18:16:47.984242 44853 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:16:47.984252 44853 net.cpp:165] Memory required for data: 7939119296
I0712 18:16:47.984266 44853 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0712 18:16:47.984278 44853 net.cpp:106] Creating Layer conv91_conv91_0_split
I0712 18:16:47.984287 44853 net.cpp:454] conv91_conv91_0_split <- conv91
I0712 18:16:47.984299 44853 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0712 18:16:47.984314 44853 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0712 18:16:47.984369 44853 net.cpp:150] Setting up conv91_conv91_0_split
I0712 18:16:47.984383 44853 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:16:47.984393 44853 net.cpp:157] Top shape: 8 3 1 1 (24)
I0712 18:16:47.984402 44853 net.cpp:165] Memory required for data: 7939119488
I0712 18:16:47.984411 44853 layer_factory.hpp:76] Creating layer accuracy
I0712 18:16:47.984426 44853 net.cpp:106] Creating Layer accuracy
I0712 18:16:47.984436 44853 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0712 18:16:47.984447 44853 net.cpp:454] accuracy <- label_data_1_split_0
I0712 18:16:47.984457 44853 net.cpp:411] accuracy -> accuracy
I0712 18:16:47.984470 44853 net.cpp:150] Setting up accuracy
I0712 18:16:47.984483 44853 net.cpp:157] Top shape: (1)
I0712 18:16:47.984493 44853 net.cpp:165] Memory required for data: 7939119492
I0712 18:16:47.984501 44853 layer_factory.hpp:76] Creating layer loss
I0712 18:16:47.984513 44853 net.cpp:106] Creating Layer loss
I0712 18:16:47.984521 44853 net.cpp:454] loss <- conv91_conv91_0_split_1
I0712 18:16:47.984531 44853 net.cpp:454] loss <- label_data_1_split_1
I0712 18:16:47.984542 44853 net.cpp:411] loss -> loss
I0712 18:16:47.984560 44853 layer_factory.hpp:76] Creating layer loss
I0712 18:16:47.985038 44853 net.cpp:150] Setting up loss
I0712 18:16:47.985059 44853 net.cpp:157] Top shape: (1)
I0712 18:16:47.985069 44853 net.cpp:160]     with loss weight 1
I0712 18:16:47.985086 44853 net.cpp:165] Memory required for data: 7939119496
I0712 18:16:47.985096 44853 net.cpp:226] loss needs backward computation.
I0712 18:16:47.985123 44853 net.cpp:228] accuracy does not need backward computation.
I0712 18:16:47.985133 44853 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0712 18:16:47.985142 44853 net.cpp:226] conv91 needs backward computation.
I0712 18:16:47.985152 44853 net.cpp:226] drop0 needs backward computation.
I0712 18:16:47.985159 44853 net.cpp:226] pool7 needs backward computation.
I0712 18:16:47.985168 44853 net.cpp:226] relu82 needs backward computation.
I0712 18:16:47.985177 44853 net.cpp:226] conv82 needs backward computation.
I0712 18:16:47.985185 44853 net.cpp:226] relu81 needs backward computation.
I0712 18:16:47.985193 44853 net.cpp:226] conv81 needs backward computation.
I0712 18:16:47.985203 44853 net.cpp:226] pool6 needs backward computation.
I0712 18:16:47.985211 44853 net.cpp:226] relu72 needs backward computation.
I0712 18:16:47.985219 44853 net.cpp:226] conv72 needs backward computation.
I0712 18:16:47.985229 44853 net.cpp:226] relu71 needs backward computation.
I0712 18:16:47.985237 44853 net.cpp:226] conv71 needs backward computation.
I0712 18:16:47.985246 44853 net.cpp:226] pool5 needs backward computation.
I0712 18:16:47.985255 44853 net.cpp:226] relu62 needs backward computation.
I0712 18:16:47.985263 44853 net.cpp:226] conv62 needs backward computation.
I0712 18:16:47.985272 44853 net.cpp:226] relu61 needs backward computation.
I0712 18:16:47.985280 44853 net.cpp:226] conv61 needs backward computation.
I0712 18:16:47.985290 44853 net.cpp:228] relu53 does not need backward computation.
I0712 18:16:47.985298 44853 net.cpp:228] conv53 does not need backward computation.
I0712 18:16:47.985307 44853 net.cpp:228] relu52 does not need backward computation.
I0712 18:16:47.985316 44853 net.cpp:228] conv52 does not need backward computation.
I0712 18:16:47.985324 44853 net.cpp:228] relu51 does not need backward computation.
I0712 18:16:47.985333 44853 net.cpp:228] conv51 does not need backward computation.
I0712 18:16:47.985342 44853 net.cpp:228] pool4 does not need backward computation.
I0712 18:16:47.985352 44853 net.cpp:228] relu42 does not need backward computation.
I0712 18:16:47.985360 44853 net.cpp:228] conv42 does not need backward computation.
I0712 18:16:47.985369 44853 net.cpp:228] relu41 does not need backward computation.
I0712 18:16:47.985379 44853 net.cpp:228] conv41 does not need backward computation.
I0712 18:16:47.985388 44853 net.cpp:228] pool3 does not need backward computation.
I0712 18:16:47.985397 44853 net.cpp:228] relu32 does not need backward computation.
I0712 18:16:47.985406 44853 net.cpp:228] conv32 does not need backward computation.
I0712 18:16:47.985415 44853 net.cpp:228] relu31 does not need backward computation.
I0712 18:16:47.985424 44853 net.cpp:228] conv31 does not need backward computation.
I0712 18:16:47.985433 44853 net.cpp:228] pool2 does not need backward computation.
I0712 18:16:47.985442 44853 net.cpp:228] relu22 does not need backward computation.
I0712 18:16:47.985451 44853 net.cpp:228] conv22 does not need backward computation.
I0712 18:16:47.985460 44853 net.cpp:228] relu21 does not need backward computation.
I0712 18:16:47.985469 44853 net.cpp:228] conv21 does not need backward computation.
I0712 18:16:47.985481 44853 net.cpp:228] pool1 does not need backward computation.
I0712 18:16:47.985491 44853 net.cpp:228] relu12 does not need backward computation.
I0712 18:16:47.985499 44853 net.cpp:228] conv12 does not need backward computation.
I0712 18:16:47.985508 44853 net.cpp:228] relu11 does not need backward computation.
I0712 18:16:47.985517 44853 net.cpp:228] conv11 does not need backward computation.
I0712 18:16:47.985527 44853 net.cpp:228] label_data_1_split does not need backward computation.
I0712 18:16:47.985537 44853 net.cpp:228] data does not need backward computation.
I0712 18:16:47.985544 44853 net.cpp:270] This network produces output accuracy
I0712 18:16:47.985553 44853 net.cpp:270] This network produces output loss
I0712 18:16:47.985586 44853 net.cpp:283] Network initialization done.
I0712 18:16:47.985785 44853 solver.cpp:59] Solver scaffolding done.
I0712 18:16:47.987373 44853 caffe.cpp:128] Finetuning from models/cnn10_iter_217316.caffemodel
I0712 18:16:48.144847 44853 caffe.cpp:212] Starting Optimization
I0712 18:16:48.144914 44853 solver.cpp:287] Solving FaceNN
I0712 18:16:48.144925 44853 solver.cpp:288] Learning Rate Policy: step
I0712 18:16:49.607008 44853 solver.cpp:236] Iteration 0, loss = 1.08952
I0712 18:16:49.607067 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:16:49.607095 44853 solver.cpp:252]     Train net output #1: loss = 1.08952 (* 1 = 1.08952 loss)
I0712 18:16:49.607125 44853 sgd_solver.cpp:106] Iteration 0, lr = 0.015
I0712 18:16:50.884644 44853 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 18:18:52.344249 44853 solver.cpp:236] Iteration 100, loss = 1.0688
I0712 18:18:52.344465 44853 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:18:52.344488 44853 solver.cpp:252]     Train net output #1: loss = 1.19024 (* 1 = 1.19024 loss)
I0712 18:18:52.344503 44853 sgd_solver.cpp:106] Iteration 100, lr = 0.015
I0712 18:20:54.205987 44853 solver.cpp:236] Iteration 200, loss = 1.07884
I0712 18:20:54.206226 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:20:54.206251 44853 solver.cpp:252]     Train net output #1: loss = 1.09479 (* 1 = 1.09479 loss)
I0712 18:20:54.206267 44853 sgd_solver.cpp:106] Iteration 200, lr = 0.015
I0712 18:22:48.512068 44853 solver.cpp:236] Iteration 300, loss = 1.07835
I0712 18:22:48.512238 44853 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:22:48.512269 44853 solver.cpp:252]     Train net output #1: loss = 1.20046 (* 1 = 1.20046 loss)
I0712 18:22:48.512284 44853 sgd_solver.cpp:106] Iteration 300, lr = 0.015
I0712 18:24:25.662662 44853 solver.cpp:236] Iteration 400, loss = 1.06401
I0712 18:24:25.662817 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:24:25.662845 44853 solver.cpp:252]     Train net output #1: loss = 1.0523 (* 1 = 1.0523 loss)
I0712 18:24:25.662863 44853 sgd_solver.cpp:106] Iteration 400, lr = 0.015
I0712 18:26:02.779134 44853 solver.cpp:236] Iteration 500, loss = 1.09308
I0712 18:26:02.779356 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:26:02.779383 44853 solver.cpp:252]     Train net output #1: loss = 1.09305 (* 1 = 1.09305 loss)
I0712 18:26:02.779400 44853 sgd_solver.cpp:106] Iteration 500, lr = 0.015
I0712 18:27:40.406182 44853 solver.cpp:236] Iteration 600, loss = 1.08455
I0712 18:27:40.406333 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:27:40.406368 44853 solver.cpp:252]     Train net output #1: loss = 1.08176 (* 1 = 1.08176 loss)
I0712 18:27:40.406383 44853 sgd_solver.cpp:106] Iteration 600, lr = 0.015
I0712 18:29:17.736896 44853 solver.cpp:236] Iteration 700, loss = 1.06608
I0712 18:29:17.737135 44853 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0712 18:29:17.737160 44853 solver.cpp:252]     Train net output #1: loss = 1.17381 (* 1 = 1.17381 loss)
I0712 18:29:17.737175 44853 sgd_solver.cpp:106] Iteration 700, lr = 0.015
I0712 18:30:54.793615 44853 solver.cpp:236] Iteration 800, loss = 1.06471
I0712 18:30:54.793809 44853 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0712 18:30:54.793836 44853 solver.cpp:252]     Train net output #1: loss = 1.39866 (* 1 = 1.39866 loss)
I0712 18:30:54.793850 44853 sgd_solver.cpp:106] Iteration 800, lr = 0.015
I0712 18:32:31.915832 44853 solver.cpp:236] Iteration 900, loss = 1.07993
I0712 18:32:31.916013 44853 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 18:32:31.916038 44853 solver.cpp:252]     Train net output #1: loss = 0.994407 (* 1 = 0.994407 loss)
I0712 18:32:31.916055 44853 sgd_solver.cpp:106] Iteration 900, lr = 0.015
I0712 18:34:08.340149 44853 solver.cpp:236] Iteration 1000, loss = 1.03914
I0712 18:34:08.340325 44853 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0712 18:34:08.340358 44853 solver.cpp:252]     Train net output #1: loss = 0.910964 (* 1 = 0.910964 loss)
I0712 18:34:08.340379 44853 sgd_solver.cpp:106] Iteration 1000, lr = 0.015
I0712 18:34:51.278381 44853 blocking_queue.cpp:50] Data layer prefetch queue empty
I0712 18:35:46.062582 44853 solver.cpp:236] Iteration 1100, loss = 1.08998
I0712 18:35:46.069303 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:35:46.069336 44853 solver.cpp:252]     Train net output #1: loss = 1.06562 (* 1 = 1.06562 loss)
I0712 18:35:46.069353 44853 sgd_solver.cpp:106] Iteration 1100, lr = 0.015
I0712 18:37:23.532012 44853 solver.cpp:236] Iteration 1200, loss = 1.06283
I0712 18:37:23.532253 44853 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0712 18:37:23.532276 44853 solver.cpp:252]     Train net output #1: loss = 1.09922 (* 1 = 1.09922 loss)
I0712 18:37:23.532294 44853 sgd_solver.cpp:106] Iteration 1200, lr = 0.015
I0712 18:39:00.533031 44853 solver.cpp:236] Iteration 1300, loss = 1.06962
I0712 18:39:00.533175 44853 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0712 18:39:00.533200 44853 solver.cpp:252]     Train net output #1: loss = 0.98134 (* 1 = 0.98134 loss)
I0712 18:39:00.533221 44853 sgd_solver.cpp:106] Iteration 1300, lr = 0.015
I0712 18:40:38.453114 44853 solver.cpp:236] Iteration 1400, loss = 1.07511
I0712 18:40:38.453261 44853 solver.cpp:252]     Train net output #0: accuracy = 1
I0712 18:40:38.453287 44853 solver.cpp:252]     Train net output #1: loss = 0.902912 (* 1 = 0.902912 loss)
I0712 18:40:38.453302 44853 sgd_solver.cpp:106] Iteration 1400, lr = 0.015
I0712 18:42:14.446887 44853 solver.cpp:340] Iteration 1500, Testing net (#0)
F0712 18:42:14.544633 44853 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
