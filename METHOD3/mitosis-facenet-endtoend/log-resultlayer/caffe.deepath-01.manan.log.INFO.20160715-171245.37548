Log file created at: 2016/07/15 17:12:45
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0715 17:12:45.902057 37548 caffe.cpp:184] Using GPUs 0, 1, 2
I0715 17:12:46.234143 37548 solver.cpp:47] Initializing solver from parameters: 
test_iter: 500
test_interval: 1500
base_lr: 0.015
display: 50
max_iter: 180000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 60000
snapshot: 5000
snapshot_prefix: "models-resultlayer"
solver_mode: GPU
device_id: 0
net: "train_val-resultlayer-3stack.prototxt"
test_initialization: false
average_loss: 50
I0715 17:12:46.234344 37548 solver.cpp:90] Creating training net from net file: train_val-resultlayer-3stack.prototxt
I0715 17:12:46.242296 37548 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0715 17:12:46.242602 37548 net.cpp:49] Initializing net from parameters: 
name: "Result Layer 3 Stack"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 163
    mean_value: 116
    mean_value: 181
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 6
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv_c"
  type: "Convolution"
  bottom: "conv53"
  top: "conv_c"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv_c"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0715 17:12:46.245317 37548 layer_factory.hpp:76] Creating layer data
I0715 17:12:46.245373 37548 net.cpp:106] Creating Layer data
I0715 17:12:46.245389 37548 net.cpp:411] data -> data
I0715 17:12:46.245427 37548 net.cpp:411] data -> label
I0715 17:12:46.245864 37548 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0715 17:12:46.257155 37548 image_data_layer.cpp:46] Shuffling data
I0715 17:12:46.258656 37548 image_data_layer.cpp:51] A total of 21366 images.
I0715 17:12:46.690198 37548 image_data_layer.cpp:78] output data size: 6,3,1000,1000
I0715 17:12:46.869698 37548 net.cpp:150] Setting up data
I0715 17:12:46.869817 37548 net.cpp:157] Top shape: 6 3 1000 1000 (18000000)
I0715 17:12:46.869840 37548 net.cpp:157] Top shape: 6 (6)
I0715 17:12:46.869845 37548 net.cpp:165] Memory required for data: 72000024
I0715 17:12:46.869866 37548 layer_factory.hpp:76] Creating layer label_data_1_split
I0715 17:12:46.869884 37548 net.cpp:106] Creating Layer label_data_1_split
I0715 17:12:46.869892 37548 net.cpp:454] label_data_1_split <- label
I0715 17:12:46.869920 37548 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0715 17:12:46.869933 37548 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0715 17:12:46.870038 37548 net.cpp:150] Setting up label_data_1_split
I0715 17:12:46.870055 37548 net.cpp:157] Top shape: 6 (6)
I0715 17:12:46.870110 37548 net.cpp:157] Top shape: 6 (6)
I0715 17:12:46.870115 37548 net.cpp:165] Memory required for data: 72000072
I0715 17:12:46.870120 37548 layer_factory.hpp:76] Creating layer conv11
I0715 17:12:46.870146 37548 net.cpp:106] Creating Layer conv11
I0715 17:12:46.870151 37548 net.cpp:454] conv11 <- data
I0715 17:12:46.870157 37548 net.cpp:411] conv11 -> conv11
I0715 17:12:47.091138 37548 net.cpp:150] Setting up conv11
I0715 17:12:47.091214 37548 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0715 17:12:47.091225 37548 net.cpp:165] Memory required for data: 840000072
I0715 17:12:47.091275 37548 layer_factory.hpp:76] Creating layer relu11
I0715 17:12:47.091311 37548 net.cpp:106] Creating Layer relu11
I0715 17:12:47.091323 37548 net.cpp:454] relu11 <- conv11
I0715 17:12:47.091336 37548 net.cpp:397] relu11 -> conv11 (in-place)
I0715 17:12:47.091598 37548 net.cpp:150] Setting up relu11
I0715 17:12:47.091615 37548 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0715 17:12:47.091624 37548 net.cpp:165] Memory required for data: 1608000072
I0715 17:12:47.091634 37548 layer_factory.hpp:76] Creating layer conv12
I0715 17:12:47.091665 37548 net.cpp:106] Creating Layer conv12
I0715 17:12:47.091675 37548 net.cpp:454] conv12 <- conv11
I0715 17:12:47.091687 37548 net.cpp:411] conv12 -> conv12
I0715 17:12:47.103013 37548 net.cpp:150] Setting up conv12
I0715 17:12:47.103063 37548 net.cpp:157] Top shape: 6 64 1000 1000 (384000000)
I0715 17:12:47.103073 37548 net.cpp:165] Memory required for data: 3144000072
I0715 17:12:47.103101 37548 layer_factory.hpp:76] Creating layer relu12
I0715 17:12:47.103124 37548 net.cpp:106] Creating Layer relu12
I0715 17:12:47.103134 37548 net.cpp:454] relu12 <- conv12
I0715 17:12:47.103147 37548 net.cpp:397] relu12 -> conv12 (in-place)
I0715 17:12:47.106683 37548 net.cpp:150] Setting up relu12
I0715 17:12:47.106736 37548 net.cpp:157] Top shape: 6 64 1000 1000 (384000000)
I0715 17:12:47.106746 37548 net.cpp:165] Memory required for data: 4680000072
I0715 17:12:47.106775 37548 layer_factory.hpp:76] Creating layer pool1
I0715 17:12:47.106802 37548 net.cpp:106] Creating Layer pool1
I0715 17:12:47.106814 37548 net.cpp:454] pool1 <- conv12
I0715 17:12:47.106829 37548 net.cpp:411] pool1 -> pool1
I0715 17:12:47.107214 37548 net.cpp:150] Setting up pool1
I0715 17:12:47.107233 37548 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0715 17:12:47.107244 37548 net.cpp:165] Memory required for data: 5064000072
I0715 17:12:47.107250 37548 layer_factory.hpp:76] Creating layer conv21
I0715 17:12:47.107271 37548 net.cpp:106] Creating Layer conv21
I0715 17:12:47.107280 37548 net.cpp:454] conv21 <- pool1
I0715 17:12:47.107292 37548 net.cpp:411] conv21 -> conv21
I0715 17:12:47.115150 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:47.116118 37548 net.cpp:150] Setting up conv21
I0715 17:12:47.116148 37548 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0715 17:12:47.116158 37548 net.cpp:165] Memory required for data: 5448000072
I0715 17:12:47.116181 37548 layer_factory.hpp:76] Creating layer relu21
I0715 17:12:47.116207 37548 net.cpp:106] Creating Layer relu21
I0715 17:12:47.116220 37548 net.cpp:454] relu21 <- conv21
I0715 17:12:47.116233 37548 net.cpp:397] relu21 -> conv21 (in-place)
I0715 17:12:47.117053 37548 net.cpp:150] Setting up relu21
I0715 17:12:47.117072 37548 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0715 17:12:47.117086 37548 net.cpp:165] Memory required for data: 5832000072
I0715 17:12:47.117095 37548 layer_factory.hpp:76] Creating layer conv22
I0715 17:12:47.117115 37548 net.cpp:106] Creating Layer conv22
I0715 17:12:47.117122 37548 net.cpp:454] conv22 <- conv21
I0715 17:12:47.117132 37548 net.cpp:411] conv22 -> conv22
I0715 17:12:47.120327 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:47.120368 37548 net.cpp:150] Setting up conv22
I0715 17:12:47.120380 37548 net.cpp:157] Top shape: 6 128 500 500 (192000000)
I0715 17:12:47.120388 37548 net.cpp:165] Memory required for data: 6600000072
I0715 17:12:47.120400 37548 layer_factory.hpp:76] Creating layer relu22
I0715 17:12:47.120435 37548 net.cpp:106] Creating Layer relu22
I0715 17:12:47.120445 37548 net.cpp:454] relu22 <- conv22
I0715 17:12:47.120455 37548 net.cpp:397] relu22 -> conv22 (in-place)
I0715 17:12:47.121078 37548 net.cpp:150] Setting up relu22
I0715 17:12:47.121100 37548 net.cpp:157] Top shape: 6 128 500 500 (192000000)
I0715 17:12:47.121109 37548 net.cpp:165] Memory required for data: 7368000072
I0715 17:12:47.121117 37548 layer_factory.hpp:76] Creating layer pool2
I0715 17:12:47.121132 37548 net.cpp:106] Creating Layer pool2
I0715 17:12:47.121140 37548 net.cpp:454] pool2 <- conv22
I0715 17:12:47.121150 37548 net.cpp:411] pool2 -> pool2
I0715 17:12:47.121369 37548 net.cpp:150] Setting up pool2
I0715 17:12:47.121387 37548 net.cpp:157] Top shape: 6 128 250 250 (48000000)
I0715 17:12:47.121393 37548 net.cpp:165] Memory required for data: 7560000072
I0715 17:12:47.121402 37548 layer_factory.hpp:76] Creating layer conv31
I0715 17:12:47.121415 37548 net.cpp:106] Creating Layer conv31
I0715 17:12:47.121423 37548 net.cpp:454] conv31 <- pool2
I0715 17:12:47.121438 37548 net.cpp:411] conv31 -> conv31
I0715 17:12:47.124038 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:47.124078 37548 net.cpp:150] Setting up conv31
I0715 17:12:47.124094 37548 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0715 17:12:47.124102 37548 net.cpp:165] Memory required for data: 7704000072
I0715 17:12:47.124119 37548 layer_factory.hpp:76] Creating layer relu31
I0715 17:12:47.124131 37548 net.cpp:106] Creating Layer relu31
I0715 17:12:47.124140 37548 net.cpp:454] relu31 <- conv31
I0715 17:12:47.124151 37548 net.cpp:397] relu31 -> conv31 (in-place)
I0715 17:12:47.124732 37548 net.cpp:150] Setting up relu31
I0715 17:12:47.124754 37548 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0715 17:12:47.124763 37548 net.cpp:165] Memory required for data: 7848000072
I0715 17:12:47.124771 37548 layer_factory.hpp:76] Creating layer conv32
I0715 17:12:47.124788 37548 net.cpp:106] Creating Layer conv32
I0715 17:12:47.124796 37548 net.cpp:454] conv32 <- conv31
I0715 17:12:47.124809 37548 net.cpp:411] conv32 -> conv32
I0715 17:12:47.128419 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:47.128451 37548 net.cpp:150] Setting up conv32
I0715 17:12:47.128464 37548 net.cpp:157] Top shape: 6 192 250 250 (72000000)
I0715 17:12:47.128475 37548 net.cpp:165] Memory required for data: 8136000072
I0715 17:12:47.128486 37548 layer_factory.hpp:76] Creating layer relu32
I0715 17:12:47.128500 37548 net.cpp:106] Creating Layer relu32
I0715 17:12:47.128509 37548 net.cpp:454] relu32 <- conv32
I0715 17:12:47.128518 37548 net.cpp:397] relu32 -> conv32 (in-place)
I0715 17:12:47.128701 37548 net.cpp:150] Setting up relu32
I0715 17:12:47.128729 37548 net.cpp:157] Top shape: 6 192 250 250 (72000000)
I0715 17:12:47.128737 37548 net.cpp:165] Memory required for data: 8424000072
I0715 17:12:47.128746 37548 layer_factory.hpp:76] Creating layer pool3
I0715 17:12:47.128762 37548 net.cpp:106] Creating Layer pool3
I0715 17:12:47.128769 37548 net.cpp:454] pool3 <- conv32
I0715 17:12:47.128779 37548 net.cpp:411] pool3 -> pool3
I0715 17:12:47.129783 37548 net.cpp:150] Setting up pool3
I0715 17:12:47.129803 37548 net.cpp:157] Top shape: 6 192 125 125 (18000000)
I0715 17:12:47.129812 37548 net.cpp:165] Memory required for data: 8496000072
I0715 17:12:47.129819 37548 layer_factory.hpp:76] Creating layer conv41
I0715 17:12:47.129837 37548 net.cpp:106] Creating Layer conv41
I0715 17:12:47.129848 37548 net.cpp:454] conv41 <- pool3
I0715 17:12:47.129859 37548 net.cpp:411] conv41 -> conv41
I0715 17:12:47.134296 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20736
I0715 17:12:47.134960 37548 net.cpp:150] Setting up conv41
I0715 17:12:47.134979 37548 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0715 17:12:47.134987 37548 net.cpp:165] Memory required for data: 8544000072
I0715 17:12:47.135020 37548 layer_factory.hpp:76] Creating layer relu41
I0715 17:12:47.135031 37548 net.cpp:106] Creating Layer relu41
I0715 17:12:47.135056 37548 net.cpp:454] relu41 <- conv41
I0715 17:12:47.135066 37548 net.cpp:397] relu41 -> conv41 (in-place)
I0715 17:12:47.135500 37548 net.cpp:150] Setting up relu41
I0715 17:12:47.135519 37548 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0715 17:12:47.135527 37548 net.cpp:165] Memory required for data: 8592000072
I0715 17:12:47.135535 37548 layer_factory.hpp:76] Creating layer conv42
I0715 17:12:47.135551 37548 net.cpp:106] Creating Layer conv42
I0715 17:12:47.135560 37548 net.cpp:454] conv42 <- conv41
I0715 17:12:47.135571 37548 net.cpp:411] conv42 -> conv42
I0715 17:12:47.141144 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:47.141177 37548 net.cpp:150] Setting up conv42
I0715 17:12:47.141190 37548 net.cpp:157] Top shape: 6 256 125 125 (24000000)
I0715 17:12:47.141197 37548 net.cpp:165] Memory required for data: 8688000072
I0715 17:12:47.141208 37548 layer_factory.hpp:76] Creating layer relu42
I0715 17:12:47.141222 37548 net.cpp:106] Creating Layer relu42
I0715 17:12:47.141229 37548 net.cpp:454] relu42 <- conv42
I0715 17:12:47.141240 37548 net.cpp:397] relu42 -> conv42 (in-place)
I0715 17:12:47.141407 37548 net.cpp:150] Setting up relu42
I0715 17:12:47.141422 37548 net.cpp:157] Top shape: 6 256 125 125 (24000000)
I0715 17:12:47.141430 37548 net.cpp:165] Memory required for data: 8784000072
I0715 17:12:47.141438 37548 layer_factory.hpp:76] Creating layer pool4
I0715 17:12:47.141450 37548 net.cpp:106] Creating Layer pool4
I0715 17:12:47.141458 37548 net.cpp:454] pool4 <- conv42
I0715 17:12:47.141468 37548 net.cpp:411] pool4 -> pool4
I0715 17:12:47.142279 37548 net.cpp:150] Setting up pool4
I0715 17:12:47.142299 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.142307 37548 net.cpp:165] Memory required for data: 8808385608
I0715 17:12:47.142316 37548 layer_factory.hpp:76] Creating layer conv51
I0715 17:12:47.142331 37548 net.cpp:106] Creating Layer conv51
I0715 17:12:47.142339 37548 net.cpp:454] conv51 <- pool4
I0715 17:12:47.142382 37548 net.cpp:411] conv51 -> conv51
I0715 17:12:47.149451 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:47.149487 37548 net.cpp:150] Setting up conv51
I0715 17:12:47.149500 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.149507 37548 net.cpp:165] Memory required for data: 8832771144
I0715 17:12:47.149524 37548 layer_factory.hpp:76] Creating layer relu51
I0715 17:12:47.149538 37548 net.cpp:106] Creating Layer relu51
I0715 17:12:47.149547 37548 net.cpp:454] relu51 <- conv51
I0715 17:12:47.149556 37548 net.cpp:397] relu51 -> conv51 (in-place)
I0715 17:12:47.149751 37548 net.cpp:150] Setting up relu51
I0715 17:12:47.149780 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.149787 37548 net.cpp:165] Memory required for data: 8857156680
I0715 17:12:47.149796 37548 layer_factory.hpp:76] Creating layer conv52
I0715 17:12:47.149814 37548 net.cpp:106] Creating Layer conv52
I0715 17:12:47.149835 37548 net.cpp:454] conv52 <- conv51
I0715 17:12:47.149844 37548 net.cpp:411] conv52 -> conv52
I0715 17:12:47.156244 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:47.156275 37548 net.cpp:150] Setting up conv52
I0715 17:12:47.156287 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.156296 37548 net.cpp:165] Memory required for data: 8881542216
I0715 17:12:47.156306 37548 layer_factory.hpp:76] Creating layer relu52
I0715 17:12:47.156322 37548 net.cpp:106] Creating Layer relu52
I0715 17:12:47.156329 37548 net.cpp:454] relu52 <- conv52
I0715 17:12:47.156338 37548 net.cpp:397] relu52 -> conv52 (in-place)
I0715 17:12:47.156704 37548 net.cpp:150] Setting up relu52
I0715 17:12:47.156723 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.156731 37548 net.cpp:165] Memory required for data: 8905927752
I0715 17:12:47.156754 37548 layer_factory.hpp:76] Creating layer conv53
I0715 17:12:47.156769 37548 net.cpp:106] Creating Layer conv53
I0715 17:12:47.156779 37548 net.cpp:454] conv53 <- conv52
I0715 17:12:47.156815 37548 net.cpp:411] conv53 -> conv53
I0715 17:12:47.185356 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0715 17:12:47.186106 37548 net.cpp:150] Setting up conv53
I0715 17:12:47.186136 37548 net.cpp:157] Top shape: 6 256 57 57 (4990464)
I0715 17:12:47.186146 37548 net.cpp:165] Memory required for data: 8925889608
I0715 17:12:47.186161 37548 layer_factory.hpp:76] Creating layer relu53
I0715 17:12:47.186178 37548 net.cpp:106] Creating Layer relu53
I0715 17:12:47.186189 37548 net.cpp:454] relu53 <- conv53
I0715 17:12:47.186203 37548 net.cpp:397] relu53 -> conv53 (in-place)
I0715 17:12:47.186859 37548 net.cpp:150] Setting up relu53
I0715 17:12:47.186880 37548 net.cpp:157] Top shape: 6 256 57 57 (4990464)
I0715 17:12:47.186888 37548 net.cpp:165] Memory required for data: 8945851464
I0715 17:12:47.186897 37548 layer_factory.hpp:76] Creating layer conv_c
I0715 17:12:47.186916 37548 net.cpp:106] Creating Layer conv_c
I0715 17:12:47.186926 37548 net.cpp:454] conv_c <- conv53
I0715 17:12:47.186938 37548 net.cpp:411] conv_c -> conv_c
I0715 17:12:47.188570 37548 net.cpp:150] Setting up conv_c
I0715 17:12:47.188591 37548 net.cpp:157] Top shape: 6 2 57 57 (38988)
I0715 17:12:47.188601 37548 net.cpp:165] Memory required for data: 8946007416
I0715 17:12:47.188611 37548 layer_factory.hpp:76] Creating layer interloss
I0715 17:12:47.188627 37548 net.cpp:106] Creating Layer interloss
I0715 17:12:47.188637 37548 net.cpp:454] interloss <- conv_c
I0715 17:12:47.188645 37548 net.cpp:411] interloss -> interloss
I0715 17:12:47.188920 37548 net.cpp:150] Setting up interloss
I0715 17:12:47.188936 37548 net.cpp:157] Top shape: 6 2 57 57 (38988)
I0715 17:12:47.188946 37548 net.cpp:165] Memory required for data: 8946163368
I0715 17:12:47.188956 37548 layer_factory.hpp:76] Creating layer conv61
I0715 17:12:47.188971 37548 net.cpp:106] Creating Layer conv61
I0715 17:12:47.188980 37548 net.cpp:454] conv61 <- interloss
I0715 17:12:47.188992 37548 net.cpp:411] conv61 -> conv61
I0715 17:12:47.190528 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4210704
I0715 17:12:47.191048 37548 net.cpp:150] Setting up conv61
I0715 17:12:47.191078 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.191087 37548 net.cpp:165] Memory required for data: 8951153832
I0715 17:12:47.191098 37548 layer_factory.hpp:76] Creating layer relu61
I0715 17:12:47.191108 37548 net.cpp:106] Creating Layer relu61
I0715 17:12:47.191118 37548 net.cpp:454] relu61 <- conv61
I0715 17:12:47.191131 37548 net.cpp:397] relu61 -> conv61 (in-place)
I0715 17:12:47.191771 37548 net.cpp:150] Setting up relu61
I0715 17:12:47.191789 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.191799 37548 net.cpp:165] Memory required for data: 8956144296
I0715 17:12:47.191807 37548 layer_factory.hpp:76] Creating layer conv62
I0715 17:12:47.191826 37548 net.cpp:106] Creating Layer conv62
I0715 17:12:47.191834 37548 net.cpp:454] conv62 <- conv61
I0715 17:12:47.191857 37548 net.cpp:411] conv62 -> conv62
I0715 17:12:47.193310 37548 net.cpp:150] Setting up conv62
I0715 17:12:47.193330 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.193341 37548 net.cpp:165] Memory required for data: 8961134760
I0715 17:12:47.193351 37548 layer_factory.hpp:76] Creating layer relu62
I0715 17:12:47.193375 37548 net.cpp:106] Creating Layer relu62
I0715 17:12:47.193385 37548 net.cpp:454] relu62 <- conv62
I0715 17:12:47.193394 37548 net.cpp:397] relu62 -> conv62 (in-place)
I0715 17:12:47.194757 37548 net.cpp:150] Setting up relu62
I0715 17:12:47.194779 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.194788 37548 net.cpp:165] Memory required for data: 8966125224
I0715 17:12:47.194797 37548 layer_factory.hpp:76] Creating layer pool5
I0715 17:12:47.194823 37548 net.cpp:106] Creating Layer pool5
I0715 17:12:47.194831 37548 net.cpp:454] pool5 <- conv62
I0715 17:12:47.194841 37548 net.cpp:411] pool5 -> pool5
I0715 17:12:47.195103 37548 net.cpp:150] Setting up pool5
I0715 17:12:47.195119 37548 net.cpp:157] Top shape: 6 64 29 29 (322944)
I0715 17:12:47.195166 37548 net.cpp:165] Memory required for data: 8967417000
I0715 17:12:47.195179 37548 layer_factory.hpp:76] Creating layer conv71
I0715 17:12:47.195194 37548 net.cpp:106] Creating Layer conv71
I0715 17:12:47.195204 37548 net.cpp:454] conv71 <- pool5
I0715 17:12:47.195214 37548 net.cpp:411] conv71 -> conv71
I0715 17:12:47.197895 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:47.197926 37548 net.cpp:150] Setting up conv71
I0715 17:12:47.197937 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.197943 37548 net.cpp:165] Memory required for data: 8969354664
I0715 17:12:47.197953 37548 layer_factory.hpp:76] Creating layer relu71
I0715 17:12:47.197963 37548 net.cpp:106] Creating Layer relu71
I0715 17:12:47.197983 37548 net.cpp:454] relu71 <- conv71
I0715 17:12:47.197994 37548 net.cpp:397] relu71 -> conv71 (in-place)
I0715 17:12:47.198592 37548 net.cpp:150] Setting up relu71
I0715 17:12:47.198611 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.198637 37548 net.cpp:165] Memory required for data: 8971292328
I0715 17:12:47.198645 37548 layer_factory.hpp:76] Creating layer conv72
I0715 17:12:47.198657 37548 net.cpp:106] Creating Layer conv72
I0715 17:12:47.198665 37548 net.cpp:454] conv72 <- conv71
I0715 17:12:47.198689 37548 net.cpp:411] conv72 -> conv72
I0715 17:12:47.200733 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:47.200765 37548 net.cpp:150] Setting up conv72
I0715 17:12:47.200778 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.200785 37548 net.cpp:165] Memory required for data: 8973229992
I0715 17:12:47.200809 37548 layer_factory.hpp:76] Creating layer relu72
I0715 17:12:47.200820 37548 net.cpp:106] Creating Layer relu72
I0715 17:12:47.200827 37548 net.cpp:454] relu72 <- conv72
I0715 17:12:47.200837 37548 net.cpp:397] relu72 -> conv72 (in-place)
I0715 17:12:47.201086 37548 net.cpp:150] Setting up relu72
I0715 17:12:47.201102 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.201122 37548 net.cpp:165] Memory required for data: 8975167656
I0715 17:12:47.201129 37548 layer_factory.hpp:76] Creating layer pool6
I0715 17:12:47.201138 37548 net.cpp:106] Creating Layer pool6
I0715 17:12:47.201158 37548 net.cpp:454] pool6 <- conv72
I0715 17:12:47.201169 37548 net.cpp:411] pool6 -> pool6
I0715 17:12:47.201882 37548 net.cpp:150] Setting up pool6
I0715 17:12:47.201900 37548 net.cpp:157] Top shape: 6 96 15 15 (129600)
I0715 17:12:47.201913 37548 net.cpp:165] Memory required for data: 8975686056
I0715 17:12:47.201920 37548 layer_factory.hpp:76] Creating layer conv81
I0715 17:12:47.201932 37548 net.cpp:106] Creating Layer conv81
I0715 17:12:47.201952 37548 net.cpp:454] conv81 <- pool6
I0715 17:12:47.201964 37548 net.cpp:411] conv81 -> conv81
I0715 17:12:47.204715 37548 net.cpp:150] Setting up conv81
I0715 17:12:47.204735 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.204742 37548 net.cpp:165] Memory required for data: 8976377256
I0715 17:12:47.204761 37548 layer_factory.hpp:76] Creating layer relu81
I0715 17:12:47.204771 37548 net.cpp:106] Creating Layer relu81
I0715 17:12:47.204779 37548 net.cpp:454] relu81 <- conv81
I0715 17:12:47.204789 37548 net.cpp:397] relu81 -> conv81 (in-place)
I0715 17:12:47.205376 37548 net.cpp:150] Setting up relu81
I0715 17:12:47.205406 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.205415 37548 net.cpp:165] Memory required for data: 8977068456
I0715 17:12:47.205421 37548 layer_factory.hpp:76] Creating layer conv82
I0715 17:12:47.205437 37548 net.cpp:106] Creating Layer conv82
I0715 17:12:47.205458 37548 net.cpp:454] conv82 <- conv81
I0715 17:12:47.205482 37548 net.cpp:411] conv82 -> conv82
I0715 17:12:47.207855 37548 net.cpp:150] Setting up conv82
I0715 17:12:47.207875 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.207882 37548 net.cpp:165] Memory required for data: 8977759656
I0715 17:12:47.207891 37548 layer_factory.hpp:76] Creating layer relu82
I0715 17:12:47.207903 37548 net.cpp:106] Creating Layer relu82
I0715 17:12:47.207929 37548 net.cpp:454] relu82 <- conv82
I0715 17:12:47.207939 37548 net.cpp:397] relu82 -> conv82 (in-place)
I0715 17:12:47.208165 37548 net.cpp:150] Setting up relu82
I0715 17:12:47.208181 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.208189 37548 net.cpp:165] Memory required for data: 8978450856
I0715 17:12:47.208196 37548 layer_factory.hpp:76] Creating layer pool7
I0715 17:12:47.208209 37548 net.cpp:106] Creating Layer pool7
I0715 17:12:47.208216 37548 net.cpp:454] pool7 <- conv82
I0715 17:12:47.208230 37548 net.cpp:411] pool7 -> pool7
I0715 17:12:47.208787 37548 net.cpp:150] Setting up pool7
I0715 17:12:47.208804 37548 net.cpp:157] Top shape: 6 128 8 8 (49152)
I0715 17:12:47.208811 37548 net.cpp:165] Memory required for data: 8978647464
I0715 17:12:47.208818 37548 layer_factory.hpp:76] Creating layer drop0
I0715 17:12:47.208835 37548 net.cpp:106] Creating Layer drop0
I0715 17:12:47.208843 37548 net.cpp:454] drop0 <- pool7
I0715 17:12:47.208852 37548 net.cpp:397] drop0 -> pool7 (in-place)
I0715 17:12:47.208895 37548 net.cpp:150] Setting up drop0
I0715 17:12:47.208907 37548 net.cpp:157] Top shape: 6 128 8 8 (49152)
I0715 17:12:47.208915 37548 net.cpp:165] Memory required for data: 8978844072
I0715 17:12:47.208926 37548 layer_factory.hpp:76] Creating layer conv91
I0715 17:12:47.208941 37548 net.cpp:106] Creating Layer conv91
I0715 17:12:47.208950 37548 net.cpp:454] conv91 <- pool7
I0715 17:12:47.208959 37548 net.cpp:411] conv91 -> conv91
I0715 17:12:47.210294 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0715 17:12:47.210326 37548 net.cpp:150] Setting up conv91
I0715 17:12:47.210338 37548 net.cpp:157] Top shape: 6 3 1 1 (18)
I0715 17:12:47.210347 37548 net.cpp:165] Memory required for data: 8978844144
I0715 17:12:47.210361 37548 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0715 17:12:47.210372 37548 net.cpp:106] Creating Layer conv91_conv91_0_split
I0715 17:12:47.210382 37548 net.cpp:454] conv91_conv91_0_split <- conv91
I0715 17:12:47.210392 37548 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0715 17:12:47.210407 37548 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0715 17:12:47.210458 37548 net.cpp:150] Setting up conv91_conv91_0_split
I0715 17:12:47.210491 37548 net.cpp:157] Top shape: 6 3 1 1 (18)
I0715 17:12:47.210502 37548 net.cpp:157] Top shape: 6 3 1 1 (18)
I0715 17:12:47.210510 37548 net.cpp:165] Memory required for data: 8978844288
I0715 17:12:47.210531 37548 layer_factory.hpp:76] Creating layer accuracy
I0715 17:12:47.210547 37548 net.cpp:106] Creating Layer accuracy
I0715 17:12:47.210556 37548 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0715 17:12:47.210566 37548 net.cpp:454] accuracy <- label_data_1_split_0
I0715 17:12:47.210587 37548 net.cpp:411] accuracy -> accuracy
I0715 17:12:47.210613 37548 net.cpp:150] Setting up accuracy
I0715 17:12:47.210639 37548 net.cpp:157] Top shape: (1)
I0715 17:12:47.210647 37548 net.cpp:165] Memory required for data: 8978844292
I0715 17:12:47.210655 37548 layer_factory.hpp:76] Creating layer loss
I0715 17:12:47.210667 37548 net.cpp:106] Creating Layer loss
I0715 17:12:47.210686 37548 net.cpp:454] loss <- conv91_conv91_0_split_1
I0715 17:12:47.210695 37548 net.cpp:454] loss <- label_data_1_split_1
I0715 17:12:47.210703 37548 net.cpp:411] loss -> loss
I0715 17:12:47.210721 37548 layer_factory.hpp:76] Creating layer loss
I0715 17:12:47.211072 37548 net.cpp:150] Setting up loss
I0715 17:12:47.211089 37548 net.cpp:157] Top shape: (1)
I0715 17:12:47.211097 37548 net.cpp:160]     with loss weight 1
I0715 17:12:47.211127 37548 net.cpp:165] Memory required for data: 8978844296
I0715 17:12:47.211134 37548 net.cpp:226] loss needs backward computation.
I0715 17:12:47.211143 37548 net.cpp:228] accuracy does not need backward computation.
I0715 17:12:47.211150 37548 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0715 17:12:47.211158 37548 net.cpp:226] conv91 needs backward computation.
I0715 17:12:47.211165 37548 net.cpp:226] drop0 needs backward computation.
I0715 17:12:47.211189 37548 net.cpp:226] pool7 needs backward computation.
I0715 17:12:47.211196 37548 net.cpp:226] relu82 needs backward computation.
I0715 17:12:47.211204 37548 net.cpp:226] conv82 needs backward computation.
I0715 17:12:47.211210 37548 net.cpp:226] relu81 needs backward computation.
I0715 17:12:47.211217 37548 net.cpp:226] conv81 needs backward computation.
I0715 17:12:47.211226 37548 net.cpp:226] pool6 needs backward computation.
I0715 17:12:47.211233 37548 net.cpp:226] relu72 needs backward computation.
I0715 17:12:47.211241 37548 net.cpp:226] conv72 needs backward computation.
I0715 17:12:47.211247 37548 net.cpp:226] relu71 needs backward computation.
I0715 17:12:47.211254 37548 net.cpp:226] conv71 needs backward computation.
I0715 17:12:47.211261 37548 net.cpp:226] pool5 needs backward computation.
I0715 17:12:47.211268 37548 net.cpp:226] relu62 needs backward computation.
I0715 17:12:47.211275 37548 net.cpp:226] conv62 needs backward computation.
I0715 17:12:47.211282 37548 net.cpp:226] relu61 needs backward computation.
I0715 17:12:47.211289 37548 net.cpp:226] conv61 needs backward computation.
I0715 17:12:47.211297 37548 net.cpp:228] interloss does not need backward computation.
I0715 17:12:47.211305 37548 net.cpp:228] conv_c does not need backward computation.
I0715 17:12:47.211313 37548 net.cpp:228] relu53 does not need backward computation.
I0715 17:12:47.211320 37548 net.cpp:228] conv53 does not need backward computation.
I0715 17:12:47.211328 37548 net.cpp:228] relu52 does not need backward computation.
I0715 17:12:47.211335 37548 net.cpp:228] conv52 does not need backward computation.
I0715 17:12:47.211343 37548 net.cpp:228] relu51 does not need backward computation.
I0715 17:12:47.211352 37548 net.cpp:228] conv51 does not need backward computation.
I0715 17:12:47.211360 37548 net.cpp:228] pool4 does not need backward computation.
I0715 17:12:47.211369 37548 net.cpp:228] relu42 does not need backward computation.
I0715 17:12:47.211375 37548 net.cpp:228] conv42 does not need backward computation.
I0715 17:12:47.211383 37548 net.cpp:228] relu41 does not need backward computation.
I0715 17:12:47.211391 37548 net.cpp:228] conv41 does not need backward computation.
I0715 17:12:47.211400 37548 net.cpp:228] pool3 does not need backward computation.
I0715 17:12:47.211406 37548 net.cpp:228] relu32 does not need backward computation.
I0715 17:12:47.211415 37548 net.cpp:228] conv32 does not need backward computation.
I0715 17:12:47.211421 37548 net.cpp:228] relu31 does not need backward computation.
I0715 17:12:47.211441 37548 net.cpp:228] conv31 does not need backward computation.
I0715 17:12:47.211449 37548 net.cpp:228] pool2 does not need backward computation.
I0715 17:12:47.211457 37548 net.cpp:228] relu22 does not need backward computation.
I0715 17:12:47.211463 37548 net.cpp:228] conv22 does not need backward computation.
I0715 17:12:47.211472 37548 net.cpp:228] relu21 does not need backward computation.
I0715 17:12:47.211478 37548 net.cpp:228] conv21 does not need backward computation.
I0715 17:12:47.211486 37548 net.cpp:228] pool1 does not need backward computation.
I0715 17:12:47.211493 37548 net.cpp:228] relu12 does not need backward computation.
I0715 17:12:47.211501 37548 net.cpp:228] conv12 does not need backward computation.
I0715 17:12:47.211508 37548 net.cpp:228] relu11 does not need backward computation.
I0715 17:12:47.211516 37548 net.cpp:228] conv11 does not need backward computation.
I0715 17:12:47.211524 37548 net.cpp:228] label_data_1_split does not need backward computation.
I0715 17:12:47.211532 37548 net.cpp:228] data does not need backward computation.
I0715 17:12:47.211539 37548 net.cpp:270] This network produces output accuracy
I0715 17:12:47.211546 37548 net.cpp:270] This network produces output loss
I0715 17:12:47.211578 37548 net.cpp:283] Network initialization done.
I0715 17:12:47.212888 37548 solver.cpp:180] Creating test net (#0) specified by net file: train_val-resultlayer-3stack.prototxt
I0715 17:12:47.212980 37548 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0715 17:12:47.213312 37548 net.cpp:49] Initializing net from parameters: 
name: "Result Layer 3 Stack"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 163
    mean_value: 116
    mean_value: 181
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 6
    shuffle: true
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv12"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv22"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv32"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "pool3"
  top: "conv41"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv42"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv51"
  type: "Convolution"
  bottom: "pool4"
  top: "conv51"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu51"
  type: "ReLU"
  bottom: "conv51"
  top: "conv51"
}
layer {
  name: "conv52"
  type: "Convolution"
  bottom: "conv51"
  top: "conv52"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv52"
  top: "conv52"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv52"
  top: "conv53"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "relu53"
  type: "ReLU"
  bottom: "conv53"
  top: "conv53"
}
layer {
  name: "conv_c"
  type: "Convolution"
  bottom: "conv53"
  top: "conv_c"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "conv_c"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0715 17:12:47.215641 37548 layer_factory.hpp:76] Creating layer data
I0715 17:12:47.215668 37548 net.cpp:106] Creating Layer data
I0715 17:12:47.215679 37548 net.cpp:411] data -> data
I0715 17:12:47.215692 37548 net.cpp:411] data -> label
I0715 17:12:47.215704 37548 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0715 17:12:47.217020 37548 image_data_layer.cpp:46] Shuffling data
I0715 17:12:47.217221 37548 image_data_layer.cpp:51] A total of 2375 images.
I0715 17:12:47.296931 37548 image_data_layer.cpp:78] output data size: 6,3,1000,1000
I0715 17:12:47.468821 37548 net.cpp:150] Setting up data
I0715 17:12:47.469882 37548 net.cpp:157] Top shape: 6 3 1000 1000 (18000000)
I0715 17:12:47.469940 37548 net.cpp:157] Top shape: 6 (6)
I0715 17:12:47.469951 37548 net.cpp:165] Memory required for data: 72000024
I0715 17:12:47.469966 37548 layer_factory.hpp:76] Creating layer label_data_1_split
I0715 17:12:47.469988 37548 net.cpp:106] Creating Layer label_data_1_split
I0715 17:12:47.470010 37548 net.cpp:454] label_data_1_split <- label
I0715 17:12:47.470022 37548 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0715 17:12:47.470041 37548 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0715 17:12:47.470304 37548 net.cpp:150] Setting up label_data_1_split
I0715 17:12:47.470365 37548 net.cpp:157] Top shape: 6 (6)
I0715 17:12:47.470374 37548 net.cpp:157] Top shape: 6 (6)
I0715 17:12:47.470382 37548 net.cpp:165] Memory required for data: 72000072
I0715 17:12:47.470394 37548 layer_factory.hpp:76] Creating layer conv11
I0715 17:12:47.470422 37548 net.cpp:106] Creating Layer conv11
I0715 17:12:47.470432 37548 net.cpp:454] conv11 <- data
I0715 17:12:47.470445 37548 net.cpp:411] conv11 -> conv11
I0715 17:12:47.479992 37548 net.cpp:150] Setting up conv11
I0715 17:12:47.480031 37548 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0715 17:12:47.480041 37548 net.cpp:165] Memory required for data: 840000072
I0715 17:12:47.480085 37548 layer_factory.hpp:76] Creating layer relu11
I0715 17:12:47.480106 37548 net.cpp:106] Creating Layer relu11
I0715 17:12:47.480115 37548 net.cpp:454] relu11 <- conv11
I0715 17:12:47.480125 37548 net.cpp:397] relu11 -> conv11 (in-place)
I0715 17:12:47.487407 37548 net.cpp:150] Setting up relu11
I0715 17:12:47.487468 37548 net.cpp:157] Top shape: 6 32 1000 1000 (192000000)
I0715 17:12:47.487478 37548 net.cpp:165] Memory required for data: 1608000072
I0715 17:12:47.487491 37548 layer_factory.hpp:76] Creating layer conv12
I0715 17:12:47.487520 37548 net.cpp:106] Creating Layer conv12
I0715 17:12:47.487531 37548 net.cpp:454] conv12 <- conv11
I0715 17:12:47.487545 37548 net.cpp:411] conv12 -> conv12
I0715 17:12:47.492300 37548 net.cpp:150] Setting up conv12
I0715 17:12:47.492336 37548 net.cpp:157] Top shape: 6 64 1000 1000 (384000000)
I0715 17:12:47.492346 37548 net.cpp:165] Memory required for data: 3144000072
I0715 17:12:47.492362 37548 layer_factory.hpp:76] Creating layer relu12
I0715 17:12:47.492375 37548 net.cpp:106] Creating Layer relu12
I0715 17:12:47.492383 37548 net.cpp:454] relu12 <- conv12
I0715 17:12:47.492394 37548 net.cpp:397] relu12 -> conv12 (in-place)
I0715 17:12:47.500571 37548 net.cpp:150] Setting up relu12
I0715 17:12:47.500630 37548 net.cpp:157] Top shape: 6 64 1000 1000 (384000000)
I0715 17:12:47.500640 37548 net.cpp:165] Memory required for data: 4680000072
I0715 17:12:47.500654 37548 layer_factory.hpp:76] Creating layer pool1
I0715 17:12:47.500675 37548 net.cpp:106] Creating Layer pool1
I0715 17:12:47.500689 37548 net.cpp:454] pool1 <- conv12
I0715 17:12:47.500702 37548 net.cpp:411] pool1 -> pool1
I0715 17:12:47.500973 37548 net.cpp:150] Setting up pool1
I0715 17:12:47.501003 37548 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0715 17:12:47.501011 37548 net.cpp:165] Memory required for data: 5064000072
I0715 17:12:47.501019 37548 layer_factory.hpp:76] Creating layer conv21
I0715 17:12:47.501036 37548 net.cpp:106] Creating Layer conv21
I0715 17:12:47.501044 37548 net.cpp:454] conv21 <- pool1
I0715 17:12:47.501055 37548 net.cpp:411] conv21 -> conv21
I0715 17:12:47.510453 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:47.510556 37548 net.cpp:150] Setting up conv21
I0715 17:12:47.510571 37548 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0715 17:12:47.510576 37548 net.cpp:165] Memory required for data: 5448000072
I0715 17:12:47.510596 37548 layer_factory.hpp:76] Creating layer relu21
I0715 17:12:47.510613 37548 net.cpp:106] Creating Layer relu21
I0715 17:12:47.510619 37548 net.cpp:454] relu21 <- conv21
I0715 17:12:47.510639 37548 net.cpp:397] relu21 -> conv21 (in-place)
I0715 17:12:47.511719 37548 net.cpp:150] Setting up relu21
I0715 17:12:47.511746 37548 net.cpp:157] Top shape: 6 64 500 500 (96000000)
I0715 17:12:47.511759 37548 net.cpp:165] Memory required for data: 5832000072
I0715 17:12:47.511768 37548 layer_factory.hpp:76] Creating layer conv22
I0715 17:12:47.511785 37548 net.cpp:106] Creating Layer conv22
I0715 17:12:47.511795 37548 net.cpp:454] conv22 <- conv21
I0715 17:12:47.511807 37548 net.cpp:411] conv22 -> conv22
I0715 17:12:47.521291 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:47.521430 37548 net.cpp:150] Setting up conv22
I0715 17:12:47.521463 37548 net.cpp:157] Top shape: 6 128 500 500 (192000000)
I0715 17:12:47.521481 37548 net.cpp:165] Memory required for data: 6600000072
I0715 17:12:47.521505 37548 layer_factory.hpp:76] Creating layer relu22
I0715 17:12:47.521529 37548 net.cpp:106] Creating Layer relu22
I0715 17:12:47.521543 37548 net.cpp:454] relu22 <- conv22
I0715 17:12:47.521559 37548 net.cpp:397] relu22 -> conv22 (in-place)
I0715 17:12:47.521875 37548 net.cpp:150] Setting up relu22
I0715 17:12:47.521894 37548 net.cpp:157] Top shape: 6 128 500 500 (192000000)
I0715 17:12:47.521903 37548 net.cpp:165] Memory required for data: 7368000072
I0715 17:12:47.521911 37548 layer_factory.hpp:76] Creating layer pool2
I0715 17:12:47.521927 37548 net.cpp:106] Creating Layer pool2
I0715 17:12:47.521973 37548 net.cpp:454] pool2 <- conv22
I0715 17:12:47.521986 37548 net.cpp:411] pool2 -> pool2
I0715 17:12:47.523097 37548 net.cpp:150] Setting up pool2
I0715 17:12:47.523129 37548 net.cpp:157] Top shape: 6 128 250 250 (48000000)
I0715 17:12:47.523138 37548 net.cpp:165] Memory required for data: 7560000072
I0715 17:12:47.523152 37548 layer_factory.hpp:76] Creating layer conv31
I0715 17:12:47.523169 37548 net.cpp:106] Creating Layer conv31
I0715 17:12:47.523180 37548 net.cpp:454] conv31 <- pool2
I0715 17:12:47.523195 37548 net.cpp:411] conv31 -> conv31
I0715 17:12:47.532557 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:47.532655 37548 net.cpp:150] Setting up conv31
I0715 17:12:47.532673 37548 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0715 17:12:47.532682 37548 net.cpp:165] Memory required for data: 7704000072
I0715 17:12:47.532706 37548 layer_factory.hpp:76] Creating layer relu31
I0715 17:12:47.532723 37548 net.cpp:106] Creating Layer relu31
I0715 17:12:47.532734 37548 net.cpp:454] relu31 <- conv31
I0715 17:12:47.532747 37548 net.cpp:397] relu31 -> conv31 (in-place)
I0715 17:12:47.555521 37548 net.cpp:150] Setting up relu31
I0715 17:12:47.555569 37548 net.cpp:157] Top shape: 6 96 250 250 (36000000)
I0715 17:12:47.555579 37548 net.cpp:165] Memory required for data: 7848000072
I0715 17:12:47.555593 37548 layer_factory.hpp:76] Creating layer conv32
I0715 17:12:47.555613 37548 net.cpp:106] Creating Layer conv32
I0715 17:12:47.555624 37548 net.cpp:454] conv32 <- conv31
I0715 17:12:47.555639 37548 net.cpp:411] conv32 -> conv32
I0715 17:12:47.564105 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:47.564173 37548 net.cpp:150] Setting up conv32
I0715 17:12:47.564193 37548 net.cpp:157] Top shape: 6 192 250 250 (72000000)
I0715 17:12:47.564201 37548 net.cpp:165] Memory required for data: 8136000072
I0715 17:12:47.564218 37548 layer_factory.hpp:76] Creating layer relu32
I0715 17:12:47.564234 37548 net.cpp:106] Creating Layer relu32
I0715 17:12:47.564245 37548 net.cpp:454] relu32 <- conv32
I0715 17:12:47.564257 37548 net.cpp:397] relu32 -> conv32 (in-place)
I0715 17:12:47.564451 37548 net.cpp:150] Setting up relu32
I0715 17:12:47.564471 37548 net.cpp:157] Top shape: 6 192 250 250 (72000000)
I0715 17:12:47.564481 37548 net.cpp:165] Memory required for data: 8424000072
I0715 17:12:47.564489 37548 layer_factory.hpp:76] Creating layer pool3
I0715 17:12:47.564507 37548 net.cpp:106] Creating Layer pool3
I0715 17:12:47.564515 37548 net.cpp:454] pool3 <- conv32
I0715 17:12:47.564528 37548 net.cpp:411] pool3 -> pool3
I0715 17:12:47.593377 37548 net.cpp:150] Setting up pool3
I0715 17:12:47.593438 37548 net.cpp:157] Top shape: 6 192 125 125 (18000000)
I0715 17:12:47.593449 37548 net.cpp:165] Memory required for data: 8496000072
I0715 17:12:47.593461 37548 layer_factory.hpp:76] Creating layer conv41
I0715 17:12:47.593488 37548 net.cpp:106] Creating Layer conv41
I0715 17:12:47.593500 37548 net.cpp:454] conv41 <- pool3
I0715 17:12:47.593518 37548 net.cpp:411] conv41 -> conv41
I0715 17:12:47.606559 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20736
I0715 17:12:47.606652 37548 net.cpp:150] Setting up conv41
I0715 17:12:47.606680 37548 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0715 17:12:47.606696 37548 net.cpp:165] Memory required for data: 8544000072
I0715 17:12:47.606714 37548 layer_factory.hpp:76] Creating layer relu41
I0715 17:12:47.606731 37548 net.cpp:106] Creating Layer relu41
I0715 17:12:47.606744 37548 net.cpp:454] relu41 <- conv41
I0715 17:12:47.606756 37548 net.cpp:397] relu41 -> conv41 (in-place)
I0715 17:12:47.606971 37548 net.cpp:150] Setting up relu41
I0715 17:12:47.606991 37548 net.cpp:157] Top shape: 6 128 125 125 (12000000)
I0715 17:12:47.606999 37548 net.cpp:165] Memory required for data: 8592000072
I0715 17:12:47.607008 37548 layer_factory.hpp:76] Creating layer conv42
I0715 17:12:47.607026 37548 net.cpp:106] Creating Layer conv42
I0715 17:12:47.607035 37548 net.cpp:454] conv42 <- conv41
I0715 17:12:47.607048 37548 net.cpp:411] conv42 -> conv42
I0715 17:12:47.624080 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:47.624160 37548 net.cpp:150] Setting up conv42
I0715 17:12:47.624181 37548 net.cpp:157] Top shape: 6 256 125 125 (24000000)
I0715 17:12:47.624191 37548 net.cpp:165] Memory required for data: 8688000072
I0715 17:12:47.624209 37548 layer_factory.hpp:76] Creating layer relu42
I0715 17:12:47.624228 37548 net.cpp:106] Creating Layer relu42
I0715 17:12:47.624239 37548 net.cpp:454] relu42 <- conv42
I0715 17:12:47.624250 37548 net.cpp:397] relu42 -> conv42 (in-place)
I0715 17:12:47.624454 37548 net.cpp:150] Setting up relu42
I0715 17:12:47.624474 37548 net.cpp:157] Top shape: 6 256 125 125 (24000000)
I0715 17:12:47.624481 37548 net.cpp:165] Memory required for data: 8784000072
I0715 17:12:47.624490 37548 layer_factory.hpp:76] Creating layer pool4
I0715 17:12:47.624505 37548 net.cpp:106] Creating Layer pool4
I0715 17:12:47.624514 37548 net.cpp:454] pool4 <- conv42
I0715 17:12:47.624526 37548 net.cpp:411] pool4 -> pool4
I0715 17:12:47.625381 37548 net.cpp:150] Setting up pool4
I0715 17:12:47.625408 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.625422 37548 net.cpp:165] Memory required for data: 8808385608
I0715 17:12:47.625432 37548 layer_factory.hpp:76] Creating layer conv51
I0715 17:12:47.625450 37548 net.cpp:106] Creating Layer conv51
I0715 17:12:47.625459 37548 net.cpp:454] conv51 <- pool4
I0715 17:12:47.625473 37548 net.cpp:411] conv51 -> conv51
I0715 17:12:47.639293 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:47.639344 37548 net.cpp:150] Setting up conv51
I0715 17:12:47.639361 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.639367 37548 net.cpp:165] Memory required for data: 8832771144
I0715 17:12:47.639389 37548 layer_factory.hpp:76] Creating layer relu51
I0715 17:12:47.639408 37548 net.cpp:106] Creating Layer relu51
I0715 17:12:47.639415 37548 net.cpp:454] relu51 <- conv51
I0715 17:12:47.639425 37548 net.cpp:397] relu51 -> conv51 (in-place)
I0715 17:12:47.639710 37548 net.cpp:150] Setting up relu51
I0715 17:12:47.639720 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.639724 37548 net.cpp:165] Memory required for data: 8857156680
I0715 17:12:47.639729 37548 layer_factory.hpp:76] Creating layer conv52
I0715 17:12:47.639744 37548 net.cpp:106] Creating Layer conv52
I0715 17:12:47.639749 37548 net.cpp:454] conv52 <- conv51
I0715 17:12:47.639756 37548 net.cpp:411] conv52 -> conv52
I0715 17:12:47.648913 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:47.648974 37548 net.cpp:150] Setting up conv52
I0715 17:12:47.648991 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.649000 37548 net.cpp:165] Memory required for data: 8881542216
I0715 17:12:47.649014 37548 layer_factory.hpp:76] Creating layer relu52
I0715 17:12:47.649030 37548 net.cpp:106] Creating Layer relu52
I0715 17:12:47.649047 37548 net.cpp:454] relu52 <- conv52
I0715 17:12:47.649060 37548 net.cpp:397] relu52 -> conv52 (in-place)
I0715 17:12:47.649509 37548 net.cpp:150] Setting up relu52
I0715 17:12:47.649528 37548 net.cpp:157] Top shape: 6 256 63 63 (6096384)
I0715 17:12:47.649538 37548 net.cpp:165] Memory required for data: 8905927752
I0715 17:12:47.649545 37548 layer_factory.hpp:76] Creating layer conv53
I0715 17:12:47.649561 37548 net.cpp:106] Creating Layer conv53
I0715 17:12:47.649570 37548 net.cpp:454] conv53 <- conv52
I0715 17:12:47.649583 37548 net.cpp:411] conv53 -> conv53
I0715 17:12:47.679566 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0715 17:12:47.679635 37548 net.cpp:150] Setting up conv53
I0715 17:12:47.679651 37548 net.cpp:157] Top shape: 6 256 57 57 (4990464)
I0715 17:12:47.679659 37548 net.cpp:165] Memory required for data: 8925889608
I0715 17:12:47.679673 37548 layer_factory.hpp:76] Creating layer relu53
I0715 17:12:47.679689 37548 net.cpp:106] Creating Layer relu53
I0715 17:12:47.679699 37548 net.cpp:454] relu53 <- conv53
I0715 17:12:47.679716 37548 net.cpp:397] relu53 -> conv53 (in-place)
I0715 17:12:47.680477 37548 net.cpp:150] Setting up relu53
I0715 17:12:47.680502 37548 net.cpp:157] Top shape: 6 256 57 57 (4990464)
I0715 17:12:47.680516 37548 net.cpp:165] Memory required for data: 8945851464
I0715 17:12:47.680524 37548 layer_factory.hpp:76] Creating layer conv_c
I0715 17:12:47.680541 37548 net.cpp:106] Creating Layer conv_c
I0715 17:12:47.680549 37548 net.cpp:454] conv_c <- conv53
I0715 17:12:47.680562 37548 net.cpp:411] conv_c -> conv_c
I0715 17:12:47.682075 37548 net.cpp:150] Setting up conv_c
I0715 17:12:47.682106 37548 net.cpp:157] Top shape: 6 2 57 57 (38988)
I0715 17:12:47.682116 37548 net.cpp:165] Memory required for data: 8946007416
I0715 17:12:47.682128 37548 layer_factory.hpp:76] Creating layer interloss
I0715 17:12:47.682142 37548 net.cpp:106] Creating Layer interloss
I0715 17:12:47.682152 37548 net.cpp:454] interloss <- conv_c
I0715 17:12:47.682163 37548 net.cpp:411] interloss -> interloss
I0715 17:12:47.682422 37548 net.cpp:150] Setting up interloss
I0715 17:12:47.682440 37548 net.cpp:157] Top shape: 6 2 57 57 (38988)
I0715 17:12:47.682452 37548 net.cpp:165] Memory required for data: 8946163368
I0715 17:12:47.682461 37548 layer_factory.hpp:76] Creating layer conv61
I0715 17:12:47.682476 37548 net.cpp:106] Creating Layer conv61
I0715 17:12:47.682485 37548 net.cpp:454] conv61 <- interloss
I0715 17:12:47.682497 37548 net.cpp:411] conv61 -> conv61
I0715 17:12:47.683785 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4210704
I0715 17:12:47.684165 37548 net.cpp:150] Setting up conv61
I0715 17:12:47.684185 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.684198 37548 net.cpp:165] Memory required for data: 8951153832
I0715 17:12:47.684211 37548 layer_factory.hpp:76] Creating layer relu61
I0715 17:12:47.684223 37548 net.cpp:106] Creating Layer relu61
I0715 17:12:47.684231 37548 net.cpp:454] relu61 <- conv61
I0715 17:12:47.684242 37548 net.cpp:397] relu61 -> conv61 (in-place)
I0715 17:12:47.684698 37548 net.cpp:150] Setting up relu61
I0715 17:12:47.684718 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.684726 37548 net.cpp:165] Memory required for data: 8956144296
I0715 17:12:47.684734 37548 layer_factory.hpp:76] Creating layer conv62
I0715 17:12:47.684759 37548 net.cpp:106] Creating Layer conv62
I0715 17:12:47.684767 37548 net.cpp:454] conv62 <- conv61
I0715 17:12:47.684779 37548 net.cpp:411] conv62 -> conv62
I0715 17:12:47.685994 37548 net.cpp:150] Setting up conv62
I0715 17:12:47.686017 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.686024 37548 net.cpp:165] Memory required for data: 8961134760
I0715 17:12:47.686036 37548 layer_factory.hpp:76] Creating layer relu62
I0715 17:12:47.686048 37548 net.cpp:106] Creating Layer relu62
I0715 17:12:47.686056 37548 net.cpp:454] relu62 <- conv62
I0715 17:12:47.686066 37548 net.cpp:397] relu62 -> conv62 (in-place)
I0715 17:12:47.686497 37548 net.cpp:150] Setting up relu62
I0715 17:12:47.686517 37548 net.cpp:157] Top shape: 6 64 57 57 (1247616)
I0715 17:12:47.686524 37548 net.cpp:165] Memory required for data: 8966125224
I0715 17:12:47.686533 37548 layer_factory.hpp:76] Creating layer pool5
I0715 17:12:47.686548 37548 net.cpp:106] Creating Layer pool5
I0715 17:12:47.686556 37548 net.cpp:454] pool5 <- conv62
I0715 17:12:47.686568 37548 net.cpp:411] pool5 -> pool5
I0715 17:12:47.687062 37548 net.cpp:150] Setting up pool5
I0715 17:12:47.687083 37548 net.cpp:157] Top shape: 6 64 29 29 (322944)
I0715 17:12:47.687091 37548 net.cpp:165] Memory required for data: 8967417000
I0715 17:12:47.687100 37548 layer_factory.hpp:76] Creating layer conv71
I0715 17:12:47.687115 37548 net.cpp:106] Creating Layer conv71
I0715 17:12:47.687124 37548 net.cpp:454] conv71 <- pool5
I0715 17:12:47.687150 37548 net.cpp:411] conv71 -> conv71
I0715 17:12:47.689705 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:47.689767 37548 net.cpp:150] Setting up conv71
I0715 17:12:47.689788 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.689797 37548 net.cpp:165] Memory required for data: 8969354664
I0715 17:12:47.689851 37548 layer_factory.hpp:76] Creating layer relu71
I0715 17:12:47.689867 37548 net.cpp:106] Creating Layer relu71
I0715 17:12:47.689875 37548 net.cpp:454] relu71 <- conv71
I0715 17:12:47.689888 37548 net.cpp:397] relu71 -> conv71 (in-place)
I0715 17:12:47.690348 37548 net.cpp:150] Setting up relu71
I0715 17:12:47.690368 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.690376 37548 net.cpp:165] Memory required for data: 8971292328
I0715 17:12:47.690385 37548 layer_factory.hpp:76] Creating layer conv72
I0715 17:12:47.690404 37548 net.cpp:106] Creating Layer conv72
I0715 17:12:47.690412 37548 net.cpp:454] conv72 <- conv71
I0715 17:12:47.690426 37548 net.cpp:411] conv72 -> conv72
I0715 17:12:47.692283 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:47.692329 37548 net.cpp:150] Setting up conv72
I0715 17:12:47.692342 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.692351 37548 net.cpp:165] Memory required for data: 8973229992
I0715 17:12:47.692373 37548 layer_factory.hpp:76] Creating layer relu72
I0715 17:12:47.692389 37548 net.cpp:106] Creating Layer relu72
I0715 17:12:47.692399 37548 net.cpp:454] relu72 <- conv72
I0715 17:12:47.692409 37548 net.cpp:397] relu72 -> conv72 (in-place)
I0715 17:12:47.692862 37548 net.cpp:150] Setting up relu72
I0715 17:12:47.692883 37548 net.cpp:157] Top shape: 6 96 29 29 (484416)
I0715 17:12:47.692890 37548 net.cpp:165] Memory required for data: 8975167656
I0715 17:12:47.692898 37548 layer_factory.hpp:76] Creating layer pool6
I0715 17:12:47.692915 37548 net.cpp:106] Creating Layer pool6
I0715 17:12:47.692924 37548 net.cpp:454] pool6 <- conv72
I0715 17:12:47.692935 37548 net.cpp:411] pool6 -> pool6
I0715 17:12:47.693433 37548 net.cpp:150] Setting up pool6
I0715 17:12:47.693452 37548 net.cpp:157] Top shape: 6 96 15 15 (129600)
I0715 17:12:47.693460 37548 net.cpp:165] Memory required for data: 8975686056
I0715 17:12:47.693470 37548 layer_factory.hpp:76] Creating layer conv81
I0715 17:12:47.693485 37548 net.cpp:106] Creating Layer conv81
I0715 17:12:47.693493 37548 net.cpp:454] conv81 <- pool6
I0715 17:12:47.693505 37548 net.cpp:411] conv81 -> conv81
I0715 17:12:47.695495 37548 net.cpp:150] Setting up conv81
I0715 17:12:47.695516 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.695524 37548 net.cpp:165] Memory required for data: 8976377256
I0715 17:12:47.695547 37548 layer_factory.hpp:76] Creating layer relu81
I0715 17:12:47.695559 37548 net.cpp:106] Creating Layer relu81
I0715 17:12:47.695567 37548 net.cpp:454] relu81 <- conv81
I0715 17:12:47.695586 37548 net.cpp:397] relu81 -> conv81 (in-place)
I0715 17:12:47.695763 37548 net.cpp:150] Setting up relu81
I0715 17:12:47.695780 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.695786 37548 net.cpp:165] Memory required for data: 8977068456
I0715 17:12:47.695794 37548 layer_factory.hpp:76] Creating layer conv82
I0715 17:12:47.695811 37548 net.cpp:106] Creating Layer conv82
I0715 17:12:47.695818 37548 net.cpp:454] conv82 <- conv81
I0715 17:12:47.695830 37548 net.cpp:411] conv82 -> conv82
I0715 17:12:47.698807 37548 net.cpp:150] Setting up conv82
I0715 17:12:47.698832 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.698839 37548 net.cpp:165] Memory required for data: 8977759656
I0715 17:12:47.698851 37548 layer_factory.hpp:76] Creating layer relu82
I0715 17:12:47.698864 37548 net.cpp:106] Creating Layer relu82
I0715 17:12:47.698873 37548 net.cpp:454] relu82 <- conv82
I0715 17:12:47.698882 37548 net.cpp:397] relu82 -> conv82 (in-place)
I0715 17:12:47.699075 37548 net.cpp:150] Setting up relu82
I0715 17:12:47.699091 37548 net.cpp:157] Top shape: 6 128 15 15 (172800)
I0715 17:12:47.699098 37548 net.cpp:165] Memory required for data: 8978450856
I0715 17:12:47.699107 37548 layer_factory.hpp:76] Creating layer pool7
I0715 17:12:47.699118 37548 net.cpp:106] Creating Layer pool7
I0715 17:12:47.699126 37548 net.cpp:454] pool7 <- conv82
I0715 17:12:47.699137 37548 net.cpp:411] pool7 -> pool7
I0715 17:12:47.699970 37548 net.cpp:150] Setting up pool7
I0715 17:12:47.699995 37548 net.cpp:157] Top shape: 6 128 8 8 (49152)
I0715 17:12:47.700004 37548 net.cpp:165] Memory required for data: 8978647464
I0715 17:12:47.700013 37548 layer_factory.hpp:76] Creating layer drop0
I0715 17:12:47.700027 37548 net.cpp:106] Creating Layer drop0
I0715 17:12:47.700037 37548 net.cpp:454] drop0 <- pool7
I0715 17:12:47.700045 37548 net.cpp:397] drop0 -> pool7 (in-place)
I0715 17:12:47.700094 37548 net.cpp:150] Setting up drop0
I0715 17:12:47.700109 37548 net.cpp:157] Top shape: 6 128 8 8 (49152)
I0715 17:12:47.700117 37548 net.cpp:165] Memory required for data: 8978844072
I0715 17:12:47.700129 37548 layer_factory.hpp:76] Creating layer conv91
I0715 17:12:47.700145 37548 net.cpp:106] Creating Layer conv91
I0715 17:12:47.700155 37548 net.cpp:454] conv91 <- pool7
I0715 17:12:47.700168 37548 net.cpp:411] conv91 -> conv91
I0715 17:12:47.701889 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0715 17:12:47.701933 37548 net.cpp:150] Setting up conv91
I0715 17:12:47.701947 37548 net.cpp:157] Top shape: 6 3 1 1 (18)
I0715 17:12:47.701956 37548 net.cpp:165] Memory required for data: 8978844144
I0715 17:12:47.701970 37548 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0715 17:12:47.701990 37548 net.cpp:106] Creating Layer conv91_conv91_0_split
I0715 17:12:47.702000 37548 net.cpp:454] conv91_conv91_0_split <- conv91
I0715 17:12:47.702013 37548 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0715 17:12:47.702025 37548 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0715 17:12:47.702097 37548 net.cpp:150] Setting up conv91_conv91_0_split
I0715 17:12:47.702111 37548 net.cpp:157] Top shape: 6 3 1 1 (18)
I0715 17:12:47.702122 37548 net.cpp:157] Top shape: 6 3 1 1 (18)
I0715 17:12:47.702132 37548 net.cpp:165] Memory required for data: 8978844288
I0715 17:12:47.702142 37548 layer_factory.hpp:76] Creating layer accuracy
I0715 17:12:47.702157 37548 net.cpp:106] Creating Layer accuracy
I0715 17:12:47.702167 37548 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0715 17:12:47.702177 37548 net.cpp:454] accuracy <- label_data_1_split_0
I0715 17:12:47.702188 37548 net.cpp:411] accuracy -> accuracy
I0715 17:12:47.702201 37548 net.cpp:150] Setting up accuracy
I0715 17:12:47.702214 37548 net.cpp:157] Top shape: (1)
I0715 17:12:47.702224 37548 net.cpp:165] Memory required for data: 8978844292
I0715 17:12:47.702232 37548 layer_factory.hpp:76] Creating layer loss
I0715 17:12:47.702245 37548 net.cpp:106] Creating Layer loss
I0715 17:12:47.702255 37548 net.cpp:454] loss <- conv91_conv91_0_split_1
I0715 17:12:47.702265 37548 net.cpp:454] loss <- label_data_1_split_1
I0715 17:12:47.702275 37548 net.cpp:411] loss -> loss
I0715 17:12:47.702288 37548 layer_factory.hpp:76] Creating layer loss
I0715 17:12:47.702590 37548 net.cpp:150] Setting up loss
I0715 17:12:47.702607 37548 net.cpp:157] Top shape: (1)
I0715 17:12:47.702617 37548 net.cpp:160]     with loss weight 1
I0715 17:12:47.702642 37548 net.cpp:165] Memory required for data: 8978844296
I0715 17:12:47.702651 37548 net.cpp:226] loss needs backward computation.
I0715 17:12:47.702661 37548 net.cpp:228] accuracy does not need backward computation.
I0715 17:12:47.702672 37548 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0715 17:12:47.702682 37548 net.cpp:226] conv91 needs backward computation.
I0715 17:12:47.702692 37548 net.cpp:226] drop0 needs backward computation.
I0715 17:12:47.702699 37548 net.cpp:226] pool7 needs backward computation.
I0715 17:12:47.702708 37548 net.cpp:226] relu82 needs backward computation.
I0715 17:12:47.702720 37548 net.cpp:226] conv82 needs backward computation.
I0715 17:12:47.702729 37548 net.cpp:226] relu81 needs backward computation.
I0715 17:12:47.702740 37548 net.cpp:226] conv81 needs backward computation.
I0715 17:12:47.702750 37548 net.cpp:226] pool6 needs backward computation.
I0715 17:12:47.702759 37548 net.cpp:226] relu72 needs backward computation.
I0715 17:12:47.702769 37548 net.cpp:226] conv72 needs backward computation.
I0715 17:12:47.702805 37548 net.cpp:226] relu71 needs backward computation.
I0715 17:12:47.702816 37548 net.cpp:226] conv71 needs backward computation.
I0715 17:12:47.702823 37548 net.cpp:226] pool5 needs backward computation.
I0715 17:12:47.702833 37548 net.cpp:226] relu62 needs backward computation.
I0715 17:12:47.702841 37548 net.cpp:226] conv62 needs backward computation.
I0715 17:12:47.702850 37548 net.cpp:226] relu61 needs backward computation.
I0715 17:12:47.702859 37548 net.cpp:226] conv61 needs backward computation.
I0715 17:12:47.702868 37548 net.cpp:228] interloss does not need backward computation.
I0715 17:12:47.702877 37548 net.cpp:228] conv_c does not need backward computation.
I0715 17:12:47.702891 37548 net.cpp:228] relu53 does not need backward computation.
I0715 17:12:47.702900 37548 net.cpp:228] conv53 does not need backward computation.
I0715 17:12:47.702910 37548 net.cpp:228] relu52 does not need backward computation.
I0715 17:12:47.702919 37548 net.cpp:228] conv52 does not need backward computation.
I0715 17:12:47.702929 37548 net.cpp:228] relu51 does not need backward computation.
I0715 17:12:47.702939 37548 net.cpp:228] conv51 does not need backward computation.
I0715 17:12:47.702947 37548 net.cpp:228] pool4 does not need backward computation.
I0715 17:12:47.702956 37548 net.cpp:228] relu42 does not need backward computation.
I0715 17:12:47.702965 37548 net.cpp:228] conv42 does not need backward computation.
I0715 17:12:47.702975 37548 net.cpp:228] relu41 does not need backward computation.
I0715 17:12:47.702985 37548 net.cpp:228] conv41 does not need backward computation.
I0715 17:12:47.702996 37548 net.cpp:228] pool3 does not need backward computation.
I0715 17:12:47.703004 37548 net.cpp:228] relu32 does not need backward computation.
I0715 17:12:47.703016 37548 net.cpp:228] conv32 does not need backward computation.
I0715 17:12:47.703023 37548 net.cpp:228] relu31 does not need backward computation.
I0715 17:12:47.703033 37548 net.cpp:228] conv31 does not need backward computation.
I0715 17:12:47.703042 37548 net.cpp:228] pool2 does not need backward computation.
I0715 17:12:47.703054 37548 net.cpp:228] relu22 does not need backward computation.
I0715 17:12:47.703063 37548 net.cpp:228] conv22 does not need backward computation.
I0715 17:12:47.703073 37548 net.cpp:228] relu21 does not need backward computation.
I0715 17:12:47.703080 37548 net.cpp:228] conv21 does not need backward computation.
I0715 17:12:47.703090 37548 net.cpp:228] pool1 does not need backward computation.
I0715 17:12:47.703104 37548 net.cpp:228] relu12 does not need backward computation.
I0715 17:12:47.703114 37548 net.cpp:228] conv12 does not need backward computation.
I0715 17:12:47.703122 37548 net.cpp:228] relu11 does not need backward computation.
I0715 17:12:47.703132 37548 net.cpp:228] conv11 does not need backward computation.
I0715 17:12:47.703142 37548 net.cpp:228] label_data_1_split does not need backward computation.
I0715 17:12:47.703152 37548 net.cpp:228] data does not need backward computation.
I0715 17:12:47.703161 37548 net.cpp:270] This network produces output accuracy
I0715 17:12:47.703171 37548 net.cpp:270] This network produces output loss
I0715 17:12:47.703203 37548 net.cpp:283] Network initialization done.
I0715 17:12:47.703413 37548 solver.cpp:59] Solver scaffolding done.
I0715 17:12:47.705018 37548 caffe.cpp:128] Finetuning from cnn10_iter_23559.caffemodel
I0715 17:12:47.916045 37548 parallel.cpp:394] GPUs pairs 0:1, 0:2
I0715 17:12:48.127578 37548 net.cpp:99] Sharing layer data from root net
I0715 17:12:48.128991 37548 net.cpp:143] Created top blob 0 (shape: 6 3 1000 1000 (18000000)) for shared layer data
I0715 17:12:48.129061 37548 net.cpp:143] Created top blob 1 (shape: 6 (6)) for shared layer data
I0715 17:12:48.267271 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:48.271494 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:48.273988 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:48.277503 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:48.283337 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20736
I0715 17:12:48.288058 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:48.296437 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:48.303408 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:48.411731 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0715 17:12:48.415207 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4210704
I0715 17:12:48.420333 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:48.422423 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:48.430074 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0715 17:12:48.745668 37548 net.cpp:99] Sharing layer data from root net
I0715 17:12:48.746943 37548 net.cpp:143] Created top blob 0 (shape: 6 3 1000 1000 (18000000)) for shared layer data
I0715 17:12:48.747030 37548 net.cpp:143] Created top blob 1 (shape: 6 (6)) for shared layer data
I0715 17:12:48.899281 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:48.905990 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:48.909543 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:48.914927 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:48.924733 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20736
I0715 17:12:48.969424 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0715 17:12:48.978952 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:48.986340 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0715 17:12:49.021117 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 150528
I0715 17:12:49.025310 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4210704
I0715 17:12:49.033689 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0715 17:12:49.037180 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0715 17:12:49.070149 37548 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0715 17:12:49.071404 37548 parallel.cpp:237] GPU 2 does not have p2p access to GPU 0
I0715 17:12:49.072036 37548 parallel.cpp:422] Starting Optimization
I0715 17:12:49.072157 37548 solver.cpp:287] Solving Result Layer 3 Stack
I0715 17:12:49.072170 37548 solver.cpp:288] Learning Rate Policy: step
I0715 17:12:55.000012 37548 solver.cpp:236] Iteration 0, loss = 1.1045
I0715 17:12:55.000136 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 17:12:55.000212 37548 solver.cpp:252]     Train net output #1: loss = 1.1045 (* 1 = 1.1045 loss)
I0715 17:13:01.980069 37548 sgd_solver.cpp:106] Iteration 0, lr = 0.015
I0715 17:18:32.922385 37548 solver.cpp:236] Iteration 50, loss = 1.02757
I0715 17:18:32.922565 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0715 17:18:32.922595 37548 solver.cpp:252]     Train net output #1: loss = 0.783446 (* 1 = 0.783446 loss)
I0715 17:18:36.698885 37548 sgd_solver.cpp:106] Iteration 50, lr = 0.015
I0715 17:24:07.400463 37548 solver.cpp:236] Iteration 100, loss = 1.06969
I0715 17:24:07.400696 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 17:24:07.400727 37548 solver.cpp:252]     Train net output #1: loss = 1.11505 (* 1 = 1.11505 loss)
I0715 17:24:11.171465 37548 sgd_solver.cpp:106] Iteration 100, lr = 0.015
I0715 17:29:42.224298 37548 solver.cpp:236] Iteration 150, loss = 1.05665
I0715 17:29:42.224485 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 17:29:42.224519 37548 solver.cpp:252]     Train net output #1: loss = 0.923236 (* 1 = 0.923236 loss)
I0715 17:29:46.079874 37548 sgd_solver.cpp:106] Iteration 150, lr = 0.015
I0715 17:35:17.401358 37548 solver.cpp:236] Iteration 200, loss = 1.09054
I0715 17:35:17.401625 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 17:35:17.401653 37548 solver.cpp:252]     Train net output #1: loss = 1.10795 (* 1 = 1.10795 loss)
I0715 17:35:21.262938 37548 sgd_solver.cpp:106] Iteration 200, lr = 0.015
I0715 17:40:51.887583 37548 solver.cpp:236] Iteration 250, loss = 1.04053
I0715 17:40:51.910250 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 17:40:51.910276 37548 solver.cpp:252]     Train net output #1: loss = 0.970545 (* 1 = 0.970545 loss)
I0715 17:40:55.532671 37548 sgd_solver.cpp:106] Iteration 250, lr = 0.015
I0715 17:46:26.107657 37548 solver.cpp:236] Iteration 300, loss = 1.02691
I0715 17:46:26.107838 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 17:46:26.107861 37548 solver.cpp:252]     Train net output #1: loss = 1.01518 (* 1 = 1.01518 loss)
I0715 17:46:29.825278 37548 sgd_solver.cpp:106] Iteration 300, lr = 0.015
I0715 17:52:01.027979 37548 solver.cpp:236] Iteration 350, loss = 1.07847
I0715 17:52:01.028272 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0715 17:52:01.028308 37548 solver.cpp:252]     Train net output #1: loss = 0.910176 (* 1 = 0.910176 loss)
I0715 17:52:04.937929 37548 sgd_solver.cpp:106] Iteration 350, lr = 0.015
I0715 17:57:35.955730 37548 solver.cpp:236] Iteration 400, loss = 1.05511
I0715 17:57:35.955979 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 17:57:35.956028 37548 solver.cpp:252]     Train net output #1: loss = 1.03214 (* 1 = 1.03214 loss)
I0715 17:57:39.971781 37548 sgd_solver.cpp:106] Iteration 400, lr = 0.015
I0715 18:03:10.801723 37548 solver.cpp:236] Iteration 450, loss = 1.04182
I0715 18:03:10.801899 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 18:03:10.801933 37548 solver.cpp:252]     Train net output #1: loss = 0.958201 (* 1 = 0.958201 loss)
I0715 18:03:14.489436 37548 sgd_solver.cpp:106] Iteration 450, lr = 0.015
I0715 18:08:45.572422 37548 solver.cpp:236] Iteration 500, loss = 1.03985
I0715 18:08:45.572551 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 18:08:45.572574 37548 solver.cpp:252]     Train net output #1: loss = 1.13136 (* 1 = 1.13136 loss)
I0715 18:08:49.415249 37548 sgd_solver.cpp:106] Iteration 500, lr = 0.015
I0715 18:14:20.509183 37548 solver.cpp:236] Iteration 550, loss = 1.08771
I0715 18:14:20.509521 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 18:14:20.509587 37548 solver.cpp:252]     Train net output #1: loss = 1.0695 (* 1 = 1.0695 loss)
I0715 18:14:24.327217 37548 sgd_solver.cpp:106] Iteration 550, lr = 0.015
I0715 18:19:55.078737 37548 solver.cpp:236] Iteration 600, loss = 1.05443
I0715 18:19:55.078878 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 18:19:55.078901 37548 solver.cpp:252]     Train net output #1: loss = 1.12681 (* 1 = 1.12681 loss)
I0715 18:19:58.797667 37548 sgd_solver.cpp:106] Iteration 600, lr = 0.015
I0715 18:25:29.707859 37548 solver.cpp:236] Iteration 650, loss = 1.08219
I0715 18:25:29.708035 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 18:25:29.708067 37548 solver.cpp:252]     Train net output #1: loss = 1.32018 (* 1 = 1.32018 loss)
I0715 18:25:33.489509 37548 sgd_solver.cpp:106] Iteration 650, lr = 0.015
I0715 18:31:04.287328 37548 solver.cpp:236] Iteration 700, loss = 1.0602
I0715 18:31:04.287540 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 18:31:04.287570 37548 solver.cpp:252]     Train net output #1: loss = 0.954036 (* 1 = 0.954036 loss)
I0715 18:31:08.048070 37548 sgd_solver.cpp:106] Iteration 700, lr = 0.015
I0715 18:36:38.802343 37548 solver.cpp:236] Iteration 750, loss = 1.07407
I0715 18:36:38.802564 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0715 18:36:38.802603 37548 solver.cpp:252]     Train net output #1: loss = 0.856915 (* 1 = 0.856915 loss)
I0715 18:36:42.665621 37548 sgd_solver.cpp:106] Iteration 750, lr = 0.015
I0715 18:42:12.917850 37548 solver.cpp:236] Iteration 800, loss = 1.05683
I0715 18:42:12.918156 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 18:42:12.918191 37548 solver.cpp:252]     Train net output #1: loss = 0.960694 (* 1 = 0.960694 loss)
I0715 18:42:16.578064 37548 sgd_solver.cpp:106] Iteration 800, lr = 0.015
I0715 18:47:47.162770 37548 solver.cpp:236] Iteration 850, loss = 1.07001
I0715 18:47:47.162984 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0715 18:47:47.163018 37548 solver.cpp:252]     Train net output #1: loss = 0.969714 (* 1 = 0.969714 loss)
I0715 18:47:50.978693 37548 sgd_solver.cpp:106] Iteration 850, lr = 0.015
I0715 18:53:21.242736 37548 solver.cpp:236] Iteration 900, loss = 1.09727
I0715 18:53:21.243032 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0715 18:53:21.243083 37548 solver.cpp:252]     Train net output #1: loss = 1.21307 (* 1 = 1.21307 loss)
I0715 18:53:24.999968 37548 sgd_solver.cpp:106] Iteration 900, lr = 0.015
I0715 18:58:55.473673 37548 solver.cpp:236] Iteration 950, loss = 1.06118
I0715 18:58:55.473908 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0715 18:58:55.473947 37548 solver.cpp:252]     Train net output #1: loss = 0.780526 (* 1 = 0.780526 loss)
I0715 18:58:59.229137 37548 sgd_solver.cpp:106] Iteration 950, lr = 0.015
I0715 19:04:29.729130 37548 solver.cpp:236] Iteration 1000, loss = 1.09077
I0715 19:04:29.729298 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 19:04:29.729327 37548 solver.cpp:252]     Train net output #1: loss = 0.882671 (* 1 = 0.882671 loss)
I0715 19:04:33.431913 37548 sgd_solver.cpp:106] Iteration 1000, lr = 0.015
I0715 19:10:03.913341 37548 solver.cpp:236] Iteration 1050, loss = 1.05044
I0715 19:10:03.913542 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 19:10:03.913576 37548 solver.cpp:252]     Train net output #1: loss = 1.03537 (* 1 = 1.03537 loss)
I0715 19:10:07.693789 37548 sgd_solver.cpp:106] Iteration 1050, lr = 0.015
I0715 19:15:38.186920 37548 solver.cpp:236] Iteration 1100, loss = 1.07759
I0715 19:15:38.187105 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 19:15:38.187126 37548 solver.cpp:252]     Train net output #1: loss = 1.02115 (* 1 = 1.02115 loss)
I0715 19:15:41.947664 37548 sgd_solver.cpp:106] Iteration 1100, lr = 0.015
I0715 19:21:12.672318 37548 solver.cpp:236] Iteration 1150, loss = 1.06676
I0715 19:21:12.672469 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 19:21:12.672502 37548 solver.cpp:252]     Train net output #1: loss = 1.1989 (* 1 = 1.1989 loss)
I0715 19:21:16.492360 37548 sgd_solver.cpp:106] Iteration 1150, lr = 0.015
I0715 19:26:47.209628 37548 solver.cpp:236] Iteration 1200, loss = 1.06395
I0715 19:26:47.209862 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 19:26:47.209903 37548 solver.cpp:252]     Train net output #1: loss = 1.12616 (* 1 = 1.12616 loss)
I0715 19:26:50.966511 37548 sgd_solver.cpp:106] Iteration 1200, lr = 0.015
I0715 19:32:21.307894 37548 solver.cpp:236] Iteration 1250, loss = 1.09007
I0715 19:32:21.308012 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 19:32:21.308032 37548 solver.cpp:252]     Train net output #1: loss = 0.942946 (* 1 = 0.942946 loss)
I0715 19:32:25.215088 37548 sgd_solver.cpp:106] Iteration 1250, lr = 0.015
I0715 19:37:55.848590 37548 solver.cpp:236] Iteration 1300, loss = 1.05049
I0715 19:37:55.848778 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 19:37:55.848804 37548 solver.cpp:252]     Train net output #1: loss = 0.995463 (* 1 = 0.995463 loss)
I0715 19:37:59.625963 37548 sgd_solver.cpp:106] Iteration 1300, lr = 0.015
I0715 19:43:30.235154 37548 solver.cpp:236] Iteration 1350, loss = 1.07957
I0715 19:43:30.235436 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 19:43:30.235476 37548 solver.cpp:252]     Train net output #1: loss = 1.07361 (* 1 = 1.07361 loss)
I0715 19:43:33.687127 37548 sgd_solver.cpp:106] Iteration 1350, lr = 0.015
I0715 19:49:04.174897 37548 solver.cpp:236] Iteration 1400, loss = 1.04859
I0715 19:49:04.175215 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0715 19:49:04.175243 37548 solver.cpp:252]     Train net output #1: loss = 0.863554 (* 1 = 0.863554 loss)
I0715 19:49:07.925606 37548 sgd_solver.cpp:106] Iteration 1400, lr = 0.015
I0715 19:54:38.410946 37548 solver.cpp:236] Iteration 1450, loss = 1.08775
I0715 19:54:38.411110 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 19:54:38.411144 37548 solver.cpp:252]     Train net output #1: loss = 1.34826 (* 1 = 1.34826 loss)
I0715 19:54:42.203227 37548 sgd_solver.cpp:106] Iteration 1450, lr = 0.015
I0715 20:00:08.309180 37548 solver.cpp:340] Iteration 1500, Testing net (#0)
I0715 20:23:22.349057 37548 solver.cpp:408]     Test net output #0: accuracy = 0.457
I0715 20:23:22.349472 37548 solver.cpp:408]     Test net output #1: loss = 1.07031 (* 1 = 1.07031 loss)
I0715 20:23:25.222018 37548 solver.cpp:236] Iteration 1500, loss = 1.08045
I0715 20:23:25.222084 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0715 20:23:25.222141 37548 solver.cpp:252]     Train net output #1: loss = 1.34452 (* 1 = 1.34452 loss)
I0715 20:23:25.222239 37548 sgd_solver.cpp:106] Iteration 1500, lr = 0.015
I0715 20:23:25.337085 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0715 20:26:59.760267 37548 solver.cpp:236] Iteration 1550, loss = 1.06762
I0715 20:26:59.760540 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 20:26:59.760584 37548 solver.cpp:252]     Train net output #1: loss = 1.08164 (* 1 = 1.08164 loss)
I0715 20:27:00.709836 37548 sgd_solver.cpp:106] Iteration 1550, lr = 0.015
I0715 20:30:34.585508 37548 solver.cpp:236] Iteration 1600, loss = 1.11233
I0715 20:30:34.585829 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0715 20:30:34.585909 37548 solver.cpp:252]     Train net output #1: loss = 1.16791 (* 1 = 1.16791 loss)
I0715 20:30:35.538705 37548 sgd_solver.cpp:106] Iteration 1600, lr = 0.015
I0715 20:34:06.714743 37548 solver.cpp:236] Iteration 1650, loss = 1.05504
I0715 20:34:06.715049 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 20:34:06.715090 37548 solver.cpp:252]     Train net output #1: loss = 1.31672 (* 1 = 1.31672 loss)
I0715 20:34:07.594398 37548 sgd_solver.cpp:106] Iteration 1650, lr = 0.015
I0715 20:37:35.367686 37548 solver.cpp:236] Iteration 1700, loss = 1.07264
I0715 20:37:35.368044 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 20:37:35.368100 37548 solver.cpp:252]     Train net output #1: loss = 1.41052 (* 1 = 1.41052 loss)
I0715 20:37:36.259057 37548 sgd_solver.cpp:106] Iteration 1700, lr = 0.015
I0715 20:41:07.621093 37548 solver.cpp:236] Iteration 1750, loss = 1.07646
I0715 20:41:07.621382 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 20:41:07.621413 37548 solver.cpp:252]     Train net output #1: loss = 1.05685 (* 1 = 1.05685 loss)
I0715 20:41:08.499119 37548 sgd_solver.cpp:106] Iteration 1750, lr = 0.015
I0715 20:44:38.521841 37548 solver.cpp:236] Iteration 1800, loss = 1.06778
I0715 20:44:38.522054 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 20:44:38.522089 37548 solver.cpp:252]     Train net output #1: loss = 1.03783 (* 1 = 1.03783 loss)
I0715 20:44:39.404259 37548 sgd_solver.cpp:106] Iteration 1800, lr = 0.015
I0715 20:48:09.528619 37548 solver.cpp:236] Iteration 1850, loss = 1.074
I0715 20:48:09.528843 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 20:48:09.528883 37548 solver.cpp:252]     Train net output #1: loss = 1.08944 (* 1 = 1.08944 loss)
I0715 20:48:10.409803 37548 sgd_solver.cpp:106] Iteration 1850, lr = 0.015
I0715 20:51:42.494498 37548 solver.cpp:236] Iteration 1900, loss = 1.05265
I0715 20:51:42.494964 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 20:51:42.495086 37548 solver.cpp:252]     Train net output #1: loss = 1.02478 (* 1 = 1.02478 loss)
I0715 20:51:43.384547 37548 sgd_solver.cpp:106] Iteration 1900, lr = 0.015
I0715 20:55:14.744849 37548 solver.cpp:236] Iteration 1950, loss = 1.08582
I0715 20:55:14.745184 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 20:55:14.745213 37548 solver.cpp:252]     Train net output #1: loss = 1.02621 (* 1 = 1.02621 loss)
I0715 20:55:15.686321 37548 sgd_solver.cpp:106] Iteration 1950, lr = 0.015
I0715 20:57:50.322545 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0715 20:58:42.924070 37548 solver.cpp:236] Iteration 2000, loss = 1.09278
I0715 20:58:42.924335 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 20:58:42.924382 37548 solver.cpp:252]     Train net output #1: loss = 1.13122 (* 1 = 1.13122 loss)
I0715 20:58:43.804792 37548 sgd_solver.cpp:106] Iteration 2000, lr = 0.015
I0715 21:02:15.178792 37548 solver.cpp:236] Iteration 2050, loss = 1.08829
I0715 21:02:15.179193 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:02:15.179271 37548 solver.cpp:252]     Train net output #1: loss = 1.06267 (* 1 = 1.06267 loss)
I0715 21:02:16.050571 37548 sgd_solver.cpp:106] Iteration 2050, lr = 0.015
I0715 21:05:52.622088 37548 solver.cpp:236] Iteration 2100, loss = 1.07255
I0715 21:05:52.622356 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 21:05:52.622380 37548 solver.cpp:252]     Train net output #1: loss = 0.983729 (* 1 = 0.983729 loss)
I0715 21:05:53.505256 37548 sgd_solver.cpp:106] Iteration 2100, lr = 0.015
I0715 21:09:28.278805 37548 solver.cpp:236] Iteration 2150, loss = 1.05094
I0715 21:09:28.279157 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 21:09:28.279196 37548 solver.cpp:252]     Train net output #1: loss = 1.14471 (* 1 = 1.14471 loss)
I0715 21:09:29.156404 37548 sgd_solver.cpp:106] Iteration 2150, lr = 0.015
I0715 21:13:08.201742 37548 solver.cpp:236] Iteration 2200, loss = 1.07078
I0715 21:13:08.202047 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:13:08.202080 37548 solver.cpp:252]     Train net output #1: loss = 1.00437 (* 1 = 1.00437 loss)
I0715 21:13:09.088351 37548 sgd_solver.cpp:106] Iteration 2200, lr = 0.015
I0715 21:16:43.457643 37548 solver.cpp:236] Iteration 2250, loss = 1.08546
I0715 21:16:43.458000 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 21:16:43.458063 37548 solver.cpp:252]     Train net output #1: loss = 1.12689 (* 1 = 1.12689 loss)
I0715 21:16:44.347858 37548 sgd_solver.cpp:106] Iteration 2250, lr = 0.015
I0715 21:20:27.442143 37548 solver.cpp:236] Iteration 2300, loss = 1.05906
I0715 21:20:27.442549 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 21:20:27.442589 37548 solver.cpp:252]     Train net output #1: loss = 1.02314 (* 1 = 1.02314 loss)
I0715 21:20:28.395437 37548 sgd_solver.cpp:106] Iteration 2300, lr = 0.015
I0715 21:24:08.433600 37548 solver.cpp:236] Iteration 2350, loss = 1.05079
I0715 21:24:08.433835 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 21:24:08.433862 37548 solver.cpp:252]     Train net output #1: loss = 1.13845 (* 1 = 1.13845 loss)
I0715 21:24:09.294867 37548 sgd_solver.cpp:106] Iteration 2350, lr = 0.015
I0715 21:27:48.172937 37548 solver.cpp:236] Iteration 2400, loss = 1.05696
I0715 21:27:48.173195 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:27:48.173231 37548 solver.cpp:252]     Train net output #1: loss = 1.10758 (* 1 = 1.10758 loss)
I0715 21:27:49.123584 37548 sgd_solver.cpp:106] Iteration 2400, lr = 0.015
I0715 21:31:11.106277 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0715 21:31:22.668995 37548 solver.cpp:236] Iteration 2450, loss = 1.07866
I0715 21:31:22.669106 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 21:31:22.669144 37548 solver.cpp:252]     Train net output #1: loss = 0.962213 (* 1 = 0.962213 loss)
I0715 21:31:23.545553 37548 sgd_solver.cpp:106] Iteration 2450, lr = 0.015
I0715 21:35:01.424005 37548 solver.cpp:236] Iteration 2500, loss = 1.05348
I0715 21:35:01.424556 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:35:01.424614 37548 solver.cpp:252]     Train net output #1: loss = 1.03496 (* 1 = 1.03496 loss)
I0715 21:35:02.364118 37548 sgd_solver.cpp:106] Iteration 2500, lr = 0.015
I0715 21:38:41.961385 37548 solver.cpp:236] Iteration 2550, loss = 1.06265
I0715 21:38:41.961597 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:38:41.961630 37548 solver.cpp:252]     Train net output #1: loss = 1.06045 (* 1 = 1.06045 loss)
I0715 21:38:42.837136 37548 sgd_solver.cpp:106] Iteration 2550, lr = 0.015
I0715 21:42:20.556416 37548 solver.cpp:236] Iteration 2600, loss = 1.02877
I0715 21:42:20.556892 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:42:20.556958 37548 solver.cpp:252]     Train net output #1: loss = 1.0786 (* 1 = 1.0786 loss)
I0715 21:42:21.508661 37548 sgd_solver.cpp:106] Iteration 2600, lr = 0.015
I0715 21:45:59.328999 37548 solver.cpp:236] Iteration 2650, loss = 1.05954
I0715 21:45:59.329391 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 21:45:59.329443 37548 solver.cpp:252]     Train net output #1: loss = 0.916203 (* 1 = 0.916203 loss)
I0715 21:46:00.345218 37548 sgd_solver.cpp:106] Iteration 2650, lr = 0.015
I0715 21:49:40.073930 37548 solver.cpp:236] Iteration 2700, loss = 1.03693
I0715 21:49:40.074213 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 21:49:40.074252 37548 solver.cpp:252]     Train net output #1: loss = 1.14469 (* 1 = 1.14469 loss)
I0715 21:49:41.018445 37548 sgd_solver.cpp:106] Iteration 2700, lr = 0.015
I0715 21:53:18.163929 37548 solver.cpp:236] Iteration 2750, loss = 1.07868
I0715 21:53:18.164343 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 21:53:18.164413 37548 solver.cpp:252]     Train net output #1: loss = 1.16976 (* 1 = 1.16976 loss)
I0715 21:53:19.120628 37548 sgd_solver.cpp:106] Iteration 2750, lr = 0.015
I0715 21:57:01.775786 37548 solver.cpp:236] Iteration 2800, loss = 1.06551
I0715 21:57:01.776129 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 21:57:01.776175 37548 solver.cpp:252]     Train net output #1: loss = 1.05278 (* 1 = 1.05278 loss)
I0715 21:57:02.660281 37548 sgd_solver.cpp:106] Iteration 2800, lr = 0.015
I0715 22:00:37.989421 37548 solver.cpp:236] Iteration 2850, loss = 1.07697
I0715 22:00:37.989680 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 22:00:37.989717 37548 solver.cpp:252]     Train net output #1: loss = 1.1155 (* 1 = 1.1155 loss)
I0715 22:00:38.945574 37548 sgd_solver.cpp:106] Iteration 2850, lr = 0.015
I0715 22:04:19.580454 37548 solver.cpp:236] Iteration 2900, loss = 1.07511
I0715 22:04:19.580739 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 22:04:19.580780 37548 solver.cpp:252]     Train net output #1: loss = 0.922317 (* 1 = 0.922317 loss)
I0715 22:04:20.531044 37548 sgd_solver.cpp:106] Iteration 2900, lr = 0.015
I0715 22:04:25.442107 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0715 22:08:02.950091 37548 solver.cpp:236] Iteration 2950, loss = 1.05444
I0715 22:08:02.950404 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0715 22:08:02.950439 37548 solver.cpp:252]     Train net output #1: loss = 1.22242 (* 1 = 1.22242 loss)
I0715 22:08:03.837244 37548 sgd_solver.cpp:106] Iteration 2950, lr = 0.015
I0715 22:11:38.911152 37548 solver.cpp:340] Iteration 3000, Testing net (#0)
I0715 22:34:52.731633 37548 solver.cpp:408]     Test net output #0: accuracy = 0.469
I0715 22:34:52.731840 37548 solver.cpp:408]     Test net output #1: loss = 1.06714 (* 1 = 1.06714 loss)
I0715 22:34:55.608587 37548 solver.cpp:236] Iteration 3000, loss = 1.06141
I0715 22:34:55.608623 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 22:34:55.608639 37548 solver.cpp:252]     Train net output #1: loss = 1.10771 (* 1 = 1.10771 loss)
I0715 22:34:55.608672 37548 sgd_solver.cpp:106] Iteration 3000, lr = 0.015
I0715 22:38:43.874253 37548 solver.cpp:236] Iteration 3050, loss = 1.05338
I0715 22:38:43.874809 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 22:38:43.874886 37548 solver.cpp:252]     Train net output #1: loss = 1.1341 (* 1 = 1.1341 loss)
I0715 22:38:44.826117 37548 sgd_solver.cpp:106] Iteration 3050, lr = 0.015
I0715 22:42:27.769235 37548 solver.cpp:236] Iteration 3100, loss = 1.08081
I0715 22:42:27.769533 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 22:42:27.769567 37548 solver.cpp:252]     Train net output #1: loss = 0.973298 (* 1 = 0.973298 loss)
I0715 22:42:28.729856 37548 sgd_solver.cpp:106] Iteration 3100, lr = 0.015
I0715 22:46:10.379308 37548 solver.cpp:236] Iteration 3150, loss = 1.06247
I0715 22:46:10.379781 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 22:46:10.379850 37548 solver.cpp:252]     Train net output #1: loss = 1.1679 (* 1 = 1.1679 loss)
I0715 22:46:11.253039 37548 sgd_solver.cpp:106] Iteration 3150, lr = 0.015
I0715 22:49:56.875579 37548 solver.cpp:236] Iteration 3200, loss = 1.06956
I0715 22:49:56.875962 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0715 22:49:56.876027 37548 solver.cpp:252]     Train net output #1: loss = 1.27592 (* 1 = 1.27592 loss)
I0715 22:49:57.759194 37548 sgd_solver.cpp:106] Iteration 3200, lr = 0.015
I0715 22:53:42.873877 37548 solver.cpp:236] Iteration 3250, loss = 1.02221
I0715 22:53:42.874184 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 22:53:42.874213 37548 solver.cpp:252]     Train net output #1: loss = 0.922498 (* 1 = 0.922498 loss)
I0715 22:53:43.736006 37548 sgd_solver.cpp:106] Iteration 3250, lr = 0.015
I0715 22:57:24.559655 37548 solver.cpp:236] Iteration 3300, loss = 1.05736
I0715 22:57:24.559943 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 22:57:24.559968 37548 solver.cpp:252]     Train net output #1: loss = 1.0281 (* 1 = 1.0281 loss)
I0715 22:57:25.490387 37548 sgd_solver.cpp:106] Iteration 3300, lr = 0.015
I0715 23:00:44.038727 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0715 23:01:11.468513 37548 solver.cpp:236] Iteration 3350, loss = 1.05993
I0715 23:01:11.468587 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 23:01:11.468622 37548 solver.cpp:252]     Train net output #1: loss = 1.02429 (* 1 = 1.02429 loss)
I0715 23:01:12.418936 37548 sgd_solver.cpp:106] Iteration 3350, lr = 0.015
I0715 23:04:52.412132 37548 solver.cpp:236] Iteration 3400, loss = 1.06729
I0715 23:04:52.412374 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 23:04:52.412405 37548 solver.cpp:252]     Train net output #1: loss = 1.34138 (* 1 = 1.34138 loss)
I0715 23:04:53.278810 37548 sgd_solver.cpp:106] Iteration 3400, lr = 0.015
I0715 23:08:37.734241 37548 solver.cpp:236] Iteration 3450, loss = 1.08631
I0715 23:08:37.734524 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 23:08:37.734570 37548 solver.cpp:252]     Train net output #1: loss = 0.925264 (* 1 = 0.925264 loss)
I0715 23:08:38.605710 37548 sgd_solver.cpp:106] Iteration 3450, lr = 0.015
I0715 23:12:21.977331 37548 solver.cpp:236] Iteration 3500, loss = 1.09091
I0715 23:12:21.977655 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 23:12:21.977686 37548 solver.cpp:252]     Train net output #1: loss = 1.32458 (* 1 = 1.32458 loss)
I0715 23:12:22.931314 37548 sgd_solver.cpp:106] Iteration 3500, lr = 0.015
I0715 23:16:07.305218 37548 solver.cpp:236] Iteration 3550, loss = 1.09131
I0715 23:16:07.305513 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 23:16:07.305544 37548 solver.cpp:252]     Train net output #1: loss = 1.18983 (* 1 = 1.18983 loss)
I0715 23:16:08.179030 37548 sgd_solver.cpp:106] Iteration 3550, lr = 0.015
I0715 23:19:49.145866 37548 solver.cpp:236] Iteration 3600, loss = 1.06961
I0715 23:19:49.146095 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 23:19:49.146116 37548 solver.cpp:252]     Train net output #1: loss = 1.1257 (* 1 = 1.1257 loss)
I0715 23:19:50.008339 37548 sgd_solver.cpp:106] Iteration 3600, lr = 0.015
I0715 23:23:30.695791 37548 solver.cpp:236] Iteration 3650, loss = 1.06547
I0715 23:23:30.696161 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0715 23:23:30.696197 37548 solver.cpp:252]     Train net output #1: loss = 1.29382 (* 1 = 1.29382 loss)
I0715 23:23:31.583962 37548 sgd_solver.cpp:106] Iteration 3650, lr = 0.015
I0715 23:27:17.507316 37548 solver.cpp:236] Iteration 3700, loss = 1.05427
I0715 23:27:17.507735 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 23:27:17.507789 37548 solver.cpp:252]     Train net output #1: loss = 0.966562 (* 1 = 0.966562 loss)
I0715 23:27:18.386260 37548 sgd_solver.cpp:106] Iteration 3700, lr = 0.015
I0715 23:31:01.437439 37548 solver.cpp:236] Iteration 3750, loss = 1.06888
I0715 23:31:01.437744 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0715 23:31:01.437778 37548 solver.cpp:252]     Train net output #1: loss = 1.21652 (* 1 = 1.21652 loss)
I0715 23:31:02.320858 37548 sgd_solver.cpp:106] Iteration 3750, lr = 0.015
I0715 23:33:39.716891 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0715 23:34:43.069325 37548 solver.cpp:236] Iteration 3800, loss = 1.06836
I0715 23:34:43.069593 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 23:34:43.069631 37548 solver.cpp:252]     Train net output #1: loss = 1.09049 (* 1 = 1.09049 loss)
I0715 23:34:43.954751 37548 sgd_solver.cpp:106] Iteration 3800, lr = 0.015
I0715 23:38:27.548063 37548 solver.cpp:236] Iteration 3850, loss = 1.05029
I0715 23:38:27.548298 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0715 23:38:27.548341 37548 solver.cpp:252]     Train net output #1: loss = 0.680125 (* 1 = 0.680125 loss)
I0715 23:38:28.516118 37548 sgd_solver.cpp:106] Iteration 3850, lr = 0.015
I0715 23:42:07.418762 37548 solver.cpp:236] Iteration 3900, loss = 1.04697
I0715 23:42:07.419131 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0715 23:42:07.419167 37548 solver.cpp:252]     Train net output #1: loss = 0.991224 (* 1 = 0.991224 loss)
I0715 23:42:08.352298 37548 sgd_solver.cpp:106] Iteration 3900, lr = 0.015
I0715 23:45:48.631515 37548 solver.cpp:236] Iteration 3950, loss = 1.06647
I0715 23:45:48.631750 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 23:45:48.631788 37548 solver.cpp:252]     Train net output #1: loss = 1.07617 (* 1 = 1.07617 loss)
I0715 23:45:49.582418 37548 sgd_solver.cpp:106] Iteration 3950, lr = 0.015
I0715 23:49:33.434442 37548 solver.cpp:236] Iteration 4000, loss = 1.05071
I0715 23:49:33.434731 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 23:49:33.434794 37548 solver.cpp:252]     Train net output #1: loss = 1.14041 (* 1 = 1.14041 loss)
I0715 23:49:34.316278 37548 sgd_solver.cpp:106] Iteration 4000, lr = 0.015
I0715 23:53:15.154822 37548 solver.cpp:236] Iteration 4050, loss = 1.06017
I0715 23:53:15.155077 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0715 23:53:15.155117 37548 solver.cpp:252]     Train net output #1: loss = 1.02651 (* 1 = 1.02651 loss)
I0715 23:53:16.105099 37548 sgd_solver.cpp:106] Iteration 4050, lr = 0.015
I0715 23:57:00.011142 37548 solver.cpp:236] Iteration 4100, loss = 1.06861
I0715 23:57:00.011510 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0715 23:57:00.011565 37548 solver.cpp:252]     Train net output #1: loss = 1.14762 (* 1 = 1.14762 loss)
I0715 23:57:00.955958 37548 sgd_solver.cpp:106] Iteration 4100, lr = 0.015
I0716 00:00:44.842978 37548 solver.cpp:236] Iteration 4150, loss = 1.05734
I0716 00:00:44.843271 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 00:00:44.843324 37548 solver.cpp:252]     Train net output #1: loss = 1.05997 (* 1 = 1.05997 loss)
I0716 00:00:45.769304 37548 sgd_solver.cpp:106] Iteration 4150, lr = 0.015
I0716 00:04:27.869915 37548 solver.cpp:236] Iteration 4200, loss = 1.06945
I0716 00:04:27.870199 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 00:04:27.870235 37548 solver.cpp:252]     Train net output #1: loss = 1.05302 (* 1 = 1.05302 loss)
I0716 00:04:28.734179 37548 sgd_solver.cpp:106] Iteration 4200, lr = 0.015
I0716 00:06:50.098152 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 00:08:13.576850 37548 solver.cpp:236] Iteration 4250, loss = 1.08837
I0716 00:08:13.577136 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 00:08:13.577177 37548 solver.cpp:252]     Train net output #1: loss = 1.18915 (* 1 = 1.18915 loss)
I0716 00:08:14.469066 37548 sgd_solver.cpp:106] Iteration 4250, lr = 0.015
I0716 00:12:03.598490 37548 solver.cpp:236] Iteration 4300, loss = 1.05902
I0716 00:12:03.598809 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 00:12:03.598848 37548 solver.cpp:252]     Train net output #1: loss = 1.22102 (* 1 = 1.22102 loss)
I0716 00:12:04.526399 37548 sgd_solver.cpp:106] Iteration 4300, lr = 0.015
I0716 00:15:49.444372 37548 solver.cpp:236] Iteration 4350, loss = 1.05586
I0716 00:15:49.444671 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 00:15:49.444710 37548 solver.cpp:252]     Train net output #1: loss = 0.934723 (* 1 = 0.934723 loss)
I0716 00:15:50.327354 37548 sgd_solver.cpp:106] Iteration 4350, lr = 0.015
I0716 00:19:36.299760 37548 solver.cpp:236] Iteration 4400, loss = 1.07508
I0716 00:19:36.300015 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 00:19:36.300068 37548 solver.cpp:252]     Train net output #1: loss = 1.13803 (* 1 = 1.13803 loss)
I0716 00:19:37.265369 37548 sgd_solver.cpp:106] Iteration 4400, lr = 0.015
I0716 00:23:19.501467 37548 solver.cpp:236] Iteration 4450, loss = 1.07082
I0716 00:23:19.501827 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 00:23:19.501859 37548 solver.cpp:252]     Train net output #1: loss = 1.01297 (* 1 = 1.01297 loss)
I0716 00:23:20.390413 37548 sgd_solver.cpp:106] Iteration 4450, lr = 0.015
I0716 00:27:00.775620 37548 solver.cpp:340] Iteration 4500, Testing net (#0)
I0716 00:50:15.034258 37548 solver.cpp:408]     Test net output #0: accuracy = 0.462667
I0716 00:50:15.034580 37548 solver.cpp:408]     Test net output #1: loss = 1.06367 (* 1 = 1.06367 loss)
I0716 00:50:17.899873 37548 solver.cpp:236] Iteration 4500, loss = 1.08808
I0716 00:50:17.899982 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 00:50:17.900018 37548 solver.cpp:252]     Train net output #1: loss = 0.920853 (* 1 = 0.920853 loss)
I0716 00:50:17.900084 37548 sgd_solver.cpp:106] Iteration 4500, lr = 0.015
I0716 00:54:11.612838 37548 solver.cpp:236] Iteration 4550, loss = 1.02478
I0716 00:54:11.613152 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 00:54:11.613196 37548 solver.cpp:252]     Train net output #1: loss = 1.06716 (* 1 = 1.06716 loss)
I0716 00:54:12.628700 37548 sgd_solver.cpp:106] Iteration 4550, lr = 0.015
I0716 00:57:55.756047 37548 solver.cpp:236] Iteration 4600, loss = 1.06618
I0716 00:57:55.756256 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 00:57:55.756288 37548 solver.cpp:252]     Train net output #1: loss = 1.09482 (* 1 = 1.09482 loss)
I0716 00:57:56.701230 37548 sgd_solver.cpp:106] Iteration 4600, lr = 0.015
I0716 01:01:46.303527 37548 solver.cpp:236] Iteration 4650, loss = 1.06025
I0716 01:01:46.303788 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 01:01:46.303823 37548 solver.cpp:252]     Train net output #1: loss = 0.944415 (* 1 = 0.944415 loss)
I0716 01:01:47.247128 37548 sgd_solver.cpp:106] Iteration 4650, lr = 0.015
I0716 01:02:42.811790 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 01:05:31.437994 37548 solver.cpp:236] Iteration 4700, loss = 1.08873
I0716 01:05:31.438289 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 01:05:31.438320 37548 solver.cpp:252]     Train net output #1: loss = 1.13018 (* 1 = 1.13018 loss)
I0716 01:05:32.395956 37548 sgd_solver.cpp:106] Iteration 4700, lr = 0.015
I0716 01:09:14.071051 37548 solver.cpp:236] Iteration 4750, loss = 1.03977
I0716 01:09:14.071436 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 01:09:14.071488 37548 solver.cpp:252]     Train net output #1: loss = 1.28834 (* 1 = 1.28834 loss)
I0716 01:09:14.959302 37548 sgd_solver.cpp:106] Iteration 4750, lr = 0.015
I0716 01:13:03.450969 37548 solver.cpp:236] Iteration 4800, loss = 1.04457
I0716 01:13:03.451231 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 01:13:03.451277 37548 solver.cpp:252]     Train net output #1: loss = 1.03225 (* 1 = 1.03225 loss)
I0716 01:13:04.413179 37548 sgd_solver.cpp:106] Iteration 4800, lr = 0.015
I0716 01:16:47.238260 37548 solver.cpp:236] Iteration 4850, loss = 1.07072
I0716 01:16:47.238734 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 01:16:47.238801 37548 solver.cpp:252]     Train net output #1: loss = 1.02487 (* 1 = 1.02487 loss)
I0716 01:16:48.116834 37548 sgd_solver.cpp:106] Iteration 4850, lr = 0.015
I0716 01:20:26.446029 37548 solver.cpp:236] Iteration 4900, loss = 1.07658
I0716 01:20:26.446307 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 01:20:26.446352 37548 solver.cpp:252]     Train net output #1: loss = 0.973763 (* 1 = 0.973763 loss)
I0716 01:20:27.339246 37548 sgd_solver.cpp:106] Iteration 4900, lr = 0.015
I0716 01:24:12.388638 37548 solver.cpp:236] Iteration 4950, loss = 1.06001
I0716 01:24:12.388864 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 01:24:12.388885 37548 solver.cpp:252]     Train net output #1: loss = 0.908041 (* 1 = 0.908041 loss)
I0716 01:24:13.262243 37548 sgd_solver.cpp:106] Iteration 4950, lr = 0.015
I0716 01:27:52.599627 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_5000.caffemodel
I0716 01:27:52.909327 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_5000.solverstate
I0716 01:27:55.778131 37548 solver.cpp:236] Iteration 5000, loss = 1.06186
I0716 01:27:55.778218 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 01:27:55.778249 37548 solver.cpp:252]     Train net output #1: loss = 1.0657 (* 1 = 1.0657 loss)
I0716 01:27:56.747323 37548 sgd_solver.cpp:106] Iteration 5000, lr = 0.015
I0716 01:31:43.393693 37548 solver.cpp:236] Iteration 5050, loss = 1.04858
I0716 01:31:43.394003 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 01:31:43.394043 37548 solver.cpp:252]     Train net output #1: loss = 1.19567 (* 1 = 1.19567 loss)
I0716 01:31:44.280416 37548 sgd_solver.cpp:106] Iteration 5050, lr = 0.015
I0716 01:35:26.590644 37548 solver.cpp:236] Iteration 5100, loss = 1.07985
I0716 01:35:26.590950 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 01:35:26.591006 37548 solver.cpp:252]     Train net output #1: loss = 1.06246 (* 1 = 1.06246 loss)
I0716 01:35:27.538836 37548 sgd_solver.cpp:106] Iteration 5100, lr = 0.015
I0716 01:35:59.412061 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 01:39:09.718686 37548 solver.cpp:236] Iteration 5150, loss = 1.05989
I0716 01:39:09.718955 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 01:39:09.719000 37548 solver.cpp:252]     Train net output #1: loss = 1.17518 (* 1 = 1.17518 loss)
I0716 01:39:10.672178 37548 sgd_solver.cpp:106] Iteration 5150, lr = 0.015
I0716 01:42:57.262935 37548 solver.cpp:236] Iteration 5200, loss = 1.06469
I0716 01:42:57.263265 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 01:42:57.263322 37548 solver.cpp:252]     Train net output #1: loss = 1.14107 (* 1 = 1.14107 loss)
I0716 01:42:58.144438 37548 sgd_solver.cpp:106] Iteration 5200, lr = 0.015
I0716 01:46:42.802487 37548 solver.cpp:236] Iteration 5250, loss = 1.04686
I0716 01:46:42.802855 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 01:46:42.802919 37548 solver.cpp:252]     Train net output #1: loss = 1.24638 (* 1 = 1.24638 loss)
I0716 01:46:43.736853 37548 sgd_solver.cpp:106] Iteration 5250, lr = 0.015
I0716 01:50:33.105865 37548 solver.cpp:236] Iteration 5300, loss = 1.10109
I0716 01:50:33.106278 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 01:50:33.106358 37548 solver.cpp:252]     Train net output #1: loss = 1.07182 (* 1 = 1.07182 loss)
I0716 01:50:34.061558 37548 sgd_solver.cpp:106] Iteration 5300, lr = 0.015
I0716 01:54:19.849489 37548 solver.cpp:236] Iteration 5350, loss = 1.05506
I0716 01:54:19.849866 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 01:54:19.849928 37548 solver.cpp:252]     Train net output #1: loss = 1.14232 (* 1 = 1.14232 loss)
I0716 01:54:20.809737 37548 sgd_solver.cpp:106] Iteration 5350, lr = 0.015
I0716 01:58:09.632098 37548 solver.cpp:236] Iteration 5400, loss = 1.05251
I0716 01:58:09.632355 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 01:58:09.632419 37548 solver.cpp:252]     Train net output #1: loss = 0.885486 (* 1 = 0.885486 loss)
I0716 01:58:10.492137 37548 sgd_solver.cpp:106] Iteration 5400, lr = 0.015
I0716 02:01:58.757516 37548 solver.cpp:236] Iteration 5450, loss = 1.06725
I0716 02:01:58.757843 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 02:01:58.757879 37548 solver.cpp:252]     Train net output #1: loss = 0.898424 (* 1 = 0.898424 loss)
I0716 02:01:59.636044 37548 sgd_solver.cpp:106] Iteration 5450, lr = 0.015
I0716 02:05:45.232059 37548 solver.cpp:236] Iteration 5500, loss = 1.04105
I0716 02:05:45.232339 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 02:05:45.232374 37548 solver.cpp:252]     Train net output #1: loss = 1.02072 (* 1 = 1.02072 loss)
I0716 02:05:46.180354 37548 sgd_solver.cpp:106] Iteration 5500, lr = 0.015
I0716 02:08:06.899363 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 02:09:35.333542 37548 solver.cpp:236] Iteration 5550, loss = 1.05506
I0716 02:09:35.333850 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 02:09:35.333873 37548 solver.cpp:252]     Train net output #1: loss = 1.07947 (* 1 = 1.07947 loss)
I0716 02:09:36.333151 37548 sgd_solver.cpp:106] Iteration 5550, lr = 0.015
I0716 02:13:24.133189 37548 solver.cpp:236] Iteration 5600, loss = 1.07183
I0716 02:13:24.133698 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 02:13:24.133754 37548 solver.cpp:252]     Train net output #1: loss = 1.02169 (* 1 = 1.02169 loss)
I0716 02:13:25.043668 37548 sgd_solver.cpp:106] Iteration 5600, lr = 0.015
I0716 02:17:12.989986 37548 solver.cpp:236] Iteration 5650, loss = 1.06812
I0716 02:17:12.990384 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 02:17:12.990419 37548 solver.cpp:252]     Train net output #1: loss = 0.901078 (* 1 = 0.901078 loss)
I0716 02:17:13.926997 37548 sgd_solver.cpp:106] Iteration 5650, lr = 0.015
I0716 02:21:01.156191 37548 solver.cpp:236] Iteration 5700, loss = 1.0571
I0716 02:21:01.156507 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 02:21:01.156570 37548 solver.cpp:252]     Train net output #1: loss = 1.05897 (* 1 = 1.05897 loss)
I0716 02:21:02.103889 37548 sgd_solver.cpp:106] Iteration 5700, lr = 0.015
I0716 02:24:46.342764 37548 solver.cpp:236] Iteration 5750, loss = 1.07827
I0716 02:24:46.343101 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 02:24:46.343142 37548 solver.cpp:252]     Train net output #1: loss = 0.952939 (* 1 = 0.952939 loss)
I0716 02:24:47.233458 37548 sgd_solver.cpp:106] Iteration 5750, lr = 0.015
I0716 02:28:34.260432 37548 solver.cpp:236] Iteration 5800, loss = 1.04799
I0716 02:28:34.260713 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 02:28:34.260746 37548 solver.cpp:252]     Train net output #1: loss = 1.08611 (* 1 = 1.08611 loss)
I0716 02:28:35.144408 37548 sgd_solver.cpp:106] Iteration 5800, lr = 0.015
I0716 02:32:27.344569 37548 solver.cpp:236] Iteration 5850, loss = 1.08714
I0716 02:32:27.344897 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 02:32:27.344945 37548 solver.cpp:252]     Train net output #1: loss = 1.21262 (* 1 = 1.21262 loss)
I0716 02:32:28.223883 37548 sgd_solver.cpp:106] Iteration 5850, lr = 0.015
I0716 02:36:15.757541 37548 solver.cpp:236] Iteration 5900, loss = 1.05539
I0716 02:36:15.757975 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 02:36:15.758049 37548 solver.cpp:252]     Train net output #1: loss = 0.984571 (* 1 = 0.984571 loss)
I0716 02:36:16.719662 37548 sgd_solver.cpp:106] Iteration 5900, lr = 0.015
I0716 02:39:31.021781 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 02:40:00.942817 37548 solver.cpp:236] Iteration 5950, loss = 1.07488
I0716 02:40:00.942924 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 02:40:00.942967 37548 solver.cpp:252]     Train net output #1: loss = 1.03515 (* 1 = 1.03515 loss)
I0716 02:40:01.824067 37548 sgd_solver.cpp:106] Iteration 5950, lr = 0.015
I0716 02:43:47.489132 37548 solver.cpp:340] Iteration 6000, Testing net (#0)
I0716 03:07:01.479928 37548 solver.cpp:408]     Test net output #0: accuracy = 0.459667
I0716 03:07:01.495067 37548 solver.cpp:408]     Test net output #1: loss = 1.06589 (* 1 = 1.06589 loss)
I0716 03:07:04.364840 37548 solver.cpp:236] Iteration 6000, loss = 1.0439
I0716 03:07:04.364895 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 03:07:04.364922 37548 solver.cpp:252]     Train net output #1: loss = 0.790525 (* 1 = 0.790525 loss)
I0716 03:07:04.364996 37548 sgd_solver.cpp:106] Iteration 6000, lr = 0.015
I0716 03:10:50.816746 37548 solver.cpp:236] Iteration 6050, loss = 1.03449
I0716 03:10:50.817030 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 03:10:50.817064 37548 solver.cpp:252]     Train net output #1: loss = 1.07891 (* 1 = 1.07891 loss)
I0716 03:10:51.691133 37548 sgd_solver.cpp:106] Iteration 6050, lr = 0.015
I0716 03:14:38.574542 37548 solver.cpp:236] Iteration 6100, loss = 1.06889
I0716 03:14:38.574888 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 03:14:38.574923 37548 solver.cpp:252]     Train net output #1: loss = 0.928977 (* 1 = 0.928977 loss)
I0716 03:14:39.452428 37548 sgd_solver.cpp:106] Iteration 6100, lr = 0.015
I0716 03:18:25.005044 37548 solver.cpp:236] Iteration 6150, loss = 1.08723
I0716 03:18:25.005295 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 03:18:25.005327 37548 solver.cpp:252]     Train net output #1: loss = 1.04551 (* 1 = 1.04551 loss)
I0716 03:18:25.882206 37548 sgd_solver.cpp:106] Iteration 6150, lr = 0.015
I0716 03:22:09.346941 37548 solver.cpp:236] Iteration 6200, loss = 1.05888
I0716 03:22:09.347329 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 03:22:09.347373 37548 solver.cpp:252]     Train net output #1: loss = 1.26175 (* 1 = 1.26175 loss)
I0716 03:22:10.223652 37548 sgd_solver.cpp:106] Iteration 6200, lr = 0.015
I0716 03:25:59.525382 37548 solver.cpp:236] Iteration 6250, loss = 1.07811
I0716 03:25:59.525615 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 03:25:59.525655 37548 solver.cpp:252]     Train net output #1: loss = 1.19353 (* 1 = 1.19353 loss)
I0716 03:26:00.412866 37548 sgd_solver.cpp:106] Iteration 6250, lr = 0.015
I0716 03:29:45.590941 37548 solver.cpp:236] Iteration 6300, loss = 1.07073
I0716 03:29:45.591277 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 03:29:45.591323 37548 solver.cpp:252]     Train net output #1: loss = 1.01681 (* 1 = 1.01681 loss)
I0716 03:29:46.528183 37548 sgd_solver.cpp:106] Iteration 6300, lr = 0.015
I0716 03:33:26.718402 37548 solver.cpp:236] Iteration 6350, loss = 1.08901
I0716 03:33:26.718664 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 03:33:26.718699 37548 solver.cpp:252]     Train net output #1: loss = 1.03504 (* 1 = 1.03504 loss)
I0716 03:33:27.581033 37548 sgd_solver.cpp:106] Iteration 6350, lr = 0.015
I0716 03:35:03.709805 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 03:37:14.197950 37548 solver.cpp:236] Iteration 6400, loss = 1.08706
I0716 03:37:14.198241 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 03:37:14.198276 37548 solver.cpp:252]     Train net output #1: loss = 1.2282 (* 1 = 1.2282 loss)
I0716 03:37:15.154894 37548 sgd_solver.cpp:106] Iteration 6400, lr = 0.015
I0716 03:41:06.281680 37548 solver.cpp:236] Iteration 6450, loss = 1.04824
I0716 03:41:06.282152 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 03:41:06.282222 37548 solver.cpp:252]     Train net output #1: loss = 1.02251 (* 1 = 1.02251 loss)
I0716 03:41:07.161536 37548 sgd_solver.cpp:106] Iteration 6450, lr = 0.015
I0716 03:44:51.209236 37548 solver.cpp:236] Iteration 6500, loss = 1.05272
I0716 03:44:51.209559 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 03:44:51.209595 37548 solver.cpp:252]     Train net output #1: loss = 1.047 (* 1 = 1.047 loss)
I0716 03:44:52.081346 37548 sgd_solver.cpp:106] Iteration 6500, lr = 0.015
I0716 03:48:35.785531 37548 solver.cpp:236] Iteration 6550, loss = 1.03638
I0716 03:48:35.785797 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 03:48:35.785838 37548 solver.cpp:252]     Train net output #1: loss = 1.12121 (* 1 = 1.12121 loss)
I0716 03:48:36.664461 37548 sgd_solver.cpp:106] Iteration 6550, lr = 0.015
I0716 03:52:19.333783 37548 solver.cpp:236] Iteration 6600, loss = 1.09806
I0716 03:52:19.334079 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 03:52:19.334147 37548 solver.cpp:252]     Train net output #1: loss = 0.992642 (* 1 = 0.992642 loss)
I0716 03:52:20.206677 37548 sgd_solver.cpp:106] Iteration 6600, lr = 0.015
I0716 03:56:15.631216 37548 solver.cpp:236] Iteration 6650, loss = 1.0427
I0716 03:56:15.631530 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 03:56:15.631587 37548 solver.cpp:252]     Train net output #1: loss = 0.794248 (* 1 = 0.794248 loss)
I0716 03:56:16.528199 37548 sgd_solver.cpp:106] Iteration 6650, lr = 0.015
I0716 04:00:05.102179 37548 solver.cpp:236] Iteration 6700, loss = 1.05064
I0716 04:00:05.102414 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0716 04:00:05.102468 37548 solver.cpp:252]     Train net output #1: loss = 1.3412 (* 1 = 1.3412 loss)
I0716 04:00:06.055531 37548 sgd_solver.cpp:106] Iteration 6700, lr = 0.015
I0716 04:03:53.833653 37548 solver.cpp:236] Iteration 6750, loss = 1.06651
I0716 04:03:53.833901 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 04:03:53.833941 37548 solver.cpp:252]     Train net output #1: loss = 1.03276 (* 1 = 1.03276 loss)
I0716 04:03:54.767011 37548 sgd_solver.cpp:106] Iteration 6750, lr = 0.015
I0716 04:07:42.291555 37548 solver.cpp:236] Iteration 6800, loss = 1.07177
I0716 04:07:42.291908 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 04:07:42.291956 37548 solver.cpp:252]     Train net output #1: loss = 1.20811 (* 1 = 1.20811 loss)
I0716 04:07:43.188721 37548 sgd_solver.cpp:106] Iteration 6800, lr = 0.015
I0716 04:07:53.079932 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 04:11:29.857825 37548 solver.cpp:236] Iteration 6850, loss = 1.07993
I0716 04:11:29.858142 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 04:11:29.858194 37548 solver.cpp:252]     Train net output #1: loss = 1.22914 (* 1 = 1.22914 loss)
I0716 04:11:30.749114 37548 sgd_solver.cpp:106] Iteration 6850, lr = 0.015
I0716 04:15:15.345659 37548 solver.cpp:236] Iteration 6900, loss = 1.08096
I0716 04:15:15.345952 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 04:15:15.345983 37548 solver.cpp:252]     Train net output #1: loss = 1.21617 (* 1 = 1.21617 loss)
I0716 04:15:16.223675 37548 sgd_solver.cpp:106] Iteration 6900, lr = 0.015
I0716 04:19:04.656574 37548 solver.cpp:236] Iteration 6950, loss = 1.05919
I0716 04:19:04.656935 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 04:19:04.656977 37548 solver.cpp:252]     Train net output #1: loss = 1.19215 (* 1 = 1.19215 loss)
I0716 04:19:05.535464 37548 sgd_solver.cpp:106] Iteration 6950, lr = 0.015
I0716 04:22:52.156775 37548 solver.cpp:236] Iteration 7000, loss = 1.04981
I0716 04:22:52.157156 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 04:22:52.157208 37548 solver.cpp:252]     Train net output #1: loss = 0.941298 (* 1 = 0.941298 loss)
I0716 04:22:53.034886 37548 sgd_solver.cpp:106] Iteration 7000, lr = 0.015
I0716 04:26:40.487570 37548 solver.cpp:236] Iteration 7050, loss = 1.08369
I0716 04:26:40.487802 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 04:26:40.487838 37548 solver.cpp:252]     Train net output #1: loss = 1.09845 (* 1 = 1.09845 loss)
I0716 04:26:41.380285 37548 sgd_solver.cpp:106] Iteration 7050, lr = 0.015
I0716 04:30:30.171512 37548 solver.cpp:236] Iteration 7100, loss = 1.07638
I0716 04:30:30.171778 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 04:30:30.171828 37548 solver.cpp:252]     Train net output #1: loss = 1.13988 (* 1 = 1.13988 loss)
I0716 04:30:31.098732 37548 sgd_solver.cpp:106] Iteration 7100, lr = 0.015
I0716 04:34:12.058167 37548 solver.cpp:236] Iteration 7150, loss = 1.05222
I0716 04:34:12.058450 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 04:34:12.058501 37548 solver.cpp:252]     Train net output #1: loss = 1.02624 (* 1 = 1.02624 loss)
I0716 04:34:13.005513 37548 sgd_solver.cpp:106] Iteration 7150, lr = 0.015
I0716 04:38:00.446576 37548 solver.cpp:236] Iteration 7200, loss = 1.05872
I0716 04:38:00.446907 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 04:38:00.446967 37548 solver.cpp:252]     Train net output #1: loss = 0.950849 (* 1 = 0.950849 loss)
I0716 04:38:01.379626 37548 sgd_solver.cpp:106] Iteration 7200, lr = 0.015
I0716 04:40:03.801542 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 04:41:46.879842 37548 solver.cpp:236] Iteration 7250, loss = 1.03578
I0716 04:41:46.880103 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 04:41:46.880147 37548 solver.cpp:252]     Train net output #1: loss = 0.912404 (* 1 = 0.912404 loss)
I0716 04:41:47.762030 37548 sgd_solver.cpp:106] Iteration 7250, lr = 0.015
I0716 04:45:38.320217 37548 solver.cpp:236] Iteration 7300, loss = 1.06065
I0716 04:45:38.320499 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 04:45:38.320535 37548 solver.cpp:252]     Train net output #1: loss = 1.02463 (* 1 = 1.02463 loss)
I0716 04:45:39.197443 37548 sgd_solver.cpp:106] Iteration 7300, lr = 0.015
I0716 04:49:28.905961 37548 solver.cpp:236] Iteration 7350, loss = 1.069
I0716 04:49:28.906376 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 04:49:28.906463 37548 solver.cpp:252]     Train net output #1: loss = 1.02099 (* 1 = 1.02099 loss)
I0716 04:49:29.778946 37548 sgd_solver.cpp:106] Iteration 7350, lr = 0.015
I0716 04:53:16.849400 37548 solver.cpp:236] Iteration 7400, loss = 1.0539
I0716 04:53:16.849694 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 04:53:16.849738 37548 solver.cpp:252]     Train net output #1: loss = 1.12715 (* 1 = 1.12715 loss)
I0716 04:53:17.793459 37548 sgd_solver.cpp:106] Iteration 7400, lr = 0.015
I0716 04:57:05.354329 37548 solver.cpp:236] Iteration 7450, loss = 1.05869
I0716 04:57:05.354607 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 04:57:05.354683 37548 solver.cpp:252]     Train net output #1: loss = 1.12965 (* 1 = 1.12965 loss)
I0716 04:57:06.241494 37548 sgd_solver.cpp:106] Iteration 7450, lr = 0.015
I0716 05:00:50.161217 37548 solver.cpp:340] Iteration 7500, Testing net (#0)
I0716 05:24:04.252230 37548 solver.cpp:408]     Test net output #0: accuracy = 0.465333
I0716 05:24:04.252482 37548 solver.cpp:408]     Test net output #1: loss = 1.06769 (* 1 = 1.06769 loss)
I0716 05:24:07.120621 37548 solver.cpp:236] Iteration 7500, loss = 1.05908
I0716 05:24:07.120671 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 05:24:07.120699 37548 solver.cpp:252]     Train net output #1: loss = 0.961793 (* 1 = 0.961793 loss)
I0716 05:24:07.120764 37548 sgd_solver.cpp:106] Iteration 7500, lr = 0.015
I0716 05:27:47.057806 37548 solver.cpp:236] Iteration 7550, loss = 1.05871
I0716 05:27:47.058152 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 05:27:47.058187 37548 solver.cpp:252]     Train net output #1: loss = 1.09339 (* 1 = 1.09339 loss)
I0716 05:27:48.016494 37548 sgd_solver.cpp:106] Iteration 7550, lr = 0.015
I0716 05:31:32.726377 37548 solver.cpp:236] Iteration 7600, loss = 1.07624
I0716 05:31:32.726697 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 05:31:32.726750 37548 solver.cpp:252]     Train net output #1: loss = 0.917642 (* 1 = 0.917642 loss)
I0716 05:31:33.607704 37548 sgd_solver.cpp:106] Iteration 7600, lr = 0.015
I0716 05:35:18.038846 37548 solver.cpp:236] Iteration 7650, loss = 1.0851
I0716 05:35:18.039134 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 05:35:18.039185 37548 solver.cpp:252]     Train net output #1: loss = 1.07633 (* 1 = 1.07633 loss)
I0716 05:35:18.917995 37548 sgd_solver.cpp:106] Iteration 7650, lr = 0.015
I0716 05:35:28.976645 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 05:39:06.065328 37548 solver.cpp:236] Iteration 7700, loss = 1.05627
I0716 05:39:06.065666 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 05:39:06.065752 37548 solver.cpp:252]     Train net output #1: loss = 0.896956 (* 1 = 0.896956 loss)
I0716 05:39:06.927937 37548 sgd_solver.cpp:106] Iteration 7700, lr = 0.015
I0716 05:42:52.293655 37548 solver.cpp:236] Iteration 7750, loss = 1.03512
I0716 05:42:52.293951 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 05:42:52.294005 37548 solver.cpp:252]     Train net output #1: loss = 1.01903 (* 1 = 1.01903 loss)
I0716 05:42:53.234622 37548 sgd_solver.cpp:106] Iteration 7750, lr = 0.015
I0716 05:46:31.626557 37548 solver.cpp:236] Iteration 7800, loss = 1.06977
I0716 05:46:31.627007 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 05:46:31.627101 37548 solver.cpp:252]     Train net output #1: loss = 1.22836 (* 1 = 1.22836 loss)
I0716 05:46:32.502792 37548 sgd_solver.cpp:106] Iteration 7800, lr = 0.015
I0716 05:50:22.427292 37548 solver.cpp:236] Iteration 7850, loss = 1.04175
I0716 05:50:22.427562 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 05:50:22.427594 37548 solver.cpp:252]     Train net output #1: loss = 0.794813 (* 1 = 0.794813 loss)
I0716 05:50:23.307561 37548 sgd_solver.cpp:106] Iteration 7850, lr = 0.015
I0716 05:54:11.410514 37548 solver.cpp:236] Iteration 7900, loss = 1.05976
I0716 05:54:11.410802 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 05:54:11.410852 37548 solver.cpp:252]     Train net output #1: loss = 0.880039 (* 1 = 0.880039 loss)
I0716 05:54:12.297930 37548 sgd_solver.cpp:106] Iteration 7900, lr = 0.015
I0716 05:57:53.627251 37548 solver.cpp:236] Iteration 7950, loss = 1.04921
I0716 05:57:53.627578 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 05:57:53.627614 37548 solver.cpp:252]     Train net output #1: loss = 1.10186 (* 1 = 1.10186 loss)
I0716 05:57:54.523692 37548 sgd_solver.cpp:106] Iteration 7950, lr = 0.015
I0716 06:01:38.036026 37548 solver.cpp:236] Iteration 8000, loss = 1.04407
I0716 06:01:38.036331 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:01:38.036381 37548 solver.cpp:252]     Train net output #1: loss = 1.0171 (* 1 = 1.0171 loss)
I0716 06:01:38.912250 37548 sgd_solver.cpp:106] Iteration 8000, lr = 0.015
I0716 06:05:17.744490 37548 solver.cpp:236] Iteration 8050, loss = 1.08083
I0716 06:05:17.744750 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:05:17.744784 37548 solver.cpp:252]     Train net output #1: loss = 1.07611 (* 1 = 1.07611 loss)
I0716 06:05:18.626730 37548 sgd_solver.cpp:106] Iteration 8050, lr = 0.015
I0716 06:08:21.188887 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 06:09:00.720090 37548 solver.cpp:236] Iteration 8100, loss = 1.02989
I0716 06:09:00.720387 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:09:00.720417 37548 solver.cpp:252]     Train net output #1: loss = 1.06404 (* 1 = 1.06404 loss)
I0716 06:09:01.582540 37548 sgd_solver.cpp:106] Iteration 8100, lr = 0.015
I0716 06:12:44.515414 37548 solver.cpp:236] Iteration 8150, loss = 1.08364
I0716 06:12:44.515636 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:12:44.515660 37548 solver.cpp:252]     Train net output #1: loss = 1.02955 (* 1 = 1.02955 loss)
I0716 06:12:45.403055 37548 sgd_solver.cpp:106] Iteration 8150, lr = 0.015
I0716 06:16:28.380409 37548 solver.cpp:236] Iteration 8200, loss = 1.08845
I0716 06:16:28.380664 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 06:16:28.380714 37548 solver.cpp:252]     Train net output #1: loss = 0.930898 (* 1 = 0.930898 loss)
I0716 06:16:29.257580 37548 sgd_solver.cpp:106] Iteration 8200, lr = 0.015
I0716 06:20:17.204409 37548 solver.cpp:236] Iteration 8250, loss = 1.06623
I0716 06:20:17.204753 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 06:20:17.204818 37548 solver.cpp:252]     Train net output #1: loss = 1.19279 (* 1 = 1.19279 loss)
I0716 06:20:18.094611 37548 sgd_solver.cpp:106] Iteration 8250, lr = 0.015
I0716 06:24:06.397642 37548 solver.cpp:236] Iteration 8300, loss = 1.02049
I0716 06:24:06.397981 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 06:24:06.398016 37548 solver.cpp:252]     Train net output #1: loss = 0.941888 (* 1 = 0.941888 loss)
I0716 06:24:07.276654 37548 sgd_solver.cpp:106] Iteration 8300, lr = 0.015
I0716 06:27:50.205076 37548 solver.cpp:236] Iteration 8350, loss = 1.06759
I0716 06:27:50.205349 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:27:50.205384 37548 solver.cpp:252]     Train net output #1: loss = 1.02864 (* 1 = 1.02864 loss)
I0716 06:27:51.095161 37548 sgd_solver.cpp:106] Iteration 8350, lr = 0.015
I0716 06:31:34.705876 37548 solver.cpp:236] Iteration 8400, loss = 1.05797
I0716 06:31:34.706178 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 06:31:34.706238 37548 solver.cpp:252]     Train net output #1: loss = 0.901701 (* 1 = 0.901701 loss)
I0716 06:31:35.589730 37548 sgd_solver.cpp:106] Iteration 8400, lr = 0.015
I0716 06:35:18.292659 37548 solver.cpp:236] Iteration 8450, loss = 1.06493
I0716 06:35:18.292976 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:35:18.293006 37548 solver.cpp:252]     Train net output #1: loss = 1.05093 (* 1 = 1.05093 loss)
I0716 06:35:19.169486 37548 sgd_solver.cpp:106] Iteration 8450, lr = 0.015
I0716 06:39:03.951902 37548 solver.cpp:236] Iteration 8500, loss = 1.07786
I0716 06:39:03.952208 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:39:03.952250 37548 solver.cpp:252]     Train net output #1: loss = 1.02353 (* 1 = 1.02353 loss)
I0716 06:39:04.828804 37548 sgd_solver.cpp:106] Iteration 8500, lr = 0.015
I0716 06:40:45.450079 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 06:42:53.017642 37548 solver.cpp:236] Iteration 8550, loss = 1.04252
I0716 06:42:53.017917 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 06:42:53.017963 37548 solver.cpp:252]     Train net output #1: loss = 1.03118 (* 1 = 1.03118 loss)
I0716 06:42:53.974238 37548 sgd_solver.cpp:106] Iteration 8550, lr = 0.015
I0716 06:46:35.178616 37548 solver.cpp:236] Iteration 8600, loss = 1.06069
I0716 06:46:35.178952 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 06:46:35.179000 37548 solver.cpp:252]     Train net output #1: loss = 0.890735 (* 1 = 0.890735 loss)
I0716 06:46:36.054772 37548 sgd_solver.cpp:106] Iteration 8600, lr = 0.015
I0716 06:50:22.202148 37548 solver.cpp:236] Iteration 8650, loss = 1.05116
I0716 06:50:22.202448 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 06:50:22.202481 37548 solver.cpp:252]     Train net output #1: loss = 0.97871 (* 1 = 0.97871 loss)
I0716 06:50:23.081069 37548 sgd_solver.cpp:106] Iteration 8650, lr = 0.015
I0716 06:54:11.219534 37548 solver.cpp:236] Iteration 8700, loss = 1.04808
I0716 06:54:11.219810 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 06:54:11.219844 37548 solver.cpp:252]     Train net output #1: loss = 1.16941 (* 1 = 1.16941 loss)
I0716 06:54:12.103608 37548 sgd_solver.cpp:106] Iteration 8700, lr = 0.015
I0716 06:57:57.448194 37548 solver.cpp:236] Iteration 8750, loss = 1.05963
I0716 06:57:57.448585 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 06:57:57.448619 37548 solver.cpp:252]     Train net output #1: loss = 1.12307 (* 1 = 1.12307 loss)
I0716 06:57:58.329705 37548 sgd_solver.cpp:106] Iteration 8750, lr = 0.015
I0716 07:01:45.247129 37548 solver.cpp:236] Iteration 8800, loss = 1.06936
I0716 07:01:45.247551 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 07:01:45.247624 37548 solver.cpp:252]     Train net output #1: loss = 1.09915 (* 1 = 1.09915 loss)
I0716 07:01:46.206128 37548 sgd_solver.cpp:106] Iteration 8800, lr = 0.015
I0716 07:05:32.370939 37548 solver.cpp:236] Iteration 8850, loss = 1.07571
I0716 07:05:32.371172 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 07:05:32.371214 37548 solver.cpp:252]     Train net output #1: loss = 0.894576 (* 1 = 0.894576 loss)
I0716 07:05:33.309514 37548 sgd_solver.cpp:106] Iteration 8850, lr = 0.015
I0716 07:09:15.047174 37548 solver.cpp:236] Iteration 8900, loss = 1.08745
I0716 07:09:15.047448 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 07:09:15.047482 37548 solver.cpp:252]     Train net output #1: loss = 1.10927 (* 1 = 1.10927 loss)
I0716 07:09:15.924409 37548 sgd_solver.cpp:106] Iteration 8900, lr = 0.015
I0716 07:12:56.205431 37548 solver.cpp:236] Iteration 8950, loss = 1.06852
I0716 07:12:56.205713 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0716 07:12:56.205783 37548 solver.cpp:252]     Train net output #1: loss = 1.33757 (* 1 = 1.33757 loss)
I0716 07:12:57.094473 37548 sgd_solver.cpp:106] Iteration 8950, lr = 0.015
I0716 07:13:10.715703 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 07:16:40.836261 37548 solver.cpp:340] Iteration 9000, Testing net (#0)
I0716 07:39:54.982985 37548 solver.cpp:408]     Test net output #0: accuracy = 0.465333
I0716 07:39:54.999397 37548 solver.cpp:408]     Test net output #1: loss = 1.05811 (* 1 = 1.05811 loss)
I0716 07:39:57.861652 37548 solver.cpp:236] Iteration 9000, loss = 1.05025
I0716 07:39:57.861701 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 07:39:57.861754 37548 solver.cpp:252]     Train net output #1: loss = 1.19304 (* 1 = 1.19304 loss)
I0716 07:39:57.861826 37548 sgd_solver.cpp:106] Iteration 9000, lr = 0.015
I0716 07:43:48.009456 37548 solver.cpp:236] Iteration 9050, loss = 1.04845
I0716 07:43:48.009786 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 07:43:48.009858 37548 solver.cpp:252]     Train net output #1: loss = 0.901246 (* 1 = 0.901246 loss)
I0716 07:43:48.892202 37548 sgd_solver.cpp:106] Iteration 9050, lr = 0.015
I0716 07:47:34.809170 37548 solver.cpp:236] Iteration 9100, loss = 1.05641
I0716 07:47:34.809530 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 07:47:34.809587 37548 solver.cpp:252]     Train net output #1: loss = 1.20441 (* 1 = 1.20441 loss)
I0716 07:47:35.777045 37548 sgd_solver.cpp:106] Iteration 9100, lr = 0.015
I0716 07:51:20.275148 37548 solver.cpp:236] Iteration 9150, loss = 1.05328
I0716 07:51:20.275504 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 07:51:20.275543 37548 solver.cpp:252]     Train net output #1: loss = 0.956139 (* 1 = 0.956139 loss)
I0716 07:51:21.158454 37548 sgd_solver.cpp:106] Iteration 9150, lr = 0.015
I0716 07:55:11.316882 37548 solver.cpp:236] Iteration 9200, loss = 1.04502
I0716 07:55:11.317165 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 07:55:11.317193 37548 solver.cpp:252]     Train net output #1: loss = 1.14006 (* 1 = 1.14006 loss)
I0716 07:55:12.202217 37548 sgd_solver.cpp:106] Iteration 9200, lr = 0.015
I0716 07:58:54.507040 37548 solver.cpp:236] Iteration 9250, loss = 1.05914
I0716 07:58:54.507374 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 07:58:54.507433 37548 solver.cpp:252]     Train net output #1: loss = 1.14277 (* 1 = 1.14277 loss)
I0716 07:58:55.373252 37548 sgd_solver.cpp:106] Iteration 9250, lr = 0.015
I0716 08:02:46.039439 37548 solver.cpp:236] Iteration 9300, loss = 1.06026
I0716 08:02:46.039674 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 08:02:46.039715 37548 solver.cpp:252]     Train net output #1: loss = 1.06283 (* 1 = 1.06283 loss)
I0716 08:02:47.001719 37548 sgd_solver.cpp:106] Iteration 9300, lr = 0.015
I0716 08:06:33.962294 37548 solver.cpp:236] Iteration 9350, loss = 1.03983
I0716 08:06:33.962604 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 08:06:33.962653 37548 solver.cpp:252]     Train net output #1: loss = 1.03214 (* 1 = 1.03214 loss)
I0716 08:06:34.917337 37548 sgd_solver.cpp:106] Iteration 9350, lr = 0.015
I0716 08:08:46.006793 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 08:10:21.823519 37548 solver.cpp:236] Iteration 9400, loss = 1.06561
I0716 08:10:21.823782 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 08:10:21.823812 37548 solver.cpp:252]     Train net output #1: loss = 1.01115 (* 1 = 1.01115 loss)
I0716 08:10:22.700161 37548 sgd_solver.cpp:106] Iteration 9400, lr = 0.015
I0716 08:14:08.610368 37548 solver.cpp:236] Iteration 9450, loss = 1.07148
I0716 08:14:08.610831 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 08:14:08.610944 37548 solver.cpp:252]     Train net output #1: loss = 0.930999 (* 1 = 0.930999 loss)
I0716 08:14:09.565390 37548 sgd_solver.cpp:106] Iteration 9450, lr = 0.015
I0716 08:17:56.595638 37548 solver.cpp:236] Iteration 9500, loss = 1.04497
I0716 08:17:56.595981 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 08:17:56.596040 37548 solver.cpp:252]     Train net output #1: loss = 0.9311 (* 1 = 0.9311 loss)
I0716 08:17:57.535225 37548 sgd_solver.cpp:106] Iteration 9500, lr = 0.015
I0716 08:21:39.785051 37548 solver.cpp:236] Iteration 9550, loss = 1.06167
I0716 08:21:39.785250 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 08:21:39.785326 37548 solver.cpp:252]     Train net output #1: loss = 0.982554 (* 1 = 0.982554 loss)
I0716 08:21:40.712643 37548 sgd_solver.cpp:106] Iteration 9550, lr = 0.015
I0716 08:25:20.381793 37548 solver.cpp:236] Iteration 9600, loss = 1.09449
I0716 08:25:20.382110 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 08:25:20.382141 37548 solver.cpp:252]     Train net output #1: loss = 1.13301 (* 1 = 1.13301 loss)
I0716 08:25:21.257701 37548 sgd_solver.cpp:106] Iteration 9600, lr = 0.015
I0716 08:29:05.568791 37548 solver.cpp:236] Iteration 9650, loss = 1.02077
I0716 08:29:05.569077 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 08:29:05.569106 37548 solver.cpp:252]     Train net output #1: loss = 0.944623 (* 1 = 0.944623 loss)
I0716 08:29:06.446075 37548 sgd_solver.cpp:106] Iteration 9650, lr = 0.015
I0716 08:32:49.924621 37548 solver.cpp:236] Iteration 9700, loss = 1.07101
I0716 08:32:49.924921 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 08:32:49.924980 37548 solver.cpp:252]     Train net output #1: loss = 1.20229 (* 1 = 1.20229 loss)
I0716 08:32:50.865419 37548 sgd_solver.cpp:106] Iteration 9700, lr = 0.015
I0716 08:36:36.158237 37548 solver.cpp:236] Iteration 9750, loss = 1.05275
I0716 08:36:36.158536 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 08:36:36.158571 37548 solver.cpp:252]     Train net output #1: loss = 1.09634 (* 1 = 1.09634 loss)
I0716 08:36:37.043249 37548 sgd_solver.cpp:106] Iteration 9750, lr = 0.015
I0716 08:40:20.355770 37548 solver.cpp:236] Iteration 9800, loss = 1.06931
I0716 08:40:20.356056 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 08:40:20.356086 37548 solver.cpp:252]     Train net output #1: loss = 1.09944 (* 1 = 1.09944 loss)
I0716 08:40:21.242048 37548 sgd_solver.cpp:106] Iteration 9800, lr = 0.015
I0716 08:41:32.569274 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 08:44:09.840454 37548 solver.cpp:236] Iteration 9850, loss = 1.07437
I0716 08:44:09.862133 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 08:44:09.862187 37548 solver.cpp:252]     Train net output #1: loss = 1.10312 (* 1 = 1.10312 loss)
I0716 08:44:10.789640 37548 sgd_solver.cpp:106] Iteration 9850, lr = 0.015
I0716 08:48:03.512028 37548 solver.cpp:236] Iteration 9900, loss = 1.04576
I0716 08:48:03.512323 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 08:48:03.512357 37548 solver.cpp:252]     Train net output #1: loss = 1.06725 (* 1 = 1.06725 loss)
I0716 08:48:04.399269 37548 sgd_solver.cpp:106] Iteration 9900, lr = 0.015
I0716 08:51:45.103736 37548 solver.cpp:236] Iteration 9950, loss = 1.05963
I0716 08:51:45.104053 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 08:51:45.104102 37548 solver.cpp:252]     Train net output #1: loss = 1.07928 (* 1 = 1.07928 loss)
I0716 08:51:45.977175 37548 sgd_solver.cpp:106] Iteration 9950, lr = 0.015
I0716 08:55:31.670267 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_10000.caffemodel
I0716 08:55:33.987224 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_10000.solverstate
I0716 08:55:37.506585 37548 solver.cpp:236] Iteration 10000, loss = 1.06408
I0716 08:55:37.506700 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 08:55:37.506742 37548 solver.cpp:252]     Train net output #1: loss = 0.936453 (* 1 = 0.936453 loss)
I0716 08:55:38.374693 37548 sgd_solver.cpp:106] Iteration 10000, lr = 0.015
I0716 08:59:21.577432 37548 solver.cpp:236] Iteration 10050, loss = 1.0812
I0716 08:59:21.577606 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 08:59:21.577657 37548 solver.cpp:252]     Train net output #1: loss = 0.990912 (* 1 = 0.990912 loss)
I0716 08:59:22.526183 37548 sgd_solver.cpp:106] Iteration 10050, lr = 0.015
I0716 09:03:03.522804 37548 solver.cpp:236] Iteration 10100, loss = 1.06526
I0716 09:03:03.523139 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 09:03:03.523183 37548 solver.cpp:252]     Train net output #1: loss = 1.04899 (* 1 = 1.04899 loss)
I0716 09:03:04.478005 37548 sgd_solver.cpp:106] Iteration 10100, lr = 0.015
I0716 09:06:48.602121 37548 solver.cpp:236] Iteration 10150, loss = 1.06406
I0716 09:06:48.602412 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 09:06:48.602464 37548 solver.cpp:252]     Train net output #1: loss = 1.17547 (* 1 = 1.17547 loss)
I0716 09:06:49.568204 37548 sgd_solver.cpp:106] Iteration 10150, lr = 0.015
I0716 09:10:37.121626 37548 solver.cpp:236] Iteration 10200, loss = 1.04206
I0716 09:10:37.121839 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 09:10:37.121876 37548 solver.cpp:252]     Train net output #1: loss = 0.932188 (* 1 = 0.932188 loss)
I0716 09:10:38.017848 37548 sgd_solver.cpp:106] Iteration 10200, lr = 0.015
I0716 09:13:48.422299 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 09:14:14.644013 37548 solver.cpp:236] Iteration 10250, loss = 1.03514
I0716 09:14:14.644101 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 09:14:14.644136 37548 solver.cpp:252]     Train net output #1: loss = 1.07308 (* 1 = 1.07308 loss)
I0716 09:14:15.507822 37548 sgd_solver.cpp:106] Iteration 10250, lr = 0.015
I0716 09:17:59.403452 37548 solver.cpp:236] Iteration 10300, loss = 1.08056
I0716 09:17:59.403676 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 09:17:59.403712 37548 solver.cpp:252]     Train net output #1: loss = 1.11497 (* 1 = 1.11497 loss)
I0716 09:18:00.292296 37548 sgd_solver.cpp:106] Iteration 10300, lr = 0.015
I0716 09:21:44.438863 37548 solver.cpp:236] Iteration 10350, loss = 1.07509
I0716 09:21:44.439255 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 09:21:44.439352 37548 solver.cpp:252]     Train net output #1: loss = 1.13262 (* 1 = 1.13262 loss)
I0716 09:21:45.321353 37548 sgd_solver.cpp:106] Iteration 10350, lr = 0.015
I0716 09:25:32.165992 37548 solver.cpp:236] Iteration 10400, loss = 1.05659
I0716 09:25:32.166200 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 09:25:32.166224 37548 solver.cpp:252]     Train net output #1: loss = 0.894296 (* 1 = 0.894296 loss)
I0716 09:25:33.117151 37548 sgd_solver.cpp:106] Iteration 10400, lr = 0.015
I0716 09:29:18.923758 37548 solver.cpp:236] Iteration 10450, loss = 1.04863
I0716 09:29:18.924021 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 09:29:18.924057 37548 solver.cpp:252]     Train net output #1: loss = 0.997593 (* 1 = 0.997593 loss)
I0716 09:29:19.871742 37548 sgd_solver.cpp:106] Iteration 10450, lr = 0.015
I0716 09:33:02.328759 37548 solver.cpp:340] Iteration 10500, Testing net (#0)
I0716 09:56:16.598964 37548 solver.cpp:408]     Test net output #0: accuracy = 0.454333
I0716 09:56:16.612133 37548 solver.cpp:408]     Test net output #1: loss = 1.0727 (* 1 = 1.0727 loss)
I0716 09:56:19.478531 37548 solver.cpp:236] Iteration 10500, loss = 1.06849
I0716 09:56:19.478596 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 09:56:19.478626 37548 solver.cpp:252]     Train net output #1: loss = 1.15713 (* 1 = 1.15713 loss)
I0716 09:56:19.478723 37548 sgd_solver.cpp:106] Iteration 10500, lr = 0.015
I0716 10:00:03.813794 37548 solver.cpp:236] Iteration 10550, loss = 1.0623
I0716 10:00:03.830840 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 10:00:03.830922 37548 solver.cpp:252]     Train net output #1: loss = 1.09109 (* 1 = 1.09109 loss)
I0716 10:00:04.761391 37548 sgd_solver.cpp:106] Iteration 10550, lr = 0.015
I0716 10:03:53.293686 37548 solver.cpp:236] Iteration 10600, loss = 1.06147
I0716 10:03:53.293877 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 10:03:53.293907 37548 solver.cpp:252]     Train net output #1: loss = 1.12404 (* 1 = 1.12404 loss)
I0716 10:03:54.169435 37548 sgd_solver.cpp:106] Iteration 10600, lr = 0.015
I0716 10:07:41.386064 37548 solver.cpp:236] Iteration 10650, loss = 1.05968
I0716 10:07:41.386399 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 10:07:41.386440 37548 solver.cpp:252]     Train net output #1: loss = 1.18061 (* 1 = 1.18061 loss)
I0716 10:07:42.285699 37548 sgd_solver.cpp:106] Iteration 10650, lr = 0.015
I0716 10:08:47.546809 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 10:11:28.782886 37548 solver.cpp:236] Iteration 10700, loss = 1.08692
I0716 10:11:28.783138 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 10:11:28.783191 37548 solver.cpp:252]     Train net output #1: loss = 1.08627 (* 1 = 1.08627 loss)
I0716 10:11:29.730907 37548 sgd_solver.cpp:106] Iteration 10700, lr = 0.015
I0716 10:15:09.647827 37548 solver.cpp:236] Iteration 10750, loss = 1.06938
I0716 10:15:09.656970 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 10:15:09.657013 37548 solver.cpp:252]     Train net output #1: loss = 1.04807 (* 1 = 1.04807 loss)
I0716 10:15:10.599344 37548 sgd_solver.cpp:106] Iteration 10750, lr = 0.015
I0716 10:18:52.104498 37548 solver.cpp:236] Iteration 10800, loss = 1.0491
I0716 10:18:52.104703 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 10:18:52.104739 37548 solver.cpp:252]     Train net output #1: loss = 0.904929 (* 1 = 0.904929 loss)
I0716 10:18:52.981503 37548 sgd_solver.cpp:106] Iteration 10800, lr = 0.015
I0716 10:22:35.731201 37548 solver.cpp:236] Iteration 10850, loss = 1.09633
I0716 10:22:35.731467 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 10:22:35.731508 37548 solver.cpp:252]     Train net output #1: loss = 1.26986 (* 1 = 1.26986 loss)
I0716 10:22:36.662487 37548 sgd_solver.cpp:106] Iteration 10850, lr = 0.015
I0716 10:26:26.013695 37548 solver.cpp:236] Iteration 10900, loss = 1.03541
I0716 10:26:26.013969 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 10:26:26.013998 37548 solver.cpp:252]     Train net output #1: loss = 1.01475 (* 1 = 1.01475 loss)
I0716 10:26:26.888914 37548 sgd_solver.cpp:106] Iteration 10900, lr = 0.015
I0716 10:30:07.348816 37548 solver.cpp:236] Iteration 10950, loss = 1.06144
I0716 10:30:07.349208 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 10:30:07.349277 37548 solver.cpp:252]     Train net output #1: loss = 1.07287 (* 1 = 1.07287 loss)
I0716 10:30:08.247205 37548 sgd_solver.cpp:106] Iteration 10950, lr = 0.015
I0716 10:33:49.665782 37548 solver.cpp:236] Iteration 11000, loss = 1.05442
I0716 10:33:49.666043 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 10:33:49.666076 37548 solver.cpp:252]     Train net output #1: loss = 1.08391 (* 1 = 1.08391 loss)
I0716 10:33:50.621395 37548 sgd_solver.cpp:106] Iteration 11000, lr = 0.015
I0716 10:37:32.882846 37548 solver.cpp:236] Iteration 11050, loss = 1.06899
I0716 10:37:32.883250 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 10:37:32.883347 37548 solver.cpp:252]     Train net output #1: loss = 1.17802 (* 1 = 1.17802 loss)
I0716 10:37:33.845474 37548 sgd_solver.cpp:106] Iteration 11050, lr = 0.015
I0716 10:41:20.650228 37548 solver.cpp:236] Iteration 11100, loss = 1.01899
I0716 10:41:20.650522 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 10:41:20.650549 37548 solver.cpp:252]     Train net output #1: loss = 1.09423 (* 1 = 1.09423 loss)
I0716 10:41:21.534863 37548 sgd_solver.cpp:106] Iteration 11100, lr = 0.015
I0716 10:41:25.781677 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 10:45:05.676126 37548 solver.cpp:236] Iteration 11150, loss = 1.03968
I0716 10:45:05.676496 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 10:45:05.676553 37548 solver.cpp:252]     Train net output #1: loss = 1.07285 (* 1 = 1.07285 loss)
I0716 10:45:06.553586 37548 sgd_solver.cpp:106] Iteration 11150, lr = 0.015
I0716 10:48:52.710017 37548 solver.cpp:236] Iteration 11200, loss = 1.05767
I0716 10:48:52.710366 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 10:48:52.710433 37548 solver.cpp:252]     Train net output #1: loss = 1.11802 (* 1 = 1.11802 loss)
I0716 10:48:53.664989 37548 sgd_solver.cpp:106] Iteration 11200, lr = 0.015
I0716 10:52:39.029865 37548 solver.cpp:236] Iteration 11250, loss = 1.09099
I0716 10:52:39.030176 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 10:52:39.030222 37548 solver.cpp:252]     Train net output #1: loss = 1.08326 (* 1 = 1.08326 loss)
I0716 10:52:39.973598 37548 sgd_solver.cpp:106] Iteration 11250, lr = 0.015
I0716 10:56:19.376147 37548 solver.cpp:236] Iteration 11300, loss = 1.05656
I0716 10:56:19.376453 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 10:56:19.376513 37548 solver.cpp:252]     Train net output #1: loss = 1.17279 (* 1 = 1.17279 loss)
I0716 10:56:20.327419 37548 sgd_solver.cpp:106] Iteration 11300, lr = 0.015
I0716 11:00:11.987864 37548 solver.cpp:236] Iteration 11350, loss = 1.04346
I0716 11:00:11.988117 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 11:00:11.988157 37548 solver.cpp:252]     Train net output #1: loss = 1.10531 (* 1 = 1.10531 loss)
I0716 11:00:12.872891 37548 sgd_solver.cpp:106] Iteration 11350, lr = 0.015
I0716 11:03:56.825235 37548 solver.cpp:236] Iteration 11400, loss = 1.08225
I0716 11:03:56.825525 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 11:03:56.825558 37548 solver.cpp:252]     Train net output #1: loss = 1.10245 (* 1 = 1.10245 loss)
I0716 11:03:57.704882 37548 sgd_solver.cpp:106] Iteration 11400, lr = 0.015
I0716 11:07:42.104744 37548 solver.cpp:236] Iteration 11450, loss = 1.07313
I0716 11:07:42.105136 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 11:07:42.105239 37548 solver.cpp:252]     Train net output #1: loss = 1.24857 (* 1 = 1.24857 loss)
I0716 11:07:42.978869 37548 sgd_solver.cpp:106] Iteration 11450, lr = 0.015
I0716 11:11:28.236248 37548 solver.cpp:236] Iteration 11500, loss = 1.05628
I0716 11:11:28.242753 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 11:11:28.242818 37548 solver.cpp:252]     Train net output #1: loss = 1.13863 (* 1 = 1.13863 loss)
I0716 11:11:29.183301 37548 sgd_solver.cpp:106] Iteration 11500, lr = 0.015
I0716 11:13:50.016701 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 11:15:18.111280 37548 solver.cpp:236] Iteration 11550, loss = 1.05124
I0716 11:15:18.111551 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 11:15:18.111595 37548 solver.cpp:252]     Train net output #1: loss = 0.993268 (* 1 = 0.993268 loss)
I0716 11:15:18.987866 37548 sgd_solver.cpp:106] Iteration 11550, lr = 0.015
I0716 11:19:03.422382 37548 solver.cpp:236] Iteration 11600, loss = 1.06196
I0716 11:19:03.422696 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 11:19:03.422732 37548 solver.cpp:252]     Train net output #1: loss = 1.17748 (* 1 = 1.17748 loss)
I0716 11:19:04.292316 37548 sgd_solver.cpp:106] Iteration 11600, lr = 0.015
I0716 11:22:49.692118 37548 solver.cpp:236] Iteration 11650, loss = 1.03769
I0716 11:22:49.692404 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 11:22:49.692463 37548 solver.cpp:252]     Train net output #1: loss = 0.933327 (* 1 = 0.933327 loss)
I0716 11:22:50.554376 37548 sgd_solver.cpp:106] Iteration 11650, lr = 0.015
I0716 11:26:33.672155 37548 solver.cpp:236] Iteration 11700, loss = 1.07076
I0716 11:26:33.672466 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 11:26:33.672525 37548 solver.cpp:252]     Train net output #1: loss = 1.15408 (* 1 = 1.15408 loss)
I0716 11:26:34.556838 37548 sgd_solver.cpp:106] Iteration 11700, lr = 0.015
I0716 11:30:19.824404 37548 solver.cpp:236] Iteration 11750, loss = 1.04627
I0716 11:30:19.824753 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 11:30:19.824800 37548 solver.cpp:252]     Train net output #1: loss = 1.02372 (* 1 = 1.02372 loss)
I0716 11:30:20.685756 37548 sgd_solver.cpp:106] Iteration 11750, lr = 0.015
I0716 11:34:05.684103 37548 solver.cpp:236] Iteration 11800, loss = 1.043
I0716 11:34:05.684377 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 11:34:05.684409 37548 solver.cpp:252]     Train net output #1: loss = 1.14413 (* 1 = 1.14413 loss)
I0716 11:34:06.655671 37548 sgd_solver.cpp:106] Iteration 11800, lr = 0.015
I0716 11:37:51.436715 37548 solver.cpp:236] Iteration 11850, loss = 1.07734
I0716 11:37:51.437086 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 11:37:51.437160 37548 solver.cpp:252]     Train net output #1: loss = 0.930806 (* 1 = 0.930806 loss)
I0716 11:37:52.357758 37548 sgd_solver.cpp:106] Iteration 11850, lr = 0.015
I0716 11:41:33.405987 37548 solver.cpp:236] Iteration 11900, loss = 1.07427
I0716 11:41:33.406280 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 11:41:33.406338 37548 solver.cpp:252]     Train net output #1: loss = 0.975434 (* 1 = 0.975434 loss)
I0716 11:41:34.350286 37548 sgd_solver.cpp:106] Iteration 11900, lr = 0.015
I0716 11:45:17.415102 37548 solver.cpp:236] Iteration 11950, loss = 1.05071
I0716 11:45:17.415349 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 11:45:17.415385 37548 solver.cpp:252]     Train net output #1: loss = 1.02041 (* 1 = 1.02041 loss)
I0716 11:45:18.362326 37548 sgd_solver.cpp:106] Iteration 11950, lr = 0.015
I0716 11:46:06.253626 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 11:49:02.865648 37548 solver.cpp:340] Iteration 12000, Testing net (#0)
I0716 12:12:16.998944 37548 solver.cpp:408]     Test net output #0: accuracy = 0.463667
I0716 12:12:17.010804 37548 solver.cpp:408]     Test net output #1: loss = 1.05968 (* 1 = 1.05968 loss)
I0716 12:12:19.868082 37548 solver.cpp:236] Iteration 12000, loss = 1.05155
I0716 12:12:19.868216 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 12:12:19.868255 37548 solver.cpp:252]     Train net output #1: loss = 1.05371 (* 1 = 1.05371 loss)
I0716 12:12:19.868371 37548 sgd_solver.cpp:106] Iteration 12000, lr = 0.015
I0716 12:16:02.061403 37548 solver.cpp:236] Iteration 12050, loss = 1.05161
I0716 12:16:02.072247 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 12:16:02.072307 37548 solver.cpp:252]     Train net output #1: loss = 0.986114 (* 1 = 0.986114 loss)
I0716 12:16:02.949874 37548 sgd_solver.cpp:106] Iteration 12050, lr = 0.015
I0716 12:19:47.756559 37548 solver.cpp:236] Iteration 12100, loss = 1.07166
I0716 12:19:47.756770 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 12:19:47.756829 37548 solver.cpp:252]     Train net output #1: loss = 1.02615 (* 1 = 1.02615 loss)
I0716 12:19:48.630707 37548 sgd_solver.cpp:106] Iteration 12100, lr = 0.015
I0716 12:23:28.552062 37548 solver.cpp:236] Iteration 12150, loss = 1.0914
I0716 12:23:28.552443 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 12:23:28.552507 37548 solver.cpp:252]     Train net output #1: loss = 1.13149 (* 1 = 1.13149 loss)
I0716 12:23:29.429100 37548 sgd_solver.cpp:106] Iteration 12150, lr = 0.015
I0716 12:27:13.626021 37548 solver.cpp:236] Iteration 12200, loss = 1.07068
I0716 12:27:13.626354 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 12:27:13.626389 37548 solver.cpp:252]     Train net output #1: loss = 1.14797 (* 1 = 1.14797 loss)
I0716 12:27:14.503376 37548 sgd_solver.cpp:106] Iteration 12200, lr = 0.015
I0716 12:30:52.789252 37548 solver.cpp:236] Iteration 12250, loss = 1.05908
I0716 12:30:52.789520 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 12:30:52.789561 37548 solver.cpp:252]     Train net output #1: loss = 1.06278 (* 1 = 1.06278 loss)
I0716 12:30:53.667145 37548 sgd_solver.cpp:106] Iteration 12250, lr = 0.015
I0716 12:34:34.452451 37548 solver.cpp:236] Iteration 12300, loss = 1.05506
I0716 12:34:34.452733 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 12:34:34.452787 37548 solver.cpp:252]     Train net output #1: loss = 1.22929 (* 1 = 1.22929 loss)
I0716 12:34:35.385201 37548 sgd_solver.cpp:106] Iteration 12300, lr = 0.015
I0716 12:38:15.213851 37548 solver.cpp:236] Iteration 12350, loss = 1.05136
I0716 12:38:15.232463 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 12:38:15.232523 37548 solver.cpp:252]     Train net output #1: loss = 0.918317 (* 1 = 0.918317 loss)
I0716 12:38:16.153735 37548 sgd_solver.cpp:106] Iteration 12350, lr = 0.015
I0716 12:41:55.270236 37548 solver.cpp:236] Iteration 12400, loss = 1.06305
I0716 12:41:55.270522 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 12:41:55.270555 37548 solver.cpp:252]     Train net output #1: loss = 0.913599 (* 1 = 0.913599 loss)
I0716 12:41:56.148672 37548 sgd_solver.cpp:106] Iteration 12400, lr = 0.015
I0716 12:42:20.743446 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 12:45:37.714282 37548 solver.cpp:236] Iteration 12450, loss = 1.073
I0716 12:45:37.714576 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 12:45:37.714612 37548 solver.cpp:252]     Train net output #1: loss = 1.05905 (* 1 = 1.05905 loss)
I0716 12:45:38.596752 37548 sgd_solver.cpp:106] Iteration 12450, lr = 0.015
I0716 12:49:25.003317 37548 solver.cpp:236] Iteration 12500, loss = 1.07101
I0716 12:49:25.003660 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 12:49:25.003695 37548 solver.cpp:252]     Train net output #1: loss = 0.828984 (* 1 = 0.828984 loss)
I0716 12:49:25.882896 37548 sgd_solver.cpp:106] Iteration 12500, lr = 0.015
I0716 12:53:17.086570 37548 solver.cpp:236] Iteration 12550, loss = 1.02983
I0716 12:53:17.086941 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 12:53:17.086992 37548 solver.cpp:252]     Train net output #1: loss = 1.06735 (* 1 = 1.06735 loss)
I0716 12:53:17.978889 37548 sgd_solver.cpp:106] Iteration 12550, lr = 0.015
I0716 12:57:01.200623 37548 solver.cpp:236] Iteration 12600, loss = 1.07997
I0716 12:57:01.200848 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 12:57:01.200882 37548 solver.cpp:252]     Train net output #1: loss = 1.03889 (* 1 = 1.03889 loss)
I0716 12:57:02.072787 37548 sgd_solver.cpp:106] Iteration 12600, lr = 0.015
I0716 13:00:45.324590 37548 solver.cpp:236] Iteration 12650, loss = 1.0504
I0716 13:00:45.324909 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 13:00:45.324946 37548 solver.cpp:252]     Train net output #1: loss = 1.04735 (* 1 = 1.04735 loss)
I0716 13:00:46.267244 37548 sgd_solver.cpp:106] Iteration 12650, lr = 0.015
I0716 13:04:33.006448 37548 solver.cpp:236] Iteration 12700, loss = 1.06172
I0716 13:04:33.006744 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:04:33.006790 37548 solver.cpp:252]     Train net output #1: loss = 1.14135 (* 1 = 1.14135 loss)
I0716 13:04:33.958345 37548 sgd_solver.cpp:106] Iteration 12700, lr = 0.015
I0716 13:08:13.144285 37548 solver.cpp:236] Iteration 12750, loss = 1.05058
I0716 13:08:13.144598 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:08:13.144639 37548 solver.cpp:252]     Train net output #1: loss = 1.14302 (* 1 = 1.14302 loss)
I0716 13:08:14.115689 37548 sgd_solver.cpp:106] Iteration 12750, lr = 0.015
I0716 13:11:55.925573 37548 solver.cpp:236] Iteration 12800, loss = 1.07545
I0716 13:11:55.925963 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:11:55.926023 37548 solver.cpp:252]     Train net output #1: loss = 1.06975 (* 1 = 1.06975 loss)
I0716 13:11:56.807284 37548 sgd_solver.cpp:106] Iteration 12800, lr = 0.015
I0716 13:14:56.595671 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 13:15:40.438263 37548 solver.cpp:236] Iteration 12850, loss = 1.0534
I0716 13:15:40.438513 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 13:15:40.438560 37548 solver.cpp:252]     Train net output #1: loss = 1.03799 (* 1 = 1.03799 loss)
I0716 13:15:41.316045 37548 sgd_solver.cpp:106] Iteration 12850, lr = 0.015
I0716 13:19:21.498610 37548 solver.cpp:236] Iteration 12900, loss = 1.06669
I0716 13:19:21.498898 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 13:19:21.498922 37548 solver.cpp:252]     Train net output #1: loss = 0.981305 (* 1 = 0.981305 loss)
I0716 13:19:22.454258 37548 sgd_solver.cpp:106] Iteration 12900, lr = 0.015
I0716 13:23:03.748961 37548 solver.cpp:236] Iteration 12950, loss = 1.04529
I0716 13:23:03.749214 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 13:23:03.749248 37548 solver.cpp:252]     Train net output #1: loss = 0.831623 (* 1 = 0.831623 loss)
I0716 13:23:04.693804 37548 sgd_solver.cpp:106] Iteration 12950, lr = 0.015
I0716 13:26:44.895326 37548 solver.cpp:236] Iteration 13000, loss = 1.1007
I0716 13:26:44.895545 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:26:44.895566 37548 solver.cpp:252]     Train net output #1: loss = 1.13003 (* 1 = 1.13003 loss)
I0716 13:26:45.768399 37548 sgd_solver.cpp:106] Iteration 13000, lr = 0.015
I0716 13:30:27.356202 37548 solver.cpp:236] Iteration 13050, loss = 1.03349
I0716 13:30:27.356611 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:30:27.356662 37548 solver.cpp:252]     Train net output #1: loss = 1.11795 (* 1 = 1.11795 loss)
I0716 13:30:28.290254 37548 sgd_solver.cpp:106] Iteration 13050, lr = 0.015
I0716 13:34:07.085791 37548 solver.cpp:236] Iteration 13100, loss = 1.03183
I0716 13:34:07.086055 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 13:34:07.086089 37548 solver.cpp:252]     Train net output #1: loss = 1.27452 (* 1 = 1.27452 loss)
I0716 13:34:08.023073 37548 sgd_solver.cpp:106] Iteration 13100, lr = 0.015
I0716 13:37:46.154536 37548 solver.cpp:236] Iteration 13150, loss = 1.07008
I0716 13:37:46.154919 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 13:37:46.155004 37548 solver.cpp:252]     Train net output #1: loss = 1.01821 (* 1 = 1.01821 loss)
I0716 13:37:47.030433 37548 sgd_solver.cpp:106] Iteration 13150, lr = 0.015
I0716 13:41:31.715140 37548 solver.cpp:236] Iteration 13200, loss = 1.04594
I0716 13:41:31.715678 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:41:31.715713 37548 solver.cpp:252]     Train net output #1: loss = 1.18231 (* 1 = 1.18231 loss)
I0716 13:41:32.586189 37548 sgd_solver.cpp:106] Iteration 13200, lr = 0.015
I0716 13:45:23.330627 37548 solver.cpp:236] Iteration 13250, loss = 1.03716
I0716 13:45:23.330896 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:45:23.330955 37548 solver.cpp:252]     Train net output #1: loss = 1.19136 (* 1 = 1.19136 loss)
I0716 13:45:24.279145 37548 sgd_solver.cpp:106] Iteration 13250, lr = 0.015
I0716 13:47:48.555953 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 13:49:08.569340 37548 solver.cpp:236] Iteration 13300, loss = 1.07
I0716 13:49:08.569588 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 13:49:08.569630 37548 solver.cpp:252]     Train net output #1: loss = 1.14749 (* 1 = 1.14749 loss)
I0716 13:49:09.451869 37548 sgd_solver.cpp:106] Iteration 13300, lr = 0.015
I0716 13:52:51.159721 37548 solver.cpp:236] Iteration 13350, loss = 1.0412
I0716 13:52:51.159906 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 13:52:51.159930 37548 solver.cpp:252]     Train net output #1: loss = 0.823166 (* 1 = 0.823166 loss)
I0716 13:52:52.098963 37548 sgd_solver.cpp:106] Iteration 13350, lr = 0.015
I0716 13:56:35.094728 37548 solver.cpp:236] Iteration 13400, loss = 1.08599
I0716 13:56:35.095125 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 13:56:35.095185 37548 solver.cpp:252]     Train net output #1: loss = 1.17435 (* 1 = 1.17435 loss)
I0716 13:56:36.024108 37548 sgd_solver.cpp:106] Iteration 13400, lr = 0.015
I0716 14:00:24.076311 37548 solver.cpp:236] Iteration 13450, loss = 1.05569
I0716 14:00:24.076601 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 14:00:24.076635 37548 solver.cpp:252]     Train net output #1: loss = 0.966789 (* 1 = 0.966789 loss)
I0716 14:00:24.964818 37548 sgd_solver.cpp:106] Iteration 13450, lr = 0.015
I0716 14:04:02.566534 37548 solver.cpp:340] Iteration 13500, Testing net (#0)
I0716 14:27:16.596513 37548 solver.cpp:408]     Test net output #0: accuracy = 0.471
I0716 14:27:16.596848 37548 solver.cpp:408]     Test net output #1: loss = 1.06232 (* 1 = 1.06232 loss)
I0716 14:27:19.450752 37548 solver.cpp:236] Iteration 13500, loss = 1.07176
I0716 14:27:19.450824 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 14:27:19.450861 37548 solver.cpp:252]     Train net output #1: loss = 0.986466 (* 1 = 0.986466 loss)
I0716 14:27:19.450942 37548 sgd_solver.cpp:106] Iteration 13500, lr = 0.015
I0716 14:30:59.434348 37548 solver.cpp:236] Iteration 13550, loss = 1.05112
I0716 14:30:59.434692 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 14:30:59.434798 37548 solver.cpp:252]     Train net output #1: loss = 0.883363 (* 1 = 0.883363 loss)
I0716 14:31:00.395666 37548 sgd_solver.cpp:106] Iteration 13550, lr = 0.015
I0716 14:34:40.424636 37548 solver.cpp:236] Iteration 13600, loss = 1.05054
I0716 14:34:40.424996 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 14:34:40.425036 37548 solver.cpp:252]     Train net output #1: loss = 0.978851 (* 1 = 0.978851 loss)
I0716 14:34:41.302723 37548 sgd_solver.cpp:106] Iteration 13600, lr = 0.015
I0716 14:38:17.167551 37548 solver.cpp:236] Iteration 13650, loss = 1.04467
I0716 14:38:17.178726 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 14:38:17.178766 37548 solver.cpp:252]     Train net output #1: loss = 1.09269 (* 1 = 1.09269 loss)
I0716 14:38:18.115872 37548 sgd_solver.cpp:106] Iteration 13650, lr = 0.015
I0716 14:42:01.284960 37548 solver.cpp:236] Iteration 13700, loss = 1.07495
I0716 14:42:01.285188 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 14:42:01.285238 37548 solver.cpp:252]     Train net output #1: loss = 0.991501 (* 1 = 0.991501 loss)
I0716 14:42:02.233862 37548 sgd_solver.cpp:106] Iteration 13700, lr = 0.015
I0716 14:44:21.955253 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 14:45:47.540563 37548 solver.cpp:236] Iteration 13750, loss = 1.0881
I0716 14:45:47.540804 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 14:45:47.540843 37548 solver.cpp:252]     Train net output #1: loss = 1.12151 (* 1 = 1.12151 loss)
I0716 14:45:48.490581 37548 sgd_solver.cpp:106] Iteration 13750, lr = 0.015
I0716 14:49:28.457542 37548 solver.cpp:236] Iteration 13800, loss = 1.05526
I0716 14:49:28.457792 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 14:49:28.457834 37548 solver.cpp:252]     Train net output #1: loss = 0.924574 (* 1 = 0.924574 loss)
I0716 14:49:29.410380 37548 sgd_solver.cpp:106] Iteration 13800, lr = 0.015
I0716 14:53:16.824679 37548 solver.cpp:236] Iteration 13850, loss = 1.04681
I0716 14:53:16.824990 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 14:53:16.825026 37548 solver.cpp:252]     Train net output #1: loss = 1.02494 (* 1 = 1.02494 loss)
I0716 14:53:17.712544 37548 sgd_solver.cpp:106] Iteration 13850, lr = 0.015
I0716 14:57:06.601336 37548 solver.cpp:236] Iteration 13900, loss = 1.06887
I0716 14:57:06.601840 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 14:57:06.601927 37548 solver.cpp:252]     Train net output #1: loss = 1.10631 (* 1 = 1.10631 loss)
I0716 14:57:07.546243 37548 sgd_solver.cpp:106] Iteration 13900, lr = 0.015
I0716 15:00:53.105350 37548 solver.cpp:236] Iteration 13950, loss = 1.04605
I0716 15:00:53.105583 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 15:00:53.105621 37548 solver.cpp:252]     Train net output #1: loss = 1.29214 (* 1 = 1.29214 loss)
I0716 15:00:54.057423 37548 sgd_solver.cpp:106] Iteration 13950, lr = 0.015
I0716 15:04:32.581691 37548 solver.cpp:236] Iteration 14000, loss = 1.06141
I0716 15:04:32.859254 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 15:04:32.859302 37548 solver.cpp:252]     Train net output #1: loss = 1.1398 (* 1 = 1.1398 loss)
I0716 15:04:33.523778 37548 sgd_solver.cpp:106] Iteration 14000, lr = 0.015
I0716 15:08:07.953274 37548 solver.cpp:236] Iteration 14050, loss = 1.07905
I0716 15:08:07.953536 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 15:08:07.953567 37548 solver.cpp:252]     Train net output #1: loss = 1.08285 (* 1 = 1.08285 loss)
I0716 15:08:08.836524 37548 sgd_solver.cpp:106] Iteration 14050, lr = 0.015
I0716 15:11:40.033946 37548 solver.cpp:236] Iteration 14100, loss = 1.06313
I0716 15:11:40.034198 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 15:11:40.034234 37548 solver.cpp:252]     Train net output #1: loss = 0.974633 (* 1 = 0.974633 loss)
I0716 15:11:40.998080 37548 sgd_solver.cpp:106] Iteration 14100, lr = 0.015
I0716 15:15:21.425253 37548 solver.cpp:236] Iteration 14150, loss = 1.07844
I0716 15:15:21.425618 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 15:15:21.425659 37548 solver.cpp:252]     Train net output #1: loss = 1.12204 (* 1 = 1.12204 loss)
I0716 15:15:22.305528 37548 sgd_solver.cpp:106] Iteration 14150, lr = 0.015
I0716 15:16:40.942602 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 15:19:07.979835 37548 solver.cpp:236] Iteration 14200, loss = 1.03751
I0716 15:19:07.980128 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 15:19:07.980187 37548 solver.cpp:252]     Train net output #1: loss = 0.885316 (* 1 = 0.885316 loss)
I0716 15:19:08.917543 37548 sgd_solver.cpp:106] Iteration 14200, lr = 0.015
I0716 15:22:54.180899 37548 solver.cpp:236] Iteration 14250, loss = 1.05627
I0716 15:22:54.181200 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0716 15:22:54.181260 37548 solver.cpp:252]     Train net output #1: loss = 0.827504 (* 1 = 0.827504 loss)
I0716 15:22:55.051470 37548 sgd_solver.cpp:106] Iteration 14250, lr = 0.015
I0716 15:26:36.048110 37548 solver.cpp:236] Iteration 14300, loss = 1.07012
I0716 15:26:36.048557 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0716 15:26:36.048595 37548 solver.cpp:252]     Train net output #1: loss = 0.794823 (* 1 = 0.794823 loss)
I0716 15:26:37.004159 37548 sgd_solver.cpp:106] Iteration 14300, lr = 0.015
I0716 15:30:27.312676 37548 solver.cpp:236] Iteration 14350, loss = 1.05014
I0716 15:30:27.326021 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 15:30:27.326062 37548 solver.cpp:252]     Train net output #1: loss = 0.974893 (* 1 = 0.974893 loss)
I0716 15:30:28.196425 37548 sgd_solver.cpp:106] Iteration 14350, lr = 0.015
I0716 15:34:17.449357 37548 solver.cpp:236] Iteration 14400, loss = 1.06783
I0716 15:34:17.449728 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 15:34:17.449831 37548 solver.cpp:252]     Train net output #1: loss = 1.13969 (* 1 = 1.13969 loss)
I0716 15:34:18.443999 37548 sgd_solver.cpp:106] Iteration 14400, lr = 0.015
I0716 15:38:00.093648 37548 solver.cpp:236] Iteration 14450, loss = 1.03561
I0716 15:38:00.093950 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 15:38:00.093997 37548 solver.cpp:252]     Train net output #1: loss = 1.12405 (* 1 = 1.12405 loss)
I0716 15:38:00.978220 37548 sgd_solver.cpp:106] Iteration 14450, lr = 0.015
I0716 15:41:45.228473 37548 solver.cpp:236] Iteration 14500, loss = 1.07746
I0716 15:41:45.243779 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 15:41:45.243883 37548 solver.cpp:252]     Train net output #1: loss = 0.934944 (* 1 = 0.934944 loss)
I0716 15:41:46.179973 37548 sgd_solver.cpp:106] Iteration 14500, lr = 0.015
I0716 15:45:32.221038 37548 solver.cpp:236] Iteration 14550, loss = 1.04854
I0716 15:45:32.221294 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 15:45:32.221333 37548 solver.cpp:252]     Train net output #1: loss = 1.00594 (* 1 = 1.00594 loss)
I0716 15:45:33.103729 37548 sgd_solver.cpp:106] Iteration 14550, lr = 0.015
I0716 15:48:46.428977 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 15:49:12.058296 37548 solver.cpp:236] Iteration 14600, loss = 1.06016
I0716 15:49:12.058491 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 15:49:12.058606 37548 solver.cpp:252]     Train net output #1: loss = 0.997941 (* 1 = 0.997941 loss)
I0716 15:49:12.941829 37548 sgd_solver.cpp:106] Iteration 14600, lr = 0.015
I0716 15:53:00.044178 37548 solver.cpp:236] Iteration 14650, loss = 1.03624
I0716 15:53:00.044560 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 15:53:00.044631 37548 solver.cpp:252]     Train net output #1: loss = 0.939422 (* 1 = 0.939422 loss)
I0716 15:53:01.068369 37548 sgd_solver.cpp:106] Iteration 14650, lr = 0.015
I0716 15:56:42.470399 37548 solver.cpp:236] Iteration 14700, loss = 1.08541
I0716 15:56:42.471170 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 15:56:42.471236 37548 solver.cpp:252]     Train net output #1: loss = 1.18437 (* 1 = 1.18437 loss)
I0716 15:56:43.425673 37548 sgd_solver.cpp:106] Iteration 14700, lr = 0.015
I0716 16:00:26.366511 37548 solver.cpp:236] Iteration 14750, loss = 1.07694
I0716 16:00:26.366996 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 16:00:26.367019 37548 solver.cpp:252]     Train net output #1: loss = 0.994778 (* 1 = 0.994778 loss)
I0716 16:00:27.244082 37548 sgd_solver.cpp:106] Iteration 14750, lr = 0.015
I0716 16:04:07.729105 37548 solver.cpp:236] Iteration 14800, loss = 1.07589
I0716 16:04:07.729390 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0716 16:04:07.729467 37548 solver.cpp:252]     Train net output #1: loss = 0.93103 (* 1 = 0.93103 loss)
I0716 16:04:08.601735 37548 sgd_solver.cpp:106] Iteration 14800, lr = 0.015
I0716 16:07:47.221071 37548 solver.cpp:236] Iteration 14850, loss = 1.06019
I0716 16:07:47.221526 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 16:07:47.221614 37548 solver.cpp:252]     Train net output #1: loss = 1.10579 (* 1 = 1.10579 loss)
I0716 16:07:48.148756 37548 sgd_solver.cpp:106] Iteration 14850, lr = 0.015
I0716 16:11:31.393688 37548 solver.cpp:236] Iteration 14900, loss = 1.0408
I0716 16:11:31.394045 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 16:11:31.394073 37548 solver.cpp:252]     Train net output #1: loss = 1.00169 (* 1 = 1.00169 loss)
I0716 16:11:32.269074 37548 sgd_solver.cpp:106] Iteration 14900, lr = 0.015
I0716 16:15:09.230448 37548 solver.cpp:236] Iteration 14950, loss = 1.05994
I0716 16:15:09.236721 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 16:15:09.236804 37548 solver.cpp:252]     Train net output #1: loss = 1.02187 (* 1 = 1.02187 loss)
I0716 16:15:10.110808 37548 sgd_solver.cpp:106] Iteration 14950, lr = 0.015
I0716 16:18:43.868614 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_15000.caffemodel
I0716 16:18:45.325951 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_15000.solverstate
I0716 16:18:45.393909 37548 solver.cpp:340] Iteration 15000, Testing net (#0)
I0716 16:41:59.393496 37548 solver.cpp:408]     Test net output #0: accuracy = 0.45
I0716 16:41:59.425696 37548 solver.cpp:408]     Test net output #1: loss = 1.07171 (* 1 = 1.07171 loss)
I0716 16:42:02.289350 37548 solver.cpp:236] Iteration 15000, loss = 1.06826
I0716 16:42:02.289423 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 16:42:02.289444 37548 solver.cpp:252]     Train net output #1: loss = 1.00306 (* 1 = 1.00306 loss)
I0716 16:42:02.289492 37548 sgd_solver.cpp:106] Iteration 15000, lr = 0.015
I0716 16:44:24.830819 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 16:45:48.291551 37548 solver.cpp:236] Iteration 15050, loss = 1.06438
I0716 16:45:48.291956 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 16:45:48.292013 37548 solver.cpp:252]     Train net output #1: loss = 1.30706 (* 1 = 1.30706 loss)
I0716 16:45:49.190747 37548 sgd_solver.cpp:106] Iteration 15050, lr = 0.015
I0716 16:49:26.623920 37548 solver.cpp:236] Iteration 15100, loss = 1.06357
I0716 16:49:26.673100 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 16:49:26.673166 37548 solver.cpp:252]     Train net output #1: loss = 0.965464 (* 1 = 0.965464 loss)
I0716 16:49:27.497874 37548 sgd_solver.cpp:106] Iteration 15100, lr = 0.015
I0716 16:53:08.622119 37548 solver.cpp:236] Iteration 15150, loss = 1.07035
I0716 16:53:08.626729 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 16:53:08.626816 37548 solver.cpp:252]     Train net output #1: loss = 1.07455 (* 1 = 1.07455 loss)
I0716 16:53:09.595458 37548 sgd_solver.cpp:106] Iteration 15150, lr = 0.015
I0716 16:56:54.367780 37548 solver.cpp:236] Iteration 15200, loss = 1.07296
I0716 16:56:54.368072 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 16:56:54.368098 37548 solver.cpp:252]     Train net output #1: loss = 0.97904 (* 1 = 0.97904 loss)
I0716 16:56:55.323882 37548 sgd_solver.cpp:106] Iteration 15200, lr = 0.015
I0716 17:00:44.455025 37548 solver.cpp:236] Iteration 15250, loss = 1.05444
I0716 17:00:44.468799 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0716 17:00:44.468845 37548 solver.cpp:252]     Train net output #1: loss = 0.642806 (* 1 = 0.642806 loss)
I0716 17:00:45.420595 37548 sgd_solver.cpp:106] Iteration 15250, lr = 0.015
I0716 17:04:31.490674 37548 solver.cpp:236] Iteration 15300, loss = 1.06843
I0716 17:04:31.490998 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 17:04:31.491035 37548 solver.cpp:252]     Train net output #1: loss = 1.02186 (* 1 = 1.02186 loss)
I0716 17:04:32.415554 37548 sgd_solver.cpp:106] Iteration 15300, lr = 0.015
I0716 17:08:15.390527 37548 solver.cpp:236] Iteration 15350, loss = 1.05657
I0716 17:08:15.398739 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 17:08:15.398823 37548 solver.cpp:252]     Train net output #1: loss = 1.02809 (* 1 = 1.02809 loss)
I0716 17:08:16.342556 37548 sgd_solver.cpp:106] Iteration 15350, lr = 0.015
I0716 17:12:03.864539 37548 solver.cpp:236] Iteration 15400, loss = 1.0914
I0716 17:12:03.864822 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 17:12:03.864920 37548 solver.cpp:252]     Train net output #1: loss = 1.03034 (* 1 = 1.03034 loss)
I0716 17:12:04.799430 37548 sgd_solver.cpp:106] Iteration 15400, lr = 0.015
I0716 17:15:52.884562 37548 solver.cpp:236] Iteration 15450, loss = 1.04646
I0716 17:15:52.884799 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 17:15:52.884840 37548 solver.cpp:252]     Train net output #1: loss = 1.06065 (* 1 = 1.06065 loss)
I0716 17:15:53.762279 37548 sgd_solver.cpp:106] Iteration 15450, lr = 0.015
I0716 17:16:24.797509 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 17:19:36.537968 37548 solver.cpp:236] Iteration 15500, loss = 1.0728
I0716 17:19:36.538236 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 17:19:36.538286 37548 solver.cpp:252]     Train net output #1: loss = 1.11441 (* 1 = 1.11441 loss)
I0716 17:19:37.421986 37548 sgd_solver.cpp:106] Iteration 15500, lr = 0.015
I0716 17:23:21.521615 37548 solver.cpp:236] Iteration 15550, loss = 1.06269
I0716 17:23:21.521966 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 17:23:21.522078 37548 solver.cpp:252]     Train net output #1: loss = 0.971268 (* 1 = 0.971268 loss)
I0716 17:23:22.400046 37548 sgd_solver.cpp:106] Iteration 15550, lr = 0.015
I0716 17:27:11.372761 37548 solver.cpp:236] Iteration 15600, loss = 1.08023
I0716 17:27:11.373046 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 17:27:11.373098 37548 solver.cpp:252]     Train net output #1: loss = 0.965875 (* 1 = 0.965875 loss)
I0716 17:27:12.303088 37548 sgd_solver.cpp:106] Iteration 15600, lr = 0.015
I0716 17:30:55.417088 37548 solver.cpp:236] Iteration 15650, loss = 1.07423
I0716 17:30:55.417407 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 17:30:55.417464 37548 solver.cpp:252]     Train net output #1: loss = 0.977897 (* 1 = 0.977897 loss)
I0716 17:30:56.363188 37548 sgd_solver.cpp:106] Iteration 15650, lr = 0.015
I0716 17:34:37.375875 37548 solver.cpp:236] Iteration 15700, loss = 1.05119
I0716 17:34:37.376199 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 17:34:37.376266 37548 solver.cpp:252]     Train net output #1: loss = 1.22206 (* 1 = 1.22206 loss)
I0716 17:34:38.257666 37548 sgd_solver.cpp:106] Iteration 15700, lr = 0.015
I0716 17:38:50.730600 37548 solver.cpp:236] Iteration 15750, loss = 1.09464
I0716 17:38:50.731091 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 17:38:50.731183 37548 solver.cpp:252]     Train net output #1: loss = 1.08784 (* 1 = 1.08784 loss)
I0716 17:38:51.682484 37548 sgd_solver.cpp:106] Iteration 15750, lr = 0.015
I0716 17:43:03.450346 37548 solver.cpp:236] Iteration 15800, loss = 1.06343
I0716 17:43:03.451143 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 17:43:03.451325 37548 solver.cpp:252]     Train net output #1: loss = 1.09639 (* 1 = 1.09639 loss)
I0716 17:43:04.398937 37548 sgd_solver.cpp:106] Iteration 15800, lr = 0.015
I0716 17:47:17.309834 37548 solver.cpp:236] Iteration 15850, loss = 1.04779
I0716 17:47:17.310212 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 17:47:17.310276 37548 solver.cpp:252]     Train net output #1: loss = 0.832724 (* 1 = 0.832724 loss)
I0716 17:47:18.186328 37548 sgd_solver.cpp:106] Iteration 15850, lr = 0.015
I0716 17:47:59.559780 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 17:51:29.768683 37548 solver.cpp:236] Iteration 15900, loss = 1.07883
I0716 17:51:29.769011 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 17:51:29.769078 37548 solver.cpp:252]     Train net output #1: loss = 1.15915 (* 1 = 1.15915 loss)
I0716 17:51:30.727720 37548 sgd_solver.cpp:106] Iteration 15900, lr = 0.015
I0716 17:55:42.732228 37548 solver.cpp:236] Iteration 15950, loss = 1.05464
I0716 17:55:42.732523 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 17:55:42.732571 37548 solver.cpp:252]     Train net output #1: loss = 1.19092 (* 1 = 1.19092 loss)
I0716 17:55:43.606591 37548 sgd_solver.cpp:106] Iteration 15950, lr = 0.015
I0716 17:59:57.334005 37548 solver.cpp:236] Iteration 16000, loss = 1.03822
I0716 17:59:57.334381 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 17:59:57.334419 37548 solver.cpp:252]     Train net output #1: loss = 1.18028 (* 1 = 1.18028 loss)
I0716 17:59:58.280680 37548 sgd_solver.cpp:106] Iteration 16000, lr = 0.015
I0716 18:04:19.870793 37548 solver.cpp:236] Iteration 16050, loss = 1.07859
I0716 18:04:19.891139 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 18:04:19.891250 37548 solver.cpp:252]     Train net output #1: loss = 1.03517 (* 1 = 1.03517 loss)
I0716 18:04:20.744846 37548 sgd_solver.cpp:106] Iteration 16050, lr = 0.015
I0716 18:08:25.149029 37548 solver.cpp:236] Iteration 16100, loss = 1.07248
I0716 18:08:25.175766 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 18:08:25.175894 37548 solver.cpp:252]     Train net output #1: loss = 1.13795 (* 1 = 1.13795 loss)
I0716 18:08:26.039958 37548 sgd_solver.cpp:106] Iteration 16100, lr = 0.015
I0716 18:12:41.584815 37548 solver.cpp:236] Iteration 16150, loss = 1.08127
I0716 18:12:41.604624 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 18:12:41.604701 37548 solver.cpp:252]     Train net output #1: loss = 1.23956 (* 1 = 1.23956 loss)
I0716 18:12:42.476114 37548 sgd_solver.cpp:106] Iteration 16150, lr = 0.015
I0716 18:16:51.427084 37548 solver.cpp:236] Iteration 16200, loss = 1.08092
I0716 18:16:51.445245 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 18:16:51.445291 37548 solver.cpp:252]     Train net output #1: loss = 1.06127 (* 1 = 1.06127 loss)
I0716 18:16:52.368211 37548 sgd_solver.cpp:106] Iteration 16200, lr = 0.015
I0716 18:18:52.235658 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 18:21:10.060178 37548 solver.cpp:236] Iteration 16250, loss = 1.07119
I0716 18:21:10.060566 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 18:21:10.060617 37548 solver.cpp:252]     Train net output #1: loss = 0.882241 (* 1 = 0.882241 loss)
I0716 18:21:10.954977 37548 sgd_solver.cpp:106] Iteration 16250, lr = 0.015
I0716 18:25:27.830235 37548 solver.cpp:236] Iteration 16300, loss = 1.04924
I0716 18:25:27.830555 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 18:25:27.830615 37548 solver.cpp:252]     Train net output #1: loss = 0.928982 (* 1 = 0.928982 loss)
I0716 18:25:28.747665 37548 sgd_solver.cpp:106] Iteration 16300, lr = 0.015
I0716 18:29:39.539517 37548 solver.cpp:236] Iteration 16350, loss = 1.04233
I0716 18:29:39.557788 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 18:29:39.557844 37548 solver.cpp:252]     Train net output #1: loss = 1.01946 (* 1 = 1.01946 loss)
I0716 18:29:40.477458 37548 sgd_solver.cpp:106] Iteration 16350, lr = 0.015
I0716 18:33:54.384007 37548 solver.cpp:236] Iteration 16400, loss = 1.07053
I0716 18:33:54.404232 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 18:33:54.404364 37548 solver.cpp:252]     Train net output #1: loss = 1.06228 (* 1 = 1.06228 loss)
I0716 18:33:55.331421 37548 sgd_solver.cpp:106] Iteration 16400, lr = 0.015
I0716 18:38:05.952811 37548 solver.cpp:236] Iteration 16450, loss = 1.0539
I0716 18:38:05.977488 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 18:38:05.977608 37548 solver.cpp:252]     Train net output #1: loss = 0.973065 (* 1 = 0.973065 loss)
I0716 18:38:06.903368 37548 sgd_solver.cpp:106] Iteration 16450, lr = 0.015
I0716 18:42:09.984287 37548 solver.cpp:340] Iteration 16500, Testing net (#0)
I0716 19:05:24.119868 37548 solver.cpp:408]     Test net output #0: accuracy = 0.468333
I0716 19:05:24.159174 37548 solver.cpp:408]     Test net output #1: loss = 1.05743 (* 1 = 1.05743 loss)
I0716 19:05:27.052762 37548 solver.cpp:236] Iteration 16500, loss = 1.07864
I0716 19:05:27.052846 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 19:05:27.052886 37548 solver.cpp:252]     Train net output #1: loss = 1.11201 (* 1 = 1.11201 loss)
I0716 19:05:27.054198 37548 sgd_solver.cpp:106] Iteration 16500, lr = 0.015
I0716 19:09:21.221621 37548 solver.cpp:236] Iteration 16550, loss = 1.08614
I0716 19:09:21.249985 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 19:09:21.250092 37548 solver.cpp:252]     Train net output #1: loss = 0.949735 (* 1 = 0.949735 loss)
I0716 19:09:22.105947 37548 sgd_solver.cpp:106] Iteration 16550, lr = 0.015
I0716 19:12:46.184206 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 19:13:12.762070 37548 solver.cpp:236] Iteration 16600, loss = 1.04732
I0716 19:13:12.762150 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 19:13:12.762171 37548 solver.cpp:252]     Train net output #1: loss = 0.909749 (* 1 = 0.909749 loss)
I0716 19:13:13.645936 37548 sgd_solver.cpp:106] Iteration 16600, lr = 0.015
I0716 19:17:04.905694 37548 solver.cpp:236] Iteration 16650, loss = 1.07186
I0716 19:17:04.906147 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 19:17:04.906267 37548 solver.cpp:252]     Train net output #1: loss = 1.15207 (* 1 = 1.15207 loss)
I0716 19:17:05.861546 37548 sgd_solver.cpp:106] Iteration 16650, lr = 0.015
I0716 19:20:52.910411 37548 solver.cpp:236] Iteration 16700, loss = 1.05061
I0716 19:20:52.910869 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 19:20:52.910935 37548 solver.cpp:252]     Train net output #1: loss = 0.979389 (* 1 = 0.979389 loss)
I0716 19:20:53.791802 37548 sgd_solver.cpp:106] Iteration 16700, lr = 0.015
I0716 19:24:39.187252 37548 solver.cpp:236] Iteration 16750, loss = 1.03933
I0716 19:24:39.211400 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 19:24:39.211447 37548 solver.cpp:252]     Train net output #1: loss = 1.01768 (* 1 = 1.01768 loss)
I0716 19:24:40.126760 37548 sgd_solver.cpp:106] Iteration 16750, lr = 0.015
I0716 19:28:33.215570 37548 solver.cpp:236] Iteration 16800, loss = 1.06767
I0716 19:28:33.227244 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 19:28:33.227424 37548 solver.cpp:252]     Train net output #1: loss = 1.12315 (* 1 = 1.12315 loss)
I0716 19:28:34.101222 37548 sgd_solver.cpp:106] Iteration 16800, lr = 0.015
I0716 19:32:28.258246 37548 solver.cpp:236] Iteration 16850, loss = 1.0863
I0716 19:32:28.258870 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 19:32:28.258971 37548 solver.cpp:252]     Train net output #1: loss = 0.951922 (* 1 = 0.951922 loss)
I0716 19:32:29.141975 37548 sgd_solver.cpp:106] Iteration 16850, lr = 0.015
I0716 19:36:17.637467 37548 solver.cpp:236] Iteration 16900, loss = 1.0864
I0716 19:36:17.637965 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 19:36:17.638006 37548 solver.cpp:252]     Train net output #1: loss = 0.975163 (* 1 = 0.975163 loss)
I0716 19:36:18.534919 37548 sgd_solver.cpp:106] Iteration 16900, lr = 0.015
I0716 19:40:11.583385 37548 solver.cpp:236] Iteration 16950, loss = 1.07749
I0716 19:40:11.583653 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 19:40:11.583686 37548 solver.cpp:252]     Train net output #1: loss = 1.06224 (* 1 = 1.06224 loss)
I0716 19:40:12.480011 37548 sgd_solver.cpp:106] Iteration 16950, lr = 0.015
I0716 19:44:06.522683 37548 solver.cpp:236] Iteration 17000, loss = 1.05956
I0716 19:44:06.523052 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 19:44:06.523087 37548 solver.cpp:252]     Train net output #1: loss = 0.836704 (* 1 = 0.836704 loss)
I0716 19:44:07.401757 37548 sgd_solver.cpp:106] Iteration 17000, lr = 0.015
I0716 19:44:07.438746 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 19:47:59.597192 37548 solver.cpp:236] Iteration 17050, loss = 1.06004
I0716 19:47:59.597503 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 19:47:59.597540 37548 solver.cpp:252]     Train net output #1: loss = 1.06471 (* 1 = 1.06471 loss)
I0716 19:48:00.477738 37548 sgd_solver.cpp:106] Iteration 17050, lr = 0.015
I0716 19:51:47.914414 37548 solver.cpp:236] Iteration 17100, loss = 1.0576
I0716 19:51:47.914800 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 19:51:47.914907 37548 solver.cpp:252]     Train net output #1: loss = 1.25291 (* 1 = 1.25291 loss)
I0716 19:51:48.877694 37548 sgd_solver.cpp:106] Iteration 17100, lr = 0.015
I0716 19:55:37.141152 37548 solver.cpp:236] Iteration 17150, loss = 1.06596
I0716 19:55:37.155941 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 19:55:37.156007 37548 solver.cpp:252]     Train net output #1: loss = 1.09165 (* 1 = 1.09165 loss)
I0716 19:55:38.054605 37548 sgd_solver.cpp:106] Iteration 17150, lr = 0.015
I0716 19:59:22.819885 37548 solver.cpp:236] Iteration 17200, loss = 1.06098
I0716 19:59:22.842182 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 19:59:22.842391 37548 solver.cpp:252]     Train net output #1: loss = 0.987327 (* 1 = 0.987327 loss)
I0716 19:59:23.706135 37548 sgd_solver.cpp:106] Iteration 17200, lr = 0.015
I0716 20:03:21.016383 37548 solver.cpp:236] Iteration 17250, loss = 1.06523
I0716 20:03:21.016736 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:03:21.016790 37548 solver.cpp:252]     Train net output #1: loss = 1.0291 (* 1 = 1.0291 loss)
I0716 20:03:21.961921 37548 sgd_solver.cpp:106] Iteration 17250, lr = 0.015
I0716 20:07:22.122946 37548 solver.cpp:236] Iteration 17300, loss = 1.05716
I0716 20:07:22.123193 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:07:22.123224 37548 solver.cpp:252]     Train net output #1: loss = 1.02821 (* 1 = 1.02821 loss)
I0716 20:07:23.007277 37548 sgd_solver.cpp:106] Iteration 17300, lr = 0.015
I0716 20:11:14.421068 37548 solver.cpp:236] Iteration 17350, loss = 1.04996
I0716 20:11:14.421315 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 20:11:14.421355 37548 solver.cpp:252]     Train net output #1: loss = 1.13589 (* 1 = 1.13589 loss)
I0716 20:11:15.297185 37548 sgd_solver.cpp:106] Iteration 17350, lr = 0.015
I0716 20:15:03.553004 37548 solver.cpp:236] Iteration 17400, loss = 1.04725
I0716 20:15:03.553236 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 20:15:03.553262 37548 solver.cpp:252]     Train net output #1: loss = 1.06918 (* 1 = 1.06918 loss)
I0716 20:15:04.503598 37548 sgd_solver.cpp:106] Iteration 17400, lr = 0.015
I0716 20:15:33.647842 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 20:18:58.490450 37548 solver.cpp:236] Iteration 17450, loss = 1.07536
I0716 20:18:58.490906 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:18:58.491021 37548 solver.cpp:252]     Train net output #1: loss = 1.02557 (* 1 = 1.02557 loss)
I0716 20:18:59.376648 37548 sgd_solver.cpp:106] Iteration 17450, lr = 0.015
I0716 20:22:49.137316 37548 solver.cpp:236] Iteration 17500, loss = 1.08599
I0716 20:22:49.137503 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 20:22:49.137527 37548 solver.cpp:252]     Train net output #1: loss = 1.15945 (* 1 = 1.15945 loss)
I0716 20:22:50.159541 37548 sgd_solver.cpp:106] Iteration 17500, lr = 0.015
I0716 20:26:38.439945 37548 solver.cpp:236] Iteration 17550, loss = 1.07393
I0716 20:26:38.440371 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 20:26:38.440407 37548 solver.cpp:252]     Train net output #1: loss = 0.954736 (* 1 = 0.954736 loss)
I0716 20:26:39.308125 37548 sgd_solver.cpp:106] Iteration 17550, lr = 0.015
I0716 20:30:31.331982 37548 solver.cpp:236] Iteration 17600, loss = 1.06825
I0716 20:30:31.332378 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:30:31.332442 37548 solver.cpp:252]     Train net output #1: loss = 1.15594 (* 1 = 1.15594 loss)
I0716 20:30:32.287065 37548 sgd_solver.cpp:106] Iteration 17600, lr = 0.015
I0716 20:34:23.682098 37548 solver.cpp:236] Iteration 17650, loss = 1.04303
I0716 20:34:23.682564 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:34:23.682687 37548 solver.cpp:252]     Train net output #1: loss = 1.02122 (* 1 = 1.02122 loss)
I0716 20:34:24.628023 37548 sgd_solver.cpp:106] Iteration 17650, lr = 0.015
I0716 20:38:18.217288 37548 solver.cpp:236] Iteration 17700, loss = 1.07094
I0716 20:38:18.217830 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 20:38:18.217911 37548 solver.cpp:252]     Train net output #1: loss = 1.12384 (* 1 = 1.12384 loss)
I0716 20:38:19.161604 37548 sgd_solver.cpp:106] Iteration 17700, lr = 0.015
I0716 20:42:05.215816 37548 solver.cpp:236] Iteration 17750, loss = 1.03709
I0716 20:42:05.218930 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 20:42:05.218988 37548 solver.cpp:252]     Train net output #1: loss = 0.805134 (* 1 = 0.805134 loss)
I0716 20:42:06.081603 37548 sgd_solver.cpp:106] Iteration 17750, lr = 0.015
I0716 20:45:53.520848 37548 solver.cpp:236] Iteration 17800, loss = 1.05238
I0716 20:45:53.521075 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:45:53.521096 37548 solver.cpp:252]     Train net output #1: loss = 0.970742 (* 1 = 0.970742 loss)
I0716 20:45:54.464573 37548 sgd_solver.cpp:106] Iteration 17800, lr = 0.015
I0716 20:46:59.712393 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 20:49:43.178014 37548 solver.cpp:236] Iteration 17850, loss = 1.05945
I0716 20:49:43.178223 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:49:43.178249 37548 solver.cpp:252]     Train net output #1: loss = 1.03526 (* 1 = 1.03526 loss)
I0716 20:49:44.062847 37548 sgd_solver.cpp:106] Iteration 17850, lr = 0.015
I0716 20:53:36.168113 37548 solver.cpp:236] Iteration 17900, loss = 1.06555
I0716 20:53:36.168486 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 20:53:36.168526 37548 solver.cpp:252]     Train net output #1: loss = 0.950734 (* 1 = 0.950734 loss)
I0716 20:53:37.048949 37548 sgd_solver.cpp:106] Iteration 17900, lr = 0.015
I0716 20:57:27.035029 37548 solver.cpp:236] Iteration 17950, loss = 1.06862
I0716 20:57:27.035275 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 20:57:27.035336 37548 solver.cpp:252]     Train net output #1: loss = 0.861422 (* 1 = 0.861422 loss)
I0716 20:57:27.912888 37548 sgd_solver.cpp:106] Iteration 17950, lr = 0.015
I0716 21:01:17.255192 37548 solver.cpp:340] Iteration 18000, Testing net (#0)
I0716 21:24:31.324251 37548 solver.cpp:408]     Test net output #0: accuracy = 0.466333
I0716 21:24:31.364923 37548 solver.cpp:408]     Test net output #1: loss = 1.05947 (* 1 = 1.05947 loss)
I0716 21:24:34.235934 37548 solver.cpp:236] Iteration 18000, loss = 1.05415
I0716 21:24:34.236060 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 21:24:34.236218 37548 solver.cpp:252]     Train net output #1: loss = 0.971403 (* 1 = 0.971403 loss)
I0716 21:24:34.236428 37548 sgd_solver.cpp:106] Iteration 18000, lr = 0.015
I0716 21:28:26.922323 37548 solver.cpp:236] Iteration 18050, loss = 1.06882
I0716 21:28:26.954287 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 21:28:26.954392 37548 solver.cpp:252]     Train net output #1: loss = 0.958814 (* 1 = 0.958814 loss)
I0716 21:28:27.940299 37548 sgd_solver.cpp:106] Iteration 18050, lr = 0.015
I0716 21:32:13.877717 37548 solver.cpp:236] Iteration 18100, loss = 1.03942
I0716 21:32:13.898190 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 21:32:13.898355 37548 solver.cpp:252]     Train net output #1: loss = 0.872364 (* 1 = 0.872364 loss)
I0716 21:32:14.754760 37548 sgd_solver.cpp:106] Iteration 18100, lr = 0.015
I0716 21:36:07.269500 37548 solver.cpp:236] Iteration 18150, loss = 1.06482
I0716 21:36:07.280462 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 21:36:07.280576 37548 solver.cpp:252]     Train net output #1: loss = 1.05374 (* 1 = 1.05374 loss)
I0716 21:36:08.156445 37548 sgd_solver.cpp:106] Iteration 18150, lr = 0.015
I0716 21:39:58.773079 37548 solver.cpp:236] Iteration 18200, loss = 1.08533
I0716 21:39:58.805351 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 21:39:58.805475 37548 solver.cpp:252]     Train net output #1: loss = 1.11567 (* 1 = 1.11567 loss)
I0716 21:39:59.727035 37548 sgd_solver.cpp:106] Iteration 18200, lr = 0.015
I0716 21:41:23.610277 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 21:43:58.662896 37548 solver.cpp:236] Iteration 18250, loss = 1.06815
I0716 21:43:58.663233 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 21:43:58.663281 37548 solver.cpp:252]     Train net output #1: loss = 0.970208 (* 1 = 0.970208 loss)
I0716 21:43:59.666473 37548 sgd_solver.cpp:106] Iteration 18250, lr = 0.015
I0716 21:47:43.890133 37548 solver.cpp:236] Iteration 18300, loss = 1.06532
I0716 21:47:43.890609 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0716 21:47:43.890790 37548 solver.cpp:252]     Train net output #1: loss = 0.735447 (* 1 = 0.735447 loss)
I0716 21:47:44.838433 37548 sgd_solver.cpp:106] Iteration 18300, lr = 0.015
I0716 21:51:30.057795 37548 solver.cpp:236] Iteration 18350, loss = 1.04903
I0716 21:51:30.058058 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 21:51:30.058105 37548 solver.cpp:252]     Train net output #1: loss = 1.14147 (* 1 = 1.14147 loss)
I0716 21:51:31.006680 37548 sgd_solver.cpp:106] Iteration 18350, lr = 0.015
I0716 21:55:26.437677 37548 solver.cpp:236] Iteration 18400, loss = 1.06587
I0716 21:55:26.455016 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 21:55:26.455076 37548 solver.cpp:252]     Train net output #1: loss = 0.936153 (* 1 = 0.936153 loss)
I0716 21:55:27.314285 37548 sgd_solver.cpp:106] Iteration 18400, lr = 0.015
I0716 21:59:18.836581 37548 solver.cpp:236] Iteration 18450, loss = 1.05156
I0716 21:59:18.836791 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 21:59:18.836813 37548 solver.cpp:252]     Train net output #1: loss = 0.932071 (* 1 = 0.932071 loss)
I0716 21:59:19.792749 37548 sgd_solver.cpp:106] Iteration 18450, lr = 0.015
I0716 22:03:09.307389 37548 solver.cpp:236] Iteration 18500, loss = 1.04076
I0716 22:03:09.307610 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 22:03:09.307631 37548 solver.cpp:252]     Train net output #1: loss = 1.18778 (* 1 = 1.18778 loss)
I0716 22:03:10.252306 37548 sgd_solver.cpp:106] Iteration 18500, lr = 0.015
I0716 22:06:53.860535 37548 solver.cpp:236] Iteration 18550, loss = 1.09345
I0716 22:06:53.861004 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 22:06:53.861100 37548 solver.cpp:252]     Train net output #1: loss = 0.93435 (* 1 = 0.93435 loss)
I0716 22:06:54.802191 37548 sgd_solver.cpp:106] Iteration 18550, lr = 0.015
I0716 22:10:45.079856 37548 solver.cpp:236] Iteration 18600, loss = 1.02828
I0716 22:10:45.080425 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 22:10:45.080590 37548 solver.cpp:252]     Train net output #1: loss = 1.03022 (* 1 = 1.03022 loss)
I0716 22:10:46.046453 37548 sgd_solver.cpp:106] Iteration 18600, lr = 0.015
I0716 22:12:51.354800 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 22:14:40.194804 37548 solver.cpp:236] Iteration 18650, loss = 1.0631
I0716 22:14:40.195077 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 22:14:40.195134 37548 solver.cpp:252]     Train net output #1: loss = 1.10346 (* 1 = 1.10346 loss)
I0716 22:14:41.141932 37548 sgd_solver.cpp:106] Iteration 18650, lr = 0.015
I0716 22:18:36.890354 37548 solver.cpp:236] Iteration 18700, loss = 1.03598
I0716 22:18:36.890676 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 22:18:36.890722 37548 solver.cpp:252]     Train net output #1: loss = 0.877992 (* 1 = 0.877992 loss)
I0716 22:18:37.771231 37548 sgd_solver.cpp:106] Iteration 18700, lr = 0.015
I0716 22:22:28.782990 37548 solver.cpp:236] Iteration 18750, loss = 1.05443
I0716 22:22:28.783356 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 22:22:28.783393 37548 solver.cpp:252]     Train net output #1: loss = 1.06346 (* 1 = 1.06346 loss)
I0716 22:22:29.713058 37548 sgd_solver.cpp:106] Iteration 18750, lr = 0.015
I0716 22:26:16.338937 37548 solver.cpp:236] Iteration 18800, loss = 1.07993
I0716 22:26:16.339201 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 22:26:16.339233 37548 solver.cpp:252]     Train net output #1: loss = 1.27022 (* 1 = 1.27022 loss)
I0716 22:26:17.294128 37548 sgd_solver.cpp:106] Iteration 18800, lr = 0.015
I0716 22:30:03.614506 37548 solver.cpp:236] Iteration 18850, loss = 1.0745
I0716 22:30:03.656015 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0716 22:30:03.656112 37548 solver.cpp:252]     Train net output #1: loss = 0.77778 (* 1 = 0.77778 loss)
I0716 22:30:04.491171 37548 sgd_solver.cpp:106] Iteration 18850, lr = 0.015
I0716 22:33:55.689585 37548 solver.cpp:236] Iteration 18900, loss = 1.04416
I0716 22:33:55.705515 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 22:33:55.705554 37548 solver.cpp:252]     Train net output #1: loss = 0.965172 (* 1 = 0.965172 loss)
I0716 22:33:56.658717 37548 sgd_solver.cpp:106] Iteration 18900, lr = 0.015
I0716 22:37:56.019690 37548 solver.cpp:236] Iteration 18950, loss = 1.07073
I0716 22:37:56.034585 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0716 22:37:56.034742 37548 solver.cpp:252]     Train net output #1: loss = 1.44682 (* 1 = 1.44682 loss)
I0716 22:37:56.904398 37548 sgd_solver.cpp:106] Iteration 18950, lr = 0.015
I0716 22:41:53.825660 37548 solver.cpp:236] Iteration 19000, loss = 1.06675
I0716 22:41:53.825995 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 22:41:53.826040 37548 solver.cpp:252]     Train net output #1: loss = 1.06824 (* 1 = 1.06824 loss)
I0716 22:41:54.706737 37548 sgd_solver.cpp:106] Iteration 19000, lr = 0.015
I0716 22:44:14.145750 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 22:45:49.679013 37548 solver.cpp:236] Iteration 19050, loss = 1.0649
I0716 22:45:49.679381 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 22:45:49.679450 37548 solver.cpp:252]     Train net output #1: loss = 1.1278 (* 1 = 1.1278 loss)
I0716 22:45:50.622730 37548 sgd_solver.cpp:106] Iteration 19050, lr = 0.015
I0716 22:49:34.178722 37548 solver.cpp:236] Iteration 19100, loss = 1.07547
I0716 22:49:34.179162 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 22:49:34.179286 37548 solver.cpp:252]     Train net output #1: loss = 0.969476 (* 1 = 0.969476 loss)
I0716 22:49:35.053776 37548 sgd_solver.cpp:106] Iteration 19100, lr = 0.015
I0716 22:53:20.224808 37548 solver.cpp:236] Iteration 19150, loss = 1.07452
I0716 22:53:20.235489 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 22:53:20.235626 37548 solver.cpp:252]     Train net output #1: loss = 0.901373 (* 1 = 0.901373 loss)
I0716 22:53:21.172417 37548 sgd_solver.cpp:106] Iteration 19150, lr = 0.015
I0716 22:57:06.243631 37548 solver.cpp:236] Iteration 19200, loss = 1.07528
I0716 22:57:06.243917 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 22:57:06.243965 37548 solver.cpp:252]     Train net output #1: loss = 0.975726 (* 1 = 0.975726 loss)
I0716 22:57:07.116636 37548 sgd_solver.cpp:106] Iteration 19200, lr = 0.015
I0716 23:00:49.678540 37548 solver.cpp:236] Iteration 19250, loss = 1.04421
I0716 23:00:49.691681 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0716 23:00:49.691733 37548 solver.cpp:252]     Train net output #1: loss = 0.816632 (* 1 = 0.816632 loss)
I0716 23:00:50.570783 37548 sgd_solver.cpp:106] Iteration 19250, lr = 0.015
I0716 23:04:37.347728 37548 solver.cpp:236] Iteration 19300, loss = 1.05291
I0716 23:04:37.348044 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 23:04:37.348078 37548 solver.cpp:252]     Train net output #1: loss = 1.15977 (* 1 = 1.15977 loss)
I0716 23:04:38.220476 37548 sgd_solver.cpp:106] Iteration 19300, lr = 0.015
I0716 23:08:27.982415 37548 solver.cpp:236] Iteration 19350, loss = 1.08843
I0716 23:08:27.982887 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0716 23:08:27.983064 37548 solver.cpp:252]     Train net output #1: loss = 1.19694 (* 1 = 1.19694 loss)
I0716 23:08:28.928308 37548 sgd_solver.cpp:106] Iteration 19350, lr = 0.015
I0716 23:12:18.385043 37548 solver.cpp:236] Iteration 19400, loss = 1.03612
I0716 23:12:18.393807 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0716 23:12:18.393878 37548 solver.cpp:252]     Train net output #1: loss = 1.08985 (* 1 = 1.08985 loss)
I0716 23:12:19.248478 37548 sgd_solver.cpp:106] Iteration 19400, lr = 0.015
I0716 23:15:57.676245 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0716 23:16:05.824086 37548 solver.cpp:236] Iteration 19450, loss = 1.06005
I0716 23:16:05.824156 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 23:16:05.824187 37548 solver.cpp:252]     Train net output #1: loss = 0.970934 (* 1 = 0.970934 loss)
I0716 23:16:06.704498 37548 sgd_solver.cpp:106] Iteration 19450, lr = 0.015
I0716 23:19:56.844631 37548 solver.cpp:340] Iteration 19500, Testing net (#0)
I0716 23:43:10.715764 37548 solver.cpp:408]     Test net output #0: accuracy = 0.454667
I0716 23:43:10.758818 37548 solver.cpp:408]     Test net output #1: loss = 1.06657 (* 1 = 1.06657 loss)
I0716 23:43:13.673025 37548 solver.cpp:236] Iteration 19500, loss = 1.05987
I0716 23:43:13.673121 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0716 23:43:13.673159 37548 solver.cpp:252]     Train net output #1: loss = 1.29772 (* 1 = 1.29772 loss)
I0716 23:43:13.673234 37548 sgd_solver.cpp:106] Iteration 19500, lr = 0.015
I0716 23:46:52.112552 37548 solver.cpp:236] Iteration 19550, loss = 1.0596
I0716 23:46:52.122467 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 23:46:52.122509 37548 solver.cpp:252]     Train net output #1: loss = 1.02468 (* 1 = 1.02468 loss)
I0716 23:46:52.985671 37548 sgd_solver.cpp:106] Iteration 19550, lr = 0.015
I0716 23:50:29.910218 37548 solver.cpp:236] Iteration 19600, loss = 1.06964
I0716 23:50:29.910454 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0716 23:50:29.910492 37548 solver.cpp:252]     Train net output #1: loss = 0.950777 (* 1 = 0.950777 loss)
I0716 23:50:30.787794 37548 sgd_solver.cpp:106] Iteration 19600, lr = 0.015
I0716 23:54:07.367480 37548 solver.cpp:236] Iteration 19650, loss = 1.03181
I0716 23:54:07.367907 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 23:54:07.367974 37548 solver.cpp:252]     Train net output #1: loss = 0.987662 (* 1 = 0.987662 loss)
I0716 23:54:08.246697 37548 sgd_solver.cpp:106] Iteration 19650, lr = 0.015
I0716 23:57:46.843109 37548 solver.cpp:236] Iteration 19700, loss = 1.06222
I0716 23:57:46.843354 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0716 23:57:46.843420 37548 solver.cpp:252]     Train net output #1: loss = 0.974793 (* 1 = 0.974793 loss)
I0716 23:57:47.722002 37548 sgd_solver.cpp:106] Iteration 19700, lr = 0.015
I0717 00:01:25.008203 37548 solver.cpp:236] Iteration 19750, loss = 1.08693
I0717 00:01:25.008535 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:01:25.008610 37548 solver.cpp:252]     Train net output #1: loss = 1.02117 (* 1 = 1.02117 loss)
I0717 00:01:25.890022 37548 sgd_solver.cpp:106] Iteration 19750, lr = 0.015
I0717 00:05:02.552299 37548 solver.cpp:236] Iteration 19800, loss = 1.07175
I0717 00:05:02.580715 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:05:02.580775 37548 solver.cpp:252]     Train net output #1: loss = 0.973854 (* 1 = 0.973854 loss)
I0717 00:05:03.497740 37548 sgd_solver.cpp:106] Iteration 19800, lr = 0.015
I0717 00:08:48.016484 37548 solver.cpp:236] Iteration 19850, loss = 1.03565
I0717 00:08:48.049388 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:08:48.049430 37548 solver.cpp:252]     Train net output #1: loss = 0.930264 (* 1 = 0.930264 loss)
I0717 00:08:48.895153 37548 sgd_solver.cpp:106] Iteration 19850, lr = 0.015
I0717 00:11:39.142127 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 00:12:32.840864 37548 solver.cpp:236] Iteration 19900, loss = 1.08992
I0717 00:12:32.841179 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 00:12:32.841243 37548 solver.cpp:252]     Train net output #1: loss = 0.850012 (* 1 = 0.850012 loss)
I0717 00:12:33.718992 37548 sgd_solver.cpp:106] Iteration 19900, lr = 0.015
I0717 00:16:12.587043 37548 solver.cpp:236] Iteration 19950, loss = 1.05857
I0717 00:16:12.587278 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 00:16:12.587303 37548 solver.cpp:252]     Train net output #1: loss = 0.964711 (* 1 = 0.964711 loss)
I0717 00:16:13.446331 37548 sgd_solver.cpp:106] Iteration 19950, lr = 0.015
I0717 00:19:50.812927 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_20000.caffemodel
I0717 00:19:52.005992 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_20000.solverstate
I0717 00:19:55.245249 37548 solver.cpp:236] Iteration 20000, loss = 1.06454
I0717 00:19:55.245313 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 00:19:55.245335 37548 solver.cpp:252]     Train net output #1: loss = 1.15073 (* 1 = 1.15073 loss)
I0717 00:19:56.138459 37548 sgd_solver.cpp:106] Iteration 20000, lr = 0.015
I0717 00:23:26.708412 37548 solver.cpp:236] Iteration 20050, loss = 1.08634
I0717 00:23:26.714411 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:23:26.714516 37548 solver.cpp:252]     Train net output #1: loss = 1.01866 (* 1 = 1.01866 loss)
I0717 00:23:27.607856 37548 sgd_solver.cpp:106] Iteration 20050, lr = 0.015
I0717 00:27:01.551762 37548 solver.cpp:236] Iteration 20100, loss = 1.06962
I0717 00:27:01.552047 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 00:27:01.552080 37548 solver.cpp:252]     Train net output #1: loss = 1.19993 (* 1 = 1.19993 loss)
I0717 00:27:02.424029 37548 sgd_solver.cpp:106] Iteration 20100, lr = 0.015
I0717 00:30:38.331678 37548 solver.cpp:236] Iteration 20150, loss = 1.0523
I0717 00:30:38.331943 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:30:38.331971 37548 solver.cpp:252]     Train net output #1: loss = 1.07531 (* 1 = 1.07531 loss)
I0717 00:30:39.207469 37548 sgd_solver.cpp:106] Iteration 20150, lr = 0.015
I0717 00:34:12.361961 37548 solver.cpp:236] Iteration 20200, loss = 1.06194
I0717 00:34:12.405127 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 00:34:12.405184 37548 solver.cpp:252]     Train net output #1: loss = 1.12305 (* 1 = 1.12305 loss)
I0717 00:34:13.237778 37548 sgd_solver.cpp:106] Iteration 20200, lr = 0.015
I0717 00:37:51.152864 37548 solver.cpp:236] Iteration 20250, loss = 1.05806
I0717 00:37:51.169705 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 00:37:51.169750 37548 solver.cpp:252]     Train net output #1: loss = 0.86041 (* 1 = 0.86041 loss)
I0717 00:37:52.029479 37548 sgd_solver.cpp:106] Iteration 20250, lr = 0.015
I0717 00:41:28.220473 37548 solver.cpp:236] Iteration 20300, loss = 1.07774
I0717 00:41:28.220635 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:41:28.220677 37548 solver.cpp:252]     Train net output #1: loss = 0.987379 (* 1 = 0.987379 loss)
I0717 00:41:29.098820 37548 sgd_solver.cpp:106] Iteration 20300, lr = 0.015
I0717 00:44:55.339572 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 00:45:11.472448 37548 solver.cpp:236] Iteration 20350, loss = 1.09843
I0717 00:45:11.472623 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 00:45:11.472682 37548 solver.cpp:252]     Train net output #1: loss = 1.16721 (* 1 = 1.16721 loss)
I0717 00:45:12.345921 37548 sgd_solver.cpp:106] Iteration 20350, lr = 0.015
I0717 00:48:49.012328 37548 solver.cpp:236] Iteration 20400, loss = 1.07755
I0717 00:48:49.029214 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 00:48:49.029258 37548 solver.cpp:252]     Train net output #1: loss = 1.18668 (* 1 = 1.18668 loss)
I0717 00:48:49.886984 37548 sgd_solver.cpp:106] Iteration 20400, lr = 0.015
I0717 00:52:34.753764 37548 solver.cpp:236] Iteration 20450, loss = 1.05207
I0717 00:52:34.754050 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 00:52:34.754086 37548 solver.cpp:252]     Train net output #1: loss = 1.02616 (* 1 = 1.02616 loss)
I0717 00:52:35.710371 37548 sgd_solver.cpp:106] Iteration 20450, lr = 0.015
I0717 00:56:17.542773 37548 solver.cpp:236] Iteration 20500, loss = 1.05417
I0717 00:56:17.553025 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 00:56:17.553066 37548 solver.cpp:252]     Train net output #1: loss = 0.838179 (* 1 = 0.838179 loss)
I0717 00:56:18.417489 37548 sgd_solver.cpp:106] Iteration 20500, lr = 0.015
I0717 00:59:57.116485 37548 solver.cpp:236] Iteration 20550, loss = 1.06649
I0717 00:59:57.150563 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 00:59:57.150614 37548 solver.cpp:252]     Train net output #1: loss = 1.29012 (* 1 = 1.29012 loss)
I0717 00:59:57.989285 37548 sgd_solver.cpp:106] Iteration 20550, lr = 0.015
I0717 01:03:29.886073 37548 solver.cpp:236] Iteration 20600, loss = 1.04834
I0717 01:03:29.918103 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 01:03:29.918161 37548 solver.cpp:252]     Train net output #1: loss = 0.939967 (* 1 = 0.939967 loss)
I0717 01:03:30.832612 37548 sgd_solver.cpp:106] Iteration 20600, lr = 0.015
I0717 01:07:10.043108 37548 solver.cpp:236] Iteration 20650, loss = 1.05735
I0717 01:07:10.081964 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 01:07:10.082002 37548 solver.cpp:252]     Train net output #1: loss = 0.875634 (* 1 = 0.875634 loss)
I0717 01:07:10.910706 37548 sgd_solver.cpp:106] Iteration 20650, lr = 0.015
I0717 01:10:55.027523 37548 solver.cpp:236] Iteration 20700, loss = 1.06217
I0717 01:10:55.035104 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 01:10:55.035148 37548 solver.cpp:252]     Train net output #1: loss = 1.02888 (* 1 = 1.02888 loss)
I0717 01:10:55.963884 37548 sgd_solver.cpp:106] Iteration 20700, lr = 0.015
I0717 01:14:33.572736 37548 solver.cpp:236] Iteration 20750, loss = 1.0604
I0717 01:14:33.583219 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 01:14:33.583307 37548 solver.cpp:252]     Train net output #1: loss = 0.989136 (* 1 = 0.989136 loss)
I0717 01:14:34.510447 37548 sgd_solver.cpp:106] Iteration 20750, lr = 0.015
I0717 01:17:39.964195 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 01:18:10.915927 37548 solver.cpp:236] Iteration 20800, loss = 1.03672
I0717 01:18:10.916147 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 01:18:10.916208 37548 solver.cpp:252]     Train net output #1: loss = 0.846355 (* 1 = 0.846355 loss)
I0717 01:18:11.790616 37548 sgd_solver.cpp:106] Iteration 20800, lr = 0.015
I0717 01:21:48.650483 37548 solver.cpp:236] Iteration 20850, loss = 1.06845
I0717 01:21:48.650764 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0717 01:21:48.650845 37548 solver.cpp:252]     Train net output #1: loss = 0.793187 (* 1 = 0.793187 loss)
I0717 01:21:49.532425 37548 sgd_solver.cpp:106] Iteration 20850, lr = 0.015
I0717 01:25:30.818037 37548 solver.cpp:236] Iteration 20900, loss = 1.0672
I0717 01:25:30.818294 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 01:25:30.818341 37548 solver.cpp:252]     Train net output #1: loss = 1.07131 (* 1 = 1.07131 loss)
I0717 01:25:31.752262 37548 sgd_solver.cpp:106] Iteration 20900, lr = 0.015
I0717 01:29:11.466567 37548 solver.cpp:236] Iteration 20950, loss = 1.08055
I0717 01:29:11.498363 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 01:29:11.498407 37548 solver.cpp:252]     Train net output #1: loss = 1.0679 (* 1 = 1.0679 loss)
I0717 01:29:12.414572 37548 sgd_solver.cpp:106] Iteration 20950, lr = 0.015
I0717 01:32:50.582901 37548 solver.cpp:340] Iteration 21000, Testing net (#0)
I0717 01:56:04.526003 37548 solver.cpp:408]     Test net output #0: accuracy = 0.466666
I0717 01:56:04.576014 37548 solver.cpp:408]     Test net output #1: loss = 1.06156 (* 1 = 1.06156 loss)
I0717 01:56:07.507679 37548 solver.cpp:236] Iteration 21000, loss = 1.04979
I0717 01:56:07.507730 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 01:56:07.507747 37548 solver.cpp:252]     Train net output #1: loss = 1.11961 (* 1 = 1.11961 loss)
I0717 01:56:07.507784 37548 sgd_solver.cpp:106] Iteration 21000, lr = 0.015
I0717 01:59:42.628787 37548 solver.cpp:236] Iteration 21050, loss = 1.07874
I0717 01:59:42.632589 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 01:59:42.632663 37548 solver.cpp:252]     Train net output #1: loss = 0.968988 (* 1 = 0.968988 loss)
I0717 01:59:43.583202 37548 sgd_solver.cpp:106] Iteration 21050, lr = 0.015
I0717 02:03:17.580019 37548 solver.cpp:236] Iteration 21100, loss = 1.02791
I0717 02:03:17.582412 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 02:03:17.582445 37548 solver.cpp:252]     Train net output #1: loss = 1.20067 (* 1 = 1.20067 loss)
I0717 02:03:18.523778 37548 sgd_solver.cpp:106] Iteration 21100, lr = 0.015
I0717 02:06:53.621834 37548 solver.cpp:236] Iteration 21150, loss = 1.05439
I0717 02:06:53.640034 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 02:06:53.640072 37548 solver.cpp:252]     Train net output #1: loss = 1.08203 (* 1 = 1.08203 loss)
I0717 02:06:54.500519 37548 sgd_solver.cpp:106] Iteration 21150, lr = 0.015
I0717 02:10:30.693264 37548 solver.cpp:236] Iteration 21200, loss = 1.06758
I0717 02:10:30.705523 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 02:10:30.705564 37548 solver.cpp:252]     Train net output #1: loss = 1.02529 (* 1 = 1.02529 loss)
I0717 02:10:31.568318 37548 sgd_solver.cpp:106] Iteration 21200, lr = 0.015
I0717 02:13:54.134500 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 02:14:06.465339 37548 solver.cpp:236] Iteration 21250, loss = 1.0717
I0717 02:14:06.465456 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 02:14:06.465498 37548 solver.cpp:252]     Train net output #1: loss = 0.943861 (* 1 = 0.943861 loss)
I0717 02:14:07.345512 37548 sgd_solver.cpp:106] Iteration 21250, lr = 0.015
I0717 02:17:40.275084 37548 solver.cpp:236] Iteration 21300, loss = 1.07885
I0717 02:17:40.280408 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 02:17:40.280448 37548 solver.cpp:252]     Train net output #1: loss = 1.13003 (* 1 = 1.13003 loss)
I0717 02:17:41.147825 37548 sgd_solver.cpp:106] Iteration 21300, lr = 0.015
I0717 02:21:14.461086 37548 solver.cpp:236] Iteration 21350, loss = 1.07186
I0717 02:21:14.464076 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 02:21:14.464237 37548 solver.cpp:252]     Train net output #1: loss = 0.950495 (* 1 = 0.950495 loss)
I0717 02:21:15.476399 37548 sgd_solver.cpp:106] Iteration 21350, lr = 0.015
I0717 02:24:52.833611 37548 solver.cpp:236] Iteration 21400, loss = 1.01567
I0717 02:24:52.853787 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 02:24:52.853839 37548 solver.cpp:252]     Train net output #1: loss = 1.0479 (* 1 = 1.0479 loss)
I0717 02:24:53.721868 37548 sgd_solver.cpp:106] Iteration 21400, lr = 0.015
I0717 02:28:27.358924 37548 solver.cpp:236] Iteration 21450, loss = 1.08502
I0717 02:28:27.362222 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 02:28:27.362267 37548 solver.cpp:252]     Train net output #1: loss = 1.23624 (* 1 = 1.23624 loss)
I0717 02:28:28.304560 37548 sgd_solver.cpp:106] Iteration 21450, lr = 0.015
I0717 02:32:05.326388 37548 solver.cpp:236] Iteration 21500, loss = 1.05611
I0717 02:32:05.343859 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0717 02:32:05.343891 37548 solver.cpp:252]     Train net output #1: loss = 0.772127 (* 1 = 0.772127 loss)
I0717 02:32:06.258086 37548 sgd_solver.cpp:106] Iteration 21500, lr = 0.015
I0717 02:35:36.772660 37548 solver.cpp:236] Iteration 21550, loss = 1.07085
I0717 02:35:36.779095 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 02:35:36.779212 37548 solver.cpp:252]     Train net output #1: loss = 1.13361 (* 1 = 1.13361 loss)
I0717 02:35:37.637377 37548 sgd_solver.cpp:106] Iteration 21550, lr = 0.015
I0717 02:39:12.766616 37548 solver.cpp:236] Iteration 21600, loss = 1.03727
I0717 02:39:12.794886 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 02:39:12.794947 37548 solver.cpp:252]     Train net output #1: loss = 1.01706 (* 1 = 1.01706 loss)
I0717 02:39:13.649116 37548 sgd_solver.cpp:106] Iteration 21600, lr = 0.015
I0717 02:42:47.106457 37548 solver.cpp:236] Iteration 21650, loss = 1.05564
I0717 02:42:47.111665 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 02:42:47.111724 37548 solver.cpp:252]     Train net output #1: loss = 1.0301 (* 1 = 1.0301 loss)
I0717 02:42:48.110252 37548 sgd_solver.cpp:106] Iteration 21650, lr = 0.015
I0717 02:46:25.364866 37548 solver.cpp:236] Iteration 21700, loss = 1.05673
I0717 02:46:25.384891 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 02:46:25.384927 37548 solver.cpp:252]     Train net output #1: loss = 0.911393 (* 1 = 0.911393 loss)
I0717 02:46:26.313182 37548 sgd_solver.cpp:106] Iteration 21700, lr = 0.015
I0717 02:47:14.927526 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 02:50:06.213124 37548 solver.cpp:236] Iteration 21750, loss = 1.0678
I0717 02:50:06.213418 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 02:50:06.213459 37548 solver.cpp:252]     Train net output #1: loss = 0.994711 (* 1 = 0.994711 loss)
I0717 02:50:07.095266 37548 sgd_solver.cpp:106] Iteration 21750, lr = 0.015
I0717 02:53:37.596175 37548 solver.cpp:236] Iteration 21800, loss = 1.03659
I0717 02:53:37.596468 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 02:53:37.596508 37548 solver.cpp:252]     Train net output #1: loss = 1.10042 (* 1 = 1.10042 loss)
I0717 02:53:38.485383 37548 sgd_solver.cpp:106] Iteration 21800, lr = 0.015
I0717 02:57:15.152027 37548 solver.cpp:236] Iteration 21850, loss = 1.05508
I0717 02:57:15.182030 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 02:57:15.182140 37548 solver.cpp:252]     Train net output #1: loss = 1.22627 (* 1 = 1.22627 loss)
I0717 02:57:16.113309 37548 sgd_solver.cpp:106] Iteration 21850, lr = 0.015
I0717 03:00:50.000555 37548 solver.cpp:236] Iteration 21900, loss = 1.05173
I0717 03:00:50.006916 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 03:00:50.006959 37548 solver.cpp:252]     Train net output #1: loss = 0.832409 (* 1 = 0.832409 loss)
I0717 03:00:50.960124 37548 sgd_solver.cpp:106] Iteration 21900, lr = 0.015
I0717 03:04:23.285904 37548 solver.cpp:236] Iteration 21950, loss = 1.04621
I0717 03:04:23.299298 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 03:04:23.299371 37548 solver.cpp:252]     Train net output #1: loss = 0.85824 (* 1 = 0.85824 loss)
I0717 03:04:24.165503 37548 sgd_solver.cpp:106] Iteration 21950, lr = 0.015
I0717 03:07:58.118825 37548 solver.cpp:236] Iteration 22000, loss = 1.02378
I0717 03:07:58.124137 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 03:07:58.124178 37548 solver.cpp:252]     Train net output #1: loss = 1.02564 (* 1 = 1.02564 loss)
I0717 03:07:59.065855 37548 sgd_solver.cpp:106] Iteration 22000, lr = 0.015
I0717 03:11:37.264655 37548 solver.cpp:236] Iteration 22050, loss = 1.06679
I0717 03:11:37.313576 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 03:11:37.313611 37548 solver.cpp:252]     Train net output #1: loss = 1.12232 (* 1 = 1.12232 loss)
I0717 03:11:38.189406 37548 sgd_solver.cpp:106] Iteration 22050, lr = 0.015
I0717 03:15:09.377461 37548 solver.cpp:236] Iteration 22100, loss = 1.05575
I0717 03:15:09.381505 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 03:15:09.381551 37548 solver.cpp:252]     Train net output #1: loss = 0.945547 (* 1 = 0.945547 loss)
I0717 03:15:10.322319 37548 sgd_solver.cpp:106] Iteration 22100, lr = 0.015
I0717 03:18:43.963001 37548 solver.cpp:236] Iteration 22150, loss = 1.06615
I0717 03:18:43.973495 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 03:18:43.973623 37548 solver.cpp:252]     Train net output #1: loss = 1.02561 (* 1 = 1.02561 loss)
I0717 03:18:44.825758 37548 sgd_solver.cpp:106] Iteration 22150, lr = 0.015
I0717 03:20:38.260931 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 03:22:18.567101 37548 solver.cpp:236] Iteration 22200, loss = 1.08246
I0717 03:22:18.573376 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 03:22:18.573489 37548 solver.cpp:252]     Train net output #1: loss = 1.03335 (* 1 = 1.03335 loss)
I0717 03:22:19.434784 37548 sgd_solver.cpp:106] Iteration 22200, lr = 0.015
I0717 03:26:10.454779 37548 solver.cpp:236] Iteration 22250, loss = 1.06007
I0717 03:26:10.497992 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 03:26:10.498035 37548 solver.cpp:252]     Train net output #1: loss = 1.28427 (* 1 = 1.28427 loss)
I0717 03:26:11.419843 37548 sgd_solver.cpp:106] Iteration 22250, lr = 0.015
I0717 03:30:06.528538 37548 solver.cpp:236] Iteration 22300, loss = 1.05259
I0717 03:30:06.562155 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 03:30:06.562214 37548 solver.cpp:252]     Train net output #1: loss = 1.07861 (* 1 = 1.07861 loss)
I0717 03:30:07.408437 37548 sgd_solver.cpp:106] Iteration 22300, lr = 0.015
I0717 03:34:12.359117 37548 solver.cpp:236] Iteration 22350, loss = 1.09428
I0717 03:34:12.371335 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 03:34:12.371371 37548 solver.cpp:252]     Train net output #1: loss = 1.13941 (* 1 = 1.13941 loss)
I0717 03:34:13.237057 37548 sgd_solver.cpp:106] Iteration 22350, lr = 0.015
I0717 03:38:14.806867 37548 solver.cpp:236] Iteration 22400, loss = 1.0543
I0717 03:38:14.840610 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 03:38:14.840657 37548 solver.cpp:252]     Train net output #1: loss = 1.16281 (* 1 = 1.16281 loss)
I0717 03:38:15.751297 37548 sgd_solver.cpp:106] Iteration 22400, lr = 0.015
I0717 03:42:17.455134 37548 solver.cpp:236] Iteration 22450, loss = 1.0793
I0717 03:42:17.460029 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 03:42:17.460095 37548 solver.cpp:252]     Train net output #1: loss = 0.988549 (* 1 = 0.988549 loss)
I0717 03:42:18.397367 37548 sgd_solver.cpp:106] Iteration 22450, lr = 0.015
I0717 03:46:10.408563 37548 solver.cpp:340] Iteration 22500, Testing net (#0)
I0717 04:09:24.601438 37548 solver.cpp:408]     Test net output #0: accuracy = 0.462
I0717 04:09:24.655419 37548 solver.cpp:408]     Test net output #1: loss = 1.06048 (* 1 = 1.06048 loss)
I0717 04:09:27.535053 37548 solver.cpp:236] Iteration 22500, loss = 1.06535
I0717 04:09:27.535193 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 04:09:27.535255 37548 solver.cpp:252]     Train net output #1: loss = 1.12242 (* 1 = 1.12242 loss)
I0717 04:09:27.535361 37548 sgd_solver.cpp:106] Iteration 22500, lr = 0.015
I0717 04:13:25.080425 37548 solver.cpp:236] Iteration 22550, loss = 1.08483
I0717 04:13:25.117133 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 04:13:25.117213 37548 solver.cpp:252]     Train net output #1: loss = 1.09906 (* 1 = 1.09906 loss)
I0717 04:13:26.024997 37548 sgd_solver.cpp:106] Iteration 22550, lr = 0.015
I0717 04:15:16.447214 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 04:17:21.529170 37548 solver.cpp:236] Iteration 22600, loss = 1.06641
I0717 04:17:21.539409 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 04:17:21.539444 37548 solver.cpp:252]     Train net output #1: loss = 0.951336 (* 1 = 0.951336 loss)
I0717 04:17:22.522796 37548 sgd_solver.cpp:106] Iteration 22600, lr = 0.015
I0717 04:21:22.893398 37548 solver.cpp:236] Iteration 22650, loss = 1.0416
I0717 04:21:22.925886 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 04:21:22.925987 37548 solver.cpp:252]     Train net output #1: loss = 1.31703 (* 1 = 1.31703 loss)
I0717 04:21:23.839990 37548 sgd_solver.cpp:106] Iteration 22650, lr = 0.015
I0717 04:25:14.893013 37548 solver.cpp:236] Iteration 22700, loss = 1.07217
I0717 04:25:14.950464 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 04:25:14.950515 37548 solver.cpp:252]     Train net output #1: loss = 1.15947 (* 1 = 1.15947 loss)
I0717 04:25:15.768110 37548 sgd_solver.cpp:106] Iteration 22700, lr = 0.015
I0717 04:29:26.489042 37548 solver.cpp:236] Iteration 22750, loss = 1.08682
I0717 04:29:26.498591 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 04:29:26.498682 37548 solver.cpp:252]     Train net output #1: loss = 1.14515 (* 1 = 1.14515 loss)
I0717 04:29:27.369010 37548 sgd_solver.cpp:106] Iteration 22750, lr = 0.015
I0717 04:33:28.791182 37548 solver.cpp:236] Iteration 22800, loss = 1.05566
I0717 04:33:28.817920 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 04:33:28.817957 37548 solver.cpp:252]     Train net output #1: loss = 1.12087 (* 1 = 1.12087 loss)
I0717 04:33:29.666201 37548 sgd_solver.cpp:106] Iteration 22800, lr = 0.015
I0717 04:37:28.776458 37548 solver.cpp:236] Iteration 22850, loss = 1.01293
I0717 04:37:28.813432 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 04:37:28.813484 37548 solver.cpp:252]     Train net output #1: loss = 0.883329 (* 1 = 0.883329 loss)
I0717 04:37:29.652963 37548 sgd_solver.cpp:106] Iteration 22850, lr = 0.015
I0717 04:41:31.628772 37548 solver.cpp:236] Iteration 22900, loss = 1.11293
I0717 04:41:31.666019 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 04:41:31.666142 37548 solver.cpp:252]     Train net output #1: loss = 1.14968 (* 1 = 1.14968 loss)
I0717 04:41:32.629565 37548 sgd_solver.cpp:106] Iteration 22900, lr = 0.015
I0717 04:45:28.934101 37548 solver.cpp:236] Iteration 22950, loss = 1.05839
I0717 04:45:28.962749 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 04:45:28.962805 37548 solver.cpp:252]     Train net output #1: loss = 0.985526 (* 1 = 0.985526 loss)
I0717 04:45:29.868917 37548 sgd_solver.cpp:106] Iteration 22950, lr = 0.015
I0717 04:46:35.936911 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 04:49:36.141788 37548 solver.cpp:236] Iteration 23000, loss = 1.06825
I0717 04:49:36.141978 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 04:49:36.142011 37548 solver.cpp:252]     Train net output #1: loss = 1.36699 (* 1 = 1.36699 loss)
I0717 04:49:37.023677 37548 sgd_solver.cpp:106] Iteration 23000, lr = 0.015
I0717 04:53:27.085582 37548 solver.cpp:236] Iteration 23050, loss = 1.07426
I0717 04:53:27.121435 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 04:53:27.121491 37548 solver.cpp:252]     Train net output #1: loss = 1.09133 (* 1 = 1.09133 loss)
I0717 04:53:28.028723 37548 sgd_solver.cpp:106] Iteration 23050, lr = 0.015
I0717 04:57:30.664520 37548 solver.cpp:236] Iteration 23100, loss = 1.08782
I0717 04:57:30.706924 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 04:57:30.706977 37548 solver.cpp:252]     Train net output #1: loss = 1.15426 (* 1 = 1.15426 loss)
I0717 04:57:31.550206 37548 sgd_solver.cpp:106] Iteration 23100, lr = 0.015
I0717 05:01:31.974256 37548 solver.cpp:236] Iteration 23150, loss = 1.07143
I0717 05:01:31.976796 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 05:01:31.976850 37548 solver.cpp:252]     Train net output #1: loss = 1.2236 (* 1 = 1.2236 loss)
I0717 05:01:32.855736 37548 sgd_solver.cpp:106] Iteration 23150, lr = 0.015
I0717 05:05:24.707597 37548 solver.cpp:236] Iteration 23200, loss = 1.05535
I0717 05:05:24.717705 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 05:05:24.717839 37548 solver.cpp:252]     Train net output #1: loss = 1.28378 (* 1 = 1.28378 loss)
I0717 05:05:25.596122 37548 sgd_solver.cpp:106] Iteration 23200, lr = 0.015
I0717 05:09:22.079828 37548 solver.cpp:236] Iteration 23250, loss = 1.04243
I0717 05:09:22.089558 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 05:09:22.089597 37548 solver.cpp:252]     Train net output #1: loss = 1.13277 (* 1 = 1.13277 loss)
I0717 05:09:22.964965 37548 sgd_solver.cpp:106] Iteration 23250, lr = 0.015
I0717 05:13:09.936702 37548 solver.cpp:236] Iteration 23300, loss = 1.04444
I0717 05:13:09.941354 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 05:13:09.941471 37548 solver.cpp:252]     Train net output #1: loss = 1.10814 (* 1 = 1.10814 loss)
I0717 05:13:10.813879 37548 sgd_solver.cpp:106] Iteration 23300, lr = 0.015
I0717 05:16:51.433475 37548 solver.cpp:236] Iteration 23350, loss = 1.04409
I0717 05:16:51.437891 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 05:16:51.437974 37548 solver.cpp:252]     Train net output #1: loss = 1.30019 (* 1 = 1.30019 loss)
I0717 05:16:52.288305 37548 sgd_solver.cpp:106] Iteration 23350, lr = 0.015
I0717 05:18:21.013027 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 05:20:44.747684 37548 solver.cpp:236] Iteration 23400, loss = 1.05692
I0717 05:20:44.748034 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 05:20:44.748085 37548 solver.cpp:252]     Train net output #1: loss = 1.02969 (* 1 = 1.02969 loss)
I0717 05:20:45.613457 37548 sgd_solver.cpp:106] Iteration 23400, lr = 0.015
I0717 05:24:36.131294 37548 solver.cpp:236] Iteration 23450, loss = 1.05947
I0717 05:24:36.131531 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 05:24:36.131569 37548 solver.cpp:252]     Train net output #1: loss = 1.28553 (* 1 = 1.28553 loss)
I0717 05:24:37.080829 37548 sgd_solver.cpp:106] Iteration 23450, lr = 0.015
I0717 05:28:37.504072 37548 solver.cpp:236] Iteration 23500, loss = 1.06432
I0717 05:28:37.548269 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 05:28:37.548337 37548 solver.cpp:252]     Train net output #1: loss = 0.99222 (* 1 = 0.99222 loss)
I0717 05:28:38.382829 37548 sgd_solver.cpp:106] Iteration 23500, lr = 0.015
I0717 05:32:33.511379 37548 solver.cpp:236] Iteration 23550, loss = 1.05938
I0717 05:32:33.554018 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 05:32:33.554045 37548 solver.cpp:252]     Train net output #1: loss = 0.960869 (* 1 = 0.960869 loss)
I0717 05:32:34.398900 37548 sgd_solver.cpp:106] Iteration 23550, lr = 0.015
I0717 05:36:29.358192 37548 solver.cpp:236] Iteration 23600, loss = 1.02868
I0717 05:36:29.368459 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0717 05:36:29.368580 37548 solver.cpp:252]     Train net output #1: loss = 0.625517 (* 1 = 0.625517 loss)
I0717 05:36:30.215575 37548 sgd_solver.cpp:106] Iteration 23600, lr = 0.015
I0717 05:40:22.401327 37548 solver.cpp:236] Iteration 23650, loss = 1.05086
I0717 05:40:22.442416 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 05:40:22.442453 37548 solver.cpp:252]     Train net output #1: loss = 1.31223 (* 1 = 1.31223 loss)
I0717 05:40:23.285374 37548 sgd_solver.cpp:106] Iteration 23650, lr = 0.015
I0717 05:44:19.644026 37548 solver.cpp:236] Iteration 23700, loss = 1.05981
I0717 05:44:19.664418 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 05:44:19.664492 37548 solver.cpp:252]     Train net output #1: loss = 1.08375 (* 1 = 1.08375 loss)
I0717 05:44:20.571223 37548 sgd_solver.cpp:106] Iteration 23700, lr = 0.015
I0717 05:48:25.685353 37548 solver.cpp:236] Iteration 23750, loss = 1.07259
I0717 05:48:25.731935 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 05:48:25.732041 37548 solver.cpp:252]     Train net output #1: loss = 1.13845 (* 1 = 1.13845 loss)
I0717 05:48:26.565979 37548 sgd_solver.cpp:106] Iteration 23750, lr = 0.015
I0717 05:49:46.683878 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 05:52:21.616596 37548 solver.cpp:236] Iteration 23800, loss = 1.07763
I0717 05:52:21.621132 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 05:52:21.621199 37548 solver.cpp:252]     Train net output #1: loss = 1.3121 (* 1 = 1.3121 loss)
I0717 05:52:22.488057 37548 sgd_solver.cpp:106] Iteration 23800, lr = 0.015
I0717 05:56:15.061316 37548 solver.cpp:236] Iteration 23850, loss = 1.07652
I0717 05:56:15.078516 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 05:56:15.078675 37548 solver.cpp:252]     Train net output #1: loss = 0.948572 (* 1 = 0.948572 loss)
I0717 05:56:15.938058 37548 sgd_solver.cpp:106] Iteration 23850, lr = 0.015
I0717 06:00:09.530104 37548 solver.cpp:236] Iteration 23900, loss = 1.03585
I0717 06:00:09.535226 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 06:00:09.535256 37548 solver.cpp:252]     Train net output #1: loss = 1.0006 (* 1 = 1.0006 loss)
I0717 06:00:10.457070 37548 sgd_solver.cpp:106] Iteration 23900, lr = 0.015
I0717 06:04:08.267197 37548 solver.cpp:236] Iteration 23950, loss = 1.08736
I0717 06:04:08.297906 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 06:04:08.297977 37548 solver.cpp:252]     Train net output #1: loss = 1.24542 (* 1 = 1.24542 loss)
I0717 06:04:09.146554 37548 sgd_solver.cpp:106] Iteration 23950, lr = 0.015
I0717 06:08:16.491938 37548 solver.cpp:340] Iteration 24000, Testing net (#0)
I0717 06:31:30.959753 37548 solver.cpp:408]     Test net output #0: accuracy = 0.461333
I0717 06:31:31.018782 37548 solver.cpp:408]     Test net output #1: loss = 1.06204 (* 1 = 1.06204 loss)
I0717 06:31:33.910997 37548 solver.cpp:236] Iteration 24000, loss = 1.04183
I0717 06:31:33.911157 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 06:31:33.911221 37548 solver.cpp:252]     Train net output #1: loss = 0.848527 (* 1 = 0.848527 loss)
I0717 06:31:33.911370 37548 sgd_solver.cpp:106] Iteration 24000, lr = 0.015
I0717 06:35:32.634733 37548 solver.cpp:236] Iteration 24050, loss = 1.05844
I0717 06:35:32.663363 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 06:35:32.663427 37548 solver.cpp:252]     Train net output #1: loss = 0.945924 (* 1 = 0.945924 loss)
I0717 06:35:33.563443 37548 sgd_solver.cpp:106] Iteration 24050, lr = 0.015
I0717 06:39:28.947470 37548 solver.cpp:236] Iteration 24100, loss = 1.08829
I0717 06:39:28.952445 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 06:39:28.952510 37548 solver.cpp:252]     Train net output #1: loss = 1.13571 (* 1 = 1.13571 loss)
I0717 06:39:29.842073 37548 sgd_solver.cpp:106] Iteration 24100, lr = 0.015
I0717 06:43:32.868235 37548 solver.cpp:236] Iteration 24150, loss = 1.05333
I0717 06:43:32.904337 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 06:43:32.919114 37548 solver.cpp:252]     Train net output #1: loss = 1.08695 (* 1 = 1.08695 loss)
I0717 06:43:33.748782 37548 sgd_solver.cpp:106] Iteration 24150, lr = 0.015
I0717 06:44:25.778892 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 06:47:34.395925 37548 solver.cpp:236] Iteration 24200, loss = 1.07699
I0717 06:47:34.432531 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 06:47:34.432600 37548 solver.cpp:252]     Train net output #1: loss = 1.0049 (* 1 = 1.0049 loss)
I0717 06:47:35.274875 37548 sgd_solver.cpp:106] Iteration 24200, lr = 0.015
I0717 06:51:39.820019 37548 solver.cpp:236] Iteration 24250, loss = 1.05847
I0717 06:51:39.850291 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 06:51:39.850343 37548 solver.cpp:252]     Train net output #1: loss = 1.14385 (* 1 = 1.14385 loss)
I0717 06:51:40.695133 37548 sgd_solver.cpp:106] Iteration 24250, lr = 0.015
I0717 06:55:37.362032 37548 solver.cpp:236] Iteration 24300, loss = 1.06121
I0717 06:55:37.372169 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 06:55:37.372233 37548 solver.cpp:252]     Train net output #1: loss = 1.02284 (* 1 = 1.02284 loss)
I0717 06:55:38.242266 37548 sgd_solver.cpp:106] Iteration 24300, lr = 0.015
I0717 06:59:38.078235 37548 solver.cpp:236] Iteration 24350, loss = 1.06234
I0717 06:59:38.109010 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 06:59:38.109125 37548 solver.cpp:252]     Train net output #1: loss = 0.967344 (* 1 = 0.967344 loss)
I0717 06:59:38.954056 37548 sgd_solver.cpp:106] Iteration 24350, lr = 0.015
I0717 07:03:35.135849 37548 solver.cpp:236] Iteration 24400, loss = 1.06404
I0717 07:03:35.164427 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 07:03:35.164527 37548 solver.cpp:252]     Train net output #1: loss = 1.07013 (* 1 = 1.07013 loss)
I0717 07:03:36.094666 37548 sgd_solver.cpp:106] Iteration 24400, lr = 0.015
I0717 07:07:26.161466 37548 solver.cpp:236] Iteration 24450, loss = 1.0675
I0717 07:07:26.168812 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 07:07:26.168836 37548 solver.cpp:252]     Train net output #1: loss = 1.03792 (* 1 = 1.03792 loss)
I0717 07:07:27.113523 37548 sgd_solver.cpp:106] Iteration 24450, lr = 0.015
I0717 07:11:22.980103 37548 solver.cpp:236] Iteration 24500, loss = 1.06984
I0717 07:11:23.006625 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 07:11:23.006686 37548 solver.cpp:252]     Train net output #1: loss = 1.00338 (* 1 = 1.00338 loss)
I0717 07:11:23.854585 37548 sgd_solver.cpp:106] Iteration 24500, lr = 0.015
I0717 07:15:21.311333 37548 solver.cpp:236] Iteration 24550, loss = 1.04184
I0717 07:15:21.343729 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 07:15:21.343822 37548 solver.cpp:252]     Train net output #1: loss = 0.949418 (* 1 = 0.949418 loss)
I0717 07:15:22.187714 37548 sgd_solver.cpp:106] Iteration 24550, lr = 0.015
I0717 07:15:40.627985 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 07:19:20.242367 37548 solver.cpp:236] Iteration 24600, loss = 1.07117
I0717 07:19:20.280511 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 07:19:20.280576 37548 solver.cpp:252]     Train net output #1: loss = 1.25073 (* 1 = 1.25073 loss)
I0717 07:19:21.126384 37548 sgd_solver.cpp:106] Iteration 24600, lr = 0.015
I0717 07:23:17.155952 37548 solver.cpp:236] Iteration 24650, loss = 1.04954
I0717 07:23:17.159963 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 07:23:17.160046 37548 solver.cpp:252]     Train net output #1: loss = 1.13464 (* 1 = 1.13464 loss)
I0717 07:23:18.037258 37548 sgd_solver.cpp:106] Iteration 24650, lr = 0.015
I0717 07:27:13.054940 37548 solver.cpp:236] Iteration 24700, loss = 1.07263
I0717 07:27:13.073086 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 07:27:13.073150 37548 solver.cpp:252]     Train net output #1: loss = 0.828417 (* 1 = 0.828417 loss)
I0717 07:27:13.926096 37548 sgd_solver.cpp:106] Iteration 24700, lr = 0.015
I0717 07:31:10.488018 37548 solver.cpp:236] Iteration 24750, loss = 1.05846
I0717 07:31:10.493933 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 07:31:10.494019 37548 solver.cpp:252]     Train net output #1: loss = 1.15734 (* 1 = 1.15734 loss)
I0717 07:31:11.448068 37548 sgd_solver.cpp:106] Iteration 24750, lr = 0.015
I0717 07:35:05.588770 37548 solver.cpp:236] Iteration 24800, loss = 1.02526
I0717 07:35:05.599598 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 07:35:05.599892 37548 solver.cpp:252]     Train net output #1: loss = 0.945229 (* 1 = 0.945229 loss)
I0717 07:35:06.460959 37548 sgd_solver.cpp:106] Iteration 24800, lr = 0.015
I0717 07:39:04.338058 37548 solver.cpp:236] Iteration 24850, loss = 1.09141
I0717 07:39:04.369493 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 07:39:04.369624 37548 solver.cpp:252]     Train net output #1: loss = 1.09063 (* 1 = 1.09063 loss)
I0717 07:39:05.284785 37548 sgd_solver.cpp:106] Iteration 24850, lr = 0.015
I0717 07:43:13.890594 37548 solver.cpp:236] Iteration 24900, loss = 1.06737
I0717 07:43:13.925833 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 07:43:13.925901 37548 solver.cpp:252]     Train net output #1: loss = 1.11703 (* 1 = 1.11703 loss)
I0717 07:43:14.771695 37548 sgd_solver.cpp:106] Iteration 24900, lr = 0.015
I0717 07:46:56.768501 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 07:47:00.146427 37548 solver.cpp:236] Iteration 24950, loss = 1.0571
I0717 07:47:00.146527 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 07:47:00.146572 37548 solver.cpp:252]     Train net output #1: loss = 1.30487 (* 1 = 1.30487 loss)
I0717 07:47:01.012020 37548 sgd_solver.cpp:106] Iteration 24950, lr = 0.015
I0717 07:50:40.383684 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_25000.caffemodel
I0717 07:50:41.478394 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_25000.solverstate
I0717 07:50:44.384862 37548 solver.cpp:236] Iteration 25000, loss = 1.08572
I0717 07:50:44.384994 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 07:50:44.385061 37548 solver.cpp:252]     Train net output #1: loss = 1.08061 (* 1 = 1.08061 loss)
I0717 07:50:45.325187 37548 sgd_solver.cpp:106] Iteration 25000, lr = 0.015
I0717 07:54:23.468926 37548 solver.cpp:236] Iteration 25050, loss = 1.03407
I0717 07:54:23.493528 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 07:54:23.493574 37548 solver.cpp:252]     Train net output #1: loss = 1.06936 (* 1 = 1.06936 loss)
I0717 07:54:24.343873 37548 sgd_solver.cpp:106] Iteration 25050, lr = 0.015
I0717 07:58:10.897608 37548 solver.cpp:236] Iteration 25100, loss = 1.05987
I0717 07:58:10.927654 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 07:58:10.927707 37548 solver.cpp:252]     Train net output #1: loss = 0.966104 (* 1 = 0.966104 loss)
I0717 07:58:11.850287 37548 sgd_solver.cpp:106] Iteration 25100, lr = 0.015
I0717 08:01:49.045928 37548 solver.cpp:236] Iteration 25150, loss = 1.07026
I0717 08:01:49.075181 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 08:01:49.075256 37548 solver.cpp:252]     Train net output #1: loss = 1.1539 (* 1 = 1.1539 loss)
I0717 08:01:49.941298 37548 sgd_solver.cpp:106] Iteration 25150, lr = 0.015
I0717 08:05:27.729202 37548 solver.cpp:236] Iteration 25200, loss = 1.07761
I0717 08:05:27.738850 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 08:05:27.767817 37548 solver.cpp:252]     Train net output #1: loss = 0.98552 (* 1 = 0.98552 loss)
I0717 08:05:28.677754 37548 sgd_solver.cpp:106] Iteration 25200, lr = 0.015
I0717 08:09:02.788535 37548 solver.cpp:236] Iteration 25250, loss = 1.04657
I0717 08:09:02.829407 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 08:09:02.829463 37548 solver.cpp:252]     Train net output #1: loss = 1.1352 (* 1 = 1.1352 loss)
I0717 08:09:03.674219 37548 sgd_solver.cpp:106] Iteration 25250, lr = 0.015
I0717 08:12:57.912863 37548 solver.cpp:236] Iteration 25300, loss = 1.05837
I0717 08:12:57.943078 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 08:12:57.943105 37548 solver.cpp:252]     Train net output #1: loss = 1.16809 (* 1 = 1.16809 loss)
I0717 08:12:58.876829 37548 sgd_solver.cpp:106] Iteration 25300, lr = 0.015
I0717 08:16:56.257428 37548 solver.cpp:236] Iteration 25350, loss = 1.06872
I0717 08:16:56.288430 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 08:16:56.288480 37548 solver.cpp:252]     Train net output #1: loss = 1.1374 (* 1 = 1.1374 loss)
I0717 08:16:57.142460 37548 sgd_solver.cpp:106] Iteration 25350, lr = 0.015
I0717 08:19:11.416977 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 08:20:55.854070 37548 solver.cpp:236] Iteration 25400, loss = 1.01823
I0717 08:20:55.883368 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 08:20:55.883437 37548 solver.cpp:252]     Train net output #1: loss = 1.03163 (* 1 = 1.03163 loss)
I0717 08:20:56.807252 37548 sgd_solver.cpp:106] Iteration 25400, lr = 0.015
I0717 08:25:02.373306 37548 solver.cpp:236] Iteration 25450, loss = 1.03227
I0717 08:25:02.408118 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 08:25:02.408195 37548 solver.cpp:252]     Train net output #1: loss = 1.04278 (* 1 = 1.04278 loss)
I0717 08:25:03.320279 37548 sgd_solver.cpp:106] Iteration 25450, lr = 0.015
I0717 08:29:00.475545 37548 solver.cpp:340] Iteration 25500, Testing net (#0)
I0717 08:52:15.103070 37548 solver.cpp:408]     Test net output #0: accuracy = 0.463667
I0717 08:52:15.160220 37548 solver.cpp:408]     Test net output #1: loss = 1.06361 (* 1 = 1.06361 loss)
I0717 08:52:18.042954 37548 solver.cpp:236] Iteration 25500, loss = 1.07166
I0717 08:52:18.043014 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 08:52:18.043035 37548 solver.cpp:252]     Train net output #1: loss = 1.13463 (* 1 = 1.13463 loss)
I0717 08:52:18.043093 37548 sgd_solver.cpp:106] Iteration 25500, lr = 0.015
I0717 08:56:27.461748 37548 solver.cpp:236] Iteration 25550, loss = 1.06715
I0717 08:56:27.506795 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 08:56:27.506856 37548 solver.cpp:252]     Train net output #1: loss = 1.20904 (* 1 = 1.20904 loss)
I0717 08:56:28.341249 37548 sgd_solver.cpp:106] Iteration 25550, lr = 0.015
I0717 09:00:28.469905 37548 solver.cpp:236] Iteration 25600, loss = 1.06205
I0717 09:00:28.500911 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 09:00:28.501000 37548 solver.cpp:252]     Train net output #1: loss = 1.16822 (* 1 = 1.16822 loss)
I0717 09:00:29.356379 37548 sgd_solver.cpp:106] Iteration 25600, lr = 0.015
I0717 09:04:13.208566 37548 solver.cpp:236] Iteration 25650, loss = 1.06654
I0717 09:04:13.219822 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 09:04:13.219858 37548 solver.cpp:252]     Train net output #1: loss = 1.19076 (* 1 = 1.19076 loss)
I0717 09:04:14.105036 37548 sgd_solver.cpp:106] Iteration 25650, lr = 0.015
I0717 09:08:11.651067 37548 solver.cpp:236] Iteration 25700, loss = 1.07724
I0717 09:08:11.681890 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 09:08:11.681974 37548 solver.cpp:252]     Train net output #1: loss = 1.09708 (* 1 = 1.09708 loss)
I0717 09:08:12.595515 37548 sgd_solver.cpp:106] Iteration 25700, lr = 0.015
I0717 09:12:06.288089 37548 solver.cpp:236] Iteration 25750, loss = 1.064
I0717 09:12:06.320876 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 09:12:06.320919 37548 solver.cpp:252]     Train net output #1: loss = 1.14228 (* 1 = 1.14228 loss)
I0717 09:12:07.160830 37548 sgd_solver.cpp:106] Iteration 25750, lr = 0.015
I0717 09:13:30.370971 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 09:15:49.892513 37548 solver.cpp:236] Iteration 25800, loss = 1.07073
I0717 09:15:49.898746 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 09:15:49.898810 37548 solver.cpp:252]     Train net output #1: loss = 0.986625 (* 1 = 0.986625 loss)
I0717 09:15:50.839872 37548 sgd_solver.cpp:106] Iteration 25800, lr = 0.015
I0717 09:19:32.197342 37548 solver.cpp:236] Iteration 25850, loss = 1.07845
I0717 09:19:32.235630 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 09:19:32.235682 37548 solver.cpp:252]     Train net output #1: loss = 1.19052 (* 1 = 1.19052 loss)
I0717 09:19:33.089342 37548 sgd_solver.cpp:106] Iteration 25850, lr = 0.015
I0717 09:23:11.886914 37548 solver.cpp:236] Iteration 25900, loss = 1.06319
I0717 09:23:11.932250 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 09:23:11.932368 37548 solver.cpp:252]     Train net output #1: loss = 0.931611 (* 1 = 0.931611 loss)
I0717 09:23:12.832861 37548 sgd_solver.cpp:106] Iteration 25900, lr = 0.015
I0717 09:26:59.217730 37548 solver.cpp:236] Iteration 25950, loss = 1.0702
I0717 09:26:59.274915 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 09:26:59.274971 37548 solver.cpp:252]     Train net output #1: loss = 0.945802 (* 1 = 0.945802 loss)
I0717 09:27:00.096060 37548 sgd_solver.cpp:106] Iteration 25950, lr = 0.015
I0717 09:30:59.559595 37548 solver.cpp:236] Iteration 26000, loss = 1.0675
I0717 09:30:59.594295 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 09:30:59.594424 37548 solver.cpp:252]     Train net output #1: loss = 1.00092 (* 1 = 1.00092 loss)
I0717 09:31:00.513360 37548 sgd_solver.cpp:106] Iteration 26000, lr = 0.015
I0717 09:35:07.023411 37548 solver.cpp:236] Iteration 26050, loss = 1.04676
I0717 09:35:07.060056 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 09:35:07.060163 37548 solver.cpp:252]     Train net output #1: loss = 1.13415 (* 1 = 1.13415 loss)
I0717 09:35:07.951514 37548 sgd_solver.cpp:106] Iteration 26050, lr = 0.015
I0717 09:39:09.068019 37548 solver.cpp:236] Iteration 26100, loss = 1.08118
I0717 09:39:09.095180 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 09:39:09.095221 37548 solver.cpp:252]     Train net output #1: loss = 1.17783 (* 1 = 1.17783 loss)
I0717 09:39:09.959306 37548 sgd_solver.cpp:106] Iteration 26100, lr = 0.015
I0717 09:42:53.468828 37548 solver.cpp:236] Iteration 26150, loss = 1.0691
I0717 09:42:53.497618 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 09:42:53.497676 37548 solver.cpp:252]     Train net output #1: loss = 1.26107 (* 1 = 1.26107 loss)
I0717 09:42:54.416858 37548 sgd_solver.cpp:106] Iteration 26150, lr = 0.015
I0717 09:45:28.601557 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 09:46:49.990360 37548 solver.cpp:236] Iteration 26200, loss = 1.04295
I0717 09:46:49.994050 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 09:46:49.994105 37548 solver.cpp:252]     Train net output #1: loss = 1.05907 (* 1 = 1.05907 loss)
I0717 09:46:50.851963 37548 sgd_solver.cpp:106] Iteration 26200, lr = 0.015
I0717 09:50:57.122612 37548 solver.cpp:236] Iteration 26250, loss = 1.05915
I0717 09:50:57.151724 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 09:50:57.151767 37548 solver.cpp:252]     Train net output #1: loss = 0.936797 (* 1 = 0.936797 loss)
I0717 09:50:58.043992 37548 sgd_solver.cpp:106] Iteration 26250, lr = 0.015
I0717 09:54:54.980475 37548 solver.cpp:236] Iteration 26300, loss = 1.0818
I0717 09:54:55.013923 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 09:54:55.013991 37548 solver.cpp:252]     Train net output #1: loss = 0.950973 (* 1 = 0.950973 loss)
I0717 09:54:55.862012 37548 sgd_solver.cpp:106] Iteration 26300, lr = 0.015
I0717 09:58:58.325376 37548 solver.cpp:236] Iteration 26350, loss = 1.02691
I0717 09:58:58.356672 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 09:58:58.356730 37548 solver.cpp:252]     Train net output #1: loss = 1.15954 (* 1 = 1.15954 loss)
I0717 09:58:59.276090 37548 sgd_solver.cpp:106] Iteration 26350, lr = 0.015
I0717 10:02:59.827457 37548 solver.cpp:236] Iteration 26400, loss = 1.09686
I0717 10:02:59.867116 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 10:02:59.887281 37548 solver.cpp:252]     Train net output #1: loss = 1.16491 (* 1 = 1.16491 loss)
I0717 10:03:00.720139 37548 sgd_solver.cpp:106] Iteration 26400, lr = 0.015
I0717 10:06:44.863787 37548 solver.cpp:236] Iteration 26450, loss = 1.06207
I0717 10:06:44.864018 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 10:06:44.864058 37548 solver.cpp:252]     Train net output #1: loss = 0.904178 (* 1 = 0.904178 loss)
I0717 10:06:45.743947 37548 sgd_solver.cpp:106] Iteration 26450, lr = 0.015
I0717 10:10:34.831887 37548 solver.cpp:236] Iteration 26500, loss = 1.06898
I0717 10:10:34.832183 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 10:10:34.832228 37548 solver.cpp:252]     Train net output #1: loss = 0.927785 (* 1 = 0.927785 loss)
I0717 10:10:35.718788 37548 sgd_solver.cpp:106] Iteration 26500, lr = 0.015
I0717 10:14:29.507469 37548 solver.cpp:236] Iteration 26550, loss = 0.997112
I0717 10:14:29.507800 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 10:14:29.507854 37548 solver.cpp:252]     Train net output #1: loss = 1.21645 (* 1 = 1.21645 loss)
I0717 10:14:30.394621 37548 sgd_solver.cpp:106] Iteration 26550, lr = 0.015
I0717 10:17:14.432319 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 10:18:24.022992 37548 solver.cpp:236] Iteration 26600, loss = 1.05776
I0717 10:18:24.023314 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 10:18:24.023401 37548 solver.cpp:252]     Train net output #1: loss = 1.21981 (* 1 = 1.21981 loss)
I0717 10:18:24.900805 37548 sgd_solver.cpp:106] Iteration 26600, lr = 0.015
I0717 10:22:15.137701 37548 solver.cpp:236] Iteration 26650, loss = 1.07513
I0717 10:22:15.137964 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 10:22:15.138010 37548 solver.cpp:252]     Train net output #1: loss = 0.954209 (* 1 = 0.954209 loss)
I0717 10:22:16.018612 37548 sgd_solver.cpp:106] Iteration 26650, lr = 0.015
I0717 10:26:07.071900 37548 solver.cpp:236] Iteration 26700, loss = 1.07984
I0717 10:26:07.072182 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 10:26:07.072252 37548 solver.cpp:252]     Train net output #1: loss = 1.02916 (* 1 = 1.02916 loss)
I0717 10:26:07.954216 37548 sgd_solver.cpp:106] Iteration 26700, lr = 0.015
I0717 10:30:00.151743 37548 solver.cpp:236] Iteration 26750, loss = 1.05663
I0717 10:30:00.152045 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 10:30:00.152078 37548 solver.cpp:252]     Train net output #1: loss = 1.27127 (* 1 = 1.27127 loss)
I0717 10:30:01.033030 37548 sgd_solver.cpp:106] Iteration 26750, lr = 0.015
I0717 10:33:50.316298 37548 solver.cpp:236] Iteration 26800, loss = 1.04716
I0717 10:33:50.316543 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 10:33:50.316566 37548 solver.cpp:252]     Train net output #1: loss = 1.10341 (* 1 = 1.10341 loss)
I0717 10:33:51.190933 37548 sgd_solver.cpp:106] Iteration 26800, lr = 0.015
I0717 10:37:44.050545 37548 solver.cpp:236] Iteration 26850, loss = 1.05467
I0717 10:37:44.050871 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 10:37:44.050938 37548 solver.cpp:252]     Train net output #1: loss = 0.936442 (* 1 = 0.936442 loss)
I0717 10:37:45.073846 37548 sgd_solver.cpp:106] Iteration 26850, lr = 0.015
I0717 10:41:40.036213 37548 solver.cpp:236] Iteration 26900, loss = 1.04471
I0717 10:41:40.036500 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 10:41:40.036559 37548 solver.cpp:252]     Train net output #1: loss = 0.920565 (* 1 = 0.920565 loss)
I0717 10:41:40.906553 37548 sgd_solver.cpp:106] Iteration 26900, lr = 0.015
I0717 10:45:35.349369 37548 solver.cpp:236] Iteration 26950, loss = 1.07583
I0717 10:45:35.349493 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 10:45:35.349526 37548 solver.cpp:252]     Train net output #1: loss = 1.13028 (* 1 = 1.13028 loss)
I0717 10:45:36.239295 37548 sgd_solver.cpp:106] Iteration 26950, lr = 0.015
I0717 10:48:41.587853 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 10:49:20.696102 37548 solver.cpp:340] Iteration 27000, Testing net (#0)
I0717 11:12:35.157837 37548 solver.cpp:408]     Test net output #0: accuracy = 0.456333
I0717 11:12:35.158251 37548 solver.cpp:408]     Test net output #1: loss = 1.07112 (* 1 = 1.07112 loss)
I0717 11:12:38.035604 37548 solver.cpp:236] Iteration 27000, loss = 1.06069
I0717 11:12:38.035686 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 11:12:38.035717 37548 solver.cpp:252]     Train net output #1: loss = 1.04059 (* 1 = 1.04059 loss)
I0717 11:12:38.035836 37548 sgd_solver.cpp:106] Iteration 27000, lr = 0.015
I0717 11:16:27.762456 37548 solver.cpp:236] Iteration 27050, loss = 1.06032
I0717 11:16:27.762743 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 11:16:27.762828 37548 solver.cpp:252]     Train net output #1: loss = 0.979525 (* 1 = 0.979525 loss)
I0717 11:16:28.634750 37548 sgd_solver.cpp:106] Iteration 27050, lr = 0.015
I0717 11:20:19.544608 37548 solver.cpp:236] Iteration 27100, loss = 1.06532
I0717 11:20:19.544910 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 11:20:19.544975 37548 solver.cpp:252]     Train net output #1: loss = 1.23911 (* 1 = 1.23911 loss)
I0717 11:20:20.426431 37548 sgd_solver.cpp:106] Iteration 27100, lr = 0.015
I0717 11:24:10.618232 37548 solver.cpp:236] Iteration 27150, loss = 1.09312
I0717 11:24:10.618551 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 11:24:10.618594 37548 solver.cpp:252]     Train net output #1: loss = 1.02524 (* 1 = 1.02524 loss)
I0717 11:24:11.482998 37548 sgd_solver.cpp:106] Iteration 27150, lr = 0.015
I0717 11:28:04.729444 37548 solver.cpp:236] Iteration 27200, loss = 1.07378
I0717 11:28:04.729629 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 11:28:04.729665 37548 solver.cpp:252]     Train net output #1: loss = 1.02602 (* 1 = 1.02602 loss)
I0717 11:28:05.602373 37548 sgd_solver.cpp:106] Iteration 27200, lr = 0.015
I0717 11:31:58.649595 37548 solver.cpp:236] Iteration 27250, loss = 1.04174
I0717 11:31:58.649827 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 11:31:58.649866 37548 solver.cpp:252]     Train net output #1: loss = 0.975876 (* 1 = 0.975876 loss)
I0717 11:31:59.592025 37548 sgd_solver.cpp:106] Iteration 27250, lr = 0.015
I0717 11:35:51.235277 37548 solver.cpp:236] Iteration 27300, loss = 1.07303
I0717 11:35:51.235554 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 11:35:51.235620 37548 solver.cpp:252]     Train net output #1: loss = 1.13501 (* 1 = 1.13501 loss)
I0717 11:35:52.162061 37548 sgd_solver.cpp:106] Iteration 27300, lr = 0.015
I0717 11:39:46.834003 37548 solver.cpp:236] Iteration 27350, loss = 1.07166
I0717 11:39:46.835631 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 11:39:46.835675 37548 solver.cpp:252]     Train net output #1: loss = 1.15399 (* 1 = 1.15399 loss)
I0717 11:39:47.790735 37548 sgd_solver.cpp:106] Iteration 27350, lr = 0.015
I0717 11:43:21.612994 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 11:43:35.161698 37548 solver.cpp:236] Iteration 27400, loss = 1.03407
I0717 11:43:35.161829 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 11:43:35.161905 37548 solver.cpp:252]     Train net output #1: loss = 1.06407 (* 1 = 1.06407 loss)
I0717 11:43:36.043421 37548 sgd_solver.cpp:106] Iteration 27400, lr = 0.015
I0717 11:47:29.301674 37548 solver.cpp:236] Iteration 27450, loss = 1.04854
I0717 11:47:29.302000 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 11:47:29.302094 37548 solver.cpp:252]     Train net output #1: loss = 1.08182 (* 1 = 1.08182 loss)
I0717 11:47:30.177479 37548 sgd_solver.cpp:106] Iteration 27450, lr = 0.015
I0717 11:51:20.814704 37548 solver.cpp:236] Iteration 27500, loss = 1.06843
I0717 11:51:20.815016 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 11:51:20.815073 37548 solver.cpp:252]     Train net output #1: loss = 1.04066 (* 1 = 1.04066 loss)
I0717 11:51:21.701910 37548 sgd_solver.cpp:106] Iteration 27500, lr = 0.015
I0717 11:55:08.771420 37548 solver.cpp:236] Iteration 27550, loss = 1.06916
I0717 11:55:08.771651 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 11:55:08.771716 37548 solver.cpp:252]     Train net output #1: loss = 1.0835 (* 1 = 1.0835 loss)
I0717 11:55:09.714084 37548 sgd_solver.cpp:106] Iteration 27550, lr = 0.015
I0717 11:59:03.862288 37548 solver.cpp:236] Iteration 27600, loss = 1.08397
I0717 11:59:03.862551 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 11:59:03.862601 37548 solver.cpp:252]     Train net output #1: loss = 1.03654 (* 1 = 1.03654 loss)
I0717 11:59:04.733693 37548 sgd_solver.cpp:106] Iteration 27600, lr = 0.015
I0717 12:03:00.276082 37548 solver.cpp:236] Iteration 27650, loss = 1.06919
I0717 12:03:00.276437 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 12:03:00.276484 37548 solver.cpp:252]     Train net output #1: loss = 1.32669 (* 1 = 1.32669 loss)
I0717 12:03:01.155104 37548 sgd_solver.cpp:106] Iteration 27650, lr = 0.015
I0717 12:06:53.606921 37548 solver.cpp:236] Iteration 27700, loss = 1.08173
I0717 12:06:53.607090 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 12:06:53.607125 37548 solver.cpp:252]     Train net output #1: loss = 1.02276 (* 1 = 1.02276 loss)
I0717 12:06:54.490969 37548 sgd_solver.cpp:106] Iteration 27700, lr = 0.015
I0717 12:10:45.831547 37548 solver.cpp:236] Iteration 27750, loss = 1.05905
I0717 12:10:45.831908 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 12:10:45.832005 37548 solver.cpp:252]     Train net output #1: loss = 1.07831 (* 1 = 1.07831 loss)
I0717 12:10:46.838491 37548 sgd_solver.cpp:106] Iteration 27750, lr = 0.015
I0717 12:14:38.726660 37548 solver.cpp:236] Iteration 27800, loss = 1.06901
I0717 12:14:38.726953 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 12:14:38.727013 37548 solver.cpp:252]     Train net output #1: loss = 1.11851 (* 1 = 1.11851 loss)
I0717 12:14:39.643237 37548 sgd_solver.cpp:106] Iteration 27800, lr = 0.015
I0717 12:14:44.127384 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 12:18:32.103981 37548 solver.cpp:236] Iteration 27850, loss = 1.06927
I0717 12:18:32.104357 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 12:18:32.104441 37548 solver.cpp:252]     Train net output #1: loss = 0.930257 (* 1 = 0.930257 loss)
I0717 12:18:33.034313 37548 sgd_solver.cpp:106] Iteration 27850, lr = 0.015
I0717 12:22:27.364352 37548 solver.cpp:236] Iteration 27900, loss = 1.07882
I0717 12:22:27.364673 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 12:22:27.364720 37548 solver.cpp:252]     Train net output #1: loss = 1.02561 (* 1 = 1.02561 loss)
I0717 12:22:28.293052 37548 sgd_solver.cpp:106] Iteration 27900, lr = 0.015
I0717 12:26:23.835191 37548 solver.cpp:236] Iteration 27950, loss = 1.04743
I0717 12:26:23.835454 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 12:26:23.835506 37548 solver.cpp:252]     Train net output #1: loss = 0.94997 (* 1 = 0.94997 loss)
I0717 12:26:24.717308 37548 sgd_solver.cpp:106] Iteration 27950, lr = 0.015
I0717 12:30:13.220701 37548 solver.cpp:236] Iteration 28000, loss = 1.03784
I0717 12:30:13.220986 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 12:30:13.221055 37548 solver.cpp:252]     Train net output #1: loss = 0.980904 (* 1 = 0.980904 loss)
I0717 12:30:14.131873 37548 sgd_solver.cpp:106] Iteration 28000, lr = 0.015
I0717 12:34:04.157013 37548 solver.cpp:236] Iteration 28050, loss = 1.04095
I0717 12:34:04.157275 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 12:34:04.157305 37548 solver.cpp:252]     Train net output #1: loss = 0.955627 (* 1 = 0.955627 loss)
I0717 12:34:05.035653 37548 sgd_solver.cpp:106] Iteration 28050, lr = 0.015
I0717 12:37:52.966730 37548 solver.cpp:236] Iteration 28100, loss = 1.03827
I0717 12:37:52.967010 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 12:37:52.967084 37548 solver.cpp:252]     Train net output #1: loss = 1.08581 (* 1 = 1.08581 loss)
I0717 12:37:53.853659 37548 sgd_solver.cpp:106] Iteration 28100, lr = 0.015
I0717 12:41:46.094907 37548 solver.cpp:236] Iteration 28150, loss = 1.08217
I0717 12:41:46.095145 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 12:41:46.095180 37548 solver.cpp:252]     Train net output #1: loss = 1.11939 (* 1 = 1.11939 loss)
I0717 12:41:47.031106 37548 sgd_solver.cpp:106] Iteration 28150, lr = 0.015
I0717 12:45:36.743438 37548 solver.cpp:236] Iteration 28200, loss = 1.0639
I0717 12:45:36.743700 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 12:45:36.743738 37548 solver.cpp:252]     Train net output #1: loss = 1.19107 (* 1 = 1.19107 loss)
I0717 12:45:37.635663 37548 sgd_solver.cpp:106] Iteration 28200, lr = 0.015
I0717 12:46:35.995383 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 12:49:30.110841 37548 solver.cpp:236] Iteration 28250, loss = 1.04129
I0717 12:49:30.111050 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 12:49:30.111099 37548 solver.cpp:252]     Train net output #1: loss = 0.833384 (* 1 = 0.833384 loss)
I0717 12:49:30.988492 37548 sgd_solver.cpp:106] Iteration 28250, lr = 0.015
I0717 12:53:28.750957 37548 solver.cpp:236] Iteration 28300, loss = 1.06207
I0717 12:53:28.751224 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 12:53:28.751271 37548 solver.cpp:252]     Train net output #1: loss = 1.13761 (* 1 = 1.13761 loss)
I0717 12:53:29.638041 37548 sgd_solver.cpp:106] Iteration 28300, lr = 0.015
I0717 12:57:24.789480 37548 solver.cpp:236] Iteration 28350, loss = 1.06196
I0717 12:57:24.789635 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 12:57:24.789667 37548 solver.cpp:252]     Train net output #1: loss = 1.06039 (* 1 = 1.06039 loss)
I0717 12:57:25.655163 37548 sgd_solver.cpp:106] Iteration 28350, lr = 0.015
I0717 13:01:17.684288 37548 solver.cpp:236] Iteration 28400, loss = 1.06395
I0717 13:01:17.684540 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 13:01:17.684573 37548 solver.cpp:252]     Train net output #1: loss = 1.15279 (* 1 = 1.15279 loss)
I0717 13:01:18.559651 37548 sgd_solver.cpp:106] Iteration 28400, lr = 0.015
I0717 13:05:11.995532 37548 solver.cpp:236] Iteration 28450, loss = 1.05974
I0717 13:05:11.995769 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 13:05:11.995800 37548 solver.cpp:252]     Train net output #1: loss = 0.8781 (* 1 = 0.8781 loss)
I0717 13:05:12.883862 37548 sgd_solver.cpp:106] Iteration 28450, lr = 0.015
I0717 13:09:02.652055 37548 solver.cpp:340] Iteration 28500, Testing net (#0)
I0717 13:32:17.137953 37548 solver.cpp:408]     Test net output #0: accuracy = 0.466667
I0717 13:32:17.138231 37548 solver.cpp:408]     Test net output #1: loss = 1.06068 (* 1 = 1.06068 loss)
I0717 13:32:20.010154 37548 solver.cpp:236] Iteration 28500, loss = 1.07669
I0717 13:32:20.010201 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 13:32:20.010218 37548 solver.cpp:252]     Train net output #1: loss = 1.07992 (* 1 = 1.07992 loss)
I0717 13:32:20.010254 37548 sgd_solver.cpp:106] Iteration 28500, lr = 0.015
I0717 13:36:15.734313 37548 solver.cpp:236] Iteration 28550, loss = 1.04549
I0717 13:36:15.734477 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 13:36:15.734515 37548 solver.cpp:252]     Train net output #1: loss = 0.940948 (* 1 = 0.940948 loss)
I0717 13:36:16.758041 37548 sgd_solver.cpp:106] Iteration 28550, lr = 0.015
I0717 13:40:09.811131 37548 solver.cpp:236] Iteration 28600, loss = 1.07281
I0717 13:40:09.811444 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 13:40:09.811506 37548 solver.cpp:252]     Train net output #1: loss = 1.03835 (* 1 = 1.03835 loss)
I0717 13:40:10.700472 37548 sgd_solver.cpp:106] Iteration 28600, lr = 0.015
I0717 13:41:34.618006 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 13:43:54.952891 37548 solver.cpp:236] Iteration 28650, loss = 1.0469
I0717 13:43:54.953196 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 13:43:54.953284 37548 solver.cpp:252]     Train net output #1: loss = 1.27755 (* 1 = 1.27755 loss)
I0717 13:43:55.906733 37548 sgd_solver.cpp:106] Iteration 28650, lr = 0.015
I0717 13:47:46.625613 37548 solver.cpp:236] Iteration 28700, loss = 1.07106
I0717 13:47:46.625911 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 13:47:46.625949 37548 solver.cpp:252]     Train net output #1: loss = 0.937228 (* 1 = 0.937228 loss)
I0717 13:47:47.502149 37548 sgd_solver.cpp:106] Iteration 28700, lr = 0.015
I0717 13:51:40.240260 37548 solver.cpp:236] Iteration 28750, loss = 1.07155
I0717 13:51:40.240566 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 13:51:40.240639 37548 solver.cpp:252]     Train net output #1: loss = 1.14209 (* 1 = 1.14209 loss)
I0717 13:51:41.191112 37548 sgd_solver.cpp:106] Iteration 28750, lr = 0.015
I0717 13:55:38.718291 37548 solver.cpp:236] Iteration 28800, loss = 1.08515
I0717 13:55:38.718544 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 13:55:38.718582 37548 solver.cpp:252]     Train net output #1: loss = 0.969368 (* 1 = 0.969368 loss)
I0717 13:55:39.600986 37548 sgd_solver.cpp:106] Iteration 28800, lr = 0.015
I0717 13:59:31.315369 37548 solver.cpp:236] Iteration 28850, loss = 1.08231
I0717 13:59:31.316089 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 13:59:31.316128 37548 solver.cpp:252]     Train net output #1: loss = 1.34174 (* 1 = 1.34174 loss)
I0717 13:59:32.189296 37548 sgd_solver.cpp:106] Iteration 28850, lr = 0.015
I0717 14:03:28.265736 37548 solver.cpp:236] Iteration 28900, loss = 1.05212
I0717 14:03:28.266027 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 14:03:28.266062 37548 solver.cpp:252]     Train net output #1: loss = 1.09195 (* 1 = 1.09195 loss)
I0717 14:03:29.151780 37548 sgd_solver.cpp:106] Iteration 28900, lr = 0.015
I0717 14:07:19.168844 37548 solver.cpp:236] Iteration 28950, loss = 1.05936
I0717 14:07:19.168995 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 14:07:19.169028 37548 solver.cpp:252]     Train net output #1: loss = 1.26671 (* 1 = 1.26671 loss)
I0717 14:07:20.093622 37548 sgd_solver.cpp:106] Iteration 28950, lr = 0.015
I0717 14:11:12.485002 37548 solver.cpp:236] Iteration 29000, loss = 1.08503
I0717 14:11:12.485247 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 14:11:12.485294 37548 solver.cpp:252]     Train net output #1: loss = 1.1694 (* 1 = 1.1694 loss)
I0717 14:11:13.358310 37548 sgd_solver.cpp:106] Iteration 29000, lr = 0.015
I0717 14:12:38.927608 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 14:15:07.859132 37548 solver.cpp:236] Iteration 29050, loss = 1.04878
I0717 14:15:07.859421 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 14:15:07.859462 37548 solver.cpp:252]     Train net output #1: loss = 1.1487 (* 1 = 1.1487 loss)
I0717 14:15:08.735704 37548 sgd_solver.cpp:106] Iteration 29050, lr = 0.015
I0717 14:18:58.970302 37548 solver.cpp:236] Iteration 29100, loss = 1.07019
I0717 14:18:58.970516 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 14:18:58.970561 37548 solver.cpp:252]     Train net output #1: loss = 0.920511 (* 1 = 0.920511 loss)
I0717 14:18:59.838106 37548 sgd_solver.cpp:106] Iteration 29100, lr = 0.015
I0717 14:22:50.627193 37548 solver.cpp:236] Iteration 29150, loss = 1.07397
I0717 14:22:50.627401 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 14:22:50.627424 37548 solver.cpp:252]     Train net output #1: loss = 0.927624 (* 1 = 0.927624 loss)
I0717 14:22:51.490772 37548 sgd_solver.cpp:106] Iteration 29150, lr = 0.015
I0717 14:26:42.814064 37548 solver.cpp:236] Iteration 29200, loss = 1.1125
I0717 14:26:42.814260 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 14:26:42.814301 37548 solver.cpp:252]     Train net output #1: loss = 0.961227 (* 1 = 0.961227 loss)
I0717 14:26:43.682152 37548 sgd_solver.cpp:106] Iteration 29200, lr = 0.015
I0717 14:30:38.929584 37548 solver.cpp:236] Iteration 29250, loss = 1.07343
I0717 14:30:38.929719 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 14:30:38.929759 37548 solver.cpp:252]     Train net output #1: loss = 1.00145 (* 1 = 1.00145 loss)
I0717 14:30:39.816813 37548 sgd_solver.cpp:106] Iteration 29250, lr = 0.015
I0717 14:34:35.871610 37548 solver.cpp:236] Iteration 29300, loss = 1.06675
I0717 14:34:35.871856 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 14:34:35.871891 37548 solver.cpp:252]     Train net output #1: loss = 1.09641 (* 1 = 1.09641 loss)
I0717 14:34:36.738168 37548 sgd_solver.cpp:106] Iteration 29300, lr = 0.015
I0717 14:38:24.545367 37548 solver.cpp:236] Iteration 29350, loss = 1.08609
I0717 14:38:24.545735 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 14:38:24.545792 37548 solver.cpp:252]     Train net output #1: loss = 0.971482 (* 1 = 0.971482 loss)
I0717 14:38:25.428624 37548 sgd_solver.cpp:106] Iteration 29350, lr = 0.015
I0717 14:42:25.973314 37548 solver.cpp:236] Iteration 29400, loss = 1.06089
I0717 14:42:25.973937 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 14:42:25.974071 37548 solver.cpp:252]     Train net output #1: loss = 0.880861 (* 1 = 0.880861 loss)
I0717 14:42:26.854310 37548 sgd_solver.cpp:106] Iteration 29400, lr = 0.015
I0717 14:43:53.215737 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 14:46:18.125844 37548 solver.cpp:236] Iteration 29450, loss = 1.07618
I0717 14:46:18.126090 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 14:46:18.126119 37548 solver.cpp:252]     Train net output #1: loss = 0.981163 (* 1 = 0.981163 loss)
I0717 14:46:19.006558 37548 sgd_solver.cpp:106] Iteration 29450, lr = 0.015
I0717 14:50:05.172914 37548 solver.cpp:236] Iteration 29500, loss = 1.07756
I0717 14:50:05.173270 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 14:50:05.173326 37548 solver.cpp:252]     Train net output #1: loss = 1.13174 (* 1 = 1.13174 loss)
I0717 14:50:06.045470 37548 sgd_solver.cpp:106] Iteration 29500, lr = 0.015
I0717 14:54:01.113116 37548 solver.cpp:236] Iteration 29550, loss = 1.07176
I0717 14:54:01.113294 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 14:54:01.113327 37548 solver.cpp:252]     Train net output #1: loss = 1.14793 (* 1 = 1.14793 loss)
I0717 14:54:01.987898 37548 sgd_solver.cpp:106] Iteration 29550, lr = 0.015
I0717 14:57:54.355075 37548 solver.cpp:236] Iteration 29600, loss = 1.07928
I0717 14:57:54.355540 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 14:57:54.355695 37548 solver.cpp:252]     Train net output #1: loss = 0.897076 (* 1 = 0.897076 loss)
I0717 14:57:55.216645 37548 sgd_solver.cpp:106] Iteration 29600, lr = 0.015
I0717 15:01:48.172153 37548 solver.cpp:236] Iteration 29650, loss = 1.0611
I0717 15:01:48.172538 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 15:01:48.172585 37548 solver.cpp:252]     Train net output #1: loss = 1.0197 (* 1 = 1.0197 loss)
I0717 15:01:49.061549 37548 sgd_solver.cpp:106] Iteration 29650, lr = 0.015
I0717 15:05:39.604316 37548 solver.cpp:236] Iteration 29700, loss = 1.0728
I0717 15:05:39.604567 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 15:05:39.604603 37548 solver.cpp:252]     Train net output #1: loss = 1.14223 (* 1 = 1.14223 loss)
I0717 15:05:40.486781 37548 sgd_solver.cpp:106] Iteration 29700, lr = 0.015
I0717 15:09:35.028710 37548 solver.cpp:236] Iteration 29750, loss = 1.07438
I0717 15:09:35.029083 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 15:09:35.029175 37548 solver.cpp:252]     Train net output #1: loss = 1.12359 (* 1 = 1.12359 loss)
I0717 15:09:35.971637 37548 sgd_solver.cpp:106] Iteration 29750, lr = 0.015
I0717 15:13:26.106269 37548 solver.cpp:236] Iteration 29800, loss = 1.05671
I0717 15:13:26.106498 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 15:13:26.106546 37548 solver.cpp:252]     Train net output #1: loss = 1.07546 (* 1 = 1.07546 loss)
I0717 15:13:27.034536 37548 sgd_solver.cpp:106] Iteration 29800, lr = 0.015
I0717 15:15:29.339818 37569 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 15:17:16.996628 37548 solver.cpp:236] Iteration 29850, loss = 1.06979
I0717 15:17:16.996906 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 15:17:16.996948 37548 solver.cpp:252]     Train net output #1: loss = 1.2609 (* 1 = 1.2609 loss)
I0717 15:17:17.889365 37548 sgd_solver.cpp:106] Iteration 29850, lr = 0.015
I0717 15:21:08.334255 37548 solver.cpp:236] Iteration 29900, loss = 1.05524
I0717 15:21:08.334569 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 15:21:08.334609 37548 solver.cpp:252]     Train net output #1: loss = 1.03908 (* 1 = 1.03908 loss)
I0717 15:21:09.208559 37548 sgd_solver.cpp:106] Iteration 29900, lr = 0.015
I0717 15:25:00.569600 37548 solver.cpp:236] Iteration 29950, loss = 1.07284
I0717 15:25:00.569906 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 15:25:00.569972 37548 solver.cpp:252]     Train net output #1: loss = 1.06122 (* 1 = 1.06122 loss)
I0717 15:25:01.449970 37548 sgd_solver.cpp:106] Iteration 29950, lr = 0.015
I0717 15:28:47.922780 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_30000.caffemodel
I0717 15:28:48.422408 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_30000.solverstate
I0717 15:28:48.521227 37548 solver.cpp:340] Iteration 30000, Testing net (#0)
I0717 15:52:02.904460 37548 solver.cpp:408]     Test net output #0: accuracy = 0.461333
I0717 15:52:02.904675 37548 solver.cpp:408]     Test net output #1: loss = 1.06481 (* 1 = 1.06481 loss)
I0717 15:52:05.772119 37548 solver.cpp:236] Iteration 30000, loss = 1.06475
I0717 15:52:05.772171 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 15:52:05.772188 37548 solver.cpp:252]     Train net output #1: loss = 1.22521 (* 1 = 1.22521 loss)
I0717 15:52:05.772224 37548 sgd_solver.cpp:106] Iteration 30000, lr = 0.015
I0717 15:55:59.718678 37548 solver.cpp:236] Iteration 30050, loss = 1.04803
I0717 15:55:59.719063 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 15:55:59.719156 37548 solver.cpp:252]     Train net output #1: loss = 0.930818 (* 1 = 0.930818 loss)
I0717 15:56:00.654705 37548 sgd_solver.cpp:106] Iteration 30050, lr = 0.015
I0717 15:59:54.080670 37548 solver.cpp:236] Iteration 30100, loss = 1.06588
I0717 15:59:54.080880 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 15:59:54.080922 37548 solver.cpp:252]     Train net output #1: loss = 1.02446 (* 1 = 1.02446 loss)
I0717 15:59:54.962945 37548 sgd_solver.cpp:106] Iteration 30100, lr = 0.015
I0717 16:03:48.677379 37548 solver.cpp:236] Iteration 30150, loss = 1.0433
I0717 16:03:48.677629 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 16:03:48.677659 37548 solver.cpp:252]     Train net output #1: loss = 1.18172 (* 1 = 1.18172 loss)
I0717 16:03:49.623085 37548 sgd_solver.cpp:106] Iteration 30150, lr = 0.015
I0717 16:07:46.863116 37548 solver.cpp:236] Iteration 30200, loss = 1.07067
I0717 16:07:46.863353 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 16:07:46.863387 37548 solver.cpp:252]     Train net output #1: loss = 1.37558 (* 1 = 1.37558 loss)
I0717 16:07:47.797062 37548 sgd_solver.cpp:106] Iteration 30200, lr = 0.015
I0717 16:10:26.673825 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 16:11:46.408488 37548 solver.cpp:236] Iteration 30250, loss = 1.06763
I0717 16:11:46.408763 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 16:11:46.408819 37548 solver.cpp:252]     Train net output #1: loss = 1.03136 (* 1 = 1.03136 loss)
I0717 16:11:47.289968 37548 sgd_solver.cpp:106] Iteration 30250, lr = 0.015
I0717 16:15:42.451406 37548 solver.cpp:236] Iteration 30300, loss = 1.04538
I0717 16:15:42.451756 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 16:15:42.451803 37548 solver.cpp:252]     Train net output #1: loss = 1.22866 (* 1 = 1.22866 loss)
I0717 16:15:43.334367 37548 sgd_solver.cpp:106] Iteration 30300, lr = 0.015
I0717 16:19:34.167645 37548 solver.cpp:236] Iteration 30350, loss = 1.05584
I0717 16:19:34.167881 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 16:19:34.167911 37548 solver.cpp:252]     Train net output #1: loss = 1.10603 (* 1 = 1.10603 loss)
I0717 16:19:35.052453 37548 sgd_solver.cpp:106] Iteration 30350, lr = 0.015
I0717 16:23:20.356086 37548 solver.cpp:236] Iteration 30400, loss = 1.06331
I0717 16:23:20.356297 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 16:23:20.356341 37548 solver.cpp:252]     Train net output #1: loss = 1.01913 (* 1 = 1.01913 loss)
I0717 16:23:21.307402 37548 sgd_solver.cpp:106] Iteration 30400, lr = 0.015
I0717 16:26:50.728739 37548 solver.cpp:236] Iteration 30450, loss = 1.05831
I0717 16:26:50.729065 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 16:26:50.729104 37548 solver.cpp:252]     Train net output #1: loss = 1.05837 (* 1 = 1.05837 loss)
I0717 16:26:51.623606 37548 sgd_solver.cpp:106] Iteration 30450, lr = 0.015
I0717 16:30:16.205453 37548 solver.cpp:236] Iteration 30500, loss = 1.06642
I0717 16:30:16.205760 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 16:30:16.205816 37548 solver.cpp:252]     Train net output #1: loss = 1.03151 (* 1 = 1.03151 loss)
I0717 16:30:17.089380 37548 sgd_solver.cpp:106] Iteration 30500, lr = 0.015
I0717 16:33:44.894691 37548 solver.cpp:236] Iteration 30550, loss = 1.09338
I0717 16:33:44.895015 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 16:33:44.895087 37548 solver.cpp:252]     Train net output #1: loss = 1.14932 (* 1 = 1.14932 loss)
I0717 16:33:45.774021 37548 sgd_solver.cpp:106] Iteration 30550, lr = 0.015
I0717 16:37:06.797011 37548 solver.cpp:236] Iteration 30600, loss = 1.07389
I0717 16:37:06.797263 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 16:37:06.797304 37548 solver.cpp:252]     Train net output #1: loss = 0.937606 (* 1 = 0.937606 loss)
I0717 16:37:07.670598 37548 sgd_solver.cpp:106] Iteration 30600, lr = 0.015
I0717 16:40:34.821352 37548 solver.cpp:236] Iteration 30650, loss = 1.08743
I0717 16:40:34.821559 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 16:40:34.821588 37548 solver.cpp:252]     Train net output #1: loss = 1.11874 (* 1 = 1.11874 loss)
I0717 16:40:35.686305 37548 sgd_solver.cpp:106] Iteration 30650, lr = 0.015
I0717 16:43:40.099500 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 16:43:59.189787 37548 solver.cpp:236] Iteration 30700, loss = 1.08915
I0717 16:43:59.189865 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 16:43:59.189903 37548 solver.cpp:252]     Train net output #1: loss = 1.06117 (* 1 = 1.06117 loss)
I0717 16:44:00.192325 37548 sgd_solver.cpp:106] Iteration 30700, lr = 0.015
I0717 16:47:24.378669 37548 solver.cpp:236] Iteration 30750, loss = 1.04887
I0717 16:47:24.378933 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 16:47:24.378973 37548 solver.cpp:252]     Train net output #1: loss = 1.01294 (* 1 = 1.01294 loss)
I0717 16:47:25.260220 37548 sgd_solver.cpp:106] Iteration 30750, lr = 0.015
I0717 16:50:50.926997 37548 solver.cpp:236] Iteration 30800, loss = 1.03933
I0717 16:50:50.927265 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 16:50:50.927320 37548 solver.cpp:252]     Train net output #1: loss = 0.921812 (* 1 = 0.921812 loss)
I0717 16:50:51.785780 37548 sgd_solver.cpp:106] Iteration 30800, lr = 0.015
I0717 16:54:15.244007 37548 solver.cpp:236] Iteration 30850, loss = 1.07283
I0717 16:54:15.244248 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 16:54:15.244282 37548 solver.cpp:252]     Train net output #1: loss = 0.939062 (* 1 = 0.939062 loss)
I0717 16:54:15.244343 37548 sgd_solver.cpp:106] Iteration 30850, lr = 0.015
I0717 16:57:41.174901 37548 solver.cpp:236] Iteration 30900, loss = 1.05568
I0717 16:57:41.175196 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 16:57:41.175268 37548 solver.cpp:252]     Train net output #1: loss = 0.80815 (* 1 = 0.80815 loss)
I0717 16:57:42.120715 37548 sgd_solver.cpp:106] Iteration 30900, lr = 0.015
I0717 17:01:03.577942 37548 solver.cpp:236] Iteration 30950, loss = 1.04617
I0717 17:01:03.578161 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 17:01:03.578207 37548 solver.cpp:252]     Train net output #1: loss = 1.13965 (* 1 = 1.13965 loss)
I0717 17:01:04.496253 37548 sgd_solver.cpp:106] Iteration 30950, lr = 0.015
I0717 17:04:28.448843 37548 solver.cpp:236] Iteration 31000, loss = 1.06556
I0717 17:04:28.449137 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 17:04:28.449170 37548 solver.cpp:252]     Train net output #1: loss = 1.06576 (* 1 = 1.06576 loss)
I0717 17:04:29.334018 37548 sgd_solver.cpp:106] Iteration 31000, lr = 0.015
I0717 17:07:51.792768 37548 solver.cpp:236] Iteration 31050, loss = 1.08084
I0717 17:07:51.793077 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 17:07:51.793117 37548 solver.cpp:252]     Train net output #1: loss = 0.984469 (* 1 = 0.984469 loss)
I0717 17:07:52.686826 37548 sgd_solver.cpp:106] Iteration 31050, lr = 0.015
I0717 17:11:14.879854 37548 solver.cpp:236] Iteration 31100, loss = 1.06327
I0717 17:11:14.880079 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 17:11:14.880115 37548 solver.cpp:252]     Train net output #1: loss = 0.994049 (* 1 = 0.994049 loss)
I0717 17:11:15.760221 37548 sgd_solver.cpp:106] Iteration 31100, lr = 0.015
I0717 17:14:42.122124 37548 solver.cpp:236] Iteration 31150, loss = 1.07968
I0717 17:14:42.122370 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 17:14:42.122436 37548 solver.cpp:252]     Train net output #1: loss = 1.0338 (* 1 = 1.0338 loss)
I0717 17:14:42.997565 37548 sgd_solver.cpp:106] Iteration 31150, lr = 0.015
I0717 17:18:06.253875 37548 solver.cpp:236] Iteration 31200, loss = 1.04545
I0717 17:18:06.254151 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 17:18:06.254209 37548 solver.cpp:252]     Train net output #1: loss = 1.21851 (* 1 = 1.21851 loss)
I0717 17:18:07.193760 37548 sgd_solver.cpp:106] Iteration 31200, lr = 0.015
I0717 17:18:19.368090 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 17:21:25.117298 37548 solver.cpp:236] Iteration 31250, loss = 1.06401
I0717 17:21:25.117570 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 17:21:25.117615 37548 solver.cpp:252]     Train net output #1: loss = 1.0276 (* 1 = 1.0276 loss)
I0717 17:21:26.133462 37548 sgd_solver.cpp:106] Iteration 31250, lr = 0.015
I0717 17:24:50.392042 37548 solver.cpp:236] Iteration 31300, loss = 1.0366
I0717 17:24:50.392272 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 17:24:50.392308 37548 solver.cpp:252]     Train net output #1: loss = 1.02961 (* 1 = 1.02961 loss)
I0717 17:24:51.263010 37548 sgd_solver.cpp:106] Iteration 31300, lr = 0.015
I0717 17:28:16.834604 37548 solver.cpp:236] Iteration 31350, loss = 1.06707
I0717 17:28:16.834828 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 17:28:16.834877 37548 solver.cpp:252]     Train net output #1: loss = 1.14434 (* 1 = 1.14434 loss)
I0717 17:28:17.831086 37548 sgd_solver.cpp:106] Iteration 31350, lr = 0.015
I0717 17:31:46.253049 37548 solver.cpp:236] Iteration 31400, loss = 1.04366
I0717 17:31:46.253430 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 17:31:46.253506 37548 solver.cpp:252]     Train net output #1: loss = 1.03699 (* 1 = 1.03699 loss)
I0717 17:31:47.124110 37548 sgd_solver.cpp:106] Iteration 31400, lr = 0.015
I0717 17:35:10.979923 37548 solver.cpp:236] Iteration 31450, loss = 1.06397
I0717 17:35:10.980219 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 17:35:10.980285 37548 solver.cpp:252]     Train net output #1: loss = 1.1515 (* 1 = 1.1515 loss)
I0717 17:35:11.895799 37548 sgd_solver.cpp:106] Iteration 31450, lr = 0.015
I0717 17:38:33.739737 37548 solver.cpp:340] Iteration 31500, Testing net (#0)
I0717 18:01:47.515688 37548 solver.cpp:408]     Test net output #0: accuracy = 0.458
I0717 18:01:47.515972 37548 solver.cpp:408]     Test net output #1: loss = 1.06259 (* 1 = 1.06259 loss)
I0717 18:01:50.388799 37548 solver.cpp:236] Iteration 31500, loss = 1.07892
I0717 18:01:50.388877 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 18:01:50.388913 37548 solver.cpp:252]     Train net output #1: loss = 1.02986 (* 1 = 1.02986 loss)
I0717 18:01:50.389000 37548 sgd_solver.cpp:106] Iteration 31500, lr = 0.015
I0717 18:05:16.156944 37548 solver.cpp:236] Iteration 31550, loss = 1.05207
I0717 18:05:16.157223 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 18:05:16.157263 37548 solver.cpp:252]     Train net output #1: loss = 1.08309 (* 1 = 1.08309 loss)
I0717 18:05:17.104490 37548 sgd_solver.cpp:106] Iteration 31550, lr = 0.015
I0717 18:08:41.374188 37548 solver.cpp:236] Iteration 31600, loss = 1.06431
I0717 18:08:41.374413 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 18:08:41.374452 37548 solver.cpp:252]     Train net output #1: loss = 1.10988 (* 1 = 1.10988 loss)
I0717 18:08:42.339855 37548 sgd_solver.cpp:106] Iteration 31600, lr = 0.015
I0717 18:12:05.300523 37548 solver.cpp:236] Iteration 31650, loss = 1.04934
I0717 18:12:05.300834 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 18:12:05.300870 37548 solver.cpp:252]     Train net output #1: loss = 1.02022 (* 1 = 1.02022 loss)
I0717 18:12:06.242975 37548 sgd_solver.cpp:106] Iteration 31650, lr = 0.015
I0717 18:15:29.862771 37548 solver.cpp:236] Iteration 31700, loss = 1.02873
I0717 18:15:29.864506 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 18:15:29.864542 37548 solver.cpp:252]     Train net output #1: loss = 1.29259 (* 1 = 1.29259 loss)
I0717 18:15:30.735520 37548 sgd_solver.cpp:106] Iteration 31700, lr = 0.015
I0717 18:15:50.594837 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 18:18:52.635541 37548 solver.cpp:236] Iteration 31750, loss = 1.06596
I0717 18:18:52.635774 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 18:18:52.635809 37548 solver.cpp:252]     Train net output #1: loss = 1.22831 (* 1 = 1.22831 loss)
I0717 18:18:53.508776 37548 sgd_solver.cpp:106] Iteration 31750, lr = 0.015
I0717 18:22:20.737800 37548 solver.cpp:236] Iteration 31800, loss = 1.05685
I0717 18:22:20.738091 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 18:22:20.738129 37548 solver.cpp:252]     Train net output #1: loss = 1.27461 (* 1 = 1.27461 loss)
I0717 18:22:21.626895 37548 sgd_solver.cpp:106] Iteration 31800, lr = 0.015
I0717 18:25:45.734510 37548 solver.cpp:236] Iteration 31850, loss = 1.03546
I0717 18:25:45.734764 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 18:25:45.734815 37548 solver.cpp:252]     Train net output #1: loss = 0.950702 (* 1 = 0.950702 loss)
I0717 18:25:46.738983 37548 sgd_solver.cpp:106] Iteration 31850, lr = 0.015
I0717 18:29:10.635627 37548 solver.cpp:236] Iteration 31900, loss = 1.06391
I0717 18:29:10.635896 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 18:29:10.635934 37548 solver.cpp:252]     Train net output #1: loss = 0.947601 (* 1 = 0.947601 loss)
I0717 18:29:11.598284 37548 sgd_solver.cpp:106] Iteration 31900, lr = 0.015
I0717 18:32:34.835185 37548 solver.cpp:236] Iteration 31950, loss = 1.06318
I0717 18:32:34.835419 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 18:32:34.835520 37548 solver.cpp:252]     Train net output #1: loss = 1.01709 (* 1 = 1.01709 loss)
I0717 18:32:35.774111 37548 sgd_solver.cpp:106] Iteration 31950, lr = 0.015
I0717 18:35:57.309944 37548 solver.cpp:236] Iteration 32000, loss = 1.06406
I0717 18:35:57.310179 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 18:35:57.310210 37548 solver.cpp:252]     Train net output #1: loss = 1.24621 (* 1 = 1.24621 loss)
I0717 18:35:58.182552 37548 sgd_solver.cpp:106] Iteration 32000, lr = 0.015
I0717 18:39:24.366411 37548 solver.cpp:236] Iteration 32050, loss = 1.06388
I0717 18:39:24.366735 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 18:39:24.366773 37548 solver.cpp:252]     Train net output #1: loss = 1.48954 (* 1 = 1.48954 loss)
I0717 18:39:25.228830 37548 sgd_solver.cpp:106] Iteration 32050, lr = 0.015
I0717 18:42:48.577558 37548 solver.cpp:236] Iteration 32100, loss = 1.08102
I0717 18:42:48.577739 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 18:42:48.577786 37548 solver.cpp:252]     Train net output #1: loss = 1.16935 (* 1 = 1.16935 loss)
I0717 18:42:49.449893 37548 sgd_solver.cpp:106] Iteration 32100, lr = 0.015
I0717 18:46:14.833432 37548 solver.cpp:236] Iteration 32150, loss = 1.05358
I0717 18:46:14.833745 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 18:46:14.833807 37548 solver.cpp:252]     Train net output #1: loss = 1.01585 (* 1 = 1.01585 loss)
I0717 18:46:15.721063 37548 sgd_solver.cpp:106] Iteration 32150, lr = 0.015
I0717 18:49:40.956567 37548 solver.cpp:236] Iteration 32200, loss = 1.06987
I0717 18:49:40.956750 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 18:49:40.956815 37548 solver.cpp:252]     Train net output #1: loss = 0.99442 (* 1 = 0.99442 loss)
I0717 18:49:41.911655 37548 sgd_solver.cpp:106] Iteration 32200, lr = 0.015
I0717 18:50:05.683341 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 18:53:01.829183 37548 solver.cpp:236] Iteration 32250, loss = 1.07837
I0717 18:53:01.829407 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 18:53:01.829453 37548 solver.cpp:252]     Train net output #1: loss = 0.986566 (* 1 = 0.986566 loss)
I0717 18:53:02.769785 37548 sgd_solver.cpp:106] Iteration 32250, lr = 0.015
I0717 18:56:27.376406 37548 solver.cpp:236] Iteration 32300, loss = 1.05471
I0717 18:56:27.378701 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 18:56:27.378742 37548 solver.cpp:252]     Train net output #1: loss = 1.23601 (* 1 = 1.23601 loss)
I0717 18:56:28.326202 37548 sgd_solver.cpp:106] Iteration 32300, lr = 0.015
I0717 18:59:52.626427 37548 solver.cpp:236] Iteration 32350, loss = 1.0582
I0717 18:59:52.626729 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 18:59:52.626796 37548 solver.cpp:252]     Train net output #1: loss = 1.13313 (* 1 = 1.13313 loss)
I0717 18:59:53.503898 37548 sgd_solver.cpp:106] Iteration 32350, lr = 0.015
I0717 19:03:20.442802 37548 solver.cpp:236] Iteration 32400, loss = 1.0788
I0717 19:03:20.443013 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 19:03:20.443058 37548 solver.cpp:252]     Train net output #1: loss = 1.1426 (* 1 = 1.1426 loss)
I0717 19:03:21.316424 37548 sgd_solver.cpp:106] Iteration 32400, lr = 0.015
I0717 19:06:47.496744 37548 solver.cpp:236] Iteration 32450, loss = 1.08236
I0717 19:06:47.496987 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 19:06:47.497040 37548 solver.cpp:252]     Train net output #1: loss = 1.19393 (* 1 = 1.19393 loss)
I0717 19:06:48.370942 37548 sgd_solver.cpp:106] Iteration 32450, lr = 0.015
I0717 19:10:14.801489 37548 solver.cpp:236] Iteration 32500, loss = 1.09009
I0717 19:10:14.801769 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:10:14.801806 37548 solver.cpp:252]     Train net output #1: loss = 1.05968 (* 1 = 1.05968 loss)
I0717 19:10:15.763314 37548 sgd_solver.cpp:106] Iteration 32500, lr = 0.015
I0717 19:13:41.956018 37548 solver.cpp:236] Iteration 32550, loss = 1.0654
I0717 19:13:41.956473 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:13:41.956617 37548 solver.cpp:252]     Train net output #1: loss = 1.09003 (* 1 = 1.09003 loss)
I0717 19:13:42.892660 37548 sgd_solver.cpp:106] Iteration 32550, lr = 0.015
I0717 19:17:07.808192 37548 solver.cpp:236] Iteration 32600, loss = 1.07081
I0717 19:17:07.812430 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:17:07.812481 37548 solver.cpp:252]     Train net output #1: loss = 1.03606 (* 1 = 1.03606 loss)
I0717 19:17:08.684566 37548 sgd_solver.cpp:106] Iteration 32600, lr = 0.015
I0717 19:20:34.710377 37548 solver.cpp:236] Iteration 32650, loss = 1.05902
I0717 19:20:34.710702 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:20:34.710754 37548 solver.cpp:252]     Train net output #1: loss = 1.07897 (* 1 = 1.07897 loss)
I0717 19:20:35.593416 37548 sgd_solver.cpp:106] Iteration 32650, lr = 0.015
I0717 19:24:01.648540 37548 solver.cpp:236] Iteration 32700, loss = 1.09017
I0717 19:24:01.648843 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:24:01.648876 37548 solver.cpp:252]     Train net output #1: loss = 1.00342 (* 1 = 1.00342 loss)
I0717 19:24:02.517822 37548 sgd_solver.cpp:106] Iteration 32700, lr = 0.015
I0717 19:24:32.329474 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 19:27:27.559100 37548 solver.cpp:236] Iteration 32750, loss = 1.04632
I0717 19:27:27.561144 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 19:27:27.561183 37548 solver.cpp:252]     Train net output #1: loss = 1.22169 (* 1 = 1.22169 loss)
I0717 19:27:28.449679 37548 sgd_solver.cpp:106] Iteration 32750, lr = 0.015
I0717 19:30:52.556835 37548 solver.cpp:236] Iteration 32800, loss = 1.0855
I0717 19:30:52.557034 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:30:52.557097 37548 solver.cpp:252]     Train net output #1: loss = 1.07901 (* 1 = 1.07901 loss)
I0717 19:30:53.495633 37548 sgd_solver.cpp:106] Iteration 32800, lr = 0.015
I0717 19:34:18.271823 37548 solver.cpp:236] Iteration 32850, loss = 1.07115
I0717 19:34:18.271973 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 19:34:18.271996 37548 solver.cpp:252]     Train net output #1: loss = 1.01459 (* 1 = 1.01459 loss)
I0717 19:34:19.157934 37548 sgd_solver.cpp:106] Iteration 32850, lr = 0.015
I0717 19:37:45.473812 37548 solver.cpp:236] Iteration 32900, loss = 1.01343
I0717 19:37:45.473974 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 19:37:45.474027 37548 solver.cpp:252]     Train net output #1: loss = 1.00552 (* 1 = 1.00552 loss)
I0717 19:37:46.433732 37548 sgd_solver.cpp:106] Iteration 32900, lr = 0.015
I0717 19:41:15.307235 37548 solver.cpp:236] Iteration 32950, loss = 1.05606
I0717 19:41:15.307521 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 19:41:15.307569 37548 solver.cpp:252]     Train net output #1: loss = 1.07452 (* 1 = 1.07452 loss)
I0717 19:41:16.187445 37548 sgd_solver.cpp:106] Iteration 32950, lr = 0.015
I0717 19:44:35.603382 37548 solver.cpp:340] Iteration 33000, Testing net (#0)
I0717 20:07:49.421555 37548 solver.cpp:408]     Test net output #0: accuracy = 0.467667
I0717 20:07:49.421843 37548 solver.cpp:408]     Test net output #1: loss = 1.0587 (* 1 = 1.0587 loss)
I0717 20:07:52.274212 37548 solver.cpp:236] Iteration 33000, loss = 1.07071
I0717 20:07:52.274296 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:07:52.274343 37548 solver.cpp:252]     Train net output #1: loss = 0.945316 (* 1 = 0.945316 loss)
I0717 20:07:52.274425 37548 sgd_solver.cpp:106] Iteration 33000, lr = 0.015
I0717 20:11:15.020197 37548 solver.cpp:236] Iteration 33050, loss = 1.06989
I0717 20:11:15.020426 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 20:11:15.020450 37548 solver.cpp:252]     Train net output #1: loss = 1.20964 (* 1 = 1.20964 loss)
I0717 20:11:15.877817 37548 sgd_solver.cpp:106] Iteration 33050, lr = 0.015
I0717 20:14:38.053346 37548 solver.cpp:236] Iteration 33100, loss = 1.08195
I0717 20:14:38.053555 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:14:38.053597 37548 solver.cpp:252]     Train net output #1: loss = 0.963532 (* 1 = 0.963532 loss)
I0717 20:14:39.005029 37548 sgd_solver.cpp:106] Iteration 33100, lr = 0.015
I0717 20:18:05.742447 37548 solver.cpp:236] Iteration 33150, loss = 1.05974
I0717 20:18:05.742787 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:18:05.742894 37548 solver.cpp:252]     Train net output #1: loss = 0.930772 (* 1 = 0.930772 loss)
I0717 20:18:06.637101 37548 sgd_solver.cpp:106] Iteration 33150, lr = 0.015
I0717 20:21:30.033707 37548 solver.cpp:236] Iteration 33200, loss = 1.04085
I0717 20:21:30.033990 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:21:30.034050 37548 solver.cpp:252]     Train net output #1: loss = 0.926495 (* 1 = 0.926495 loss)
I0717 20:21:30.920006 37548 sgd_solver.cpp:106] Iteration 33200, lr = 0.015
I0717 20:22:12.819389 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 20:24:53.879871 37548 solver.cpp:236] Iteration 33250, loss = 1.0791
I0717 20:24:53.880215 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 20:24:53.880261 37548 solver.cpp:252]     Train net output #1: loss = 1.03117 (* 1 = 1.03117 loss)
I0717 20:24:54.827400 37548 sgd_solver.cpp:106] Iteration 33250, lr = 0.015
I0717 20:28:17.231534 37548 solver.cpp:236] Iteration 33300, loss = 1.07315
I0717 20:28:17.231797 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:28:17.231837 37548 solver.cpp:252]     Train net output #1: loss = 1.00382 (* 1 = 1.00382 loss)
I0717 20:28:18.174773 37548 sgd_solver.cpp:106] Iteration 33300, lr = 0.015
I0717 20:31:39.583016 37548 solver.cpp:236] Iteration 33350, loss = 1.0609
I0717 20:31:39.583350 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 20:31:39.583416 37548 solver.cpp:252]     Train net output #1: loss = 1.02533 (* 1 = 1.02533 loss)
I0717 20:31:40.532140 37548 sgd_solver.cpp:106] Iteration 33350, lr = 0.015
I0717 20:35:05.064672 37548 solver.cpp:236] Iteration 33400, loss = 1.07268
I0717 20:35:05.064872 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 20:35:05.064903 37548 solver.cpp:252]     Train net output #1: loss = 1.03814 (* 1 = 1.03814 loss)
I0717 20:35:06.016758 37548 sgd_solver.cpp:106] Iteration 33400, lr = 0.015
I0717 20:38:28.249491 37548 solver.cpp:236] Iteration 33450, loss = 1.06526
I0717 20:38:28.249774 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 20:38:28.249830 37548 solver.cpp:252]     Train net output #1: loss = 1.13909 (* 1 = 1.13909 loss)
I0717 20:38:29.120764 37548 sgd_solver.cpp:106] Iteration 33450, lr = 0.015
I0717 20:41:55.772207 37548 solver.cpp:236] Iteration 33500, loss = 1.06269
I0717 20:41:55.772555 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:41:55.772611 37548 solver.cpp:252]     Train net output #1: loss = 0.967487 (* 1 = 0.967487 loss)
I0717 20:41:56.655640 37548 sgd_solver.cpp:106] Iteration 33500, lr = 0.015
I0717 20:45:24.032908 37548 solver.cpp:236] Iteration 33550, loss = 1.07138
I0717 20:45:24.033138 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 20:45:24.033179 37548 solver.cpp:252]     Train net output #1: loss = 0.800341 (* 1 = 0.800341 loss)
I0717 20:45:24.911511 37548 sgd_solver.cpp:106] Iteration 33550, lr = 0.015
I0717 20:48:50.291291 37548 solver.cpp:236] Iteration 33600, loss = 1.07398
I0717 20:48:50.291561 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 20:48:50.291626 37548 solver.cpp:252]     Train net output #1: loss = 1.11427 (* 1 = 1.11427 loss)
I0717 20:48:51.237905 37548 sgd_solver.cpp:106] Iteration 33600, lr = 0.015
I0717 20:52:17.823809 37548 solver.cpp:236] Iteration 33650, loss = 1.0706
I0717 20:52:17.824059 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:52:17.824111 37548 solver.cpp:252]     Train net output #1: loss = 0.972431 (* 1 = 0.972431 loss)
I0717 20:52:18.758061 37548 sgd_solver.cpp:106] Iteration 33650, lr = 0.015
I0717 20:55:41.182999 37548 solver.cpp:236] Iteration 33700, loss = 1.0618
I0717 20:55:41.183145 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 20:55:41.183200 37548 solver.cpp:252]     Train net output #1: loss = 0.984048 (* 1 = 0.984048 loss)
I0717 20:55:42.110431 37548 sgd_solver.cpp:106] Iteration 33700, lr = 0.015
I0717 20:56:52.499408 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 20:59:05.637825 37548 solver.cpp:236] Iteration 33750, loss = 1.0647
I0717 20:59:05.638080 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 20:59:05.638115 37548 solver.cpp:252]     Train net output #1: loss = 1.02341 (* 1 = 1.02341 loss)
I0717 20:59:06.525187 37548 sgd_solver.cpp:106] Iteration 33750, lr = 0.015
I0717 21:02:31.211211 37548 solver.cpp:236] Iteration 33800, loss = 1.05891
I0717 21:02:31.211489 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 21:02:31.211549 37548 solver.cpp:252]     Train net output #1: loss = 1.17445 (* 1 = 1.17445 loss)
I0717 21:02:32.094472 37548 sgd_solver.cpp:106] Iteration 33800, lr = 0.015
I0717 21:05:58.892983 37548 solver.cpp:236] Iteration 33850, loss = 1.06831
I0717 21:05:58.893152 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 21:05:58.893198 37548 solver.cpp:252]     Train net output #1: loss = 1.15475 (* 1 = 1.15475 loss)
I0717 21:05:59.837635 37548 sgd_solver.cpp:106] Iteration 33850, lr = 0.015
I0717 21:09:21.837524 37548 solver.cpp:236] Iteration 33900, loss = 1.08745
I0717 21:09:21.837848 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 21:09:21.837872 37548 solver.cpp:252]     Train net output #1: loss = 1.175 (* 1 = 1.175 loss)
I0717 21:09:22.719681 37548 sgd_solver.cpp:106] Iteration 33900, lr = 0.015
I0717 21:12:48.042915 37548 solver.cpp:236] Iteration 33950, loss = 1.0795
I0717 21:12:48.043274 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 21:12:48.043325 37548 solver.cpp:252]     Train net output #1: loss = 1.08084 (* 1 = 1.08084 loss)
I0717 21:12:48.925571 37548 sgd_solver.cpp:106] Iteration 33950, lr = 0.015
I0717 21:16:13.605793 37548 solver.cpp:236] Iteration 34000, loss = 1.06081
I0717 21:16:13.605988 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 21:16:13.606034 37548 solver.cpp:252]     Train net output #1: loss = 0.910781 (* 1 = 0.910781 loss)
I0717 21:16:14.562767 37548 sgd_solver.cpp:106] Iteration 34000, lr = 0.015
I0717 21:19:38.331147 37548 solver.cpp:236] Iteration 34050, loss = 1.07331
I0717 21:19:38.331392 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0717 21:19:38.331413 37548 solver.cpp:252]     Train net output #1: loss = 1.27068 (* 1 = 1.27068 loss)
I0717 21:19:39.275317 37548 sgd_solver.cpp:106] Iteration 34050, lr = 0.015
I0717 21:23:03.022244 37548 solver.cpp:236] Iteration 34100, loss = 1.07746
I0717 21:23:03.022526 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 21:23:03.022562 37548 solver.cpp:252]     Train net output #1: loss = 0.980198 (* 1 = 0.980198 loss)
I0717 21:23:03.906803 37548 sgd_solver.cpp:106] Iteration 34100, lr = 0.015
I0717 21:26:30.181715 37548 solver.cpp:236] Iteration 34150, loss = 1.06937
I0717 21:26:30.181921 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 21:26:30.181953 37548 solver.cpp:252]     Train net output #1: loss = 1.12797 (* 1 = 1.12797 loss)
I0717 21:26:31.171223 37548 sgd_solver.cpp:106] Iteration 34150, lr = 0.015
I0717 21:29:56.310577 37548 solver.cpp:236] Iteration 34200, loss = 1.07077
I0717 21:29:56.310813 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 21:29:56.310842 37548 solver.cpp:252]     Train net output #1: loss = 1.06554 (* 1 = 1.06554 loss)
I0717 21:29:57.190680 37548 sgd_solver.cpp:106] Iteration 34200, lr = 0.015
I0717 21:31:14.758527 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 21:33:21.120654 37548 solver.cpp:236] Iteration 34250, loss = 1.08323
I0717 21:33:21.120852 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 21:33:21.120879 37548 solver.cpp:252]     Train net output #1: loss = 0.970432 (* 1 = 0.970432 loss)
I0717 21:33:22.002651 37548 sgd_solver.cpp:106] Iteration 34250, lr = 0.015
I0717 21:36:46.137121 37548 solver.cpp:236] Iteration 34300, loss = 1.07241
I0717 21:36:46.137399 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0717 21:36:46.137436 37548 solver.cpp:252]     Train net output #1: loss = 0.70683 (* 1 = 0.70683 loss)
I0717 21:36:47.022661 37548 sgd_solver.cpp:106] Iteration 34300, lr = 0.015
I0717 21:40:11.367506 37548 solver.cpp:236] Iteration 34350, loss = 1.0753
I0717 21:40:11.367758 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 21:40:11.367810 37548 solver.cpp:252]     Train net output #1: loss = 1.07914 (* 1 = 1.07914 loss)
I0717 21:40:12.315845 37548 sgd_solver.cpp:106] Iteration 34350, lr = 0.015
I0717 21:43:36.278980 37548 solver.cpp:236] Iteration 34400, loss = 1.08104
I0717 21:43:36.279227 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 21:43:36.279273 37548 solver.cpp:252]     Train net output #1: loss = 1.11407 (* 1 = 1.11407 loss)
I0717 21:43:37.161515 37548 sgd_solver.cpp:106] Iteration 34400, lr = 0.015
I0717 21:46:58.441404 37548 solver.cpp:236] Iteration 34450, loss = 1.09193
I0717 21:46:58.441664 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 21:46:58.441720 37548 solver.cpp:252]     Train net output #1: loss = 0.937003 (* 1 = 0.937003 loss)
I0717 21:46:59.380437 37548 sgd_solver.cpp:106] Iteration 34450, lr = 0.015
I0717 21:50:21.568545 37548 solver.cpp:340] Iteration 34500, Testing net (#0)
I0717 22:13:35.158020 37548 solver.cpp:408]     Test net output #0: accuracy = 0.462666
I0717 22:13:35.168315 37548 solver.cpp:408]     Test net output #1: loss = 1.06191 (* 1 = 1.06191 loss)
I0717 22:13:38.042060 37548 solver.cpp:236] Iteration 34500, loss = 1.07596
I0717 22:13:38.042127 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 22:13:38.042188 37548 solver.cpp:252]     Train net output #1: loss = 1.02118 (* 1 = 1.02118 loss)
I0717 22:13:38.042249 37548 sgd_solver.cpp:106] Iteration 34500, lr = 0.015
I0717 22:17:08.067294 37548 solver.cpp:236] Iteration 34550, loss = 1.0516
I0717 22:17:08.067481 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 22:17:08.067519 37548 solver.cpp:252]     Train net output #1: loss = 1.03035 (* 1 = 1.03035 loss)
I0717 22:17:08.958940 37548 sgd_solver.cpp:106] Iteration 34550, lr = 0.015
I0717 22:20:36.510016 37548 solver.cpp:236] Iteration 34600, loss = 1.07376
I0717 22:20:36.510195 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 22:20:36.510217 37548 solver.cpp:252]     Train net output #1: loss = 1.0539 (* 1 = 1.0539 loss)
I0717 22:20:37.475581 37548 sgd_solver.cpp:106] Iteration 34600, lr = 0.015
I0717 22:24:02.746328 37548 solver.cpp:236] Iteration 34650, loss = 1.04608
I0717 22:24:02.746563 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 22:24:02.746608 37548 solver.cpp:252]     Train net output #1: loss = 0.893768 (* 1 = 0.893768 loss)
I0717 22:24:03.691831 37548 sgd_solver.cpp:106] Iteration 34650, lr = 0.015
I0717 22:27:27.534870 37548 solver.cpp:236] Iteration 34700, loss = 1.03522
I0717 22:27:27.535104 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 22:27:27.535130 37548 solver.cpp:252]     Train net output #1: loss = 0.970935 (* 1 = 0.970935 loss)
I0717 22:27:28.421066 37548 sgd_solver.cpp:106] Iteration 34700, lr = 0.015
I0717 22:29:00.920799 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 22:30:50.874534 37548 solver.cpp:236] Iteration 34750, loss = 1.06418
I0717 22:30:50.874812 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 22:30:50.874835 37548 solver.cpp:252]     Train net output #1: loss = 0.896488 (* 1 = 0.896488 loss)
I0717 22:30:51.752708 37548 sgd_solver.cpp:106] Iteration 34750, lr = 0.015
I0717 22:34:15.861764 37548 solver.cpp:236] Iteration 34800, loss = 1.06805
I0717 22:34:15.861907 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 22:34:15.861933 37548 solver.cpp:252]     Train net output #1: loss = 0.953444 (* 1 = 0.953444 loss)
I0717 22:34:16.822978 37548 sgd_solver.cpp:106] Iteration 34800, lr = 0.015
I0717 22:37:42.014133 37548 solver.cpp:236] Iteration 34850, loss = 1.06311
I0717 22:37:42.014327 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 22:37:42.014394 37548 solver.cpp:252]     Train net output #1: loss = 1.01892 (* 1 = 1.01892 loss)
I0717 22:37:42.963452 37548 sgd_solver.cpp:106] Iteration 34850, lr = 0.015
I0717 22:41:08.104998 37548 solver.cpp:236] Iteration 34900, loss = 1.02728
I0717 22:41:08.105886 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 22:41:08.105932 37548 solver.cpp:252]     Train net output #1: loss = 0.95842 (* 1 = 0.95842 loss)
I0717 22:41:08.976905 37548 sgd_solver.cpp:106] Iteration 34900, lr = 0.015
I0717 22:44:33.141568 37548 solver.cpp:236] Iteration 34950, loss = 1.07909
I0717 22:44:33.141741 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 22:44:33.141782 37548 solver.cpp:252]     Train net output #1: loss = 0.971425 (* 1 = 0.971425 loss)
I0717 22:44:34.024220 37548 sgd_solver.cpp:106] Iteration 34950, lr = 0.015
I0717 22:47:58.179510 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_35000.caffemodel
I0717 22:47:59.670068 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_35000.solverstate
I0717 22:48:02.637785 37548 solver.cpp:236] Iteration 35000, loss = 1.08573
I0717 22:48:02.637850 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 22:48:02.637876 37548 solver.cpp:252]     Train net output #1: loss = 1.24643 (* 1 = 1.24643 loss)
I0717 22:48:03.516779 37548 sgd_solver.cpp:106] Iteration 35000, lr = 0.015
I0717 22:51:31.491133 37548 solver.cpp:236] Iteration 35050, loss = 1.08509
I0717 22:51:31.491528 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 22:51:31.491585 37548 solver.cpp:252]     Train net output #1: loss = 1.02822 (* 1 = 1.02822 loss)
I0717 22:51:32.369016 37548 sgd_solver.cpp:106] Iteration 35050, lr = 0.015
I0717 22:54:57.140527 37548 solver.cpp:236] Iteration 35100, loss = 1.07836
I0717 22:54:57.140769 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 22:54:57.140832 37548 solver.cpp:252]     Train net output #1: loss = 1.13559 (* 1 = 1.13559 loss)
I0717 22:54:58.087224 37548 sgd_solver.cpp:106] Iteration 35100, lr = 0.015
I0717 22:58:23.238113 37548 solver.cpp:236] Iteration 35150, loss = 1.06043
I0717 22:58:23.238345 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 22:58:23.238376 37548 solver.cpp:252]     Train net output #1: loss = 1.19613 (* 1 = 1.19613 loss)
I0717 22:58:24.201748 37548 sgd_solver.cpp:106] Iteration 35150, lr = 0.015
I0717 23:01:46.570807 37548 solver.cpp:236] Iteration 35200, loss = 1.05409
I0717 23:01:46.571002 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 23:01:46.571025 37548 solver.cpp:252]     Train net output #1: loss = 1.16378 (* 1 = 1.16378 loss)
I0717 23:01:47.444305 37548 sgd_solver.cpp:106] Iteration 35200, lr = 0.015
I0717 23:03:04.529646 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 23:05:13.702726 37548 solver.cpp:236] Iteration 35250, loss = 1.08322
I0717 23:05:13.702983 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 23:05:13.703033 37548 solver.cpp:252]     Train net output #1: loss = 1.09336 (* 1 = 1.09336 loss)
I0717 23:05:14.576705 37548 sgd_solver.cpp:106] Iteration 35250, lr = 0.015
I0717 23:08:36.023100 37548 solver.cpp:236] Iteration 35300, loss = 1.04686
I0717 23:08:36.023381 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 23:08:36.023408 37548 solver.cpp:252]     Train net output #1: loss = 1.31563 (* 1 = 1.31563 loss)
I0717 23:08:37.007427 37548 sgd_solver.cpp:106] Iteration 35300, lr = 0.015
I0717 23:12:06.097244 37548 solver.cpp:236] Iteration 35350, loss = 1.10052
I0717 23:12:06.097434 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 23:12:06.097455 37548 solver.cpp:252]     Train net output #1: loss = 1.07343 (* 1 = 1.07343 loss)
I0717 23:12:07.047446 37548 sgd_solver.cpp:106] Iteration 35350, lr = 0.015
I0717 23:15:30.798883 37548 solver.cpp:236] Iteration 35400, loss = 1.04698
I0717 23:15:30.799154 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 23:15:30.799193 37548 solver.cpp:252]     Train net output #1: loss = 0.886095 (* 1 = 0.886095 loss)
I0717 23:15:31.683940 37548 sgd_solver.cpp:106] Iteration 35400, lr = 0.015
I0717 23:18:59.258852 37548 solver.cpp:236] Iteration 35450, loss = 1.05918
I0717 23:18:59.259141 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 23:18:59.259181 37548 solver.cpp:252]     Train net output #1: loss = 0.966454 (* 1 = 0.966454 loss)
I0717 23:19:00.200026 37548 sgd_solver.cpp:106] Iteration 35450, lr = 0.015
I0717 23:22:28.965445 37548 solver.cpp:236] Iteration 35500, loss = 1.04742
I0717 23:22:28.966085 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 23:22:28.966145 37548 solver.cpp:252]     Train net output #1: loss = 1.08369 (* 1 = 1.08369 loss)
I0717 23:22:29.844041 37548 sgd_solver.cpp:106] Iteration 35500, lr = 0.015
I0717 23:25:57.991883 37548 solver.cpp:236] Iteration 35550, loss = 1.03926
I0717 23:25:57.992156 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0717 23:25:57.992197 37548 solver.cpp:252]     Train net output #1: loss = 0.781318 (* 1 = 0.781318 loss)
I0717 23:25:58.868671 37548 sgd_solver.cpp:106] Iteration 35550, lr = 0.015
I0717 23:29:26.391307 37548 solver.cpp:236] Iteration 35600, loss = 1.07765
I0717 23:29:26.391574 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 23:29:26.391614 37548 solver.cpp:252]     Train net output #1: loss = 1.26535 (* 1 = 1.26535 loss)
I0717 23:29:27.274457 37548 sgd_solver.cpp:106] Iteration 35600, lr = 0.015
I0717 23:32:51.307903 37548 solver.cpp:236] Iteration 35650, loss = 1.06051
I0717 23:32:51.308110 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0717 23:32:51.308156 37548 solver.cpp:252]     Train net output #1: loss = 0.961446 (* 1 = 0.961446 loss)
I0717 23:32:52.186969 37548 sgd_solver.cpp:106] Iteration 35650, lr = 0.015
I0717 23:36:16.664139 37548 solver.cpp:236] Iteration 35700, loss = 1.07659
I0717 23:36:16.664484 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0717 23:36:16.664540 37548 solver.cpp:252]     Train net output #1: loss = 1.22184 (* 1 = 1.22184 loss)
I0717 23:36:17.538750 37548 sgd_solver.cpp:106] Iteration 35700, lr = 0.015
I0717 23:37:51.218176 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0717 23:39:42.004791 37548 solver.cpp:236] Iteration 35750, loss = 1.07409
I0717 23:39:42.004992 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 23:39:42.005025 37548 solver.cpp:252]     Train net output #1: loss = 1.11828 (* 1 = 1.11828 loss)
I0717 23:39:42.920069 37548 sgd_solver.cpp:106] Iteration 35750, lr = 0.015
I0717 23:43:05.500835 37548 solver.cpp:236] Iteration 35800, loss = 1.07236
I0717 23:43:05.501147 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 23:43:05.501197 37548 solver.cpp:252]     Train net output #1: loss = 1.01909 (* 1 = 1.01909 loss)
I0717 23:43:06.385506 37548 sgd_solver.cpp:106] Iteration 35800, lr = 0.015
I0717 23:46:30.887055 37548 solver.cpp:236] Iteration 35850, loss = 1.03668
I0717 23:46:30.887320 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 23:46:30.887358 37548 solver.cpp:252]     Train net output #1: loss = 1.02881 (* 1 = 1.02881 loss)
I0717 23:46:31.770833 37548 sgd_solver.cpp:106] Iteration 35850, lr = 0.015
I0717 23:49:55.029368 37548 solver.cpp:236] Iteration 35900, loss = 1.0564
I0717 23:49:55.029608 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0717 23:49:55.029655 37548 solver.cpp:252]     Train net output #1: loss = 0.985989 (* 1 = 0.985989 loss)
I0717 23:49:55.969650 37548 sgd_solver.cpp:106] Iteration 35900, lr = 0.015
I0717 23:53:20.265727 37548 solver.cpp:236] Iteration 35950, loss = 1.08779
I0717 23:53:20.270711 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0717 23:53:20.270750 37548 solver.cpp:252]     Train net output #1: loss = 1.09418 (* 1 = 1.09418 loss)
I0717 23:53:21.139724 37548 sgd_solver.cpp:106] Iteration 35950, lr = 0.015
I0717 23:56:40.634670 37548 solver.cpp:340] Iteration 36000, Testing net (#0)
I0718 00:19:54.366289 37548 solver.cpp:408]     Test net output #0: accuracy = 0.460333
I0718 00:19:54.381217 37548 solver.cpp:408]     Test net output #1: loss = 1.06632 (* 1 = 1.06632 loss)
I0718 00:19:57.234294 37548 solver.cpp:236] Iteration 36000, loss = 1.06262
I0718 00:19:57.234362 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:19:57.234395 37548 solver.cpp:252]     Train net output #1: loss = 1.08589 (* 1 = 1.08589 loss)
I0718 00:19:57.234468 37548 sgd_solver.cpp:106] Iteration 36000, lr = 0.015
I0718 00:23:25.400375 37548 solver.cpp:236] Iteration 36050, loss = 1.07632
I0718 00:23:25.416056 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 00:23:25.416098 37548 solver.cpp:252]     Train net output #1: loss = 1.22554 (* 1 = 1.22554 loss)
I0718 00:23:26.272413 37548 sgd_solver.cpp:106] Iteration 36050, lr = 0.015
I0718 00:26:52.559984 37548 solver.cpp:236] Iteration 36100, loss = 1.03528
I0718 00:26:52.560307 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:26:52.560344 37548 solver.cpp:252]     Train net output #1: loss = 1.02349 (* 1 = 1.02349 loss)
I0718 00:26:53.433668 37548 sgd_solver.cpp:106] Iteration 36100, lr = 0.015
I0718 00:30:18.425545 37548 solver.cpp:236] Iteration 36150, loss = 1.06927
I0718 00:30:18.425835 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:30:18.425882 37548 solver.cpp:252]     Train net output #1: loss = 1.03907 (* 1 = 1.03907 loss)
I0718 00:30:19.368891 37548 sgd_solver.cpp:106] Iteration 36150, lr = 0.015
I0718 00:33:45.042460 37548 solver.cpp:236] Iteration 36200, loss = 1.04372
I0718 00:33:45.042822 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:33:45.042876 37548 solver.cpp:252]     Train net output #1: loss = 0.947675 (* 1 = 0.947675 loss)
I0718 00:33:45.912840 37548 sgd_solver.cpp:106] Iteration 36200, lr = 0.015
I0718 00:35:40.568320 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 00:37:10.797163 37548 solver.cpp:236] Iteration 36250, loss = 1.04595
I0718 00:37:10.797420 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 00:37:10.797463 37548 solver.cpp:252]     Train net output #1: loss = 1.2064 (* 1 = 1.2064 loss)
I0718 00:37:11.677399 37548 sgd_solver.cpp:106] Iteration 36250, lr = 0.015
I0718 00:40:36.343441 37548 solver.cpp:236] Iteration 36300, loss = 1.07004
I0718 00:40:36.343693 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 00:40:36.343745 37548 solver.cpp:252]     Train net output #1: loss = 1.17723 (* 1 = 1.17723 loss)
I0718 00:40:37.296633 37548 sgd_solver.cpp:106] Iteration 36300, lr = 0.015
I0718 00:44:00.416105 37548 solver.cpp:236] Iteration 36350, loss = 1.06702
I0718 00:44:00.416286 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 00:44:00.416343 37548 solver.cpp:252]     Train net output #1: loss = 1.13699 (* 1 = 1.13699 loss)
I0718 00:44:01.276945 37548 sgd_solver.cpp:106] Iteration 36350, lr = 0.015
I0718 00:47:25.416956 37548 solver.cpp:236] Iteration 36400, loss = 1.05748
I0718 00:47:25.417176 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:47:25.417209 37548 solver.cpp:252]     Train net output #1: loss = 1.05413 (* 1 = 1.05413 loss)
I0718 00:47:26.303277 37548 sgd_solver.cpp:106] Iteration 36400, lr = 0.015
I0718 00:50:47.108356 37548 solver.cpp:236] Iteration 36450, loss = 1.08493
I0718 00:50:47.108614 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 00:50:47.108680 37548 solver.cpp:252]     Train net output #1: loss = 1.22141 (* 1 = 1.22141 loss)
I0718 00:50:47.983376 37548 sgd_solver.cpp:106] Iteration 36450, lr = 0.015
I0718 00:54:13.481091 37548 solver.cpp:236] Iteration 36500, loss = 1.07501
I0718 00:54:13.481288 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:54:13.481324 37548 solver.cpp:252]     Train net output #1: loss = 1.08448 (* 1 = 1.08448 loss)
I0718 00:54:14.431434 37548 sgd_solver.cpp:106] Iteration 36500, lr = 0.015
I0718 00:57:40.897649 37548 solver.cpp:236] Iteration 36550, loss = 1.06973
I0718 00:57:40.897883 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 00:57:40.897917 37548 solver.cpp:252]     Train net output #1: loss = 1.10022 (* 1 = 1.10022 loss)
I0718 00:57:41.782835 37548 sgd_solver.cpp:106] Iteration 36550, lr = 0.015
I0718 01:01:07.071208 37548 solver.cpp:236] Iteration 36600, loss = 1.09367
I0718 01:01:07.071508 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:01:07.071540 37548 solver.cpp:252]     Train net output #1: loss = 0.90839 (* 1 = 0.90839 loss)
I0718 01:01:07.944646 37548 sgd_solver.cpp:106] Iteration 36600, lr = 0.015
I0718 01:04:34.832399 37548 solver.cpp:236] Iteration 36650, loss = 1.04994
I0718 01:04:34.832648 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 01:04:34.832684 37548 solver.cpp:252]     Train net output #1: loss = 1.11196 (* 1 = 1.11196 loss)
I0718 01:04:35.709837 37548 sgd_solver.cpp:106] Iteration 36650, lr = 0.015
I0718 01:08:02.163524 37548 solver.cpp:236] Iteration 36700, loss = 1.09708
I0718 01:08:02.163826 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 01:08:02.163851 37548 solver.cpp:252]     Train net output #1: loss = 1.20893 (* 1 = 1.20893 loss)
I0718 01:08:03.053203 37548 sgd_solver.cpp:106] Iteration 36700, lr = 0.015
I0718 01:09:54.514799 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 01:11:28.933164 37548 solver.cpp:236] Iteration 36750, loss = 1.07226
I0718 01:11:28.933360 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 01:11:28.933400 37548 solver.cpp:252]     Train net output #1: loss = 1.02464 (* 1 = 1.02464 loss)
I0718 01:11:29.880633 37548 sgd_solver.cpp:106] Iteration 36750, lr = 0.015
I0718 01:14:56.750427 37548 solver.cpp:236] Iteration 36800, loss = 1.04881
I0718 01:14:56.750691 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:14:56.750753 37548 solver.cpp:252]     Train net output #1: loss = 0.972245 (* 1 = 0.972245 loss)
I0718 01:14:57.683112 37548 sgd_solver.cpp:106] Iteration 36800, lr = 0.015
I0718 01:18:23.107935 37548 solver.cpp:236] Iteration 36850, loss = 1.06715
I0718 01:18:23.108184 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 01:18:23.108222 37548 solver.cpp:252]     Train net output #1: loss = 1.04787 (* 1 = 1.04787 loss)
I0718 01:18:23.992297 37548 sgd_solver.cpp:106] Iteration 36850, lr = 0.015
I0718 01:21:46.823859 37548 solver.cpp:236] Iteration 36900, loss = 1.06287
I0718 01:21:46.824107 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:21:46.824128 37548 solver.cpp:252]     Train net output #1: loss = 0.920309 (* 1 = 0.920309 loss)
I0718 01:21:47.748518 37548 sgd_solver.cpp:106] Iteration 36900, lr = 0.015
I0718 01:25:13.408406 37548 solver.cpp:236] Iteration 36950, loss = 1.04532
I0718 01:25:13.408677 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:25:13.408718 37548 solver.cpp:252]     Train net output #1: loss = 0.970834 (* 1 = 0.970834 loss)
I0718 01:25:14.371920 37548 sgd_solver.cpp:106] Iteration 36950, lr = 0.015
I0718 01:28:40.661643 37548 solver.cpp:236] Iteration 37000, loss = 1.05927
I0718 01:28:40.661870 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 01:28:40.661927 37548 solver.cpp:252]     Train net output #1: loss = 1.1146 (* 1 = 1.1146 loss)
I0718 01:28:41.546145 37548 sgd_solver.cpp:106] Iteration 37000, lr = 0.015
I0718 01:32:05.704239 37548 solver.cpp:236] Iteration 37050, loss = 1.04446
I0718 01:32:05.704529 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 01:32:05.704566 37548 solver.cpp:252]     Train net output #1: loss = 1.05733 (* 1 = 1.05733 loss)
I0718 01:32:06.584612 37548 sgd_solver.cpp:106] Iteration 37050, lr = 0.015
I0718 01:35:32.500808 37548 solver.cpp:236] Iteration 37100, loss = 1.07424
I0718 01:35:32.501261 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 01:35:32.501365 37548 solver.cpp:252]     Train net output #1: loss = 1.1724 (* 1 = 1.1724 loss)
I0718 01:35:33.380625 37548 sgd_solver.cpp:106] Iteration 37100, lr = 0.015
I0718 01:38:59.049738 37548 solver.cpp:236] Iteration 37150, loss = 1.07218
I0718 01:38:59.049973 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 01:38:59.049998 37548 solver.cpp:252]     Train net output #1: loss = 1.2189 (* 1 = 1.2189 loss)
I0718 01:38:59.927461 37548 sgd_solver.cpp:106] Iteration 37150, lr = 0.015
I0718 01:42:24.098500 37548 solver.cpp:236] Iteration 37200, loss = 1.06504
I0718 01:42:24.098753 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 01:42:24.098784 37548 solver.cpp:252]     Train net output #1: loss = 1.01864 (* 1 = 1.01864 loss)
I0718 01:42:24.979531 37548 sgd_solver.cpp:106] Iteration 37200, lr = 0.015
I0718 01:44:40.220397 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 01:45:51.793380 37548 solver.cpp:236] Iteration 37250, loss = 1.0813
I0718 01:45:51.793606 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 01:45:51.793642 37548 solver.cpp:252]     Train net output #1: loss = 1.10408 (* 1 = 1.10408 loss)
I0718 01:45:52.680568 37548 sgd_solver.cpp:106] Iteration 37250, lr = 0.015
I0718 01:49:16.971890 37548 solver.cpp:236] Iteration 37300, loss = 1.05561
I0718 01:49:16.972185 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:49:16.972244 37548 solver.cpp:252]     Train net output #1: loss = 0.947091 (* 1 = 0.947091 loss)
I0718 01:49:17.923136 37548 sgd_solver.cpp:106] Iteration 37300, lr = 0.015
I0718 01:52:43.253099 37548 solver.cpp:236] Iteration 37350, loss = 1.01901
I0718 01:52:43.253326 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:52:43.253377 37548 solver.cpp:252]     Train net output #1: loss = 0.960509 (* 1 = 0.960509 loss)
I0718 01:52:44.251476 37548 sgd_solver.cpp:106] Iteration 37350, lr = 0.015
I0718 01:56:09.390357 37548 solver.cpp:236] Iteration 37400, loss = 1.0919
I0718 01:56:09.390568 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 01:56:09.390594 37548 solver.cpp:252]     Train net output #1: loss = 0.976309 (* 1 = 0.976309 loss)
I0718 01:56:10.268263 37548 sgd_solver.cpp:106] Iteration 37400, lr = 0.015
I0718 01:59:36.947209 37548 solver.cpp:236] Iteration 37450, loss = 1.05414
I0718 01:59:36.947494 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 01:59:36.947537 37548 solver.cpp:252]     Train net output #1: loss = 1.03495 (* 1 = 1.03495 loss)
I0718 01:59:37.875823 37548 sgd_solver.cpp:106] Iteration 37450, lr = 0.015
I0718 02:02:59.630226 37548 solver.cpp:340] Iteration 37500, Testing net (#0)
I0718 02:26:13.412264 37548 solver.cpp:408]     Test net output #0: accuracy = 0.462333
I0718 02:26:13.412598 37548 solver.cpp:408]     Test net output #1: loss = 1.06263 (* 1 = 1.06263 loss)
I0718 02:26:16.272218 37548 solver.cpp:236] Iteration 37500, loss = 1.05695
I0718 02:26:16.272326 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 02:26:16.272385 37548 solver.cpp:252]     Train net output #1: loss = 0.964552 (* 1 = 0.964552 loss)
I0718 02:26:16.272469 37548 sgd_solver.cpp:106] Iteration 37500, lr = 0.015
I0718 02:29:40.711899 37548 solver.cpp:236] Iteration 37550, loss = 1.0433
I0718 02:29:40.712190 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 02:29:40.712236 37548 solver.cpp:252]     Train net output #1: loss = 1.03033 (* 1 = 1.03033 loss)
I0718 02:29:41.660708 37548 sgd_solver.cpp:106] Iteration 37550, lr = 0.015
I0718 02:33:06.073973 37548 solver.cpp:236] Iteration 37600, loss = 1.05538
I0718 02:33:06.074221 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 02:33:06.074275 37548 solver.cpp:252]     Train net output #1: loss = 1.02234 (* 1 = 1.02234 loss)
I0718 02:33:07.014227 37548 sgd_solver.cpp:106] Iteration 37600, lr = 0.015
I0718 02:36:35.224596 37548 solver.cpp:236] Iteration 37650, loss = 1.05778
I0718 02:36:35.224799 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 02:36:35.224823 37548 solver.cpp:252]     Train net output #1: loss = 1.30917 (* 1 = 1.30917 loss)
I0718 02:36:36.102376 37548 sgd_solver.cpp:106] Iteration 37650, lr = 0.015
I0718 02:40:02.078701 37548 solver.cpp:236] Iteration 37700, loss = 1.08071
I0718 02:40:02.079010 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 02:40:02.079058 37548 solver.cpp:252]     Train net output #1: loss = 0.904511 (* 1 = 0.904511 loss)
I0718 02:40:03.033892 37548 sgd_solver.cpp:106] Iteration 37700, lr = 0.015
I0718 02:42:17.613109 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 02:43:27.040521 37548 solver.cpp:236] Iteration 37750, loss = 1.05148
I0718 02:43:27.040787 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 02:43:27.040838 37548 solver.cpp:252]     Train net output #1: loss = 1.03629 (* 1 = 1.03629 loss)
I0718 02:43:27.915395 37548 sgd_solver.cpp:106] Iteration 37750, lr = 0.015
I0718 02:46:52.211819 37548 solver.cpp:236] Iteration 37800, loss = 1.06509
I0718 02:46:52.212065 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 02:46:52.212090 37548 solver.cpp:252]     Train net output #1: loss = 1.17339 (* 1 = 1.17339 loss)
I0718 02:46:53.147270 37548 sgd_solver.cpp:106] Iteration 37800, lr = 0.015
I0718 02:50:19.262593 37548 solver.cpp:236] Iteration 37850, loss = 1.04356
I0718 02:50:19.262799 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 02:50:19.262830 37548 solver.cpp:252]     Train net output #1: loss = 0.982296 (* 1 = 0.982296 loss)
I0718 02:50:20.228626 37548 sgd_solver.cpp:106] Iteration 37850, lr = 0.015
I0718 02:53:42.046625 37548 solver.cpp:236] Iteration 37900, loss = 1.06434
I0718 02:53:42.046967 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 02:53:42.047078 37548 solver.cpp:252]     Train net output #1: loss = 0.980231 (* 1 = 0.980231 loss)
I0718 02:53:42.914858 37548 sgd_solver.cpp:106] Iteration 37900, lr = 0.015
I0718 02:57:05.364787 37548 solver.cpp:236] Iteration 37950, loss = 1.06188
I0718 02:57:05.364998 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 02:57:05.365043 37548 solver.cpp:252]     Train net output #1: loss = 1.23823 (* 1 = 1.23823 loss)
I0718 02:57:06.314839 37548 sgd_solver.cpp:106] Iteration 37950, lr = 0.015
I0718 03:00:30.035066 37548 solver.cpp:236] Iteration 38000, loss = 1.05376
I0718 03:00:30.035426 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 03:00:30.035491 37548 solver.cpp:252]     Train net output #1: loss = 0.764794 (* 1 = 0.764794 loss)
I0718 03:00:30.983738 37548 sgd_solver.cpp:106] Iteration 38000, lr = 0.015
I0718 03:03:55.094784 37548 solver.cpp:236] Iteration 38050, loss = 1.07298
I0718 03:03:55.094985 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 03:03:55.095018 37548 solver.cpp:252]     Train net output #1: loss = 1.2487 (* 1 = 1.2487 loss)
I0718 03:03:56.038403 37548 sgd_solver.cpp:106] Iteration 38050, lr = 0.015
I0718 03:07:20.098481 37548 solver.cpp:236] Iteration 38100, loss = 1.06672
I0718 03:07:20.098706 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 03:07:20.098738 37548 solver.cpp:252]     Train net output #1: loss = 1.15396 (* 1 = 1.15396 loss)
I0718 03:07:20.988492 37548 sgd_solver.cpp:106] Iteration 38100, lr = 0.015
I0718 03:10:43.780845 37548 solver.cpp:236] Iteration 38150, loss = 1.06576
I0718 03:10:43.781095 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 03:10:43.781131 37548 solver.cpp:252]     Train net output #1: loss = 0.968215 (* 1 = 0.968215 loss)
I0718 03:10:44.662351 37548 sgd_solver.cpp:106] Iteration 38150, lr = 0.015
I0718 03:14:08.828248 37548 solver.cpp:236] Iteration 38200, loss = 1.06616
I0718 03:14:08.828583 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 03:14:08.828630 37548 solver.cpp:252]     Train net output #1: loss = 1.09507 (* 1 = 1.09507 loss)
I0718 03:14:09.769997 37548 sgd_solver.cpp:106] Iteration 38200, lr = 0.015
I0718 03:16:44.967597 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 03:17:33.342727 37548 solver.cpp:236] Iteration 38250, loss = 1.0608
I0718 03:17:33.342896 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 03:17:33.342960 37548 solver.cpp:252]     Train net output #1: loss = 0.992623 (* 1 = 0.992623 loss)
I0718 03:17:34.286825 37548 sgd_solver.cpp:106] Iteration 38250, lr = 0.015
I0718 03:21:00.121373 37548 solver.cpp:236] Iteration 38300, loss = 1.0652
I0718 03:21:00.121672 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 03:21:00.121716 37548 solver.cpp:252]     Train net output #1: loss = 0.994104 (* 1 = 0.994104 loss)
I0718 03:21:01.069396 37548 sgd_solver.cpp:106] Iteration 38300, lr = 0.015
I0718 03:24:23.504063 37548 solver.cpp:236] Iteration 38350, loss = 1.06265
I0718 03:24:23.504361 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 03:24:23.504397 37548 solver.cpp:252]     Train net output #1: loss = 0.954218 (* 1 = 0.954218 loss)
I0718 03:24:24.391279 37548 sgd_solver.cpp:106] Iteration 38350, lr = 0.015
I0718 03:27:44.951367 37548 solver.cpp:236] Iteration 38400, loss = 1.03909
I0718 03:27:44.951747 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 03:27:44.951793 37548 solver.cpp:252]     Train net output #1: loss = 1.1338 (* 1 = 1.1338 loss)
I0718 03:27:45.836803 37548 sgd_solver.cpp:106] Iteration 38400, lr = 0.015
I0718 03:31:14.011070 37548 solver.cpp:236] Iteration 38450, loss = 1.0639
I0718 03:31:14.011312 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 03:31:14.011354 37548 solver.cpp:252]     Train net output #1: loss = 1.08229 (* 1 = 1.08229 loss)
I0718 03:31:14.947489 37548 sgd_solver.cpp:106] Iteration 38450, lr = 0.015
I0718 03:34:37.507674 37548 solver.cpp:236] Iteration 38500, loss = 1.07425
I0718 03:34:37.507869 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 03:34:37.507923 37548 solver.cpp:252]     Train net output #1: loss = 1.1714 (* 1 = 1.1714 loss)
I0718 03:34:38.475056 37548 sgd_solver.cpp:106] Iteration 38500, lr = 0.015
I0718 03:38:02.834452 37548 solver.cpp:236] Iteration 38550, loss = 1.07055
I0718 03:38:02.834733 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 03:38:02.834802 37548 solver.cpp:252]     Train net output #1: loss = 1.21538 (* 1 = 1.21538 loss)
I0718 03:38:03.697212 37548 sgd_solver.cpp:106] Iteration 38550, lr = 0.015
I0718 03:41:24.303524 37548 solver.cpp:236] Iteration 38600, loss = 1.03676
I0718 03:41:24.303766 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 03:41:24.303824 37548 solver.cpp:252]     Train net output #1: loss = 0.925916 (* 1 = 0.925916 loss)
I0718 03:41:25.324242 37548 sgd_solver.cpp:106] Iteration 38600, lr = 0.015
I0718 03:44:50.003573 37548 solver.cpp:236] Iteration 38650, loss = 1.03527
I0718 03:44:50.003832 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 03:44:50.003876 37548 solver.cpp:252]     Train net output #1: loss = 1.06979 (* 1 = 1.06979 loss)
I0718 03:44:50.950248 37548 sgd_solver.cpp:106] Iteration 38650, lr = 0.015
I0718 03:48:14.807122 37548 solver.cpp:236] Iteration 38700, loss = 1.04208
I0718 03:48:14.807411 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 03:48:14.807445 37548 solver.cpp:252]     Train net output #1: loss = 0.938498 (* 1 = 0.938498 loss)
I0718 03:48:15.684954 37548 sgd_solver.cpp:106] Iteration 38700, lr = 0.015
I0718 03:51:03.358757 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 03:51:40.400619 37548 solver.cpp:236] Iteration 38750, loss = 1.08537
I0718 03:51:40.400876 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 03:51:40.400921 37548 solver.cpp:252]     Train net output #1: loss = 1.03149 (* 1 = 1.03149 loss)
I0718 03:51:41.338299 37548 sgd_solver.cpp:106] Iteration 38750, lr = 0.015
I0718 03:55:06.756044 37548 solver.cpp:236] Iteration 38800, loss = 1.04814
I0718 03:55:06.756201 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 03:55:06.756224 37548 solver.cpp:252]     Train net output #1: loss = 1.19591 (* 1 = 1.19591 loss)
I0718 03:55:07.645596 37548 sgd_solver.cpp:106] Iteration 38800, lr = 0.015
I0718 03:58:31.196416 37548 solver.cpp:236] Iteration 38850, loss = 1.0624
I0718 03:58:31.196568 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0718 03:58:31.196621 37548 solver.cpp:252]     Train net output #1: loss = 0.818445 (* 1 = 0.818445 loss)
I0718 03:58:32.142246 37548 sgd_solver.cpp:106] Iteration 38850, lr = 0.015
I0718 04:01:58.830832 37548 solver.cpp:236] Iteration 38900, loss = 1.07626
I0718 04:01:58.831122 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 04:01:58.831164 37548 solver.cpp:252]     Train net output #1: loss = 1.02211 (* 1 = 1.02211 loss)
I0718 04:01:59.716550 37548 sgd_solver.cpp:106] Iteration 38900, lr = 0.015
I0718 04:05:23.147653 37548 solver.cpp:236] Iteration 38950, loss = 1.05566
I0718 04:05:23.147871 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 04:05:23.147896 37548 solver.cpp:252]     Train net output #1: loss = 1.02063 (* 1 = 1.02063 loss)
I0718 04:05:24.031314 37548 sgd_solver.cpp:106] Iteration 38950, lr = 0.015
I0718 04:08:47.552875 37548 solver.cpp:340] Iteration 39000, Testing net (#0)
I0718 04:32:01.365079 37548 solver.cpp:408]     Test net output #0: accuracy = 0.466333
I0718 04:32:01.373572 37548 solver.cpp:408]     Test net output #1: loss = 1.0579 (* 1 = 1.0579 loss)
I0718 04:32:04.233597 37548 solver.cpp:236] Iteration 39000, loss = 1.07288
I0718 04:32:04.233656 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 04:32:04.233697 37548 solver.cpp:252]     Train net output #1: loss = 1.05703 (* 1 = 1.05703 loss)
I0718 04:32:04.233767 37548 sgd_solver.cpp:106] Iteration 39000, lr = 0.015
I0718 04:35:28.055325 37548 solver.cpp:236] Iteration 39050, loss = 1.0572
I0718 04:35:28.055639 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 04:35:28.055702 37548 solver.cpp:252]     Train net output #1: loss = 1.06928 (* 1 = 1.06928 loss)
I0718 04:35:28.925969 37548 sgd_solver.cpp:106] Iteration 39050, lr = 0.015
I0718 04:38:52.544067 37548 solver.cpp:236] Iteration 39100, loss = 1.03803
I0718 04:38:52.544319 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 04:38:52.544345 37548 solver.cpp:252]     Train net output #1: loss = 1.02115 (* 1 = 1.02115 loss)
I0718 04:38:53.437464 37548 sgd_solver.cpp:106] Iteration 39100, lr = 0.015
I0718 04:42:17.950500 37548 solver.cpp:236] Iteration 39150, loss = 1.04093
I0718 04:42:17.950822 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 04:42:17.950911 37548 solver.cpp:252]     Train net output #1: loss = 1.01344 (* 1 = 1.01344 loss)
I0718 04:42:18.891867 37548 sgd_solver.cpp:106] Iteration 39150, lr = 0.015
I0718 04:45:39.077682 37548 solver.cpp:236] Iteration 39200, loss = 1.07825
I0718 04:45:39.077915 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 04:45:39.077971 37548 solver.cpp:252]     Train net output #1: loss = 1.24476 (* 1 = 1.24476 loss)
I0718 04:45:40.039170 37548 sgd_solver.cpp:106] Iteration 39200, lr = 0.015
I0718 04:48:45.447697 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 04:49:04.694350 37548 solver.cpp:236] Iteration 39250, loss = 1.06949
I0718 04:49:04.694429 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 04:49:04.694461 37548 solver.cpp:252]     Train net output #1: loss = 0.984975 (* 1 = 0.984975 loss)
I0718 04:49:05.566573 37548 sgd_solver.cpp:106] Iteration 39250, lr = 0.015
I0718 04:52:32.281524 37548 solver.cpp:236] Iteration 39300, loss = 1.05974
I0718 04:52:32.281823 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 04:52:32.281860 37548 solver.cpp:252]     Train net output #1: loss = 1.12608 (* 1 = 1.12608 loss)
I0718 04:52:33.225071 37548 sgd_solver.cpp:106] Iteration 39300, lr = 0.015
I0718 04:55:56.691547 37548 solver.cpp:236] Iteration 39350, loss = 1.02237
I0718 04:55:56.691738 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 04:55:56.691777 37548 solver.cpp:252]     Train net output #1: loss = 0.869726 (* 1 = 0.869726 loss)
I0718 04:55:57.714853 37548 sgd_solver.cpp:106] Iteration 39350, lr = 0.015
I0718 04:59:18.674147 37548 solver.cpp:236] Iteration 39400, loss = 1.05394
I0718 04:59:18.674433 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 04:59:18.674460 37548 solver.cpp:252]     Train net output #1: loss = 1.10571 (* 1 = 1.10571 loss)
I0718 04:59:19.553098 37548 sgd_solver.cpp:106] Iteration 39400, lr = 0.015
I0718 05:02:43.145073 37548 solver.cpp:236] Iteration 39450, loss = 1.07712
I0718 05:02:43.145411 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 05:02:43.145448 37548 solver.cpp:252]     Train net output #1: loss = 0.931872 (* 1 = 0.931872 loss)
I0718 05:02:44.019384 37548 sgd_solver.cpp:106] Iteration 39450, lr = 0.015
I0718 05:06:11.401643 37548 solver.cpp:236] Iteration 39500, loss = 1.06647
I0718 05:06:11.401872 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 05:06:11.401943 37548 solver.cpp:252]     Train net output #1: loss = 1.25118 (* 1 = 1.25118 loss)
I0718 05:06:12.265198 37548 sgd_solver.cpp:106] Iteration 39500, lr = 0.015
I0718 05:09:37.453181 37548 solver.cpp:236] Iteration 39550, loss = 1.04949
I0718 05:09:37.453465 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 05:09:37.453487 37548 solver.cpp:252]     Train net output #1: loss = 1.24157 (* 1 = 1.24157 loss)
I0718 05:09:38.329390 37548 sgd_solver.cpp:106] Iteration 39550, lr = 0.015
I0718 05:13:02.809520 37548 solver.cpp:236] Iteration 39600, loss = 1.09492
I0718 05:13:02.809825 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 05:13:02.809871 37548 solver.cpp:252]     Train net output #1: loss = 0.990898 (* 1 = 0.990898 loss)
I0718 05:13:03.676766 37548 sgd_solver.cpp:106] Iteration 39600, lr = 0.015
I0718 05:16:27.788573 37548 solver.cpp:236] Iteration 39650, loss = 1.05413
I0718 05:16:27.788864 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 05:16:27.788888 37548 solver.cpp:252]     Train net output #1: loss = 1.04947 (* 1 = 1.04947 loss)
I0718 05:16:28.670339 37548 sgd_solver.cpp:106] Iteration 39650, lr = 0.015
I0718 05:19:53.715046 37548 solver.cpp:236] Iteration 39700, loss = 1.05742
I0718 05:19:53.715272 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 05:19:53.715306 37548 solver.cpp:252]     Train net output #1: loss = 1.04756 (* 1 = 1.04756 loss)
I0718 05:19:54.660094 37548 sgd_solver.cpp:106] Iteration 39700, lr = 0.015
I0718 05:23:05.718382 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 05:23:20.599007 37548 solver.cpp:236] Iteration 39750, loss = 1.0742
I0718 05:23:20.599066 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0718 05:23:20.599087 37548 solver.cpp:252]     Train net output #1: loss = 0.813414 (* 1 = 0.813414 loss)
I0718 05:23:21.563917 37548 sgd_solver.cpp:106] Iteration 39750, lr = 0.015
I0718 05:26:47.209462 37548 solver.cpp:236] Iteration 39800, loss = 1.07997
I0718 05:26:47.209817 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 05:26:47.209859 37548 solver.cpp:252]     Train net output #1: loss = 1.15837 (* 1 = 1.15837 loss)
I0718 05:26:48.098865 37548 sgd_solver.cpp:106] Iteration 39800, lr = 0.015
I0718 05:30:13.112679 37548 solver.cpp:236] Iteration 39850, loss = 1.06945
I0718 05:30:13.112880 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 05:30:13.112920 37548 solver.cpp:252]     Train net output #1: loss = 1.12887 (* 1 = 1.12887 loss)
I0718 05:30:13.984833 37548 sgd_solver.cpp:106] Iteration 39850, lr = 0.015
I0718 05:33:36.487730 37548 solver.cpp:236] Iteration 39900, loss = 1.05382
I0718 05:33:36.487998 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 05:33:36.488036 37548 solver.cpp:252]     Train net output #1: loss = 1.24181 (* 1 = 1.24181 loss)
I0718 05:33:37.370930 37548 sgd_solver.cpp:106] Iteration 39900, lr = 0.015
I0718 05:37:03.655606 37548 solver.cpp:236] Iteration 39950, loss = 1.04975
I0718 05:37:03.655882 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 05:37:03.655939 37548 solver.cpp:252]     Train net output #1: loss = 1.40989 (* 1 = 1.40989 loss)
I0718 05:37:04.603047 37548 sgd_solver.cpp:106] Iteration 39950, lr = 0.015
I0718 05:40:29.056032 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_40000.caffemodel
I0718 05:40:30.101027 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_40000.solverstate
I0718 05:40:33.019588 37548 solver.cpp:236] Iteration 40000, loss = 1.04088
I0718 05:40:33.019656 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 05:40:33.019680 37548 solver.cpp:252]     Train net output #1: loss = 1.12948 (* 1 = 1.12948 loss)
I0718 05:40:33.891044 37548 sgd_solver.cpp:106] Iteration 40000, lr = 0.015
I0718 05:44:01.434012 37548 solver.cpp:236] Iteration 40050, loss = 1.0356
I0718 05:44:01.434276 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 05:44:01.434304 37548 solver.cpp:252]     Train net output #1: loss = 0.912202 (* 1 = 0.912202 loss)
I0718 05:44:02.303369 37548 sgd_solver.cpp:106] Iteration 40050, lr = 0.015
I0718 05:47:26.510897 37548 solver.cpp:236] Iteration 40100, loss = 1.07455
I0718 05:47:26.511227 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 05:47:26.511289 37548 solver.cpp:252]     Train net output #1: loss = 1.03446 (* 1 = 1.03446 loss)
I0718 05:47:27.392455 37548 sgd_solver.cpp:106] Iteration 40100, lr = 0.015
I0718 05:50:55.130784 37548 solver.cpp:236] Iteration 40150, loss = 1.05942
I0718 05:50:55.131078 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 05:50:55.131126 37548 solver.cpp:252]     Train net output #1: loss = 1.22613 (* 1 = 1.22613 loss)
I0718 05:50:56.013526 37548 sgd_solver.cpp:106] Iteration 40150, lr = 0.015
I0718 05:54:22.468998 37548 solver.cpp:236] Iteration 40200, loss = 1.04006
I0718 05:54:22.469167 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 05:54:22.469202 37548 solver.cpp:252]     Train net output #1: loss = 0.902382 (* 1 = 0.902382 loss)
I0718 05:54:23.411433 37548 sgd_solver.cpp:106] Iteration 40200, lr = 0.015
I0718 05:57:32.062633 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 05:57:47.584002 37548 solver.cpp:236] Iteration 40250, loss = 1.06032
I0718 05:57:47.584087 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 05:57:47.584111 37548 solver.cpp:252]     Train net output #1: loss = 1.08004 (* 1 = 1.08004 loss)
I0718 05:57:48.464452 37548 sgd_solver.cpp:106] Iteration 40250, lr = 0.015
I0718 06:01:14.598742 37548 solver.cpp:236] Iteration 40300, loss = 1.04555
I0718 06:01:14.598994 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 06:01:14.599040 37548 solver.cpp:252]     Train net output #1: loss = 0.949006 (* 1 = 0.949006 loss)
I0718 06:01:15.547626 37548 sgd_solver.cpp:106] Iteration 40300, lr = 0.015
I0718 06:04:40.421900 37548 solver.cpp:236] Iteration 40350, loss = 1.07972
I0718 06:04:40.422116 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 06:04:40.422140 37548 solver.cpp:252]     Train net output #1: loss = 0.886394 (* 1 = 0.886394 loss)
I0718 06:04:41.300879 37548 sgd_solver.cpp:106] Iteration 40350, lr = 0.015
I0718 06:08:03.595090 37548 solver.cpp:236] Iteration 40400, loss = 1.05766
I0718 06:08:03.595314 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 06:08:03.595352 37548 solver.cpp:252]     Train net output #1: loss = 1.46514 (* 1 = 1.46514 loss)
I0718 06:08:04.473939 37548 sgd_solver.cpp:106] Iteration 40400, lr = 0.015
I0718 06:11:24.382261 37548 solver.cpp:236] Iteration 40450, loss = 1.03143
I0718 06:11:24.382534 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 06:11:24.382573 37548 solver.cpp:252]     Train net output #1: loss = 1.09261 (* 1 = 1.09261 loss)
I0718 06:11:25.329871 37548 sgd_solver.cpp:106] Iteration 40450, lr = 0.015
I0718 06:14:45.395262 37548 solver.cpp:340] Iteration 40500, Testing net (#0)
I0718 06:37:59.260573 37548 solver.cpp:408]     Test net output #0: accuracy = 0.456667
I0718 06:37:59.260761 37548 solver.cpp:408]     Test net output #1: loss = 1.06477 (* 1 = 1.06477 loss)
I0718 06:38:02.137513 37548 solver.cpp:236] Iteration 40500, loss = 1.05274
I0718 06:38:02.137575 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 06:38:02.137603 37548 solver.cpp:252]     Train net output #1: loss = 1.11363 (* 1 = 1.11363 loss)
I0718 06:38:02.137655 37548 sgd_solver.cpp:106] Iteration 40500, lr = 0.015
I0718 06:41:30.063871 37548 solver.cpp:236] Iteration 40550, loss = 1.07724
I0718 06:41:30.064056 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 06:41:30.064079 37548 solver.cpp:252]     Train net output #1: loss = 0.951278 (* 1 = 0.951278 loss)
I0718 06:41:30.944232 37548 sgd_solver.cpp:106] Iteration 40550, lr = 0.015
I0718 06:44:54.902405 37548 solver.cpp:236] Iteration 40600, loss = 1.06443
I0718 06:44:54.902590 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 06:44:54.902662 37548 solver.cpp:252]     Train net output #1: loss = 1.0282 (* 1 = 1.0282 loss)
I0718 06:44:55.785630 37548 sgd_solver.cpp:106] Iteration 40600, lr = 0.015
I0718 06:48:18.391510 37548 solver.cpp:236] Iteration 40650, loss = 1.04797
I0718 06:48:18.391687 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 06:48:18.391772 37548 solver.cpp:252]     Train net output #1: loss = 1.12569 (* 1 = 1.12569 loss)
I0718 06:48:19.271744 37548 sgd_solver.cpp:106] Iteration 40650, lr = 0.015
I0718 06:51:40.633957 37548 solver.cpp:236] Iteration 40700, loss = 1.06885
I0718 06:51:40.634222 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 06:51:40.634269 37548 solver.cpp:252]     Train net output #1: loss = 1.2708 (* 1 = 1.2708 loss)
I0718 06:51:41.493590 37548 sgd_solver.cpp:106] Iteration 40700, lr = 0.015
I0718 06:55:02.032651 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 06:55:09.021515 37548 solver.cpp:236] Iteration 40750, loss = 1.04841
I0718 06:55:09.021572 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 06:55:09.021591 37548 solver.cpp:252]     Train net output #1: loss = 0.982059 (* 1 = 0.982059 loss)
I0718 06:55:09.903715 37548 sgd_solver.cpp:106] Iteration 40750, lr = 0.015
I0718 06:58:34.892943 37548 solver.cpp:236] Iteration 40800, loss = 1.06068
I0718 06:58:34.893210 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 06:58:34.893296 37548 solver.cpp:252]     Train net output #1: loss = 0.972301 (* 1 = 0.972301 loss)
I0718 06:58:35.840446 37548 sgd_solver.cpp:106] Iteration 40800, lr = 0.015
I0718 07:02:02.701431 37548 solver.cpp:236] Iteration 40850, loss = 1.00811
I0718 07:02:02.701764 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:02:02.701822 37548 solver.cpp:252]     Train net output #1: loss = 1.01931 (* 1 = 1.01931 loss)
I0718 07:02:03.642071 37548 sgd_solver.cpp:106] Iteration 40850, lr = 0.015
I0718 07:05:28.075891 37548 solver.cpp:236] Iteration 40900, loss = 1.07947
I0718 07:05:28.076117 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 07:05:28.076153 37548 solver.cpp:252]     Train net output #1: loss = 1.19955 (* 1 = 1.19955 loss)
I0718 07:05:28.944836 37548 sgd_solver.cpp:106] Iteration 40900, lr = 0.015
I0718 07:08:50.393180 37548 solver.cpp:236] Iteration 40950, loss = 1.05218
I0718 07:08:50.393415 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:08:50.393450 37548 solver.cpp:252]     Train net output #1: loss = 1.08122 (* 1 = 1.08122 loss)
I0718 07:08:51.345044 37548 sgd_solver.cpp:106] Iteration 40950, lr = 0.015
I0718 07:12:16.293112 37548 solver.cpp:236] Iteration 41000, loss = 1.04694
I0718 07:12:16.293350 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 07:12:16.293388 37548 solver.cpp:252]     Train net output #1: loss = 1.08737 (* 1 = 1.08737 loss)
I0718 07:12:17.178004 37548 sgd_solver.cpp:106] Iteration 41000, lr = 0.015
I0718 07:15:39.886855 37548 solver.cpp:236] Iteration 41050, loss = 1.07116
I0718 07:15:39.887089 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:15:39.887122 37548 solver.cpp:252]     Train net output #1: loss = 1.0344 (* 1 = 1.0344 loss)
I0718 07:15:40.846715 37548 sgd_solver.cpp:106] Iteration 41050, lr = 0.015
I0718 07:19:06.117529 37548 solver.cpp:236] Iteration 41100, loss = 1.05567
I0718 07:19:06.117754 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:19:06.117794 37548 solver.cpp:252]     Train net output #1: loss = 0.985811 (* 1 = 0.985811 loss)
I0718 07:19:07.000165 37548 sgd_solver.cpp:106] Iteration 41100, lr = 0.015
I0718 07:22:31.776826 37548 solver.cpp:236] Iteration 41150, loss = 1.03855
I0718 07:22:31.777022 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 07:22:31.777050 37548 solver.cpp:252]     Train net output #1: loss = 0.809035 (* 1 = 0.809035 loss)
I0718 07:22:32.659992 37548 sgd_solver.cpp:106] Iteration 41150, lr = 0.015
I0718 07:25:57.490097 37548 solver.cpp:236] Iteration 41200, loss = 1.07099
I0718 07:25:57.490389 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 07:25:57.490422 37548 solver.cpp:252]     Train net output #1: loss = 0.935336 (* 1 = 0.935336 loss)
I0718 07:25:58.364271 37548 sgd_solver.cpp:106] Iteration 41200, lr = 0.015
I0718 07:29:09.171986 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 07:29:24.197878 37548 solver.cpp:236] Iteration 41250, loss = 1.03173
I0718 07:29:24.197968 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 07:29:24.198006 37548 solver.cpp:252]     Train net output #1: loss = 0.810962 (* 1 = 0.810962 loss)
I0718 07:29:25.087206 37548 sgd_solver.cpp:106] Iteration 41250, lr = 0.015
I0718 07:32:50.877914 37548 solver.cpp:236] Iteration 41300, loss = 1.06667
I0718 07:32:50.878202 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:32:50.878265 37548 solver.cpp:252]     Train net output #1: loss = 1.03758 (* 1 = 1.03758 loss)
I0718 07:32:51.809464 37548 sgd_solver.cpp:106] Iteration 41300, lr = 0.015
I0718 07:36:19.908720 37548 solver.cpp:236] Iteration 41350, loss = 1.05775
I0718 07:36:19.908993 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 07:36:19.909057 37548 solver.cpp:252]     Train net output #1: loss = 1.30611 (* 1 = 1.30611 loss)
I0718 07:36:20.786219 37548 sgd_solver.cpp:106] Iteration 41350, lr = 0.015
I0718 07:39:46.371783 37548 solver.cpp:236] Iteration 41400, loss = 1.08335
I0718 07:39:46.372089 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 07:39:46.372129 37548 solver.cpp:252]     Train net output #1: loss = 1.10311 (* 1 = 1.10311 loss)
I0718 07:39:47.250691 37548 sgd_solver.cpp:106] Iteration 41400, lr = 0.015
I0718 07:43:13.487790 37548 solver.cpp:236] Iteration 41450, loss = 1.04599
I0718 07:43:13.488091 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 07:43:13.488126 37548 solver.cpp:252]     Train net output #1: loss = 0.980342 (* 1 = 0.980342 loss)
I0718 07:43:14.349321 37548 sgd_solver.cpp:106] Iteration 41450, lr = 0.015
I0718 07:46:40.256150 37548 solver.cpp:236] Iteration 41500, loss = 1.05179
I0718 07:46:40.256428 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 07:46:40.256466 37548 solver.cpp:252]     Train net output #1: loss = 0.913103 (* 1 = 0.913103 loss)
I0718 07:46:41.133051 37548 sgd_solver.cpp:106] Iteration 41500, lr = 0.015
I0718 07:50:07.400806 37548 solver.cpp:236] Iteration 41550, loss = 1.08955
I0718 07:50:07.401125 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 07:50:07.401157 37548 solver.cpp:252]     Train net output #1: loss = 1.206 (* 1 = 1.206 loss)
I0718 07:50:08.285526 37548 sgd_solver.cpp:106] Iteration 41550, lr = 0.015
I0718 07:53:30.224055 37548 solver.cpp:236] Iteration 41600, loss = 1.06158
I0718 07:53:30.224290 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:53:30.224334 37548 solver.cpp:252]     Train net output #1: loss = 1.02493 (* 1 = 1.02493 loss)
I0718 07:53:31.109510 37548 sgd_solver.cpp:106] Iteration 41600, lr = 0.015
I0718 07:56:54.041111 37548 solver.cpp:236] Iteration 41650, loss = 1.04967
I0718 07:56:54.041301 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 07:56:54.041348 37548 solver.cpp:252]     Train net output #1: loss = 1.05209 (* 1 = 1.05209 loss)
I0718 07:56:54.923405 37548 sgd_solver.cpp:106] Iteration 41650, lr = 0.015
I0718 08:00:19.631450 37548 solver.cpp:236] Iteration 41700, loss = 1.06495
I0718 08:00:19.631690 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 08:00:19.631728 37548 solver.cpp:252]     Train net output #1: loss = 1.16094 (* 1 = 1.16094 loss)
I0718 08:00:20.579243 37548 sgd_solver.cpp:106] Iteration 41700, lr = 0.015
I0718 08:03:30.084355 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 08:03:45.045336 37548 solver.cpp:236] Iteration 41750, loss = 1.01548
I0718 08:03:45.045387 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 08:03:45.045414 37548 solver.cpp:252]     Train net output #1: loss = 1.05962 (* 1 = 1.05962 loss)
I0718 08:03:45.917511 37548 sgd_solver.cpp:106] Iteration 41750, lr = 0.015
I0718 08:07:09.945029 37548 solver.cpp:236] Iteration 41800, loss = 1.0674
I0718 08:07:09.945309 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 08:07:09.945370 37548 solver.cpp:252]     Train net output #1: loss = 1.20125 (* 1 = 1.20125 loss)
I0718 08:07:10.829715 37548 sgd_solver.cpp:106] Iteration 41800, lr = 0.015
I0718 08:10:36.391154 37548 solver.cpp:236] Iteration 41850, loss = 1.07336
I0718 08:10:36.391408 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 08:10:36.391455 37548 solver.cpp:252]     Train net output #1: loss = 0.974906 (* 1 = 0.974906 loss)
I0718 08:10:37.317682 37548 sgd_solver.cpp:106] Iteration 41850, lr = 0.015
I0718 08:14:00.120868 37548 solver.cpp:236] Iteration 41900, loss = 1.08282
I0718 08:14:00.121076 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 08:14:00.121115 37548 solver.cpp:252]     Train net output #1: loss = 1.02499 (* 1 = 1.02499 loss)
I0718 08:14:01.097023 37548 sgd_solver.cpp:106] Iteration 41900, lr = 0.015
I0718 08:17:20.449338 37548 solver.cpp:236] Iteration 41950, loss = 1.06366
I0718 08:17:20.449513 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 08:17:20.449560 37548 solver.cpp:252]     Train net output #1: loss = 0.969826 (* 1 = 0.969826 loss)
I0718 08:17:21.329336 37548 sgd_solver.cpp:106] Iteration 41950, lr = 0.015
I0718 08:20:42.055229 37548 solver.cpp:340] Iteration 42000, Testing net (#0)
I0718 08:43:55.880782 37548 solver.cpp:408]     Test net output #0: accuracy = 0.469333
I0718 08:43:55.881023 37548 solver.cpp:408]     Test net output #1: loss = 1.05918 (* 1 = 1.05918 loss)
I0718 08:43:58.757763 37548 solver.cpp:236] Iteration 42000, loss = 1.02699
I0718 08:43:58.757818 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 08:43:58.757854 37548 solver.cpp:252]     Train net output #1: loss = 1.14868 (* 1 = 1.14868 loss)
I0718 08:43:58.757921 37548 sgd_solver.cpp:106] Iteration 42000, lr = 0.015
I0718 08:47:24.295476 37548 solver.cpp:236] Iteration 42050, loss = 1.01849
I0718 08:47:24.295701 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 08:47:24.295768 37548 solver.cpp:252]     Train net output #1: loss = 1.03353 (* 1 = 1.03353 loss)
I0718 08:47:25.168515 37548 sgd_solver.cpp:106] Iteration 42050, lr = 0.015
I0718 08:50:47.739382 37548 solver.cpp:236] Iteration 42100, loss = 1.05571
I0718 08:50:47.739670 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 08:50:47.739714 37548 solver.cpp:252]     Train net output #1: loss = 1.10206 (* 1 = 1.10206 loss)
I0718 08:50:48.618227 37548 sgd_solver.cpp:106] Iteration 42100, lr = 0.015
I0718 08:54:13.109338 37548 solver.cpp:236] Iteration 42150, loss = 1.03142
I0718 08:54:13.109558 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 08:54:13.109589 37548 solver.cpp:252]     Train net output #1: loss = 1.18113 (* 1 = 1.18113 loss)
I0718 08:54:14.063041 37548 sgd_solver.cpp:106] Iteration 42150, lr = 0.015
I0718 08:57:38.970276 37548 solver.cpp:236] Iteration 42200, loss = 1.08121
I0718 08:57:38.970588 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 08:57:38.970636 37548 solver.cpp:252]     Train net output #1: loss = 1.28074 (* 1 = 1.28074 loss)
I0718 08:57:39.848253 37548 sgd_solver.cpp:106] Iteration 42200, lr = 0.015
I0718 09:01:05.064934 37548 solver.cpp:236] Iteration 42250, loss = 1.03427
I0718 09:01:05.065197 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 09:01:05.065245 37548 solver.cpp:252]     Train net output #1: loss = 1.19293 (* 1 = 1.19293 loss)
I0718 09:01:06.007408 37548 sgd_solver.cpp:106] Iteration 42250, lr = 0.015
I0718 09:01:10.003871 37548 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 09:04:28.630882 37548 solver.cpp:236] Iteration 42300, loss = 1.06804
I0718 09:04:28.631177 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 09:04:28.631242 37548 solver.cpp:252]     Train net output #1: loss = 1.08331 (* 1 = 1.08331 loss)
I0718 09:04:29.508458 37548 sgd_solver.cpp:106] Iteration 42300, lr = 0.015
I0718 09:07:54.683212 37548 solver.cpp:236] Iteration 42350, loss = 1.07404
I0718 09:07:54.690574 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 09:07:54.690600 37548 solver.cpp:252]     Train net output #1: loss = 1.10224 (* 1 = 1.10224 loss)
I0718 09:07:55.548403 37548 sgd_solver.cpp:106] Iteration 42350, lr = 0.015
I0718 09:11:19.038868 37548 solver.cpp:236] Iteration 42400, loss = 1.06907
I0718 09:11:19.039120 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 09:11:19.039181 37548 solver.cpp:252]     Train net output #1: loss = 1.03376 (* 1 = 1.03376 loss)
I0718 09:11:19.902619 37548 sgd_solver.cpp:106] Iteration 42400, lr = 0.015
I0718 09:14:47.769875 37548 solver.cpp:236] Iteration 42450, loss = 1.06023
I0718 09:14:47.770153 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 09:14:47.770190 37548 solver.cpp:252]     Train net output #1: loss = 1.0853 (* 1 = 1.0853 loss)
I0718 09:14:48.653681 37548 sgd_solver.cpp:106] Iteration 42450, lr = 0.015
I0718 09:18:14.624294 37548 solver.cpp:236] Iteration 42500, loss = 1.03499
I0718 09:18:14.624562 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 09:18:14.624621 37548 solver.cpp:252]     Train net output #1: loss = 0.917512 (* 1 = 0.917512 loss)
I0718 09:18:15.571769 37548 sgd_solver.cpp:106] Iteration 42500, lr = 0.015
I0718 09:21:40.028117 37548 solver.cpp:236] Iteration 42550, loss = 1.0451
I0718 09:21:40.028352 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 09:21:40.028388 37548 solver.cpp:252]     Train net output #1: loss = 1.05646 (* 1 = 1.05646 loss)
I0718 09:21:40.904498 37548 sgd_solver.cpp:106] Iteration 42550, lr = 0.015
I0718 09:25:06.065783 37548 solver.cpp:236] Iteration 42600, loss = 1.05049
I0718 09:25:06.065980 37548 solver.cpp:252]     Train net output #0: accuracy = 0.833333
I0718 09:25:06.066011 37548 solver.cpp:252]     Train net output #1: loss = 0.919015 (* 1 = 0.919015 loss)
I0718 09:25:06.940937 37548 sgd_solver.cpp:106] Iteration 42600, lr = 0.015
I0718 09:28:35.088058 37548 solver.cpp:236] Iteration 42650, loss = 1.06406
I0718 09:28:35.088263 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 09:28:35.088296 37548 solver.cpp:252]     Train net output #1: loss = 1.09318 (* 1 = 1.09318 loss)
I0718 09:28:35.972837 37548 sgd_solver.cpp:106] Iteration 42650, lr = 0.015
I0718 09:32:00.064327 37548 solver.cpp:236] Iteration 42700, loss = 1.08567
I0718 09:32:00.070729 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 09:32:00.070791 37548 solver.cpp:252]     Train net output #1: loss = 1.19538 (* 1 = 1.19538 loss)
I0718 09:32:00.997536 37548 sgd_solver.cpp:106] Iteration 42700, lr = 0.015
I0718 09:35:26.391955 37548 solver.cpp:236] Iteration 42750, loss = 1.08102
I0718 09:35:26.392168 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 09:35:26.392210 37548 solver.cpp:252]     Train net output #1: loss = 1.02575 (* 1 = 1.02575 loss)
I0718 09:35:27.255890 37548 sgd_solver.cpp:106] Iteration 42750, lr = 0.015
I0718 09:35:31.936957 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 09:38:46.263275 37548 solver.cpp:236] Iteration 42800, loss = 1.06052
I0718 09:38:46.263504 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 09:38:46.263543 37548 solver.cpp:252]     Train net output #1: loss = 0.998769 (* 1 = 0.998769 loss)
I0718 09:38:47.141974 37548 sgd_solver.cpp:106] Iteration 42800, lr = 0.015
I0718 09:42:01.285455 37548 solver.cpp:236] Iteration 42850, loss = 1.06242
I0718 09:42:01.285634 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 09:42:01.285655 37548 solver.cpp:252]     Train net output #1: loss = 1.0125 (* 1 = 1.0125 loss)
I0718 09:42:02.215975 37548 sgd_solver.cpp:106] Iteration 42850, lr = 0.015
I0718 09:45:16.252174 37548 solver.cpp:236] Iteration 42900, loss = 1.05029
I0718 09:45:16.252410 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 09:45:16.252445 37548 solver.cpp:252]     Train net output #1: loss = 1.02638 (* 1 = 1.02638 loss)
I0718 09:45:17.215806 37548 sgd_solver.cpp:106] Iteration 42900, lr = 0.015
I0718 09:48:29.483821 37548 solver.cpp:236] Iteration 42950, loss = 1.07707
I0718 09:48:29.483995 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 09:48:29.484035 37548 solver.cpp:252]     Train net output #1: loss = 1.30509 (* 1 = 1.30509 loss)
I0718 09:48:30.363122 37548 sgd_solver.cpp:106] Iteration 42950, lr = 0.015
I0718 09:51:43.907487 37548 solver.cpp:236] Iteration 43000, loss = 1.06194
I0718 09:51:43.907748 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 09:51:43.907778 37548 solver.cpp:252]     Train net output #1: loss = 1.04473 (* 1 = 1.04473 loss)
I0718 09:51:44.805038 37548 sgd_solver.cpp:106] Iteration 43000, lr = 0.015
I0718 09:54:57.064743 37548 solver.cpp:236] Iteration 43050, loss = 1.05385
I0718 09:54:57.064924 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 09:54:57.064957 37548 solver.cpp:252]     Train net output #1: loss = 1.28552 (* 1 = 1.28552 loss)
I0718 09:54:57.945484 37548 sgd_solver.cpp:106] Iteration 43050, lr = 0.015
I0718 09:58:09.878051 37548 solver.cpp:236] Iteration 43100, loss = 1.08196
I0718 09:58:09.878252 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 09:58:09.878298 37548 solver.cpp:252]     Train net output #1: loss = 1.09943 (* 1 = 1.09943 loss)
I0718 09:58:10.752781 37548 sgd_solver.cpp:106] Iteration 43100, lr = 0.015
I0718 10:01:22.922080 37548 solver.cpp:236] Iteration 43150, loss = 1.06275
I0718 10:01:22.922257 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 10:01:22.922291 37548 solver.cpp:252]     Train net output #1: loss = 1.03184 (* 1 = 1.03184 loss)
I0718 10:01:23.869283 37548 sgd_solver.cpp:106] Iteration 43150, lr = 0.015
I0718 10:04:35.736062 37548 solver.cpp:236] Iteration 43200, loss = 1.01517
I0718 10:04:35.736218 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 10:04:35.736250 37548 solver.cpp:252]     Train net output #1: loss = 1.26703 (* 1 = 1.26703 loss)
I0718 10:04:36.617571 37548 sgd_solver.cpp:106] Iteration 43200, lr = 0.015
I0718 10:07:48.336379 37548 solver.cpp:236] Iteration 43250, loss = 1.06289
I0718 10:07:48.336530 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 10:07:48.336575 37548 solver.cpp:252]     Train net output #1: loss = 1.02894 (* 1 = 1.02894 loss)
I0718 10:07:49.199007 37548 sgd_solver.cpp:106] Iteration 43250, lr = 0.015
I0718 10:09:03.755005 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 10:11:03.124925 37548 solver.cpp:236] Iteration 43300, loss = 1.05889
I0718 10:11:03.125174 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 10:11:03.125222 37548 solver.cpp:252]     Train net output #1: loss = 1.06585 (* 1 = 1.06585 loss)
I0718 10:11:04.001845 37548 sgd_solver.cpp:106] Iteration 43300, lr = 0.015
I0718 10:14:15.683228 37548 solver.cpp:236] Iteration 43350, loss = 1.08171
I0718 10:14:15.683481 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 10:14:15.683513 37548 solver.cpp:252]     Train net output #1: loss = 1.03265 (* 1 = 1.03265 loss)
I0718 10:14:16.657451 37548 sgd_solver.cpp:106] Iteration 43350, lr = 0.015
I0718 10:17:28.646239 37548 solver.cpp:236] Iteration 43400, loss = 1.07444
I0718 10:17:28.646461 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 10:17:28.646483 37548 solver.cpp:252]     Train net output #1: loss = 1.05217 (* 1 = 1.05217 loss)
I0718 10:17:29.530623 37548 sgd_solver.cpp:106] Iteration 43400, lr = 0.015
I0718 10:20:43.751518 37548 solver.cpp:236] Iteration 43450, loss = 1.04889
I0718 10:20:43.751679 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 10:20:43.751715 37548 solver.cpp:252]     Train net output #1: loss = 1.02414 (* 1 = 1.02414 loss)
I0718 10:20:44.705673 37548 sgd_solver.cpp:106] Iteration 43450, lr = 0.015
I0718 10:23:53.633426 37548 solver.cpp:340] Iteration 43500, Testing net (#0)
I0718 10:47:06.752780 37548 solver.cpp:408]     Test net output #0: accuracy = 0.451667
I0718 10:47:06.774791 37548 solver.cpp:408]     Test net output #1: loss = 1.07039 (* 1 = 1.07039 loss)
I0718 10:47:09.641757 37548 solver.cpp:236] Iteration 43500, loss = 1.07337
I0718 10:47:09.641790 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 10:47:09.641805 37548 solver.cpp:252]     Train net output #1: loss = 0.971542 (* 1 = 0.971542 loss)
I0718 10:47:09.641839 37548 sgd_solver.cpp:106] Iteration 43500, lr = 0.015
I0718 10:50:22.337313 37548 solver.cpp:236] Iteration 43550, loss = 1.08856
I0718 10:50:22.337474 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 10:50:22.337507 37548 solver.cpp:252]     Train net output #1: loss = 0.99333 (* 1 = 0.99333 loss)
I0718 10:50:23.217393 37548 sgd_solver.cpp:106] Iteration 43550, lr = 0.015
I0718 10:53:41.297988 37548 solver.cpp:236] Iteration 43600, loss = 1.07903
I0718 10:53:41.298144 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 10:53:41.298190 37548 solver.cpp:252]     Train net output #1: loss = 1.24217 (* 1 = 1.24217 loss)
I0718 10:53:42.177700 37548 sgd_solver.cpp:106] Iteration 43600, lr = 0.015
I0718 10:57:02.675915 37548 solver.cpp:236] Iteration 43650, loss = 1.04529
I0718 10:57:02.676080 37548 solver.cpp:252]     Train net output #0: accuracy = 0.166667
I0718 10:57:02.676113 37548 solver.cpp:252]     Train net output #1: loss = 1.18346 (* 1 = 1.18346 loss)
I0718 10:57:03.550528 37548 sgd_solver.cpp:106] Iteration 43650, lr = 0.015
I0718 11:00:24.232764 37548 solver.cpp:236] Iteration 43700, loss = 1.02379
I0718 11:00:24.232925 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 11:00:24.232972 37548 solver.cpp:252]     Train net output #1: loss = 1.026 (* 1 = 1.026 loss)
I0718 11:00:25.109560 37548 sgd_solver.cpp:106] Iteration 43700, lr = 0.015
I0718 11:03:44.011155 37548 solver.cpp:236] Iteration 43750, loss = 1.06856
I0718 11:03:44.011458 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 11:03:44.011502 37548 solver.cpp:252]     Train net output #1: loss = 1.15811 (* 1 = 1.15811 loss)
I0718 11:03:44.974427 37548 sgd_solver.cpp:106] Iteration 43750, lr = 0.015
I0718 11:05:40.093794 37568 blocking_queue.cpp:50] Data layer prefetch queue empty
I0718 11:07:03.442775 37548 solver.cpp:236] Iteration 43800, loss = 1.06308
I0718 11:07:03.443073 37548 solver.cpp:252]     Train net output #0: accuracy = 0.666667
I0718 11:07:03.443097 37548 solver.cpp:252]     Train net output #1: loss = 0.934488 (* 1 = 0.934488 loss)
I0718 11:07:04.332999 37548 sgd_solver.cpp:106] Iteration 43800, lr = 0.015
I0718 11:10:22.279742 37548 solver.cpp:236] Iteration 43850, loss = 1.05336
I0718 11:10:22.279901 37548 solver.cpp:252]     Train net output #0: accuracy = 1
I0718 11:10:22.279945 37548 solver.cpp:252]     Train net output #1: loss = 0.781428 (* 1 = 0.781428 loss)
I0718 11:10:23.136080 37548 sgd_solver.cpp:106] Iteration 43850, lr = 0.015
I0718 11:13:39.659739 37548 solver.cpp:236] Iteration 43900, loss = 1.05511
I0718 11:13:39.659965 37548 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0718 11:13:39.660003 37548 solver.cpp:252]     Train net output #1: loss = 1.02702 (* 1 = 1.02702 loss)
I0718 11:13:40.540072 37548 sgd_solver.cpp:106] Iteration 43900, lr = 0.015
I0718 11:16:52.961191 37548 solver.cpp:236] Iteration 43950, loss = 1.06225
I0718 11:16:52.961359 37548 solver.cpp:252]     Train net output #0: accuracy = 0.333333
I0718 11:16:52.961380 37548 solver.cpp:252]     Train net output #1: loss = 1.13985 (* 1 = 1.13985 loss)
I0718 11:16:53.844872 37548 sgd_solver.cpp:106] Iteration 43950, lr = 0.015
I0718 11:20:06.094017 37548 solver.cpp:236] Iteration 44000, loss = 1.06347
I0718 11:20:06.094269 37548 solver.cpp:252]     Train net output #0: accuracy = 0
I0718 11:20:06.094300 37548 solver.cpp:252]     Train net output #1: loss = 1.31703 (* 1 = 1.31703 loss)
I0718 11:20:06.969128 37548 sgd_solver.cpp:106] Iteration 44000, lr = 0.015
I0718 11:20:37.694839 37548 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_44009.caffemodel
I0718 11:20:38.228504 37548 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_44009.solverstate
I0718 11:20:38.264070 37548 solver.cpp:308] Optimization stopped early.
I0718 11:20:38.619511 37548 caffe.cpp:215] Optimization Done.
