Log file created at: 2016/07/21 09:17:34
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0721 09:17:34.316532 146637 caffe.cpp:184] Using GPUs 1, 2, 3
I0721 09:17:34.589100 146637 solver.cpp:47] Initializing solver from parameters: 
test_iter: 500
test_interval: 1500
base_lr: 0.01
display: 10
max_iter: 180000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0003
stepsize: 60000
snapshot: 1000
snapshot_prefix: "models-resultlayer"
solver_mode: GPU
device_id: 1
net: "train_val-resultlayer-3stack.prototxt"
test_initialization: false
average_loss: 50
I0721 09:17:34.589330 146637 solver.cpp:90] Creating training net from net file: train_val-resultlayer-3stack.prototxt
I0721 09:17:34.590114 146637 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0721 09:17:34.590385 146637 net.cpp:49] Initializing net from parameters: 
name: "Result Layer 3 Stack"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 150
    mean_value: 150
    mean_value: 150
  }
  image_data_param {
    source: "../lists/mitosis_train.lst"
    batch_size: 16
    shuffle: true
    new_height: 1000
    new_width: 1000
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 4
    stride: 1
  }
}
layer {
  name: "nonlin1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_c"
  type: "Convolution"
  bottom: "pool4"
  top: "ip1"
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "nonlin_ip1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2_c"
  type: "Convolution"
  bottom: "ip1"
  top: "ip2"
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "ip2"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0721 09:17:34.592020 146637 layer_factory.hpp:76] Creating layer data
I0721 09:17:34.592089 146637 net.cpp:106] Creating Layer data
I0721 09:17:34.592133 146637 net.cpp:411] data -> data
I0721 09:17:34.592173 146637 net.cpp:411] data -> label
I0721 09:17:34.592658 146637 image_data_layer.cpp:36] Opening file ../lists/mitosis_train.lst
I0721 09:17:34.603775 146637 image_data_layer.cpp:46] Shuffling data
I0721 09:17:34.605108 146637 image_data_layer.cpp:51] A total of 21366 images.
I0721 09:17:34.743880 146637 image_data_layer.cpp:78] output data size: 16,3,1000,1000
I0721 09:17:35.184231 146637 net.cpp:150] Setting up data
I0721 09:17:35.184340 146637 net.cpp:157] Top shape: 16 3 1000 1000 (48000000)
I0721 09:17:35.184386 146637 net.cpp:157] Top shape: 16 (16)
I0721 09:17:35.184397 146637 net.cpp:165] Memory required for data: 192000064
I0721 09:17:35.184448 146637 layer_factory.hpp:76] Creating layer label_data_1_split
I0721 09:17:35.184473 146637 net.cpp:106] Creating Layer label_data_1_split
I0721 09:17:35.184500 146637 net.cpp:454] label_data_1_split <- label
I0721 09:17:35.184533 146637 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0721 09:17:35.184551 146637 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0721 09:17:35.184643 146637 net.cpp:150] Setting up label_data_1_split
I0721 09:17:35.184679 146637 net.cpp:157] Top shape: 16 (16)
I0721 09:17:35.184689 146637 net.cpp:157] Top shape: 16 (16)
I0721 09:17:35.184700 146637 net.cpp:165] Memory required for data: 192000192
I0721 09:17:35.184708 146637 layer_factory.hpp:76] Creating layer conv1
I0721 09:17:35.184734 146637 net.cpp:106] Creating Layer conv1
I0721 09:17:35.184756 146637 net.cpp:454] conv1 <- data
I0721 09:17:35.184769 146637 net.cpp:411] conv1 -> conv1
I0721 09:17:35.340514 146637 net.cpp:150] Setting up conv1
I0721 09:17:35.340575 146637 net.cpp:157] Top shape: 16 16 997 997 (254466304)
I0721 09:17:35.340586 146637 net.cpp:165] Memory required for data: 1209865408
I0721 09:17:35.340620 146637 layer_factory.hpp:76] Creating layer nonlin1
I0721 09:17:35.340641 146637 net.cpp:106] Creating Layer nonlin1
I0721 09:17:35.340652 146637 net.cpp:454] nonlin1 <- conv1
I0721 09:17:35.340663 146637 net.cpp:397] nonlin1 -> conv1 (in-place)
I0721 09:17:35.340869 146637 net.cpp:150] Setting up nonlin1
I0721 09:17:35.340896 146637 net.cpp:157] Top shape: 16 16 997 997 (254466304)
I0721 09:17:35.340905 146637 net.cpp:165] Memory required for data: 2227730624
I0721 09:17:35.340914 146637 layer_factory.hpp:76] Creating layer pool1
I0721 09:17:35.340929 146637 net.cpp:106] Creating Layer pool1
I0721 09:17:35.340936 146637 net.cpp:454] pool1 <- conv1
I0721 09:17:35.340945 146637 net.cpp:411] pool1 -> pool1
I0721 09:17:35.341516 146637 net.cpp:150] Setting up pool1
I0721 09:17:35.341549 146637 net.cpp:157] Top shape: 16 16 499 499 (63744256)
I0721 09:17:35.341570 146637 net.cpp:165] Memory required for data: 2482707648
I0721 09:17:35.341580 146637 layer_factory.hpp:76] Creating layer conv2
I0721 09:17:35.341595 146637 net.cpp:106] Creating Layer conv2
I0721 09:17:35.341604 146637 net.cpp:454] conv2 <- pool1
I0721 09:17:35.341614 146637 net.cpp:411] conv2 -> conv2
I0721 09:17:35.344491 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0721 09:17:35.344956 146637 net.cpp:150] Setting up conv2
I0721 09:17:35.344990 146637 net.cpp:157] Top shape: 16 16 497 497 (63234304)
I0721 09:17:35.344998 146637 net.cpp:165] Memory required for data: 2735644864
I0721 09:17:35.345012 146637 layer_factory.hpp:76] Creating layer nonlin2
I0721 09:17:35.345023 146637 net.cpp:106] Creating Layer nonlin2
I0721 09:17:35.345032 146637 net.cpp:454] nonlin2 <- conv2
I0721 09:17:35.345041 146637 net.cpp:397] nonlin2 -> conv2 (in-place)
I0721 09:17:35.345234 146637 net.cpp:150] Setting up nonlin2
I0721 09:17:35.345260 146637 net.cpp:157] Top shape: 16 16 497 497 (63234304)
I0721 09:17:35.345269 146637 net.cpp:165] Memory required for data: 2988582080
I0721 09:17:35.345278 146637 layer_factory.hpp:76] Creating layer pool2
I0721 09:17:35.345289 146637 net.cpp:106] Creating Layer pool2
I0721 09:17:35.345298 146637 net.cpp:454] pool2 <- conv2
I0721 09:17:35.345306 146637 net.cpp:411] pool2 -> pool2
I0721 09:17:35.345810 146637 net.cpp:150] Setting up pool2
I0721 09:17:35.345844 146637 net.cpp:157] Top shape: 16 16 249 249 (15872256)
I0721 09:17:35.345854 146637 net.cpp:165] Memory required for data: 3052071104
I0721 09:17:35.345862 146637 layer_factory.hpp:76] Creating layer conv3
I0721 09:17:35.345876 146637 net.cpp:106] Creating Layer conv3
I0721 09:17:35.345885 146637 net.cpp:454] conv3 <- pool2
I0721 09:17:35.345896 146637 net.cpp:411] conv3 -> conv3
I0721 09:17:35.347954 146637 net.cpp:150] Setting up conv3
I0721 09:17:35.347988 146637 net.cpp:157] Top shape: 16 16 247 247 (15618304)
I0721 09:17:35.347997 146637 net.cpp:165] Memory required for data: 3114544320
I0721 09:17:35.348067 146637 layer_factory.hpp:76] Creating layer nonlin3
I0721 09:17:35.348080 146637 net.cpp:106] Creating Layer nonlin3
I0721 09:17:35.348099 146637 net.cpp:454] nonlin3 <- conv3
I0721 09:17:35.348110 146637 net.cpp:397] nonlin3 -> conv3 (in-place)
I0721 09:17:35.348316 146637 net.cpp:150] Setting up nonlin3
I0721 09:17:35.348343 146637 net.cpp:157] Top shape: 16 16 247 247 (15618304)
I0721 09:17:35.348351 146637 net.cpp:165] Memory required for data: 3177017536
I0721 09:17:35.348359 146637 layer_factory.hpp:76] Creating layer pool3
I0721 09:17:35.348371 146637 net.cpp:106] Creating Layer pool3
I0721 09:17:35.348379 146637 net.cpp:454] pool3 <- conv3
I0721 09:17:35.348389 146637 net.cpp:411] pool3 -> pool3
I0721 09:17:35.348884 146637 net.cpp:150] Setting up pool3
I0721 09:17:35.348917 146637 net.cpp:157] Top shape: 16 16 124 124 (3936256)
I0721 09:17:35.348927 146637 net.cpp:165] Memory required for data: 3192762560
I0721 09:17:35.348935 146637 layer_factory.hpp:76] Creating layer conv4
I0721 09:17:35.348948 146637 net.cpp:106] Creating Layer conv4
I0721 09:17:35.348958 146637 net.cpp:454] conv4 <- pool3
I0721 09:17:35.348968 146637 net.cpp:411] conv4 -> conv4
I0721 09:17:35.350662 146637 net.cpp:150] Setting up conv4
I0721 09:17:35.350685 146637 net.cpp:157] Top shape: 16 16 122 122 (3810304)
I0721 09:17:35.350694 146637 net.cpp:165] Memory required for data: 3208003776
I0721 09:17:35.350706 146637 layer_factory.hpp:76] Creating layer nonlin4
I0721 09:17:35.350729 146637 net.cpp:106] Creating Layer nonlin4
I0721 09:17:35.350738 146637 net.cpp:454] nonlin4 <- conv4
I0721 09:17:35.350749 146637 net.cpp:397] nonlin4 -> conv4 (in-place)
I0721 09:17:35.351200 146637 net.cpp:150] Setting up nonlin4
I0721 09:17:35.351238 146637 net.cpp:157] Top shape: 16 16 122 122 (3810304)
I0721 09:17:35.351246 146637 net.cpp:165] Memory required for data: 3223244992
I0721 09:17:35.351258 146637 layer_factory.hpp:76] Creating layer pool4
I0721 09:17:35.351269 146637 net.cpp:106] Creating Layer pool4
I0721 09:17:35.351276 146637 net.cpp:454] pool4 <- conv4
I0721 09:17:35.351289 146637 net.cpp:411] pool4 -> pool4
I0721 09:17:35.351799 146637 net.cpp:150] Setting up pool4
I0721 09:17:35.351829 146637 net.cpp:157] Top shape: 16 16 61 61 (952576)
I0721 09:17:35.351836 146637 net.cpp:165] Memory required for data: 3227055296
I0721 09:17:35.351845 146637 layer_factory.hpp:76] Creating layer ip1_c
I0721 09:17:35.351857 146637 net.cpp:106] Creating Layer ip1_c
I0721 09:17:35.351867 146637 net.cpp:454] ip1_c <- pool4
I0721 09:17:35.351878 146637 net.cpp:411] ip1_c -> ip1
I0721 09:17:35.352807 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0721 09:17:35.352835 146637 net.cpp:150] Setting up ip1_c
I0721 09:17:35.352846 146637 net.cpp:157] Top shape: 16 200 60 60 (11520000)
I0721 09:17:35.352854 146637 net.cpp:165] Memory required for data: 3273135296
I0721 09:17:35.352869 146637 layer_factory.hpp:76] Creating layer nonlin_ip1
I0721 09:17:35.352882 146637 net.cpp:106] Creating Layer nonlin_ip1
I0721 09:17:35.352890 146637 net.cpp:454] nonlin_ip1 <- ip1
I0721 09:17:35.352898 146637 net.cpp:397] nonlin_ip1 -> ip1 (in-place)
I0721 09:17:35.353310 146637 net.cpp:150] Setting up nonlin_ip1
I0721 09:17:35.353329 146637 net.cpp:157] Top shape: 16 200 60 60 (11520000)
I0721 09:17:35.353337 146637 net.cpp:165] Memory required for data: 3319215296
I0721 09:17:35.353345 146637 layer_factory.hpp:76] Creating layer ip2_c
I0721 09:17:35.353361 146637 net.cpp:106] Creating Layer ip2_c
I0721 09:17:35.353369 146637 net.cpp:454] ip2_c <- ip1
I0721 09:17:35.353379 146637 net.cpp:411] ip2_c -> ip2
I0721 09:17:35.354622 146637 net.cpp:150] Setting up ip2_c
I0721 09:17:35.354660 146637 net.cpp:157] Top shape: 16 2 60 60 (115200)
I0721 09:17:35.354682 146637 net.cpp:165] Memory required for data: 3319676096
I0721 09:17:35.354696 146637 layer_factory.hpp:76] Creating layer interloss
I0721 09:17:35.354712 146637 net.cpp:106] Creating Layer interloss
I0721 09:17:35.354732 146637 net.cpp:454] interloss <- ip2
I0721 09:17:35.354756 146637 net.cpp:411] interloss -> interloss
I0721 09:17:35.355047 146637 net.cpp:150] Setting up interloss
I0721 09:17:35.355073 146637 net.cpp:157] Top shape: 16 2 60 60 (115200)
I0721 09:17:35.355082 146637 net.cpp:165] Memory required for data: 3320136896
I0721 09:17:35.355090 146637 layer_factory.hpp:76] Creating layer conv61
I0721 09:17:35.355108 146637 net.cpp:106] Creating Layer conv61
I0721 09:17:35.355116 146637 net.cpp:454] conv61 <- interloss
I0721 09:17:35.355129 146637 net.cpp:411] conv61 -> conv61
I0721 09:17:35.356564 146637 net.cpp:150] Setting up conv61
I0721 09:17:35.356592 146637 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0721 09:17:35.356603 146637 net.cpp:165] Memory required for data: 3334882496
I0721 09:17:35.356614 146637 layer_factory.hpp:76] Creating layer relu61
I0721 09:17:35.356628 146637 net.cpp:106] Creating Layer relu61
I0721 09:17:35.356637 146637 net.cpp:454] relu61 <- conv61
I0721 09:17:35.356647 146637 net.cpp:397] relu61 -> conv61 (in-place)
I0721 09:17:35.357517 146637 net.cpp:150] Setting up relu61
I0721 09:17:35.357544 146637 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0721 09:17:35.357553 146637 net.cpp:165] Memory required for data: 3349628096
I0721 09:17:35.357561 146637 layer_factory.hpp:76] Creating layer conv62
I0721 09:17:35.357576 146637 net.cpp:106] Creating Layer conv62
I0721 09:17:35.357584 146637 net.cpp:454] conv62 <- conv61
I0721 09:17:35.357595 146637 net.cpp:411] conv62 -> conv62
I0721 09:17:35.358860 146637 net.cpp:150] Setting up conv62
I0721 09:17:35.358891 146637 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0721 09:17:35.358899 146637 net.cpp:165] Memory required for data: 3364373696
I0721 09:17:35.358911 146637 layer_factory.hpp:76] Creating layer relu62
I0721 09:17:35.358922 146637 net.cpp:106] Creating Layer relu62
I0721 09:17:35.358929 146637 net.cpp:454] relu62 <- conv62
I0721 09:17:35.358937 146637 net.cpp:397] relu62 -> conv62 (in-place)
I0721 09:17:35.359423 146637 net.cpp:150] Setting up relu62
I0721 09:17:35.359452 146637 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0721 09:17:35.359459 146637 net.cpp:165] Memory required for data: 3379119296
I0721 09:17:35.359467 146637 layer_factory.hpp:76] Creating layer pool5
I0721 09:17:35.359478 146637 net.cpp:106] Creating Layer pool5
I0721 09:17:35.359486 146637 net.cpp:454] pool5 <- conv62
I0721 09:17:35.359498 146637 net.cpp:411] pool5 -> pool5
I0721 09:17:35.359726 146637 net.cpp:150] Setting up pool5
I0721 09:17:35.359755 146637 net.cpp:157] Top shape: 16 64 30 30 (921600)
I0721 09:17:35.359764 146637 net.cpp:165] Memory required for data: 3382805696
I0721 09:17:35.359772 146637 layer_factory.hpp:76] Creating layer conv71
I0721 09:17:35.359784 146637 net.cpp:106] Creating Layer conv71
I0721 09:17:35.359792 146637 net.cpp:454] conv71 <- pool5
I0721 09:17:35.359804 146637 net.cpp:411] conv71 -> conv71
I0721 09:17:35.377753 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0721 09:17:35.388468 146637 net.cpp:150] Setting up conv71
I0721 09:17:35.388501 146637 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0721 09:17:35.388510 146637 net.cpp:165] Memory required for data: 3388335296
I0721 09:17:35.388531 146637 layer_factory.hpp:76] Creating layer relu71
I0721 09:17:35.388546 146637 net.cpp:106] Creating Layer relu71
I0721 09:17:35.388556 146637 net.cpp:454] relu71 <- conv71
I0721 09:17:35.388566 146637 net.cpp:397] relu71 -> conv71 (in-place)
I0721 09:17:35.397478 146637 net.cpp:150] Setting up relu71
I0721 09:17:35.397513 146637 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0721 09:17:35.397522 146637 net.cpp:165] Memory required for data: 3393864896
I0721 09:17:35.397534 146637 layer_factory.hpp:76] Creating layer conv72
I0721 09:17:35.397567 146637 net.cpp:106] Creating Layer conv72
I0721 09:17:35.397583 146637 net.cpp:454] conv72 <- conv71
I0721 09:17:35.397603 146637 net.cpp:411] conv72 -> conv72
I0721 09:17:35.400348 146637 net.cpp:150] Setting up conv72
I0721 09:17:35.400400 146637 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0721 09:17:35.400411 146637 net.cpp:165] Memory required for data: 3399394496
I0721 09:17:35.400449 146637 layer_factory.hpp:76] Creating layer relu72
I0721 09:17:35.400473 146637 net.cpp:106] Creating Layer relu72
I0721 09:17:35.400483 146637 net.cpp:454] relu72 <- conv72
I0721 09:17:35.400497 146637 net.cpp:397] relu72 -> conv72 (in-place)
I0721 09:17:35.400696 146637 net.cpp:150] Setting up relu72
I0721 09:17:35.400713 146637 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0721 09:17:35.400722 146637 net.cpp:165] Memory required for data: 3404924096
I0721 09:17:35.400729 146637 layer_factory.hpp:76] Creating layer pool6
I0721 09:17:35.400743 146637 net.cpp:106] Creating Layer pool6
I0721 09:17:35.400753 146637 net.cpp:454] pool6 <- conv72
I0721 09:17:35.400761 146637 net.cpp:411] pool6 -> pool6
I0721 09:17:35.401104 146637 net.cpp:150] Setting up pool6
I0721 09:17:35.401124 146637 net.cpp:157] Top shape: 16 96 15 15 (345600)
I0721 09:17:35.401134 146637 net.cpp:165] Memory required for data: 3406306496
I0721 09:17:35.401141 146637 layer_factory.hpp:76] Creating layer conv81
I0721 09:17:35.401157 146637 net.cpp:106] Creating Layer conv81
I0721 09:17:35.401166 146637 net.cpp:454] conv81 <- pool6
I0721 09:17:35.401180 146637 net.cpp:411] conv81 -> conv81
I0721 09:17:35.402798 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0721 09:17:35.402833 146637 net.cpp:150] Setting up conv81
I0721 09:17:35.402845 146637 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0721 09:17:35.402854 146637 net.cpp:165] Memory required for data: 3408149696
I0721 09:17:35.402865 146637 layer_factory.hpp:76] Creating layer relu81
I0721 09:17:35.402884 146637 net.cpp:106] Creating Layer relu81
I0721 09:17:35.402894 146637 net.cpp:454] relu81 <- conv81
I0721 09:17:35.402902 146637 net.cpp:397] relu81 -> conv81 (in-place)
I0721 09:17:35.403241 146637 net.cpp:150] Setting up relu81
I0721 09:17:35.403260 146637 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0721 09:17:35.403270 146637 net.cpp:165] Memory required for data: 3409992896
I0721 09:17:35.403277 146637 layer_factory.hpp:76] Creating layer conv82
I0721 09:17:35.403296 146637 net.cpp:106] Creating Layer conv82
I0721 09:17:35.403307 146637 net.cpp:454] conv82 <- conv81
I0721 09:17:35.403317 146637 net.cpp:411] conv82 -> conv82
I0721 09:17:35.405825 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0721 09:17:35.405867 146637 net.cpp:150] Setting up conv82
I0721 09:17:35.405882 146637 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0721 09:17:35.405890 146637 net.cpp:165] Memory required for data: 3411836096
I0721 09:17:35.405903 146637 layer_factory.hpp:76] Creating layer relu82
I0721 09:17:35.405915 146637 net.cpp:106] Creating Layer relu82
I0721 09:17:35.405922 146637 net.cpp:454] relu82 <- conv82
I0721 09:17:35.405937 146637 net.cpp:397] relu82 -> conv82 (in-place)
I0721 09:17:35.406116 146637 net.cpp:150] Setting up relu82
I0721 09:17:35.406133 146637 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0721 09:17:35.406141 146637 net.cpp:165] Memory required for data: 3413679296
I0721 09:17:35.406150 146637 layer_factory.hpp:76] Creating layer pool7
I0721 09:17:35.406178 146637 net.cpp:106] Creating Layer pool7
I0721 09:17:35.406186 146637 net.cpp:454] pool7 <- conv82
I0721 09:17:35.406196 146637 net.cpp:411] pool7 -> pool7
I0721 09:17:35.406534 146637 net.cpp:150] Setting up pool7
I0721 09:17:35.406553 146637 net.cpp:157] Top shape: 16 128 8 8 (131072)
I0721 09:17:35.406560 146637 net.cpp:165] Memory required for data: 3414203584
I0721 09:17:35.406569 146637 layer_factory.hpp:76] Creating layer drop0
I0721 09:17:35.406585 146637 net.cpp:106] Creating Layer drop0
I0721 09:17:35.406594 146637 net.cpp:454] drop0 <- pool7
I0721 09:17:35.406604 146637 net.cpp:397] drop0 -> pool7 (in-place)
I0721 09:17:35.406646 146637 net.cpp:150] Setting up drop0
I0721 09:17:35.406671 146637 net.cpp:157] Top shape: 16 128 8 8 (131072)
I0721 09:17:35.406677 146637 net.cpp:165] Memory required for data: 3414727872
I0721 09:17:35.406688 146637 layer_factory.hpp:76] Creating layer conv91
I0721 09:17:35.406702 146637 net.cpp:106] Creating Layer conv91
I0721 09:17:35.406734 146637 net.cpp:454] conv91 <- pool7
I0721 09:17:35.406744 146637 net.cpp:411] conv91 -> conv91
I0721 09:17:35.407922 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0721 09:17:35.408136 146637 net.cpp:150] Setting up conv91
I0721 09:17:35.408154 146637 net.cpp:157] Top shape: 16 3 1 1 (48)
I0721 09:17:35.408164 146637 net.cpp:165] Memory required for data: 3414728064
I0721 09:17:35.408186 146637 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0721 09:17:35.408200 146637 net.cpp:106] Creating Layer conv91_conv91_0_split
I0721 09:17:35.408207 146637 net.cpp:454] conv91_conv91_0_split <- conv91
I0721 09:17:35.408217 146637 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0721 09:17:35.408231 146637 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0721 09:17:35.408273 146637 net.cpp:150] Setting up conv91_conv91_0_split
I0721 09:17:35.408288 146637 net.cpp:157] Top shape: 16 3 1 1 (48)
I0721 09:17:35.408295 146637 net.cpp:157] Top shape: 16 3 1 1 (48)
I0721 09:17:35.408306 146637 net.cpp:165] Memory required for data: 3414728448
I0721 09:17:35.408318 146637 layer_factory.hpp:76] Creating layer accuracy
I0721 09:17:35.408334 146637 net.cpp:106] Creating Layer accuracy
I0721 09:17:35.408342 146637 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0721 09:17:35.408351 146637 net.cpp:454] accuracy <- label_data_1_split_0
I0721 09:17:35.408361 146637 net.cpp:411] accuracy -> accuracy
I0721 09:17:35.408378 146637 net.cpp:150] Setting up accuracy
I0721 09:17:35.408387 146637 net.cpp:157] Top shape: (1)
I0721 09:17:35.408409 146637 net.cpp:165] Memory required for data: 3414728452
I0721 09:17:35.408418 146637 layer_factory.hpp:76] Creating layer loss
I0721 09:17:35.408430 146637 net.cpp:106] Creating Layer loss
I0721 09:17:35.408439 146637 net.cpp:454] loss <- conv91_conv91_0_split_1
I0721 09:17:35.408448 146637 net.cpp:454] loss <- label_data_1_split_1
I0721 09:17:35.408474 146637 net.cpp:411] loss -> loss
I0721 09:17:35.408490 146637 layer_factory.hpp:76] Creating layer loss
I0721 09:17:35.408797 146637 net.cpp:150] Setting up loss
I0721 09:17:35.408818 146637 net.cpp:157] Top shape: (1)
I0721 09:17:35.408824 146637 net.cpp:160]     with loss weight 1
I0721 09:17:35.408854 146637 net.cpp:165] Memory required for data: 3414728456
I0721 09:17:35.408861 146637 net.cpp:226] loss needs backward computation.
I0721 09:17:35.408870 146637 net.cpp:228] accuracy does not need backward computation.
I0721 09:17:35.408879 146637 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0721 09:17:35.408886 146637 net.cpp:226] conv91 needs backward computation.
I0721 09:17:35.408893 146637 net.cpp:226] drop0 needs backward computation.
I0721 09:17:35.408900 146637 net.cpp:226] pool7 needs backward computation.
I0721 09:17:35.408907 146637 net.cpp:226] relu82 needs backward computation.
I0721 09:17:35.408917 146637 net.cpp:226] conv82 needs backward computation.
I0721 09:17:35.408924 146637 net.cpp:226] relu81 needs backward computation.
I0721 09:17:35.408931 146637 net.cpp:226] conv81 needs backward computation.
I0721 09:17:35.408941 146637 net.cpp:226] pool6 needs backward computation.
I0721 09:17:35.408947 146637 net.cpp:226] relu72 needs backward computation.
I0721 09:17:35.408956 146637 net.cpp:226] conv72 needs backward computation.
I0721 09:17:35.408962 146637 net.cpp:226] relu71 needs backward computation.
I0721 09:17:35.408970 146637 net.cpp:226] conv71 needs backward computation.
I0721 09:17:35.408982 146637 net.cpp:226] pool5 needs backward computation.
I0721 09:17:35.408988 146637 net.cpp:226] relu62 needs backward computation.
I0721 09:17:35.408999 146637 net.cpp:226] conv62 needs backward computation.
I0721 09:17:35.409006 146637 net.cpp:226] relu61 needs backward computation.
I0721 09:17:35.409016 146637 net.cpp:226] conv61 needs backward computation.
I0721 09:17:35.409024 146637 net.cpp:226] interloss needs backward computation.
I0721 09:17:35.409034 146637 net.cpp:226] ip2_c needs backward computation.
I0721 09:17:35.409054 146637 net.cpp:226] nonlin_ip1 needs backward computation.
I0721 09:17:35.409062 146637 net.cpp:226] ip1_c needs backward computation.
I0721 09:17:35.409070 146637 net.cpp:228] pool4 does not need backward computation.
I0721 09:17:35.409081 146637 net.cpp:228] nonlin4 does not need backward computation.
I0721 09:17:35.409092 146637 net.cpp:228] conv4 does not need backward computation.
I0721 09:17:35.409101 146637 net.cpp:228] pool3 does not need backward computation.
I0721 09:17:35.409111 146637 net.cpp:228] nonlin3 does not need backward computation.
I0721 09:17:35.409118 146637 net.cpp:228] conv3 does not need backward computation.
I0721 09:17:35.409127 146637 net.cpp:228] pool2 does not need backward computation.
I0721 09:17:35.409134 146637 net.cpp:228] nonlin2 does not need backward computation.
I0721 09:17:35.409142 146637 net.cpp:228] conv2 does not need backward computation.
I0721 09:17:35.409152 146637 net.cpp:228] pool1 does not need backward computation.
I0721 09:17:35.409159 146637 net.cpp:228] nonlin1 does not need backward computation.
I0721 09:17:35.409169 146637 net.cpp:228] conv1 does not need backward computation.
I0721 09:17:35.409178 146637 net.cpp:228] label_data_1_split does not need backward computation.
I0721 09:17:35.409184 146637 net.cpp:228] data does not need backward computation.
I0721 09:17:35.409193 146637 net.cpp:270] This network produces output accuracy
I0721 09:17:35.409199 146637 net.cpp:270] This network produces output loss
I0721 09:17:35.409230 146637 net.cpp:283] Network initialization done.
I0721 09:17:35.409971 146637 solver.cpp:180] Creating test net (#0) specified by net file: train_val-resultlayer-3stack.prototxt
I0721 09:17:35.410048 146637 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0721 09:17:35.410259 146637 net.cpp:49] Initializing net from parameters: 
name: "Result Layer 3 Stack"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 150
    mean_value: 150
    mean_value: 150
  }
  image_data_param {
    source: "../lists/mitosis_val.lst"
    batch_size: 8
    shuffle: true
    new_height: 1000
    new_width: 1000
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 4
    stride: 1
  }
}
layer {
  name: "nonlin1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_c"
  type: "Convolution"
  bottom: "pool4"
  top: "ip1"
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "nonlin_ip1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2_c"
  type: "Convolution"
  bottom: "ip1"
  top: "ip2"
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "interloss"
  type: "Softmax"
  bottom: "ip2"
  top: "interloss"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "interloss"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0721 09:17:35.411986 146637 layer_factory.hpp:76] Creating layer data
I0721 09:17:35.412012 146637 net.cpp:106] Creating Layer data
I0721 09:17:35.412021 146637 net.cpp:411] data -> data
I0721 09:17:35.412034 146637 net.cpp:411] data -> label
I0721 09:17:35.412055 146637 image_data_layer.cpp:36] Opening file ../lists/mitosis_val.lst
I0721 09:17:35.440238 146637 image_data_layer.cpp:46] Shuffling data
I0721 09:17:35.440428 146637 image_data_layer.cpp:51] A total of 2375 images.
I0721 09:17:35.537856 146637 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0721 09:17:35.741346 146637 net.cpp:150] Setting up data
I0721 09:17:35.741399 146637 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0721 09:17:35.741410 146637 net.cpp:157] Top shape: 8 (8)
I0721 09:17:35.741417 146637 net.cpp:165] Memory required for data: 96000032
I0721 09:17:35.741431 146637 layer_factory.hpp:76] Creating layer label_data_1_split
I0721 09:17:35.741458 146637 net.cpp:106] Creating Layer label_data_1_split
I0721 09:17:35.741466 146637 net.cpp:454] label_data_1_split <- label
I0721 09:17:35.741477 146637 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0721 09:17:35.741492 146637 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0721 09:17:35.741650 146637 net.cpp:150] Setting up label_data_1_split
I0721 09:17:35.741677 146637 net.cpp:157] Top shape: 8 (8)
I0721 09:17:35.741683 146637 net.cpp:157] Top shape: 8 (8)
I0721 09:17:35.741688 146637 net.cpp:165] Memory required for data: 96000096
I0721 09:17:35.741694 146637 layer_factory.hpp:76] Creating layer conv1
I0721 09:17:35.741719 146637 net.cpp:106] Creating Layer conv1
I0721 09:17:35.741724 146637 net.cpp:454] conv1 <- data
I0721 09:17:35.741735 146637 net.cpp:411] conv1 -> conv1
I0721 09:17:35.745980 146637 net.cpp:150] Setting up conv1
I0721 09:17:35.746021 146637 net.cpp:157] Top shape: 8 16 997 997 (127233152)
I0721 09:17:35.746031 146637 net.cpp:165] Memory required for data: 604932704
I0721 09:17:35.746048 146637 layer_factory.hpp:76] Creating layer nonlin1
I0721 09:17:35.746067 146637 net.cpp:106] Creating Layer nonlin1
I0721 09:17:35.746076 146637 net.cpp:454] nonlin1 <- conv1
I0721 09:17:35.746088 146637 net.cpp:397] nonlin1 -> conv1 (in-place)
I0721 09:17:35.746456 146637 net.cpp:150] Setting up nonlin1
I0721 09:17:35.746490 146637 net.cpp:157] Top shape: 8 16 997 997 (127233152)
I0721 09:17:35.746498 146637 net.cpp:165] Memory required for data: 1113865312
I0721 09:17:35.746507 146637 layer_factory.hpp:76] Creating layer pool1
I0721 09:17:35.746525 146637 net.cpp:106] Creating Layer pool1
I0721 09:17:35.746534 146637 net.cpp:454] pool1 <- conv1
I0721 09:17:35.746546 146637 net.cpp:411] pool1 -> pool1
I0721 09:17:35.746785 146637 net.cpp:150] Setting up pool1
I0721 09:17:35.746819 146637 net.cpp:157] Top shape: 8 16 499 499 (31872128)
I0721 09:17:35.746829 146637 net.cpp:165] Memory required for data: 1241353824
I0721 09:17:35.746839 146637 layer_factory.hpp:76] Creating layer conv2
I0721 09:17:35.746855 146637 net.cpp:106] Creating Layer conv2
I0721 09:17:35.746862 146637 net.cpp:454] conv2 <- pool1
I0721 09:17:35.746876 146637 net.cpp:411] conv2 -> conv2
I0721 09:17:35.748720 146637 net.cpp:150] Setting up conv2
I0721 09:17:35.748755 146637 net.cpp:157] Top shape: 8 16 497 497 (31617152)
I0721 09:17:35.748765 146637 net.cpp:165] Memory required for data: 1367822432
I0721 09:17:35.748780 146637 layer_factory.hpp:76] Creating layer nonlin2
I0721 09:17:35.748795 146637 net.cpp:106] Creating Layer nonlin2
I0721 09:17:35.748803 146637 net.cpp:454] nonlin2 <- conv2
I0721 09:17:35.748816 146637 net.cpp:397] nonlin2 -> conv2 (in-place)
I0721 09:17:35.749017 146637 net.cpp:150] Setting up nonlin2
I0721 09:17:35.749070 146637 net.cpp:157] Top shape: 8 16 497 497 (31617152)
I0721 09:17:35.749080 146637 net.cpp:165] Memory required for data: 1494291040
I0721 09:17:35.749089 146637 layer_factory.hpp:76] Creating layer pool2
I0721 09:17:35.749104 146637 net.cpp:106] Creating Layer pool2
I0721 09:17:35.749112 146637 net.cpp:454] pool2 <- conv2
I0721 09:17:35.749122 146637 net.cpp:411] pool2 -> pool2
I0721 09:17:35.749500 146637 net.cpp:150] Setting up pool2
I0721 09:17:35.749531 146637 net.cpp:157] Top shape: 8 16 249 249 (7936128)
I0721 09:17:35.749541 146637 net.cpp:165] Memory required for data: 1526035552
I0721 09:17:35.749550 146637 layer_factory.hpp:76] Creating layer conv3
I0721 09:17:35.749568 146637 net.cpp:106] Creating Layer conv3
I0721 09:17:35.749577 146637 net.cpp:454] conv3 <- pool2
I0721 09:17:35.749588 146637 net.cpp:411] conv3 -> conv3
I0721 09:17:35.750743 146637 net.cpp:150] Setting up conv3
I0721 09:17:35.750777 146637 net.cpp:157] Top shape: 8 16 247 247 (7809152)
I0721 09:17:35.750787 146637 net.cpp:165] Memory required for data: 1557272160
I0721 09:17:35.750800 146637 layer_factory.hpp:76] Creating layer nonlin3
I0721 09:17:35.750818 146637 net.cpp:106] Creating Layer nonlin3
I0721 09:17:35.750826 146637 net.cpp:454] nonlin3 <- conv3
I0721 09:17:35.750836 146637 net.cpp:397] nonlin3 -> conv3 (in-place)
I0721 09:17:35.751022 146637 net.cpp:150] Setting up nonlin3
I0721 09:17:35.751050 146637 net.cpp:157] Top shape: 8 16 247 247 (7809152)
I0721 09:17:35.751058 146637 net.cpp:165] Memory required for data: 1588508768
I0721 09:17:35.751068 146637 layer_factory.hpp:76] Creating layer pool3
I0721 09:17:35.751080 146637 net.cpp:106] Creating Layer pool3
I0721 09:17:35.751090 146637 net.cpp:454] pool3 <- conv3
I0721 09:17:35.751098 146637 net.cpp:411] pool3 -> pool3
I0721 09:17:35.751476 146637 net.cpp:150] Setting up pool3
I0721 09:17:35.751505 146637 net.cpp:157] Top shape: 8 16 124 124 (1968128)
I0721 09:17:35.751514 146637 net.cpp:165] Memory required for data: 1596381280
I0721 09:17:35.751523 146637 layer_factory.hpp:76] Creating layer conv4
I0721 09:17:35.751539 146637 net.cpp:106] Creating Layer conv4
I0721 09:17:35.751549 146637 net.cpp:454] conv4 <- pool3
I0721 09:17:35.751559 146637 net.cpp:411] conv4 -> conv4
I0721 09:17:35.752635 146637 net.cpp:150] Setting up conv4
I0721 09:17:35.752668 146637 net.cpp:157] Top shape: 8 16 122 122 (1905152)
I0721 09:17:35.752678 146637 net.cpp:165] Memory required for data: 1604001888
I0721 09:17:35.752691 146637 layer_factory.hpp:76] Creating layer nonlin4
I0721 09:17:35.752704 146637 net.cpp:106] Creating Layer nonlin4
I0721 09:17:35.752714 146637 net.cpp:454] nonlin4 <- conv4
I0721 09:17:35.752723 146637 net.cpp:397] nonlin4 -> conv4 (in-place)
I0721 09:17:35.752915 146637 net.cpp:150] Setting up nonlin4
I0721 09:17:35.752944 146637 net.cpp:157] Top shape: 8 16 122 122 (1905152)
I0721 09:17:35.752953 146637 net.cpp:165] Memory required for data: 1611622496
I0721 09:17:35.752962 146637 layer_factory.hpp:76] Creating layer pool4
I0721 09:17:35.752974 146637 net.cpp:106] Creating Layer pool4
I0721 09:17:35.752981 146637 net.cpp:454] pool4 <- conv4
I0721 09:17:35.752996 146637 net.cpp:411] pool4 -> pool4
I0721 09:17:35.753370 146637 net.cpp:150] Setting up pool4
I0721 09:17:35.753401 146637 net.cpp:157] Top shape: 8 16 61 61 (476288)
I0721 09:17:35.753410 146637 net.cpp:165] Memory required for data: 1613527648
I0721 09:17:35.753422 146637 layer_factory.hpp:76] Creating layer ip1_c
I0721 09:17:35.753437 146637 net.cpp:106] Creating Layer ip1_c
I0721 09:17:35.753446 146637 net.cpp:454] ip1_c <- pool4
I0721 09:17:35.753456 146637 net.cpp:411] ip1_c -> ip1
I0721 09:17:35.754443 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 22118400
I0721 09:17:35.754706 146637 net.cpp:150] Setting up ip1_c
I0721 09:17:35.754739 146637 net.cpp:157] Top shape: 8 200 60 60 (5760000)
I0721 09:17:35.754747 146637 net.cpp:165] Memory required for data: 1636567648
I0721 09:17:35.754762 146637 layer_factory.hpp:76] Creating layer nonlin_ip1
I0721 09:17:35.754792 146637 net.cpp:106] Creating Layer nonlin_ip1
I0721 09:17:35.754807 146637 net.cpp:454] nonlin_ip1 <- ip1
I0721 09:17:35.754817 146637 net.cpp:397] nonlin_ip1 -> ip1 (in-place)
I0721 09:17:35.755156 146637 net.cpp:150] Setting up nonlin_ip1
I0721 09:17:35.755187 146637 net.cpp:157] Top shape: 8 200 60 60 (5760000)
I0721 09:17:35.755198 146637 net.cpp:165] Memory required for data: 1659607648
I0721 09:17:35.755206 146637 layer_factory.hpp:76] Creating layer ip2_c
I0721 09:17:35.755223 146637 net.cpp:106] Creating Layer ip2_c
I0721 09:17:35.755233 146637 net.cpp:454] ip2_c <- ip1
I0721 09:17:35.755244 146637 net.cpp:411] ip2_c -> ip2
I0721 09:17:35.756326 146637 net.cpp:150] Setting up ip2_c
I0721 09:17:35.756359 146637 net.cpp:157] Top shape: 8 2 60 60 (57600)
I0721 09:17:35.756371 146637 net.cpp:165] Memory required for data: 1659838048
I0721 09:17:35.756383 146637 layer_factory.hpp:76] Creating layer interloss
I0721 09:17:35.756398 146637 net.cpp:106] Creating Layer interloss
I0721 09:17:35.756407 146637 net.cpp:454] interloss <- ip2
I0721 09:17:35.756417 146637 net.cpp:411] interloss -> interloss
I0721 09:17:35.756676 146637 net.cpp:150] Setting up interloss
I0721 09:17:35.756705 146637 net.cpp:157] Top shape: 8 2 60 60 (57600)
I0721 09:17:35.756714 146637 net.cpp:165] Memory required for data: 1660068448
I0721 09:17:35.756726 146637 layer_factory.hpp:76] Creating layer conv61
I0721 09:17:35.756743 146637 net.cpp:106] Creating Layer conv61
I0721 09:17:35.756752 146637 net.cpp:454] conv61 <- interloss
I0721 09:17:35.756762 146637 net.cpp:411] conv61 -> conv61
I0721 09:17:35.757844 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6220800
I0721 09:17:35.758081 146637 net.cpp:150] Setting up conv61
I0721 09:17:35.758111 146637 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0721 09:17:35.758119 146637 net.cpp:165] Memory required for data: 1667441248
I0721 09:17:35.758133 146637 layer_factory.hpp:76] Creating layer relu61
I0721 09:17:35.758144 146637 net.cpp:106] Creating Layer relu61
I0721 09:17:35.758153 146637 net.cpp:454] relu61 <- conv61
I0721 09:17:35.758165 146637 net.cpp:397] relu61 -> conv61 (in-place)
I0721 09:17:35.758514 146637 net.cpp:150] Setting up relu61
I0721 09:17:35.758545 146637 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0721 09:17:35.758554 146637 net.cpp:165] Memory required for data: 1674814048
I0721 09:17:35.758563 146637 layer_factory.hpp:76] Creating layer conv62
I0721 09:17:35.758579 146637 net.cpp:106] Creating Layer conv62
I0721 09:17:35.758589 146637 net.cpp:454] conv62 <- conv61
I0721 09:17:35.758600 146637 net.cpp:411] conv62 -> conv62
I0721 09:17:35.760555 146637 net.cpp:150] Setting up conv62
I0721 09:17:35.760589 146637 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0721 09:17:35.760598 146637 net.cpp:165] Memory required for data: 1682186848
I0721 09:17:35.760610 146637 layer_factory.hpp:76] Creating layer relu62
I0721 09:17:35.760622 146637 net.cpp:106] Creating Layer relu62
I0721 09:17:35.760630 146637 net.cpp:454] relu62 <- conv62
I0721 09:17:35.760643 146637 net.cpp:397] relu62 -> conv62 (in-place)
I0721 09:17:35.760972 146637 net.cpp:150] Setting up relu62
I0721 09:17:35.761003 146637 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0721 09:17:35.761011 146637 net.cpp:165] Memory required for data: 1689559648
I0721 09:17:35.761021 146637 layer_factory.hpp:76] Creating layer pool5
I0721 09:17:35.761034 146637 net.cpp:106] Creating Layer pool5
I0721 09:17:35.761041 146637 net.cpp:454] pool5 <- conv62
I0721 09:17:35.761054 146637 net.cpp:411] pool5 -> pool5
I0721 09:17:35.761423 146637 net.cpp:150] Setting up pool5
I0721 09:17:35.761453 146637 net.cpp:157] Top shape: 8 64 30 30 (460800)
I0721 09:17:35.761462 146637 net.cpp:165] Memory required for data: 1691402848
I0721 09:17:35.761471 146637 layer_factory.hpp:76] Creating layer conv71
I0721 09:17:35.761488 146637 net.cpp:106] Creating Layer conv71
I0721 09:17:35.761497 146637 net.cpp:454] conv71 <- pool5
I0721 09:17:35.761509 146637 net.cpp:411] conv71 -> conv71
I0721 09:17:35.762861 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0721 09:17:35.762931 146637 net.cpp:150] Setting up conv71
I0721 09:17:35.762945 146637 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0721 09:17:35.762953 146637 net.cpp:165] Memory required for data: 1694167648
I0721 09:17:35.762971 146637 layer_factory.hpp:76] Creating layer relu71
I0721 09:17:35.763000 146637 net.cpp:106] Creating Layer relu71
I0721 09:17:35.763008 146637 net.cpp:454] relu71 <- conv71
I0721 09:17:35.763020 146637 net.cpp:397] relu71 -> conv71 (in-place)
I0721 09:17:35.763376 146637 net.cpp:150] Setting up relu71
I0721 09:17:35.763406 146637 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0721 09:17:35.763416 146637 net.cpp:165] Memory required for data: 1696932448
I0721 09:17:35.763423 146637 layer_factory.hpp:76] Creating layer conv72
I0721 09:17:35.763442 146637 net.cpp:106] Creating Layer conv72
I0721 09:17:35.763451 146637 net.cpp:454] conv72 <- conv71
I0721 09:17:35.763461 146637 net.cpp:411] conv72 -> conv72
I0721 09:17:35.765257 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0721 09:17:35.765311 146637 net.cpp:150] Setting up conv72
I0721 09:17:35.765323 146637 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0721 09:17:35.765332 146637 net.cpp:165] Memory required for data: 1699697248
I0721 09:17:35.765348 146637 layer_factory.hpp:76] Creating layer relu72
I0721 09:17:35.765362 146637 net.cpp:106] Creating Layer relu72
I0721 09:17:35.765370 146637 net.cpp:454] relu72 <- conv72
I0721 09:17:35.765383 146637 net.cpp:397] relu72 -> conv72 (in-place)
I0721 09:17:35.765585 146637 net.cpp:150] Setting up relu72
I0721 09:17:35.765614 146637 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0721 09:17:35.765622 146637 net.cpp:165] Memory required for data: 1702462048
I0721 09:17:35.765632 146637 layer_factory.hpp:76] Creating layer pool6
I0721 09:17:35.765657 146637 net.cpp:106] Creating Layer pool6
I0721 09:17:35.765666 146637 net.cpp:454] pool6 <- conv72
I0721 09:17:35.765677 146637 net.cpp:411] pool6 -> pool6
I0721 09:17:35.766062 146637 net.cpp:150] Setting up pool6
I0721 09:17:35.766098 146637 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0721 09:17:35.766108 146637 net.cpp:165] Memory required for data: 1703153248
I0721 09:17:35.766118 146637 layer_factory.hpp:76] Creating layer conv81
I0721 09:17:35.766134 146637 net.cpp:106] Creating Layer conv81
I0721 09:17:35.766142 146637 net.cpp:454] conv81 <- pool6
I0721 09:17:35.766156 146637 net.cpp:411] conv81 -> conv81
I0721 09:17:35.768457 146637 net.cpp:150] Setting up conv81
I0721 09:17:35.768491 146637 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0721 09:17:35.768501 146637 net.cpp:165] Memory required for data: 1704074848
I0721 09:17:35.768512 146637 layer_factory.hpp:76] Creating layer relu81
I0721 09:17:35.768525 146637 net.cpp:106] Creating Layer relu81
I0721 09:17:35.768534 146637 net.cpp:454] relu81 <- conv81
I0721 09:17:35.768546 146637 net.cpp:397] relu81 -> conv81 (in-place)
I0721 09:17:35.768733 146637 net.cpp:150] Setting up relu81
I0721 09:17:35.768748 146637 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0721 09:17:35.768769 146637 net.cpp:165] Memory required for data: 1704996448
I0721 09:17:35.768780 146637 layer_factory.hpp:76] Creating layer conv82
I0721 09:17:35.768795 146637 net.cpp:106] Creating Layer conv82
I0721 09:17:35.768805 146637 net.cpp:454] conv82 <- conv81
I0721 09:17:35.768815 146637 net.cpp:411] conv82 -> conv82
I0721 09:17:35.770923 146637 net.cpp:150] Setting up conv82
I0721 09:17:35.770956 146637 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0721 09:17:35.770965 146637 net.cpp:165] Memory required for data: 1705918048
I0721 09:17:35.770977 146637 layer_factory.hpp:76] Creating layer relu82
I0721 09:17:35.770988 146637 net.cpp:106] Creating Layer relu82
I0721 09:17:35.770998 146637 net.cpp:454] relu82 <- conv82
I0721 09:17:35.771010 146637 net.cpp:397] relu82 -> conv82 (in-place)
I0721 09:17:35.771205 146637 net.cpp:150] Setting up relu82
I0721 09:17:35.771232 146637 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0721 09:17:35.771245 146637 net.cpp:165] Memory required for data: 1706839648
I0721 09:17:35.771280 146637 layer_factory.hpp:76] Creating layer pool7
I0721 09:17:35.771309 146637 net.cpp:106] Creating Layer pool7
I0721 09:17:35.771319 146637 net.cpp:454] pool7 <- conv82
I0721 09:17:35.771343 146637 net.cpp:411] pool7 -> pool7
I0721 09:17:35.771719 146637 net.cpp:150] Setting up pool7
I0721 09:17:35.771750 146637 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0721 09:17:35.771759 146637 net.cpp:165] Memory required for data: 1707101792
I0721 09:17:35.771767 146637 layer_factory.hpp:76] Creating layer drop0
I0721 09:17:35.771778 146637 net.cpp:106] Creating Layer drop0
I0721 09:17:35.771802 146637 net.cpp:454] drop0 <- pool7
I0721 09:17:35.771811 146637 net.cpp:397] drop0 -> pool7 (in-place)
I0721 09:17:35.771847 146637 net.cpp:150] Setting up drop0
I0721 09:17:35.771859 146637 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0721 09:17:35.771867 146637 net.cpp:165] Memory required for data: 1707363936
I0721 09:17:35.771875 146637 layer_factory.hpp:76] Creating layer conv91
I0721 09:17:35.771896 146637 net.cpp:106] Creating Layer conv91
I0721 09:17:35.771908 146637 net.cpp:454] conv91 <- pool7
I0721 09:17:35.771930 146637 net.cpp:411] conv91 -> conv91
I0721 09:17:35.773221 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0721 09:17:35.773267 146637 net.cpp:150] Setting up conv91
I0721 09:17:35.773283 146637 net.cpp:157] Top shape: 8 3 1 1 (24)
I0721 09:17:35.773291 146637 net.cpp:165] Memory required for data: 1707364032
I0721 09:17:35.773304 146637 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0721 09:17:35.773316 146637 net.cpp:106] Creating Layer conv91_conv91_0_split
I0721 09:17:35.773325 146637 net.cpp:454] conv91_conv91_0_split <- conv91
I0721 09:17:35.773335 146637 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0721 09:17:35.773347 146637 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0721 09:17:35.773399 146637 net.cpp:150] Setting up conv91_conv91_0_split
I0721 09:17:35.773412 146637 net.cpp:157] Top shape: 8 3 1 1 (24)
I0721 09:17:35.773422 146637 net.cpp:157] Top shape: 8 3 1 1 (24)
I0721 09:17:35.773429 146637 net.cpp:165] Memory required for data: 1707364224
I0721 09:17:35.773437 146637 layer_factory.hpp:76] Creating layer accuracy
I0721 09:17:35.773448 146637 net.cpp:106] Creating Layer accuracy
I0721 09:17:35.773457 146637 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0721 09:17:35.773465 146637 net.cpp:454] accuracy <- label_data_1_split_0
I0721 09:17:35.773478 146637 net.cpp:411] accuracy -> accuracy
I0721 09:17:35.773490 146637 net.cpp:150] Setting up accuracy
I0721 09:17:35.773499 146637 net.cpp:157] Top shape: (1)
I0721 09:17:35.773507 146637 net.cpp:165] Memory required for data: 1707364228
I0721 09:17:35.773515 146637 layer_factory.hpp:76] Creating layer loss
I0721 09:17:35.773526 146637 net.cpp:106] Creating Layer loss
I0721 09:17:35.773535 146637 net.cpp:454] loss <- conv91_conv91_0_split_1
I0721 09:17:35.773546 146637 net.cpp:454] loss <- label_data_1_split_1
I0721 09:17:35.773556 146637 net.cpp:411] loss -> loss
I0721 09:17:35.773568 146637 layer_factory.hpp:76] Creating layer loss
I0721 09:17:35.773962 146637 net.cpp:150] Setting up loss
I0721 09:17:35.773990 146637 net.cpp:157] Top shape: (1)
I0721 09:17:35.773998 146637 net.cpp:160]     with loss weight 1
I0721 09:17:35.774024 146637 net.cpp:165] Memory required for data: 1707364232
I0721 09:17:35.774044 146637 net.cpp:226] loss needs backward computation.
I0721 09:17:35.774055 146637 net.cpp:228] accuracy does not need backward computation.
I0721 09:17:35.774075 146637 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0721 09:17:35.774082 146637 net.cpp:226] conv91 needs backward computation.
I0721 09:17:35.774091 146637 net.cpp:226] drop0 needs backward computation.
I0721 09:17:35.774097 146637 net.cpp:226] pool7 needs backward computation.
I0721 09:17:35.774106 146637 net.cpp:226] relu82 needs backward computation.
I0721 09:17:35.774112 146637 net.cpp:226] conv82 needs backward computation.
I0721 09:17:35.774135 146637 net.cpp:226] relu81 needs backward computation.
I0721 09:17:35.774143 146637 net.cpp:226] conv81 needs backward computation.
I0721 09:17:35.774152 146637 net.cpp:226] pool6 needs backward computation.
I0721 09:17:35.774159 146637 net.cpp:226] relu72 needs backward computation.
I0721 09:17:35.774168 146637 net.cpp:226] conv72 needs backward computation.
I0721 09:17:35.774175 146637 net.cpp:226] relu71 needs backward computation.
I0721 09:17:35.774183 146637 net.cpp:226] conv71 needs backward computation.
I0721 09:17:35.774190 146637 net.cpp:226] pool5 needs backward computation.
I0721 09:17:35.774201 146637 net.cpp:226] relu62 needs backward computation.
I0721 09:17:35.774209 146637 net.cpp:226] conv62 needs backward computation.
I0721 09:17:35.774217 146637 net.cpp:226] relu61 needs backward computation.
I0721 09:17:35.774224 146637 net.cpp:226] conv61 needs backward computation.
I0721 09:17:35.774232 146637 net.cpp:226] interloss needs backward computation.
I0721 09:17:35.774240 146637 net.cpp:226] ip2_c needs backward computation.
I0721 09:17:35.774250 146637 net.cpp:226] nonlin_ip1 needs backward computation.
I0721 09:17:35.774258 146637 net.cpp:226] ip1_c needs backward computation.
I0721 09:17:35.774266 146637 net.cpp:228] pool4 does not need backward computation.
I0721 09:17:35.774274 146637 net.cpp:228] nonlin4 does not need backward computation.
I0721 09:17:35.774281 146637 net.cpp:228] conv4 does not need backward computation.
I0721 09:17:35.774289 146637 net.cpp:228] pool3 does not need backward computation.
I0721 09:17:35.774297 146637 net.cpp:228] nonlin3 does not need backward computation.
I0721 09:17:35.774307 146637 net.cpp:228] conv3 does not need backward computation.
I0721 09:17:35.774313 146637 net.cpp:228] pool2 does not need backward computation.
I0721 09:17:35.774322 146637 net.cpp:228] nonlin2 does not need backward computation.
I0721 09:17:35.774330 146637 net.cpp:228] conv2 does not need backward computation.
I0721 09:17:35.774338 146637 net.cpp:228] pool1 does not need backward computation.
I0721 09:17:35.774345 146637 net.cpp:228] nonlin1 does not need backward computation.
I0721 09:17:35.774353 146637 net.cpp:228] conv1 does not need backward computation.
I0721 09:17:35.774361 146637 net.cpp:228] label_data_1_split does not need backward computation.
I0721 09:17:35.774370 146637 net.cpp:228] data does not need backward computation.
I0721 09:17:35.774377 146637 net.cpp:270] This network produces output accuracy
I0721 09:17:35.774385 146637 net.cpp:270] This network produces output loss
I0721 09:17:35.774415 146637 net.cpp:283] Network initialization done.
I0721 09:17:35.774615 146637 solver.cpp:59] Solver scaffolding done.
I0721 09:17:35.775629 146637 caffe.cpp:128] Finetuning from models.final/mitosis_detection_wo_norm.caffemodel
I0721 09:17:35.814693 146637 parallel.cpp:394] GPUs pairs 2:3, 1:2
I0721 09:17:36.056572 146637 net.cpp:99] Sharing layer data from root net
I0721 09:17:36.057481 146637 net.cpp:143] Created top blob 0 (shape: 16 3 1000 1000 (48000000)) for shared layer data
I0721 09:17:36.057528 146637 net.cpp:143] Created top blob 1 (shape: 16 (16)) for shared layer data
I0721 09:17:36.182991 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0721 09:17:36.190837 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0721 09:17:36.198374 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0721 09:17:36.204535 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0721 09:17:36.207854 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0721 09:17:36.209952 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0721 09:17:36.211128 146637 parallel.cpp:237] GPU 2 does not have p2p access to GPU 1
I0721 09:17:36.495400 146637 net.cpp:99] Sharing layer data from root net
I0721 09:17:36.496762 146637 net.cpp:143] Created top blob 0 (shape: 16 3 1000 1000 (48000000)) for shared layer data
I0721 09:17:36.496866 146637 net.cpp:143] Created top blob 1 (shape: 16 (16)) for shared layer data
I0721 09:17:36.649829 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0721 09:17:36.662087 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0721 09:17:36.674245 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0721 09:17:36.681335 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0721 09:17:36.685919 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0721 09:17:36.688832 146637 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0721 09:17:36.693281 146637 parallel.cpp:422] Starting Optimization
I0721 09:17:36.693575 146637 solver.cpp:287] Solving Result Layer 3 Stack
I0721 09:17:36.693603 146637 solver.cpp:288] Learning Rate Policy: step
I0721 09:17:36.695349 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 09:17:37.614878 146637 solver.cpp:236] Iteration 0, loss = 1.0925
I0721 09:17:37.614943 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:17:37.614960 146637 solver.cpp:252]     Train net output #1: loss = 1.0925 (* 1 = 1.0925 loss)
I0721 09:17:41.512329 146637 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0721 09:18:28.434139 146637 solver.cpp:236] Iteration 10, loss = 1.11974
I0721 09:18:28.434301 146637 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0721 09:18:28.434340 146637 solver.cpp:252]     Train net output #1: loss = 1.11732 (* 1 = 1.11732 loss)
I0721 09:18:31.769470 146637 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I0721 09:19:17.601526 146637 solver.cpp:236] Iteration 20, loss = 1.11885
I0721 09:19:17.601732 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 09:19:17.601765 146637 solver.cpp:252]     Train net output #1: loss = 1.0958 (* 1 = 1.0958 loss)
I0721 09:19:21.165673 146637 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0721 09:20:06.185802 146637 solver.cpp:236] Iteration 30, loss = 1.0971
I0721 09:20:06.185967 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:20:06.186012 146637 solver.cpp:252]     Train net output #1: loss = 1.10307 (* 1 = 1.10307 loss)
I0721 09:20:09.508878 146637 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I0721 09:20:55.387887 146637 solver.cpp:236] Iteration 40, loss = 1.08941
I0721 09:20:55.388053 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:20:55.388108 146637 solver.cpp:252]     Train net output #1: loss = 1.1006 (* 1 = 1.1006 loss)
I0721 09:20:58.680546 146637 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0721 09:21:43.891408 146637 solver.cpp:236] Iteration 50, loss = 1.08784
I0721 09:21:43.891615 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 09:21:43.891647 146637 solver.cpp:252]     Train net output #1: loss = 1.13728 (* 1 = 1.13728 loss)
I0721 09:21:47.229708 146637 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I0721 09:22:33.151002 146637 solver.cpp:236] Iteration 60, loss = 1.07766
I0721 09:22:33.151212 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:22:33.151245 146637 solver.cpp:252]     Train net output #1: loss = 1.12548 (* 1 = 1.12548 loss)
I0721 09:22:36.715481 146637 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0721 09:23:23.382853 146637 solver.cpp:236] Iteration 70, loss = 1.069
I0721 09:23:23.383069 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 09:23:23.383101 146637 solver.cpp:252]     Train net output #1: loss = 0.989721 (* 1 = 0.989721 loss)
I0721 09:23:27.063417 146637 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I0721 09:24:13.067662 146637 solver.cpp:236] Iteration 80, loss = 1.08099
I0721 09:24:13.067891 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 09:24:13.067952 146637 solver.cpp:252]     Train net output #1: loss = 1.11832 (* 1 = 1.11832 loss)
I0721 09:24:16.619457 146637 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0721 09:25:03.477907 146637 solver.cpp:236] Iteration 90, loss = 1.07438
I0721 09:25:03.478153 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 09:25:03.478174 146637 solver.cpp:252]     Train net output #1: loss = 0.927526 (* 1 = 0.927526 loss)
I0721 09:25:07.021240 146637 sgd_solver.cpp:106] Iteration 90, lr = 0.01
I0721 09:25:52.703752 146637 solver.cpp:236] Iteration 100, loss = 1.07291
I0721 09:25:52.703969 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 09:25:52.704002 146637 solver.cpp:252]     Train net output #1: loss = 1.13397 (* 1 = 1.13397 loss)
I0721 09:25:56.113013 146637 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0721 09:26:42.632911 146637 solver.cpp:236] Iteration 110, loss = 1.07189
I0721 09:26:42.633152 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:26:42.633185 146637 solver.cpp:252]     Train net output #1: loss = 1.08248 (* 1 = 1.08248 loss)
I0721 09:26:46.207144 146637 sgd_solver.cpp:106] Iteration 110, lr = 0.01
I0721 09:27:32.295747 146637 solver.cpp:236] Iteration 120, loss = 1.07362
I0721 09:27:32.296005 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:27:32.296036 146637 solver.cpp:252]     Train net output #1: loss = 1.03561 (* 1 = 1.03561 loss)
I0721 09:27:35.614181 146637 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0721 09:28:23.711899 146637 solver.cpp:236] Iteration 130, loss = 1.06365
I0721 09:28:23.712108 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 09:28:23.712142 146637 solver.cpp:252]     Train net output #1: loss = 0.983409 (* 1 = 0.983409 loss)
I0721 09:28:27.179291 146637 sgd_solver.cpp:106] Iteration 130, lr = 0.01
I0721 09:29:13.138041 146637 solver.cpp:236] Iteration 140, loss = 1.07156
I0721 09:29:13.138195 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:29:13.138228 146637 solver.cpp:252]     Train net output #1: loss = 1.05701 (* 1 = 1.05701 loss)
I0721 09:29:16.383185 146637 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0721 09:30:01.799571 146637 solver.cpp:236] Iteration 150, loss = 1.07293
I0721 09:30:01.799748 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 09:30:01.799779 146637 solver.cpp:252]     Train net output #1: loss = 1.09548 (* 1 = 1.09548 loss)
I0721 09:30:05.115839 146637 sgd_solver.cpp:106] Iteration 150, lr = 0.01
I0721 09:30:50.865358 146637 solver.cpp:236] Iteration 160, loss = 1.06768
I0721 09:30:50.865527 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:30:50.865574 146637 solver.cpp:252]     Train net output #1: loss = 1.0274 (* 1 = 1.0274 loss)
I0721 09:30:54.308739 146637 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0721 09:31:39.732045 146637 solver.cpp:236] Iteration 170, loss = 1.06725
I0721 09:31:39.732234 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 09:31:39.732273 146637 solver.cpp:252]     Train net output #1: loss = 0.975307 (* 1 = 0.975307 loss)
I0721 09:31:43.129613 146637 sgd_solver.cpp:106] Iteration 170, lr = 0.01
I0721 09:32:28.623435 146637 solver.cpp:236] Iteration 180, loss = 1.06814
I0721 09:32:28.623709 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:32:28.623733 146637 solver.cpp:252]     Train net output #1: loss = 1.0079 (* 1 = 1.0079 loss)
I0721 09:32:32.066642 146637 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0721 09:33:16.808316 146637 solver.cpp:236] Iteration 190, loss = 1.05914
I0721 09:33:16.808593 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 09:33:16.808615 146637 solver.cpp:252]     Train net output #1: loss = 0.965601 (* 1 = 0.965601 loss)
I0721 09:33:20.117214 146637 sgd_solver.cpp:106] Iteration 190, lr = 0.01
I0721 09:34:05.985162 146637 solver.cpp:236] Iteration 200, loss = 1.05194
I0721 09:34:05.985406 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:34:05.985447 146637 solver.cpp:252]     Train net output #1: loss = 1.10189 (* 1 = 1.10189 loss)
I0721 09:34:09.361393 146637 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0721 09:34:54.391517 146637 solver.cpp:236] Iteration 210, loss = 1.06569
I0721 09:34:54.391753 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:34:54.391799 146637 solver.cpp:252]     Train net output #1: loss = 1.04697 (* 1 = 1.04697 loss)
I0721 09:34:57.730398 146637 sgd_solver.cpp:106] Iteration 210, lr = 0.01
I0721 09:35:42.566123 146637 solver.cpp:236] Iteration 220, loss = 1.06718
I0721 09:35:42.566283 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:35:42.566303 146637 solver.cpp:252]     Train net output #1: loss = 1.09311 (* 1 = 1.09311 loss)
I0721 09:35:45.949784 146637 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0721 09:36:31.733162 146637 solver.cpp:236] Iteration 230, loss = 1.05873
I0721 09:36:31.733338 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 09:36:31.733371 146637 solver.cpp:252]     Train net output #1: loss = 0.92156 (* 1 = 0.92156 loss)
I0721 09:36:35.049865 146637 sgd_solver.cpp:106] Iteration 230, lr = 0.01
I0721 09:37:20.034021 146637 solver.cpp:236] Iteration 240, loss = 1.07031
I0721 09:37:20.034255 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:37:20.034278 146637 solver.cpp:252]     Train net output #1: loss = 1.12903 (* 1 = 1.12903 loss)
I0721 09:37:23.406028 146637 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0721 09:38:09.249013 146637 solver.cpp:236] Iteration 250, loss = 1.08252
I0721 09:38:09.249228 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:38:09.249256 146637 solver.cpp:252]     Train net output #1: loss = 1.03552 (* 1 = 1.03552 loss)
I0721 09:38:12.673329 146637 sgd_solver.cpp:106] Iteration 250, lr = 0.01
I0721 09:38:58.601172 146637 solver.cpp:236] Iteration 260, loss = 1.07403
I0721 09:38:58.601435 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:38:58.601471 146637 solver.cpp:252]     Train net output #1: loss = 1.08945 (* 1 = 1.08945 loss)
I0721 09:39:02.123965 146637 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0721 09:39:48.706217 146637 solver.cpp:236] Iteration 270, loss = 1.07058
I0721 09:39:48.706424 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:39:48.706478 146637 solver.cpp:252]     Train net output #1: loss = 1.08211 (* 1 = 1.08211 loss)
I0721 09:39:52.294317 146637 sgd_solver.cpp:106] Iteration 270, lr = 0.01
I0721 09:40:38.933805 146637 solver.cpp:236] Iteration 280, loss = 1.07755
I0721 09:40:38.933975 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 09:40:38.934013 146637 solver.cpp:252]     Train net output #1: loss = 0.94805 (* 1 = 0.94805 loss)
I0721 09:40:42.419914 146637 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0721 09:41:28.254475 146637 solver.cpp:236] Iteration 290, loss = 1.07386
I0721 09:41:28.254703 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:41:28.254739 146637 solver.cpp:252]     Train net output #1: loss = 1.05245 (* 1 = 1.05245 loss)
I0721 09:41:31.737689 146637 sgd_solver.cpp:106] Iteration 290, lr = 0.01
I0721 09:42:18.347409 146637 solver.cpp:236] Iteration 300, loss = 1.05822
I0721 09:42:18.347584 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:42:18.347614 146637 solver.cpp:252]     Train net output #1: loss = 1.09714 (* 1 = 1.09714 loss)
I0721 09:42:21.896842 146637 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0721 09:43:07.924968 146637 solver.cpp:236] Iteration 310, loss = 1.05956
I0721 09:43:07.925159 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:43:07.925200 146637 solver.cpp:252]     Train net output #1: loss = 1.07289 (* 1 = 1.07289 loss)
I0721 09:43:11.679705 146637 sgd_solver.cpp:106] Iteration 310, lr = 0.01
I0721 09:43:57.252137 146637 solver.cpp:236] Iteration 320, loss = 1.06386
I0721 09:43:57.252349 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:43:57.252367 146637 solver.cpp:252]     Train net output #1: loss = 1.12675 (* 1 = 1.12675 loss)
I0721 09:44:00.633788 146637 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0721 09:44:46.904892 146637 solver.cpp:236] Iteration 330, loss = 1.06298
I0721 09:44:46.905098 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:44:46.905134 146637 solver.cpp:252]     Train net output #1: loss = 1.07974 (* 1 = 1.07974 loss)
I0721 09:44:50.808861 146637 sgd_solver.cpp:106] Iteration 330, lr = 0.01
I0721 09:45:04.008107 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 09:45:38.054072 146637 solver.cpp:236] Iteration 340, loss = 1.05374
I0721 09:45:38.054230 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 09:45:38.054277 146637 solver.cpp:252]     Train net output #1: loss = 1.11998 (* 1 = 1.11998 loss)
I0721 09:45:41.379760 146637 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0721 09:46:26.357640 146637 solver.cpp:236] Iteration 350, loss = 1.06101
I0721 09:46:26.357846 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:46:26.357866 146637 solver.cpp:252]     Train net output #1: loss = 1.11029 (* 1 = 1.11029 loss)
I0721 09:46:30.039460 146637 sgd_solver.cpp:106] Iteration 350, lr = 0.01
I0721 09:47:14.661727 146637 solver.cpp:236] Iteration 360, loss = 1.05941
I0721 09:47:14.661896 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:47:14.661928 146637 solver.cpp:252]     Train net output #1: loss = 1.08341 (* 1 = 1.08341 loss)
I0721 09:47:17.937093 146637 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0721 09:48:03.528403 146637 solver.cpp:236] Iteration 370, loss = 1.05368
I0721 09:48:03.528609 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:48:03.528645 146637 solver.cpp:252]     Train net output #1: loss = 1.07628 (* 1 = 1.07628 loss)
I0721 09:48:06.810752 146637 sgd_solver.cpp:106] Iteration 370, lr = 0.01
I0721 09:48:51.912600 146637 solver.cpp:236] Iteration 380, loss = 1.05795
I0721 09:48:51.912780 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:48:51.912824 146637 solver.cpp:252]     Train net output #1: loss = 1.07466 (* 1 = 1.07466 loss)
I0721 09:48:55.331969 146637 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0721 09:49:40.574669 146637 solver.cpp:236] Iteration 390, loss = 1.06206
I0721 09:49:40.574905 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:49:40.574940 146637 solver.cpp:252]     Train net output #1: loss = 1.03604 (* 1 = 1.03604 loss)
I0721 09:49:43.941159 146637 sgd_solver.cpp:106] Iteration 390, lr = 0.01
I0721 09:50:29.360108 146637 solver.cpp:236] Iteration 400, loss = 1.06259
I0721 09:50:29.360404 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:50:29.360433 146637 solver.cpp:252]     Train net output #1: loss = 1.10065 (* 1 = 1.10065 loss)
I0721 09:50:33.266266 146637 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0721 09:51:19.746666 146637 solver.cpp:236] Iteration 410, loss = 1.06335
I0721 09:51:19.746861 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:51:19.746892 146637 solver.cpp:252]     Train net output #1: loss = 1.05694 (* 1 = 1.05694 loss)
I0721 09:51:23.458580 146637 sgd_solver.cpp:106] Iteration 410, lr = 0.01
I0721 09:52:08.077126 146637 solver.cpp:236] Iteration 420, loss = 1.06768
I0721 09:52:08.077354 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 09:52:08.077379 146637 solver.cpp:252]     Train net output #1: loss = 1.09315 (* 1 = 1.09315 loss)
I0721 09:52:11.576145 146637 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0721 09:52:56.676100 146637 solver.cpp:236] Iteration 430, loss = 1.06892
I0721 09:52:56.676270 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 09:52:56.676306 146637 solver.cpp:252]     Train net output #1: loss = 1.1083 (* 1 = 1.1083 loss)
I0721 09:53:00.148629 146637 sgd_solver.cpp:106] Iteration 430, lr = 0.01
I0721 09:53:44.771498 146637 solver.cpp:236] Iteration 440, loss = 1.0699
I0721 09:53:44.771714 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:53:44.771749 146637 solver.cpp:252]     Train net output #1: loss = 1.01973 (* 1 = 1.01973 loss)
I0721 09:53:48.216554 146637 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0721 09:54:31.609745 146637 solver.cpp:236] Iteration 450, loss = 1.06319
I0721 09:54:31.609959 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 09:54:31.609994 146637 solver.cpp:252]     Train net output #1: loss = 0.996169 (* 1 = 0.996169 loss)
I0721 09:54:34.791398 146637 sgd_solver.cpp:106] Iteration 450, lr = 0.01
I0721 09:55:17.463871 146637 solver.cpp:236] Iteration 460, loss = 1.05238
I0721 09:55:17.464089 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 09:55:17.464115 146637 solver.cpp:252]     Train net output #1: loss = 0.990727 (* 1 = 0.990727 loss)
I0721 09:55:20.458816 146637 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0721 09:56:03.657871 146637 solver.cpp:236] Iteration 470, loss = 1.04841
I0721 09:56:03.658103 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:56:03.658123 146637 solver.cpp:252]     Train net output #1: loss = 1.03727 (* 1 = 1.03727 loss)
I0721 09:56:06.981731 146637 sgd_solver.cpp:106] Iteration 470, lr = 0.01
I0721 09:56:52.156884 146637 solver.cpp:236] Iteration 480, loss = 1.03942
I0721 09:56:52.157096 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 09:56:52.157127 146637 solver.cpp:252]     Train net output #1: loss = 0.96565 (* 1 = 0.96565 loss)
I0721 09:56:55.311800 146637 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0721 09:57:39.988811 146637 solver.cpp:236] Iteration 490, loss = 1.05408
I0721 09:57:39.988934 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:57:39.988966 146637 solver.cpp:252]     Train net output #1: loss = 1.08342 (* 1 = 1.08342 loss)
I0721 09:57:43.377617 146637 sgd_solver.cpp:106] Iteration 490, lr = 0.01
I0721 09:58:29.095690 146637 solver.cpp:236] Iteration 500, loss = 1.06491
I0721 09:58:29.095880 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 09:58:29.095901 146637 solver.cpp:252]     Train net output #1: loss = 1.06685 (* 1 = 1.06685 loss)
I0721 09:58:32.730532 146637 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0721 09:59:18.307240 146637 solver.cpp:236] Iteration 510, loss = 1.07589
I0721 09:59:18.307425 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 09:59:18.307473 146637 solver.cpp:252]     Train net output #1: loss = 1.07754 (* 1 = 1.07754 loss)
I0721 09:59:21.998541 146637 sgd_solver.cpp:106] Iteration 510, lr = 0.01
I0721 10:00:07.607913 146637 solver.cpp:236] Iteration 520, loss = 1.08053
I0721 10:00:07.608085 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:00:07.608120 146637 solver.cpp:252]     Train net output #1: loss = 1.06492 (* 1 = 1.06492 loss)
I0721 10:00:11.078608 146637 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0721 10:00:55.907312 146637 solver.cpp:236] Iteration 530, loss = 1.08314
I0721 10:00:55.907510 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:00:55.907542 146637 solver.cpp:252]     Train net output #1: loss = 0.944407 (* 1 = 0.944407 loss)
I0721 10:00:59.419093 146637 sgd_solver.cpp:106] Iteration 530, lr = 0.01
I0721 10:01:44.740824 146637 solver.cpp:236] Iteration 540, loss = 1.07666
I0721 10:01:44.741025 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:01:44.741057 146637 solver.cpp:252]     Train net output #1: loss = 1.11674 (* 1 = 1.11674 loss)
I0721 10:01:47.985795 146637 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0721 10:02:34.740531 146637 solver.cpp:236] Iteration 550, loss = 1.06664
I0721 10:02:34.740697 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:02:34.740746 146637 solver.cpp:252]     Train net output #1: loss = 1.07388 (* 1 = 1.07388 loss)
I0721 10:02:38.156093 146637 sgd_solver.cpp:106] Iteration 550, lr = 0.01
I0721 10:03:23.258905 146637 solver.cpp:236] Iteration 560, loss = 1.05748
I0721 10:03:23.259086 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:03:23.259131 146637 solver.cpp:252]     Train net output #1: loss = 0.968918 (* 1 = 0.968918 loss)
I0721 10:03:26.721899 146637 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0721 10:04:11.225462 146637 solver.cpp:236] Iteration 570, loss = 1.04597
I0721 10:04:11.225690 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:04:11.225718 146637 solver.cpp:252]     Train net output #1: loss = 0.969915 (* 1 = 0.969915 loss)
I0721 10:04:14.454309 146637 sgd_solver.cpp:106] Iteration 570, lr = 0.01
I0721 10:05:01.853070 146637 solver.cpp:236] Iteration 580, loss = 1.04489
I0721 10:05:01.853329 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:05:01.853353 146637 solver.cpp:252]     Train net output #1: loss = 1.12263 (* 1 = 1.12263 loss)
I0721 10:05:05.390992 146637 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0721 10:05:54.488936 146637 solver.cpp:236] Iteration 590, loss = 1.03931
I0721 10:05:54.489150 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:05:54.489173 146637 solver.cpp:252]     Train net output #1: loss = 1.03955 (* 1 = 1.03955 loss)
I0721 10:05:58.259759 146637 sgd_solver.cpp:106] Iteration 590, lr = 0.01
I0721 10:06:46.524099 146637 solver.cpp:236] Iteration 600, loss = 1.05138
I0721 10:06:46.524377 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 10:06:46.524411 146637 solver.cpp:252]     Train net output #1: loss = 1.19528 (* 1 = 1.19528 loss)
I0721 10:06:50.152153 146637 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0721 10:07:38.869921 146637 solver.cpp:236] Iteration 610, loss = 1.05763
I0721 10:07:38.870074 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 10:07:38.870095 146637 solver.cpp:252]     Train net output #1: loss = 1.18241 (* 1 = 1.18241 loss)
I0721 10:07:42.437134 146637 sgd_solver.cpp:106] Iteration 610, lr = 0.01
I0721 10:08:30.692662 146637 solver.cpp:236] Iteration 620, loss = 1.05696
I0721 10:08:30.692935 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:08:30.692965 146637 solver.cpp:252]     Train net output #1: loss = 0.975969 (* 1 = 0.975969 loss)
I0721 10:08:34.659147 146637 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0721 10:09:23.414808 146637 solver.cpp:236] Iteration 630, loss = 1.06543
I0721 10:09:23.414990 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:09:23.415037 146637 solver.cpp:252]     Train net output #1: loss = 1.05052 (* 1 = 1.05052 loss)
I0721 10:09:26.964740 146637 sgd_solver.cpp:106] Iteration 630, lr = 0.01
I0721 10:10:15.790181 146637 solver.cpp:236] Iteration 640, loss = 1.06277
I0721 10:10:15.790374 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:10:15.790426 146637 solver.cpp:252]     Train net output #1: loss = 0.975636 (* 1 = 0.975636 loss)
I0721 10:10:19.382537 146637 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0721 10:11:09.153179 146637 solver.cpp:236] Iteration 650, loss = 1.06161
I0721 10:11:09.153447 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:11:09.153470 146637 solver.cpp:252]     Train net output #1: loss = 1.09211 (* 1 = 1.09211 loss)
I0721 10:11:12.864123 146637 sgd_solver.cpp:106] Iteration 650, lr = 0.01
I0721 10:12:02.056258 146637 solver.cpp:236] Iteration 660, loss = 1.06342
I0721 10:12:02.056471 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:12:02.056493 146637 solver.cpp:252]     Train net output #1: loss = 1.04709 (* 1 = 1.04709 loss)
I0721 10:12:05.985971 146637 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0721 10:12:36.109033 146655 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 10:12:55.889082 146637 solver.cpp:236] Iteration 670, loss = 1.06602
I0721 10:12:55.889149 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:12:55.889178 146637 solver.cpp:252]     Train net output #1: loss = 1.04679 (* 1 = 1.04679 loss)
I0721 10:12:59.552088 146637 sgd_solver.cpp:106] Iteration 670, lr = 0.01
I0721 10:13:48.350363 146637 solver.cpp:236] Iteration 680, loss = 1.06157
I0721 10:13:48.350584 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:13:48.350615 146637 solver.cpp:252]     Train net output #1: loss = 1.04104 (* 1 = 1.04104 loss)
I0721 10:13:51.888460 146637 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0721 10:14:37.747066 146637 solver.cpp:236] Iteration 690, loss = 1.07156
I0721 10:14:37.747229 146637 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0721 10:14:37.747262 146637 solver.cpp:252]     Train net output #1: loss = 1.13087 (* 1 = 1.13087 loss)
I0721 10:14:41.102880 146637 sgd_solver.cpp:106] Iteration 690, lr = 0.01
I0721 10:15:27.047036 146637 solver.cpp:236] Iteration 700, loss = 1.06196
I0721 10:15:27.047206 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:15:27.047253 146637 solver.cpp:252]     Train net output #1: loss = 1.05553 (* 1 = 1.05553 loss)
I0721 10:15:30.594722 146637 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0721 10:16:16.509165 146637 solver.cpp:236] Iteration 710, loss = 1.06049
I0721 10:16:16.509415 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:16:16.509449 146637 solver.cpp:252]     Train net output #1: loss = 1.04847 (* 1 = 1.04847 loss)
I0721 10:16:19.931622 146637 sgd_solver.cpp:106] Iteration 710, lr = 0.01
I0721 10:17:05.905325 146637 solver.cpp:236] Iteration 720, loss = 1.06532
I0721 10:17:05.905539 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:17:05.905557 146637 solver.cpp:252]     Train net output #1: loss = 1.02422 (* 1 = 1.02422 loss)
I0721 10:17:09.328979 146637 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0721 10:17:55.968206 146637 solver.cpp:236] Iteration 730, loss = 1.06296
I0721 10:17:55.968431 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:17:55.968464 146637 solver.cpp:252]     Train net output #1: loss = 1.01343 (* 1 = 1.01343 loss)
I0721 10:17:59.396873 146637 sgd_solver.cpp:106] Iteration 730, lr = 0.01
I0721 10:18:45.526892 146637 solver.cpp:236] Iteration 740, loss = 1.05676
I0721 10:18:45.527083 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 10:18:45.527103 146637 solver.cpp:252]     Train net output #1: loss = 1.17165 (* 1 = 1.17165 loss)
I0721 10:18:48.832072 146637 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0721 10:19:34.292536 146637 solver.cpp:236] Iteration 750, loss = 1.06061
I0721 10:19:34.292862 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:19:34.292898 146637 solver.cpp:252]     Train net output #1: loss = 1.14614 (* 1 = 1.14614 loss)
I0721 10:19:37.660150 146637 sgd_solver.cpp:106] Iteration 750, lr = 0.01
I0721 10:20:26.103585 146637 solver.cpp:236] Iteration 760, loss = 1.05998
I0721 10:20:26.103775 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:20:26.103813 146637 solver.cpp:252]     Train net output #1: loss = 1.16568 (* 1 = 1.16568 loss)
I0721 10:20:29.584872 146637 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0721 10:21:15.581004 146637 solver.cpp:236] Iteration 770, loss = 1.05082
I0721 10:21:15.581204 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:21:15.581241 146637 solver.cpp:252]     Train net output #1: loss = 1.05578 (* 1 = 1.05578 loss)
I0721 10:21:19.068670 146637 sgd_solver.cpp:106] Iteration 770, lr = 0.01
I0721 10:22:05.135344 146637 solver.cpp:236] Iteration 780, loss = 1.05675
I0721 10:22:05.135498 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:22:05.135547 146637 solver.cpp:252]     Train net output #1: loss = 1.06112 (* 1 = 1.06112 loss)
I0721 10:22:08.591626 146637 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0721 10:22:54.605418 146637 solver.cpp:236] Iteration 790, loss = 1.0525
I0721 10:22:54.605662 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:22:54.605681 146637 solver.cpp:252]     Train net output #1: loss = 0.930949 (* 1 = 0.930949 loss)
I0721 10:22:57.987208 146637 sgd_solver.cpp:106] Iteration 790, lr = 0.01
I0721 10:23:44.489329 146637 solver.cpp:236] Iteration 800, loss = 1.0473
I0721 10:23:44.489509 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:23:44.489540 146637 solver.cpp:252]     Train net output #1: loss = 0.960828 (* 1 = 0.960828 loss)
I0721 10:23:47.911456 146637 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0721 10:24:34.049728 146637 solver.cpp:236] Iteration 810, loss = 1.04939
I0721 10:24:34.049937 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:24:34.049983 146637 solver.cpp:252]     Train net output #1: loss = 1.07122 (* 1 = 1.07122 loss)
I0721 10:24:37.540436 146637 sgd_solver.cpp:106] Iteration 810, lr = 0.01
I0721 10:25:24.008270 146637 solver.cpp:236] Iteration 820, loss = 1.05409
I0721 10:25:24.012817 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 10:25:24.012843 146637 solver.cpp:252]     Train net output #1: loss = 1.13154 (* 1 = 1.13154 loss)
I0721 10:25:27.676440 146637 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0721 10:26:13.603559 146637 solver.cpp:236] Iteration 830, loss = 1.04726
I0721 10:26:13.603744 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:26:13.603766 146637 solver.cpp:252]     Train net output #1: loss = 1.12033 (* 1 = 1.12033 loss)
I0721 10:26:17.020385 146637 sgd_solver.cpp:106] Iteration 830, lr = 0.01
I0721 10:27:03.344523 146637 solver.cpp:236] Iteration 840, loss = 1.04901
I0721 10:27:03.344712 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:27:03.344744 146637 solver.cpp:252]     Train net output #1: loss = 1.09052 (* 1 = 1.09052 loss)
I0721 10:27:06.761186 146637 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0721 10:27:52.736011 146637 solver.cpp:236] Iteration 850, loss = 1.06009
I0721 10:27:52.736222 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:27:52.736266 146637 solver.cpp:252]     Train net output #1: loss = 1.0087 (* 1 = 1.0087 loss)
I0721 10:27:56.140051 146637 sgd_solver.cpp:106] Iteration 850, lr = 0.01
I0721 10:28:41.926810 146637 solver.cpp:236] Iteration 860, loss = 1.05866
I0721 10:28:41.927011 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:28:41.927037 146637 solver.cpp:252]     Train net output #1: loss = 1.0513 (* 1 = 1.0513 loss)
I0721 10:28:45.210932 146637 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0721 10:29:32.019268 146637 solver.cpp:236] Iteration 870, loss = 1.06051
I0721 10:29:32.019486 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:29:32.019516 146637 solver.cpp:252]     Train net output #1: loss = 1.14824 (* 1 = 1.14824 loss)
I0721 10:29:35.415558 146637 sgd_solver.cpp:106] Iteration 870, lr = 0.01
I0721 10:30:22.392158 146637 solver.cpp:236] Iteration 880, loss = 1.06236
I0721 10:30:22.392360 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:30:22.392396 146637 solver.cpp:252]     Train net output #1: loss = 1.00882 (* 1 = 1.00882 loss)
I0721 10:30:25.832703 146637 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0721 10:31:12.206825 146637 solver.cpp:236] Iteration 890, loss = 1.06593
I0721 10:31:12.207072 146637 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0721 10:31:12.207099 146637 solver.cpp:252]     Train net output #1: loss = 1.14388 (* 1 = 1.14388 loss)
I0721 10:31:15.391149 146637 sgd_solver.cpp:106] Iteration 890, lr = 0.01
I0721 10:31:58.781054 146637 solver.cpp:236] Iteration 900, loss = 1.06139
I0721 10:31:58.781235 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:31:58.781271 146637 solver.cpp:252]     Train net output #1: loss = 0.995515 (* 1 = 0.995515 loss)
I0721 10:32:02.045117 146637 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0721 10:32:45.246142 146637 solver.cpp:236] Iteration 910, loss = 1.06422
I0721 10:32:45.246323 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:32:45.246353 146637 solver.cpp:252]     Train net output #1: loss = 1.08977 (* 1 = 1.08977 loss)
I0721 10:32:48.346709 146637 sgd_solver.cpp:106] Iteration 910, lr = 0.01
I0721 10:33:32.283985 146637 solver.cpp:236] Iteration 920, loss = 1.06468
I0721 10:33:32.284209 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:33:32.284230 146637 solver.cpp:252]     Train net output #1: loss = 1.12417 (* 1 = 1.12417 loss)
I0721 10:33:35.586207 146637 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0721 10:34:19.978119 146637 solver.cpp:236] Iteration 930, loss = 1.07057
I0721 10:34:19.978324 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:34:19.978355 146637 solver.cpp:252]     Train net output #1: loss = 1.11601 (* 1 = 1.11601 loss)
I0721 10:34:23.228932 146637 sgd_solver.cpp:106] Iteration 930, lr = 0.01
I0721 10:35:07.919438 146637 solver.cpp:236] Iteration 940, loss = 1.07054
I0721 10:35:07.919630 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:35:07.919656 146637 solver.cpp:252]     Train net output #1: loss = 1.02447 (* 1 = 1.02447 loss)
I0721 10:35:11.288064 146637 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0721 10:35:56.179982 146637 solver.cpp:236] Iteration 950, loss = 1.06799
I0721 10:35:56.180166 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:35:56.180209 146637 solver.cpp:252]     Train net output #1: loss = 0.984506 (* 1 = 0.984506 loss)
I0721 10:35:59.405503 146637 sgd_solver.cpp:106] Iteration 950, lr = 0.01
I0721 10:36:44.571964 146637 solver.cpp:236] Iteration 960, loss = 1.06089
I0721 10:36:44.572155 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:36:44.572177 146637 solver.cpp:252]     Train net output #1: loss = 0.966922 (* 1 = 0.966922 loss)
I0721 10:36:48.058867 146637 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0721 10:37:36.200588 146637 solver.cpp:236] Iteration 970, loss = 1.0592
I0721 10:37:36.200803 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:37:36.200853 146637 solver.cpp:252]     Train net output #1: loss = 1.17346 (* 1 = 1.17346 loss)
I0721 10:37:39.616060 146637 sgd_solver.cpp:106] Iteration 970, lr = 0.01
I0721 10:38:25.229164 146637 solver.cpp:236] Iteration 980, loss = 1.0581
I0721 10:38:25.229287 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:38:25.229321 146637 solver.cpp:252]     Train net output #1: loss = 0.987002 (* 1 = 0.987002 loss)
I0721 10:38:28.796581 146637 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0721 10:39:14.596782 146637 solver.cpp:236] Iteration 990, loss = 1.05229
I0721 10:39:14.597018 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:39:14.597038 146637 solver.cpp:252]     Train net output #1: loss = 0.975819 (* 1 = 0.975819 loss)
I0721 10:39:17.929426 146637 sgd_solver.cpp:106] Iteration 990, lr = 0.01
I0721 10:40:02.671906 146637 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_1000.caffemodel
I0721 10:40:02.712823 146637 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_1000.solverstate
I0721 10:40:02.727501 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 10:40:04.201700 146637 solver.cpp:236] Iteration 1000, loss = 1.0501
I0721 10:40:04.201776 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:40:04.201794 146637 solver.cpp:252]     Train net output #1: loss = 0.971688 (* 1 = 0.971688 loss)
I0721 10:40:07.617311 146637 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0721 10:40:52.504371 146637 solver.cpp:236] Iteration 1010, loss = 1.04826
I0721 10:40:52.504546 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:40:52.504585 146637 solver.cpp:252]     Train net output #1: loss = 1.04428 (* 1 = 1.04428 loss)
I0721 10:40:55.905591 146637 sgd_solver.cpp:106] Iteration 1010, lr = 0.01
I0721 10:41:41.566004 146637 solver.cpp:236] Iteration 1020, loss = 1.04549
I0721 10:41:41.566170 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:41:41.566205 146637 solver.cpp:252]     Train net output #1: loss = 0.972989 (* 1 = 0.972989 loss)
I0721 10:41:45.008631 146637 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0721 10:42:30.685664 146637 solver.cpp:236] Iteration 1030, loss = 1.04827
I0721 10:42:30.685845 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:42:30.685866 146637 solver.cpp:252]     Train net output #1: loss = 1.11698 (* 1 = 1.11698 loss)
I0721 10:42:34.078330 146637 sgd_solver.cpp:106] Iteration 1030, lr = 0.01
I0721 10:43:19.846202 146637 solver.cpp:236] Iteration 1040, loss = 1.04904
I0721 10:43:19.846379 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:43:19.846412 146637 solver.cpp:252]     Train net output #1: loss = 1.09733 (* 1 = 1.09733 loss)
I0721 10:43:23.316054 146637 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0721 10:44:08.990231 146637 solver.cpp:236] Iteration 1050, loss = 1.04395
I0721 10:44:08.990419 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:44:08.990473 146637 solver.cpp:252]     Train net output #1: loss = 0.969623 (* 1 = 0.969623 loss)
I0721 10:44:12.490546 146637 sgd_solver.cpp:106] Iteration 1050, lr = 0.01
I0721 10:44:58.495409 146637 solver.cpp:236] Iteration 1060, loss = 1.04156
I0721 10:44:58.495607 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:44:58.495642 146637 solver.cpp:252]     Train net output #1: loss = 0.999062 (* 1 = 0.999062 loss)
I0721 10:45:01.938948 146637 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0721 10:45:48.223903 146637 solver.cpp:236] Iteration 1070, loss = 1.04627
I0721 10:45:48.224105 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:45:48.224138 146637 solver.cpp:252]     Train net output #1: loss = 1.00962 (* 1 = 1.00962 loss)
I0721 10:45:51.534142 146637 sgd_solver.cpp:106] Iteration 1070, lr = 0.01
I0721 10:46:37.425951 146637 solver.cpp:236] Iteration 1080, loss = 1.03632
I0721 10:46:37.426136 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:46:37.426157 146637 solver.cpp:252]     Train net output #1: loss = 1.13689 (* 1 = 1.13689 loss)
I0721 10:46:41.043856 146637 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0721 10:47:26.460486 146637 solver.cpp:236] Iteration 1090, loss = 1.03037
I0721 10:47:26.460626 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:47:26.460671 146637 solver.cpp:252]     Train net output #1: loss = 0.99354 (* 1 = 0.99354 loss)
I0721 10:47:29.840448 146637 sgd_solver.cpp:106] Iteration 1090, lr = 0.01
I0721 10:48:16.109431 146637 solver.cpp:236] Iteration 1100, loss = 1.03381
I0721 10:48:16.109608 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:48:16.109649 146637 solver.cpp:252]     Train net output #1: loss = 1.01159 (* 1 = 1.01159 loss)
I0721 10:48:19.659901 146637 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0721 10:49:05.668634 146637 solver.cpp:236] Iteration 1110, loss = 1.04167
I0721 10:49:05.668828 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:49:05.668872 146637 solver.cpp:252]     Train net output #1: loss = 1.09789 (* 1 = 1.09789 loss)
I0721 10:49:09.567256 146637 sgd_solver.cpp:106] Iteration 1110, lr = 0.01
I0721 10:49:55.069703 146637 solver.cpp:236] Iteration 1120, loss = 1.04539
I0721 10:49:55.069941 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:49:55.069973 146637 solver.cpp:252]     Train net output #1: loss = 1.08686 (* 1 = 1.08686 loss)
I0721 10:49:58.277595 146637 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0721 10:50:44.339603 146637 solver.cpp:236] Iteration 1130, loss = 1.04902
I0721 10:50:44.339794 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:50:44.339840 146637 solver.cpp:252]     Train net output #1: loss = 1.04405 (* 1 = 1.04405 loss)
I0721 10:50:47.876019 146637 sgd_solver.cpp:106] Iteration 1130, lr = 0.01
I0721 10:51:34.167534 146637 solver.cpp:236] Iteration 1140, loss = 1.06034
I0721 10:51:34.167717 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 10:51:34.167762 146637 solver.cpp:252]     Train net output #1: loss = 1.03118 (* 1 = 1.03118 loss)
I0721 10:51:37.654578 146637 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0721 10:52:24.053323 146637 solver.cpp:236] Iteration 1150, loss = 1.0677
I0721 10:52:24.053573 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:52:24.053599 146637 solver.cpp:252]     Train net output #1: loss = 0.984399 (* 1 = 0.984399 loss)
I0721 10:52:27.602068 146637 sgd_solver.cpp:106] Iteration 1150, lr = 0.01
I0721 10:53:13.526558 146637 solver.cpp:236] Iteration 1160, loss = 1.06565
I0721 10:53:13.526732 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:53:13.526764 146637 solver.cpp:252]     Train net output #1: loss = 1.1155 (* 1 = 1.1155 loss)
I0721 10:53:16.881189 146637 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0721 10:54:03.096316 146637 solver.cpp:236] Iteration 1170, loss = 1.05824
I0721 10:54:03.096492 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 10:54:03.096541 146637 solver.cpp:252]     Train net output #1: loss = 1.1018 (* 1 = 1.1018 loss)
I0721 10:54:06.714860 146637 sgd_solver.cpp:106] Iteration 1170, lr = 0.01
I0721 10:54:53.296092 146637 solver.cpp:236] Iteration 1180, loss = 1.05311
I0721 10:54:53.296291 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 10:54:53.296324 146637 solver.cpp:252]     Train net output #1: loss = 0.882589 (* 1 = 0.882589 loss)
I0721 10:54:57.087373 146637 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0721 10:55:44.657624 146637 solver.cpp:236] Iteration 1190, loss = 1.04406
I0721 10:55:44.657807 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:55:44.657855 146637 solver.cpp:252]     Train net output #1: loss = 1.06754 (* 1 = 1.06754 loss)
I0721 10:55:47.955878 146637 sgd_solver.cpp:106] Iteration 1190, lr = 0.01
I0721 10:56:34.910707 146637 solver.cpp:236] Iteration 1200, loss = 1.02936
I0721 10:56:34.910913 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 10:56:34.910946 146637 solver.cpp:252]     Train net output #1: loss = 0.998759 (* 1 = 0.998759 loss)
I0721 10:56:38.268532 146637 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0721 10:57:24.059656 146637 solver.cpp:236] Iteration 1210, loss = 1.03298
I0721 10:57:24.059902 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 10:57:24.059936 146637 solver.cpp:252]     Train net output #1: loss = 1.10867 (* 1 = 1.10867 loss)
I0721 10:57:27.422132 146637 sgd_solver.cpp:106] Iteration 1210, lr = 0.01
I0721 10:58:12.996397 146637 solver.cpp:236] Iteration 1220, loss = 1.03867
I0721 10:58:12.996553 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 10:58:12.996600 146637 solver.cpp:252]     Train net output #1: loss = 1.08998 (* 1 = 1.08998 loss)
I0721 10:58:16.333127 146637 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0721 10:59:01.835572 146637 solver.cpp:236] Iteration 1230, loss = 1.03285
I0721 10:59:01.835865 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 10:59:01.835911 146637 solver.cpp:252]     Train net output #1: loss = 0.943877 (* 1 = 0.943877 loss)
I0721 10:59:05.239094 146637 sgd_solver.cpp:106] Iteration 1230, lr = 0.01
I0721 10:59:51.015766 146637 solver.cpp:236] Iteration 1240, loss = 1.03684
I0721 10:59:51.015954 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 10:59:51.016002 146637 solver.cpp:252]     Train net output #1: loss = 1.01694 (* 1 = 1.01694 loss)
I0721 10:59:54.530027 146637 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0721 11:00:39.942777 146637 solver.cpp:236] Iteration 1250, loss = 1.04381
I0721 11:00:39.943045 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:00:39.943080 146637 solver.cpp:252]     Train net output #1: loss = 0.998374 (* 1 = 0.998374 loss)
I0721 11:00:43.329439 146637 sgd_solver.cpp:106] Iteration 1250, lr = 0.01
I0721 11:01:29.425393 146637 solver.cpp:236] Iteration 1260, loss = 1.03758
I0721 11:01:29.425581 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:01:29.425631 146637 solver.cpp:252]     Train net output #1: loss = 0.956354 (* 1 = 0.956354 loss)
I0721 11:01:33.001974 146637 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0721 11:02:18.782588 146637 solver.cpp:236] Iteration 1270, loss = 1.0335
I0721 11:02:18.782840 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:02:18.782860 146637 solver.cpp:252]     Train net output #1: loss = 0.970186 (* 1 = 0.970186 loss)
I0721 11:02:22.212947 146637 sgd_solver.cpp:106] Iteration 1270, lr = 0.01
I0721 11:03:07.940125 146637 solver.cpp:236] Iteration 1280, loss = 1.03724
I0721 11:03:07.940304 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 11:03:07.940362 146637 solver.cpp:252]     Train net output #1: loss = 1.02146 (* 1 = 1.02146 loss)
I0721 11:03:11.417503 146637 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0721 11:03:57.036628 146637 solver.cpp:236] Iteration 1290, loss = 1.04054
I0721 11:03:57.036770 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:03:57.036803 146637 solver.cpp:252]     Train net output #1: loss = 1.05827 (* 1 = 1.05827 loss)
I0721 11:04:00.384443 146637 sgd_solver.cpp:106] Iteration 1290, lr = 0.01
I0721 11:04:46.662329 146637 solver.cpp:236] Iteration 1300, loss = 1.04029
I0721 11:04:46.662541 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:04:46.662582 146637 solver.cpp:252]     Train net output #1: loss = 1.04473 (* 1 = 1.04473 loss)
I0721 11:04:50.077920 146637 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0721 11:05:35.749966 146637 solver.cpp:236] Iteration 1310, loss = 1.04541
I0721 11:05:35.750160 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:05:35.750182 146637 solver.cpp:252]     Train net output #1: loss = 1.00116 (* 1 = 1.00116 loss)
I0721 11:05:39.123756 146637 sgd_solver.cpp:106] Iteration 1310, lr = 0.01
I0721 11:06:26.132380 146637 solver.cpp:236] Iteration 1320, loss = 1.04353
I0721 11:06:26.132573 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:06:26.132617 146637 solver.cpp:252]     Train net output #1: loss = 0.919047 (* 1 = 0.919047 loss)
I0721 11:06:29.712110 146637 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0721 11:07:15.886795 146637 solver.cpp:236] Iteration 1330, loss = 1.03834
I0721 11:07:15.887042 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:07:15.887063 146637 solver.cpp:252]     Train net output #1: loss = 1.01302 (* 1 = 1.01302 loss)
I0721 11:07:19.325449 146637 sgd_solver.cpp:106] Iteration 1330, lr = 0.01
I0721 11:07:30.679114 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 11:08:04.645301 146637 solver.cpp:236] Iteration 1340, loss = 1.03686
I0721 11:08:04.645498 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:08:04.645519 146637 solver.cpp:252]     Train net output #1: loss = 1.08848 (* 1 = 1.08848 loss)
I0721 11:08:07.909442 146637 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0721 11:08:51.037086 146637 solver.cpp:236] Iteration 1350, loss = 1.03117
I0721 11:08:51.037329 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:08:51.037351 146637 solver.cpp:252]     Train net output #1: loss = 1.041 (* 1 = 1.041 loss)
I0721 11:08:54.188308 146637 sgd_solver.cpp:106] Iteration 1350, lr = 0.01
I0721 11:09:37.834949 146637 solver.cpp:236] Iteration 1360, loss = 1.02552
I0721 11:09:37.835204 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:09:37.835239 146637 solver.cpp:252]     Train net output #1: loss = 1.1386 (* 1 = 1.1386 loss)
I0721 11:09:41.072543 146637 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0721 11:10:25.989308 146637 solver.cpp:236] Iteration 1370, loss = 1.02691
I0721 11:10:25.989444 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:10:25.989477 146637 solver.cpp:252]     Train net output #1: loss = 1.09351 (* 1 = 1.09351 loss)
I0721 11:10:29.363900 146637 sgd_solver.cpp:106] Iteration 1370, lr = 0.01
I0721 11:11:14.379027 146637 solver.cpp:236] Iteration 1380, loss = 1.04365
I0721 11:11:14.379256 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:11:14.379299 146637 solver.cpp:252]     Train net output #1: loss = 1.02577 (* 1 = 1.02577 loss)
I0721 11:11:17.553198 146637 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0721 11:12:02.884456 146637 solver.cpp:236] Iteration 1390, loss = 1.04206
I0721 11:12:02.884650 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:12:02.884676 146637 solver.cpp:252]     Train net output #1: loss = 1.08054 (* 1 = 1.08054 loss)
I0721 11:12:06.194982 146637 sgd_solver.cpp:106] Iteration 1390, lr = 0.01
I0721 11:12:52.845474 146637 solver.cpp:236] Iteration 1400, loss = 1.05158
I0721 11:12:52.845635 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:12:52.845667 146637 solver.cpp:252]     Train net output #1: loss = 1.15721 (* 1 = 1.15721 loss)
I0721 11:12:56.175789 146637 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0721 11:13:40.227077 146637 solver.cpp:236] Iteration 1410, loss = 1.05506
I0721 11:13:40.227306 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:13:40.227340 146637 solver.cpp:252]     Train net output #1: loss = 0.999958 (* 1 = 0.999958 loss)
I0721 11:13:43.485626 146637 sgd_solver.cpp:106] Iteration 1410, lr = 0.01
I0721 11:14:28.426473 146637 solver.cpp:236] Iteration 1420, loss = 1.06823
I0721 11:14:28.426635 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:14:28.426681 146637 solver.cpp:252]     Train net output #1: loss = 1.11851 (* 1 = 1.11851 loss)
I0721 11:14:31.855731 146637 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0721 11:15:17.215353 146637 solver.cpp:236] Iteration 1430, loss = 1.0591
I0721 11:15:17.215608 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:15:17.215631 146637 solver.cpp:252]     Train net output #1: loss = 1.05918 (* 1 = 1.05918 loss)
I0721 11:15:20.750022 146637 sgd_solver.cpp:106] Iteration 1430, lr = 0.01
I0721 11:16:05.560479 146637 solver.cpp:236] Iteration 1440, loss = 1.05617
I0721 11:16:05.560664 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:16:05.560700 146637 solver.cpp:252]     Train net output #1: loss = 1.0814 (* 1 = 1.0814 loss)
I0721 11:16:08.796525 146637 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0721 11:16:54.448163 146637 solver.cpp:236] Iteration 1450, loss = 1.05181
I0721 11:16:54.448367 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:16:54.448390 146637 solver.cpp:252]     Train net output #1: loss = 0.941811 (* 1 = 0.941811 loss)
I0721 11:16:57.822279 146637 sgd_solver.cpp:106] Iteration 1450, lr = 0.01
I0721 11:17:42.186228 146637 solver.cpp:236] Iteration 1460, loss = 1.04928
I0721 11:17:42.186429 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:17:42.186468 146637 solver.cpp:252]     Train net output #1: loss = 1.04451 (* 1 = 1.04451 loss)
I0721 11:17:45.505954 146637 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0721 11:18:29.492786 146637 solver.cpp:236] Iteration 1470, loss = 1.04132
I0721 11:18:29.492977 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:18:29.493024 146637 solver.cpp:252]     Train net output #1: loss = 1.18474 (* 1 = 1.18474 loss)
I0721 11:18:32.991262 146637 sgd_solver.cpp:106] Iteration 1470, lr = 0.01
I0721 11:19:17.430934 146637 solver.cpp:236] Iteration 1480, loss = 1.04171
I0721 11:19:17.431133 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:19:17.431167 146637 solver.cpp:252]     Train net output #1: loss = 1.06421 (* 1 = 1.06421 loss)
I0721 11:19:20.721377 146637 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0721 11:20:06.218045 146637 solver.cpp:236] Iteration 1490, loss = 1.04583
I0721 11:20:06.218219 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 11:20:06.218250 146637 solver.cpp:252]     Train net output #1: loss = 0.989156 (* 1 = 0.989156 loss)
I0721 11:20:09.748132 146637 sgd_solver.cpp:106] Iteration 1490, lr = 0.01
I0721 11:20:53.477210 146637 solver.cpp:340] Iteration 1500, Testing net (#0)
I0721 11:26:57.852800 146637 solver.cpp:408]     Test net output #0: accuracy = 0.487
I0721 11:26:57.853021 146637 solver.cpp:408]     Test net output #1: loss = 1.03623 (* 1 = 1.03623 loss)
I0721 11:26:58.125460 146637 solver.cpp:236] Iteration 1500, loss = 1.04779
I0721 11:26:58.125531 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:26:58.125553 146637 solver.cpp:252]     Train net output #1: loss = 1.12723 (* 1 = 1.12723 loss)
I0721 11:26:58.970309 146637 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0721 11:27:03.151060 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 11:27:44.296830 146637 solver.cpp:236] Iteration 1510, loss = 1.05316
I0721 11:27:44.297044 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:27:44.297081 146637 solver.cpp:252]     Train net output #1: loss = 1.16784 (* 1 = 1.16784 loss)
I0721 11:27:47.679657 146637 sgd_solver.cpp:106] Iteration 1510, lr = 0.01
I0721 11:28:34.083129 146637 solver.cpp:236] Iteration 1520, loss = 1.04706
I0721 11:28:34.083335 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 11:28:34.083359 146637 solver.cpp:252]     Train net output #1: loss = 0.862573 (* 1 = 0.862573 loss)
I0721 11:28:37.559919 146637 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0721 11:29:24.402081 146637 solver.cpp:236] Iteration 1530, loss = 1.04437
I0721 11:29:24.402278 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:29:24.402309 146637 solver.cpp:252]     Train net output #1: loss = 1.02848 (* 1 = 1.02848 loss)
I0721 11:29:28.290809 146637 sgd_solver.cpp:106] Iteration 1530, lr = 0.01
I0721 11:30:17.049079 146637 solver.cpp:236] Iteration 1540, loss = 1.03953
I0721 11:30:17.049252 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 11:30:17.049284 146637 solver.cpp:252]     Train net output #1: loss = 0.876697 (* 1 = 0.876697 loss)
I0721 11:30:20.511922 146637 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0721 11:31:07.793743 146637 solver.cpp:236] Iteration 1550, loss = 1.03246
I0721 11:31:07.793946 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:31:07.793982 146637 solver.cpp:252]     Train net output #1: loss = 1.10935 (* 1 = 1.10935 loss)
I0721 11:31:11.275836 146637 sgd_solver.cpp:106] Iteration 1550, lr = 0.01
I0721 11:31:58.126874 146637 solver.cpp:236] Iteration 1560, loss = 1.0202
I0721 11:31:58.127106 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:31:58.127146 146637 solver.cpp:252]     Train net output #1: loss = 1.12357 (* 1 = 1.12357 loss)
I0721 11:32:01.431284 146637 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0721 11:32:49.010495 146637 solver.cpp:236] Iteration 1570, loss = 1.02134
I0721 11:32:49.010725 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:32:49.010746 146637 solver.cpp:252]     Train net output #1: loss = 1.03812 (* 1 = 1.03812 loss)
I0721 11:32:52.535696 146637 sgd_solver.cpp:106] Iteration 1570, lr = 0.01
I0721 11:33:40.125330 146637 solver.cpp:236] Iteration 1580, loss = 1.02354
I0721 11:33:40.125535 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 11:33:40.125579 146637 solver.cpp:252]     Train net output #1: loss = 0.962766 (* 1 = 0.962766 loss)
I0721 11:33:43.612637 146637 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0721 11:34:30.327849 146637 solver.cpp:236] Iteration 1590, loss = 1.02349
I0721 11:34:30.328063 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:34:30.328083 146637 solver.cpp:252]     Train net output #1: loss = 0.940023 (* 1 = 0.940023 loss)
I0721 11:34:33.674226 146637 sgd_solver.cpp:106] Iteration 1590, lr = 0.01
I0721 11:35:21.123625 146637 solver.cpp:236] Iteration 1600, loss = 1.02855
I0721 11:35:21.123787 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:35:21.123836 146637 solver.cpp:252]     Train net output #1: loss = 1.039 (* 1 = 1.039 loss)
I0721 11:35:24.527451 146637 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0721 11:36:11.960330 146637 solver.cpp:236] Iteration 1610, loss = 1.04504
I0721 11:36:11.960525 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:36:11.960547 146637 solver.cpp:252]     Train net output #1: loss = 1.15891 (* 1 = 1.15891 loss)
I0721 11:36:15.557010 146637 sgd_solver.cpp:106] Iteration 1610, lr = 0.01
I0721 11:37:02.781496 146637 solver.cpp:236] Iteration 1620, loss = 1.05554
I0721 11:37:02.781700 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 11:37:02.781725 146637 solver.cpp:252]     Train net output #1: loss = 1.1529 (* 1 = 1.1529 loss)
I0721 11:37:06.272047 146637 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0721 11:37:54.004288 146637 solver.cpp:236] Iteration 1630, loss = 1.05311
I0721 11:37:54.004454 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:37:54.004503 146637 solver.cpp:252]     Train net output #1: loss = 1.04851 (* 1 = 1.04851 loss)
I0721 11:37:57.492028 146637 sgd_solver.cpp:106] Iteration 1630, lr = 0.01
I0721 11:38:44.267251 146637 solver.cpp:236] Iteration 1640, loss = 1.04401
I0721 11:38:44.267474 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:38:44.267513 146637 solver.cpp:252]     Train net output #1: loss = 0.925609 (* 1 = 0.925609 loss)
I0721 11:38:47.635362 146637 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0721 11:39:34.875607 146637 solver.cpp:236] Iteration 1650, loss = 1.052
I0721 11:39:34.875777 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:39:34.875821 146637 solver.cpp:252]     Train net output #1: loss = 1.0317 (* 1 = 1.0317 loss)
I0721 11:39:38.437685 146637 sgd_solver.cpp:106] Iteration 1650, lr = 0.01
I0721 11:40:27.091295 146637 solver.cpp:236] Iteration 1660, loss = 1.04771
I0721 11:40:27.091475 146637 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0721 11:40:27.091497 146637 solver.cpp:252]     Train net output #1: loss = 1.18821 (* 1 = 1.18821 loss)
I0721 11:40:30.979189 146637 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0721 11:41:23.788074 146637 solver.cpp:236] Iteration 1670, loss = 1.02819
I0721 11:41:23.788316 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 11:41:23.788342 146637 solver.cpp:252]     Train net output #1: loss = 0.836302 (* 1 = 0.836302 loss)
I0721 11:41:27.441932 146637 sgd_solver.cpp:106] Iteration 1670, lr = 0.01
I0721 11:42:19.900221 146637 solver.cpp:236] Iteration 1680, loss = 1.02956
I0721 11:42:19.900463 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:42:19.900490 146637 solver.cpp:252]     Train net output #1: loss = 0.970796 (* 1 = 0.970796 loss)
I0721 11:42:23.576164 146637 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0721 11:43:16.567706 146637 solver.cpp:236] Iteration 1690, loss = 1.04133
I0721 11:43:16.567889 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:43:16.567911 146637 solver.cpp:252]     Train net output #1: loss = 1.03484 (* 1 = 1.03484 loss)
I0721 11:43:20.578428 146637 sgd_solver.cpp:106] Iteration 1690, lr = 0.01
I0721 11:44:13.940951 146637 solver.cpp:236] Iteration 1700, loss = 1.03799
I0721 11:44:13.941190 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:44:13.941229 146637 solver.cpp:252]     Train net output #1: loss = 1.06226 (* 1 = 1.06226 loss)
I0721 11:44:18.161628 146637 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0721 11:45:11.677165 146637 solver.cpp:236] Iteration 1710, loss = 1.02825
I0721 11:45:11.677481 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:45:11.677516 146637 solver.cpp:252]     Train net output #1: loss = 1.01831 (* 1 = 1.01831 loss)
I0721 11:45:15.808017 146637 sgd_solver.cpp:106] Iteration 1710, lr = 0.01
I0721 11:46:10.260046 146637 solver.cpp:236] Iteration 1720, loss = 1.03207
I0721 11:46:10.260213 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:46:10.260248 146637 solver.cpp:252]     Train net output #1: loss = 1.02667 (* 1 = 1.02667 loss)
I0721 11:46:14.198148 146637 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0721 11:47:06.651778 146637 solver.cpp:236] Iteration 1730, loss = 1.03026
I0721 11:47:06.651995 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:47:06.652030 146637 solver.cpp:252]     Train net output #1: loss = 1.17309 (* 1 = 1.17309 loss)
I0721 11:47:10.771111 146637 sgd_solver.cpp:106] Iteration 1730, lr = 0.01
I0721 11:48:03.230466 146637 solver.cpp:236] Iteration 1740, loss = 1.03324
I0721 11:48:03.230666 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:48:03.230695 146637 solver.cpp:252]     Train net output #1: loss = 0.95135 (* 1 = 0.95135 loss)
I0721 11:48:07.420545 146637 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0721 11:48:59.890135 146637 solver.cpp:236] Iteration 1750, loss = 1.02759
I0721 11:48:59.890347 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:48:59.890380 146637 solver.cpp:252]     Train net output #1: loss = 1.0448 (* 1 = 1.0448 loss)
I0721 11:49:03.807565 146637 sgd_solver.cpp:106] Iteration 1750, lr = 0.01
I0721 11:49:59.301740 146637 solver.cpp:236] Iteration 1760, loss = 1.03463
I0721 11:49:59.310678 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 11:49:59.310704 146637 solver.cpp:252]     Train net output #1: loss = 1.00988 (* 1 = 1.00988 loss)
I0721 11:50:02.991617 146637 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0721 11:50:55.921236 146637 solver.cpp:236] Iteration 1770, loss = 1.03246
I0721 11:50:55.921406 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 11:50:55.921439 146637 solver.cpp:252]     Train net output #1: loss = 1.12496 (* 1 = 1.12496 loss)
I0721 11:50:59.697234 146637 sgd_solver.cpp:106] Iteration 1770, lr = 0.01
I0721 11:51:51.654827 146637 solver.cpp:236] Iteration 1780, loss = 1.04672
I0721 11:51:51.655057 146637 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0721 11:51:51.655093 146637 solver.cpp:252]     Train net output #1: loss = 1.24742 (* 1 = 1.24742 loss)
I0721 11:51:55.503772 146637 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0721 11:52:46.932765 146637 solver.cpp:236] Iteration 1790, loss = 1.05269
I0721 11:52:46.932998 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:52:46.933022 146637 solver.cpp:252]     Train net output #1: loss = 1.13528 (* 1 = 1.13528 loss)
I0721 11:52:51.100846 146637 sgd_solver.cpp:106] Iteration 1790, lr = 0.01
I0721 11:53:42.498808 146637 solver.cpp:236] Iteration 1800, loss = 1.04918
I0721 11:53:42.499030 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 11:53:42.499065 146637 solver.cpp:252]     Train net output #1: loss = 0.818272 (* 1 = 0.818272 loss)
I0721 11:53:46.166613 146637 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0721 11:54:42.354995 146637 solver.cpp:236] Iteration 1810, loss = 1.0502
I0721 11:54:42.355155 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:54:42.355192 146637 solver.cpp:252]     Train net output #1: loss = 0.948401 (* 1 = 0.948401 loss)
I0721 11:54:46.413527 146637 sgd_solver.cpp:106] Iteration 1810, lr = 0.01
I0721 11:55:39.593149 146637 solver.cpp:236] Iteration 1820, loss = 1.05764
I0721 11:55:39.593324 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 11:55:39.593371 146637 solver.cpp:252]     Train net output #1: loss = 1.06575 (* 1 = 1.06575 loss)
I0721 11:55:43.714114 146637 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0721 11:56:37.234815 146637 solver.cpp:236] Iteration 1830, loss = 1.03619
I0721 11:56:37.235031 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:56:37.235057 146637 solver.cpp:252]     Train net output #1: loss = 1.09182 (* 1 = 1.09182 loss)
I0721 11:56:41.105201 146637 sgd_solver.cpp:106] Iteration 1830, lr = 0.01
I0721 11:57:05.708706 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 11:57:35.871906 146637 solver.cpp:236] Iteration 1840, loss = 1.02538
I0721 11:57:35.872174 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:57:35.872206 146637 solver.cpp:252]     Train net output #1: loss = 0.938471 (* 1 = 0.938471 loss)
I0721 11:57:39.886651 146637 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0721 11:58:33.625967 146637 solver.cpp:236] Iteration 1850, loss = 1.02216
I0721 11:58:33.626197 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 11:58:33.626222 146637 solver.cpp:252]     Train net output #1: loss = 1.00915 (* 1 = 1.00915 loss)
I0721 11:58:37.585677 146637 sgd_solver.cpp:106] Iteration 1850, lr = 0.01
I0721 11:59:32.209890 146637 solver.cpp:236] Iteration 1860, loss = 1.01742
I0721 11:59:32.210033 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 11:59:32.210081 146637 solver.cpp:252]     Train net output #1: loss = 1.12283 (* 1 = 1.12283 loss)
I0721 11:59:36.035074 146637 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0721 12:00:30.387433 146637 solver.cpp:236] Iteration 1870, loss = 1.01007
I0721 12:00:30.387611 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:00:30.387645 146637 solver.cpp:252]     Train net output #1: loss = 1.02461 (* 1 = 1.02461 loss)
I0721 12:00:34.379256 146637 sgd_solver.cpp:106] Iteration 1870, lr = 0.01
I0721 12:01:27.717063 146637 solver.cpp:236] Iteration 1880, loss = 1.02284
I0721 12:01:27.717195 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:01:27.717223 146637 solver.cpp:252]     Train net output #1: loss = 1.08676 (* 1 = 1.08676 loss)
I0721 12:01:31.952921 146637 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0721 12:02:25.256556 146637 solver.cpp:236] Iteration 1890, loss = 1.02953
I0721 12:02:25.256738 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:02:25.256772 146637 solver.cpp:252]     Train net output #1: loss = 1.03963 (* 1 = 1.03963 loss)
I0721 12:02:29.037019 146637 sgd_solver.cpp:106] Iteration 1890, lr = 0.01
I0721 12:03:23.238221 146637 solver.cpp:236] Iteration 1900, loss = 1.02408
I0721 12:03:23.238396 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:03:23.238435 146637 solver.cpp:252]     Train net output #1: loss = 0.899325 (* 1 = 0.899325 loss)
I0721 12:03:26.855348 146637 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0721 12:04:16.087540 146637 solver.cpp:236] Iteration 1910, loss = 1.02277
I0721 12:04:16.087764 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 12:04:16.087802 146637 solver.cpp:252]     Train net output #1: loss = 1.20304 (* 1 = 1.20304 loss)
I0721 12:04:19.654119 146637 sgd_solver.cpp:106] Iteration 1910, lr = 0.01
I0721 12:05:07.470722 146637 solver.cpp:236] Iteration 1920, loss = 1.01828
I0721 12:05:07.470929 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:05:07.470966 146637 solver.cpp:252]     Train net output #1: loss = 1.13299 (* 1 = 1.13299 loss)
I0721 12:05:11.226670 146637 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0721 12:05:59.392994 146637 solver.cpp:236] Iteration 1930, loss = 1.01159
I0721 12:05:59.393182 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:05:59.393232 146637 solver.cpp:252]     Train net output #1: loss = 1.03029 (* 1 = 1.03029 loss)
I0721 12:06:02.991056 146637 sgd_solver.cpp:106] Iteration 1930, lr = 0.01
I0721 12:06:51.168051 146637 solver.cpp:236] Iteration 1940, loss = 0.996403
I0721 12:06:51.168229 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 12:06:51.168282 146637 solver.cpp:252]     Train net output #1: loss = 1.05473 (* 1 = 1.05473 loss)
I0721 12:06:54.671377 146637 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0721 12:07:43.510512 146637 solver.cpp:236] Iteration 1950, loss = 1.01672
I0721 12:07:43.510687 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:07:43.510726 146637 solver.cpp:252]     Train net output #1: loss = 1.02847 (* 1 = 1.02847 loss)
I0721 12:07:46.914852 146637 sgd_solver.cpp:106] Iteration 1950, lr = 0.01
I0721 12:08:33.373703 146637 solver.cpp:236] Iteration 1960, loss = 1.0242
I0721 12:08:33.373883 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:08:33.373919 146637 solver.cpp:252]     Train net output #1: loss = 1.0911 (* 1 = 1.0911 loss)
I0721 12:08:36.892647 146637 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0721 12:09:23.392071 146637 solver.cpp:236] Iteration 1970, loss = 1.02842
I0721 12:09:23.392244 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 12:09:23.392294 146637 solver.cpp:252]     Train net output #1: loss = 0.980329 (* 1 = 0.980329 loss)
I0721 12:09:26.840272 146637 sgd_solver.cpp:106] Iteration 1970, lr = 0.01
I0721 12:10:14.705852 146637 solver.cpp:236] Iteration 1980, loss = 1.03486
I0721 12:10:14.705994 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:10:14.706017 146637 solver.cpp:252]     Train net output #1: loss = 0.994101 (* 1 = 0.994101 loss)
I0721 12:10:18.226837 146637 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0721 12:11:04.373047 146637 solver.cpp:236] Iteration 1990, loss = 1.04364
I0721 12:11:04.373165 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 12:11:04.373188 146637 solver.cpp:252]     Train net output #1: loss = 1.1111 (* 1 = 1.1111 loss)
I0721 12:11:07.707654 146637 sgd_solver.cpp:106] Iteration 1990, lr = 0.01
I0721 12:11:52.107619 146637 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_2000.caffemodel
I0721 12:11:52.127537 146637 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_2000.solverstate
I0721 12:11:53.535881 146637 solver.cpp:236] Iteration 2000, loss = 1.03423
I0721 12:11:53.535940 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:11:53.535958 146637 solver.cpp:252]     Train net output #1: loss = 0.979169 (* 1 = 0.979169 loss)
I0721 12:11:56.908524 146637 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0721 12:12:42.634135 146637 solver.cpp:236] Iteration 2010, loss = 1.02627
I0721 12:12:42.634308 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:12:42.634353 146637 solver.cpp:252]     Train net output #1: loss = 0.934159 (* 1 = 0.934159 loss)
I0721 12:12:46.071141 146637 sgd_solver.cpp:106] Iteration 2010, lr = 0.01
I0721 12:13:31.292969 146637 solver.cpp:236] Iteration 2020, loss = 1.02682
I0721 12:13:31.293140 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:13:31.293184 146637 solver.cpp:252]     Train net output #1: loss = 0.956196 (* 1 = 0.956196 loss)
I0721 12:13:34.611513 146637 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0721 12:14:20.299705 146637 solver.cpp:236] Iteration 2030, loss = 1.03221
I0721 12:14:20.299850 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 12:14:20.299901 146637 solver.cpp:252]     Train net output #1: loss = 1.22169 (* 1 = 1.22169 loss)
I0721 12:14:23.626497 146637 sgd_solver.cpp:106] Iteration 2030, lr = 0.01
I0721 12:15:09.577950 146637 solver.cpp:236] Iteration 2040, loss = 1.02483
I0721 12:15:09.578321 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:15:09.578344 146637 solver.cpp:252]     Train net output #1: loss = 1.1367 (* 1 = 1.1367 loss)
I0721 12:15:12.978791 146637 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0721 12:15:58.552232 146637 solver.cpp:236] Iteration 2050, loss = 1.02762
I0721 12:15:58.552408 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:15:58.552431 146637 solver.cpp:252]     Train net output #1: loss = 1.05444 (* 1 = 1.05444 loss)
I0721 12:16:01.800150 146637 sgd_solver.cpp:106] Iteration 2050, lr = 0.01
I0721 12:16:47.660914 146637 solver.cpp:236] Iteration 2060, loss = 1.02909
I0721 12:16:47.661104 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:16:47.661137 146637 solver.cpp:252]     Train net output #1: loss = 1.16374 (* 1 = 1.16374 loss)
I0721 12:16:50.944391 146637 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0721 12:17:36.303385 146637 solver.cpp:236] Iteration 2070, loss = 1.03748
I0721 12:17:36.303544 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 12:17:36.303591 146637 solver.cpp:252]     Train net output #1: loss = 1.14441 (* 1 = 1.14441 loss)
I0721 12:17:39.668710 146637 sgd_solver.cpp:106] Iteration 2070, lr = 0.01
I0721 12:18:25.155300 146637 solver.cpp:236] Iteration 2080, loss = 1.03012
I0721 12:18:25.155472 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:18:25.155496 146637 solver.cpp:252]     Train net output #1: loss = 1.10702 (* 1 = 1.10702 loss)
I0721 12:18:28.548168 146637 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0721 12:19:14.196437 146637 solver.cpp:236] Iteration 2090, loss = 1.03509
I0721 12:19:14.196616 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:19:14.196650 146637 solver.cpp:252]     Train net output #1: loss = 1.19603 (* 1 = 1.19603 loss)
I0721 12:19:17.476616 146637 sgd_solver.cpp:106] Iteration 2090, lr = 0.01
I0721 12:20:03.317670 146637 solver.cpp:236] Iteration 2100, loss = 1.04279
I0721 12:20:03.317857 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:20:03.317884 146637 solver.cpp:252]     Train net output #1: loss = 1.18473 (* 1 = 1.18473 loss)
I0721 12:20:06.640429 146637 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0721 12:20:52.185367 146637 solver.cpp:236] Iteration 2110, loss = 1.03676
I0721 12:20:52.185549 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 12:20:52.185581 146637 solver.cpp:252]     Train net output #1: loss = 1.01231 (* 1 = 1.01231 loss)
I0721 12:20:55.518157 146637 sgd_solver.cpp:106] Iteration 2110, lr = 0.01
I0721 12:21:44.954270 146637 solver.cpp:236] Iteration 2120, loss = 1.02933
I0721 12:21:44.954421 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:21:44.954465 146637 solver.cpp:252]     Train net output #1: loss = 1.14627 (* 1 = 1.14627 loss)
I0721 12:21:48.392395 146637 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0721 12:22:34.585703 146637 solver.cpp:236] Iteration 2130, loss = 1.0231
I0721 12:22:34.585896 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 12:22:34.585929 146637 solver.cpp:252]     Train net output #1: loss = 1.15431 (* 1 = 1.15431 loss)
I0721 12:22:37.918066 146637 sgd_solver.cpp:106] Iteration 2130, lr = 0.01
I0721 12:23:25.349184 146637 solver.cpp:236] Iteration 2140, loss = 1.03721
I0721 12:23:25.349405 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:23:25.349439 146637 solver.cpp:252]     Train net output #1: loss = 1.08628 (* 1 = 1.08628 loss)
I0721 12:23:28.809437 146637 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0721 12:24:15.160233 146637 solver.cpp:236] Iteration 2150, loss = 1.02181
I0721 12:24:15.160416 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:24:15.160468 146637 solver.cpp:252]     Train net output #1: loss = 1.06926 (* 1 = 1.06926 loss)
I0721 12:24:18.536748 146637 sgd_solver.cpp:106] Iteration 2150, lr = 0.01
I0721 12:25:05.725713 146637 solver.cpp:236] Iteration 2160, loss = 1.02213
I0721 12:25:05.725967 146637 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0721 12:25:05.725994 146637 solver.cpp:252]     Train net output #1: loss = 0.780341 (* 1 = 0.780341 loss)
I0721 12:25:09.131002 146637 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0721 12:25:46.925925 146655 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 12:25:55.319238 146637 solver.cpp:236] Iteration 2170, loss = 1.0177
I0721 12:25:55.319295 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:25:55.319316 146637 solver.cpp:252]     Train net output #1: loss = 1.07878 (* 1 = 1.07878 loss)
I0721 12:25:58.739850 146637 sgd_solver.cpp:106] Iteration 2170, lr = 0.01
I0721 12:26:47.150409 146637 solver.cpp:236] Iteration 2180, loss = 1.03011
I0721 12:26:47.150600 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 12:26:47.150653 146637 solver.cpp:252]     Train net output #1: loss = 1.17468 (* 1 = 1.17468 loss)
I0721 12:26:50.799703 146637 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0721 12:27:36.343097 146637 solver.cpp:236] Iteration 2190, loss = 1.01983
I0721 12:27:36.343309 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:27:36.343350 146637 solver.cpp:252]     Train net output #1: loss = 1.06443 (* 1 = 1.06443 loss)
I0721 12:27:39.835302 146637 sgd_solver.cpp:106] Iteration 2190, lr = 0.01
I0721 12:28:26.371690 146637 solver.cpp:236] Iteration 2200, loss = 1.02742
I0721 12:28:26.371892 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:28:26.371922 146637 solver.cpp:252]     Train net output #1: loss = 1.13496 (* 1 = 1.13496 loss)
I0721 12:28:30.090224 146637 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0721 12:29:18.327774 146637 solver.cpp:236] Iteration 2210, loss = 1.03042
I0721 12:29:18.327965 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:29:18.328016 146637 solver.cpp:252]     Train net output #1: loss = 0.89756 (* 1 = 0.89756 loss)
I0721 12:29:21.939450 146637 sgd_solver.cpp:106] Iteration 2210, lr = 0.01
I0721 12:30:11.051084 146637 solver.cpp:236] Iteration 2220, loss = 1.03251
I0721 12:30:11.051259 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:30:11.051316 146637 solver.cpp:252]     Train net output #1: loss = 1.08646 (* 1 = 1.08646 loss)
I0721 12:30:14.723016 146637 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0721 12:31:00.917031 146637 solver.cpp:236] Iteration 2230, loss = 1.02165
I0721 12:31:00.917186 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:31:00.917232 146637 solver.cpp:252]     Train net output #1: loss = 0.981438 (* 1 = 0.981438 loss)
I0721 12:31:04.822898 146637 sgd_solver.cpp:106] Iteration 2230, lr = 0.01
I0721 12:31:49.248059 146637 solver.cpp:236] Iteration 2240, loss = 1.01808
I0721 12:31:49.248208 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 12:31:49.248237 146637 solver.cpp:252]     Train net output #1: loss = 1.26049 (* 1 = 1.26049 loss)
I0721 12:31:52.492753 146637 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0721 12:32:36.198176 146637 solver.cpp:236] Iteration 2250, loss = 1.01761
I0721 12:32:36.198351 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:32:36.198386 146637 solver.cpp:252]     Train net output #1: loss = 1.07001 (* 1 = 1.07001 loss)
I0721 12:32:39.387336 146637 sgd_solver.cpp:106] Iteration 2250, lr = 0.01
I0721 12:33:23.372241 146637 solver.cpp:236] Iteration 2260, loss = 1.02016
I0721 12:33:23.372419 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:33:23.372464 146637 solver.cpp:252]     Train net output #1: loss = 0.934484 (* 1 = 0.934484 loss)
I0721 12:33:26.563902 146637 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0721 12:34:10.961594 146637 solver.cpp:236] Iteration 2270, loss = 1.02083
I0721 12:34:10.961772 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:34:10.961817 146637 solver.cpp:252]     Train net output #1: loss = 1.03963 (* 1 = 1.03963 loss)
I0721 12:34:14.267762 146637 sgd_solver.cpp:106] Iteration 2270, lr = 0.01
I0721 12:35:03.865135 146637 solver.cpp:236] Iteration 2280, loss = 1.02161
I0721 12:35:03.865326 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 12:35:03.865360 146637 solver.cpp:252]     Train net output #1: loss = 1.14318 (* 1 = 1.14318 loss)
I0721 12:35:07.378705 146637 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0721 12:35:53.226203 146637 solver.cpp:236] Iteration 2290, loss = 1.01109
I0721 12:35:53.226387 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 12:35:53.226429 146637 solver.cpp:252]     Train net output #1: loss = 1.00425 (* 1 = 1.00425 loss)
I0721 12:35:56.507453 146637 sgd_solver.cpp:106] Iteration 2290, lr = 0.01
I0721 12:36:41.802296 146637 solver.cpp:236] Iteration 2300, loss = 1.00865
I0721 12:36:41.802462 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:36:41.802507 146637 solver.cpp:252]     Train net output #1: loss = 1.01742 (* 1 = 1.01742 loss)
I0721 12:36:45.237632 146637 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0721 12:37:30.019580 146637 solver.cpp:236] Iteration 2310, loss = 1.01153
I0721 12:37:30.019748 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:37:30.019771 146637 solver.cpp:252]     Train net output #1: loss = 1.0832 (* 1 = 1.0832 loss)
I0721 12:37:33.341634 146637 sgd_solver.cpp:106] Iteration 2310, lr = 0.01
I0721 12:38:19.868404 146637 solver.cpp:236] Iteration 2320, loss = 1.008
I0721 12:38:19.868588 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:38:19.868639 146637 solver.cpp:252]     Train net output #1: loss = 0.98769 (* 1 = 0.98769 loss)
I0721 12:38:23.393653 146637 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0721 12:39:09.173720 146637 solver.cpp:236] Iteration 2330, loss = 1.01115
I0721 12:39:09.173898 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 12:39:09.173941 146637 solver.cpp:252]     Train net output #1: loss = 1.20895 (* 1 = 1.20895 loss)
I0721 12:39:12.547600 146637 sgd_solver.cpp:106] Iteration 2330, lr = 0.01
I0721 12:39:59.013067 146637 solver.cpp:236] Iteration 2340, loss = 1.01632
I0721 12:39:59.013234 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:39:59.013268 146637 solver.cpp:252]     Train net output #1: loss = 1.05959 (* 1 = 1.05959 loss)
I0721 12:40:02.505811 146637 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0721 12:40:49.061733 146637 solver.cpp:236] Iteration 2350, loss = 1.00907
I0721 12:40:49.061902 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:40:49.061955 146637 solver.cpp:252]     Train net output #1: loss = 1.03601 (* 1 = 1.03601 loss)
I0721 12:40:52.615383 146637 sgd_solver.cpp:106] Iteration 2350, lr = 0.01
I0721 12:41:39.366266 146637 solver.cpp:236] Iteration 2360, loss = 1.00101
I0721 12:41:39.366437 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:41:39.366494 146637 solver.cpp:252]     Train net output #1: loss = 1.14573 (* 1 = 1.14573 loss)
I0721 12:41:42.911295 146637 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0721 12:42:29.138777 146637 solver.cpp:236] Iteration 2370, loss = 1.00222
I0721 12:42:29.138936 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 12:42:29.138984 146637 solver.cpp:252]     Train net output #1: loss = 0.98973 (* 1 = 0.98973 loss)
I0721 12:42:32.381850 146637 sgd_solver.cpp:106] Iteration 2370, lr = 0.01
I0721 12:43:20.619613 146637 solver.cpp:236] Iteration 2380, loss = 1.00521
I0721 12:43:20.619776 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:43:20.619825 146637 solver.cpp:252]     Train net output #1: loss = 1.18132 (* 1 = 1.18132 loss)
I0721 12:43:24.165726 146637 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0721 12:44:12.169571 146637 solver.cpp:236] Iteration 2390, loss = 1.01535
I0721 12:44:12.169723 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 12:44:12.169775 146637 solver.cpp:252]     Train net output #1: loss = 1.12102 (* 1 = 1.12102 loss)
I0721 12:44:15.450398 146637 sgd_solver.cpp:106] Iteration 2390, lr = 0.01
I0721 12:45:00.921916 146637 solver.cpp:236] Iteration 2400, loss = 1.02191
I0721 12:45:00.922060 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:45:00.922097 146637 solver.cpp:252]     Train net output #1: loss = 1.12447 (* 1 = 1.12447 loss)
I0721 12:45:04.261960 146637 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0721 12:45:50.612578 146637 solver.cpp:236] Iteration 2410, loss = 1.01957
I0721 12:45:50.612776 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:45:50.612846 146637 solver.cpp:252]     Train net output #1: loss = 0.977708 (* 1 = 0.977708 loss)
I0721 12:45:53.875968 146637 sgd_solver.cpp:106] Iteration 2410, lr = 0.01
I0721 12:46:38.656607 146637 solver.cpp:236] Iteration 2420, loss = 1.0234
I0721 12:46:38.656805 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:46:38.656839 146637 solver.cpp:252]     Train net output #1: loss = 1.0276 (* 1 = 1.0276 loss)
I0721 12:46:41.965315 146637 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0721 12:47:27.315415 146637 solver.cpp:236] Iteration 2430, loss = 1.01658
I0721 12:47:27.315570 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 12:47:27.315616 146637 solver.cpp:252]     Train net output #1: loss = 0.847023 (* 1 = 0.847023 loss)
I0721 12:47:30.626715 146637 sgd_solver.cpp:106] Iteration 2430, lr = 0.01
I0721 12:48:15.759850 146637 solver.cpp:236] Iteration 2440, loss = 1.01091
I0721 12:48:15.760056 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:48:15.760079 146637 solver.cpp:252]     Train net output #1: loss = 1.04318 (* 1 = 1.04318 loss)
I0721 12:48:19.050448 146637 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0721 12:49:04.279500 146637 solver.cpp:236] Iteration 2450, loss = 1.02055
I0721 12:49:04.279697 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:49:04.279727 146637 solver.cpp:252]     Train net output #1: loss = 1.02267 (* 1 = 1.02267 loss)
I0721 12:49:07.691393 146637 sgd_solver.cpp:106] Iteration 2450, lr = 0.01
I0721 12:49:52.948990 146637 solver.cpp:236] Iteration 2460, loss = 1.01421
I0721 12:49:52.949165 146637 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0721 12:49:52.949201 146637 solver.cpp:252]     Train net output #1: loss = 0.840976 (* 1 = 0.840976 loss)
I0721 12:49:56.273855 146637 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0721 12:50:41.233781 146637 solver.cpp:236] Iteration 2470, loss = 1.01237
I0721 12:50:41.233952 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 12:50:41.234012 146637 solver.cpp:252]     Train net output #1: loss = 1.10422 (* 1 = 1.10422 loss)
I0721 12:50:44.681313 146637 sgd_solver.cpp:106] Iteration 2470, lr = 0.01
I0721 12:51:30.551676 146637 solver.cpp:236] Iteration 2480, loss = 1.01666
I0721 12:51:30.551838 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 12:51:30.551890 146637 solver.cpp:252]     Train net output #1: loss = 1.0598 (* 1 = 1.0598 loss)
I0721 12:51:33.945293 146637 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0721 12:52:19.560343 146637 solver.cpp:236] Iteration 2490, loss = 1.02156
I0721 12:52:19.560479 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 12:52:19.560514 146637 solver.cpp:252]     Train net output #1: loss = 0.962704 (* 1 = 0.962704 loss)
I0721 12:52:22.916157 146637 sgd_solver.cpp:106] Iteration 2490, lr = 0.01
I0721 12:53:08.360098 146637 solver.cpp:236] Iteration 2500, loss = 1.01379
I0721 12:53:08.360262 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 12:53:08.360309 146637 solver.cpp:252]     Train net output #1: loss = 1.13861 (* 1 = 1.13861 loss)
I0721 12:53:11.810534 146637 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0721 12:53:16.573817 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 12:53:56.287483 146637 solver.cpp:236] Iteration 2510, loss = 1.02438
I0721 12:53:56.287631 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 12:53:56.287672 146637 solver.cpp:252]     Train net output #1: loss = 1.05626 (* 1 = 1.05626 loss)
I0721 12:53:59.647138 146637 sgd_solver.cpp:106] Iteration 2510, lr = 0.01
I0721 12:54:44.355173 146637 solver.cpp:236] Iteration 2520, loss = 1.02601
I0721 12:54:44.355363 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 12:54:44.355397 146637 solver.cpp:252]     Train net output #1: loss = 0.901874 (* 1 = 0.901874 loss)
I0721 12:54:47.691714 146637 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0721 12:55:34.449525 146637 solver.cpp:236] Iteration 2530, loss = 1.01791
I0721 12:55:34.449712 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 12:55:34.449744 146637 solver.cpp:252]     Train net output #1: loss = 0.961893 (* 1 = 0.961893 loss)
I0721 12:55:37.864928 146637 sgd_solver.cpp:106] Iteration 2530, lr = 0.01
I0721 12:56:24.621668 146637 solver.cpp:236] Iteration 2540, loss = 1.00746
I0721 12:56:24.621819 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 12:56:24.621871 146637 solver.cpp:252]     Train net output #1: loss = 0.912787 (* 1 = 0.912787 loss)
I0721 12:56:28.049721 146637 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0721 12:57:14.591621 146637 solver.cpp:236] Iteration 2550, loss = 0.999214
I0721 12:57:14.591852 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:57:14.591878 146637 solver.cpp:252]     Train net output #1: loss = 1.06298 (* 1 = 1.06298 loss)
I0721 12:57:17.963690 146637 sgd_solver.cpp:106] Iteration 2550, lr = 0.01
I0721 12:58:04.601604 146637 solver.cpp:236] Iteration 2560, loss = 0.996773
I0721 12:58:04.601773 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:58:04.601809 146637 solver.cpp:252]     Train net output #1: loss = 1.01987 (* 1 = 1.01987 loss)
I0721 12:58:07.957814 146637 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0721 12:58:54.960198 146637 solver.cpp:236] Iteration 2570, loss = 0.996448
I0721 12:58:54.960404 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 12:58:54.960438 146637 solver.cpp:252]     Train net output #1: loss = 1.12994 (* 1 = 1.12994 loss)
I0721 12:58:58.485630 146637 sgd_solver.cpp:106] Iteration 2570, lr = 0.01
I0721 12:59:43.910990 146637 solver.cpp:236] Iteration 2580, loss = 1.00073
I0721 12:59:43.911178 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 12:59:43.911240 146637 solver.cpp:252]     Train net output #1: loss = 1.0081 (* 1 = 1.0081 loss)
I0721 12:59:47.159814 146637 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0721 13:00:33.527786 146637 solver.cpp:236] Iteration 2590, loss = 1.01416
I0721 13:00:33.527967 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:00:33.528012 146637 solver.cpp:252]     Train net output #1: loss = 1.06824 (* 1 = 1.06824 loss)
I0721 13:00:37.473404 146637 sgd_solver.cpp:106] Iteration 2590, lr = 0.01
I0721 13:01:20.319391 146637 solver.cpp:236] Iteration 2600, loss = 1.01681
I0721 13:01:20.319598 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:01:20.319633 146637 solver.cpp:252]     Train net output #1: loss = 0.933621 (* 1 = 0.933621 loss)
I0721 13:01:23.575743 146637 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0721 13:02:07.316476 146637 solver.cpp:236] Iteration 2610, loss = 1.01604
I0721 13:02:07.316612 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:02:07.316653 146637 solver.cpp:252]     Train net output #1: loss = 0.955932 (* 1 = 0.955932 loss)
I0721 13:02:10.492146 146637 sgd_solver.cpp:106] Iteration 2610, lr = 0.01
I0721 13:02:54.660899 146637 solver.cpp:236] Iteration 2620, loss = 1.0286
I0721 13:02:54.661083 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:02:54.661106 146637 solver.cpp:252]     Train net output #1: loss = 1.06541 (* 1 = 1.06541 loss)
I0721 13:02:58.006181 146637 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0721 13:03:43.063426 146637 solver.cpp:236] Iteration 2630, loss = 1.03332
I0721 13:03:43.063598 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:03:43.063621 146637 solver.cpp:252]     Train net output #1: loss = 1.10416 (* 1 = 1.10416 loss)
I0721 13:03:46.362220 146637 sgd_solver.cpp:106] Iteration 2630, lr = 0.01
I0721 13:04:31.104450 146637 solver.cpp:236] Iteration 2640, loss = 1.02964
I0721 13:04:31.104617 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:04:31.104643 146637 solver.cpp:252]     Train net output #1: loss = 0.939703 (* 1 = 0.939703 loss)
I0721 13:04:34.365569 146637 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0721 13:05:18.728305 146637 solver.cpp:236] Iteration 2650, loss = 1.03265
I0721 13:05:18.728477 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:05:18.728504 146637 solver.cpp:252]     Train net output #1: loss = 0.969401 (* 1 = 0.969401 loss)
I0721 13:05:21.967905 146637 sgd_solver.cpp:106] Iteration 2650, lr = 0.01
I0721 13:06:06.151803 146637 solver.cpp:236] Iteration 2660, loss = 1.03864
I0721 13:06:06.151892 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:06:06.151912 146637 solver.cpp:252]     Train net output #1: loss = 0.842791 (* 1 = 0.842791 loss)
I0721 13:06:10.269788 146637 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0721 13:06:54.901666 146637 solver.cpp:236] Iteration 2670, loss = 1.02172
I0721 13:06:54.901888 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:06:54.901918 146637 solver.cpp:252]     Train net output #1: loss = 1.02621 (* 1 = 1.02621 loss)
I0721 13:06:58.205615 146637 sgd_solver.cpp:106] Iteration 2670, lr = 0.01
I0721 13:07:39.153779 146637 solver.cpp:236] Iteration 2680, loss = 1.02308
I0721 13:07:39.153964 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:07:39.154000 146637 solver.cpp:252]     Train net output #1: loss = 1.07179 (* 1 = 1.07179 loss)
I0721 13:07:42.218314 146637 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0721 13:08:22.450847 146637 solver.cpp:236] Iteration 2690, loss = 1.01734
I0721 13:08:22.451022 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:08:22.451052 146637 solver.cpp:252]     Train net output #1: loss = 0.94633 (* 1 = 0.94633 loss)
I0721 13:08:25.496712 146637 sgd_solver.cpp:106] Iteration 2690, lr = 0.01
I0721 13:09:07.233201 146637 solver.cpp:236] Iteration 2700, loss = 1.00813
I0721 13:09:07.233369 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:09:07.233394 146637 solver.cpp:252]     Train net output #1: loss = 0.878288 (* 1 = 0.878288 loss)
I0721 13:09:10.166543 146637 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0721 13:09:52.026057 146637 solver.cpp:236] Iteration 2710, loss = 1.01384
I0721 13:09:52.026247 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:09:52.026275 146637 solver.cpp:252]     Train net output #1: loss = 1.21709 (* 1 = 1.21709 loss)
I0721 13:09:54.938923 146637 sgd_solver.cpp:106] Iteration 2710, lr = 0.01
I0721 13:10:36.577397 146637 solver.cpp:236] Iteration 2720, loss = 1.00981
I0721 13:10:36.577550 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:10:36.577574 146637 solver.cpp:252]     Train net output #1: loss = 1.06702 (* 1 = 1.06702 loss)
I0721 13:10:39.693465 146637 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0721 13:11:22.176139 146637 solver.cpp:236] Iteration 2730, loss = 1.00686
I0721 13:11:22.176332 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:11:22.176373 146637 solver.cpp:252]     Train net output #1: loss = 0.94976 (* 1 = 0.94976 loss)
I0721 13:11:25.139029 146637 sgd_solver.cpp:106] Iteration 2730, lr = 0.01
I0721 13:12:08.851996 146637 solver.cpp:236] Iteration 2740, loss = 1.01148
I0721 13:12:08.852179 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 13:12:08.852201 146637 solver.cpp:252]     Train net output #1: loss = 1.11617 (* 1 = 1.11617 loss)
I0721 13:12:12.120539 146637 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0721 13:12:55.478634 146637 solver.cpp:236] Iteration 2750, loss = 1.0275
I0721 13:12:55.478919 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:12:55.478955 146637 solver.cpp:252]     Train net output #1: loss = 1.01465 (* 1 = 1.01465 loss)
I0721 13:12:58.892864 146637 sgd_solver.cpp:106] Iteration 2750, lr = 0.01
I0721 13:13:42.874557 146637 solver.cpp:236] Iteration 2760, loss = 1.01688
I0721 13:13:42.874796 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:13:42.874820 146637 solver.cpp:252]     Train net output #1: loss = 0.996562 (* 1 = 0.996562 loss)
I0721 13:13:46.027590 146637 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0721 13:14:30.369323 146637 solver.cpp:236] Iteration 2770, loss = 1.03162
I0721 13:14:30.369604 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:14:30.369632 146637 solver.cpp:252]     Train net output #1: loss = 0.951715 (* 1 = 0.951715 loss)
I0721 13:14:33.733700 146637 sgd_solver.cpp:106] Iteration 2770, lr = 0.01
I0721 13:15:19.280915 146637 solver.cpp:236] Iteration 2780, loss = 1.02759
I0721 13:15:19.281127 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:15:19.281149 146637 solver.cpp:252]     Train net output #1: loss = 0.937575 (* 1 = 0.937575 loss)
I0721 13:15:22.643126 146637 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0721 13:16:06.476857 146637 solver.cpp:236] Iteration 2790, loss = 1.02568
I0721 13:16:06.477056 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:16:06.477093 146637 solver.cpp:252]     Train net output #1: loss = 1.10834 (* 1 = 1.10834 loss)
I0721 13:16:09.743460 146637 sgd_solver.cpp:106] Iteration 2790, lr = 0.01
I0721 13:16:54.031332 146637 solver.cpp:236] Iteration 2800, loss = 1.02438
I0721 13:16:54.031550 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:16:54.031579 146637 solver.cpp:252]     Train net output #1: loss = 1.16375 (* 1 = 1.16375 loss)
I0721 13:16:57.341094 146637 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0721 13:17:42.778188 146637 solver.cpp:236] Iteration 2810, loss = 1.02183
I0721 13:17:42.778370 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:17:42.778409 146637 solver.cpp:252]     Train net output #1: loss = 0.869407 (* 1 = 0.869407 loss)
I0721 13:17:45.991026 146637 sgd_solver.cpp:106] Iteration 2810, lr = 0.01
I0721 13:18:28.992321 146637 solver.cpp:236] Iteration 2820, loss = 1.01135
I0721 13:18:28.992485 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:18:28.992517 146637 solver.cpp:252]     Train net output #1: loss = 0.884805 (* 1 = 0.884805 loss)
I0721 13:18:32.100800 146637 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0721 13:19:15.464867 146637 solver.cpp:236] Iteration 2830, loss = 1.00096
I0721 13:19:15.465073 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:19:15.465096 146637 solver.cpp:252]     Train net output #1: loss = 0.968386 (* 1 = 0.968386 loss)
I0721 13:19:18.669021 146637 sgd_solver.cpp:106] Iteration 2830, lr = 0.01
I0721 13:19:38.725389 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 13:20:02.879807 146637 solver.cpp:236] Iteration 2840, loss = 0.996087
I0721 13:20:02.879987 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:20:02.880020 146637 solver.cpp:252]     Train net output #1: loss = 0.918526 (* 1 = 0.918526 loss)
I0721 13:20:06.335407 146637 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0721 13:20:50.083801 146637 solver.cpp:236] Iteration 2850, loss = 0.998525
I0721 13:20:50.083957 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:20:50.083992 146637 solver.cpp:252]     Train net output #1: loss = 0.879489 (* 1 = 0.879489 loss)
I0721 13:20:53.249761 146637 sgd_solver.cpp:106] Iteration 2850, lr = 0.01
I0721 13:21:36.902384 146637 solver.cpp:236] Iteration 2860, loss = 1.00728
I0721 13:21:36.902556 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:21:36.902588 146637 solver.cpp:252]     Train net output #1: loss = 1.01555 (* 1 = 1.01555 loss)
I0721 13:21:40.284435 146637 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0721 13:22:24.104962 146637 solver.cpp:236] Iteration 2870, loss = 1.01269
I0721 13:22:24.105130 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:22:24.105159 146637 solver.cpp:252]     Train net output #1: loss = 0.886084 (* 1 = 0.886084 loss)
I0721 13:22:27.271553 146637 sgd_solver.cpp:106] Iteration 2870, lr = 0.01
I0721 13:23:11.277423 146637 solver.cpp:236] Iteration 2880, loss = 1.00866
I0721 13:23:11.277655 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:23:11.277698 146637 solver.cpp:252]     Train net output #1: loss = 0.875356 (* 1 = 0.875356 loss)
I0721 13:23:14.680472 146637 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0721 13:23:59.341925 146637 solver.cpp:236] Iteration 2890, loss = 1.0212
I0721 13:23:59.342175 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:23:59.342202 146637 solver.cpp:252]     Train net output #1: loss = 1.08485 (* 1 = 1.08485 loss)
I0721 13:24:02.703490 146637 sgd_solver.cpp:106] Iteration 2890, lr = 0.01
I0721 13:24:45.869307 146637 solver.cpp:236] Iteration 2900, loss = 1.02386
I0721 13:24:45.869442 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:24:45.869463 146637 solver.cpp:252]     Train net output #1: loss = 1.15196 (* 1 = 1.15196 loss)
I0721 13:24:49.271060 146637 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0721 13:25:35.167667 146637 solver.cpp:236] Iteration 2910, loss = 1.01673
I0721 13:25:35.167902 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:25:35.167925 146637 solver.cpp:252]     Train net output #1: loss = 0.928582 (* 1 = 0.928582 loss)
I0721 13:25:38.557271 146637 sgd_solver.cpp:106] Iteration 2910, lr = 0.01
I0721 13:26:26.224941 146637 solver.cpp:236] Iteration 2920, loss = 1.0123
I0721 13:26:26.225118 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:26:26.225141 146637 solver.cpp:252]     Train net output #1: loss = 1.04215 (* 1 = 1.04215 loss)
I0721 13:26:29.884555 146637 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0721 13:27:17.348284 146637 solver.cpp:236] Iteration 2930, loss = 1.03669
I0721 13:27:17.348481 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:27:17.348505 146637 solver.cpp:252]     Train net output #1: loss = 1.09928 (* 1 = 1.09928 loss)
I0721 13:27:21.172962 146637 sgd_solver.cpp:106] Iteration 2930, lr = 0.01
I0721 13:28:09.922307 146637 solver.cpp:236] Iteration 2940, loss = 1.03069
I0721 13:28:09.922508 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:28:09.922538 146637 solver.cpp:252]     Train net output #1: loss = 1.2092 (* 1 = 1.2092 loss)
I0721 13:28:13.302978 146637 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0721 13:28:59.459589 146637 solver.cpp:236] Iteration 2950, loss = 1.02491
I0721 13:28:59.459758 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:28:59.459791 146637 solver.cpp:252]     Train net output #1: loss = 1.02858 (* 1 = 1.02858 loss)
I0721 13:29:02.840008 146637 sgd_solver.cpp:106] Iteration 2950, lr = 0.01
I0721 13:29:48.100004 146637 solver.cpp:236] Iteration 2960, loss = 1.03294
I0721 13:29:48.100203 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 13:29:48.100235 146637 solver.cpp:252]     Train net output #1: loss = 1.17485 (* 1 = 1.17485 loss)
I0721 13:29:51.679075 146637 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0721 13:30:36.850517 146637 solver.cpp:236] Iteration 2970, loss = 1.03649
I0721 13:30:36.850857 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:30:36.850884 146637 solver.cpp:252]     Train net output #1: loss = 1.08196 (* 1 = 1.08196 loss)
I0721 13:30:40.192616 146637 sgd_solver.cpp:106] Iteration 2970, lr = 0.01
I0721 13:31:26.527137 146637 solver.cpp:236] Iteration 2980, loss = 1.02538
I0721 13:31:26.527374 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 13:31:26.527395 146637 solver.cpp:252]     Train net output #1: loss = 1.17208 (* 1 = 1.17208 loss)
I0721 13:31:30.029814 146637 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0721 13:32:16.704881 146637 solver.cpp:236] Iteration 2990, loss = 1.01914
I0721 13:32:16.705065 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:32:16.705090 146637 solver.cpp:252]     Train net output #1: loss = 0.99839 (* 1 = 0.99839 loss)
I0721 13:32:20.116516 146637 sgd_solver.cpp:106] Iteration 2990, lr = 0.01
I0721 13:33:05.693779 146637 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_3000.caffemodel
I0721 13:33:05.706159 146637 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_3000.solverstate
I0721 13:33:05.710207 146637 solver.cpp:340] Iteration 3000, Testing net (#0)
I0721 13:39:08.593313 146637 solver.cpp:408]     Test net output #0: accuracy = 0.507
I0721 13:39:08.593490 146637 solver.cpp:408]     Test net output #1: loss = 1.01089 (* 1 = 1.01089 loss)
I0721 13:39:08.867442 146637 solver.cpp:236] Iteration 3000, loss = 1.01494
I0721 13:39:08.867511 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 13:39:08.867532 146637 solver.cpp:252]     Train net output #1: loss = 1.07884 (* 1 = 1.07884 loss)
I0721 13:39:09.882939 146637 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0721 13:39:23.588387 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 13:39:55.401258 146637 solver.cpp:236] Iteration 3010, loss = 1.00221
I0721 13:39:55.401497 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 13:39:55.401543 146637 solver.cpp:252]     Train net output #1: loss = 0.815523 (* 1 = 0.815523 loss)
I0721 13:39:58.998811 146637 sgd_solver.cpp:106] Iteration 3010, lr = 0.01
I0721 13:40:46.167234 146637 solver.cpp:236] Iteration 3020, loss = 0.999568
I0721 13:40:46.167446 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:40:46.167484 146637 solver.cpp:252]     Train net output #1: loss = 0.921679 (* 1 = 0.921679 loss)
I0721 13:40:49.564055 146637 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0721 13:41:35.437913 146637 solver.cpp:236] Iteration 3030, loss = 1.00151
I0721 13:41:35.438108 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:41:35.438143 146637 solver.cpp:252]     Train net output #1: loss = 1.12964 (* 1 = 1.12964 loss)
I0721 13:41:38.846566 146637 sgd_solver.cpp:106] Iteration 3030, lr = 0.01
I0721 13:42:25.206269 146637 solver.cpp:236] Iteration 3040, loss = 0.986914
I0721 13:42:25.206434 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:42:25.206468 146637 solver.cpp:252]     Train net output #1: loss = 0.871924 (* 1 = 0.871924 loss)
I0721 13:42:28.725883 146637 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0721 13:43:15.839834 146637 solver.cpp:236] Iteration 3050, loss = 0.980885
I0721 13:43:15.840031 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 13:43:15.840054 146637 solver.cpp:252]     Train net output #1: loss = 1.23919 (* 1 = 1.23919 loss)
I0721 13:43:19.381137 146637 sgd_solver.cpp:106] Iteration 3050, lr = 0.01
I0721 13:44:06.587388 146637 solver.cpp:236] Iteration 3060, loss = 0.987749
I0721 13:44:06.587604 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:44:06.587625 146637 solver.cpp:252]     Train net output #1: loss = 1.10761 (* 1 = 1.10761 loss)
I0721 13:44:10.222818 146637 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0721 13:44:57.584870 146637 solver.cpp:236] Iteration 3070, loss = 0.989907
I0721 13:44:57.585052 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:44:57.585088 146637 solver.cpp:252]     Train net output #1: loss = 0.970931 (* 1 = 0.970931 loss)
I0721 13:45:01.406191 146637 sgd_solver.cpp:106] Iteration 3070, lr = 0.01
I0721 13:45:51.383698 146637 solver.cpp:236] Iteration 3080, loss = 0.992072
I0721 13:45:51.383858 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:45:51.383915 146637 solver.cpp:252]     Train net output #1: loss = 0.960415 (* 1 = 0.960415 loss)
I0721 13:45:55.089205 146637 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0721 13:46:41.159301 146637 solver.cpp:236] Iteration 3090, loss = 1.00738
I0721 13:46:41.159538 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:46:41.159565 146637 solver.cpp:252]     Train net output #1: loss = 1.00884 (* 1 = 1.00884 loss)
I0721 13:46:44.472975 146637 sgd_solver.cpp:106] Iteration 3090, lr = 0.01
I0721 13:47:30.608508 146637 solver.cpp:236] Iteration 3100, loss = 1.0094
I0721 13:47:30.608713 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:47:30.608734 146637 solver.cpp:252]     Train net output #1: loss = 0.945241 (* 1 = 0.945241 loss)
I0721 13:47:33.819831 146637 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0721 13:48:19.484390 146637 solver.cpp:236] Iteration 3110, loss = 1.01249
I0721 13:48:19.484580 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:48:19.484616 146637 solver.cpp:252]     Train net output #1: loss = 1.12344 (* 1 = 1.12344 loss)
I0721 13:48:22.803364 146637 sgd_solver.cpp:106] Iteration 3110, lr = 0.01
I0721 13:49:06.570327 146637 solver.cpp:236] Iteration 3120, loss = 1.01277
I0721 13:49:06.570567 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:49:06.570603 146637 solver.cpp:252]     Train net output #1: loss = 1.08696 (* 1 = 1.08696 loss)
I0721 13:49:09.773908 146637 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0721 13:49:52.951568 146637 solver.cpp:236] Iteration 3130, loss = 1.0069
I0721 13:49:52.951778 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:49:52.951829 146637 solver.cpp:252]     Train net output #1: loss = 1.05403 (* 1 = 1.05403 loss)
I0721 13:49:56.266331 146637 sgd_solver.cpp:106] Iteration 3130, lr = 0.01
I0721 13:50:39.863682 146637 solver.cpp:236] Iteration 3140, loss = 1.00801
I0721 13:50:39.863826 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:50:39.863869 146637 solver.cpp:252]     Train net output #1: loss = 0.986581 (* 1 = 0.986581 loss)
I0721 13:50:43.158829 146637 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0721 13:51:26.837776 146637 solver.cpp:236] Iteration 3150, loss = 1.00059
I0721 13:51:26.838029 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:51:26.838052 146637 solver.cpp:252]     Train net output #1: loss = 1.05165 (* 1 = 1.05165 loss)
I0721 13:51:30.136194 146637 sgd_solver.cpp:106] Iteration 3150, lr = 0.01
I0721 13:52:16.199314 146637 solver.cpp:236] Iteration 3160, loss = 1.00171
I0721 13:52:16.199570 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 13:52:16.199604 146637 solver.cpp:252]     Train net output #1: loss = 1.0625 (* 1 = 1.0625 loss)
I0721 13:52:19.463016 146637 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0721 13:53:03.264195 146637 solver.cpp:236] Iteration 3170, loss = 0.999349
I0721 13:53:03.264384 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:53:03.264428 146637 solver.cpp:252]     Train net output #1: loss = 0.970322 (* 1 = 0.970322 loss)
I0721 13:53:06.547453 146637 sgd_solver.cpp:106] Iteration 3170, lr = 0.01
I0721 13:53:50.549266 146637 solver.cpp:236] Iteration 3180, loss = 1.00108
I0721 13:53:50.549492 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:53:50.549512 146637 solver.cpp:252]     Train net output #1: loss = 1.01636 (* 1 = 1.01636 loss)
I0721 13:53:53.787752 146637 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0721 13:54:38.413146 146637 solver.cpp:236] Iteration 3190, loss = 1.01248
I0721 13:54:38.413264 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:54:38.413285 146637 solver.cpp:252]     Train net output #1: loss = 1.04628 (* 1 = 1.04628 loss)
I0721 13:54:41.745911 146637 sgd_solver.cpp:106] Iteration 3190, lr = 0.01
I0721 13:55:25.400270 146637 solver.cpp:236] Iteration 3200, loss = 1.02444
I0721 13:55:25.400399 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 13:55:25.400418 146637 solver.cpp:252]     Train net output #1: loss = 0.899427 (* 1 = 0.899427 loss)
I0721 13:55:28.657059 146637 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0721 13:56:12.420747 146637 solver.cpp:236] Iteration 3210, loss = 1.01564
I0721 13:56:12.420922 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 13:56:12.420953 146637 solver.cpp:252]     Train net output #1: loss = 0.850818 (* 1 = 0.850818 loss)
I0721 13:56:15.637329 146637 sgd_solver.cpp:106] Iteration 3210, lr = 0.01
I0721 13:57:00.038347 146637 solver.cpp:236] Iteration 3220, loss = 1.00404
I0721 13:57:00.038542 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 13:57:00.038575 146637 solver.cpp:252]     Train net output #1: loss = 1.16006 (* 1 = 1.16006 loss)
I0721 13:57:03.377097 146637 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0721 13:57:47.146564 146637 solver.cpp:236] Iteration 3230, loss = 0.997227
I0721 13:57:47.146733 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 13:57:47.146785 146637 solver.cpp:252]     Train net output #1: loss = 0.995964 (* 1 = 0.995964 loss)
I0721 13:57:50.463539 146637 sgd_solver.cpp:106] Iteration 3230, lr = 0.01
I0721 13:58:35.640466 146637 solver.cpp:236] Iteration 3240, loss = 0.984832
I0721 13:58:35.640662 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:58:35.640696 146637 solver.cpp:252]     Train net output #1: loss = 1.12527 (* 1 = 1.12527 loss)
I0721 13:58:39.189301 146637 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0721 13:59:23.242321 146637 solver.cpp:236] Iteration 3250, loss = 0.986079
I0721 13:59:23.242563 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 13:59:23.242588 146637 solver.cpp:252]     Train net output #1: loss = 1.02355 (* 1 = 1.02355 loss)
I0721 13:59:26.570236 146637 sgd_solver.cpp:106] Iteration 3250, lr = 0.01
I0721 14:00:11.186301 146637 solver.cpp:236] Iteration 3260, loss = 0.992843
I0721 14:00:11.186470 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 14:00:11.186506 146637 solver.cpp:252]     Train net output #1: loss = 1.21477 (* 1 = 1.21477 loss)
I0721 14:00:14.546043 146637 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0721 14:00:59.119308 146637 solver.cpp:236] Iteration 3270, loss = 1.01275
I0721 14:00:59.119524 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:00:59.119546 146637 solver.cpp:252]     Train net output #1: loss = 0.93675 (* 1 = 0.93675 loss)
I0721 14:01:02.596115 146637 sgd_solver.cpp:106] Iteration 3270, lr = 0.01
I0721 14:01:48.978970 146637 solver.cpp:236] Iteration 3280, loss = 1.03399
I0721 14:01:48.979157 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 14:01:48.979202 146637 solver.cpp:252]     Train net output #1: loss = 1.19364 (* 1 = 1.19364 loss)
I0721 14:01:52.421552 146637 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0721 14:02:37.495107 146637 solver.cpp:236] Iteration 3290, loss = 1.02934
I0721 14:02:37.495291 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:02:37.495326 146637 solver.cpp:252]     Train net output #1: loss = 1.03851 (* 1 = 1.03851 loss)
I0721 14:02:40.860743 146637 sgd_solver.cpp:106] Iteration 3290, lr = 0.01
I0721 14:03:27.167244 146637 solver.cpp:236] Iteration 3300, loss = 1.03051
I0721 14:03:27.167426 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:03:27.167456 146637 solver.cpp:252]     Train net output #1: loss = 1.02593 (* 1 = 1.02593 loss)
I0721 14:03:30.586822 146637 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0721 14:04:17.192064 146637 solver.cpp:236] Iteration 3310, loss = 1.03006
I0721 14:04:17.192266 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 14:04:17.192288 146637 solver.cpp:252]     Train net output #1: loss = 0.770717 (* 1 = 0.770717 loss)
I0721 14:04:20.635324 146637 sgd_solver.cpp:106] Iteration 3310, lr = 0.01
I0721 14:05:06.479357 146637 solver.cpp:236] Iteration 3320, loss = 1.02425
I0721 14:05:06.479542 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:05:06.479564 146637 solver.cpp:252]     Train net output #1: loss = 1.00593 (* 1 = 1.00593 loss)
I0721 14:05:09.794879 146637 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0721 14:05:55.989836 146637 solver.cpp:236] Iteration 3330, loss = 1.00699
I0721 14:05:55.989948 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:05:55.989971 146637 solver.cpp:252]     Train net output #1: loss = 1.02567 (* 1 = 1.02567 loss)
I0721 14:05:59.483355 146637 sgd_solver.cpp:106] Iteration 3330, lr = 0.01
I0721 14:06:30.750043 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 14:06:45.620949 146637 solver.cpp:236] Iteration 3340, loss = 0.998377
I0721 14:06:45.621021 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:06:45.621042 146637 solver.cpp:252]     Train net output #1: loss = 1.07422 (* 1 = 1.07422 loss)
I0721 14:06:48.961729 146637 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0721 14:07:34.380517 146637 solver.cpp:236] Iteration 3350, loss = 0.997382
I0721 14:07:34.380679 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 14:07:34.380702 146637 solver.cpp:252]     Train net output #1: loss = 0.832189 (* 1 = 0.832189 loss)
I0721 14:07:37.882201 146637 sgd_solver.cpp:106] Iteration 3350, lr = 0.01
I0721 14:08:23.776975 146637 solver.cpp:236] Iteration 3360, loss = 0.991607
I0721 14:08:23.777245 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:08:23.777266 146637 solver.cpp:252]     Train net output #1: loss = 1.01336 (* 1 = 1.01336 loss)
I0721 14:08:27.222009 146637 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0721 14:09:13.136834 146637 solver.cpp:236] Iteration 3370, loss = 0.993648
I0721 14:09:13.137069 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:09:13.137090 146637 solver.cpp:252]     Train net output #1: loss = 0.919153 (* 1 = 0.919153 loss)
I0721 14:09:16.454890 146637 sgd_solver.cpp:106] Iteration 3370, lr = 0.01
I0721 14:10:03.346312 146637 solver.cpp:236] Iteration 3380, loss = 0.986515
I0721 14:10:03.346473 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:10:03.346525 146637 solver.cpp:252]     Train net output #1: loss = 1.02628 (* 1 = 1.02628 loss)
I0721 14:10:07.305287 146637 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0721 14:10:53.496914 146637 solver.cpp:236] Iteration 3390, loss = 1.01583
I0721 14:10:53.497087 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:10:53.497134 146637 solver.cpp:252]     Train net output #1: loss = 1.05633 (* 1 = 1.05633 loss)
I0721 14:10:56.772430 146637 sgd_solver.cpp:106] Iteration 3390, lr = 0.01
I0721 14:11:41.857328 146637 solver.cpp:236] Iteration 3400, loss = 1.02206
I0721 14:11:41.857481 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:11:41.857530 146637 solver.cpp:252]     Train net output #1: loss = 1.06556 (* 1 = 1.06556 loss)
I0721 14:11:45.311384 146637 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0721 14:12:30.107581 146637 solver.cpp:236] Iteration 3410, loss = 1.04374
I0721 14:12:30.107751 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 14:12:30.107776 146637 solver.cpp:252]     Train net output #1: loss = 1.03436 (* 1 = 1.03436 loss)
I0721 14:12:33.446771 146637 sgd_solver.cpp:106] Iteration 3410, lr = 0.01
I0721 14:13:18.134645 146637 solver.cpp:236] Iteration 3420, loss = 1.04926
I0721 14:13:18.134814 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 14:13:18.134863 146637 solver.cpp:252]     Train net output #1: loss = 1.14291 (* 1 = 1.14291 loss)
I0721 14:13:21.471915 146637 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0721 14:14:06.505215 146637 solver.cpp:236] Iteration 3430, loss = 1.05776
I0721 14:14:06.505405 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:14:06.505429 146637 solver.cpp:252]     Train net output #1: loss = 1.07092 (* 1 = 1.07092 loss)
I0721 14:14:09.769430 146637 sgd_solver.cpp:106] Iteration 3430, lr = 0.01
I0721 14:14:55.540498 146637 solver.cpp:236] Iteration 3440, loss = 1.05099
I0721 14:14:55.540738 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:14:55.540776 146637 solver.cpp:252]     Train net output #1: loss = 0.994227 (* 1 = 0.994227 loss)
I0721 14:14:59.494623 146637 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0721 14:15:45.097070 146637 solver.cpp:236] Iteration 3450, loss = 1.05343
I0721 14:15:45.097288 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 14:15:45.097312 146637 solver.cpp:252]     Train net output #1: loss = 1.09945 (* 1 = 1.09945 loss)
I0721 14:15:48.523483 146637 sgd_solver.cpp:106] Iteration 3450, lr = 0.01
I0721 14:16:33.421113 146637 solver.cpp:236] Iteration 3460, loss = 1.03336
I0721 14:16:33.421234 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:16:33.421257 146637 solver.cpp:252]     Train net output #1: loss = 0.95819 (* 1 = 0.95819 loss)
I0721 14:16:36.752651 146637 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0721 14:17:21.906756 146637 solver.cpp:236] Iteration 3470, loss = 1.02207
I0721 14:17:21.906908 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:17:21.906956 146637 solver.cpp:252]     Train net output #1: loss = 0.929811 (* 1 = 0.929811 loss)
I0721 14:17:25.210217 146637 sgd_solver.cpp:106] Iteration 3470, lr = 0.01
I0721 14:18:09.259143 146637 solver.cpp:236] Iteration 3480, loss = 1.03647
I0721 14:18:09.259361 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:18:09.259382 146637 solver.cpp:252]     Train net output #1: loss = 1.02472 (* 1 = 1.02472 loss)
I0721 14:18:12.478818 146637 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0721 14:18:57.086592 146637 solver.cpp:236] Iteration 3490, loss = 1.03582
I0721 14:18:57.086813 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:18:57.086853 146637 solver.cpp:252]     Train net output #1: loss = 1.09763 (* 1 = 1.09763 loss)
I0721 14:19:00.360291 146637 sgd_solver.cpp:106] Iteration 3490, lr = 0.01
I0721 14:19:44.881124 146637 solver.cpp:236] Iteration 3500, loss = 1.02116
I0721 14:19:44.881284 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:19:44.881317 146637 solver.cpp:252]     Train net output #1: loss = 1.00364 (* 1 = 1.00364 loss)
I0721 14:19:48.177707 146637 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0721 14:20:33.878064 146637 solver.cpp:236] Iteration 3510, loss = 1.02926
I0721 14:20:33.878224 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:20:33.878264 146637 solver.cpp:252]     Train net output #1: loss = 0.982464 (* 1 = 0.982464 loss)
I0721 14:20:37.221099 146637 sgd_solver.cpp:106] Iteration 3510, lr = 0.01
I0721 14:21:22.912652 146637 solver.cpp:236] Iteration 3520, loss = 1.03316
I0721 14:21:22.912858 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 14:21:22.912892 146637 solver.cpp:252]     Train net output #1: loss = 0.838994 (* 1 = 0.838994 loss)
I0721 14:21:26.186096 146637 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0721 14:22:11.955775 146637 solver.cpp:236] Iteration 3530, loss = 1.02551
I0721 14:22:11.955961 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:22:11.956007 146637 solver.cpp:252]     Train net output #1: loss = 0.934891 (* 1 = 0.934891 loss)
I0721 14:22:15.311350 146637 sgd_solver.cpp:106] Iteration 3530, lr = 0.01
I0721 14:23:01.388669 146637 solver.cpp:236] Iteration 3540, loss = 1.03412
I0721 14:23:01.388886 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 14:23:01.388908 146637 solver.cpp:252]     Train net output #1: loss = 1.27791 (* 1 = 1.27791 loss)
I0721 14:23:04.753793 146637 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0721 14:23:50.539400 146637 solver.cpp:236] Iteration 3550, loss = 1.03918
I0721 14:23:50.539561 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:23:50.539595 146637 solver.cpp:252]     Train net output #1: loss = 0.861874 (* 1 = 0.861874 loss)
I0721 14:23:53.820399 146637 sgd_solver.cpp:106] Iteration 3550, lr = 0.01
I0721 14:24:39.725127 146637 solver.cpp:236] Iteration 3560, loss = 1.03503
I0721 14:24:39.725307 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:24:39.725340 146637 solver.cpp:252]     Train net output #1: loss = 0.949798 (* 1 = 0.949798 loss)
I0721 14:24:43.067297 146637 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0721 14:25:25.739265 146637 solver.cpp:236] Iteration 3570, loss = 1.03669
I0721 14:25:25.739500 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 14:25:25.739534 146637 solver.cpp:252]     Train net output #1: loss = 1.16342 (* 1 = 1.16342 loss)
I0721 14:25:29.053014 146637 sgd_solver.cpp:106] Iteration 3570, lr = 0.01
I0721 14:26:11.203701 146637 solver.cpp:236] Iteration 3580, loss = 1.02556
I0721 14:26:11.203969 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:26:11.204004 146637 solver.cpp:252]     Train net output #1: loss = 1.03625 (* 1 = 1.03625 loss)
I0721 14:26:14.294498 146637 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0721 14:26:58.505147 146637 solver.cpp:236] Iteration 3590, loss = 1.00688
I0721 14:26:58.505400 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 14:26:58.505429 146637 solver.cpp:252]     Train net output #1: loss = 0.902238 (* 1 = 0.902238 loss)
I0721 14:27:01.613538 146637 sgd_solver.cpp:106] Iteration 3590, lr = 0.01
I0721 14:27:43.659584 146637 solver.cpp:236] Iteration 3600, loss = 1.0109
I0721 14:27:43.659844 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:27:43.659879 146637 solver.cpp:252]     Train net output #1: loss = 1.12774 (* 1 = 1.12774 loss)
I0721 14:27:46.949136 146637 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0721 14:28:31.495815 146637 solver.cpp:236] Iteration 3610, loss = 1.01864
I0721 14:28:31.496019 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:28:31.496042 146637 solver.cpp:252]     Train net output #1: loss = 1.07103 (* 1 = 1.07103 loss)
I0721 14:28:34.874511 146637 sgd_solver.cpp:106] Iteration 3610, lr = 0.01
I0721 14:29:23.960988 146637 solver.cpp:236] Iteration 3620, loss = 1.0173
I0721 14:29:23.961226 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:29:23.961266 146637 solver.cpp:252]     Train net output #1: loss = 1.00316 (* 1 = 1.00316 loss)
I0721 14:29:27.547950 146637 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0721 14:30:17.491801 146637 solver.cpp:236] Iteration 3630, loss = 1.02605
I0721 14:30:17.491945 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 14:30:17.491966 146637 solver.cpp:252]     Train net output #1: loss = 1.16257 (* 1 = 1.16257 loss)
I0721 14:30:20.855854 146637 sgd_solver.cpp:106] Iteration 3630, lr = 0.01
I0721 14:31:06.854347 146637 solver.cpp:236] Iteration 3640, loss = 1.02825
I0721 14:31:06.854503 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:31:06.854539 146637 solver.cpp:252]     Train net output #1: loss = 1.05436 (* 1 = 1.05436 loss)
I0721 14:31:10.303669 146637 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0721 14:31:56.998314 146637 solver.cpp:236] Iteration 3650, loss = 1.01407
I0721 14:31:56.998497 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:31:56.998533 146637 solver.cpp:252]     Train net output #1: loss = 1.01455 (* 1 = 1.01455 loss)
I0721 14:32:00.481001 146637 sgd_solver.cpp:106] Iteration 3650, lr = 0.01
I0721 14:32:47.417618 146637 solver.cpp:236] Iteration 3660, loss = 1.00077
I0721 14:32:47.417836 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 14:32:47.417865 146637 solver.cpp:252]     Train net output #1: loss = 0.89519 (* 1 = 0.89519 loss)
I0721 14:32:50.923305 146637 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0721 14:33:40.198868 146637 solver.cpp:236] Iteration 3670, loss = 1.00042
I0721 14:33:40.199111 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:33:40.199146 146637 solver.cpp:252]     Train net output #1: loss = 1.06437 (* 1 = 1.06437 loss)
I0721 14:33:41.834434 146655 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 14:33:43.862571 146637 sgd_solver.cpp:106] Iteration 3670, lr = 0.01
I0721 14:34:34.555333 146637 solver.cpp:236] Iteration 3680, loss = 0.999307
I0721 14:34:34.555620 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:34:34.555678 146637 solver.cpp:252]     Train net output #1: loss = 1.02603 (* 1 = 1.02603 loss)
I0721 14:34:38.389257 146637 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0721 14:35:25.653790 146637 solver.cpp:236] Iteration 3690, loss = 0.999239
I0721 14:35:25.653941 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:35:25.653988 146637 solver.cpp:252]     Train net output #1: loss = 1.0264 (* 1 = 1.0264 loss)
I0721 14:35:29.018016 146637 sgd_solver.cpp:106] Iteration 3690, lr = 0.01
I0721 14:36:15.790419 146637 solver.cpp:236] Iteration 3700, loss = 1.00657
I0721 14:36:15.790621 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:36:15.790675 146637 solver.cpp:252]     Train net output #1: loss = 0.982403 (* 1 = 0.982403 loss)
I0721 14:36:19.150794 146637 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0721 14:37:05.736740 146637 solver.cpp:236] Iteration 3710, loss = 1.00331
I0721 14:37:05.736933 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 14:37:05.736968 146637 solver.cpp:252]     Train net output #1: loss = 1.16684 (* 1 = 1.16684 loss)
I0721 14:37:09.256446 146637 sgd_solver.cpp:106] Iteration 3710, lr = 0.01
I0721 14:37:55.877928 146637 solver.cpp:236] Iteration 3720, loss = 0.997838
I0721 14:37:55.878206 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:37:55.878229 146637 solver.cpp:252]     Train net output #1: loss = 0.93731 (* 1 = 0.93731 loss)
I0721 14:37:59.402905 146637 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0721 14:38:45.955920 146637 solver.cpp:236] Iteration 3730, loss = 0.988917
I0721 14:38:45.956153 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:38:45.956188 146637 solver.cpp:252]     Train net output #1: loss = 1.06662 (* 1 = 1.06662 loss)
I0721 14:38:49.381191 146637 sgd_solver.cpp:106] Iteration 3730, lr = 0.01
I0721 14:39:35.805155 146637 solver.cpp:236] Iteration 3740, loss = 1.00191
I0721 14:39:35.805341 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:39:35.805382 146637 solver.cpp:252]     Train net output #1: loss = 0.907484 (* 1 = 0.907484 loss)
I0721 14:39:39.114205 146637 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0721 14:40:26.275595 146637 solver.cpp:236] Iteration 3750, loss = 1.00561
I0721 14:40:26.275825 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:40:26.275857 146637 solver.cpp:252]     Train net output #1: loss = 0.88943 (* 1 = 0.88943 loss)
I0721 14:40:29.746767 146637 sgd_solver.cpp:106] Iteration 3750, lr = 0.01
I0721 14:41:16.096303 146637 solver.cpp:236] Iteration 3760, loss = 1.01129
I0721 14:41:16.096529 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:41:16.096554 146637 solver.cpp:252]     Train net output #1: loss = 0.809457 (* 1 = 0.809457 loss)
I0721 14:41:19.540251 146637 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0721 14:42:05.387517 146637 solver.cpp:236] Iteration 3770, loss = 1.01589
I0721 14:42:05.387684 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:42:05.387708 146637 solver.cpp:252]     Train net output #1: loss = 1.00058 (* 1 = 1.00058 loss)
I0721 14:42:08.889133 146637 sgd_solver.cpp:106] Iteration 3770, lr = 0.01
I0721 14:42:54.983240 146637 solver.cpp:236] Iteration 3780, loss = 1.02127
I0721 14:42:54.983515 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 14:42:54.983544 146637 solver.cpp:252]     Train net output #1: loss = 1.02979 (* 1 = 1.02979 loss)
I0721 14:42:58.427472 146637 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0721 14:43:43.999948 146637 solver.cpp:236] Iteration 3790, loss = 0.994576
I0721 14:43:44.000135 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:43:44.000167 146637 solver.cpp:252]     Train net output #1: loss = 0.932778 (* 1 = 0.932778 loss)
I0721 14:43:47.307848 146637 sgd_solver.cpp:106] Iteration 3790, lr = 0.01
I0721 14:44:36.566352 146637 solver.cpp:236] Iteration 3800, loss = 0.989925
I0721 14:44:36.566550 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:44:36.566586 146637 solver.cpp:252]     Train net output #1: loss = 0.955789 (* 1 = 0.955789 loss)
I0721 14:44:40.301837 146637 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0721 14:45:28.949405 146637 solver.cpp:236] Iteration 3810, loss = 0.990332
I0721 14:45:28.949549 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:45:28.949594 146637 solver.cpp:252]     Train net output #1: loss = 0.902036 (* 1 = 0.902036 loss)
I0721 14:45:32.503317 146637 sgd_solver.cpp:106] Iteration 3810, lr = 0.01
I0721 14:46:21.134940 146637 solver.cpp:236] Iteration 3820, loss = 0.999593
I0721 14:46:21.135082 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:46:21.135105 146637 solver.cpp:252]     Train net output #1: loss = 0.905126 (* 1 = 0.905126 loss)
I0721 14:46:25.896839 146637 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0721 14:47:12.637190 146637 solver.cpp:236] Iteration 3830, loss = 1.00864
I0721 14:47:12.637423 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 14:47:12.637452 146637 solver.cpp:252]     Train net output #1: loss = 1.09152 (* 1 = 1.09152 loss)
I0721 14:47:15.968745 146637 sgd_solver.cpp:106] Iteration 3830, lr = 0.01
I0721 14:48:01.744962 146637 solver.cpp:236] Iteration 3840, loss = 1.0208
I0721 14:48:01.745201 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:48:01.745221 146637 solver.cpp:252]     Train net output #1: loss = 0.984582 (* 1 = 0.984582 loss)
I0721 14:48:04.987815 146637 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0721 14:48:49.274657 146637 solver.cpp:236] Iteration 3850, loss = 1.01073
I0721 14:48:49.275327 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:48:49.275393 146637 solver.cpp:252]     Train net output #1: loss = 0.901752 (* 1 = 0.901752 loss)
I0721 14:48:52.950486 146637 sgd_solver.cpp:106] Iteration 3850, lr = 0.01
I0721 14:49:37.577167 146637 solver.cpp:236] Iteration 3860, loss = 1.01626
I0721 14:49:37.577491 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:49:37.577518 146637 solver.cpp:252]     Train net output #1: loss = 0.970657 (* 1 = 0.970657 loss)
I0721 14:49:40.717816 146637 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0721 14:50:25.875946 146637 solver.cpp:236] Iteration 3870, loss = 0.99674
I0721 14:50:25.876123 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:50:25.876175 146637 solver.cpp:252]     Train net output #1: loss = 0.964631 (* 1 = 0.964631 loss)
I0721 14:50:29.310377 146637 sgd_solver.cpp:106] Iteration 3870, lr = 0.01
I0721 14:51:14.277163 146637 solver.cpp:236] Iteration 3880, loss = 0.995977
I0721 14:51:14.277326 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 14:51:14.277384 146637 solver.cpp:252]     Train net output #1: loss = 1.20723 (* 1 = 1.20723 loss)
I0721 14:51:17.552991 146637 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0721 14:52:02.729058 146637 solver.cpp:236] Iteration 3890, loss = 1.0004
I0721 14:52:02.729248 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:52:02.729285 146637 solver.cpp:252]     Train net output #1: loss = 0.909711 (* 1 = 0.909711 loss)
I0721 14:52:06.089290 146637 sgd_solver.cpp:106] Iteration 3890, lr = 0.01
I0721 14:52:50.949414 146637 solver.cpp:236] Iteration 3900, loss = 1.00833
I0721 14:52:50.949573 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:52:50.949635 146637 solver.cpp:252]     Train net output #1: loss = 1.03705 (* 1 = 1.03705 loss)
I0721 14:52:54.539367 146637 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0721 14:53:39.521075 146637 solver.cpp:236] Iteration 3910, loss = 1.00549
I0721 14:53:39.521288 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 14:53:39.521316 146637 solver.cpp:252]     Train net output #1: loss = 0.859891 (* 1 = 0.859891 loss)
I0721 14:53:42.861379 146637 sgd_solver.cpp:106] Iteration 3910, lr = 0.01
I0721 14:54:28.175164 146637 solver.cpp:236] Iteration 3920, loss = 1.01635
I0721 14:54:28.175361 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 14:54:28.175395 146637 solver.cpp:252]     Train net output #1: loss = 0.86129 (* 1 = 0.86129 loss)
I0721 14:54:31.473299 146637 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0721 14:55:16.807884 146637 solver.cpp:236] Iteration 3930, loss = 1.01607
I0721 14:55:16.808087 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:55:16.808122 146637 solver.cpp:252]     Train net output #1: loss = 1.04904 (* 1 = 1.04904 loss)
I0721 14:55:20.542603 146637 sgd_solver.cpp:106] Iteration 3930, lr = 0.01
I0721 14:56:08.781253 146637 solver.cpp:236] Iteration 3940, loss = 1.0173
I0721 14:56:08.781419 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 14:56:08.781466 146637 solver.cpp:252]     Train net output #1: loss = 1.064 (* 1 = 1.064 loss)
I0721 14:56:12.453743 146637 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0721 14:57:00.991207 146637 solver.cpp:236] Iteration 3950, loss = 1.01334
I0721 14:57:00.991473 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:57:00.991498 146637 solver.cpp:252]     Train net output #1: loss = 1.01508 (* 1 = 1.01508 loss)
I0721 14:57:04.453480 146637 sgd_solver.cpp:106] Iteration 3950, lr = 0.01
I0721 14:57:54.856923 146637 solver.cpp:236] Iteration 3960, loss = 1.01092
I0721 14:57:54.857128 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:57:54.857162 146637 solver.cpp:252]     Train net output #1: loss = 1.10816 (* 1 = 1.10816 loss)
I0721 14:57:58.263167 146637 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0721 14:58:47.977969 146637 solver.cpp:236] Iteration 3970, loss = 1.00011
I0721 14:58:47.979689 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 14:58:47.979728 146637 solver.cpp:252]     Train net output #1: loss = 1.01416 (* 1 = 1.01416 loss)
I0721 14:58:51.576822 146637 sgd_solver.cpp:106] Iteration 3970, lr = 0.01
I0721 14:59:44.173532 146637 solver.cpp:236] Iteration 3980, loss = 0.992873
I0721 14:59:44.173647 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 14:59:44.173669 146637 solver.cpp:252]     Train net output #1: loss = 1.07768 (* 1 = 1.07768 loss)
I0721 14:59:47.552177 146637 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0721 15:00:39.103854 146637 solver.cpp:236] Iteration 3990, loss = 0.9754
I0721 15:00:39.103979 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:00:39.104001 146637 solver.cpp:252]     Train net output #1: loss = 0.892815 (* 1 = 0.892815 loss)
I0721 15:00:42.662477 146637 sgd_solver.cpp:106] Iteration 3990, lr = 0.01
I0721 15:01:30.599566 146637 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_4000.caffemodel
I0721 15:01:30.631130 146637 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_4000.solverstate
I0721 15:01:32.109176 146637 solver.cpp:236] Iteration 4000, loss = 0.984496
I0721 15:01:32.109244 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:01:32.109262 146637 solver.cpp:252]     Train net output #1: loss = 0.860035 (* 1 = 0.860035 loss)
I0721 15:01:35.607262 146637 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0721 15:01:51.475672 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 15:02:23.327661 146637 solver.cpp:236] Iteration 4010, loss = 0.984106
I0721 15:02:23.327853 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:02:23.327877 146637 solver.cpp:252]     Train net output #1: loss = 1.04034 (* 1 = 1.04034 loss)
I0721 15:02:26.949908 146637 sgd_solver.cpp:106] Iteration 4010, lr = 0.01
I0721 15:03:16.008970 146637 solver.cpp:236] Iteration 4020, loss = 0.996624
I0721 15:03:16.009183 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:03:16.009220 146637 solver.cpp:252]     Train net output #1: loss = 0.958877 (* 1 = 0.958877 loss)
I0721 15:03:19.703413 146637 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0721 15:04:07.475004 146637 solver.cpp:236] Iteration 4030, loss = 0.995432
I0721 15:04:07.475196 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:04:07.475229 146637 solver.cpp:252]     Train net output #1: loss = 0.919937 (* 1 = 0.919937 loss)
I0721 15:04:11.103443 146637 sgd_solver.cpp:106] Iteration 4030, lr = 0.01
I0721 15:04:58.806556 146637 solver.cpp:236] Iteration 4040, loss = 1.00766
I0721 15:04:58.806751 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:04:58.806783 146637 solver.cpp:252]     Train net output #1: loss = 0.94069 (* 1 = 0.94069 loss)
I0721 15:05:02.430501 146637 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0721 15:05:52.726979 146637 solver.cpp:236] Iteration 4050, loss = 0.996238
I0721 15:05:52.727185 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 15:05:52.727218 146637 solver.cpp:252]     Train net output #1: loss = 0.969491 (* 1 = 0.969491 loss)
I0721 15:05:56.624265 146637 sgd_solver.cpp:106] Iteration 4050, lr = 0.01
I0721 15:06:44.834456 146637 solver.cpp:236] Iteration 4060, loss = 0.984558
I0721 15:06:44.834692 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:06:44.834715 146637 solver.cpp:252]     Train net output #1: loss = 0.943369 (* 1 = 0.943369 loss)
I0721 15:06:48.585784 146637 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0721 15:07:37.082666 146637 solver.cpp:236] Iteration 4070, loss = 0.990267
I0721 15:07:37.082855 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:07:37.082901 146637 solver.cpp:252]     Train net output #1: loss = 1.0186 (* 1 = 1.0186 loss)
I0721 15:07:41.231243 146637 sgd_solver.cpp:106] Iteration 4070, lr = 0.01
I0721 15:08:31.384593 146637 solver.cpp:236] Iteration 4080, loss = 0.992615
I0721 15:08:31.384730 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:08:31.384752 146637 solver.cpp:252]     Train net output #1: loss = 1.1311 (* 1 = 1.1311 loss)
I0721 15:08:35.190022 146637 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0721 15:09:27.145103 146637 solver.cpp:236] Iteration 4090, loss = 0.979958
I0721 15:09:27.145277 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:09:27.145301 146637 solver.cpp:252]     Train net output #1: loss = 0.871058 (* 1 = 0.871058 loss)
I0721 15:09:30.916530 146637 sgd_solver.cpp:106] Iteration 4090, lr = 0.01
I0721 15:10:20.958942 146637 solver.cpp:236] Iteration 4100, loss = 0.978508
I0721 15:10:20.959197 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:10:20.959236 146637 solver.cpp:252]     Train net output #1: loss = 0.988243 (* 1 = 0.988243 loss)
I0721 15:10:24.574618 146637 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0721 15:11:13.838922 146637 solver.cpp:236] Iteration 4110, loss = 1.00365
I0721 15:11:13.839150 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:11:13.839184 146637 solver.cpp:252]     Train net output #1: loss = 1.20206 (* 1 = 1.20206 loss)
I0721 15:11:17.667963 146637 sgd_solver.cpp:106] Iteration 4110, lr = 0.01
I0721 15:12:07.303333 146637 solver.cpp:236] Iteration 4120, loss = 0.993058
I0721 15:12:07.303508 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:12:07.303560 146637 solver.cpp:252]     Train net output #1: loss = 1.03563 (* 1 = 1.03563 loss)
I0721 15:12:11.004639 146637 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0721 15:13:04.947713 146637 solver.cpp:236] Iteration 4130, loss = 0.995529
I0721 15:13:04.947839 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 15:13:04.947893 146637 solver.cpp:252]     Train net output #1: loss = 1.1633 (* 1 = 1.1633 loss)
I0721 15:13:09.042812 146637 sgd_solver.cpp:106] Iteration 4130, lr = 0.01
I0721 15:14:02.726650 146637 solver.cpp:236] Iteration 4140, loss = 1.00356
I0721 15:14:02.726840 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:14:02.726888 146637 solver.cpp:252]     Train net output #1: loss = 0.831063 (* 1 = 0.831063 loss)
I0721 15:14:06.479090 146637 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0721 15:14:59.521606 146637 solver.cpp:236] Iteration 4150, loss = 1.01627
I0721 15:14:59.521749 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:14:59.521781 146637 solver.cpp:252]     Train net output #1: loss = 1.1125 (* 1 = 1.1125 loss)
I0721 15:15:03.126286 146637 sgd_solver.cpp:106] Iteration 4150, lr = 0.01
I0721 15:15:54.883105 146637 solver.cpp:236] Iteration 4160, loss = 1.00761
I0721 15:15:54.883283 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:15:54.883316 146637 solver.cpp:252]     Train net output #1: loss = 1.0675 (* 1 = 1.0675 loss)
I0721 15:15:58.627712 146637 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0721 15:16:47.661232 146637 solver.cpp:236] Iteration 4170, loss = 1.01669
I0721 15:16:47.661422 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:16:47.661449 146637 solver.cpp:252]     Train net output #1: loss = 0.926965 (* 1 = 0.926965 loss)
I0721 15:16:51.457260 146637 sgd_solver.cpp:106] Iteration 4170, lr = 0.01
I0721 15:17:42.110445 146637 solver.cpp:236] Iteration 4180, loss = 1.01691
I0721 15:17:42.110680 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:17:42.110713 146637 solver.cpp:252]     Train net output #1: loss = 1.06389 (* 1 = 1.06389 loss)
I0721 15:17:45.603591 146637 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0721 15:18:36.850731 146637 solver.cpp:236] Iteration 4190, loss = 1.01916
I0721 15:18:36.850917 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:18:36.850970 146637 solver.cpp:252]     Train net output #1: loss = 1.02557 (* 1 = 1.02557 loss)
I0721 15:18:40.368155 146637 sgd_solver.cpp:106] Iteration 4190, lr = 0.01
I0721 15:19:30.638662 146637 solver.cpp:236] Iteration 4200, loss = 1.00632
I0721 15:19:30.638876 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:19:30.638898 146637 solver.cpp:252]     Train net output #1: loss = 0.895044 (* 1 = 0.895044 loss)
I0721 15:19:34.605716 146637 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0721 15:20:28.123998 146637 solver.cpp:236] Iteration 4210, loss = 1.01721
I0721 15:20:28.124191 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:20:28.124245 146637 solver.cpp:252]     Train net output #1: loss = 1.04199 (* 1 = 1.04199 loss)
I0721 15:20:31.687666 146637 sgd_solver.cpp:106] Iteration 4210, lr = 0.01
I0721 15:21:21.058881 146637 solver.cpp:236] Iteration 4220, loss = 1.01336
I0721 15:21:21.059061 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 15:21:21.059093 146637 solver.cpp:252]     Train net output #1: loss = 1.19557 (* 1 = 1.19557 loss)
I0721 15:21:24.568435 146637 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0721 15:22:15.042237 146637 solver.cpp:236] Iteration 4230, loss = 1.01528
I0721 15:22:15.042382 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:22:15.042402 146637 solver.cpp:252]     Train net output #1: loss = 1.17311 (* 1 = 1.17311 loss)
I0721 15:22:18.761895 146637 sgd_solver.cpp:106] Iteration 4230, lr = 0.01
I0721 15:23:07.897238 146637 solver.cpp:236] Iteration 4240, loss = 1.0233
I0721 15:23:07.897436 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:23:07.897472 146637 solver.cpp:252]     Train net output #1: loss = 1.07665 (* 1 = 1.07665 loss)
I0721 15:23:11.902662 146637 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0721 15:24:02.934373 146637 solver.cpp:236] Iteration 4250, loss = 1.05169
I0721 15:24:02.934582 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:24:02.934613 146637 solver.cpp:252]     Train net output #1: loss = 0.977857 (* 1 = 0.977857 loss)
I0721 15:24:06.433500 146637 sgd_solver.cpp:106] Iteration 4250, lr = 0.01
I0721 15:24:56.601248 146637 solver.cpp:236] Iteration 4260, loss = 1.04127
I0721 15:24:56.601466 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:24:56.601505 146637 solver.cpp:252]     Train net output #1: loss = 0.991862 (* 1 = 0.991862 loss)
I0721 15:25:00.075125 146637 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0721 15:25:51.102133 146637 solver.cpp:236] Iteration 4270, loss = 1.03636
I0721 15:25:51.102304 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 15:25:51.102351 146637 solver.cpp:252]     Train net output #1: loss = 1.20392 (* 1 = 1.20392 loss)
I0721 15:25:55.079805 146637 sgd_solver.cpp:106] Iteration 4270, lr = 0.01
I0721 15:26:46.447825 146637 solver.cpp:236] Iteration 4280, loss = 1.02731
I0721 15:26:46.448052 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:26:46.448086 146637 solver.cpp:252]     Train net output #1: loss = 1.02945 (* 1 = 1.02945 loss)
I0721 15:26:50.042124 146637 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0721 15:27:41.162861 146637 solver.cpp:236] Iteration 4290, loss = 1.01954
I0721 15:27:41.163095 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:27:41.163120 146637 solver.cpp:252]     Train net output #1: loss = 1.03003 (* 1 = 1.03003 loss)
I0721 15:27:44.672286 146637 sgd_solver.cpp:106] Iteration 4290, lr = 0.01
I0721 15:28:35.688334 146637 solver.cpp:236] Iteration 4300, loss = 0.996046
I0721 15:28:35.688577 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 15:28:35.688608 146637 solver.cpp:252]     Train net output #1: loss = 1.02543 (* 1 = 1.02543 loss)
I0721 15:28:39.066445 146637 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0721 15:29:31.149554 146637 solver.cpp:236] Iteration 4310, loss = 0.994659
I0721 15:29:31.149705 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:29:31.149725 146637 solver.cpp:252]     Train net output #1: loss = 1.07905 (* 1 = 1.07905 loss)
I0721 15:29:34.635119 146637 sgd_solver.cpp:106] Iteration 4310, lr = 0.01
I0721 15:30:26.546062 146637 solver.cpp:236] Iteration 4320, loss = 0.997143
I0721 15:30:26.546195 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 15:30:26.546236 146637 solver.cpp:252]     Train net output #1: loss = 0.894479 (* 1 = 0.894479 loss)
I0721 15:30:30.439961 146637 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0721 15:31:19.248781 146637 solver.cpp:236] Iteration 4330, loss = 0.999299
I0721 15:31:19.248945 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:31:19.248967 146637 solver.cpp:252]     Train net output #1: loss = 1.03893 (* 1 = 1.03893 loss)
I0721 15:31:22.582178 146637 sgd_solver.cpp:106] Iteration 4330, lr = 0.01
I0721 15:31:57.054944 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 15:32:13.714159 146637 solver.cpp:236] Iteration 4340, loss = 1.0038
I0721 15:32:13.714215 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:32:13.714233 146637 solver.cpp:252]     Train net output #1: loss = 0.986806 (* 1 = 0.986806 loss)
I0721 15:32:17.198113 146637 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0721 15:33:08.695468 146637 solver.cpp:236] Iteration 4350, loss = 1.01993
I0721 15:33:08.695690 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:33:08.695726 146637 solver.cpp:252]     Train net output #1: loss = 1.00116 (* 1 = 1.00116 loss)
I0721 15:33:12.205584 146637 sgd_solver.cpp:106] Iteration 4350, lr = 0.01
I0721 15:34:02.767112 146637 solver.cpp:236] Iteration 4360, loss = 1.02156
I0721 15:34:02.767251 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:34:02.767277 146637 solver.cpp:252]     Train net output #1: loss = 1.04437 (* 1 = 1.04437 loss)
I0721 15:34:06.660487 146637 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0721 15:34:55.791113 146637 solver.cpp:236] Iteration 4370, loss = 1.01638
I0721 15:34:55.791306 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:34:55.791344 146637 solver.cpp:252]     Train net output #1: loss = 1.21813 (* 1 = 1.21813 loss)
I0721 15:34:59.259748 146637 sgd_solver.cpp:106] Iteration 4370, lr = 0.01
I0721 15:35:45.312999 146637 solver.cpp:236] Iteration 4380, loss = 1.01779
I0721 15:35:45.313216 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:35:45.313263 146637 solver.cpp:252]     Train net output #1: loss = 1.00654 (* 1 = 1.00654 loss)
I0721 15:35:48.827870 146637 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0721 15:36:36.341428 146637 solver.cpp:236] Iteration 4390, loss = 1.01371
I0721 15:36:36.341595 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:36:36.341616 146637 solver.cpp:252]     Train net output #1: loss = 0.870541 (* 1 = 0.870541 loss)
I0721 15:36:39.924438 146637 sgd_solver.cpp:106] Iteration 4390, lr = 0.01
I0721 15:37:26.260725 146637 solver.cpp:236] Iteration 4400, loss = 0.997215
I0721 15:37:26.260952 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:37:26.260979 146637 solver.cpp:252]     Train net output #1: loss = 1.00848 (* 1 = 1.00848 loss)
I0721 15:37:29.806481 146637 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0721 15:38:18.041833 146637 solver.cpp:236] Iteration 4410, loss = 0.995944
I0721 15:38:18.042083 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:38:18.042104 146637 solver.cpp:252]     Train net output #1: loss = 1.00194 (* 1 = 1.00194 loss)
I0721 15:38:21.532975 146637 sgd_solver.cpp:106] Iteration 4410, lr = 0.01
I0721 15:39:07.971257 146637 solver.cpp:236] Iteration 4420, loss = 0.991752
I0721 15:39:07.971474 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 15:39:07.971501 146637 solver.cpp:252]     Train net output #1: loss = 0.897851 (* 1 = 0.897851 loss)
I0721 15:39:11.545722 146637 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0721 15:39:58.293712 146637 solver.cpp:236] Iteration 4430, loss = 0.995289
I0721 15:39:58.293884 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 15:39:58.293946 146637 solver.cpp:252]     Train net output #1: loss = 1.08533 (* 1 = 1.08533 loss)
I0721 15:40:01.687274 146637 sgd_solver.cpp:106] Iteration 4430, lr = 0.01
I0721 15:40:48.818085 146637 solver.cpp:236] Iteration 4440, loss = 0.990607
I0721 15:40:48.818274 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:40:48.818298 146637 solver.cpp:252]     Train net output #1: loss = 0.938649 (* 1 = 0.938649 loss)
I0721 15:40:52.272188 146637 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0721 15:41:40.142983 146637 solver.cpp:236] Iteration 4450, loss = 0.9901
I0721 15:41:40.143129 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:41:40.143195 146637 solver.cpp:252]     Train net output #1: loss = 0.91492 (* 1 = 0.91492 loss)
I0721 15:41:44.088461 146637 sgd_solver.cpp:106] Iteration 4450, lr = 0.01
I0721 15:42:30.163034 146637 solver.cpp:236] Iteration 4460, loss = 0.979732
I0721 15:42:30.163162 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:42:30.163187 146637 solver.cpp:252]     Train net output #1: loss = 1.04089 (* 1 = 1.04089 loss)
I0721 15:42:33.663324 146637 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0721 15:43:18.140739 146637 solver.cpp:236] Iteration 4470, loss = 0.991448
I0721 15:43:18.140933 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:43:18.140970 146637 solver.cpp:252]     Train net output #1: loss = 1.05824 (* 1 = 1.05824 loss)
I0721 15:43:21.482431 146637 sgd_solver.cpp:106] Iteration 4470, lr = 0.01
I0721 15:44:05.661931 146637 solver.cpp:236] Iteration 4480, loss = 0.98896
I0721 15:44:05.662155 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:44:05.662195 146637 solver.cpp:252]     Train net output #1: loss = 0.897418 (* 1 = 0.897418 loss)
I0721 15:44:08.988236 146637 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0721 15:44:52.693167 146637 solver.cpp:236] Iteration 4490, loss = 1.01007
I0721 15:44:52.693339 146637 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0721 15:44:52.693384 146637 solver.cpp:252]     Train net output #1: loss = 1.33206 (* 1 = 1.33206 loss)
I0721 15:44:55.951498 146637 sgd_solver.cpp:106] Iteration 4490, lr = 0.01
I0721 15:45:38.240720 146637 solver.cpp:340] Iteration 4500, Testing net (#0)
I0721 15:53:17.074478 146637 solver.cpp:408]     Test net output #0: accuracy = 0.51525
I0721 15:53:17.149668 146637 solver.cpp:408]     Test net output #1: loss = 1.00152 (* 1 = 1.00152 loss)
I0721 15:53:17.429286 146637 solver.cpp:236] Iteration 4500, loss = 1.0238
I0721 15:53:17.429345 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:53:17.429365 146637 solver.cpp:252]     Train net output #1: loss = 1.10728 (* 1 = 1.10728 loss)
I0721 15:53:18.384717 146637 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0721 15:53:48.919848 146637 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 15:54:16.271805 146637 solver.cpp:236] Iteration 4510, loss = 1.02952
I0721 15:54:16.271890 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:54:16.271924 146637 solver.cpp:252]     Train net output #1: loss = 0.951691 (* 1 = 0.951691 loss)
I0721 15:54:20.587978 146637 sgd_solver.cpp:106] Iteration 4510, lr = 0.01
I0721 15:55:17.256099 146637 solver.cpp:236] Iteration 4520, loss = 1.02499
I0721 15:55:17.305757 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:55:17.305804 146637 solver.cpp:252]     Train net output #1: loss = 0.992502 (* 1 = 0.992502 loss)
I0721 15:55:20.833467 146637 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0721 15:56:13.861322 146637 solver.cpp:236] Iteration 4530, loss = 1.01325
I0721 15:56:13.861472 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 15:56:13.861522 146637 solver.cpp:252]     Train net output #1: loss = 0.924116 (* 1 = 0.924116 loss)
I0721 15:56:17.744065 146637 sgd_solver.cpp:106] Iteration 4530, lr = 0.01
I0721 15:57:06.728986 146637 solver.cpp:236] Iteration 4540, loss = 0.99451
I0721 15:57:06.729192 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 15:57:06.729219 146637 solver.cpp:252]     Train net output #1: loss = 0.991457 (* 1 = 0.991457 loss)
I0721 15:57:10.389500 146637 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0721 15:57:57.897505 146637 solver.cpp:236] Iteration 4550, loss = 0.980811
I0721 15:57:57.897704 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:57:57.897729 146637 solver.cpp:252]     Train net output #1: loss = 1.01803 (* 1 = 1.01803 loss)
I0721 15:58:01.429741 146637 sgd_solver.cpp:106] Iteration 4550, lr = 0.01
I0721 15:58:51.778470 146637 solver.cpp:236] Iteration 4560, loss = 0.978668
I0721 15:58:51.778710 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 15:58:51.778734 146637 solver.cpp:252]     Train net output #1: loss = 0.977384 (* 1 = 0.977384 loss)
I0721 15:58:55.342939 146637 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0721 15:59:43.840929 146637 solver.cpp:236] Iteration 4570, loss = 0.967718
I0721 15:59:43.841095 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 15:59:43.841130 146637 solver.cpp:252]     Train net output #1: loss = 0.951411 (* 1 = 0.951411 loss)
I0721 15:59:47.284150 146637 sgd_solver.cpp:106] Iteration 4570, lr = 0.01
I0721 16:00:34.991525 146637 solver.cpp:236] Iteration 4580, loss = 0.96802
I0721 16:00:34.991724 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:00:34.991780 146637 solver.cpp:252]     Train net output #1: loss = 0.942379 (* 1 = 0.942379 loss)
I0721 16:00:38.574211 146637 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0721 16:01:28.294739 146637 solver.cpp:236] Iteration 4590, loss = 0.97238
I0721 16:01:28.294967 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:01:28.295001 146637 solver.cpp:252]     Train net output #1: loss = 1.0852 (* 1 = 1.0852 loss)
I0721 16:01:32.100983 146637 sgd_solver.cpp:106] Iteration 4590, lr = 0.01
I0721 16:02:20.841960 146637 solver.cpp:236] Iteration 4600, loss = 0.978912
I0721 16:02:20.842175 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:02:20.842209 146637 solver.cpp:252]     Train net output #1: loss = 0.942809 (* 1 = 0.942809 loss)
I0721 16:02:24.510964 146637 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0721 16:03:13.904558 146637 solver.cpp:236] Iteration 4610, loss = 0.98946
I0721 16:03:13.904769 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:03:13.904793 146637 solver.cpp:252]     Train net output #1: loss = 1.04362 (* 1 = 1.04362 loss)
I0721 16:03:17.679802 146637 sgd_solver.cpp:106] Iteration 4610, lr = 0.01
I0721 16:04:10.733928 146637 solver.cpp:236] Iteration 4620, loss = 1.00957
I0721 16:04:10.734060 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:04:10.734084 146637 solver.cpp:252]     Train net output #1: loss = 0.94561 (* 1 = 0.94561 loss)
I0721 16:04:14.737076 146637 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0721 16:05:07.898586 146637 solver.cpp:236] Iteration 4630, loss = 1.01422
I0721 16:05:07.898769 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:05:07.898813 146637 solver.cpp:252]     Train net output #1: loss = 0.915641 (* 1 = 0.915641 loss)
I0721 16:05:11.523569 146637 sgd_solver.cpp:106] Iteration 4630, lr = 0.01
I0721 16:06:01.248126 146637 solver.cpp:236] Iteration 4640, loss = 1.01229
I0721 16:06:01.248354 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:06:01.248389 146637 solver.cpp:252]     Train net output #1: loss = 1.03613 (* 1 = 1.03613 loss)
I0721 16:06:04.932593 146637 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0721 16:06:54.385169 146637 solver.cpp:236] Iteration 4650, loss = 1.02335
I0721 16:06:54.385360 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 16:06:54.385382 146637 solver.cpp:252]     Train net output #1: loss = 1.15418 (* 1 = 1.15418 loss)
I0721 16:06:57.871346 146637 sgd_solver.cpp:106] Iteration 4650, lr = 0.01
I0721 16:07:46.693761 146637 solver.cpp:236] Iteration 4660, loss = 1.01644
I0721 16:07:46.693919 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:07:46.693964 146637 solver.cpp:252]     Train net output #1: loss = 0.949561 (* 1 = 0.949561 loss)
I0721 16:07:50.285871 146637 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0721 16:08:39.227912 146637 solver.cpp:236] Iteration 4670, loss = 1.00252
I0721 16:08:39.228101 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:08:39.228123 146637 solver.cpp:252]     Train net output #1: loss = 0.930832 (* 1 = 0.930832 loss)
I0721 16:08:42.788367 146637 sgd_solver.cpp:106] Iteration 4670, lr = 0.01
I0721 16:09:31.701656 146637 solver.cpp:236] Iteration 4680, loss = 1.00683
I0721 16:09:31.701884 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 16:09:31.701920 146637 solver.cpp:252]     Train net output #1: loss = 1.17541 (* 1 = 1.17541 loss)
I0721 16:09:35.611631 146637 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0721 16:10:25.907842 146637 solver.cpp:236] Iteration 4690, loss = 1.0132
I0721 16:10:25.907984 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:10:25.908017 146637 solver.cpp:252]     Train net output #1: loss = 1.02945 (* 1 = 1.02945 loss)
I0721 16:10:29.789806 146637 sgd_solver.cpp:106] Iteration 4690, lr = 0.01
I0721 16:11:19.270309 146637 solver.cpp:236] Iteration 4700, loss = 1.0094
I0721 16:11:19.270587 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:11:19.270618 146637 solver.cpp:252]     Train net output #1: loss = 0.956974 (* 1 = 0.956974 loss)
I0721 16:11:22.847168 146637 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0721 16:12:11.224035 146637 solver.cpp:236] Iteration 4710, loss = 1.01419
I0721 16:12:11.224205 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:12:11.224230 146637 solver.cpp:252]     Train net output #1: loss = 1.01293 (* 1 = 1.01293 loss)
I0721 16:12:15.040305 146637 sgd_solver.cpp:106] Iteration 4710, lr = 0.01
I0721 16:13:03.569319 146637 solver.cpp:236] Iteration 4720, loss = 1.02455
I0721 16:13:03.569481 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:13:03.569532 146637 solver.cpp:252]     Train net output #1: loss = 0.980054 (* 1 = 0.980054 loss)
I0721 16:13:07.212461 146637 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0721 16:13:54.841734 146637 solver.cpp:236] Iteration 4730, loss = 1.03617
I0721 16:13:54.841928 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:13:54.841949 146637 solver.cpp:252]     Train net output #1: loss = 1.06154 (* 1 = 1.06154 loss)
I0721 16:13:58.508999 146637 sgd_solver.cpp:106] Iteration 4730, lr = 0.01
I0721 16:14:47.665840 146637 solver.cpp:236] Iteration 4740, loss = 1.03466
I0721 16:14:47.666018 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:14:47.666079 146637 solver.cpp:252]     Train net output #1: loss = 0.865916 (* 1 = 0.865916 loss)
I0721 16:14:51.653506 146637 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0721 16:15:40.034620 146637 solver.cpp:236] Iteration 4750, loss = 1.03716
I0721 16:15:40.034858 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:15:40.034880 146637 solver.cpp:252]     Train net output #1: loss = 1.0295 (* 1 = 1.0295 loss)
I0721 16:15:43.625089 146637 sgd_solver.cpp:106] Iteration 4750, lr = 0.01
I0721 16:16:32.354471 146637 solver.cpp:236] Iteration 4760, loss = 1.04712
I0721 16:16:32.354713 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:16:32.354734 146637 solver.cpp:252]     Train net output #1: loss = 1.01274 (* 1 = 1.01274 loss)
I0721 16:16:35.887215 146637 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0721 16:17:25.768826 146637 solver.cpp:236] Iteration 4770, loss = 1.03206
I0721 16:17:25.769026 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:17:25.769059 146637 solver.cpp:252]     Train net output #1: loss = 1.03289 (* 1 = 1.03289 loss)
I0721 16:17:29.339471 146637 sgd_solver.cpp:106] Iteration 4770, lr = 0.01
I0721 16:18:16.835049 146637 solver.cpp:236] Iteration 4780, loss = 1.03093
I0721 16:18:16.835221 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:18:16.835254 146637 solver.cpp:252]     Train net output #1: loss = 0.98576 (* 1 = 0.98576 loss)
I0721 16:18:20.271723 146637 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0721 16:19:07.487421 146637 solver.cpp:236] Iteration 4790, loss = 1.02546
I0721 16:19:07.487618 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 16:19:07.487654 146637 solver.cpp:252]     Train net output #1: loss = 0.818495 (* 1 = 0.818495 loss)
I0721 16:19:11.146891 146637 sgd_solver.cpp:106] Iteration 4790, lr = 0.01
I0721 16:19:58.461472 146637 solver.cpp:236] Iteration 4800, loss = 1.01193
I0721 16:19:58.461627 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:19:58.461661 146637 solver.cpp:252]     Train net output #1: loss = 0.984249 (* 1 = 0.984249 loss)
I0721 16:20:01.949908 146637 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0721 16:20:48.988888 146637 solver.cpp:236] Iteration 4810, loss = 1.00048
I0721 16:20:48.989065 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:20:48.989106 146637 solver.cpp:252]     Train net output #1: loss = 0.974212 (* 1 = 0.974212 loss)
I0721 16:20:52.474908 146637 sgd_solver.cpp:106] Iteration 4810, lr = 0.01
I0721 16:21:39.521047 146637 solver.cpp:236] Iteration 4820, loss = 1.01541
I0721 16:21:39.522181 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:21:39.522208 146637 solver.cpp:252]     Train net output #1: loss = 0.939933 (* 1 = 0.939933 loss)
I0721 16:21:42.966976 146637 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0721 16:22:29.276229 146637 solver.cpp:236] Iteration 4830, loss = 1.00554
I0721 16:22:29.276409 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:22:29.276468 146637 solver.cpp:252]     Train net output #1: loss = 0.957628 (* 1 = 0.957628 loss)
I0721 16:22:33.132658 146637 sgd_solver.cpp:106] Iteration 4830, lr = 0.01
I0721 16:23:15.278231 146656 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 16:23:20.449368 146637 solver.cpp:236] Iteration 4840, loss = 1.01106
I0721 16:23:20.449429 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 16:23:20.449456 146637 solver.cpp:252]     Train net output #1: loss = 1.04195 (* 1 = 1.04195 loss)
I0721 16:23:23.937393 146637 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0721 16:24:10.808991 146637 solver.cpp:236] Iteration 4850, loss = 1.01589
I0721 16:24:10.809221 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 16:24:10.809253 146637 solver.cpp:252]     Train net output #1: loss = 1.18648 (* 1 = 1.18648 loss)
I0721 16:24:14.312146 146637 sgd_solver.cpp:106] Iteration 4850, lr = 0.01
I0721 16:25:01.903250 146637 solver.cpp:236] Iteration 4860, loss = 1.00879
I0721 16:25:01.903543 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:25:01.903610 146637 solver.cpp:252]     Train net output #1: loss = 0.919655 (* 1 = 0.919655 loss)
I0721 16:25:05.427676 146637 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0721 16:25:52.510870 146637 solver.cpp:236] Iteration 4870, loss = 0.992844
I0721 16:25:52.511137 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:25:52.511191 146637 solver.cpp:252]     Train net output #1: loss = 0.914006 (* 1 = 0.914006 loss)
I0721 16:25:55.915213 146637 sgd_solver.cpp:106] Iteration 4870, lr = 0.01
I0721 16:26:42.940515 146637 solver.cpp:236] Iteration 4880, loss = 0.997591
I0721 16:26:42.940699 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:26:42.940732 146637 solver.cpp:252]     Train net output #1: loss = 1.00523 (* 1 = 1.00523 loss)
I0721 16:26:46.535759 146637 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0721 16:27:33.095299 146637 solver.cpp:236] Iteration 4890, loss = 0.992098
I0721 16:27:33.095474 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:27:33.095505 146637 solver.cpp:252]     Train net output #1: loss = 0.992783 (* 1 = 0.992783 loss)
I0721 16:27:36.554760 146637 sgd_solver.cpp:106] Iteration 4890, lr = 0.01
I0721 16:28:18.158756 146637 solver.cpp:236] Iteration 4900, loss = 0.998224
I0721 16:28:18.158917 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:28:18.158937 146637 solver.cpp:252]     Train net output #1: loss = 1.05414 (* 1 = 1.05414 loss)
I0721 16:28:20.772636 146637 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0721 16:28:55.764503 146637 solver.cpp:236] Iteration 4910, loss = 0.995307
I0721 16:28:55.764710 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:28:55.764751 146637 solver.cpp:252]     Train net output #1: loss = 0.985694 (* 1 = 0.985694 loss)
I0721 16:28:58.699677 146637 sgd_solver.cpp:106] Iteration 4910, lr = 0.01
I0721 16:29:33.985905 146637 solver.cpp:236] Iteration 4920, loss = 1.01058
I0721 16:29:33.986078 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:29:33.986102 146637 solver.cpp:252]     Train net output #1: loss = 1.00885 (* 1 = 1.00885 loss)
I0721 16:29:36.848708 146637 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0721 16:30:12.015092 146637 solver.cpp:236] Iteration 4930, loss = 0.999476
I0721 16:30:12.015251 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 16:30:12.015275 146637 solver.cpp:252]     Train net output #1: loss = 0.836315 (* 1 = 0.836315 loss)
I0721 16:30:14.833446 146637 sgd_solver.cpp:106] Iteration 4930, lr = 0.01
I0721 16:30:49.548053 146637 solver.cpp:236] Iteration 4940, loss = 0.996848
I0721 16:30:49.548251 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:30:49.548274 146637 solver.cpp:252]     Train net output #1: loss = 1.00421 (* 1 = 1.00421 loss)
I0721 16:30:52.105625 146637 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0721 16:31:27.293969 146637 solver.cpp:236] Iteration 4950, loss = 0.989953
I0721 16:31:27.294162 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 16:31:27.294203 146637 solver.cpp:252]     Train net output #1: loss = 1.05343 (* 1 = 1.05343 loss)
I0721 16:31:30.119909 146637 sgd_solver.cpp:106] Iteration 4950, lr = 0.01
I0721 16:32:06.728446 146637 solver.cpp:236] Iteration 4960, loss = 0.994709
I0721 16:32:06.728694 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:32:06.728718 146637 solver.cpp:252]     Train net output #1: loss = 0.931123 (* 1 = 0.931123 loss)
I0721 16:32:09.634194 146637 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0721 16:32:48.465622 146637 solver.cpp:236] Iteration 4970, loss = 0.996701
I0721 16:32:48.465800 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 16:32:48.465822 146637 solver.cpp:252]     Train net output #1: loss = 1.05083 (* 1 = 1.05083 loss)
I0721 16:32:51.521222 146637 sgd_solver.cpp:106] Iteration 4970, lr = 0.01
I0721 16:33:30.096880 146637 solver.cpp:236] Iteration 4980, loss = 1.0102
I0721 16:33:30.097054 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:33:30.097084 146637 solver.cpp:252]     Train net output #1: loss = 0.971388 (* 1 = 0.971388 loss)
I0721 16:33:33.390761 146637 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0721 16:34:12.820757 146637 solver.cpp:236] Iteration 4990, loss = 1.01186
I0721 16:34:12.820973 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:34:12.821002 146637 solver.cpp:252]     Train net output #1: loss = 1.0249 (* 1 = 1.0249 loss)
I0721 16:34:16.251385 146637 sgd_solver.cpp:106] Iteration 4990, lr = 0.01
I0721 16:34:54.371963 146637 solver.cpp:461] Snapshotting to binary proto file models-resultlayer_iter_5000.caffemodel
I0721 16:34:54.414701 146637 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer_iter_5000.solverstate
I0721 16:34:55.473561 146637 solver.cpp:236] Iteration 5000, loss = 1.01822
I0721 16:34:55.473626 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 16:34:55.473649 146637 solver.cpp:252]     Train net output #1: loss = 0.821711 (* 1 = 0.821711 loss)
I0721 16:34:58.296882 146637 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0721 16:35:34.170788 146637 solver.cpp:236] Iteration 5010, loss = 1.01867
I0721 16:35:34.170977 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:35:34.171020 146637 solver.cpp:252]     Train net output #1: loss = 0.855079 (* 1 = 0.855079 loss)
I0721 16:35:37.091203 146637 sgd_solver.cpp:106] Iteration 5010, lr = 0.01
I0721 16:36:14.475739 146637 solver.cpp:236] Iteration 5020, loss = 1.01289
I0721 16:36:14.475978 146637 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0721 16:36:14.476013 146637 solver.cpp:252]     Train net output #1: loss = 0.869582 (* 1 = 0.869582 loss)
I0721 16:36:18.176132 146637 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0721 16:36:57.459928 146637 solver.cpp:236] Iteration 5030, loss = 1.001
I0721 16:36:57.460105 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:36:57.460153 146637 solver.cpp:252]     Train net output #1: loss = 0.939539 (* 1 = 0.939539 loss)
I0721 16:37:00.309963 146637 sgd_solver.cpp:106] Iteration 5030, lr = 0.01
I0721 16:37:39.154752 146637 solver.cpp:236] Iteration 5040, loss = 0.998414
I0721 16:37:39.154973 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:37:39.154999 146637 solver.cpp:252]     Train net output #1: loss = 0.940849 (* 1 = 0.940849 loss)
I0721 16:37:41.882350 146637 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0721 16:38:23.026156 146637 solver.cpp:236] Iteration 5050, loss = 0.992773
I0721 16:38:23.026329 146637 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0721 16:38:23.026370 146637 solver.cpp:252]     Train net output #1: loss = 1.14035 (* 1 = 1.14035 loss)
I0721 16:38:25.984155 146637 sgd_solver.cpp:106] Iteration 5050, lr = 0.01
I0721 16:39:07.105810 146637 solver.cpp:236] Iteration 5060, loss = 0.989935
I0721 16:39:07.106042 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:39:07.106077 146637 solver.cpp:252]     Train net output #1: loss = 0.936113 (* 1 = 0.936113 loss)
I0721 16:39:10.251384 146637 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0721 16:39:55.598000 146637 solver.cpp:236] Iteration 5070, loss = 0.986712
I0721 16:39:55.598273 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:39:55.598294 146637 solver.cpp:252]     Train net output #1: loss = 1.12237 (* 1 = 1.12237 loss)
I0721 16:39:58.802187 146637 sgd_solver.cpp:106] Iteration 5070, lr = 0.01
I0721 16:41:00.487349 146637 solver.cpp:236] Iteration 5080, loss = 0.98563
I0721 16:41:00.487702 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:41:00.487746 146637 solver.cpp:252]     Train net output #1: loss = 1.07961 (* 1 = 1.07961 loss)
I0721 16:41:04.052924 146637 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0721 16:41:58.454110 146637 solver.cpp:236] Iteration 5090, loss = 0.983696
I0721 16:41:58.454351 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:41:58.454393 146637 solver.cpp:252]     Train net output #1: loss = 0.844607 (* 1 = 0.844607 loss)
I0721 16:42:02.072212 146637 sgd_solver.cpp:106] Iteration 5090, lr = 0.01
I0721 16:42:52.300148 146637 solver.cpp:236] Iteration 5100, loss = 0.98546
I0721 16:42:52.300313 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:42:52.300339 146637 solver.cpp:252]     Train net output #1: loss = 0.978496 (* 1 = 0.978496 loss)
I0721 16:42:56.774857 146637 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0721 16:43:45.502507 146637 solver.cpp:236] Iteration 5110, loss = 0.994989
I0721 16:43:45.502895 146637 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0721 16:43:45.502936 146637 solver.cpp:252]     Train net output #1: loss = 1.25952 (* 1 = 1.25952 loss)
I0721 16:43:49.754750 146637 sgd_solver.cpp:106] Iteration 5110, lr = 0.01
I0721 16:44:37.888923 146637 solver.cpp:236] Iteration 5120, loss = 0.989821
I0721 16:44:37.889276 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:44:37.889312 146637 solver.cpp:252]     Train net output #1: loss = 0.842325 (* 1 = 0.842325 loss)
I0721 16:44:41.402487 146637 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0721 16:45:25.466259 146637 solver.cpp:236] Iteration 5130, loss = 1.00214
I0721 16:45:25.466536 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:45:25.466574 146637 solver.cpp:252]     Train net output #1: loss = 1.03572 (* 1 = 1.03572 loss)
I0721 16:45:29.190690 146637 sgd_solver.cpp:106] Iteration 5130, lr = 0.01
I0721 16:46:14.308900 146637 solver.cpp:236] Iteration 5140, loss = 0.996
I0721 16:46:14.309082 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:46:14.309105 146637 solver.cpp:252]     Train net output #1: loss = 1.15327 (* 1 = 1.15327 loss)
I0721 16:46:17.689656 146637 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0721 16:47:05.356923 146637 solver.cpp:236] Iteration 5150, loss = 0.99479
I0721 16:47:05.357149 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:47:05.357183 146637 solver.cpp:252]     Train net output #1: loss = 0.859477 (* 1 = 0.859477 loss)
I0721 16:47:08.775933 146637 sgd_solver.cpp:106] Iteration 5150, lr = 0.01
I0721 16:47:59.613229 146637 solver.cpp:236] Iteration 5160, loss = 0.99451
I0721 16:47:59.613487 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:47:59.613523 146637 solver.cpp:252]     Train net output #1: loss = 1.05149 (* 1 = 1.05149 loss)
I0721 16:48:03.721617 146637 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0721 16:48:51.801223 146637 solver.cpp:236] Iteration 5170, loss = 1.00057
I0721 16:48:51.801424 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:48:51.801462 146637 solver.cpp:252]     Train net output #1: loss = 0.967257 (* 1 = 0.967257 loss)
I0721 16:48:55.856272 146637 sgd_solver.cpp:106] Iteration 5170, lr = 0.01
I0721 16:49:04.727259 146655 blocking_queue.cpp:50] Data layer prefetch queue empty
I0721 16:49:51.724670 146637 solver.cpp:236] Iteration 5180, loss = 0.999248
I0721 16:49:51.724886 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:49:51.724927 146637 solver.cpp:252]     Train net output #1: loss = 1.16697 (* 1 = 1.16697 loss)
I0721 16:49:55.809382 146637 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0721 16:50:52.314504 146637 solver.cpp:236] Iteration 5190, loss = 1.00619
I0721 16:50:52.314767 146637 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0721 16:50:52.314841 146637 solver.cpp:252]     Train net output #1: loss = 1.10024 (* 1 = 1.10024 loss)
I0721 16:50:56.856514 146637 sgd_solver.cpp:106] Iteration 5190, lr = 0.01
I0721 16:51:53.545029 146637 solver.cpp:236] Iteration 5200, loss = 0.997288
I0721 16:51:53.545353 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 16:51:53.545434 146637 solver.cpp:252]     Train net output #1: loss = 0.895228 (* 1 = 0.895228 loss)
I0721 16:51:57.730602 146637 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0721 16:52:52.883692 146637 solver.cpp:236] Iteration 5210, loss = 0.99155
I0721 16:52:52.883929 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0721 16:52:52.883951 146637 solver.cpp:252]     Train net output #1: loss = 1.02554 (* 1 = 1.02554 loss)
I0721 16:52:56.513736 146637 sgd_solver.cpp:106] Iteration 5210, lr = 0.01
I0721 16:53:52.342231 146637 solver.cpp:236] Iteration 5220, loss = 0.987588
I0721 16:53:52.342412 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:53:52.342452 146637 solver.cpp:252]     Train net output #1: loss = 1.11615 (* 1 = 1.11615 loss)
I0721 16:53:56.659236 146637 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0721 16:54:52.877548 146637 solver.cpp:236] Iteration 5230, loss = 0.976531
I0721 16:54:52.877774 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 16:54:52.877806 146637 solver.cpp:252]     Train net output #1: loss = 0.922504 (* 1 = 0.922504 loss)
I0721 16:54:56.654294 146637 sgd_solver.cpp:106] Iteration 5230, lr = 0.01
I0721 16:55:54.732756 146637 solver.cpp:236] Iteration 5240, loss = 0.979596
I0721 16:55:54.732921 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:55:54.732946 146637 solver.cpp:252]     Train net output #1: loss = 0.922958 (* 1 = 0.922958 loss)
I0721 16:55:58.614040 146637 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0721 16:56:50.105859 146637 solver.cpp:236] Iteration 5250, loss = 0.980871
I0721 16:56:50.106007 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:56:50.106039 146637 solver.cpp:252]     Train net output #1: loss = 0.964807 (* 1 = 0.964807 loss)
I0721 16:56:53.716943 146637 sgd_solver.cpp:106] Iteration 5250, lr = 0.01
I0721 16:57:42.155571 146637 solver.cpp:236] Iteration 5260, loss = 0.984036
I0721 16:57:42.155769 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:57:42.155798 146637 solver.cpp:252]     Train net output #1: loss = 1.03891 (* 1 = 1.03891 loss)
I0721 16:57:45.978986 146637 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0721 16:58:38.486490 146637 solver.cpp:236] Iteration 5270, loss = 0.986048
I0721 16:58:38.486665 146637 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0721 16:58:38.486702 146637 solver.cpp:252]     Train net output #1: loss = 0.884724 (* 1 = 0.884724 loss)
I0721 16:58:42.255002 146637 sgd_solver.cpp:106] Iteration 5270, lr = 0.01
I0721 16:59:34.219259 146637 solver.cpp:236] Iteration 5280, loss = 0.995911
I0721 16:59:34.219447 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 16:59:34.219470 146637 solver.cpp:252]     Train net output #1: loss = 1.01954 (* 1 = 1.01954 loss)
I0721 16:59:37.671056 146637 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0721 17:00:27.983180 146637 solver.cpp:236] Iteration 5290, loss = 1.0023
I0721 17:00:27.983397 146637 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0721 17:00:27.983424 146637 solver.cpp:252]     Train net output #1: loss = 0.93534 (* 1 = 0.93534 loss)
I0721 17:00:31.842653 146637 sgd_solver.cpp:106] Iteration 5290, lr = 0.01
I0721 17:01:22.549257 146637 solver.cpp:236] Iteration 5300, loss = 1.01436
I0721 17:01:22.549437 146637 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0721 17:01:22.549469 146637 solver.cpp:252]     Train net output #1: loss = 1.04192 (* 1 = 1.04192 loss)
I0721 17:01:26.212034 146637 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0721 17:02:17.289182 146637 solver.cpp:236] Iteration 5310, loss = 1.01358
I0721 17:02:17.289371 146637 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0721 17:02:17.289394 146637 solver.cpp:252]     Train net output #1: loss = 0.795436 (* 1 = 0.795436 loss)
I0721 17:02:21.311458 146637 sgd_solver.cpp:106] Iteration 5310, lr = 0.01
I0721 17:03:11.416771 146637 solver.cpp:236] Iteration 5320, loss = 1.01299
I0721 17:03:11.417032 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 17:03:11.417054 146637 solver.cpp:252]     Train net output #1: loss = 0.984902 (* 1 = 0.984902 loss)
I0721 17:03:15.298195 146637 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0721 17:04:06.232059 146637 solver.cpp:236] Iteration 5330, loss = 1.01765
I0721 17:04:06.232303 146637 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0721 17:04:06.232374 146637 solver.cpp:252]     Train net output #1: loss = 1.00081 (* 1 = 1.00081 loss)
I0721 17:04:10.193619 146637 sgd_solver.cpp:106] Iteration 5330, lr = 0.01
I0721 17:05:00.148877 146637 solver.cpp:236] Iteration 5340, loss = 1.00682
