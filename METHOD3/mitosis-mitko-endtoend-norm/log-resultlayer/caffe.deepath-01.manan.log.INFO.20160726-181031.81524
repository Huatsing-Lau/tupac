Log file created at: 2016/07/26 18:10:31
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0726 18:10:31.802470 81524 caffe.cpp:184] Using GPUs 0, 1, 2, 3
I0726 18:10:32.087584 81524 solver.cpp:47] Initializing solver from parameters: 
test_iter: 250
test_interval: 100
base_lr: 0.01
display: 10
max_iter: 90000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 30000
snapshot: 1000
snapshot_prefix: "models-resultlayer/"
solver_mode: GPU
device_id: 0
net: "train_val-resultlayer-3stack.prototxt"
test_initialization: false
average_loss: 50
I0726 18:10:32.087833 81524 solver.cpp:90] Creating training net from net file: train_val-resultlayer-3stack.prototxt
I0726 18:10:32.088670 81524 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0726 18:10:32.088953 81524 net.cpp:49] Initializing net from parameters: 
name: "Result Layer 3 Stack"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 150
    mean_value: 150
    mean_value: 150
  }
  image_data_param {
    source: "../lists/mitosis_train-norm.lst"
    batch_size: 16
    shuffle: true
    new_height: 1000
    new_width: 1000
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 4
    stride: 1
  }
}
layer {
  name: "nonlin1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_c"
  type: "Convolution"
  bottom: "pool4"
  top: "ip1"
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "nonlin_ip1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "ip1"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0726 18:10:32.090574 81524 layer_factory.hpp:76] Creating layer data
I0726 18:10:32.090652 81524 net.cpp:106] Creating Layer data
I0726 18:10:32.090679 81524 net.cpp:411] data -> data
I0726 18:10:32.090718 81524 net.cpp:411] data -> label
I0726 18:10:32.091215 81524 image_data_layer.cpp:36] Opening file ../lists/mitosis_train-norm.lst
I0726 18:10:32.102470 81524 image_data_layer.cpp:46] Shuffling data
I0726 18:10:32.105108 81524 image_data_layer.cpp:51] A total of 21360 images.
I0726 18:10:32.164692 81524 image_data_layer.cpp:78] output data size: 16,3,1000,1000
I0726 18:10:32.716553 81524 net.cpp:150] Setting up data
I0726 18:10:32.716604 81524 net.cpp:157] Top shape: 16 3 1000 1000 (48000000)
I0726 18:10:32.716615 81524 net.cpp:157] Top shape: 16 (16)
I0726 18:10:32.716624 81524 net.cpp:165] Memory required for data: 192000064
I0726 18:10:32.716637 81524 layer_factory.hpp:76] Creating layer label_data_1_split
I0726 18:10:32.716660 81524 net.cpp:106] Creating Layer label_data_1_split
I0726 18:10:32.716670 81524 net.cpp:454] label_data_1_split <- label
I0726 18:10:32.716718 81524 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0726 18:10:32.716735 81524 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0726 18:10:32.716804 81524 net.cpp:150] Setting up label_data_1_split
I0726 18:10:32.716819 81524 net.cpp:157] Top shape: 16 (16)
I0726 18:10:32.716826 81524 net.cpp:157] Top shape: 16 (16)
I0726 18:10:32.716833 81524 net.cpp:165] Memory required for data: 192000192
I0726 18:10:32.716841 81524 layer_factory.hpp:76] Creating layer conv1
I0726 18:10:32.716861 81524 net.cpp:106] Creating Layer conv1
I0726 18:10:32.716869 81524 net.cpp:454] conv1 <- data
I0726 18:10:32.716879 81524 net.cpp:411] conv1 -> conv1
I0726 18:10:32.959614 81524 net.cpp:150] Setting up conv1
I0726 18:10:32.959678 81524 net.cpp:157] Top shape: 16 16 997 997 (254466304)
I0726 18:10:32.959688 81524 net.cpp:165] Memory required for data: 1209865408
I0726 18:10:32.959727 81524 layer_factory.hpp:76] Creating layer nonlin1
I0726 18:10:32.959758 81524 net.cpp:106] Creating Layer nonlin1
I0726 18:10:32.959769 81524 net.cpp:454] nonlin1 <- conv1
I0726 18:10:32.959781 81524 net.cpp:397] nonlin1 -> conv1 (in-place)
I0726 18:10:32.960074 81524 net.cpp:150] Setting up nonlin1
I0726 18:10:32.960091 81524 net.cpp:157] Top shape: 16 16 997 997 (254466304)
I0726 18:10:32.960100 81524 net.cpp:165] Memory required for data: 2227730624
I0726 18:10:32.960111 81524 layer_factory.hpp:76] Creating layer pool1
I0726 18:10:32.960129 81524 net.cpp:106] Creating Layer pool1
I0726 18:10:32.960136 81524 net.cpp:454] pool1 <- conv1
I0726 18:10:32.960149 81524 net.cpp:411] pool1 -> pool1
I0726 18:10:32.960690 81524 net.cpp:150] Setting up pool1
I0726 18:10:32.960711 81524 net.cpp:157] Top shape: 16 16 499 499 (63744256)
I0726 18:10:32.960718 81524 net.cpp:165] Memory required for data: 2482707648
I0726 18:10:32.960727 81524 layer_factory.hpp:76] Creating layer conv2
I0726 18:10:32.960746 81524 net.cpp:106] Creating Layer conv2
I0726 18:10:32.960754 81524 net.cpp:454] conv2 <- pool1
I0726 18:10:32.960767 81524 net.cpp:411] conv2 -> conv2
I0726 18:10:32.964263 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0726 18:10:32.964637 81524 net.cpp:150] Setting up conv2
I0726 18:10:32.964658 81524 net.cpp:157] Top shape: 16 16 497 497 (63234304)
I0726 18:10:32.964666 81524 net.cpp:165] Memory required for data: 2735644864
I0726 18:10:32.964686 81524 layer_factory.hpp:76] Creating layer nonlin2
I0726 18:10:32.964701 81524 net.cpp:106] Creating Layer nonlin2
I0726 18:10:32.964710 81524 net.cpp:454] nonlin2 <- conv2
I0726 18:10:32.964720 81524 net.cpp:397] nonlin2 -> conv2 (in-place)
I0726 18:10:32.964929 81524 net.cpp:150] Setting up nonlin2
I0726 18:10:32.964947 81524 net.cpp:157] Top shape: 16 16 497 497 (63234304)
I0726 18:10:32.964956 81524 net.cpp:165] Memory required for data: 2988582080
I0726 18:10:32.964975 81524 layer_factory.hpp:76] Creating layer pool2
I0726 18:10:32.964993 81524 net.cpp:106] Creating Layer pool2
I0726 18:10:32.965003 81524 net.cpp:454] pool2 <- conv2
I0726 18:10:32.965013 81524 net.cpp:411] pool2 -> pool2
I0726 18:10:32.965515 81524 net.cpp:150] Setting up pool2
I0726 18:10:32.965533 81524 net.cpp:157] Top shape: 16 16 249 249 (15872256)
I0726 18:10:32.965541 81524 net.cpp:165] Memory required for data: 3052071104
I0726 18:10:32.965551 81524 layer_factory.hpp:76] Creating layer conv3
I0726 18:10:32.965569 81524 net.cpp:106] Creating Layer conv3
I0726 18:10:32.965579 81524 net.cpp:454] conv3 <- pool2
I0726 18:10:32.965590 81524 net.cpp:411] conv3 -> conv3
I0726 18:10:32.967823 81524 net.cpp:150] Setting up conv3
I0726 18:10:32.967862 81524 net.cpp:157] Top shape: 16 16 247 247 (15618304)
I0726 18:10:32.967871 81524 net.cpp:165] Memory required for data: 3114544320
I0726 18:10:32.967890 81524 layer_factory.hpp:76] Creating layer nonlin3
I0726 18:10:32.967902 81524 net.cpp:106] Creating Layer nonlin3
I0726 18:10:32.967911 81524 net.cpp:454] nonlin3 <- conv3
I0726 18:10:32.967933 81524 net.cpp:397] nonlin3 -> conv3 (in-place)
I0726 18:10:32.968134 81524 net.cpp:150] Setting up nonlin3
I0726 18:10:32.968204 81524 net.cpp:157] Top shape: 16 16 247 247 (15618304)
I0726 18:10:32.968214 81524 net.cpp:165] Memory required for data: 3177017536
I0726 18:10:32.968222 81524 layer_factory.hpp:76] Creating layer pool3
I0726 18:10:32.968238 81524 net.cpp:106] Creating Layer pool3
I0726 18:10:32.968257 81524 net.cpp:454] pool3 <- conv3
I0726 18:10:32.968269 81524 net.cpp:411] pool3 -> pool3
I0726 18:10:32.968775 81524 net.cpp:150] Setting up pool3
I0726 18:10:32.968796 81524 net.cpp:157] Top shape: 16 16 124 124 (3936256)
I0726 18:10:32.968806 81524 net.cpp:165] Memory required for data: 3192762560
I0726 18:10:32.968816 81524 layer_factory.hpp:76] Creating layer conv4
I0726 18:10:32.968832 81524 net.cpp:106] Creating Layer conv4
I0726 18:10:32.968840 81524 net.cpp:454] conv4 <- pool3
I0726 18:10:32.968852 81524 net.cpp:411] conv4 -> conv4
I0726 18:10:32.970794 81524 net.cpp:150] Setting up conv4
I0726 18:10:32.970818 81524 net.cpp:157] Top shape: 16 16 122 122 (3810304)
I0726 18:10:32.970830 81524 net.cpp:165] Memory required for data: 3208003776
I0726 18:10:32.970842 81524 layer_factory.hpp:76] Creating layer nonlin4
I0726 18:10:32.970854 81524 net.cpp:106] Creating Layer nonlin4
I0726 18:10:32.970862 81524 net.cpp:454] nonlin4 <- conv4
I0726 18:10:32.970872 81524 net.cpp:397] nonlin4 -> conv4 (in-place)
I0726 18:10:32.971297 81524 net.cpp:150] Setting up nonlin4
I0726 18:10:32.971320 81524 net.cpp:157] Top shape: 16 16 122 122 (3810304)
I0726 18:10:32.971328 81524 net.cpp:165] Memory required for data: 3223244992
I0726 18:10:32.971336 81524 layer_factory.hpp:76] Creating layer pool4
I0726 18:10:32.971349 81524 net.cpp:106] Creating Layer pool4
I0726 18:10:32.971357 81524 net.cpp:454] pool4 <- conv4
I0726 18:10:32.971366 81524 net.cpp:411] pool4 -> pool4
I0726 18:10:32.971868 81524 net.cpp:150] Setting up pool4
I0726 18:10:32.971887 81524 net.cpp:157] Top shape: 16 16 61 61 (952576)
I0726 18:10:32.971895 81524 net.cpp:165] Memory required for data: 3227055296
I0726 18:10:32.971904 81524 layer_factory.hpp:76] Creating layer ip1_c
I0726 18:10:32.971915 81524 net.cpp:106] Creating Layer ip1_c
I0726 18:10:32.971923 81524 net.cpp:454] ip1_c <- pool4
I0726 18:10:32.971935 81524 net.cpp:411] ip1_c -> ip1
I0726 18:10:32.972892 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0726 18:10:32.972924 81524 net.cpp:150] Setting up ip1_c
I0726 18:10:32.972936 81524 net.cpp:157] Top shape: 16 200 60 60 (11520000)
I0726 18:10:32.972944 81524 net.cpp:165] Memory required for data: 3273135296
I0726 18:10:32.972960 81524 layer_factory.hpp:76] Creating layer nonlin_ip1
I0726 18:10:32.972971 81524 net.cpp:106] Creating Layer nonlin_ip1
I0726 18:10:32.972978 81524 net.cpp:454] nonlin_ip1 <- ip1
I0726 18:10:32.972990 81524 net.cpp:397] nonlin_ip1 -> ip1 (in-place)
I0726 18:10:32.973429 81524 net.cpp:150] Setting up nonlin_ip1
I0726 18:10:32.973448 81524 net.cpp:157] Top shape: 16 200 60 60 (11520000)
I0726 18:10:32.973455 81524 net.cpp:165] Memory required for data: 3319215296
I0726 18:10:32.973465 81524 layer_factory.hpp:76] Creating layer conv61
I0726 18:10:32.973486 81524 net.cpp:106] Creating Layer conv61
I0726 18:10:32.973495 81524 net.cpp:454] conv61 <- ip1
I0726 18:10:32.973506 81524 net.cpp:411] conv61 -> conv61
I0726 18:10:32.976229 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21600
I0726 18:10:32.976263 81524 net.cpp:150] Setting up conv61
I0726 18:10:32.976275 81524 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0726 18:10:32.976284 81524 net.cpp:165] Memory required for data: 3333960896
I0726 18:10:32.976294 81524 layer_factory.hpp:76] Creating layer relu61
I0726 18:10:32.976305 81524 net.cpp:106] Creating Layer relu61
I0726 18:10:32.976313 81524 net.cpp:454] relu61 <- conv61
I0726 18:10:32.976336 81524 net.cpp:397] relu61 -> conv61 (in-place)
I0726 18:10:32.976550 81524 net.cpp:150] Setting up relu61
I0726 18:10:32.976569 81524 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0726 18:10:32.976577 81524 net.cpp:165] Memory required for data: 3348706496
I0726 18:10:32.976634 81524 layer_factory.hpp:76] Creating layer conv62
I0726 18:10:32.976657 81524 net.cpp:106] Creating Layer conv62
I0726 18:10:32.976667 81524 net.cpp:454] conv62 <- conv61
I0726 18:10:32.976680 81524 net.cpp:411] conv62 -> conv62
I0726 18:10:32.978440 81524 net.cpp:150] Setting up conv62
I0726 18:10:32.978472 81524 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0726 18:10:32.978482 81524 net.cpp:165] Memory required for data: 3363452096
I0726 18:10:32.978493 81524 layer_factory.hpp:76] Creating layer relu62
I0726 18:10:32.978507 81524 net.cpp:106] Creating Layer relu62
I0726 18:10:32.978516 81524 net.cpp:454] relu62 <- conv62
I0726 18:10:32.978525 81524 net.cpp:397] relu62 -> conv62 (in-place)
I0726 18:10:32.978982 81524 net.cpp:150] Setting up relu62
I0726 18:10:32.979012 81524 net.cpp:157] Top shape: 16 64 60 60 (3686400)
I0726 18:10:32.979024 81524 net.cpp:165] Memory required for data: 3378197696
I0726 18:10:32.979033 81524 layer_factory.hpp:76] Creating layer pool5
I0726 18:10:32.979045 81524 net.cpp:106] Creating Layer pool5
I0726 18:10:32.979054 81524 net.cpp:454] pool5 <- conv62
I0726 18:10:32.979064 81524 net.cpp:411] pool5 -> pool5
I0726 18:10:32.979302 81524 net.cpp:150] Setting up pool5
I0726 18:10:32.979331 81524 net.cpp:157] Top shape: 16 64 30 30 (921600)
I0726 18:10:32.979338 81524 net.cpp:165] Memory required for data: 3381884096
I0726 18:10:32.979348 81524 layer_factory.hpp:76] Creating layer conv71
I0726 18:10:32.979362 81524 net.cpp:106] Creating Layer conv71
I0726 18:10:32.979372 81524 net.cpp:454] conv71 <- pool5
I0726 18:10:32.979383 81524 net.cpp:411] conv71 -> conv71
I0726 18:10:32.980981 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0726 18:10:32.981411 81524 net.cpp:150] Setting up conv71
I0726 18:10:32.981441 81524 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0726 18:10:32.981451 81524 net.cpp:165] Memory required for data: 3387413696
I0726 18:10:32.981465 81524 layer_factory.hpp:76] Creating layer relu71
I0726 18:10:32.981477 81524 net.cpp:106] Creating Layer relu71
I0726 18:10:32.981484 81524 net.cpp:454] relu71 <- conv71
I0726 18:10:32.981497 81524 net.cpp:397] relu71 -> conv71 (in-place)
I0726 18:10:32.981726 81524 net.cpp:150] Setting up relu71
I0726 18:10:32.981753 81524 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0726 18:10:32.981761 81524 net.cpp:165] Memory required for data: 3392943296
I0726 18:10:32.981772 81524 layer_factory.hpp:76] Creating layer conv72
I0726 18:10:32.981787 81524 net.cpp:106] Creating Layer conv72
I0726 18:10:32.981796 81524 net.cpp:454] conv72 <- conv71
I0726 18:10:32.981808 81524 net.cpp:411] conv72 -> conv72
I0726 18:10:32.983536 81524 net.cpp:150] Setting up conv72
I0726 18:10:32.983566 81524 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0726 18:10:32.983575 81524 net.cpp:165] Memory required for data: 3398472896
I0726 18:10:32.983593 81524 layer_factory.hpp:76] Creating layer relu72
I0726 18:10:32.983606 81524 net.cpp:106] Creating Layer relu72
I0726 18:10:32.983615 81524 net.cpp:454] relu72 <- conv72
I0726 18:10:32.983624 81524 net.cpp:397] relu72 -> conv72 (in-place)
I0726 18:10:32.984128 81524 net.cpp:150] Setting up relu72
I0726 18:10:32.984158 81524 net.cpp:157] Top shape: 16 96 30 30 (1382400)
I0726 18:10:32.984166 81524 net.cpp:165] Memory required for data: 3404002496
I0726 18:10:32.984174 81524 layer_factory.hpp:76] Creating layer pool6
I0726 18:10:32.984185 81524 net.cpp:106] Creating Layer pool6
I0726 18:10:32.984194 81524 net.cpp:454] pool6 <- conv72
I0726 18:10:32.984206 81524 net.cpp:411] pool6 -> pool6
I0726 18:10:32.984458 81524 net.cpp:150] Setting up pool6
I0726 18:10:32.984485 81524 net.cpp:157] Top shape: 16 96 15 15 (345600)
I0726 18:10:32.984493 81524 net.cpp:165] Memory required for data: 3405384896
I0726 18:10:32.984503 81524 layer_factory.hpp:76] Creating layer conv81
I0726 18:10:32.984519 81524 net.cpp:106] Creating Layer conv81
I0726 18:10:32.984526 81524 net.cpp:454] conv81 <- pool6
I0726 18:10:32.984539 81524 net.cpp:411] conv81 -> conv81
I0726 18:10:32.987274 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0726 18:10:32.987341 81524 net.cpp:150] Setting up conv81
I0726 18:10:32.987354 81524 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0726 18:10:32.987362 81524 net.cpp:165] Memory required for data: 3407228096
I0726 18:10:32.987375 81524 layer_factory.hpp:76] Creating layer relu81
I0726 18:10:32.987387 81524 net.cpp:106] Creating Layer relu81
I0726 18:10:32.987396 81524 net.cpp:454] relu81 <- conv81
I0726 18:10:32.987408 81524 net.cpp:397] relu81 -> conv81 (in-place)
I0726 18:10:32.987889 81524 net.cpp:150] Setting up relu81
I0726 18:10:32.987918 81524 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0726 18:10:32.987926 81524 net.cpp:165] Memory required for data: 3409071296
I0726 18:10:32.987936 81524 layer_factory.hpp:76] Creating layer conv82
I0726 18:10:32.987951 81524 net.cpp:106] Creating Layer conv82
I0726 18:10:32.987959 81524 net.cpp:454] conv82 <- conv81
I0726 18:10:32.987972 81524 net.cpp:411] conv82 -> conv82
I0726 18:10:32.989912 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0726 18:10:32.989956 81524 net.cpp:150] Setting up conv82
I0726 18:10:32.989967 81524 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0726 18:10:32.989975 81524 net.cpp:165] Memory required for data: 3410914496
I0726 18:10:32.989987 81524 layer_factory.hpp:76] Creating layer relu82
I0726 18:10:32.990000 81524 net.cpp:106] Creating Layer relu82
I0726 18:10:32.990010 81524 net.cpp:454] relu82 <- conv82
I0726 18:10:32.990020 81524 net.cpp:397] relu82 -> conv82 (in-place)
I0726 18:10:32.990475 81524 net.cpp:150] Setting up relu82
I0726 18:10:32.990504 81524 net.cpp:157] Top shape: 16 128 15 15 (460800)
I0726 18:10:32.990514 81524 net.cpp:165] Memory required for data: 3412757696
I0726 18:10:32.990521 81524 layer_factory.hpp:76] Creating layer pool7
I0726 18:10:32.990536 81524 net.cpp:106] Creating Layer pool7
I0726 18:10:32.990545 81524 net.cpp:454] pool7 <- conv82
I0726 18:10:32.990556 81524 net.cpp:411] pool7 -> pool7
I0726 18:10:32.990792 81524 net.cpp:150] Setting up pool7
I0726 18:10:32.990818 81524 net.cpp:157] Top shape: 16 128 8 8 (131072)
I0726 18:10:32.990839 81524 net.cpp:165] Memory required for data: 3413281984
I0726 18:10:32.990847 81524 layer_factory.hpp:76] Creating layer drop0
I0726 18:10:32.990865 81524 net.cpp:106] Creating Layer drop0
I0726 18:10:32.990875 81524 net.cpp:454] drop0 <- pool7
I0726 18:10:32.990883 81524 net.cpp:397] drop0 -> pool7 (in-place)
I0726 18:10:32.990932 81524 net.cpp:150] Setting up drop0
I0726 18:10:32.990945 81524 net.cpp:157] Top shape: 16 128 8 8 (131072)
I0726 18:10:32.990954 81524 net.cpp:165] Memory required for data: 3413806272
I0726 18:10:32.990962 81524 layer_factory.hpp:76] Creating layer conv91
I0726 18:10:32.990984 81524 net.cpp:106] Creating Layer conv91
I0726 18:10:32.990995 81524 net.cpp:454] conv91 <- pool7
I0726 18:10:32.991020 81524 net.cpp:411] conv91 -> conv91
I0726 18:10:32.992435 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0726 18:10:32.992830 81524 net.cpp:150] Setting up conv91
I0726 18:10:32.992859 81524 net.cpp:157] Top shape: 16 3 1 1 (48)
I0726 18:10:32.992867 81524 net.cpp:165] Memory required for data: 3413806464
I0726 18:10:32.992880 81524 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0726 18:10:32.992895 81524 net.cpp:106] Creating Layer conv91_conv91_0_split
I0726 18:10:32.992904 81524 net.cpp:454] conv91_conv91_0_split <- conv91
I0726 18:10:32.992914 81524 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0726 18:10:32.992925 81524 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0726 18:10:32.992985 81524 net.cpp:150] Setting up conv91_conv91_0_split
I0726 18:10:32.992998 81524 net.cpp:157] Top shape: 16 3 1 1 (48)
I0726 18:10:32.993007 81524 net.cpp:157] Top shape: 16 3 1 1 (48)
I0726 18:10:32.993016 81524 net.cpp:165] Memory required for data: 3413806848
I0726 18:10:32.993023 81524 layer_factory.hpp:76] Creating layer accuracy
I0726 18:10:32.993041 81524 net.cpp:106] Creating Layer accuracy
I0726 18:10:32.993049 81524 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0726 18:10:32.993083 81524 net.cpp:454] accuracy <- label_data_1_split_0
I0726 18:10:32.993093 81524 net.cpp:411] accuracy -> accuracy
I0726 18:10:32.993110 81524 net.cpp:150] Setting up accuracy
I0726 18:10:32.993124 81524 net.cpp:157] Top shape: (1)
I0726 18:10:32.993131 81524 net.cpp:165] Memory required for data: 3413806852
I0726 18:10:32.993139 81524 layer_factory.hpp:76] Creating layer loss
I0726 18:10:32.993151 81524 net.cpp:106] Creating Layer loss
I0726 18:10:32.993160 81524 net.cpp:454] loss <- conv91_conv91_0_split_1
I0726 18:10:32.993168 81524 net.cpp:454] loss <- label_data_1_split_1
I0726 18:10:32.993192 81524 net.cpp:411] loss -> loss
I0726 18:10:32.993211 81524 layer_factory.hpp:76] Creating layer loss
I0726 18:10:32.993782 81524 net.cpp:150] Setting up loss
I0726 18:10:32.993813 81524 net.cpp:157] Top shape: (1)
I0726 18:10:32.993820 81524 net.cpp:160]     with loss weight 1
I0726 18:10:32.993857 81524 net.cpp:165] Memory required for data: 3413806856
I0726 18:10:32.993878 81524 net.cpp:226] loss needs backward computation.
I0726 18:10:32.993887 81524 net.cpp:228] accuracy does not need backward computation.
I0726 18:10:32.993897 81524 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0726 18:10:32.993906 81524 net.cpp:226] conv91 needs backward computation.
I0726 18:10:32.993924 81524 net.cpp:226] drop0 needs backward computation.
I0726 18:10:32.993932 81524 net.cpp:226] pool7 needs backward computation.
I0726 18:10:32.993940 81524 net.cpp:226] relu82 needs backward computation.
I0726 18:10:32.993947 81524 net.cpp:226] conv82 needs backward computation.
I0726 18:10:32.993955 81524 net.cpp:226] relu81 needs backward computation.
I0726 18:10:32.993973 81524 net.cpp:226] conv81 needs backward computation.
I0726 18:10:32.993981 81524 net.cpp:226] pool6 needs backward computation.
I0726 18:10:32.994001 81524 net.cpp:226] relu72 needs backward computation.
I0726 18:10:32.994009 81524 net.cpp:226] conv72 needs backward computation.
I0726 18:10:32.994017 81524 net.cpp:226] relu71 needs backward computation.
I0726 18:10:32.994024 81524 net.cpp:226] conv71 needs backward computation.
I0726 18:10:32.994032 81524 net.cpp:226] pool5 needs backward computation.
I0726 18:10:32.994041 81524 net.cpp:226] relu62 needs backward computation.
I0726 18:10:32.994060 81524 net.cpp:226] conv62 needs backward computation.
I0726 18:10:32.994068 81524 net.cpp:226] relu61 needs backward computation.
I0726 18:10:32.994076 81524 net.cpp:226] conv61 needs backward computation.
I0726 18:10:32.994084 81524 net.cpp:226] nonlin_ip1 needs backward computation.
I0726 18:10:32.994092 81524 net.cpp:226] ip1_c needs backward computation.
I0726 18:10:32.994101 81524 net.cpp:228] pool4 does not need backward computation.
I0726 18:10:32.994108 81524 net.cpp:228] nonlin4 does not need backward computation.
I0726 18:10:32.994117 81524 net.cpp:228] conv4 does not need backward computation.
I0726 18:10:32.994124 81524 net.cpp:228] pool3 does not need backward computation.
I0726 18:10:32.994132 81524 net.cpp:228] nonlin3 does not need backward computation.
I0726 18:10:32.994140 81524 net.cpp:228] conv3 does not need backward computation.
I0726 18:10:32.994148 81524 net.cpp:228] pool2 does not need backward computation.
I0726 18:10:32.994156 81524 net.cpp:228] nonlin2 does not need backward computation.
I0726 18:10:32.994164 81524 net.cpp:228] conv2 does not need backward computation.
I0726 18:10:32.994175 81524 net.cpp:228] pool1 does not need backward computation.
I0726 18:10:32.994184 81524 net.cpp:228] nonlin1 does not need backward computation.
I0726 18:10:32.994191 81524 net.cpp:228] conv1 does not need backward computation.
I0726 18:10:32.994200 81524 net.cpp:228] label_data_1_split does not need backward computation.
I0726 18:10:32.994209 81524 net.cpp:228] data does not need backward computation.
I0726 18:10:32.994216 81524 net.cpp:270] This network produces output accuracy
I0726 18:10:32.994225 81524 net.cpp:270] This network produces output loss
I0726 18:10:32.994252 81524 net.cpp:283] Network initialization done.
I0726 18:10:32.995121 81524 solver.cpp:180] Creating test net (#0) specified by net file: train_val-resultlayer-3stack.prototxt
I0726 18:10:32.995198 81524 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0726 18:10:32.995470 81524 net.cpp:49] Initializing net from parameters: 
name: "Result Layer 3 Stack"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 150
    mean_value: 150
    mean_value: 150
  }
  image_data_param {
    source: "../lists/mitosis_val-norm.lst"
    batch_size: 8
    shuffle: true
    new_height: 1000
    new_width: 1000
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 4
    stride: 1
  }
}
layer {
  name: "nonlin1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "nonlin4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_c"
  type: "Convolution"
  bottom: "pool4"
  top: "ip1"
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "nonlin_ip1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "conv61"
  type: "Convolution"
  bottom: "ip1"
  top: "conv61"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu61"
  type: "ReLU"
  bottom: "conv61"
  top: "conv61"
}
layer {
  name: "conv62"
  type: "Convolution"
  bottom: "conv61"
  top: "conv62"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu62"
  type: "ReLU"
  bottom: "conv62"
  top: "conv62"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv62"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "pool5"
  top: "conv71"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu71"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "conv72"
  type: "Convolution"
  bottom: "conv71"
  top: "conv72"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu72"
  type: "ReLU"
  bottom: "conv72"
  top: "conv72"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv72"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv81"
  type: "Convolution"
  bottom: "pool6"
  top: "conv81"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu81"
  type: "ReLU"
  bottom: "conv81"
  top: "conv81"
}
layer {
  name: "conv82"
  type: "Convolution"
  bottom: "conv81"
  top: "conv82"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "relu82"
  type: "ReLU"
  bottom: "conv82"
  top: "conv82"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv82"
  top: "pool7"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop0"
  type: "Dropout"
  bottom: "pool7"
  top: "pool7"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "pool7"
  top: "conv91"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv91"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv91"
  bottom: "label"
  top: "loss"
}
I0726 18:10:32.996997 81524 layer_factory.hpp:76] Creating layer data
I0726 18:10:32.997046 81524 net.cpp:106] Creating Layer data
I0726 18:10:32.997057 81524 net.cpp:411] data -> data
I0726 18:10:32.997071 81524 net.cpp:411] data -> label
I0726 18:10:32.997097 81524 image_data_layer.cpp:36] Opening file ../lists/mitosis_val-norm.lst
I0726 18:10:32.998438 81524 image_data_layer.cpp:46] Shuffling data
I0726 18:10:32.998670 81524 image_data_layer.cpp:51] A total of 2374 images.
I0726 18:10:33.045675 81524 image_data_layer.cpp:78] output data size: 8,3,1000,1000
I0726 18:10:33.339386 81524 net.cpp:150] Setting up data
I0726 18:10:33.339440 81524 net.cpp:157] Top shape: 8 3 1000 1000 (24000000)
I0726 18:10:33.339455 81524 net.cpp:157] Top shape: 8 (8)
I0726 18:10:33.339464 81524 net.cpp:165] Memory required for data: 96000032
I0726 18:10:33.339479 81524 layer_factory.hpp:76] Creating layer label_data_1_split
I0726 18:10:33.339499 81524 net.cpp:106] Creating Layer label_data_1_split
I0726 18:10:33.339510 81524 net.cpp:454] label_data_1_split <- label
I0726 18:10:33.339524 81524 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0726 18:10:33.339552 81524 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0726 18:10:33.339643 81524 net.cpp:150] Setting up label_data_1_split
I0726 18:10:33.339658 81524 net.cpp:157] Top shape: 8 (8)
I0726 18:10:33.339666 81524 net.cpp:157] Top shape: 8 (8)
I0726 18:10:33.339720 81524 net.cpp:165] Memory required for data: 96000096
I0726 18:10:33.339731 81524 layer_factory.hpp:76] Creating layer conv1
I0726 18:10:33.339756 81524 net.cpp:106] Creating Layer conv1
I0726 18:10:33.339766 81524 net.cpp:454] conv1 <- data
I0726 18:10:33.339779 81524 net.cpp:411] conv1 -> conv1
I0726 18:10:33.343698 81524 net.cpp:150] Setting up conv1
I0726 18:10:33.343727 81524 net.cpp:157] Top shape: 8 16 997 997 (127233152)
I0726 18:10:33.343737 81524 net.cpp:165] Memory required for data: 604932704
I0726 18:10:33.343755 81524 layer_factory.hpp:76] Creating layer nonlin1
I0726 18:10:33.343771 81524 net.cpp:106] Creating Layer nonlin1
I0726 18:10:33.343791 81524 net.cpp:454] nonlin1 <- conv1
I0726 18:10:33.343802 81524 net.cpp:397] nonlin1 -> conv1 (in-place)
I0726 18:10:33.344020 81524 net.cpp:150] Setting up nonlin1
I0726 18:10:33.344038 81524 net.cpp:157] Top shape: 8 16 997 997 (127233152)
I0726 18:10:33.344050 81524 net.cpp:165] Memory required for data: 1113865312
I0726 18:10:33.344060 81524 layer_factory.hpp:76] Creating layer pool1
I0726 18:10:33.344079 81524 net.cpp:106] Creating Layer pool1
I0726 18:10:33.344089 81524 net.cpp:454] pool1 <- conv1
I0726 18:10:33.344102 81524 net.cpp:411] pool1 -> pool1
I0726 18:10:33.344573 81524 net.cpp:150] Setting up pool1
I0726 18:10:33.344594 81524 net.cpp:157] Top shape: 8 16 499 499 (31872128)
I0726 18:10:33.344604 81524 net.cpp:165] Memory required for data: 1241353824
I0726 18:10:33.344614 81524 layer_factory.hpp:76] Creating layer conv2
I0726 18:10:33.344631 81524 net.cpp:106] Creating Layer conv2
I0726 18:10:33.344641 81524 net.cpp:454] conv2 <- pool1
I0726 18:10:33.344653 81524 net.cpp:411] conv2 -> conv2
I0726 18:10:33.346892 81524 net.cpp:150] Setting up conv2
I0726 18:10:33.346915 81524 net.cpp:157] Top shape: 8 16 497 497 (31617152)
I0726 18:10:33.346927 81524 net.cpp:165] Memory required for data: 1367822432
I0726 18:10:33.346942 81524 layer_factory.hpp:76] Creating layer nonlin2
I0726 18:10:33.346956 81524 net.cpp:106] Creating Layer nonlin2
I0726 18:10:33.346966 81524 net.cpp:454] nonlin2 <- conv2
I0726 18:10:33.346976 81524 net.cpp:397] nonlin2 -> conv2 (in-place)
I0726 18:10:33.347158 81524 net.cpp:150] Setting up nonlin2
I0726 18:10:33.347175 81524 net.cpp:157] Top shape: 8 16 497 497 (31617152)
I0726 18:10:33.347185 81524 net.cpp:165] Memory required for data: 1494291040
I0726 18:10:33.347194 81524 layer_factory.hpp:76] Creating layer pool2
I0726 18:10:33.347211 81524 net.cpp:106] Creating Layer pool2
I0726 18:10:33.347221 81524 net.cpp:454] pool2 <- conv2
I0726 18:10:33.347234 81524 net.cpp:411] pool2 -> pool2
I0726 18:10:33.347692 81524 net.cpp:150] Setting up pool2
I0726 18:10:33.347712 81524 net.cpp:157] Top shape: 8 16 249 249 (7936128)
I0726 18:10:33.347723 81524 net.cpp:165] Memory required for data: 1526035552
I0726 18:10:33.347733 81524 layer_factory.hpp:76] Creating layer conv3
I0726 18:10:33.347750 81524 net.cpp:106] Creating Layer conv3
I0726 18:10:33.347761 81524 net.cpp:454] conv3 <- pool2
I0726 18:10:33.347774 81524 net.cpp:411] conv3 -> conv3
I0726 18:10:33.348706 81524 net.cpp:150] Setting up conv3
I0726 18:10:33.348727 81524 net.cpp:157] Top shape: 8 16 247 247 (7809152)
I0726 18:10:33.348738 81524 net.cpp:165] Memory required for data: 1557272160
I0726 18:10:33.348754 81524 layer_factory.hpp:76] Creating layer nonlin3
I0726 18:10:33.348770 81524 net.cpp:106] Creating Layer nonlin3
I0726 18:10:33.348781 81524 net.cpp:454] nonlin3 <- conv3
I0726 18:10:33.348793 81524 net.cpp:397] nonlin3 -> conv3 (in-place)
I0726 18:10:33.349210 81524 net.cpp:150] Setting up nonlin3
I0726 18:10:33.349230 81524 net.cpp:157] Top shape: 8 16 247 247 (7809152)
I0726 18:10:33.349241 81524 net.cpp:165] Memory required for data: 1588508768
I0726 18:10:33.349251 81524 layer_factory.hpp:76] Creating layer pool3
I0726 18:10:33.349266 81524 net.cpp:106] Creating Layer pool3
I0726 18:10:33.349275 81524 net.cpp:454] pool3 <- conv3
I0726 18:10:33.349287 81524 net.cpp:411] pool3 -> pool3
I0726 18:10:33.349493 81524 net.cpp:150] Setting up pool3
I0726 18:10:33.349542 81524 net.cpp:157] Top shape: 8 16 124 124 (1968128)
I0726 18:10:33.349553 81524 net.cpp:165] Memory required for data: 1596381280
I0726 18:10:33.349563 81524 layer_factory.hpp:76] Creating layer conv4
I0726 18:10:33.349581 81524 net.cpp:106] Creating Layer conv4
I0726 18:10:33.349591 81524 net.cpp:454] conv4 <- pool3
I0726 18:10:33.349602 81524 net.cpp:411] conv4 -> conv4
I0726 18:10:33.350745 81524 net.cpp:150] Setting up conv4
I0726 18:10:33.350767 81524 net.cpp:157] Top shape: 8 16 122 122 (1905152)
I0726 18:10:33.350777 81524 net.cpp:165] Memory required for data: 1604001888
I0726 18:10:33.350790 81524 layer_factory.hpp:76] Creating layer nonlin4
I0726 18:10:33.350803 81524 net.cpp:106] Creating Layer nonlin4
I0726 18:10:33.350813 81524 net.cpp:454] nonlin4 <- conv4
I0726 18:10:33.350826 81524 net.cpp:397] nonlin4 -> conv4 (in-place)
I0726 18:10:33.351241 81524 net.cpp:150] Setting up nonlin4
I0726 18:10:33.351259 81524 net.cpp:157] Top shape: 8 16 122 122 (1905152)
I0726 18:10:33.351269 81524 net.cpp:165] Memory required for data: 1611622496
I0726 18:10:33.351279 81524 layer_factory.hpp:76] Creating layer pool4
I0726 18:10:33.351295 81524 net.cpp:106] Creating Layer pool4
I0726 18:10:33.351305 81524 net.cpp:454] pool4 <- conv4
I0726 18:10:33.351316 81524 net.cpp:411] pool4 -> pool4
I0726 18:10:33.351522 81524 net.cpp:150] Setting up pool4
I0726 18:10:33.351539 81524 net.cpp:157] Top shape: 8 16 61 61 (476288)
I0726 18:10:33.351549 81524 net.cpp:165] Memory required for data: 1613527648
I0726 18:10:33.351558 81524 layer_factory.hpp:76] Creating layer ip1_c
I0726 18:10:33.351573 81524 net.cpp:106] Creating Layer ip1_c
I0726 18:10:33.351584 81524 net.cpp:454] ip1_c <- pool4
I0726 18:10:33.351598 81524 net.cpp:411] ip1_c -> ip1
I0726 18:10:33.352754 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 22118400
I0726 18:10:33.353001 81524 net.cpp:150] Setting up ip1_c
I0726 18:10:33.353019 81524 net.cpp:157] Top shape: 8 200 60 60 (5760000)
I0726 18:10:33.353030 81524 net.cpp:165] Memory required for data: 1636567648
I0726 18:10:33.353046 81524 layer_factory.hpp:76] Creating layer nonlin_ip1
I0726 18:10:33.353060 81524 net.cpp:106] Creating Layer nonlin_ip1
I0726 18:10:33.353070 81524 net.cpp:454] nonlin_ip1 <- ip1
I0726 18:10:33.353083 81524 net.cpp:397] nonlin_ip1 -> ip1 (in-place)
I0726 18:10:33.353513 81524 net.cpp:150] Setting up nonlin_ip1
I0726 18:10:33.353533 81524 net.cpp:157] Top shape: 8 200 60 60 (5760000)
I0726 18:10:33.353543 81524 net.cpp:165] Memory required for data: 1659607648
I0726 18:10:33.353551 81524 layer_factory.hpp:76] Creating layer conv61
I0726 18:10:33.353574 81524 net.cpp:106] Creating Layer conv61
I0726 18:10:33.353585 81524 net.cpp:454] conv61 <- ip1
I0726 18:10:33.353597 81524 net.cpp:411] conv61 -> conv61
I0726 18:10:33.355991 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21600
I0726 18:10:33.356021 81524 net.cpp:150] Setting up conv61
I0726 18:10:33.356040 81524 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0726 18:10:33.356050 81524 net.cpp:165] Memory required for data: 1666980448
I0726 18:10:33.356062 81524 layer_factory.hpp:76] Creating layer relu61
I0726 18:10:33.356076 81524 net.cpp:106] Creating Layer relu61
I0726 18:10:33.356086 81524 net.cpp:454] relu61 <- conv61
I0726 18:10:33.356101 81524 net.cpp:397] relu61 -> conv61 (in-place)
I0726 18:10:33.356511 81524 net.cpp:150] Setting up relu61
I0726 18:10:33.356530 81524 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0726 18:10:33.356540 81524 net.cpp:165] Memory required for data: 1674353248
I0726 18:10:33.356549 81524 layer_factory.hpp:76] Creating layer conv62
I0726 18:10:33.356565 81524 net.cpp:106] Creating Layer conv62
I0726 18:10:33.356575 81524 net.cpp:454] conv62 <- conv61
I0726 18:10:33.356588 81524 net.cpp:411] conv62 -> conv62
I0726 18:10:33.358688 81524 net.cpp:150] Setting up conv62
I0726 18:10:33.358711 81524 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0726 18:10:33.358721 81524 net.cpp:165] Memory required for data: 1681726048
I0726 18:10:33.358734 81524 layer_factory.hpp:76] Creating layer relu62
I0726 18:10:33.358767 81524 net.cpp:106] Creating Layer relu62
I0726 18:10:33.358778 81524 net.cpp:454] relu62 <- conv62
I0726 18:10:33.358791 81524 net.cpp:397] relu62 -> conv62 (in-place)
I0726 18:10:33.358964 81524 net.cpp:150] Setting up relu62
I0726 18:10:33.358980 81524 net.cpp:157] Top shape: 8 64 60 60 (1843200)
I0726 18:10:33.358990 81524 net.cpp:165] Memory required for data: 1689098848
I0726 18:10:33.358999 81524 layer_factory.hpp:76] Creating layer pool5
I0726 18:10:33.359014 81524 net.cpp:106] Creating Layer pool5
I0726 18:10:33.359024 81524 net.cpp:454] pool5 <- conv62
I0726 18:10:33.359035 81524 net.cpp:411] pool5 -> pool5
I0726 18:10:33.359513 81524 net.cpp:150] Setting up pool5
I0726 18:10:33.359531 81524 net.cpp:157] Top shape: 8 64 30 30 (460800)
I0726 18:10:33.359541 81524 net.cpp:165] Memory required for data: 1690942048
I0726 18:10:33.359551 81524 layer_factory.hpp:76] Creating layer conv71
I0726 18:10:33.359568 81524 net.cpp:106] Creating Layer conv71
I0726 18:10:33.359581 81524 net.cpp:454] conv71 <- pool5
I0726 18:10:33.359593 81524 net.cpp:411] conv71 -> conv71
I0726 18:10:33.361037 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0726 18:10:33.361071 81524 net.cpp:150] Setting up conv71
I0726 18:10:33.361085 81524 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0726 18:10:33.361098 81524 net.cpp:165] Memory required for data: 1693706848
I0726 18:10:33.361109 81524 layer_factory.hpp:76] Creating layer relu71
I0726 18:10:33.361122 81524 net.cpp:106] Creating Layer relu71
I0726 18:10:33.361132 81524 net.cpp:454] relu71 <- conv71
I0726 18:10:33.361143 81524 net.cpp:397] relu71 -> conv71 (in-place)
I0726 18:10:33.361563 81524 net.cpp:150] Setting up relu71
I0726 18:10:33.361582 81524 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0726 18:10:33.361593 81524 net.cpp:165] Memory required for data: 1696471648
I0726 18:10:33.361603 81524 layer_factory.hpp:76] Creating layer conv72
I0726 18:10:33.361620 81524 net.cpp:106] Creating Layer conv72
I0726 18:10:33.361630 81524 net.cpp:454] conv72 <- conv71
I0726 18:10:33.361641 81524 net.cpp:411] conv72 -> conv72
I0726 18:10:33.363508 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0726 18:10:33.363546 81524 net.cpp:150] Setting up conv72
I0726 18:10:33.363559 81524 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0726 18:10:33.363569 81524 net.cpp:165] Memory required for data: 1699236448
I0726 18:10:33.363590 81524 layer_factory.hpp:76] Creating layer relu72
I0726 18:10:33.363603 81524 net.cpp:106] Creating Layer relu72
I0726 18:10:33.363613 81524 net.cpp:454] relu72 <- conv72
I0726 18:10:33.363625 81524 net.cpp:397] relu72 -> conv72 (in-place)
I0726 18:10:33.364032 81524 net.cpp:150] Setting up relu72
I0726 18:10:33.364050 81524 net.cpp:157] Top shape: 8 96 30 30 (691200)
I0726 18:10:33.364060 81524 net.cpp:165] Memory required for data: 1702001248
I0726 18:10:33.364070 81524 layer_factory.hpp:76] Creating layer pool6
I0726 18:10:33.364085 81524 net.cpp:106] Creating Layer pool6
I0726 18:10:33.364095 81524 net.cpp:454] pool6 <- conv72
I0726 18:10:33.364106 81524 net.cpp:411] pool6 -> pool6
I0726 18:10:33.364308 81524 net.cpp:150] Setting up pool6
I0726 18:10:33.364325 81524 net.cpp:157] Top shape: 8 96 15 15 (172800)
I0726 18:10:33.364333 81524 net.cpp:165] Memory required for data: 1702692448
I0726 18:10:33.364342 81524 layer_factory.hpp:76] Creating layer conv81
I0726 18:10:33.364359 81524 net.cpp:106] Creating Layer conv81
I0726 18:10:33.364368 81524 net.cpp:454] conv81 <- pool6
I0726 18:10:33.364379 81524 net.cpp:411] conv81 -> conv81
I0726 18:10:33.366976 81524 net.cpp:150] Setting up conv81
I0726 18:10:33.366997 81524 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0726 18:10:33.367007 81524 net.cpp:165] Memory required for data: 1703614048
I0726 18:10:33.367022 81524 layer_factory.hpp:76] Creating layer relu81
I0726 18:10:33.367034 81524 net.cpp:106] Creating Layer relu81
I0726 18:10:33.367044 81524 net.cpp:454] relu81 <- conv81
I0726 18:10:33.367055 81524 net.cpp:397] relu81 -> conv81 (in-place)
I0726 18:10:33.367240 81524 net.cpp:150] Setting up relu81
I0726 18:10:33.367256 81524 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0726 18:10:33.367266 81524 net.cpp:165] Memory required for data: 1704535648
I0726 18:10:33.367275 81524 layer_factory.hpp:76] Creating layer conv82
I0726 18:10:33.367292 81524 net.cpp:106] Creating Layer conv82
I0726 18:10:33.367302 81524 net.cpp:454] conv82 <- conv81
I0726 18:10:33.367316 81524 net.cpp:411] conv82 -> conv82
I0726 18:10:33.369400 81524 net.cpp:150] Setting up conv82
I0726 18:10:33.369421 81524 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0726 18:10:33.369431 81524 net.cpp:165] Memory required for data: 1705457248
I0726 18:10:33.369443 81524 layer_factory.hpp:76] Creating layer relu82
I0726 18:10:33.369457 81524 net.cpp:106] Creating Layer relu82
I0726 18:10:33.369468 81524 net.cpp:454] relu82 <- conv82
I0726 18:10:33.369479 81524 net.cpp:397] relu82 -> conv82 (in-place)
I0726 18:10:33.369889 81524 net.cpp:150] Setting up relu82
I0726 18:10:33.369910 81524 net.cpp:157] Top shape: 8 128 15 15 (230400)
I0726 18:10:33.369920 81524 net.cpp:165] Memory required for data: 1706378848
I0726 18:10:33.369930 81524 layer_factory.hpp:76] Creating layer pool7
I0726 18:10:33.369942 81524 net.cpp:106] Creating Layer pool7
I0726 18:10:33.369951 81524 net.cpp:454] pool7 <- conv82
I0726 18:10:33.369962 81524 net.cpp:411] pool7 -> pool7
I0726 18:10:33.370151 81524 net.cpp:150] Setting up pool7
I0726 18:10:33.370167 81524 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0726 18:10:33.370177 81524 net.cpp:165] Memory required for data: 1706640992
I0726 18:10:33.370187 81524 layer_factory.hpp:76] Creating layer drop0
I0726 18:10:33.370198 81524 net.cpp:106] Creating Layer drop0
I0726 18:10:33.370208 81524 net.cpp:454] drop0 <- pool7
I0726 18:10:33.370220 81524 net.cpp:397] drop0 -> pool7 (in-place)
I0726 18:10:33.370255 81524 net.cpp:150] Setting up drop0
I0726 18:10:33.370268 81524 net.cpp:157] Top shape: 8 128 8 8 (65536)
I0726 18:10:33.370277 81524 net.cpp:165] Memory required for data: 1706903136
I0726 18:10:33.370286 81524 layer_factory.hpp:76] Creating layer conv91
I0726 18:10:33.370306 81524 net.cpp:106] Creating Layer conv91
I0726 18:10:33.370316 81524 net.cpp:454] conv91 <- pool7
I0726 18:10:33.370327 81524 net.cpp:411] conv91 -> conv91
I0726 18:10:33.371733 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0726 18:10:33.371773 81524 net.cpp:150] Setting up conv91
I0726 18:10:33.371788 81524 net.cpp:157] Top shape: 8 3 1 1 (24)
I0726 18:10:33.371798 81524 net.cpp:165] Memory required for data: 1706903232
I0726 18:10:33.371810 81524 layer_factory.hpp:76] Creating layer conv91_conv91_0_split
I0726 18:10:33.371824 81524 net.cpp:106] Creating Layer conv91_conv91_0_split
I0726 18:10:33.371834 81524 net.cpp:454] conv91_conv91_0_split <- conv91
I0726 18:10:33.371848 81524 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_0
I0726 18:10:33.371862 81524 net.cpp:411] conv91_conv91_0_split -> conv91_conv91_0_split_1
I0726 18:10:33.371912 81524 net.cpp:150] Setting up conv91_conv91_0_split
I0726 18:10:33.371927 81524 net.cpp:157] Top shape: 8 3 1 1 (24)
I0726 18:10:33.371938 81524 net.cpp:157] Top shape: 8 3 1 1 (24)
I0726 18:10:33.371948 81524 net.cpp:165] Memory required for data: 1706903424
I0726 18:10:33.371960 81524 layer_factory.hpp:76] Creating layer accuracy
I0726 18:10:33.371976 81524 net.cpp:106] Creating Layer accuracy
I0726 18:10:33.371986 81524 net.cpp:454] accuracy <- conv91_conv91_0_split_0
I0726 18:10:33.371997 81524 net.cpp:454] accuracy <- label_data_1_split_0
I0726 18:10:33.372009 81524 net.cpp:411] accuracy -> accuracy
I0726 18:10:33.372023 81524 net.cpp:150] Setting up accuracy
I0726 18:10:33.372035 81524 net.cpp:157] Top shape: (1)
I0726 18:10:33.372045 81524 net.cpp:165] Memory required for data: 1706903428
I0726 18:10:33.372053 81524 layer_factory.hpp:76] Creating layer loss
I0726 18:10:33.372067 81524 net.cpp:106] Creating Layer loss
I0726 18:10:33.372077 81524 net.cpp:454] loss <- conv91_conv91_0_split_1
I0726 18:10:33.372087 81524 net.cpp:454] loss <- label_data_1_split_1
I0726 18:10:33.372113 81524 net.cpp:411] loss -> loss
I0726 18:10:33.372128 81524 layer_factory.hpp:76] Creating layer loss
I0726 18:10:33.372655 81524 net.cpp:150] Setting up loss
I0726 18:10:33.372675 81524 net.cpp:157] Top shape: (1)
I0726 18:10:33.372685 81524 net.cpp:160]     with loss weight 1
I0726 18:10:33.372705 81524 net.cpp:165] Memory required for data: 1706903432
I0726 18:10:33.372715 81524 net.cpp:226] loss needs backward computation.
I0726 18:10:33.372725 81524 net.cpp:228] accuracy does not need backward computation.
I0726 18:10:33.372735 81524 net.cpp:226] conv91_conv91_0_split needs backward computation.
I0726 18:10:33.372745 81524 net.cpp:226] conv91 needs backward computation.
I0726 18:10:33.372755 81524 net.cpp:226] drop0 needs backward computation.
I0726 18:10:33.372764 81524 net.cpp:226] pool7 needs backward computation.
I0726 18:10:33.372773 81524 net.cpp:226] relu82 needs backward computation.
I0726 18:10:33.372782 81524 net.cpp:226] conv82 needs backward computation.
I0726 18:10:33.372792 81524 net.cpp:226] relu81 needs backward computation.
I0726 18:10:33.372800 81524 net.cpp:226] conv81 needs backward computation.
I0726 18:10:33.372809 81524 net.cpp:226] pool6 needs backward computation.
I0726 18:10:33.372822 81524 net.cpp:226] relu72 needs backward computation.
I0726 18:10:33.372833 81524 net.cpp:226] conv72 needs backward computation.
I0726 18:10:33.372845 81524 net.cpp:226] relu71 needs backward computation.
I0726 18:10:33.372855 81524 net.cpp:226] conv71 needs backward computation.
I0726 18:10:33.372864 81524 net.cpp:226] pool5 needs backward computation.
I0726 18:10:33.372875 81524 net.cpp:226] relu62 needs backward computation.
I0726 18:10:33.372884 81524 net.cpp:226] conv62 needs backward computation.
I0726 18:10:33.372895 81524 net.cpp:226] relu61 needs backward computation.
I0726 18:10:33.372903 81524 net.cpp:226] conv61 needs backward computation.
I0726 18:10:33.372912 81524 net.cpp:226] nonlin_ip1 needs backward computation.
I0726 18:10:33.372925 81524 net.cpp:226] ip1_c needs backward computation.
I0726 18:10:33.372934 81524 net.cpp:228] pool4 does not need backward computation.
I0726 18:10:33.372944 81524 net.cpp:228] nonlin4 does not need backward computation.
I0726 18:10:33.372953 81524 net.cpp:228] conv4 does not need backward computation.
I0726 18:10:33.372963 81524 net.cpp:228] pool3 does not need backward computation.
I0726 18:10:33.372973 81524 net.cpp:228] nonlin3 does not need backward computation.
I0726 18:10:33.372982 81524 net.cpp:228] conv3 does not need backward computation.
I0726 18:10:33.372992 81524 net.cpp:228] pool2 does not need backward computation.
I0726 18:10:33.373002 81524 net.cpp:228] nonlin2 does not need backward computation.
I0726 18:10:33.373010 81524 net.cpp:228] conv2 does not need backward computation.
I0726 18:10:33.373020 81524 net.cpp:228] pool1 does not need backward computation.
I0726 18:10:33.373029 81524 net.cpp:228] nonlin1 does not need backward computation.
I0726 18:10:33.373040 81524 net.cpp:228] conv1 does not need backward computation.
I0726 18:10:33.373050 81524 net.cpp:228] label_data_1_split does not need backward computation.
I0726 18:10:33.373060 81524 net.cpp:228] data does not need backward computation.
I0726 18:10:33.373070 81524 net.cpp:270] This network produces output accuracy
I0726 18:10:33.373080 81524 net.cpp:270] This network produces output loss
I0726 18:10:33.373109 81524 net.cpp:283] Network initialization done.
I0726 18:10:33.373251 81524 solver.cpp:59] Solver scaffolding done.
I0726 18:10:33.374137 81524 caffe.cpp:128] Finetuning from models.final/mitosis_detection.caffemodel
I0726 18:10:33.379895 81524 parallel.cpp:394] GPUs pairs 0:1, 2:3, 0:2
I0726 18:10:33.547535 81524 net.cpp:99] Sharing layer data from root net
I0726 18:10:33.548475 81524 net.cpp:143] Created top blob 0 (shape: 16 3 1000 1000 (48000000)) for shared layer data
I0726 18:10:33.548532 81524 net.cpp:143] Created top blob 1 (shape: 16 (16)) for shared layer data
I0726 18:10:33.666249 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0726 18:10:33.673506 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0726 18:10:33.676688 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21600
I0726 18:10:33.680881 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0726 18:10:33.686434 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0726 18:10:33.688798 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0726 18:10:33.690716 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0726 18:10:34.085134 81524 net.cpp:99] Sharing layer data from root net
I0726 18:10:34.109580 81524 net.cpp:143] Created top blob 0 (shape: 16 3 1000 1000 (48000000)) for shared layer data
I0726 18:10:34.109688 81524 net.cpp:143] Created top blob 1 (shape: 16 (16)) for shared layer data
I0726 18:10:34.480164 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0726 18:10:34.522964 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0726 18:10:34.534875 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21600
I0726 18:10:34.561534 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0726 18:10:34.587610 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0726 18:10:34.599474 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0726 18:10:34.614420 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0726 18:10:34.617368 81524 parallel.cpp:237] GPU 2 does not have p2p access to GPU 0
I0726 18:10:34.802443 81524 net.cpp:99] Sharing layer data from root net
I0726 18:10:34.803920 81524 net.cpp:143] Created top blob 0 (shape: 16 3 1000 1000 (48000000)) for shared layer data
I0726 18:10:34.804039 81524 net.cpp:143] Created top blob 1 (shape: 16 (16)) for shared layer data
I0726 18:10:34.936959 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1728
I0726 18:10:34.950654 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0726 18:10:34.989204 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21600
I0726 18:10:34.995095 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0726 18:10:35.003770 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10368
I0726 18:10:35.007122 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0726 18:10:35.010557 81524 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 98304
I0726 18:10:35.019426 81524 parallel.cpp:422] Starting Optimization
I0726 18:10:35.019611 81524 solver.cpp:287] Solving Result Layer 3 Stack
I0726 18:10:35.019625 81524 solver.cpp:288] Learning Rate Policy: step
I0726 18:10:36.552227 81524 solver.cpp:236] Iteration 0, loss = 1.1636
I0726 18:10:36.552289 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 18:10:36.552311 81524 solver.cpp:252]     Train net output #1: loss = 1.1636 (* 1 = 1.1636 loss)
I0726 18:10:36.573956 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 18:10:41.093427 81524 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0726 18:11:28.619892 81524 solver.cpp:236] Iteration 10, loss = 1.07009
I0726 18:11:28.620034 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:11:28.620054 81524 solver.cpp:252]     Train net output #1: loss = 1.05205 (* 1 = 1.05205 loss)
I0726 18:11:33.996223 81524 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I0726 18:12:22.836357 81524 solver.cpp:236] Iteration 20, loss = 1.089
I0726 18:12:22.836583 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 18:12:22.836606 81524 solver.cpp:252]     Train net output #1: loss = 1.09237 (* 1 = 1.09237 loss)
I0726 18:12:26.770634 81524 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0726 18:13:16.280592 81524 solver.cpp:236] Iteration 30, loss = 1.08742
I0726 18:13:16.280859 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 18:13:16.280889 81524 solver.cpp:252]     Train net output #1: loss = 1.11213 (* 1 = 1.11213 loss)
I0726 18:13:20.312435 81524 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I0726 18:14:12.163110 81524 solver.cpp:236] Iteration 40, loss = 1.0811
I0726 18:14:12.163285 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 18:14:12.163326 81524 solver.cpp:252]     Train net output #1: loss = 0.887112 (* 1 = 0.887112 loss)
I0726 18:14:16.752123 81524 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0726 18:15:06.908628 81524 solver.cpp:236] Iteration 50, loss = 1.07448
I0726 18:15:06.908790 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 18:15:06.908824 81524 solver.cpp:252]     Train net output #1: loss = 1.15235 (* 1 = 1.15235 loss)
I0726 18:15:12.172130 81524 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I0726 18:16:01.342612 81524 solver.cpp:236] Iteration 60, loss = 1.07587
I0726 18:16:01.342835 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 18:16:01.342869 81524 solver.cpp:252]     Train net output #1: loss = 1.13013 (* 1 = 1.13013 loss)
I0726 18:16:06.000087 81524 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0726 18:17:03.093546 81524 solver.cpp:236] Iteration 70, loss = 1.07247
I0726 18:17:03.093746 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:17:03.093794 81524 solver.cpp:252]     Train net output #1: loss = 1.03905 (* 1 = 1.03905 loss)
I0726 18:17:03.994468 81524 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I0726 18:17:58.561159 81524 solver.cpp:236] Iteration 80, loss = 1.07214
I0726 18:17:58.561331 81524 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0726 18:17:58.561369 81524 solver.cpp:252]     Train net output #1: loss = 1.14981 (* 1 = 1.14981 loss)
I0726 18:18:03.318660 81524 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0726 18:19:02.067322 81524 solver.cpp:236] Iteration 90, loss = 1.07129
I0726 18:19:02.067508 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 18:19:02.067530 81524 solver.cpp:252]     Train net output #1: loss = 1.01086 (* 1 = 1.01086 loss)
I0726 18:19:02.641314 81524 sgd_solver.cpp:106] Iteration 90, lr = 0.01
I0726 18:19:57.070664 81524 solver.cpp:340] Iteration 100, Testing net (#0)
I0726 18:23:01.673722 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4705
I0726 18:23:01.673912 81524 solver.cpp:408]     Test net output #1: loss = 1.05577 (* 1 = 1.05577 loss)
I0726 18:23:02.678825 81524 solver.cpp:236] Iteration 100, loss = 1.06833
I0726 18:23:02.678902 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 18:23:02.678923 81524 solver.cpp:252]     Train net output #1: loss = 1.07505 (* 1 = 1.07505 loss)
I0726 18:23:05.120853 81524 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0726 18:23:57.183961 81524 solver.cpp:236] Iteration 110, loss = 1.05928
I0726 18:23:57.184216 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 18:23:57.184238 81524 solver.cpp:252]     Train net output #1: loss = 1.04665 (* 1 = 1.04665 loss)
I0726 18:24:02.509608 81524 sgd_solver.cpp:106] Iteration 110, lr = 0.01
I0726 18:24:54.820574 81524 solver.cpp:236] Iteration 120, loss = 1.05096
I0726 18:24:54.820730 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 18:24:54.820770 81524 solver.cpp:252]     Train net output #1: loss = 1.15566 (* 1 = 1.15566 loss)
I0726 18:24:57.829577 81524 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0726 18:25:50.995612 81524 solver.cpp:236] Iteration 130, loss = 1.04723
I0726 18:25:50.995805 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 18:25:50.995837 81524 solver.cpp:252]     Train net output #1: loss = 1.13427 (* 1 = 1.13427 loss)
I0726 18:25:56.191092 81524 sgd_solver.cpp:106] Iteration 130, lr = 0.01
I0726 18:26:53.254206 81524 solver.cpp:236] Iteration 140, loss = 1.04657
I0726 18:26:53.254456 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 18:26:53.254483 81524 solver.cpp:252]     Train net output #1: loss = 1.00017 (* 1 = 1.00017 loss)
I0726 18:26:54.238431 81524 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0726 18:27:50.304457 81524 solver.cpp:236] Iteration 150, loss = 1.04147
I0726 18:27:50.304687 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 18:27:50.304726 81524 solver.cpp:252]     Train net output #1: loss = 1.10964 (* 1 = 1.10964 loss)
I0726 18:27:55.235358 81524 sgd_solver.cpp:106] Iteration 150, lr = 0.01
I0726 18:28:46.524302 81524 solver.cpp:236] Iteration 160, loss = 1.04989
I0726 18:28:46.524492 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 18:28:46.524518 81524 solver.cpp:252]     Train net output #1: loss = 0.913323 (* 1 = 0.913323 loss)
I0726 18:28:51.326751 81524 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0726 18:29:45.299762 81524 solver.cpp:236] Iteration 170, loss = 1.05016
I0726 18:29:45.299944 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:29:45.300004 81524 solver.cpp:252]     Train net output #1: loss = 1.02746 (* 1 = 1.02746 loss)
I0726 18:29:47.353610 81524 sgd_solver.cpp:106] Iteration 170, lr = 0.01
I0726 18:30:41.762856 81524 solver.cpp:236] Iteration 180, loss = 1.05076
I0726 18:30:41.763156 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 18:30:41.763185 81524 solver.cpp:252]     Train net output #1: loss = 1.09617 (* 1 = 1.09617 loss)
I0726 18:30:45.851845 81524 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0726 18:31:37.649333 81524 solver.cpp:236] Iteration 190, loss = 1.04852
I0726 18:31:37.649622 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:31:37.649667 81524 solver.cpp:252]     Train net output #1: loss = 1.0635 (* 1 = 1.0635 loss)
I0726 18:31:42.951694 81524 sgd_solver.cpp:106] Iteration 190, lr = 0.01
I0726 18:32:33.683995 81524 solver.cpp:340] Iteration 200, Testing net (#0)
I0726 18:33:17.037464 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 18:35:22.908568 81524 solver.cpp:408]     Test net output #0: accuracy = 0.462
I0726 18:35:22.908758 81524 solver.cpp:408]     Test net output #1: loss = 1.06286 (* 1 = 1.06286 loss)
I0726 18:35:23.861274 81524 solver.cpp:236] Iteration 200, loss = 1.06132
I0726 18:35:23.861330 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 18:35:23.861347 81524 solver.cpp:252]     Train net output #1: loss = 1.08929 (* 1 = 1.08929 loss)
I0726 18:35:26.055341 81524 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0726 18:36:20.192880 81524 solver.cpp:236] Iteration 210, loss = 1.05872
I0726 18:36:20.193104 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 18:36:20.193130 81524 solver.cpp:252]     Train net output #1: loss = 1.0699 (* 1 = 1.0699 loss)
I0726 18:36:25.004964 81524 sgd_solver.cpp:106] Iteration 210, lr = 0.01
I0726 18:37:15.020794 81524 solver.cpp:236] Iteration 220, loss = 1.05301
I0726 18:37:15.021054 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 18:37:15.021093 81524 solver.cpp:252]     Train net output #1: loss = 0.934363 (* 1 = 0.934363 loss)
I0726 18:37:19.957926 81524 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0726 18:38:14.421241 81524 solver.cpp:236] Iteration 230, loss = 1.058
I0726 18:38:14.421535 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 18:38:14.421569 81524 solver.cpp:252]     Train net output #1: loss = 1.21623 (* 1 = 1.21623 loss)
I0726 18:38:15.460655 81524 sgd_solver.cpp:106] Iteration 230, lr = 0.01
I0726 18:39:05.889675 81524 solver.cpp:236] Iteration 240, loss = 1.05475
I0726 18:39:05.889832 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 18:39:05.889878 81524 solver.cpp:252]     Train net output #1: loss = 0.923721 (* 1 = 0.923721 loss)
I0726 18:39:09.929496 81524 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0726 18:40:02.586772 81524 solver.cpp:236] Iteration 250, loss = 1.05584
I0726 18:40:02.586951 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 18:40:02.586987 81524 solver.cpp:252]     Train net output #1: loss = 1.14911 (* 1 = 1.14911 loss)
I0726 18:40:03.557365 81524 sgd_solver.cpp:106] Iteration 250, lr = 0.01
I0726 18:40:55.793346 81524 solver.cpp:236] Iteration 260, loss = 1.06647
I0726 18:40:55.793617 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 18:40:55.793648 81524 solver.cpp:252]     Train net output #1: loss = 1.00945 (* 1 = 1.00945 loss)
I0726 18:40:56.639402 81524 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0726 18:41:53.278741 81524 solver.cpp:236] Iteration 270, loss = 1.07258
I0726 18:41:53.279018 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:41:53.279063 81524 solver.cpp:252]     Train net output #1: loss = 1.0473 (* 1 = 1.0473 loss)
I0726 18:41:54.208256 81524 sgd_solver.cpp:106] Iteration 270, lr = 0.01
I0726 18:42:47.550096 81524 solver.cpp:236] Iteration 280, loss = 1.06918
I0726 18:42:47.550278 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 18:42:47.550312 81524 solver.cpp:252]     Train net output #1: loss = 1.07325 (* 1 = 1.07325 loss)
I0726 18:42:49.690876 81524 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0726 18:43:41.722646 81524 solver.cpp:236] Iteration 290, loss = 1.07226
I0726 18:43:41.722899 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 18:43:41.722936 81524 solver.cpp:252]     Train net output #1: loss = 1.04597 (* 1 = 1.04597 loss)
I0726 18:43:46.037612 81524 sgd_solver.cpp:106] Iteration 290, lr = 0.01
I0726 18:44:35.572289 81524 solver.cpp:340] Iteration 300, Testing net (#0)
I0726 18:47:15.488752 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4795
I0726 18:47:15.488979 81524 solver.cpp:408]     Test net output #1: loss = 1.05033 (* 1 = 1.05033 loss)
I0726 18:47:16.494349 81524 solver.cpp:236] Iteration 300, loss = 1.07239
I0726 18:47:16.494469 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 18:47:16.494519 81524 solver.cpp:252]     Train net output #1: loss = 0.981605 (* 1 = 0.981605 loss)
I0726 18:47:18.376180 81524 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0726 18:48:10.263974 81524 solver.cpp:236] Iteration 310, loss = 1.06414
I0726 18:48:10.264169 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:48:10.264191 81524 solver.cpp:252]     Train net output #1: loss = 1.05489 (* 1 = 1.05489 loss)
I0726 18:48:14.702401 81524 sgd_solver.cpp:106] Iteration 310, lr = 0.01
I0726 18:49:06.363127 81524 solver.cpp:236] Iteration 320, loss = 1.06419
I0726 18:49:06.363329 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 18:49:06.363384 81524 solver.cpp:252]     Train net output #1: loss = 1.00686 (* 1 = 1.00686 loss)
I0726 18:49:11.214094 81524 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0726 18:50:02.961132 81524 solver.cpp:236] Iteration 330, loss = 1.06078
I0726 18:50:02.961346 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 18:50:02.961369 81524 solver.cpp:252]     Train net output #1: loss = 0.987188 (* 1 = 0.987188 loss)
I0726 18:50:07.393164 81524 sgd_solver.cpp:106] Iteration 330, lr = 0.01
I0726 18:50:54.766105 81524 solver.cpp:236] Iteration 340, loss = 1.06328
I0726 18:50:54.766278 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 18:50:54.766299 81524 solver.cpp:252]     Train net output #1: loss = 0.930319 (* 1 = 0.930319 loss)
I0726 18:50:58.754823 81524 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0726 18:51:45.225536 81524 solver.cpp:236] Iteration 350, loss = 1.05496
I0726 18:51:45.225751 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 18:51:45.225774 81524 solver.cpp:252]     Train net output #1: loss = 1.14954 (* 1 = 1.14954 loss)
I0726 18:51:49.212415 81524 sgd_solver.cpp:106] Iteration 350, lr = 0.01
I0726 18:51:51.835275 81557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 18:52:37.082609 81524 solver.cpp:236] Iteration 360, loss = 1.05499
I0726 18:52:37.082870 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 18:52:37.082901 81524 solver.cpp:252]     Train net output #1: loss = 1.07525 (* 1 = 1.07525 loss)
I0726 18:52:40.951860 81524 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0726 18:53:30.216477 81524 solver.cpp:236] Iteration 370, loss = 1.05406
I0726 18:53:30.216668 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:53:30.216699 81524 solver.cpp:252]     Train net output #1: loss = 1.02527 (* 1 = 1.02527 loss)
I0726 18:53:34.977485 81524 sgd_solver.cpp:106] Iteration 370, lr = 0.01
I0726 18:54:28.634905 81524 solver.cpp:236] Iteration 380, loss = 1.06211
I0726 18:54:28.635128 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:54:28.635182 81524 solver.cpp:252]     Train net output #1: loss = 1.04885 (* 1 = 1.04885 loss)
I0726 18:54:29.427461 81524 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0726 18:55:22.436174 81524 solver.cpp:236] Iteration 390, loss = 1.06686
I0726 18:55:22.436363 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 18:55:22.436384 81524 solver.cpp:252]     Train net output #1: loss = 1.12665 (* 1 = 1.12665 loss)
I0726 18:55:26.240542 81524 sgd_solver.cpp:106] Iteration 390, lr = 0.01
I0726 18:56:12.844527 81524 solver.cpp:340] Iteration 400, Testing net (#0)
I0726 18:58:56.095964 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4725
I0726 18:58:56.096123 81524 solver.cpp:408]     Test net output #1: loss = 1.05486 (* 1 = 1.05486 loss)
I0726 18:58:57.105672 81524 solver.cpp:236] Iteration 400, loss = 1.07139
I0726 18:58:57.105756 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 18:58:57.105784 81524 solver.cpp:252]     Train net output #1: loss = 1.03463 (* 1 = 1.03463 loss)
I0726 18:58:59.224639 81524 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0726 18:59:50.992504 81524 solver.cpp:236] Iteration 410, loss = 1.06898
I0726 18:59:50.992724 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 18:59:50.992763 81524 solver.cpp:252]     Train net output #1: loss = 0.990531 (* 1 = 0.990531 loss)
I0726 18:59:55.953477 81524 sgd_solver.cpp:106] Iteration 410, lr = 0.01
I0726 19:00:45.116565 81524 solver.cpp:236] Iteration 420, loss = 1.07057
I0726 19:00:45.116750 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:00:45.116772 81524 solver.cpp:252]     Train net output #1: loss = 1.04687 (* 1 = 1.04687 loss)
I0726 19:00:45.917956 81524 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0726 19:01:35.998025 81524 solver.cpp:236] Iteration 430, loss = 1.06233
I0726 19:01:35.998333 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:01:35.998354 81524 solver.cpp:252]     Train net output #1: loss = 1.03436 (* 1 = 1.03436 loss)
I0726 19:01:36.555917 81524 sgd_solver.cpp:106] Iteration 430, lr = 0.01
I0726 19:02:25.008667 81524 solver.cpp:236] Iteration 440, loss = 1.05759
I0726 19:02:25.008844 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:02:25.008878 81524 solver.cpp:252]     Train net output #1: loss = 1.1207 (* 1 = 1.1207 loss)
I0726 19:02:26.997151 81524 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0726 19:03:17.232488 81524 solver.cpp:236] Iteration 450, loss = 1.04719
I0726 19:03:17.232686 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 19:03:17.232712 81524 solver.cpp:252]     Train net output #1: loss = 0.925364 (* 1 = 0.925364 loss)
I0726 19:03:21.802369 81524 sgd_solver.cpp:106] Iteration 450, lr = 0.01
I0726 19:04:08.238272 81524 solver.cpp:236] Iteration 460, loss = 1.05991
I0726 19:04:08.238505 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:04:08.238533 81524 solver.cpp:252]     Train net output #1: loss = 1.08369 (* 1 = 1.08369 loss)
I0726 19:04:13.043607 81524 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0726 19:05:00.672194 81524 solver.cpp:236] Iteration 470, loss = 1.05635
I0726 19:05:00.672444 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:05:00.672482 81524 solver.cpp:252]     Train net output #1: loss = 1.04661 (* 1 = 1.04661 loss)
I0726 19:05:04.707836 81524 sgd_solver.cpp:106] Iteration 470, lr = 0.01
I0726 19:05:51.863929 81524 solver.cpp:236] Iteration 480, loss = 1.05867
I0726 19:05:51.864193 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:05:51.864217 81524 solver.cpp:252]     Train net output #1: loss = 1.13946 (* 1 = 1.13946 loss)
I0726 19:05:55.988188 81524 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0726 19:06:48.558856 81524 solver.cpp:236] Iteration 490, loss = 1.0575
I0726 19:06:48.562188 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:06:48.562232 81524 solver.cpp:252]     Train net output #1: loss = 1.01283 (* 1 = 1.01283 loss)
I0726 19:06:53.541759 81524 sgd_solver.cpp:106] Iteration 490, lr = 0.01
I0726 19:07:46.039579 81524 solver.cpp:340] Iteration 500, Testing net (#0)
I0726 19:10:15.294649 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4695
I0726 19:10:15.294843 81524 solver.cpp:408]     Test net output #1: loss = 1.0595 (* 1 = 1.0595 loss)
I0726 19:10:16.253517 81524 solver.cpp:236] Iteration 500, loss = 1.06331
I0726 19:10:16.253595 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:10:16.253623 81524 solver.cpp:252]     Train net output #1: loss = 1.04509 (* 1 = 1.04509 loss)
I0726 19:10:17.841850 81524 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0726 19:10:24.411430 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 19:11:07.920472 81524 solver.cpp:236] Iteration 510, loss = 1.05523
I0726 19:11:07.920675 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:11:07.920718 81524 solver.cpp:252]     Train net output #1: loss = 1.03685 (* 1 = 1.03685 loss)
I0726 19:11:12.333626 81524 sgd_solver.cpp:106] Iteration 510, lr = 0.01
I0726 19:12:04.218055 81524 solver.cpp:236] Iteration 520, loss = 1.06278
I0726 19:12:04.218230 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:12:04.218261 81524 solver.cpp:252]     Train net output #1: loss = 1.04995 (* 1 = 1.04995 loss)
I0726 19:12:09.165154 81524 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0726 19:13:00.992151 81524 solver.cpp:236] Iteration 530, loss = 1.05895
I0726 19:13:00.992368 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:13:00.992400 81524 solver.cpp:252]     Train net output #1: loss = 1.03777 (* 1 = 1.03777 loss)
I0726 19:13:01.492435 81524 sgd_solver.cpp:106] Iteration 530, lr = 0.01
I0726 19:13:52.803181 81524 solver.cpp:236] Iteration 540, loss = 1.06247
I0726 19:13:52.803423 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:13:52.803472 81524 solver.cpp:252]     Train net output #1: loss = 1.07009 (* 1 = 1.07009 loss)
I0726 19:13:57.459715 81524 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0726 19:14:50.768134 81524 solver.cpp:236] Iteration 550, loss = 1.07104
I0726 19:14:50.768378 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:14:50.768414 81524 solver.cpp:252]     Train net output #1: loss = 1.05331 (* 1 = 1.05331 loss)
I0726 19:14:55.792620 81524 sgd_solver.cpp:106] Iteration 550, lr = 0.01
I0726 19:15:50.070185 81524 solver.cpp:236] Iteration 560, loss = 1.07114
I0726 19:15:50.070421 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:15:50.070472 81524 solver.cpp:252]     Train net output #1: loss = 0.994907 (* 1 = 0.994907 loss)
I0726 19:15:51.085377 81524 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0726 19:16:45.432198 81524 solver.cpp:236] Iteration 570, loss = 1.06523
I0726 19:16:45.432399 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 19:16:45.432428 81524 solver.cpp:252]     Train net output #1: loss = 0.944904 (* 1 = 0.944904 loss)
I0726 19:16:50.096065 81524 sgd_solver.cpp:106] Iteration 570, lr = 0.01
I0726 19:17:41.393244 81524 solver.cpp:236] Iteration 580, loss = 1.07419
I0726 19:17:41.393429 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:17:41.393448 81524 solver.cpp:252]     Train net output #1: loss = 1.04617 (* 1 = 1.04617 loss)
I0726 19:17:45.947319 81524 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0726 19:18:36.482568 81524 solver.cpp:236] Iteration 590, loss = 1.0719
I0726 19:18:36.482913 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:18:36.482936 81524 solver.cpp:252]     Train net output #1: loss = 1.02287 (* 1 = 1.02287 loss)
I0726 19:18:41.008328 81524 sgd_solver.cpp:106] Iteration 590, lr = 0.01
I0726 19:19:29.810986 81524 solver.cpp:340] Iteration 600, Testing net (#0)
I0726 19:22:00.516165 81524 solver.cpp:408]     Test net output #0: accuracy = 0.466
I0726 19:22:00.516435 81524 solver.cpp:408]     Test net output #1: loss = 1.05766 (* 1 = 1.05766 loss)
I0726 19:22:01.480136 81524 solver.cpp:236] Iteration 600, loss = 1.07183
I0726 19:22:01.480190 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:22:01.480209 81524 solver.cpp:252]     Train net output #1: loss = 1.00505 (* 1 = 1.00505 loss)
I0726 19:22:04.488318 81524 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0726 19:22:56.475615 81524 solver.cpp:236] Iteration 610, loss = 1.06742
I0726 19:22:56.482803 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:22:56.482897 81524 solver.cpp:252]     Train net output #1: loss = 1.01954 (* 1 = 1.01954 loss)
I0726 19:23:00.620015 81524 sgd_solver.cpp:106] Iteration 610, lr = 0.01
I0726 19:23:51.581243 81524 solver.cpp:236] Iteration 620, loss = 1.07333
I0726 19:23:51.581533 81524 solver.cpp:252]     Train net output #0: accuracy = 0.125
I0726 19:23:51.581565 81524 solver.cpp:252]     Train net output #1: loss = 1.2586 (* 1 = 1.2586 loss)
I0726 19:23:56.395864 81524 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0726 19:24:48.175357 81524 solver.cpp:236] Iteration 630, loss = 1.06173
I0726 19:24:48.175649 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:24:48.175678 81524 solver.cpp:252]     Train net output #1: loss = 1.03143 (* 1 = 1.03143 loss)
I0726 19:24:53.807629 81524 sgd_solver.cpp:106] Iteration 630, lr = 0.01
I0726 19:25:44.830265 81524 solver.cpp:236] Iteration 640, loss = 1.06271
I0726 19:25:44.830410 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:25:44.830430 81524 solver.cpp:252]     Train net output #1: loss = 1.08724 (* 1 = 1.08724 loss)
I0726 19:25:48.984202 81524 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0726 19:26:40.850319 81524 solver.cpp:236] Iteration 650, loss = 1.0561
I0726 19:26:40.850535 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:26:40.850555 81524 solver.cpp:252]     Train net output #1: loss = 1.12635 (* 1 = 1.12635 loss)
I0726 19:26:45.931990 81524 sgd_solver.cpp:106] Iteration 650, lr = 0.01
I0726 19:27:40.552573 81524 solver.cpp:236] Iteration 660, loss = 1.06134
I0726 19:27:40.552884 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 19:27:40.552922 81524 solver.cpp:252]     Train net output #1: loss = 1.13961 (* 1 = 1.13961 loss)
I0726 19:27:41.544571 81524 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0726 19:28:31.815476 81524 solver.cpp:236] Iteration 670, loss = 1.0575
I0726 19:28:31.815714 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 19:28:31.815737 81524 solver.cpp:252]     Train net output #1: loss = 1.00077 (* 1 = 1.00077 loss)
I0726 19:28:35.879482 81524 sgd_solver.cpp:106] Iteration 670, lr = 0.01
I0726 19:29:22.112790 81524 solver.cpp:236] Iteration 680, loss = 1.0639
I0726 19:29:22.113081 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:29:22.113131 81524 solver.cpp:252]     Train net output #1: loss = 1.09237 (* 1 = 1.09237 loss)
I0726 19:29:24.525456 81524 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0726 19:30:16.646141 81524 solver.cpp:236] Iteration 690, loss = 1.06695
I0726 19:30:16.646414 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:30:16.646442 81524 solver.cpp:252]     Train net output #1: loss = 1.08236 (* 1 = 1.08236 loss)
I0726 19:30:20.933542 81524 sgd_solver.cpp:106] Iteration 690, lr = 0.01
I0726 19:31:08.231870 81524 solver.cpp:340] Iteration 700, Testing net (#0)
I0726 19:31:41.169353 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 19:33:41.601300 81524 solver.cpp:408]     Test net output #0: accuracy = 0.466
I0726 19:33:41.601631 81524 solver.cpp:408]     Test net output #1: loss = 1.05767 (* 1 = 1.05767 loss)
I0726 19:33:42.655539 81524 solver.cpp:236] Iteration 700, loss = 1.07394
I0726 19:33:42.655592 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 19:33:42.655611 81524 solver.cpp:252]     Train net output #1: loss = 1.14531 (* 1 = 1.14531 loss)
I0726 19:33:44.787305 81524 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0726 19:34:32.028779 81524 solver.cpp:236] Iteration 710, loss = 1.06534
I0726 19:34:32.028964 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:34:32.028986 81524 solver.cpp:252]     Train net output #1: loss = 0.995723 (* 1 = 0.995723 loss)
I0726 19:34:32.640027 81524 sgd_solver.cpp:106] Iteration 710, lr = 0.01
I0726 19:35:18.842180 81524 solver.cpp:236] Iteration 720, loss = 1.06234
I0726 19:35:18.842388 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:35:18.842409 81524 solver.cpp:252]     Train net output #1: loss = 1.01808 (* 1 = 1.01808 loss)
I0726 19:35:23.590720 81524 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0726 19:36:10.057097 81524 solver.cpp:236] Iteration 730, loss = 1.056
I0726 19:36:10.057274 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:36:10.057294 81524 solver.cpp:252]     Train net output #1: loss = 1.06188 (* 1 = 1.06188 loss)
I0726 19:36:15.105720 81524 sgd_solver.cpp:106] Iteration 730, lr = 0.01
I0726 19:36:59.764680 81524 solver.cpp:236] Iteration 740, loss = 1.04883
I0726 19:36:59.764850 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:36:59.764890 81524 solver.cpp:252]     Train net output #1: loss = 1.07859 (* 1 = 1.07859 loss)
I0726 19:37:04.613440 81524 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0726 19:37:50.715781 81524 solver.cpp:236] Iteration 750, loss = 1.03738
I0726 19:37:50.715955 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 19:37:50.716011 81524 solver.cpp:252]     Train net output #1: loss = 0.919675 (* 1 = 0.919675 loss)
I0726 19:37:54.719446 81524 sgd_solver.cpp:106] Iteration 750, lr = 0.01
I0726 19:38:41.496417 81524 solver.cpp:236] Iteration 760, loss = 1.04507
I0726 19:38:41.496688 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:38:41.496726 81524 solver.cpp:252]     Train net output #1: loss = 1.07363 (* 1 = 1.07363 loss)
I0726 19:38:45.939533 81524 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0726 19:39:32.741940 81524 solver.cpp:236] Iteration 770, loss = 1.04726
I0726 19:39:32.742161 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:39:32.742180 81524 solver.cpp:252]     Train net output #1: loss = 1.04193 (* 1 = 1.04193 loss)
I0726 19:39:37.003396 81524 sgd_solver.cpp:106] Iteration 770, lr = 0.01
I0726 19:40:24.010618 81524 solver.cpp:236] Iteration 780, loss = 1.05472
I0726 19:40:24.010943 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 19:40:24.010994 81524 solver.cpp:252]     Train net output #1: loss = 0.887454 (* 1 = 0.887454 loss)
I0726 19:40:28.708084 81524 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0726 19:41:18.768769 81524 solver.cpp:236] Iteration 790, loss = 1.06222
I0726 19:41:18.768977 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:41:18.769002 81524 solver.cpp:252]     Train net output #1: loss = 1.11745 (* 1 = 1.11745 loss)
I0726 19:41:24.128161 81524 sgd_solver.cpp:106] Iteration 790, lr = 0.01
I0726 19:42:10.781553 81524 solver.cpp:340] Iteration 800, Testing net (#0)
I0726 19:44:48.208197 81524 solver.cpp:408]     Test net output #0: accuracy = 0.484
I0726 19:44:48.208382 81524 solver.cpp:408]     Test net output #1: loss = 1.04718 (* 1 = 1.04718 loss)
I0726 19:44:49.448807 81524 solver.cpp:236] Iteration 800, loss = 1.07301
I0726 19:44:49.448887 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:44:49.448920 81524 solver.cpp:252]     Train net output #1: loss = 1.12978 (* 1 = 1.12978 loss)
I0726 19:44:51.892701 81524 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0726 19:45:45.061913 81524 solver.cpp:236] Iteration 810, loss = 1.06495
I0726 19:45:45.062321 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:45:45.062366 81524 solver.cpp:252]     Train net output #1: loss = 1.04175 (* 1 = 1.04175 loss)
I0726 19:45:45.561378 81524 sgd_solver.cpp:106] Iteration 810, lr = 0.01
I0726 19:46:34.506196 81524 solver.cpp:236] Iteration 820, loss = 1.0637
I0726 19:46:34.506386 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 19:46:34.506414 81524 solver.cpp:252]     Train net output #1: loss = 1.11292 (* 1 = 1.11292 loss)
I0726 19:46:39.012384 81524 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0726 19:47:27.987294 81524 solver.cpp:236] Iteration 830, loss = 1.05244
I0726 19:47:27.987524 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 19:47:27.987543 81524 solver.cpp:252]     Train net output #1: loss = 0.910203 (* 1 = 0.910203 loss)
I0726 19:47:31.893601 81524 sgd_solver.cpp:106] Iteration 830, lr = 0.01
I0726 19:48:23.405148 81524 solver.cpp:236] Iteration 840, loss = 1.04804
I0726 19:48:23.405408 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:48:23.405460 81524 solver.cpp:252]     Train net output #1: loss = 1.06253 (* 1 = 1.06253 loss)
I0726 19:48:27.701704 81524 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0726 19:49:18.715495 81524 solver.cpp:236] Iteration 850, loss = 1.05077
I0726 19:49:18.715785 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 19:49:18.715823 81524 solver.cpp:252]     Train net output #1: loss = 1.16604 (* 1 = 1.16604 loss)
I0726 19:49:24.059900 81524 sgd_solver.cpp:106] Iteration 850, lr = 0.01
I0726 19:50:16.653921 81524 solver.cpp:236] Iteration 860, loss = 1.05372
I0726 19:50:16.654103 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:50:16.654127 81524 solver.cpp:252]     Train net output #1: loss = 1.01354 (* 1 = 1.01354 loss)
I0726 19:50:21.094399 81524 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0726 19:50:51.926949 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 19:51:14.940661 81524 solver.cpp:236] Iteration 870, loss = 1.05348
I0726 19:51:14.940714 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 19:51:14.940732 81524 solver.cpp:252]     Train net output #1: loss = 1.03801 (* 1 = 1.03801 loss)
I0726 19:51:17.076607 81524 sgd_solver.cpp:106] Iteration 870, lr = 0.01
I0726 19:52:19.193904 81524 solver.cpp:236] Iteration 880, loss = 1.06633
I0726 19:52:19.194270 81524 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0726 19:52:19.194293 81524 solver.cpp:252]     Train net output #1: loss = 1.21694 (* 1 = 1.21694 loss)
I0726 19:52:20.575995 81524 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0726 19:53:16.190966 81524 solver.cpp:236] Iteration 890, loss = 1.06687
I0726 19:53:16.191237 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:53:16.191269 81524 solver.cpp:252]     Train net output #1: loss = 1.01319 (* 1 = 1.01319 loss)
I0726 19:53:21.098539 81524 sgd_solver.cpp:106] Iteration 890, lr = 0.01
I0726 19:54:13.344142 81524 solver.cpp:340] Iteration 900, Testing net (#0)
I0726 19:56:46.233134 81524 solver.cpp:408]     Test net output #0: accuracy = 0.454
I0726 19:56:46.233407 81524 solver.cpp:408]     Test net output #1: loss = 1.06228 (* 1 = 1.06228 loss)
I0726 19:56:47.194383 81524 solver.cpp:236] Iteration 900, loss = 1.05916
I0726 19:56:47.194475 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 19:56:47.194509 81524 solver.cpp:252]     Train net output #1: loss = 0.959471 (* 1 = 0.959471 loss)
I0726 19:56:48.358501 81524 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0726 19:57:43.349886 81524 solver.cpp:236] Iteration 910, loss = 1.0652
I0726 19:57:43.350081 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 19:57:43.350114 81524 solver.cpp:252]     Train net output #1: loss = 1.13412 (* 1 = 1.13412 loss)
I0726 19:57:44.217682 81524 sgd_solver.cpp:106] Iteration 910, lr = 0.01
I0726 19:58:36.380260 81524 solver.cpp:236] Iteration 920, loss = 1.06895
I0726 19:58:36.380528 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 19:58:36.380559 81524 solver.cpp:252]     Train net output #1: loss = 1.02763 (* 1 = 1.02763 loss)
I0726 19:58:41.242213 81524 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0726 19:59:33.690984 81524 solver.cpp:236] Iteration 930, loss = 1.06659
I0726 19:59:33.691174 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 19:59:33.691206 81524 solver.cpp:252]     Train net output #1: loss = 1.0486 (* 1 = 1.0486 loss)
I0726 19:59:38.077366 81524 sgd_solver.cpp:106] Iteration 930, lr = 0.01
I0726 20:00:36.594069 81524 solver.cpp:236] Iteration 940, loss = 1.06988
I0726 20:00:36.594401 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 20:00:36.594468 81524 solver.cpp:252]     Train net output #1: loss = 1.12146 (* 1 = 1.12146 loss)
I0726 20:00:37.135619 81524 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0726 20:01:33.773818 81524 solver.cpp:236] Iteration 950, loss = 1.05801
I0726 20:01:33.773986 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:01:33.774008 81524 solver.cpp:252]     Train net output #1: loss = 0.945986 (* 1 = 0.945986 loss)
I0726 20:01:38.504182 81524 sgd_solver.cpp:106] Iteration 950, lr = 0.01
I0726 20:02:32.047031 81524 solver.cpp:236] Iteration 960, loss = 1.05243
I0726 20:02:32.047405 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:02:32.047451 81524 solver.cpp:252]     Train net output #1: loss = 1.08156 (* 1 = 1.08156 loss)
I0726 20:02:36.581027 81524 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0726 20:03:28.494709 81524 solver.cpp:236] Iteration 970, loss = 1.05293
I0726 20:03:28.494931 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:03:28.494958 81524 solver.cpp:252]     Train net output #1: loss = 1.07324 (* 1 = 1.07324 loss)
I0726 20:03:34.003959 81524 sgd_solver.cpp:106] Iteration 970, lr = 0.01
I0726 20:04:25.122812 81524 solver.cpp:236] Iteration 980, loss = 1.04986
I0726 20:04:25.122972 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:04:25.123004 81524 solver.cpp:252]     Train net output #1: loss = 1.08878 (* 1 = 1.08878 loss)
I0726 20:04:29.797535 81524 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0726 20:05:21.241374 81524 solver.cpp:236] Iteration 990, loss = 1.04623
I0726 20:05:21.241572 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:05:21.241605 81524 solver.cpp:252]     Train net output #1: loss = 1.0092 (* 1 = 1.0092 loss)
I0726 20:05:25.876888 81524 sgd_solver.cpp:106] Iteration 990, lr = 0.01
I0726 20:06:16.560348 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_1000.caffemodel
I0726 20:06:16.709803 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_1000.solverstate
I0726 20:06:16.716785 81524 solver.cpp:340] Iteration 1000, Testing net (#0)
I0726 20:08:49.173182 81524 solver.cpp:408]     Test net output #0: accuracy = 0.494
I0726 20:08:49.173387 81524 solver.cpp:408]     Test net output #1: loss = 1.0365 (* 1 = 1.0365 loss)
I0726 20:08:50.184121 81524 solver.cpp:236] Iteration 1000, loss = 1.04924
I0726 20:08:50.184191 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:08:50.184233 81524 solver.cpp:252]     Train net output #1: loss = 1.01755 (* 1 = 1.01755 loss)
I0726 20:08:52.341579 81524 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0726 20:08:52.367285 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 20:09:37.865619 81524 solver.cpp:236] Iteration 1010, loss = 1.03895
I0726 20:09:37.865878 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:09:37.865921 81524 solver.cpp:252]     Train net output #1: loss = 1.00529 (* 1 = 1.00529 loss)
I0726 20:09:42.182159 81524 sgd_solver.cpp:106] Iteration 1010, lr = 0.01
I0726 20:10:28.890305 81524 solver.cpp:236] Iteration 1020, loss = 1.03838
I0726 20:10:28.890599 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:10:28.890620 81524 solver.cpp:252]     Train net output #1: loss = 1.09832 (* 1 = 1.09832 loss)
I0726 20:10:33.125807 81524 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0726 20:11:20.142130 81524 solver.cpp:236] Iteration 1030, loss = 1.04311
I0726 20:11:20.142410 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 20:11:20.142452 81524 solver.cpp:252]     Train net output #1: loss = 1.13216 (* 1 = 1.13216 loss)
I0726 20:11:24.698884 81524 sgd_solver.cpp:106] Iteration 1030, lr = 0.01
I0726 20:12:12.650125 81524 solver.cpp:236] Iteration 1040, loss = 1.04307
I0726 20:12:12.650322 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:12:12.650346 81524 solver.cpp:252]     Train net output #1: loss = 0.977745 (* 1 = 0.977745 loss)
I0726 20:12:14.539566 81524 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0726 20:13:04.402878 81524 solver.cpp:236] Iteration 1050, loss = 1.05109
I0726 20:13:04.403095 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:13:04.403138 81524 solver.cpp:252]     Train net output #1: loss = 0.980271 (* 1 = 0.980271 loss)
I0726 20:13:08.170636 81524 sgd_solver.cpp:106] Iteration 1050, lr = 0.01
I0726 20:13:55.669124 81524 solver.cpp:236] Iteration 1060, loss = 1.05102
I0726 20:13:55.669298 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:13:55.669342 81524 solver.cpp:252]     Train net output #1: loss = 1.07942 (* 1 = 1.07942 loss)
I0726 20:13:59.432401 81524 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0726 20:14:46.880903 81524 solver.cpp:236] Iteration 1070, loss = 1.03865
I0726 20:14:46.881078 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:14:46.881116 81524 solver.cpp:252]     Train net output #1: loss = 0.978801 (* 1 = 0.978801 loss)
I0726 20:14:50.922446 81524 sgd_solver.cpp:106] Iteration 1070, lr = 0.01
I0726 20:15:40.264739 81524 solver.cpp:236] Iteration 1080, loss = 1.03595
I0726 20:15:40.264900 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:15:40.264922 81524 solver.cpp:252]     Train net output #1: loss = 0.91233 (* 1 = 0.91233 loss)
I0726 20:15:44.584825 81524 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0726 20:16:30.843799 81524 solver.cpp:236] Iteration 1090, loss = 1.0388
I0726 20:16:30.843976 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:16:30.844012 81524 solver.cpp:252]     Train net output #1: loss = 1.02209 (* 1 = 1.02209 loss)
I0726 20:16:34.980084 81524 sgd_solver.cpp:106] Iteration 1090, lr = 0.01
I0726 20:17:21.401671 81524 solver.cpp:340] Iteration 1100, Testing net (#0)
I0726 20:19:50.169601 81524 solver.cpp:408]     Test net output #0: accuracy = 0.474
I0726 20:19:50.169889 81524 solver.cpp:408]     Test net output #1: loss = 1.05345 (* 1 = 1.05345 loss)
I0726 20:19:51.179102 81524 solver.cpp:236] Iteration 1100, loss = 1.03605
I0726 20:19:51.179183 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:19:51.179208 81524 solver.cpp:252]     Train net output #1: loss = 1.0377 (* 1 = 1.0377 loss)
I0726 20:19:53.526012 81524 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0726 20:20:40.911506 81524 solver.cpp:236] Iteration 1110, loss = 1.03682
I0726 20:20:40.913023 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:20:40.913065 81524 solver.cpp:252]     Train net output #1: loss = 0.934574 (* 1 = 0.934574 loss)
I0726 20:20:45.300267 81524 sgd_solver.cpp:106] Iteration 1110, lr = 0.01
I0726 20:21:32.828873 81524 solver.cpp:236] Iteration 1120, loss = 1.04214
I0726 20:21:32.829080 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:21:32.829105 81524 solver.cpp:252]     Train net output #1: loss = 1.03789 (* 1 = 1.03789 loss)
I0726 20:21:37.390377 81524 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0726 20:22:24.422338 81524 solver.cpp:236] Iteration 1130, loss = 1.03523
I0726 20:22:24.422528 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:22:24.422561 81524 solver.cpp:252]     Train net output #1: loss = 1.01277 (* 1 = 1.01277 loss)
I0726 20:22:29.264735 81524 sgd_solver.cpp:106] Iteration 1130, lr = 0.01
I0726 20:23:19.747396 81524 solver.cpp:236] Iteration 1140, loss = 1.02325
I0726 20:23:19.747725 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:23:19.747752 81524 solver.cpp:252]     Train net output #1: loss = 0.982227 (* 1 = 0.982227 loss)
I0726 20:23:24.715315 81524 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0726 20:24:14.560247 81524 solver.cpp:236] Iteration 1150, loss = 1.03465
I0726 20:24:14.560458 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 20:24:14.560477 81524 solver.cpp:252]     Train net output #1: loss = 1.08734 (* 1 = 1.08734 loss)
I0726 20:24:17.620236 81524 sgd_solver.cpp:106] Iteration 1150, lr = 0.01
I0726 20:25:10.376353 81524 solver.cpp:236] Iteration 1160, loss = 1.04985
I0726 20:25:10.376476 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:25:10.376495 81524 solver.cpp:252]     Train net output #1: loss = 0.974844 (* 1 = 0.974844 loss)
I0726 20:25:14.549245 81524 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0726 20:26:03.518254 81524 solver.cpp:236] Iteration 1170, loss = 1.05695
I0726 20:26:03.518380 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:26:03.518400 81524 solver.cpp:252]     Train net output #1: loss = 1.04834 (* 1 = 1.04834 loss)
I0726 20:26:08.450986 81524 sgd_solver.cpp:106] Iteration 1170, lr = 0.01
I0726 20:26:59.546726 81524 solver.cpp:236] Iteration 1180, loss = 1.06004
I0726 20:26:59.547011 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:26:59.547044 81524 solver.cpp:252]     Train net output #1: loss = 1.03245 (* 1 = 1.03245 loss)
I0726 20:27:03.992614 81524 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0726 20:27:51.611845 81524 solver.cpp:236] Iteration 1190, loss = 1.06132
I0726 20:27:51.612087 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:27:51.612118 81524 solver.cpp:252]     Train net output #1: loss = 0.981679 (* 1 = 0.981679 loss)
I0726 20:27:56.025970 81524 sgd_solver.cpp:106] Iteration 1190, lr = 0.01
I0726 20:28:42.102705 81524 solver.cpp:340] Iteration 1200, Testing net (#0)
I0726 20:29:32.505158 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 20:31:22.879834 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4875
I0726 20:31:22.880009 81524 solver.cpp:408]     Test net output #1: loss = 1.03815 (* 1 = 1.03815 loss)
I0726 20:31:23.883668 81524 solver.cpp:236] Iteration 1200, loss = 1.049
I0726 20:31:23.883715 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:31:23.883735 81524 solver.cpp:252]     Train net output #1: loss = 1.09521 (* 1 = 1.09521 loss)
I0726 20:31:26.344985 81524 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0726 20:32:17.149210 81524 solver.cpp:236] Iteration 1210, loss = 1.04004
I0726 20:32:17.149413 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:32:17.149438 81524 solver.cpp:252]     Train net output #1: loss = 1.04484 (* 1 = 1.04484 loss)
I0726 20:32:21.865489 81524 sgd_solver.cpp:106] Iteration 1210, lr = 0.01
I0726 20:33:10.414938 81524 solver.cpp:236] Iteration 1220, loss = 1.03967
I0726 20:33:10.415197 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:33:10.415220 81524 solver.cpp:252]     Train net output #1: loss = 1.15422 (* 1 = 1.15422 loss)
I0726 20:33:15.589699 81524 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0726 20:34:07.229725 81524 solver.cpp:236] Iteration 1230, loss = 1.04237
I0726 20:34:07.229954 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:34:07.229987 81524 solver.cpp:252]     Train net output #1: loss = 1.11597 (* 1 = 1.11597 loss)
I0726 20:34:11.428735 81524 sgd_solver.cpp:106] Iteration 1230, lr = 0.01
I0726 20:35:04.721493 81524 solver.cpp:236] Iteration 1240, loss = 1.05766
I0726 20:35:04.721668 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 20:35:04.721688 81524 solver.cpp:252]     Train net output #1: loss = 1.14237 (* 1 = 1.14237 loss)
I0726 20:35:09.321571 81524 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0726 20:36:01.206918 81524 solver.cpp:236] Iteration 1250, loss = 1.05862
I0726 20:36:01.207202 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:36:01.207236 81524 solver.cpp:252]     Train net output #1: loss = 1.12982 (* 1 = 1.12982 loss)
I0726 20:36:05.990767 81524 sgd_solver.cpp:106] Iteration 1250, lr = 0.01
I0726 20:36:58.004238 81524 solver.cpp:236] Iteration 1260, loss = 1.06242
I0726 20:36:58.004443 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:36:58.004468 81524 solver.cpp:252]     Train net output #1: loss = 1.11755 (* 1 = 1.11755 loss)
I0726 20:37:02.543891 81524 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0726 20:37:54.238839 81524 solver.cpp:236] Iteration 1270, loss = 1.06856
I0726 20:37:54.239060 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:37:54.239096 81524 solver.cpp:252]     Train net output #1: loss = 1.08511 (* 1 = 1.08511 loss)
I0726 20:37:59.236879 81524 sgd_solver.cpp:106] Iteration 1270, lr = 0.01
I0726 20:38:50.475078 81524 solver.cpp:236] Iteration 1280, loss = 1.05869
I0726 20:38:50.475252 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:38:50.475291 81524 solver.cpp:252]     Train net output #1: loss = 0.949905 (* 1 = 0.949905 loss)
I0726 20:38:53.861183 81524 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0726 20:39:47.333021 81524 solver.cpp:236] Iteration 1290, loss = 1.05636
I0726 20:39:47.333277 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:39:47.333310 81524 solver.cpp:252]     Train net output #1: loss = 1.03915 (* 1 = 1.03915 loss)
I0726 20:39:52.195029 81524 sgd_solver.cpp:106] Iteration 1290, lr = 0.01
I0726 20:40:45.041648 81524 solver.cpp:340] Iteration 1300, Testing net (#0)
I0726 20:43:19.717949 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5005
I0726 20:43:19.718247 81524 solver.cpp:408]     Test net output #1: loss = 1.03924 (* 1 = 1.03924 loss)
I0726 20:43:20.717068 81524 solver.cpp:236] Iteration 1300, loss = 1.06031
I0726 20:43:20.717128 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:43:20.717149 81524 solver.cpp:252]     Train net output #1: loss = 0.973657 (* 1 = 0.973657 loss)
I0726 20:43:22.327280 81524 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0726 20:44:17.028561 81524 solver.cpp:236] Iteration 1310, loss = 1.0596
I0726 20:44:17.028736 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:44:17.028756 81524 solver.cpp:252]     Train net output #1: loss = 1.08679 (* 1 = 1.08679 loss)
I0726 20:44:21.653064 81524 sgd_solver.cpp:106] Iteration 1310, lr = 0.01
I0726 20:45:14.295621 81524 solver.cpp:236] Iteration 1320, loss = 1.0477
I0726 20:45:14.295886 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:45:14.295915 81524 solver.cpp:252]     Train net output #1: loss = 1.09696 (* 1 = 1.09696 loss)
I0726 20:45:19.521857 81524 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0726 20:46:12.566107 81524 solver.cpp:236] Iteration 1330, loss = 1.04664
I0726 20:46:12.566388 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:46:12.566416 81524 solver.cpp:252]     Train net output #1: loss = 0.963476 (* 1 = 0.963476 loss)
I0726 20:46:14.859722 81524 sgd_solver.cpp:106] Iteration 1330, lr = 0.01
I0726 20:47:03.287245 81524 solver.cpp:236] Iteration 1340, loss = 1.03999
I0726 20:47:03.287461 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:47:03.287489 81524 solver.cpp:252]     Train net output #1: loss = 0.949633 (* 1 = 0.949633 loss)
I0726 20:47:07.640327 81524 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0726 20:47:58.263660 81524 solver.cpp:236] Iteration 1350, loss = 1.04464
I0726 20:47:58.263919 81524 solver.cpp:252]     Train net output #0: accuracy = 0.0625
I0726 20:47:58.263949 81524 solver.cpp:252]     Train net output #1: loss = 1.30213 (* 1 = 1.30213 loss)
I0726 20:48:02.679348 81524 sgd_solver.cpp:106] Iteration 1350, lr = 0.01
I0726 20:48:52.852320 81524 solver.cpp:236] Iteration 1360, loss = 1.04481
I0726 20:48:52.852552 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:48:52.852574 81524 solver.cpp:252]     Train net output #1: loss = 1.01738 (* 1 = 1.01738 loss)
I0726 20:48:57.387612 81524 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0726 20:49:03.637821 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 20:49:42.430799 81524 solver.cpp:236] Iteration 1370, loss = 1.03809
I0726 20:49:42.431037 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 20:49:42.431067 81524 solver.cpp:252]     Train net output #1: loss = 0.955725 (* 1 = 0.955725 loss)
I0726 20:49:46.247324 81524 sgd_solver.cpp:106] Iteration 1370, lr = 0.01
I0726 20:50:30.893149 81524 solver.cpp:236] Iteration 1380, loss = 1.04922
I0726 20:50:30.893306 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:50:30.893326 81524 solver.cpp:252]     Train net output #1: loss = 1.08559 (* 1 = 1.08559 loss)
I0726 20:50:35.194419 81524 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0726 20:51:26.224069 81524 solver.cpp:236] Iteration 1390, loss = 1.03889
I0726 20:51:26.224272 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 20:51:26.224292 81524 solver.cpp:252]     Train net output #1: loss = 1.00154 (* 1 = 1.00154 loss)
I0726 20:51:31.049955 81524 sgd_solver.cpp:106] Iteration 1390, lr = 0.01
I0726 20:52:20.822036 81524 solver.cpp:340] Iteration 1400, Testing net (#0)
I0726 20:54:57.024441 81524 solver.cpp:408]     Test net output #0: accuracy = 0.506
I0726 20:54:57.024698 81524 solver.cpp:408]     Test net output #1: loss = 1.03756 (* 1 = 1.03756 loss)
I0726 20:54:58.032413 81524 solver.cpp:236] Iteration 1400, loss = 1.02713
I0726 20:54:58.032500 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:54:58.032536 81524 solver.cpp:252]     Train net output #1: loss = 1.10936 (* 1 = 1.10936 loss)
I0726 20:55:00.119609 81524 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0726 20:55:52.851317 81524 solver.cpp:236] Iteration 1410, loss = 1.03002
I0726 20:55:52.851488 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:55:52.851521 81524 solver.cpp:252]     Train net output #1: loss = 1.02345 (* 1 = 1.02345 loss)
I0726 20:55:53.347174 81524 sgd_solver.cpp:106] Iteration 1410, lr = 0.01
I0726 20:56:43.172749 81524 solver.cpp:236] Iteration 1420, loss = 1.03622
I0726 20:56:43.172972 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 20:56:43.172996 81524 solver.cpp:252]     Train net output #1: loss = 0.911395 (* 1 = 0.911395 loss)
I0726 20:56:47.539108 81524 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0726 20:57:35.893122 81524 solver.cpp:236] Iteration 1430, loss = 1.03919
I0726 20:57:35.893347 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 20:57:35.893388 81524 solver.cpp:252]     Train net output #1: loss = 1.19031 (* 1 = 1.19031 loss)
I0726 20:57:39.800060 81524 sgd_solver.cpp:106] Iteration 1430, lr = 0.01
I0726 20:58:29.555276 81524 solver.cpp:236] Iteration 1440, loss = 1.04481
I0726 20:58:29.555538 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 20:58:29.555593 81524 solver.cpp:252]     Train net output #1: loss = 1.12526 (* 1 = 1.12526 loss)
I0726 20:58:33.364557 81524 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0726 20:59:22.687208 81524 solver.cpp:236] Iteration 1450, loss = 1.04587
I0726 20:59:22.687537 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 20:59:22.687582 81524 solver.cpp:252]     Train net output #1: loss = 1.03877 (* 1 = 1.03877 loss)
I0726 20:59:26.982761 81524 sgd_solver.cpp:106] Iteration 1450, lr = 0.01
I0726 21:00:15.642972 81524 solver.cpp:236] Iteration 1460, loss = 1.03896
I0726 21:00:15.643203 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:00:15.643236 81524 solver.cpp:252]     Train net output #1: loss = 1.0312 (* 1 = 1.0312 loss)
I0726 21:00:19.824025 81524 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0726 21:01:08.096061 81524 solver.cpp:236] Iteration 1470, loss = 1.03085
I0726 21:01:08.096366 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:01:08.096388 81524 solver.cpp:252]     Train net output #1: loss = 0.998976 (* 1 = 0.998976 loss)
I0726 21:01:13.025763 81524 sgd_solver.cpp:106] Iteration 1470, lr = 0.01
I0726 21:02:04.354826 81524 solver.cpp:236] Iteration 1480, loss = 1.00815
I0726 21:02:04.355077 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 21:02:04.355105 81524 solver.cpp:252]     Train net output #1: loss = 0.9306 (* 1 = 0.9306 loss)
I0726 21:02:04.851258 81524 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0726 21:02:59.336467 81524 solver.cpp:236] Iteration 1490, loss = 0.997607
I0726 21:02:59.336652 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:02:59.336673 81524 solver.cpp:252]     Train net output #1: loss = 1.07809 (* 1 = 1.07809 loss)
I0726 21:02:59.968123 81524 sgd_solver.cpp:106] Iteration 1490, lr = 0.01
I0726 21:03:48.581218 81524 solver.cpp:340] Iteration 1500, Testing net (#0)
I0726 21:06:40.803728 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4885
I0726 21:06:40.804092 81524 solver.cpp:408]     Test net output #1: loss = 1.04382 (* 1 = 1.04382 loss)
I0726 21:06:41.754708 81524 solver.cpp:236] Iteration 1500, loss = 1.01783
I0726 21:06:41.754786 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 21:06:41.754817 81524 solver.cpp:252]     Train net output #1: loss = 1.09922 (* 1 = 1.09922 loss)
I0726 21:06:43.103834 81524 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0726 21:07:47.442122 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 21:07:50.230770 81524 solver.cpp:236] Iteration 1510, loss = 1.02621
I0726 21:07:50.230913 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 21:07:50.230963 81524 solver.cpp:252]     Train net output #1: loss = 1.09168 (* 1 = 1.09168 loss)
I0726 21:07:51.605049 81524 sgd_solver.cpp:106] Iteration 1510, lr = 0.01
I0726 21:09:03.247496 81524 solver.cpp:236] Iteration 1520, loss = 1.04094
I0726 21:09:03.247665 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:09:03.247716 81524 solver.cpp:252]     Train net output #1: loss = 0.963051 (* 1 = 0.963051 loss)
I0726 21:09:04.260900 81524 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0726 21:10:13.643270 81524 solver.cpp:236] Iteration 1530, loss = 1.05388
I0726 21:10:13.643476 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 21:10:13.643496 81524 solver.cpp:252]     Train net output #1: loss = 1.06774 (* 1 = 1.06774 loss)
I0726 21:10:18.983819 81524 sgd_solver.cpp:106] Iteration 1530, lr = 0.01
I0726 21:11:31.790680 81524 solver.cpp:236] Iteration 1540, loss = 1.07208
I0726 21:11:31.791034 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:11:31.791074 81524 solver.cpp:252]     Train net output #1: loss = 0.991611 (* 1 = 0.991611 loss)
I0726 21:11:33.502009 81524 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0726 21:12:37.015349 81524 solver.cpp:236] Iteration 1550, loss = 1.04828
I0726 21:12:37.015688 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:12:37.015745 81524 solver.cpp:252]     Train net output #1: loss = 0.974467 (* 1 = 0.974467 loss)
I0726 21:12:42.693919 81524 sgd_solver.cpp:106] Iteration 1550, lr = 0.01
I0726 21:13:54.417457 81524 solver.cpp:236] Iteration 1560, loss = 1.05541
I0726 21:13:54.417742 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:13:54.417801 81524 solver.cpp:252]     Train net output #1: loss = 0.977437 (* 1 = 0.977437 loss)
I0726 21:13:59.779309 81524 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0726 21:15:13.143040 81524 solver.cpp:236] Iteration 1570, loss = 1.04341
I0726 21:15:13.143359 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:15:13.143434 81524 solver.cpp:252]     Train net output #1: loss = 1.12043 (* 1 = 1.12043 loss)
I0726 21:15:14.853276 81524 sgd_solver.cpp:106] Iteration 1570, lr = 0.01
I0726 21:16:22.870496 81524 solver.cpp:236] Iteration 1580, loss = 1.0501
I0726 21:16:22.870740 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 21:16:22.870781 81524 solver.cpp:252]     Train net output #1: loss = 1.23436 (* 1 = 1.23436 loss)
I0726 21:16:28.581759 81524 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0726 21:17:22.208775 81524 solver.cpp:236] Iteration 1590, loss = 1.03264
I0726 21:17:22.208964 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:17:22.208986 81524 solver.cpp:252]     Train net output #1: loss = 0.996185 (* 1 = 0.996185 loss)
I0726 21:17:22.786759 81524 sgd_solver.cpp:106] Iteration 1590, lr = 0.01
I0726 21:18:13.090502 81524 solver.cpp:340] Iteration 1600, Testing net (#0)
I0726 21:20:41.589676 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5085
I0726 21:20:41.589900 81524 solver.cpp:408]     Test net output #1: loss = 1.03137 (* 1 = 1.03137 loss)
I0726 21:20:42.600232 81524 solver.cpp:236] Iteration 1600, loss = 1.04511
I0726 21:20:42.600299 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:20:42.600322 81524 solver.cpp:252]     Train net output #1: loss = 1.1808 (* 1 = 1.1808 loss)
I0726 21:20:44.753367 81524 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0726 21:21:36.120826 81524 solver.cpp:236] Iteration 1610, loss = 1.03158
I0726 21:21:36.121032 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 21:21:36.121068 81524 solver.cpp:252]     Train net output #1: loss = 0.892397 (* 1 = 0.892397 loss)
I0726 21:21:41.554898 81524 sgd_solver.cpp:106] Iteration 1610, lr = 0.01
I0726 21:22:32.823446 81524 solver.cpp:236] Iteration 1620, loss = 1.03566
I0726 21:22:32.823686 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:22:32.823715 81524 solver.cpp:252]     Train net output #1: loss = 1.12569 (* 1 = 1.12569 loss)
I0726 21:22:37.234200 81524 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0726 21:23:29.425854 81524 solver.cpp:236] Iteration 1630, loss = 1.0367
I0726 21:23:29.426043 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 21:23:29.426065 81524 solver.cpp:252]     Train net output #1: loss = 0.944579 (* 1 = 0.944579 loss)
I0726 21:23:34.228171 81524 sgd_solver.cpp:106] Iteration 1630, lr = 0.01
I0726 21:24:31.436574 81524 solver.cpp:236] Iteration 1640, loss = 1.05219
I0726 21:24:31.436763 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 21:24:31.436787 81524 solver.cpp:252]     Train net output #1: loss = 0.984069 (* 1 = 0.984069 loss)
I0726 21:24:31.927352 81524 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0726 21:25:25.810025 81524 solver.cpp:236] Iteration 1650, loss = 1.04551
I0726 21:25:25.810199 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 21:25:25.810221 81524 solver.cpp:252]     Train net output #1: loss = 0.94305 (* 1 = 0.94305 loss)
I0726 21:25:30.404991 81524 sgd_solver.cpp:106] Iteration 1650, lr = 0.01
I0726 21:26:22.707952 81524 solver.cpp:236] Iteration 1660, loss = 1.042
I0726 21:26:22.708112 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 21:26:22.708154 81524 solver.cpp:252]     Train net output #1: loss = 1.15799 (* 1 = 1.15799 loss)
I0726 21:26:27.312609 81524 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0726 21:27:17.996794 81524 solver.cpp:236] Iteration 1670, loss = 1.04725
I0726 21:27:17.997036 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:27:17.997063 81524 solver.cpp:252]     Train net output #1: loss = 1.00889 (* 1 = 1.00889 loss)
I0726 21:27:21.726826 81524 sgd_solver.cpp:106] Iteration 1670, lr = 0.01
I0726 21:28:10.414852 81524 solver.cpp:236] Iteration 1680, loss = 1.03743
I0726 21:28:10.415045 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:28:10.415096 81524 solver.cpp:252]     Train net output #1: loss = 1.05284 (* 1 = 1.05284 loss)
I0726 21:28:10.921392 81524 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0726 21:29:01.138437 81524 solver.cpp:236] Iteration 1690, loss = 1.04621
I0726 21:29:01.138684 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 21:29:01.138707 81524 solver.cpp:252]     Train net output #1: loss = 1.32547 (* 1 = 1.32547 loss)
I0726 21:29:05.671458 81524 sgd_solver.cpp:106] Iteration 1690, lr = 0.01
I0726 21:29:54.177299 81524 solver.cpp:340] Iteration 1700, Testing net (#0)
I0726 21:30:30.421087 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 21:32:30.846850 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4755
I0726 21:32:30.847190 81524 solver.cpp:408]     Test net output #1: loss = 1.04704 (* 1 = 1.04704 loss)
I0726 21:32:31.850289 81524 solver.cpp:236] Iteration 1700, loss = 1.05043
I0726 21:32:31.850354 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 21:32:31.850374 81524 solver.cpp:252]     Train net output #1: loss = 1.16834 (* 1 = 1.16834 loss)
I0726 21:32:33.992897 81524 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0726 21:33:21.325805 81524 solver.cpp:236] Iteration 1710, loss = 1.05062
I0726 21:33:21.325947 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:33:21.325970 81524 solver.cpp:252]     Train net output #1: loss = 1.11397 (* 1 = 1.11397 loss)
I0726 21:33:25.178228 81524 sgd_solver.cpp:106] Iteration 1710, lr = 0.01
I0726 21:34:11.298964 81524 solver.cpp:236] Iteration 1720, loss = 1.0474
I0726 21:34:11.299278 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 21:34:11.299322 81524 solver.cpp:252]     Train net output #1: loss = 1.04596 (* 1 = 1.04596 loss)
I0726 21:34:15.710489 81524 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0726 21:35:04.137567 81524 solver.cpp:236] Iteration 1730, loss = 1.05575
I0726 21:35:04.137789 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 21:35:04.137819 81524 solver.cpp:252]     Train net output #1: loss = 1.21385 (* 1 = 1.21385 loss)
I0726 21:35:08.452531 81524 sgd_solver.cpp:106] Iteration 1730, lr = 0.01
I0726 21:35:56.305114 81524 solver.cpp:236] Iteration 1740, loss = 1.04962
I0726 21:35:56.305402 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:35:56.305449 81524 solver.cpp:252]     Train net output #1: loss = 1.03653 (* 1 = 1.03653 loss)
I0726 21:36:00.643677 81524 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0726 21:36:49.418936 81524 solver.cpp:236] Iteration 1750, loss = 1.0325
I0726 21:36:49.419159 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:36:49.419189 81524 solver.cpp:252]     Train net output #1: loss = 0.962268 (* 1 = 0.962268 loss)
I0726 21:36:53.772619 81524 sgd_solver.cpp:106] Iteration 1750, lr = 0.01
I0726 21:37:42.206878 81524 solver.cpp:236] Iteration 1760, loss = 1.03246
I0726 21:37:42.207070 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:37:42.207103 81524 solver.cpp:252]     Train net output #1: loss = 0.98677 (* 1 = 0.98677 loss)
I0726 21:37:46.560758 81524 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0726 21:38:34.353636 81524 solver.cpp:236] Iteration 1770, loss = 1.03029
I0726 21:38:34.353834 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:38:34.353878 81524 solver.cpp:252]     Train net output #1: loss = 1.00934 (* 1 = 1.00934 loss)
I0726 21:38:39.587857 81524 sgd_solver.cpp:106] Iteration 1770, lr = 0.01
I0726 21:39:29.512482 81524 solver.cpp:236] Iteration 1780, loss = 1.02832
I0726 21:39:29.512614 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:39:29.512645 81524 solver.cpp:252]     Train net output #1: loss = 1.05243 (* 1 = 1.05243 loss)
I0726 21:39:30.107292 81524 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0726 21:40:21.614203 81524 solver.cpp:236] Iteration 1790, loss = 1.02669
I0726 21:40:21.614387 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:40:21.614411 81524 solver.cpp:252]     Train net output #1: loss = 1.12748 (* 1 = 1.12748 loss)
I0726 21:40:24.156565 81524 sgd_solver.cpp:106] Iteration 1790, lr = 0.01
I0726 21:41:11.624670 81524 solver.cpp:340] Iteration 1800, Testing net (#0)
I0726 21:43:48.117383 81524 solver.cpp:408]     Test net output #0: accuracy = 0.503
I0726 21:43:48.117558 81524 solver.cpp:408]     Test net output #1: loss = 1.03181 (* 1 = 1.03181 loss)
I0726 21:43:49.094089 81524 solver.cpp:236] Iteration 1800, loss = 1.04199
I0726 21:43:49.094174 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 21:43:49.094238 81524 solver.cpp:252]     Train net output #1: loss = 1.19204 (* 1 = 1.19204 loss)
I0726 21:43:51.892639 81524 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0726 21:44:42.857326 81524 solver.cpp:236] Iteration 1810, loss = 1.04826
I0726 21:44:42.857501 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:44:42.857523 81524 solver.cpp:252]     Train net output #1: loss = 1.16302 (* 1 = 1.16302 loss)
I0726 21:44:47.337476 81524 sgd_solver.cpp:106] Iteration 1810, lr = 0.01
I0726 21:45:36.888516 81524 solver.cpp:236] Iteration 1820, loss = 1.04857
I0726 21:45:36.888696 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 21:45:36.888741 81524 solver.cpp:252]     Train net output #1: loss = 0.943991 (* 1 = 0.943991 loss)
I0726 21:45:41.101584 81524 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0726 21:46:29.131701 81524 solver.cpp:236] Iteration 1830, loss = 1.04541
I0726 21:46:29.131990 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:46:29.132024 81524 solver.cpp:252]     Train net output #1: loss = 1.02116 (* 1 = 1.02116 loss)
I0726 21:46:33.364184 81524 sgd_solver.cpp:106] Iteration 1830, lr = 0.01
I0726 21:47:23.053908 81524 solver.cpp:236] Iteration 1840, loss = 1.05015
I0726 21:47:23.054122 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 21:47:23.054144 81524 solver.cpp:252]     Train net output #1: loss = 1.04196 (* 1 = 1.04196 loss)
I0726 21:47:27.718654 81524 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0726 21:48:19.582104 81524 solver.cpp:236] Iteration 1850, loss = 1.03822
I0726 21:48:19.582290 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:48:19.582324 81524 solver.cpp:252]     Train net output #1: loss = 0.997019 (* 1 = 0.997019 loss)
I0726 21:48:20.175568 81524 sgd_solver.cpp:106] Iteration 1850, lr = 0.01
I0726 21:49:13.525982 81524 solver.cpp:236] Iteration 1860, loss = 1.03966
I0726 21:49:13.526227 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 21:49:13.526250 81524 solver.cpp:252]     Train net output #1: loss = 1.14831 (* 1 = 1.14831 loss)
I0726 21:49:14.019603 81524 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0726 21:49:28.583506 81557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 21:50:04.155607 81524 solver.cpp:236] Iteration 1870, loss = 1.02878
I0726 21:50:04.155794 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 21:50:04.155817 81524 solver.cpp:252]     Train net output #1: loss = 0.922994 (* 1 = 0.922994 loss)
I0726 21:50:08.485491 81524 sgd_solver.cpp:106] Iteration 1870, lr = 0.01
I0726 21:50:58.522189 81524 solver.cpp:236] Iteration 1880, loss = 1.02652
I0726 21:50:58.522406 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 21:50:58.522435 81524 solver.cpp:252]     Train net output #1: loss = 1.0259 (* 1 = 1.0259 loss)
I0726 21:51:02.938371 81524 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0726 21:51:57.592903 81524 solver.cpp:236] Iteration 1890, loss = 1.01379
I0726 21:51:57.593184 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 21:51:57.593222 81524 solver.cpp:252]     Train net output #1: loss = 1.14619 (* 1 = 1.14619 loss)
I0726 21:51:58.234686 81524 sgd_solver.cpp:106] Iteration 1890, lr = 0.01
I0726 21:52:50.746304 81524 solver.cpp:340] Iteration 1900, Testing net (#0)
I0726 21:55:20.735570 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5025
I0726 21:55:20.735738 81524 solver.cpp:408]     Test net output #1: loss = 1.02806 (* 1 = 1.02806 loss)
I0726 21:55:21.744343 81524 solver.cpp:236] Iteration 1900, loss = 1.0186
I0726 21:55:21.744405 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:55:21.744427 81524 solver.cpp:252]     Train net output #1: loss = 0.96736 (* 1 = 0.96736 loss)
I0726 21:55:23.676625 81524 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0726 21:56:18.547124 81524 solver.cpp:236] Iteration 1910, loss = 1.01459
I0726 21:56:18.547369 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 21:56:18.547394 81524 solver.cpp:252]     Train net output #1: loss = 0.937695 (* 1 = 0.937695 loss)
I0726 21:56:19.487820 81524 sgd_solver.cpp:106] Iteration 1910, lr = 0.01
I0726 21:57:10.988813 81524 solver.cpp:236] Iteration 1920, loss = 1.02823
I0726 21:57:10.989097 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 21:57:10.989120 81524 solver.cpp:252]     Train net output #1: loss = 1.05362 (* 1 = 1.05362 loss)
I0726 21:57:15.598000 81524 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0726 21:58:10.119789 81524 solver.cpp:236] Iteration 1930, loss = 1.03152
I0726 21:58:10.119984 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:58:10.120018 81524 solver.cpp:252]     Train net output #1: loss = 1.00824 (* 1 = 1.00824 loss)
I0726 21:58:10.985893 81524 sgd_solver.cpp:106] Iteration 1930, lr = 0.01
I0726 21:59:04.862339 81524 solver.cpp:236] Iteration 1940, loss = 1.03207
I0726 21:59:04.862576 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 21:59:04.862608 81524 solver.cpp:252]     Train net output #1: loss = 0.966145 (* 1 = 0.966145 loss)
I0726 21:59:05.729746 81524 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0726 21:59:59.019275 81524 solver.cpp:236] Iteration 1950, loss = 1.03592
I0726 21:59:59.019456 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 21:59:59.019506 81524 solver.cpp:252]     Train net output #1: loss = 0.957481 (* 1 = 0.957481 loss)
I0726 22:00:03.105139 81524 sgd_solver.cpp:106] Iteration 1950, lr = 0.01
I0726 22:00:54.808912 81524 solver.cpp:236] Iteration 1960, loss = 1.03049
I0726 22:00:54.809103 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:00:54.809135 81524 solver.cpp:252]     Train net output #1: loss = 1.08361 (* 1 = 1.08361 loss)
I0726 22:00:59.716482 81524 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0726 22:01:51.415940 81524 solver.cpp:236] Iteration 1970, loss = 1.03251
I0726 22:01:51.416225 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:01:51.416249 81524 solver.cpp:252]     Train net output #1: loss = 1.06902 (* 1 = 1.06902 loss)
I0726 22:01:55.993784 81524 sgd_solver.cpp:106] Iteration 1970, lr = 0.01
I0726 22:02:50.092901 81524 solver.cpp:236] Iteration 1980, loss = 1.03941
I0726 22:02:50.093191 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:02:50.093216 81524 solver.cpp:252]     Train net output #1: loss = 0.940885 (* 1 = 0.940885 loss)
I0726 22:02:54.620896 81524 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0726 22:03:47.818477 81524 solver.cpp:236] Iteration 1990, loss = 1.04063
I0726 22:03:47.818694 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 22:03:47.819649 81524 solver.cpp:252]     Train net output #1: loss = 0.968558 (* 1 = 0.968558 loss)
I0726 22:03:51.849436 81524 sgd_solver.cpp:106] Iteration 1990, lr = 0.01
I0726 22:04:42.555430 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_2000.caffemodel
I0726 22:04:42.653455 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_2000.solverstate
I0726 22:04:42.657271 81524 solver.cpp:340] Iteration 2000, Testing net (#0)
I0726 22:07:25.342046 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4935
I0726 22:07:25.342329 81524 solver.cpp:408]     Test net output #1: loss = 1.03695 (* 1 = 1.03695 loss)
I0726 22:07:26.345685 81524 solver.cpp:236] Iteration 2000, loss = 1.03747
I0726 22:07:26.345746 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 22:07:26.345772 81524 solver.cpp:252]     Train net output #1: loss = 0.918303 (* 1 = 0.918303 loss)
I0726 22:07:28.804555 81524 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0726 22:07:35.963122 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 22:08:17.586730 81524 solver.cpp:236] Iteration 2010, loss = 1.03518
I0726 22:08:17.586958 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 22:08:17.587003 81524 solver.cpp:252]     Train net output #1: loss = 0.860991 (* 1 = 0.860991 loss)
I0726 22:08:21.816845 81524 sgd_solver.cpp:106] Iteration 2010, lr = 0.01
I0726 22:09:09.861318 81524 solver.cpp:236] Iteration 2020, loss = 1.02422
I0726 22:09:09.861510 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:09:09.861564 81524 solver.cpp:252]     Train net output #1: loss = 0.94766 (* 1 = 0.94766 loss)
I0726 22:09:14.602434 81524 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0726 22:10:00.492851 81524 solver.cpp:236] Iteration 2030, loss = 1.01435
I0726 22:10:00.493041 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:10:00.493062 81524 solver.cpp:252]     Train net output #1: loss = 0.918077 (* 1 = 0.918077 loss)
I0726 22:10:05.402988 81524 sgd_solver.cpp:106] Iteration 2030, lr = 0.01
I0726 22:10:51.363318 81524 solver.cpp:236] Iteration 2040, loss = 1.01776
I0726 22:10:51.363559 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:10:51.363581 81524 solver.cpp:252]     Train net output #1: loss = 1.09351 (* 1 = 1.09351 loss)
I0726 22:10:56.408975 81524 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0726 22:11:46.894295 81524 solver.cpp:236] Iteration 2050, loss = 1.01657
I0726 22:11:46.894570 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:11:46.894605 81524 solver.cpp:252]     Train net output #1: loss = 0.992245 (* 1 = 0.992245 loss)
I0726 22:11:47.641083 81524 sgd_solver.cpp:106] Iteration 2050, lr = 0.01
I0726 22:12:36.144541 81524 solver.cpp:236] Iteration 2060, loss = 1.02275
I0726 22:12:36.144763 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:12:36.144785 81524 solver.cpp:252]     Train net output #1: loss = 1.13902 (* 1 = 1.13902 loss)
I0726 22:12:41.253888 81524 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0726 22:13:32.137713 81524 solver.cpp:236] Iteration 2070, loss = 1.02716
I0726 22:13:32.137909 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 22:13:32.137938 81524 solver.cpp:252]     Train net output #1: loss = 0.979689 (* 1 = 0.979689 loss)
I0726 22:13:32.644510 81524 sgd_solver.cpp:106] Iteration 2070, lr = 0.01
I0726 22:14:18.660820 81524 solver.cpp:236] Iteration 2080, loss = 1.03164
I0726 22:14:18.661116 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:14:18.661155 81524 solver.cpp:252]     Train net output #1: loss = 1.24039 (* 1 = 1.24039 loss)
I0726 22:14:23.995173 81524 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0726 22:15:11.170706 81524 solver.cpp:236] Iteration 2090, loss = 1.02836
I0726 22:15:11.170886 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:15:11.170908 81524 solver.cpp:252]     Train net output #1: loss = 1.07066 (* 1 = 1.07066 loss)
I0726 22:15:15.455081 81524 sgd_solver.cpp:106] Iteration 2090, lr = 0.01
I0726 22:16:01.741756 81524 solver.cpp:340] Iteration 2100, Testing net (#0)
I0726 22:18:34.198427 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4975
I0726 22:18:34.198606 81524 solver.cpp:408]     Test net output #1: loss = 1.02918 (* 1 = 1.02918 loss)
I0726 22:18:35.204238 81524 solver.cpp:236] Iteration 2100, loss = 1.03248
I0726 22:18:35.204300 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:18:35.204324 81524 solver.cpp:252]     Train net output #1: loss = 1.11706 (* 1 = 1.11706 loss)
I0726 22:18:37.656651 81524 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0726 22:19:23.819685 81524 solver.cpp:236] Iteration 2110, loss = 1.04499
I0726 22:19:23.819866 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:19:23.819886 81524 solver.cpp:252]     Train net output #1: loss = 1.05549 (* 1 = 1.05549 loss)
I0726 22:19:27.702774 81524 sgd_solver.cpp:106] Iteration 2110, lr = 0.01
I0726 22:20:16.030696 81524 solver.cpp:236] Iteration 2120, loss = 1.05513
I0726 22:20:16.031023 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:20:16.031050 81524 solver.cpp:252]     Train net output #1: loss = 1.08237 (* 1 = 1.08237 loss)
I0726 22:20:20.099256 81524 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0726 22:21:07.448596 81524 solver.cpp:236] Iteration 2130, loss = 1.06035
I0726 22:21:07.448900 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 22:21:07.448940 81524 solver.cpp:252]     Train net output #1: loss = 1.0521 (* 1 = 1.0521 loss)
I0726 22:21:12.111331 81524 sgd_solver.cpp:106] Iteration 2130, lr = 0.01
I0726 22:22:06.527298 81524 solver.cpp:236] Iteration 2140, loss = 1.06297
I0726 22:22:06.527477 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:22:06.527524 81524 solver.cpp:252]     Train net output #1: loss = 1.09957 (* 1 = 1.09957 loss)
I0726 22:22:07.211146 81524 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0726 22:23:01.388166 81524 solver.cpp:236] Iteration 2150, loss = 1.06596
I0726 22:23:01.388411 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 22:23:01.388438 81524 solver.cpp:252]     Train net output #1: loss = 1.05753 (* 1 = 1.05753 loss)
I0726 22:23:02.409487 81524 sgd_solver.cpp:106] Iteration 2150, lr = 0.01
I0726 22:24:00.803413 81524 solver.cpp:236] Iteration 2160, loss = 1.0552
I0726 22:24:00.803620 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:24:00.803640 81524 solver.cpp:252]     Train net output #1: loss = 1.08594 (* 1 = 1.08594 loss)
I0726 22:24:01.820662 81524 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0726 22:24:56.305428 81524 solver.cpp:236] Iteration 2170, loss = 1.05037
I0726 22:24:56.305613 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:24:56.305660 81524 solver.cpp:252]     Train net output #1: loss = 1.08025 (* 1 = 1.08025 loss)
I0726 22:24:57.135150 81524 sgd_solver.cpp:106] Iteration 2170, lr = 0.01
I0726 22:25:51.615547 81524 solver.cpp:236] Iteration 2180, loss = 1.05151
I0726 22:25:51.615839 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 22:25:51.615893 81524 solver.cpp:252]     Train net output #1: loss = 1.18647 (* 1 = 1.18647 loss)
I0726 22:25:52.511309 81524 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0726 22:26:55.773988 81524 solver.cpp:236] Iteration 2190, loss = 1.04584
I0726 22:26:55.774144 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:26:55.774168 81524 solver.cpp:252]     Train net output #1: loss = 0.976423 (* 1 = 0.976423 loss)
I0726 22:26:56.940269 81524 sgd_solver.cpp:106] Iteration 2190, lr = 0.01
I0726 22:27:55.795730 81524 solver.cpp:340] Iteration 2200, Testing net (#0)
I0726 22:28:41.835361 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 22:31:05.181430 81524 solver.cpp:408]     Test net output #0: accuracy = 0.513
I0726 22:31:05.181725 81524 solver.cpp:408]     Test net output #1: loss = 1.01816 (* 1 = 1.01816 loss)
I0726 22:31:06.132186 81524 solver.cpp:236] Iteration 2200, loss = 1.04469
I0726 22:31:06.132272 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:31:06.132310 81524 solver.cpp:252]     Train net output #1: loss = 1.18065 (* 1 = 1.18065 loss)
I0726 22:31:08.192435 81524 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0726 22:32:02.891306 81524 solver.cpp:236] Iteration 2210, loss = 1.03506
I0726 22:32:02.891516 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 22:32:02.891546 81524 solver.cpp:252]     Train net output #1: loss = 1.06752 (* 1 = 1.06752 loss)
I0726 22:32:07.380604 81524 sgd_solver.cpp:106] Iteration 2210, lr = 0.01
I0726 22:32:59.662906 81524 solver.cpp:236] Iteration 2220, loss = 1.03796
I0726 22:32:59.663228 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:32:59.663285 81524 solver.cpp:252]     Train net output #1: loss = 0.993367 (* 1 = 0.993367 loss)
I0726 22:33:04.959033 81524 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0726 22:33:59.070200 81524 solver.cpp:236] Iteration 2230, loss = 1.027
I0726 22:33:59.070401 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:33:59.070435 81524 solver.cpp:252]     Train net output #1: loss = 0.966108 (* 1 = 0.966108 loss)
I0726 22:34:03.792757 81524 sgd_solver.cpp:106] Iteration 2230, lr = 0.01
I0726 22:34:56.211120 81524 solver.cpp:236] Iteration 2240, loss = 1.03023
I0726 22:34:56.211406 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:34:56.211443 81524 solver.cpp:252]     Train net output #1: loss = 1.13494 (* 1 = 1.13494 loss)
I0726 22:35:01.350663 81524 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0726 22:35:52.116659 81524 solver.cpp:236] Iteration 2250, loss = 1.02532
I0726 22:35:52.116822 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 22:35:52.116866 81524 solver.cpp:252]     Train net output #1: loss = 0.914773 (* 1 = 0.914773 loss)
I0726 22:35:56.470043 81524 sgd_solver.cpp:106] Iteration 2250, lr = 0.01
I0726 22:36:48.343564 81524 solver.cpp:236] Iteration 2260, loss = 1.02751
I0726 22:36:48.343789 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 22:36:48.343828 81524 solver.cpp:252]     Train net output #1: loss = 0.951502 (* 1 = 0.951502 loss)
I0726 22:36:53.506292 81524 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0726 22:37:47.729034 81524 solver.cpp:236] Iteration 2270, loss = 1.01277
I0726 22:37:47.729239 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:37:47.729272 81524 solver.cpp:252]     Train net output #1: loss = 1.08809 (* 1 = 1.08809 loss)
I0726 22:37:48.719841 81524 sgd_solver.cpp:106] Iteration 2270, lr = 0.01
I0726 22:38:40.530478 81524 solver.cpp:236] Iteration 2280, loss = 1.01394
I0726 22:38:40.530700 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:38:40.530732 81524 solver.cpp:252]     Train net output #1: loss = 1.09555 (* 1 = 1.09555 loss)
I0726 22:38:45.016162 81524 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0726 22:39:40.299031 81524 solver.cpp:236] Iteration 2290, loss = 1.00687
I0726 22:39:40.299283 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:39:40.299315 81524 solver.cpp:252]     Train net output #1: loss = 1.08458 (* 1 = 1.08458 loss)
I0726 22:39:41.138819 81524 sgd_solver.cpp:106] Iteration 2290, lr = 0.01
I0726 22:40:33.591785 81524 solver.cpp:340] Iteration 2300, Testing net (#0)
I0726 22:43:04.094485 81524 solver.cpp:408]     Test net output #0: accuracy = 0.502
I0726 22:43:04.094817 81524 solver.cpp:408]     Test net output #1: loss = 1.02919 (* 1 = 1.02919 loss)
I0726 22:43:05.105067 81524 solver.cpp:236] Iteration 2300, loss = 1.01592
I0726 22:43:05.105132 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:43:05.105154 81524 solver.cpp:252]     Train net output #1: loss = 1.04659 (* 1 = 1.04659 loss)
I0726 22:43:07.370028 81524 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0726 22:44:04.192170 81524 solver.cpp:236] Iteration 2310, loss = 1.02094
I0726 22:44:04.192530 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:44:04.192592 81524 solver.cpp:252]     Train net output #1: loss = 1.05162 (* 1 = 1.05162 loss)
I0726 22:44:09.135320 81524 sgd_solver.cpp:106] Iteration 2310, lr = 0.01
I0726 22:45:07.001915 81524 solver.cpp:236] Iteration 2320, loss = 1.03563
I0726 22:45:07.002140 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 22:45:07.002177 81524 solver.cpp:252]     Train net output #1: loss = 1.03395 (* 1 = 1.03395 loss)
I0726 22:45:07.607282 81524 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0726 22:46:01.112169 81524 solver.cpp:236] Iteration 2330, loss = 1.04258
I0726 22:46:01.112402 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:46:01.112443 81524 solver.cpp:252]     Train net output #1: loss = 1.16845 (* 1 = 1.16845 loss)
I0726 22:46:05.717236 81524 sgd_solver.cpp:106] Iteration 2330, lr = 0.01
I0726 22:46:55.477073 81524 solver.cpp:236] Iteration 2340, loss = 1.05721
I0726 22:46:55.477325 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 22:46:55.477347 81524 solver.cpp:252]     Train net output #1: loss = 0.94523 (* 1 = 0.94523 loss)
I0726 22:46:59.554930 81524 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0726 22:47:46.198680 81524 solver.cpp:236] Iteration 2350, loss = 1.04885
I0726 22:47:46.198859 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:47:46.198892 81524 solver.cpp:252]     Train net output #1: loss = 1.05904 (* 1 = 1.05904 loss)
I0726 22:47:50.497563 81524 sgd_solver.cpp:106] Iteration 2350, lr = 0.01
I0726 22:48:25.041565 81557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 22:48:39.986039 81524 solver.cpp:236] Iteration 2360, loss = 1.05418
I0726 22:48:39.986158 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:48:39.986194 81524 solver.cpp:252]     Train net output #1: loss = 1.07973 (* 1 = 1.07973 loss)
I0726 22:48:45.237725 81524 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0726 22:49:37.976707 81524 solver.cpp:236] Iteration 2370, loss = 1.04463
I0726 22:49:37.976948 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:49:37.976986 81524 solver.cpp:252]     Train net output #1: loss = 0.980779 (* 1 = 0.980779 loss)
I0726 22:49:38.475083 81524 sgd_solver.cpp:106] Iteration 2370, lr = 0.01
I0726 22:50:27.667325 81524 solver.cpp:236] Iteration 2380, loss = 1.03289
I0726 22:50:27.667526 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 22:50:27.667552 81524 solver.cpp:252]     Train net output #1: loss = 0.984758 (* 1 = 0.984758 loss)
I0726 22:50:31.388059 81524 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0726 22:51:18.750973 81524 solver.cpp:236] Iteration 2390, loss = 1.02098
I0726 22:51:18.751277 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 22:51:18.751313 81524 solver.cpp:252]     Train net output #1: loss = 0.917673 (* 1 = 0.917673 loss)
I0726 22:51:22.986135 81524 sgd_solver.cpp:106] Iteration 2390, lr = 0.01
I0726 22:52:08.196322 81524 solver.cpp:340] Iteration 2400, Testing net (#0)
I0726 22:54:44.821642 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4945
I0726 22:54:44.821884 81524 solver.cpp:408]     Test net output #1: loss = 1.03585 (* 1 = 1.03585 loss)
I0726 22:54:45.779608 81524 solver.cpp:236] Iteration 2400, loss = 1.02697
I0726 22:54:45.779661 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0726 22:54:45.779682 81524 solver.cpp:252]     Train net output #1: loss = 1.18136 (* 1 = 1.18136 loss)
I0726 22:54:48.643510 81524 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0726 22:55:37.077925 81524 solver.cpp:236] Iteration 2410, loss = 1.02332
I0726 22:55:37.078140 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:55:37.078166 81524 solver.cpp:252]     Train net output #1: loss = 1.04197 (* 1 = 1.04197 loss)
I0726 22:55:42.582567 81524 sgd_solver.cpp:106] Iteration 2410, lr = 0.01
I0726 22:56:40.059803 81524 solver.cpp:236] Iteration 2420, loss = 1.0144
I0726 22:56:40.060024 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 22:56:40.060061 81524 solver.cpp:252]     Train net output #1: loss = 0.822448 (* 1 = 0.822448 loss)
I0726 22:56:45.623106 81524 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0726 22:57:41.759944 81524 solver.cpp:236] Iteration 2430, loss = 1.02499
I0726 22:57:41.760093 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:57:41.760114 81524 solver.cpp:252]     Train net output #1: loss = 1.09873 (* 1 = 1.09873 loss)
I0726 22:57:46.051753 81524 sgd_solver.cpp:106] Iteration 2430, lr = 0.01
I0726 22:58:37.665678 81524 solver.cpp:236] Iteration 2440, loss = 1.03156
I0726 22:58:37.665823 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 22:58:37.665845 81524 solver.cpp:252]     Train net output #1: loss = 1.14706 (* 1 = 1.14706 loss)
I0726 22:58:42.974138 81524 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0726 22:59:31.693634 81524 solver.cpp:236] Iteration 2450, loss = 1.02076
I0726 22:59:31.693920 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 22:59:31.693980 81524 solver.cpp:252]     Train net output #1: loss = 1.0009 (* 1 = 1.0009 loss)
I0726 22:59:34.278585 81524 sgd_solver.cpp:106] Iteration 2450, lr = 0.01
I0726 23:00:24.427758 81524 solver.cpp:236] Iteration 2460, loss = 1.00894
I0726 23:00:24.427917 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 23:00:24.427940 81524 solver.cpp:252]     Train net output #1: loss = 0.943867 (* 1 = 0.943867 loss)
I0726 23:00:27.437885 81524 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0726 23:01:16.095775 81524 solver.cpp:236] Iteration 2470, loss = 1.01707
I0726 23:01:16.095968 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:01:16.096019 81524 solver.cpp:252]     Train net output #1: loss = 0.931027 (* 1 = 0.931027 loss)
I0726 23:01:18.270737 81524 sgd_solver.cpp:106] Iteration 2470, lr = 0.01
I0726 23:02:10.364974 81524 solver.cpp:236] Iteration 2480, loss = 1.01102
I0726 23:02:10.365288 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:02:10.365329 81524 solver.cpp:252]     Train net output #1: loss = 0.98607 (* 1 = 0.98607 loss)
I0726 23:02:15.178864 81524 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0726 23:03:08.209584 81524 solver.cpp:236] Iteration 2490, loss = 0.997277
I0726 23:03:08.209748 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:03:08.209779 81524 solver.cpp:252]     Train net output #1: loss = 1.06642 (* 1 = 1.06642 loss)
I0726 23:03:08.857264 81524 sgd_solver.cpp:106] Iteration 2490, lr = 0.01
I0726 23:03:56.855492 81524 solver.cpp:340] Iteration 2500, Testing net (#0)
I0726 23:06:27.128453 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5
I0726 23:06:27.128705 81524 solver.cpp:408]     Test net output #1: loss = 1.03204 (* 1 = 1.03204 loss)
I0726 23:06:28.121402 81524 solver.cpp:236] Iteration 2500, loss = 1.00788
I0726 23:06:28.121497 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 23:06:28.121528 81524 solver.cpp:252]     Train net output #1: loss = 1.07081 (* 1 = 1.07081 loss)
I0726 23:06:30.139462 81524 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0726 23:06:41.211935 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 23:07:17.843029 81524 solver.cpp:236] Iteration 2510, loss = 1.01137
I0726 23:07:17.843267 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0726 23:07:17.843324 81524 solver.cpp:252]     Train net output #1: loss = 0.943521 (* 1 = 0.943521 loss)
I0726 23:07:22.063750 81524 sgd_solver.cpp:106] Iteration 2510, lr = 0.01
I0726 23:08:12.380501 81524 solver.cpp:236] Iteration 2520, loss = 1.00432
I0726 23:08:12.380691 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:08:12.380713 81524 solver.cpp:252]     Train net output #1: loss = 1.05343 (* 1 = 1.05343 loss)
I0726 23:08:16.707234 81524 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0726 23:09:06.309840 81524 solver.cpp:236] Iteration 2530, loss = 1.0022
I0726 23:09:06.310169 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 23:09:06.310204 81524 solver.cpp:252]     Train net output #1: loss = 1.19878 (* 1 = 1.19878 loss)
I0726 23:09:10.760705 81524 sgd_solver.cpp:106] Iteration 2530, lr = 0.01
I0726 23:09:59.818315 81524 solver.cpp:236] Iteration 2540, loss = 1.02469
I0726 23:09:59.818594 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 23:09:59.818620 81524 solver.cpp:252]     Train net output #1: loss = 1.23216 (* 1 = 1.23216 loss)
I0726 23:10:05.192819 81524 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0726 23:10:55.994855 81524 solver.cpp:236] Iteration 2550, loss = 1.01952
I0726 23:10:55.995071 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:10:55.995110 81524 solver.cpp:252]     Train net output #1: loss = 1.06201 (* 1 = 1.06201 loss)
I0726 23:11:00.052752 81524 sgd_solver.cpp:106] Iteration 2550, lr = 0.01
I0726 23:11:51.725474 81524 solver.cpp:236] Iteration 2560, loss = 1.02133
I0726 23:11:51.725860 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 23:11:51.725903 81524 solver.cpp:252]     Train net output #1: loss = 1.0938 (* 1 = 1.0938 loss)
I0726 23:11:56.221523 81524 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0726 23:12:47.618831 81524 solver.cpp:236] Iteration 2570, loss = 1.02623
I0726 23:12:47.619027 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:12:47.619072 81524 solver.cpp:252]     Train net output #1: loss = 1.04651 (* 1 = 1.04651 loss)
I0726 23:12:52.582275 81524 sgd_solver.cpp:106] Iteration 2570, lr = 0.01
I0726 23:13:44.997051 81524 solver.cpp:236] Iteration 2580, loss = 1.02875
I0726 23:13:44.997279 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:13:44.997300 81524 solver.cpp:252]     Train net output #1: loss = 0.979305 (* 1 = 0.979305 loss)
I0726 23:13:49.589860 81524 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0726 23:14:41.628598 81524 solver.cpp:236] Iteration 2590, loss = 1.01636
I0726 23:14:41.628800 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 23:14:41.628837 81524 solver.cpp:252]     Train net output #1: loss = 0.935648 (* 1 = 0.935648 loss)
I0726 23:14:46.664253 81524 sgd_solver.cpp:106] Iteration 2590, lr = 0.01
I0726 23:15:38.449256 81524 solver.cpp:340] Iteration 2600, Testing net (#0)
I0726 23:18:12.248800 81524 solver.cpp:408]     Test net output #0: accuracy = 0.504
I0726 23:18:12.249133 81524 solver.cpp:408]     Test net output #1: loss = 1.02176 (* 1 = 1.02176 loss)
I0726 23:18:13.260007 81524 solver.cpp:236] Iteration 2600, loss = 1.02652
I0726 23:18:13.260073 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:18:13.260093 81524 solver.cpp:252]     Train net output #1: loss = 1.08583 (* 1 = 1.08583 loss)
I0726 23:18:15.260532 81524 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0726 23:19:09.013028 81524 solver.cpp:236] Iteration 2610, loss = 1.03371
I0726 23:19:09.013308 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:19:09.013345 81524 solver.cpp:252]     Train net output #1: loss = 1.07254 (* 1 = 1.07254 loss)
I0726 23:19:09.589807 81524 sgd_solver.cpp:106] Iteration 2610, lr = 0.01
I0726 23:20:02.497009 81524 solver.cpp:236] Iteration 2620, loss = 1.04185
I0726 23:20:02.497182 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:20:02.497215 81524 solver.cpp:252]     Train net output #1: loss = 1.15168 (* 1 = 1.15168 loss)
I0726 23:20:05.808327 81524 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0726 23:20:59.012655 81524 solver.cpp:236] Iteration 2630, loss = 1.04721
I0726 23:20:59.012859 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 23:20:59.012883 81524 solver.cpp:252]     Train net output #1: loss = 1.14498 (* 1 = 1.14498 loss)
I0726 23:21:04.304595 81524 sgd_solver.cpp:106] Iteration 2630, lr = 0.01
I0726 23:21:57.717802 81524 solver.cpp:236] Iteration 2640, loss = 1.0588
I0726 23:21:57.717980 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 23:21:57.718024 81524 solver.cpp:252]     Train net output #1: loss = 1.23596 (* 1 = 1.23596 loss)
I0726 23:22:02.413671 81524 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0726 23:22:58.419536 81524 solver.cpp:236] Iteration 2650, loss = 1.04502
I0726 23:22:58.419782 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 23:22:58.419809 81524 solver.cpp:252]     Train net output #1: loss = 0.81502 (* 1 = 0.81502 loss)
I0726 23:23:00.688278 81524 sgd_solver.cpp:106] Iteration 2650, lr = 0.01
I0726 23:23:54.874358 81524 solver.cpp:236] Iteration 2660, loss = 1.04241
I0726 23:23:54.874706 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:23:54.874755 81524 solver.cpp:252]     Train net output #1: loss = 1.04146 (* 1 = 1.04146 loss)
I0726 23:23:59.520848 81524 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0726 23:24:55.907630 81524 solver.cpp:236] Iteration 2670, loss = 1.03874
I0726 23:24:55.907821 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:24:55.907860 81524 solver.cpp:252]     Train net output #1: loss = 0.965254 (* 1 = 0.965254 loss)
I0726 23:24:58.535161 81524 sgd_solver.cpp:106] Iteration 2670, lr = 0.01
I0726 23:25:47.034935 81524 solver.cpp:236] Iteration 2680, loss = 1.03112
I0726 23:25:47.035109 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:25:47.035141 81524 solver.cpp:252]     Train net output #1: loss = 0.990303 (* 1 = 0.990303 loss)
I0726 23:25:50.515089 81524 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0726 23:26:38.508492 81524 solver.cpp:236] Iteration 2690, loss = 1.00885
I0726 23:26:38.508716 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:26:38.508751 81524 solver.cpp:252]     Train net output #1: loss = 0.99962 (* 1 = 0.99962 loss)
I0726 23:26:43.091110 81524 sgd_solver.cpp:106] Iteration 2690, lr = 0.01
I0726 23:27:27.451583 81524 solver.cpp:340] Iteration 2700, Testing net (#0)
I0726 23:27:58.093171 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 23:30:01.777642 81524 solver.cpp:408]     Test net output #0: accuracy = 0.52
I0726 23:30:01.777848 81524 solver.cpp:408]     Test net output #1: loss = 1.00756 (* 1 = 1.00756 loss)
I0726 23:30:02.788329 81524 solver.cpp:236] Iteration 2700, loss = 1.01421
I0726 23:30:02.788421 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:30:02.788458 81524 solver.cpp:252]     Train net output #1: loss = 1.0944 (* 1 = 1.0944 loss)
I0726 23:30:05.017256 81524 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0726 23:30:53.567672 81524 solver.cpp:236] Iteration 2710, loss = 1.01344
I0726 23:30:53.567845 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:30:53.567865 81524 solver.cpp:252]     Train net output #1: loss = 1.06545 (* 1 = 1.06545 loss)
I0726 23:30:57.775981 81524 sgd_solver.cpp:106] Iteration 2710, lr = 0.01
I0726 23:31:45.877634 81524 solver.cpp:236] Iteration 2720, loss = 1.01099
I0726 23:31:45.877832 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:31:45.877856 81524 solver.cpp:252]     Train net output #1: loss = 0.96785 (* 1 = 0.96785 loss)
I0726 23:31:50.840549 81524 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0726 23:32:40.075906 81524 solver.cpp:236] Iteration 2730, loss = 1.02097
I0726 23:32:40.076105 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0726 23:32:40.076140 81524 solver.cpp:252]     Train net output #1: loss = 1.11762 (* 1 = 1.11762 loss)
I0726 23:32:40.748359 81524 sgd_solver.cpp:106] Iteration 2730, lr = 0.01
I0726 23:33:32.094547 81524 solver.cpp:236] Iteration 2740, loss = 1.03487
I0726 23:33:32.094738 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:33:32.094758 81524 solver.cpp:252]     Train net output #1: loss = 1.04179 (* 1 = 1.04179 loss)
I0726 23:33:32.608270 81524 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0726 23:34:23.242027 81524 solver.cpp:236] Iteration 2750, loss = 1.04377
I0726 23:34:23.242197 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 23:34:23.242219 81524 solver.cpp:252]     Train net output #1: loss = 1.13089 (* 1 = 1.13089 loss)
I0726 23:34:23.838011 81524 sgd_solver.cpp:106] Iteration 2750, lr = 0.01
I0726 23:35:12.471747 81524 solver.cpp:236] Iteration 2760, loss = 1.04187
I0726 23:35:12.472095 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 23:35:12.472118 81524 solver.cpp:252]     Train net output #1: loss = 0.907265 (* 1 = 0.907265 loss)
I0726 23:35:17.864737 81524 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0726 23:36:05.030535 81524 solver.cpp:236] Iteration 2770, loss = 1.05706
I0726 23:36:05.030814 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0726 23:36:05.030838 81524 solver.cpp:252]     Train net output #1: loss = 0.80455 (* 1 = 0.80455 loss)
I0726 23:36:09.390507 81524 sgd_solver.cpp:106] Iteration 2770, lr = 0.01
I0726 23:36:56.383828 81524 solver.cpp:236] Iteration 2780, loss = 1.05379
I0726 23:36:56.384052 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0726 23:36:56.384085 81524 solver.cpp:252]     Train net output #1: loss = 1.10594 (* 1 = 1.10594 loss)
I0726 23:37:00.859930 81524 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0726 23:37:49.020537 81524 solver.cpp:236] Iteration 2790, loss = 1.04994
I0726 23:37:49.020823 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:37:49.020854 81524 solver.cpp:252]     Train net output #1: loss = 1.00885 (* 1 = 1.00885 loss)
I0726 23:37:53.309234 81524 sgd_solver.cpp:106] Iteration 2790, lr = 0.01
I0726 23:38:46.771129 81524 solver.cpp:340] Iteration 2800, Testing net (#0)
I0726 23:42:18.409715 81524 solver.cpp:408]     Test net output #0: accuracy = 0.506
I0726 23:42:18.410121 81524 solver.cpp:408]     Test net output #1: loss = 1.02025 (* 1 = 1.02025 loss)
I0726 23:42:19.364254 81524 solver.cpp:236] Iteration 2800, loss = 1.03319
I0726 23:42:19.364356 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:42:19.364419 81524 solver.cpp:252]     Train net output #1: loss = 0.972814 (* 1 = 0.972814 loss)
I0726 23:42:20.868762 81524 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0726 23:43:32.677460 81524 solver.cpp:236] Iteration 2810, loss = 1.03355
I0726 23:43:32.677732 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0726 23:43:32.677772 81524 solver.cpp:252]     Train net output #1: loss = 0.863646 (* 1 = 0.863646 loss)
I0726 23:43:35.593269 81524 sgd_solver.cpp:106] Iteration 2810, lr = 0.01
I0726 23:44:50.367697 81524 solver.cpp:236] Iteration 2820, loss = 1.01374
I0726 23:44:50.368088 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:44:50.368172 81524 solver.cpp:252]     Train net output #1: loss = 0.973008 (* 1 = 0.973008 loss)
I0726 23:44:53.284642 81524 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0726 23:46:14.482005 81524 solver.cpp:236] Iteration 2830, loss = 1.02246
I0726 23:46:14.482280 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:46:14.482317 81524 solver.cpp:252]     Train net output #1: loss = 1.07904 (* 1 = 1.07904 loss)
I0726 23:46:15.844939 81524 sgd_solver.cpp:106] Iteration 2830, lr = 0.01
I0726 23:47:34.003521 81524 solver.cpp:236] Iteration 2840, loss = 1.03033
I0726 23:47:34.003785 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:47:34.003828 81524 solver.cpp:252]     Train net output #1: loss = 1.02913 (* 1 = 1.02913 loss)
I0726 23:47:34.878597 81524 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0726 23:48:55.316807 81524 solver.cpp:236] Iteration 2850, loss = 1.03409
I0726 23:48:55.317143 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:48:55.317229 81524 solver.cpp:252]     Train net output #1: loss = 1.04673 (* 1 = 1.04673 loss)
I0726 23:48:56.989923 81524 sgd_solver.cpp:106] Iteration 2850, lr = 0.01
I0726 23:49:11.382647 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 23:50:17.128345 81524 solver.cpp:236] Iteration 2860, loss = 1.03687
I0726 23:50:17.128705 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:50:17.128760 81524 solver.cpp:252]     Train net output #1: loss = 0.956564 (* 1 = 0.956564 loss)
I0726 23:50:23.431349 81524 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0726 23:51:47.014812 81524 solver.cpp:236] Iteration 2870, loss = 1.03999
I0726 23:51:47.015092 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0726 23:51:47.015141 81524 solver.cpp:252]     Train net output #1: loss = 0.984841 (* 1 = 0.984841 loss)
I0726 23:51:48.880676 81524 sgd_solver.cpp:106] Iteration 2870, lr = 0.01
I0726 23:53:10.750214 81524 solver.cpp:236] Iteration 2880, loss = 1.02692
I0726 23:53:10.750478 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0726 23:53:10.750516 81524 solver.cpp:252]     Train net output #1: loss = 1.04162 (* 1 = 1.04162 loss)
I0726 23:53:16.684221 81524 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0726 23:54:42.262934 81524 solver.cpp:236] Iteration 2890, loss = 1.02849
I0726 23:54:42.263263 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0726 23:54:42.263350 81524 solver.cpp:252]     Train net output #1: loss = 0.921546 (* 1 = 0.921546 loss)
I0726 23:54:43.828550 81524 sgd_solver.cpp:106] Iteration 2890, lr = 0.01
I0726 23:56:01.320374 81524 solver.cpp:340] Iteration 2900, Testing net (#0)
I0726 23:59:58.801041 81524 solver.cpp:408]     Test net output #0: accuracy = 0.522
I0726 23:59:58.801239 81524 solver.cpp:408]     Test net output #1: loss = 1.01061 (* 1 = 1.01061 loss)
I0726 23:59:59.756904 81524 solver.cpp:236] Iteration 2900, loss = 1.02928
I0726 23:59:59.756991 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0726 23:59:59.757030 81524 solver.cpp:252]     Train net output #1: loss = 0.964253 (* 1 = 0.964253 loss)
I0727 00:00:02.813961 81524 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0727 00:01:00.142249 81524 solver.cpp:236] Iteration 2910, loss = 1.02087
I0727 00:01:00.142416 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 00:01:00.142459 81524 solver.cpp:252]     Train net output #1: loss = 0.969498 (* 1 = 0.969498 loss)
I0727 00:01:04.670272 81524 sgd_solver.cpp:106] Iteration 2910, lr = 0.01
I0727 00:01:56.573379 81524 solver.cpp:236] Iteration 2920, loss = 1.02779
I0727 00:01:56.573583 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:01:56.573609 81524 solver.cpp:252]     Train net output #1: loss = 1.09317 (* 1 = 1.09317 loss)
I0727 00:02:01.488684 81524 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0727 00:02:52.837345 81524 solver.cpp:236] Iteration 2930, loss = 1.02701
I0727 00:02:52.837635 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 00:02:52.837671 81524 solver.cpp:252]     Train net output #1: loss = 0.96751 (* 1 = 0.96751 loss)
I0727 00:02:57.360926 81524 sgd_solver.cpp:106] Iteration 2930, lr = 0.01
I0727 00:03:49.221036 81524 solver.cpp:236] Iteration 2940, loss = 1.01925
I0727 00:03:49.221305 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:03:49.221355 81524 solver.cpp:252]     Train net output #1: loss = 1.03987 (* 1 = 1.03987 loss)
I0727 00:03:54.363759 81524 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0727 00:04:45.004971 81524 solver.cpp:236] Iteration 2950, loss = 1.01613
I0727 00:04:45.005162 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:04:45.005185 81524 solver.cpp:252]     Train net output #1: loss = 0.877188 (* 1 = 0.877188 loss)
I0727 00:04:49.106153 81524 sgd_solver.cpp:106] Iteration 2950, lr = 0.01
I0727 00:05:40.750188 81524 solver.cpp:236] Iteration 2960, loss = 1.01259
I0727 00:05:40.750382 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 00:05:40.750404 81524 solver.cpp:252]     Train net output #1: loss = 1.1565 (* 1 = 1.1565 loss)
I0727 00:05:45.154727 81524 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0727 00:06:39.067131 81524 solver.cpp:236] Iteration 2970, loss = 1.01403
I0727 00:06:39.067324 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:06:39.067366 81524 solver.cpp:252]     Train net output #1: loss = 1.141 (* 1 = 1.141 loss)
I0727 00:06:44.153010 81524 sgd_solver.cpp:106] Iteration 2970, lr = 0.01
I0727 00:07:37.038120 81524 solver.cpp:236] Iteration 2980, loss = 1.01261
I0727 00:07:37.038388 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:07:37.038422 81524 solver.cpp:252]     Train net output #1: loss = 1.02258 (* 1 = 1.02258 loss)
I0727 00:07:41.730972 81524 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0727 00:08:36.452549 81524 solver.cpp:236] Iteration 2990, loss = 1.01262
I0727 00:08:36.452821 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 00:08:36.452862 81524 solver.cpp:252]     Train net output #1: loss = 1.17965 (* 1 = 1.17965 loss)
I0727 00:08:41.027986 81524 sgd_solver.cpp:106] Iteration 2990, lr = 0.01
I0727 00:09:32.750341 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_3000.caffemodel
I0727 00:09:32.832860 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_3000.solverstate
I0727 00:09:32.836580 81524 solver.cpp:340] Iteration 3000, Testing net (#0)
I0727 00:11:40.014937 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 00:12:10.576719 81524 solver.cpp:408]     Test net output #0: accuracy = 0.537
I0727 00:12:10.576920 81524 solver.cpp:408]     Test net output #1: loss = 1.00581 (* 1 = 1.00581 loss)
I0727 00:12:11.585834 81524 solver.cpp:236] Iteration 3000, loss = 1.02042
I0727 00:12:11.585903 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 00:12:11.585927 81524 solver.cpp:252]     Train net output #1: loss = 1.05647 (* 1 = 1.05647 loss)
I0727 00:12:13.372458 81524 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0727 00:13:03.420112 81524 solver.cpp:236] Iteration 3010, loss = 1.03308
I0727 00:13:03.420369 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:13:03.420403 81524 solver.cpp:252]     Train net output #1: loss = 1.06418 (* 1 = 1.06418 loss)
I0727 00:13:07.944782 81524 sgd_solver.cpp:106] Iteration 3010, lr = 0.01
I0727 00:13:52.811076 81524 solver.cpp:236] Iteration 3020, loss = 1.03485
I0727 00:13:52.811313 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 00:13:52.811347 81524 solver.cpp:252]     Train net output #1: loss = 0.949106 (* 1 = 0.949106 loss)
I0727 00:13:56.817443 81524 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0727 00:14:43.322809 81524 solver.cpp:236] Iteration 3030, loss = 1.04527
I0727 00:14:43.323004 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 00:14:43.323036 81524 solver.cpp:252]     Train net output #1: loss = 1.05156 (* 1 = 1.05156 loss)
I0727 00:14:47.139484 81524 sgd_solver.cpp:106] Iteration 3030, lr = 0.01
I0727 00:15:33.969847 81524 solver.cpp:236] Iteration 3040, loss = 1.03498
I0727 00:15:33.970134 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:15:33.970175 81524 solver.cpp:252]     Train net output #1: loss = 0.937933 (* 1 = 0.937933 loss)
I0727 00:15:37.890394 81524 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0727 00:16:25.046648 81524 solver.cpp:236] Iteration 3050, loss = 1.0389
I0727 00:16:25.046803 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 00:16:25.046836 81524 solver.cpp:252]     Train net output #1: loss = 1.07407 (* 1 = 1.07407 loss)
I0727 00:16:28.983610 81524 sgd_solver.cpp:106] Iteration 3050, lr = 0.01
I0727 00:17:18.148943 81524 solver.cpp:236] Iteration 3060, loss = 1.03935
I0727 00:17:18.149266 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:17:18.149307 81524 solver.cpp:252]     Train net output #1: loss = 1.12069 (* 1 = 1.12069 loss)
I0727 00:17:22.853528 81524 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0727 00:18:11.285318 81524 solver.cpp:236] Iteration 3070, loss = 1.02811
I0727 00:18:11.287411 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 00:18:11.287443 81524 solver.cpp:252]     Train net output #1: loss = 0.807833 (* 1 = 0.807833 loss)
I0727 00:18:15.388262 81524 sgd_solver.cpp:106] Iteration 3070, lr = 0.01
I0727 00:19:03.141196 81524 solver.cpp:236] Iteration 3080, loss = 1.01048
I0727 00:19:03.141469 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 00:19:03.141494 81524 solver.cpp:252]     Train net output #1: loss = 0.811984 (* 1 = 0.811984 loss)
I0727 00:19:07.631160 81524 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0727 00:19:54.778946 81524 solver.cpp:236] Iteration 3090, loss = 1.0171
I0727 00:19:54.779089 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 00:19:54.779110 81524 solver.cpp:252]     Train net output #1: loss = 1.02209 (* 1 = 1.02209 loss)
I0727 00:19:59.692672 81524 sgd_solver.cpp:106] Iteration 3090, lr = 0.01
I0727 00:20:47.145179 81524 solver.cpp:340] Iteration 3100, Testing net (#0)
I0727 00:23:32.585746 81524 solver.cpp:408]     Test net output #0: accuracy = 0.506
I0727 00:23:32.585929 81524 solver.cpp:408]     Test net output #1: loss = 1.02425 (* 1 = 1.02425 loss)
I0727 00:23:33.591526 81524 solver.cpp:236] Iteration 3100, loss = 1.00544
I0727 00:23:33.591593 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 00:23:33.591615 81524 solver.cpp:252]     Train net output #1: loss = 1.03981 (* 1 = 1.03981 loss)
I0727 00:23:36.028281 81524 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0727 00:24:25.744047 81524 solver.cpp:236] Iteration 3110, loss = 0.998591
I0727 00:24:25.744282 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:24:25.744303 81524 solver.cpp:252]     Train net output #1: loss = 0.933502 (* 1 = 0.933502 loss)
I0727 00:24:26.230931 81524 sgd_solver.cpp:106] Iteration 3110, lr = 0.01
I0727 00:25:16.986325 81524 solver.cpp:236] Iteration 3120, loss = 0.998246
I0727 00:25:16.986528 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 00:25:16.986562 81524 solver.cpp:252]     Train net output #1: loss = 0.841662 (* 1 = 0.841662 loss)
I0727 00:25:21.437070 81524 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0727 00:26:14.498711 81524 solver.cpp:236] Iteration 3130, loss = 1.00123
I0727 00:26:14.499023 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 00:26:14.499063 81524 solver.cpp:252]     Train net output #1: loss = 0.896603 (* 1 = 0.896603 loss)
I0727 00:26:19.884897 81524 sgd_solver.cpp:106] Iteration 3130, lr = 0.01
I0727 00:27:11.283263 81524 solver.cpp:236] Iteration 3140, loss = 0.997493
I0727 00:27:11.283542 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 00:27:11.283573 81524 solver.cpp:252]     Train net output #1: loss = 0.950004 (* 1 = 0.950004 loss)
I0727 00:27:13.622972 81524 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0727 00:28:06.283128 81524 solver.cpp:236] Iteration 3150, loss = 0.994146
I0727 00:28:06.283408 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:28:06.283434 81524 solver.cpp:252]     Train net output #1: loss = 1.05641 (* 1 = 1.05641 loss)
I0727 00:28:11.237864 81524 sgd_solver.cpp:106] Iteration 3150, lr = 0.01
I0727 00:29:00.642654 81524 solver.cpp:236] Iteration 3160, loss = 1.00809
I0727 00:29:00.642907 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:29:00.642937 81524 solver.cpp:252]     Train net output #1: loss = 1.09339 (* 1 = 1.09339 loss)
I0727 00:29:05.271710 81524 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0727 00:29:52.401661 81524 solver.cpp:236] Iteration 3170, loss = 1.03475
I0727 00:29:52.401823 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:29:52.401845 81524 solver.cpp:252]     Train net output #1: loss = 1.14318 (* 1 = 1.14318 loss)
I0727 00:29:57.669417 81524 sgd_solver.cpp:106] Iteration 3170, lr = 0.01
I0727 00:30:45.287552 81524 solver.cpp:236] Iteration 3180, loss = 1.04212
I0727 00:30:45.287873 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:30:45.287916 81524 solver.cpp:252]     Train net output #1: loss = 1.10842 (* 1 = 1.10842 loss)
I0727 00:30:49.824901 81524 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0727 00:31:40.496023 81524 solver.cpp:236] Iteration 3190, loss = 1.04868
I0727 00:31:40.496228 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:31:40.496266 81524 solver.cpp:252]     Train net output #1: loss = 0.991289 (* 1 = 0.991289 loss)
I0727 00:31:44.736093 81524 sgd_solver.cpp:106] Iteration 3190, lr = 0.01
I0727 00:32:32.724916 81524 solver.cpp:340] Iteration 3200, Testing net (#0)
I0727 00:32:51.783222 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 00:35:06.806351 81524 solver.cpp:408]     Test net output #0: accuracy = 0.4975
I0727 00:35:06.806557 81524 solver.cpp:408]     Test net output #1: loss = 1.03764 (* 1 = 1.03764 loss)
I0727 00:35:07.810492 81524 solver.cpp:236] Iteration 3200, loss = 1.05682
I0727 00:35:07.810592 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:35:07.810636 81524 solver.cpp:252]     Train net output #1: loss = 0.93542 (* 1 = 0.93542 loss)
I0727 00:35:10.984247 81524 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0727 00:36:02.602895 81524 solver.cpp:236] Iteration 3210, loss = 1.05245
I0727 00:36:02.603173 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:36:02.603202 81524 solver.cpp:252]     Train net output #1: loss = 1.12212 (* 1 = 1.12212 loss)
I0727 00:36:07.291546 81524 sgd_solver.cpp:106] Iteration 3210, lr = 0.01
I0727 00:36:55.748250 81524 solver.cpp:236] Iteration 3220, loss = 1.03045
I0727 00:36:55.748482 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:36:55.748528 81524 solver.cpp:252]     Train net output #1: loss = 1.11275 (* 1 = 1.11275 loss)
I0727 00:37:00.271302 81524 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0727 00:37:49.256041 81524 solver.cpp:236] Iteration 3230, loss = 1.01568
I0727 00:37:49.256247 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:37:49.256283 81524 solver.cpp:252]     Train net output #1: loss = 1.07166 (* 1 = 1.07166 loss)
I0727 00:37:54.335705 81524 sgd_solver.cpp:106] Iteration 3230, lr = 0.01
I0727 00:38:43.872167 81524 solver.cpp:236] Iteration 3240, loss = 1.01467
I0727 00:38:43.872390 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 00:38:43.872414 81524 solver.cpp:252]     Train net output #1: loss = 0.928636 (* 1 = 0.928636 loss)
I0727 00:38:49.005903 81524 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0727 00:39:37.831104 81524 solver.cpp:236] Iteration 3250, loss = 1.00231
I0727 00:39:37.831346 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 00:39:37.831374 81524 solver.cpp:252]     Train net output #1: loss = 0.6897 (* 1 = 0.6897 loss)
I0727 00:39:42.432847 81524 sgd_solver.cpp:106] Iteration 3250, lr = 0.01
I0727 00:40:32.016465 81524 solver.cpp:236] Iteration 3260, loss = 0.980509
I0727 00:40:32.016685 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 00:40:32.016706 81524 solver.cpp:252]     Train net output #1: loss = 0.926553 (* 1 = 0.926553 loss)
I0727 00:40:36.342378 81524 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0727 00:41:27.279198 81524 solver.cpp:236] Iteration 3270, loss = 0.981765
I0727 00:41:27.279371 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:41:27.279412 81524 solver.cpp:252]     Train net output #1: loss = 0.929859 (* 1 = 0.929859 loss)
I0727 00:41:32.189919 81524 sgd_solver.cpp:106] Iteration 3270, lr = 0.01
I0727 00:42:21.670639 81524 solver.cpp:236] Iteration 3280, loss = 0.995249
I0727 00:42:21.670871 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 00:42:21.670892 81524 solver.cpp:252]     Train net output #1: loss = 1.18508 (* 1 = 1.18508 loss)
I0727 00:42:27.095072 81524 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0727 00:43:17.580459 81524 solver.cpp:236] Iteration 3290, loss = 0.982202
I0727 00:43:17.580687 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:43:17.580715 81524 solver.cpp:252]     Train net output #1: loss = 0.88185 (* 1 = 0.88185 loss)
I0727 00:43:21.609541 81524 sgd_solver.cpp:106] Iteration 3290, lr = 0.01
I0727 00:44:10.093025 81524 solver.cpp:340] Iteration 3300, Testing net (#0)
I0727 00:46:41.603332 81524 solver.cpp:408]     Test net output #0: accuracy = 0.523
I0727 00:46:41.603495 81524 solver.cpp:408]     Test net output #1: loss = 1.00429 (* 1 = 1.00429 loss)
I0727 00:46:42.566478 81524 solver.cpp:236] Iteration 3300, loss = 0.998508
I0727 00:46:42.566545 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:46:42.566566 81524 solver.cpp:252]     Train net output #1: loss = 1.09349 (* 1 = 1.09349 loss)
I0727 00:46:45.009224 81524 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0727 00:47:38.234876 81524 solver.cpp:236] Iteration 3310, loss = 1.00039
I0727 00:47:38.235075 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 00:47:38.235100 81524 solver.cpp:252]     Train net output #1: loss = 0.746349 (* 1 = 0.746349 loss)
I0727 00:47:38.831051 81524 sgd_solver.cpp:106] Iteration 3310, lr = 0.01
I0727 00:48:30.976745 81524 solver.cpp:236] Iteration 3320, loss = 1.00198
I0727 00:48:30.976994 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 00:48:30.977025 81524 solver.cpp:252]     Train net output #1: loss = 1.03377 (* 1 = 1.03377 loss)
I0727 00:48:35.097527 81524 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0727 00:49:25.711987 81524 solver.cpp:236] Iteration 3330, loss = 0.992986
I0727 00:49:25.712182 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:49:25.712226 81524 solver.cpp:252]     Train net output #1: loss = 0.923609 (* 1 = 0.923609 loss)
I0727 00:49:30.265324 81524 sgd_solver.cpp:106] Iteration 3330, lr = 0.01
I0727 00:50:19.403048 81524 solver.cpp:236] Iteration 3340, loss = 1.00874
I0727 00:50:19.403249 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 00:50:19.403273 81524 solver.cpp:252]     Train net output #1: loss = 0.955233 (* 1 = 0.955233 loss)
I0727 00:50:23.894141 81524 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0727 00:51:08.151319 81524 solver.cpp:236] Iteration 3350, loss = 1.01261
I0727 00:51:08.151515 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 00:51:08.151554 81524 solver.cpp:252]     Train net output #1: loss = 1.04828 (* 1 = 1.04828 loss)
I0727 00:51:12.215425 81524 sgd_solver.cpp:106] Iteration 3350, lr = 0.01
I0727 00:51:32.635659 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 00:51:56.865509 81524 solver.cpp:236] Iteration 3360, loss = 1.02438
I0727 00:51:56.865691 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:51:56.865712 81524 solver.cpp:252]     Train net output #1: loss = 1.08181 (* 1 = 1.08181 loss)
I0727 00:52:01.175484 81524 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0727 00:52:48.304687 81524 solver.cpp:236] Iteration 3370, loss = 1.02399
I0727 00:52:48.304882 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 00:52:48.304905 81524 solver.cpp:252]     Train net output #1: loss = 0.87347 (* 1 = 0.87347 loss)
I0727 00:52:52.405208 81524 sgd_solver.cpp:106] Iteration 3370, lr = 0.01
I0727 00:53:38.792968 81524 solver.cpp:236] Iteration 3380, loss = 1.019
I0727 00:53:38.793335 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 00:53:38.793370 81524 solver.cpp:252]     Train net output #1: loss = 0.996864 (* 1 = 0.996864 loss)
I0727 00:53:42.909098 81524 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0727 00:54:28.732952 81524 solver.cpp:236] Iteration 3390, loss = 1.00784
I0727 00:54:28.733136 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 00:54:28.733180 81524 solver.cpp:252]     Train net output #1: loss = 1.00875 (* 1 = 1.00875 loss)
I0727 00:54:31.615581 81524 sgd_solver.cpp:106] Iteration 3390, lr = 0.01
I0727 00:55:16.156673 81524 solver.cpp:340] Iteration 3400, Testing net (#0)
I0727 00:57:45.271625 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5165
I0727 00:57:45.271821 81524 solver.cpp:408]     Test net output #1: loss = 0.996708 (* 1 = 0.996708 loss)
I0727 00:57:46.344677 81524 solver.cpp:236] Iteration 3400, loss = 0.998684
I0727 00:57:46.344740 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:57:46.344761 81524 solver.cpp:252]     Train net output #1: loss = 1.17272 (* 1 = 1.17272 loss)
I0727 00:57:48.062541 81524 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0727 00:58:32.864248 81524 solver.cpp:236] Iteration 3410, loss = 1.00742
I0727 00:58:32.864433 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 00:58:32.864490 81524 solver.cpp:252]     Train net output #1: loss = 0.936293 (* 1 = 0.936293 loss)
I0727 00:58:37.582211 81524 sgd_solver.cpp:106] Iteration 3410, lr = 0.01
I0727 00:59:22.876127 81524 solver.cpp:236] Iteration 3420, loss = 1.00054
I0727 00:59:22.876291 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 00:59:22.876322 81524 solver.cpp:252]     Train net output #1: loss = 1.10556 (* 1 = 1.10556 loss)
I0727 00:59:27.887842 81524 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0727 01:00:14.021459 81524 solver.cpp:236] Iteration 3430, loss = 1.00767
I0727 01:00:14.021672 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 01:00:14.021693 81524 solver.cpp:252]     Train net output #1: loss = 0.866105 (* 1 = 0.866105 loss)
I0727 01:00:18.997133 81524 sgd_solver.cpp:106] Iteration 3430, lr = 0.01
I0727 01:01:10.017863 81524 solver.cpp:236] Iteration 3440, loss = 1.00327
I0727 01:01:10.018069 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:01:10.018093 81524 solver.cpp:252]     Train net output #1: loss = 0.899418 (* 1 = 0.899418 loss)
I0727 01:01:10.652432 81524 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0727 01:02:10.203022 81524 solver.cpp:236] Iteration 3450, loss = 1.00294
I0727 01:02:10.203316 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 01:02:10.203377 81524 solver.cpp:252]     Train net output #1: loss = 1.16459 (* 1 = 1.16459 loss)
I0727 01:02:11.370455 81524 sgd_solver.cpp:106] Iteration 3450, lr = 0.01
I0727 01:03:10.720896 81524 solver.cpp:236] Iteration 3460, loss = 0.989669
I0727 01:03:10.721177 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:03:10.721220 81524 solver.cpp:252]     Train net output #1: loss = 1.0019 (* 1 = 1.0019 loss)
I0727 01:03:12.041523 81524 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0727 01:04:02.561640 81524 solver.cpp:236] Iteration 3470, loss = 0.990926
I0727 01:04:02.561815 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:04:02.561893 81524 solver.cpp:252]     Train net output #1: loss = 1.00284 (* 1 = 1.00284 loss)
I0727 01:04:07.503396 81524 sgd_solver.cpp:106] Iteration 3470, lr = 0.01
I0727 01:05:00.875011 81524 solver.cpp:236] Iteration 3480, loss = 0.996135
I0727 01:05:00.875272 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:05:00.875310 81524 solver.cpp:252]     Train net output #1: loss = 0.957974 (* 1 = 0.957974 loss)
I0727 01:05:01.898078 81524 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0727 01:05:58.442358 81524 solver.cpp:236] Iteration 3490, loss = 1.01201
I0727 01:05:58.442512 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:05:58.442556 81524 solver.cpp:252]     Train net output #1: loss = 1.0856 (* 1 = 1.0856 loss)
I0727 01:06:02.851151 81524 sgd_solver.cpp:106] Iteration 3490, lr = 0.01
I0727 01:06:55.263381 81524 solver.cpp:340] Iteration 3500, Testing net (#0)
I0727 01:09:44.917485 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 01:09:46.051985 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5055
I0727 01:09:46.052080 81524 solver.cpp:408]     Test net output #1: loss = 1.01761 (* 1 = 1.01761 loss)
I0727 01:09:47.142669 81524 solver.cpp:236] Iteration 3500, loss = 1.01474
I0727 01:09:47.142737 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:09:47.142761 81524 solver.cpp:252]     Train net output #1: loss = 0.938613 (* 1 = 0.938613 loss)
I0727 01:09:49.330699 81524 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0727 01:10:38.988618 81524 solver.cpp:236] Iteration 3510, loss = 1.01901
I0727 01:10:38.988905 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 01:10:38.988931 81524 solver.cpp:252]     Train net output #1: loss = 1.03853 (* 1 = 1.03853 loss)
I0727 01:10:39.577968 81524 sgd_solver.cpp:106] Iteration 3510, lr = 0.01
I0727 01:11:30.360507 81524 solver.cpp:236] Iteration 3520, loss = 1.02237
I0727 01:11:30.360690 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 01:11:30.360713 81524 solver.cpp:252]     Train net output #1: loss = 0.832158 (* 1 = 0.832158 loss)
I0727 01:11:34.741024 81524 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0727 01:12:27.810721 81524 solver.cpp:236] Iteration 3530, loss = 1.01784
I0727 01:12:27.810901 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:12:27.810933 81524 solver.cpp:252]     Train net output #1: loss = 0.966891 (* 1 = 0.966891 loss)
I0727 01:12:28.705339 81524 sgd_solver.cpp:106] Iteration 3530, lr = 0.01
I0727 01:13:18.142700 81524 solver.cpp:236] Iteration 3540, loss = 1.01709
I0727 01:13:18.142951 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:13:18.142974 81524 solver.cpp:252]     Train net output #1: loss = 1.07799 (* 1 = 1.07799 loss)
I0727 01:13:22.348392 81524 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0727 01:14:11.936722 81524 solver.cpp:236] Iteration 3550, loss = 1.02356
I0727 01:14:11.936933 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:14:11.936967 81524 solver.cpp:252]     Train net output #1: loss = 0.941696 (* 1 = 0.941696 loss)
I0727 01:14:16.464493 81524 sgd_solver.cpp:106] Iteration 3550, lr = 0.01
I0727 01:15:09.322623 81524 solver.cpp:236] Iteration 3560, loss = 1.01487
I0727 01:15:09.322799 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 01:15:09.322820 81524 solver.cpp:252]     Train net output #1: loss = 1.0378 (* 1 = 1.0378 loss)
I0727 01:15:09.819896 81524 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0727 01:16:02.202415 81524 solver.cpp:236] Iteration 3570, loss = 1.01302
I0727 01:16:02.202637 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 01:16:02.202672 81524 solver.cpp:252]     Train net output #1: loss = 1.03254 (* 1 = 1.03254 loss)
I0727 01:16:03.376865 81524 sgd_solver.cpp:106] Iteration 3570, lr = 0.01
I0727 01:16:54.886874 81524 solver.cpp:236] Iteration 3580, loss = 1.01118
I0727 01:16:54.887033 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:16:54.887066 81524 solver.cpp:252]     Train net output #1: loss = 1.1412 (* 1 = 1.1412 loss)
I0727 01:16:59.259961 81524 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0727 01:17:50.353237 81524 solver.cpp:236] Iteration 3590, loss = 1.00905
I0727 01:17:50.353413 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:17:50.353447 81524 solver.cpp:252]     Train net output #1: loss = 1.05308 (* 1 = 1.05308 loss)
I0727 01:17:55.332676 81524 sgd_solver.cpp:106] Iteration 3590, lr = 0.01
I0727 01:18:43.889564 81524 solver.cpp:340] Iteration 3600, Testing net (#0)
I0727 01:21:15.225952 81524 solver.cpp:408]     Test net output #0: accuracy = 0.534
I0727 01:21:15.226250 81524 solver.cpp:408]     Test net output #1: loss = 0.99525 (* 1 = 0.99525 loss)
I0727 01:21:16.234823 81524 solver.cpp:236] Iteration 3600, loss = 1.0013
I0727 01:21:16.234887 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:21:16.234906 81524 solver.cpp:252]     Train net output #1: loss = 1.04734 (* 1 = 1.04734 loss)
I0727 01:21:18.037737 81524 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0727 01:22:07.732910 81524 solver.cpp:236] Iteration 3610, loss = 1.01035
I0727 01:22:07.733096 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:22:07.733119 81524 solver.cpp:252]     Train net output #1: loss = 1.0752 (* 1 = 1.0752 loss)
I0727 01:22:12.175271 81524 sgd_solver.cpp:106] Iteration 3610, lr = 0.01
I0727 01:23:06.906986 81524 solver.cpp:236] Iteration 3620, loss = 0.997064
I0727 01:23:06.907116 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:23:06.907137 81524 solver.cpp:252]     Train net output #1: loss = 0.992862 (* 1 = 0.992862 loss)
I0727 01:23:07.722293 81524 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0727 01:24:01.994534 81524 solver.cpp:236] Iteration 3630, loss = 1.01084
I0727 01:24:01.994740 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:24:01.994776 81524 solver.cpp:252]     Train net output #1: loss = 1.17201 (* 1 = 1.17201 loss)
I0727 01:24:06.255456 81524 sgd_solver.cpp:106] Iteration 3630, lr = 0.01
I0727 01:24:58.026819 81524 solver.cpp:236] Iteration 3640, loss = 1.01138
I0727 01:24:58.027133 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:24:58.027170 81524 solver.cpp:252]     Train net output #1: loss = 1.05321 (* 1 = 1.05321 loss)
I0727 01:25:03.110669 81524 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0727 01:25:53.481473 81524 solver.cpp:236] Iteration 3650, loss = 1.00923
I0727 01:25:53.481684 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 01:25:53.481724 81524 solver.cpp:252]     Train net output #1: loss = 0.926359 (* 1 = 0.926359 loss)
I0727 01:25:58.369354 81524 sgd_solver.cpp:106] Iteration 3650, lr = 0.01
I0727 01:26:49.598676 81524 solver.cpp:236] Iteration 3660, loss = 1.00936
I0727 01:26:49.598935 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:26:49.598964 81524 solver.cpp:252]     Train net output #1: loss = 0.911622 (* 1 = 0.911622 loss)
I0727 01:26:51.956156 81524 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0727 01:27:43.459316 81524 solver.cpp:236] Iteration 3670, loss = 1.01943
I0727 01:27:43.459611 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:27:43.459651 81524 solver.cpp:252]     Train net output #1: loss = 0.987746 (* 1 = 0.987746 loss)
I0727 01:27:48.062454 81524 sgd_solver.cpp:106] Iteration 3670, lr = 0.01
I0727 01:28:34.488143 81524 solver.cpp:236] Iteration 3680, loss = 1.00925
I0727 01:28:34.488387 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 01:28:34.488409 81524 solver.cpp:252]     Train net output #1: loss = 1.24936 (* 1 = 1.24936 loss)
I0727 01:28:39.138576 81524 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0727 01:29:25.378963 81524 solver.cpp:236] Iteration 3690, loss = 1.00107
I0727 01:29:25.379156 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:29:25.379179 81524 solver.cpp:252]     Train net output #1: loss = 0.919374 (* 1 = 0.919374 loss)
I0727 01:29:29.527357 81524 sgd_solver.cpp:106] Iteration 3690, lr = 0.01
I0727 01:30:13.373708 81524 solver.cpp:340] Iteration 3700, Testing net (#0)
I0727 01:30:43.156172 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 01:32:43.488255 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5175
I0727 01:32:43.488471 81524 solver.cpp:408]     Test net output #1: loss = 0.996117 (* 1 = 0.996117 loss)
I0727 01:32:44.498986 81524 solver.cpp:236] Iteration 3700, loss = 0.991728
I0727 01:32:44.499055 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:32:44.499075 81524 solver.cpp:252]     Train net output #1: loss = 1.15132 (* 1 = 1.15132 loss)
I0727 01:32:46.922704 81524 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0727 01:33:32.340700 81524 solver.cpp:236] Iteration 3710, loss = 0.976204
I0727 01:33:32.340904 81524 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0727 01:33:32.340924 81524 solver.cpp:252]     Train net output #1: loss = 0.666484 (* 1 = 0.666484 loss)
I0727 01:33:36.378059 81524 sgd_solver.cpp:106] Iteration 3710, lr = 0.01
I0727 01:34:22.864011 81524 solver.cpp:236] Iteration 3720, loss = 0.987825
I0727 01:34:22.864225 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 01:34:22.864253 81524 solver.cpp:252]     Train net output #1: loss = 0.990294 (* 1 = 0.990294 loss)
I0727 01:34:26.888700 81524 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0727 01:35:14.035483 81524 solver.cpp:236] Iteration 3730, loss = 0.980481
I0727 01:35:14.035673 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:35:14.035702 81524 solver.cpp:252]     Train net output #1: loss = 1.03993 (* 1 = 1.03993 loss)
I0727 01:35:17.983969 81524 sgd_solver.cpp:106] Iteration 3730, lr = 0.01
I0727 01:36:05.487903 81524 solver.cpp:236] Iteration 3740, loss = 0.989885
I0727 01:36:05.488134 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 01:36:05.488173 81524 solver.cpp:252]     Train net output #1: loss = 1.05371 (* 1 = 1.05371 loss)
I0727 01:36:09.497400 81524 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0727 01:36:55.557929 81524 solver.cpp:236] Iteration 3750, loss = 1.00118
I0727 01:36:55.558151 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:36:55.558169 81524 solver.cpp:252]     Train net output #1: loss = 1.00236 (* 1 = 1.00236 loss)
I0727 01:36:59.397099 81524 sgd_solver.cpp:106] Iteration 3750, lr = 0.01
I0727 01:37:47.164194 81524 solver.cpp:236] Iteration 3760, loss = 1.01799
I0727 01:37:47.164448 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:37:47.164475 81524 solver.cpp:252]     Train net output #1: loss = 0.976243 (* 1 = 0.976243 loss)
I0727 01:37:51.242332 81524 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0727 01:38:37.870429 81524 solver.cpp:236] Iteration 3770, loss = 1.01698
I0727 01:38:37.870604 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 01:38:37.870625 81524 solver.cpp:252]     Train net output #1: loss = 1.15103 (* 1 = 1.15103 loss)
I0727 01:38:41.754655 81524 sgd_solver.cpp:106] Iteration 3770, lr = 0.01
I0727 01:39:29.002813 81524 solver.cpp:236] Iteration 3780, loss = 1.03441
I0727 01:39:29.003012 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:39:29.003048 81524 solver.cpp:252]     Train net output #1: loss = 0.946525 (* 1 = 0.946525 loss)
I0727 01:39:29.691622 81524 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0727 01:40:17.019078 81524 solver.cpp:236] Iteration 3790, loss = 1.02615
I0727 01:40:17.019340 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:40:17.019368 81524 solver.cpp:252]     Train net output #1: loss = 0.857866 (* 1 = 0.857866 loss)
I0727 01:40:21.128701 81524 sgd_solver.cpp:106] Iteration 3790, lr = 0.01
I0727 01:41:08.866847 81524 solver.cpp:340] Iteration 3800, Testing net (#0)
I0727 01:43:39.259286 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5135
I0727 01:43:39.259505 81524 solver.cpp:408]     Test net output #1: loss = 1.01388 (* 1 = 1.01388 loss)
I0727 01:43:40.271051 81524 solver.cpp:236] Iteration 3800, loss = 1.01467
I0727 01:43:40.271116 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:43:40.271138 81524 solver.cpp:252]     Train net output #1: loss = 0.885197 (* 1 = 0.885197 loss)
I0727 01:43:42.189138 81524 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0727 01:44:28.339892 81524 solver.cpp:236] Iteration 3810, loss = 1.01159
I0727 01:44:28.340116 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:44:28.340149 81524 solver.cpp:252]     Train net output #1: loss = 0.930679 (* 1 = 0.930679 loss)
I0727 01:44:32.409504 81524 sgd_solver.cpp:106] Iteration 3810, lr = 0.01
I0727 01:45:18.934113 81524 solver.cpp:236] Iteration 3820, loss = 1.00592
I0727 01:45:18.934350 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 01:45:18.934383 81524 solver.cpp:252]     Train net output #1: loss = 0.9782 (* 1 = 0.9782 loss)
I0727 01:45:23.303786 81524 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0727 01:46:10.848526 81524 solver.cpp:236] Iteration 3830, loss = 0.99822
I0727 01:46:10.848709 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:46:10.848732 81524 solver.cpp:252]     Train net output #1: loss = 1.07001 (* 1 = 1.07001 loss)
I0727 01:46:14.760984 81524 sgd_solver.cpp:106] Iteration 3830, lr = 0.01
I0727 01:47:02.488807 81524 solver.cpp:236] Iteration 3840, loss = 0.999523
I0727 01:47:02.489007 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 01:47:02.489029 81524 solver.cpp:252]     Train net output #1: loss = 1.03631 (* 1 = 1.03631 loss)
I0727 01:47:06.831339 81524 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0727 01:47:55.217208 81524 solver.cpp:236] Iteration 3850, loss = 1.02218
I0727 01:47:55.221030 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 01:47:55.221076 81524 solver.cpp:252]     Train net output #1: loss = 1.17596 (* 1 = 1.17596 loss)
I0727 01:47:59.435933 81524 sgd_solver.cpp:106] Iteration 3850, lr = 0.01
I0727 01:48:48.724083 81524 solver.cpp:236] Iteration 3860, loss = 1.01946
I0727 01:48:48.724329 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:48:48.724364 81524 solver.cpp:252]     Train net output #1: loss = 0.972638 (* 1 = 0.972638 loss)
I0727 01:48:53.579382 81524 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0727 01:49:30.535586 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 01:49:40.323355 81524 solver.cpp:236] Iteration 3870, loss = 1.02461
I0727 01:49:40.323417 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 01:49:40.323436 81524 solver.cpp:252]     Train net output #1: loss = 0.963832 (* 1 = 0.963832 loss)
I0727 01:49:45.197558 81524 sgd_solver.cpp:106] Iteration 3870, lr = 0.01
I0727 01:50:37.191781 81524 solver.cpp:236] Iteration 3880, loss = 1.02533
I0727 01:50:37.192200 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:50:37.192232 81524 solver.cpp:252]     Train net output #1: loss = 0.918403 (* 1 = 0.918403 loss)
I0727 01:50:37.683140 81524 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0727 01:51:28.307049 81524 solver.cpp:236] Iteration 3890, loss = 1.01374
I0727 01:51:28.307204 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 01:51:28.307237 81524 solver.cpp:252]     Train net output #1: loss = 0.801154 (* 1 = 0.801154 loss)
I0727 01:51:32.269696 81524 sgd_solver.cpp:106] Iteration 3890, lr = 0.01
I0727 01:52:21.167042 81524 solver.cpp:340] Iteration 3900, Testing net (#0)
I0727 01:54:46.355537 81524 solver.cpp:408]     Test net output #0: accuracy = 0.522
I0727 01:54:46.355731 81524 solver.cpp:408]     Test net output #1: loss = 0.997652 (* 1 = 0.997652 loss)
I0727 01:54:47.372897 81524 solver.cpp:236] Iteration 3900, loss = 0.990981
I0727 01:54:47.372959 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 01:54:47.372977 81524 solver.cpp:252]     Train net output #1: loss = 0.890486 (* 1 = 0.890486 loss)
I0727 01:54:49.038293 81524 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0727 01:55:39.798182 81524 solver.cpp:236] Iteration 3910, loss = 0.987826
I0727 01:55:39.798368 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:55:39.798393 81524 solver.cpp:252]     Train net output #1: loss = 0.898486 (* 1 = 0.898486 loss)
I0727 01:55:44.261504 81524 sgd_solver.cpp:106] Iteration 3910, lr = 0.01
I0727 01:56:34.503074 81524 solver.cpp:236] Iteration 3920, loss = 0.980725
I0727 01:56:34.503311 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 01:56:34.503351 81524 solver.cpp:252]     Train net output #1: loss = 0.877159 (* 1 = 0.877159 loss)
I0727 01:56:38.872418 81524 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0727 01:57:29.277945 81524 solver.cpp:236] Iteration 3930, loss = 0.969802
I0727 01:57:29.278214 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 01:57:29.278235 81524 solver.cpp:252]     Train net output #1: loss = 0.844891 (* 1 = 0.844891 loss)
I0727 01:57:34.706274 81524 sgd_solver.cpp:106] Iteration 3930, lr = 0.01
I0727 01:58:24.451133 81524 solver.cpp:236] Iteration 3940, loss = 0.983328
I0727 01:58:24.451413 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 01:58:24.451437 81524 solver.cpp:252]     Train net output #1: loss = 0.953116 (* 1 = 0.953116 loss)
I0727 01:58:28.973191 81524 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0727 01:59:20.992944 81524 solver.cpp:236] Iteration 3950, loss = 0.987554
I0727 01:59:20.993160 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 01:59:20.993192 81524 solver.cpp:252]     Train net output #1: loss = 1.09934 (* 1 = 1.09934 loss)
I0727 01:59:25.430197 81524 sgd_solver.cpp:106] Iteration 3950, lr = 0.01
I0727 02:00:16.686350 81524 solver.cpp:236] Iteration 3960, loss = 0.989752
I0727 02:00:16.686517 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:00:16.686549 81524 solver.cpp:252]     Train net output #1: loss = 1.07014 (* 1 = 1.07014 loss)
I0727 02:00:21.968497 81524 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0727 02:01:11.318480 81524 solver.cpp:236] Iteration 3970, loss = 0.99294
I0727 02:01:11.318699 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:01:11.318733 81524 solver.cpp:252]     Train net output #1: loss = 0.877326 (* 1 = 0.877326 loss)
I0727 02:01:15.046286 81524 sgd_solver.cpp:106] Iteration 3970, lr = 0.01
I0727 02:02:07.752184 81524 solver.cpp:236] Iteration 3980, loss = 1.00739
I0727 02:02:07.752441 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:02:07.752485 81524 solver.cpp:252]     Train net output #1: loss = 0.9842 (* 1 = 0.9842 loss)
I0727 02:02:12.120606 81524 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0727 02:03:04.236510 81524 solver.cpp:236] Iteration 3990, loss = 0.990608
I0727 02:03:04.236778 81524 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0727 02:03:04.236801 81524 solver.cpp:252]     Train net output #1: loss = 0.818378 (* 1 = 0.818378 loss)
I0727 02:03:06.447273 81524 sgd_solver.cpp:106] Iteration 3990, lr = 0.01
I0727 02:03:55.142174 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_4000.caffemodel
I0727 02:03:55.235889 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_4000.solverstate
I0727 02:03:55.239440 81524 solver.cpp:340] Iteration 4000, Testing net (#0)
I0727 02:06:20.210176 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5245
I0727 02:06:20.210394 81524 solver.cpp:408]     Test net output #1: loss = 1.00452 (* 1 = 1.00452 loss)
I0727 02:06:21.180779 81524 solver.cpp:236] Iteration 4000, loss = 0.993224
I0727 02:06:21.180843 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:06:21.180863 81524 solver.cpp:252]     Train net output #1: loss = 0.911939 (* 1 = 0.911939 loss)
I0727 02:06:24.186890 81524 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0727 02:07:10.697556 81524 solver.cpp:236] Iteration 4010, loss = 0.998601
I0727 02:07:10.697660 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 02:07:10.697680 81524 solver.cpp:252]     Train net output #1: loss = 1.0457 (* 1 = 1.0457 loss)
I0727 02:07:15.510493 81524 sgd_solver.cpp:106] Iteration 4010, lr = 0.01
I0727 02:07:19.361152 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 02:08:02.399106 81524 solver.cpp:236] Iteration 4020, loss = 0.991028
I0727 02:08:02.399363 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 02:08:02.399402 81524 solver.cpp:252]     Train net output #1: loss = 1.34734 (* 1 = 1.34734 loss)
I0727 02:08:02.949955 81524 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0727 02:08:49.466784 81524 solver.cpp:236] Iteration 4030, loss = 0.984338
I0727 02:08:49.467016 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 02:08:49.467038 81524 solver.cpp:252]     Train net output #1: loss = 1.09898 (* 1 = 1.09898 loss)
I0727 02:08:53.194787 81524 sgd_solver.cpp:106] Iteration 4030, lr = 0.01
I0727 02:09:39.046427 81524 solver.cpp:236] Iteration 4040, loss = 1.00497
I0727 02:09:39.046658 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:09:39.046680 81524 solver.cpp:252]     Train net output #1: loss = 0.972535 (* 1 = 0.972535 loss)
I0727 02:09:43.152027 81524 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0727 02:10:28.314163 81524 solver.cpp:236] Iteration 4050, loss = 1.01107
I0727 02:10:28.314327 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:10:28.314348 81524 solver.cpp:252]     Train net output #1: loss = 0.979347 (* 1 = 0.979347 loss)
I0727 02:10:32.274705 81524 sgd_solver.cpp:106] Iteration 4050, lr = 0.01
I0727 02:11:18.097839 81524 solver.cpp:236] Iteration 4060, loss = 0.999668
I0727 02:11:18.098083 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 02:11:18.098109 81524 solver.cpp:252]     Train net output #1: loss = 0.924751 (* 1 = 0.924751 loss)
I0727 02:11:21.906764 81524 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0727 02:12:08.781601 81524 solver.cpp:236] Iteration 4070, loss = 1.01158
I0727 02:12:08.781847 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:12:08.781880 81524 solver.cpp:252]     Train net output #1: loss = 1.08041 (* 1 = 1.08041 loss)
I0727 02:12:10.718816 81524 sgd_solver.cpp:106] Iteration 4070, lr = 0.01
I0727 02:12:58.076488 81524 solver.cpp:236] Iteration 4080, loss = 1.01276
I0727 02:12:58.076738 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 02:12:58.076767 81524 solver.cpp:252]     Train net output #1: loss = 0.924541 (* 1 = 0.924541 loss)
I0727 02:13:02.206902 81524 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0727 02:13:48.958508 81524 solver.cpp:236] Iteration 4090, loss = 1.00879
I0727 02:13:48.958772 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 02:13:48.958793 81524 solver.cpp:252]     Train net output #1: loss = 1.13754 (* 1 = 1.13754 loss)
I0727 02:13:52.872182 81524 sgd_solver.cpp:106] Iteration 4090, lr = 0.01
I0727 02:14:37.958061 81524 solver.cpp:340] Iteration 4100, Testing net (#0)
I0727 02:17:16.432857 81524 solver.cpp:408]     Test net output #0: accuracy = 0.549
I0727 02:17:16.433078 81524 solver.cpp:408]     Test net output #1: loss = 0.984786 (* 1 = 0.984786 loss)
I0727 02:17:17.427763 81524 solver.cpp:236] Iteration 4100, loss = 1.00639
I0727 02:17:17.427860 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:17:17.427889 81524 solver.cpp:252]     Train net output #1: loss = 0.951832 (* 1 = 0.951832 loss)
I0727 02:17:19.156314 81524 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0727 02:18:19.721552 81524 solver.cpp:236] Iteration 4110, loss = 1.02118
I0727 02:18:19.721770 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:18:19.721810 81524 solver.cpp:252]     Train net output #1: loss = 0.896446 (* 1 = 0.896446 loss)
I0727 02:18:24.297307 81524 sgd_solver.cpp:106] Iteration 4110, lr = 0.01
I0727 02:19:27.014289 81524 solver.cpp:236] Iteration 4120, loss = 1.01221
I0727 02:19:27.014560 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 02:19:27.014598 81524 solver.cpp:252]     Train net output #1: loss = 1.05543 (* 1 = 1.05543 loss)
I0727 02:19:32.176379 81524 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0727 02:20:45.427775 81524 solver.cpp:236] Iteration 4130, loss = 1.01502
I0727 02:20:45.428061 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:20:45.428092 81524 solver.cpp:252]     Train net output #1: loss = 1.0328 (* 1 = 1.0328 loss)
I0727 02:20:46.841590 81524 sgd_solver.cpp:106] Iteration 4130, lr = 0.01
I0727 02:22:02.324331 81524 solver.cpp:236] Iteration 4140, loss = 1.02696
I0727 02:22:02.324543 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:22:02.324566 81524 solver.cpp:252]     Train net output #1: loss = 0.946941 (* 1 = 0.946941 loss)
I0727 02:22:03.153363 81524 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0727 02:23:20.754762 81524 solver.cpp:236] Iteration 4150, loss = 1.02547
I0727 02:23:20.755224 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 02:23:20.755276 81524 solver.cpp:252]     Train net output #1: loss = 1.07906 (* 1 = 1.07906 loss)
I0727 02:23:24.487398 81524 sgd_solver.cpp:106] Iteration 4150, lr = 0.01
I0727 02:24:39.529798 81524 solver.cpp:236] Iteration 4160, loss = 1.02241
I0727 02:24:39.530081 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:24:39.530119 81524 solver.cpp:252]     Train net output #1: loss = 1.04269 (* 1 = 1.04269 loss)
I0727 02:24:42.872277 81524 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0727 02:26:05.203310 81524 solver.cpp:236] Iteration 4170, loss = 1.02607
I0727 02:26:05.203619 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:26:05.203694 81524 solver.cpp:252]     Train net output #1: loss = 0.858241 (* 1 = 0.858241 loss)
I0727 02:26:06.942723 81524 sgd_solver.cpp:106] Iteration 4170, lr = 0.01
I0727 02:27:23.302343 81524 solver.cpp:236] Iteration 4180, loss = 1.02717
I0727 02:27:23.303462 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:27:23.303513 81524 solver.cpp:252]     Train net output #1: loss = 1.02284 (* 1 = 1.02284 loss)
I0727 02:27:24.987138 81524 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0727 02:28:44.967347 81524 solver.cpp:236] Iteration 4190, loss = 1.02187
I0727 02:28:44.967636 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:28:44.967689 81524 solver.cpp:252]     Train net output #1: loss = 1.01912 (* 1 = 1.01912 loss)
I0727 02:28:48.346370 81524 sgd_solver.cpp:106] Iteration 4190, lr = 0.01
I0727 02:29:58.959413 81524 solver.cpp:340] Iteration 4200, Testing net (#0)
I0727 02:31:06.531195 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 02:33:37.614857 81524 solver.cpp:408]     Test net output #0: accuracy = 0.521
I0727 02:33:37.615062 81524 solver.cpp:408]     Test net output #1: loss = 1.00732 (* 1 = 1.00732 loss)
I0727 02:33:38.577888 81524 solver.cpp:236] Iteration 4200, loss = 0.998149
I0727 02:33:38.577967 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:33:38.577996 81524 solver.cpp:252]     Train net output #1: loss = 0.924032 (* 1 = 0.924032 loss)
I0727 02:33:41.394264 81524 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0727 02:34:34.927536 81524 solver.cpp:236] Iteration 4210, loss = 0.998524
I0727 02:34:34.927713 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:34:34.927748 81524 solver.cpp:252]     Train net output #1: loss = 1.02306 (* 1 = 1.02306 loss)
I0727 02:34:37.370609 81524 sgd_solver.cpp:106] Iteration 4210, lr = 0.01
I0727 02:35:28.211973 81524 solver.cpp:236] Iteration 4220, loss = 1.00885
I0727 02:35:28.212119 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 02:35:28.212142 81524 solver.cpp:252]     Train net output #1: loss = 1.05146 (* 1 = 1.05146 loss)
I0727 02:35:32.420519 81524 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0727 02:36:22.251943 81524 solver.cpp:236] Iteration 4230, loss = 1.00345
I0727 02:36:22.252140 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 02:36:22.252168 81524 solver.cpp:252]     Train net output #1: loss = 0.911921 (* 1 = 0.911921 loss)
I0727 02:36:26.828445 81524 sgd_solver.cpp:106] Iteration 4230, lr = 0.01
I0727 02:37:20.091181 81524 solver.cpp:236] Iteration 4240, loss = 0.993595
I0727 02:37:20.091450 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 02:37:20.091492 81524 solver.cpp:252]     Train net output #1: loss = 0.842198 (* 1 = 0.842198 loss)
I0727 02:37:20.853761 81524 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0727 02:38:13.328819 81524 solver.cpp:236] Iteration 4250, loss = 1.01813
I0727 02:38:13.331490 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 02:38:13.331526 81524 solver.cpp:252]     Train net output #1: loss = 0.797949 (* 1 = 0.797949 loss)
I0727 02:38:17.318222 81524 sgd_solver.cpp:106] Iteration 4250, lr = 0.01
I0727 02:39:06.791168 81524 solver.cpp:236] Iteration 4260, loss = 1.01656
I0727 02:39:06.791357 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 02:39:06.791391 81524 solver.cpp:252]     Train net output #1: loss = 0.818456 (* 1 = 0.818456 loss)
I0727 02:39:11.078140 81524 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0727 02:40:00.435287 81524 solver.cpp:236] Iteration 4270, loss = 0.992435
I0727 02:40:00.438452 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:40:00.438490 81524 solver.cpp:252]     Train net output #1: loss = 0.96489 (* 1 = 0.96489 loss)
I0727 02:40:05.219540 81524 sgd_solver.cpp:106] Iteration 4270, lr = 0.01
I0727 02:40:57.485707 81524 solver.cpp:236] Iteration 4280, loss = 0.99124
I0727 02:40:57.485916 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:40:57.485937 81524 solver.cpp:252]     Train net output #1: loss = 0.970149 (* 1 = 0.970149 loss)
I0727 02:40:58.022645 81524 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0727 02:41:49.625003 81524 solver.cpp:236] Iteration 4290, loss = 0.993757
I0727 02:41:49.625274 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:41:49.625315 81524 solver.cpp:252]     Train net output #1: loss = 0.887169 (* 1 = 0.887169 loss)
I0727 02:41:54.633308 81524 sgd_solver.cpp:106] Iteration 4290, lr = 0.01
I0727 02:42:50.974143 81524 solver.cpp:340] Iteration 4300, Testing net (#0)
I0727 02:45:23.978947 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5445
I0727 02:45:23.979209 81524 solver.cpp:408]     Test net output #1: loss = 0.987183 (* 1 = 0.987183 loss)
I0727 02:45:24.988628 81524 solver.cpp:236] Iteration 4300, loss = 0.999113
I0727 02:45:24.988699 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:45:24.988723 81524 solver.cpp:252]     Train net output #1: loss = 1.16222 (* 1 = 1.16222 loss)
I0727 02:45:27.166890 81524 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0727 02:46:24.059571 81524 solver.cpp:236] Iteration 4310, loss = 0.983913
I0727 02:46:24.059804 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 02:46:24.059828 81524 solver.cpp:252]     Train net output #1: loss = 0.946584 (* 1 = 0.946584 loss)
I0727 02:46:24.615015 81524 sgd_solver.cpp:106] Iteration 4310, lr = 0.01
I0727 02:47:17.166992 81524 solver.cpp:236] Iteration 4320, loss = 1.00335
I0727 02:47:17.167193 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:47:17.167215 81524 solver.cpp:252]     Train net output #1: loss = 0.957651 (* 1 = 0.957651 loss)
I0727 02:47:21.916309 81524 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0727 02:48:14.268677 81524 solver.cpp:236] Iteration 4330, loss = 0.99505
I0727 02:48:14.268843 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 02:48:14.268864 81524 solver.cpp:252]     Train net output #1: loss = 1.13595 (* 1 = 1.13595 loss)
I0727 02:48:19.294430 81524 sgd_solver.cpp:106] Iteration 4330, lr = 0.01
I0727 02:49:12.566478 81524 solver.cpp:236] Iteration 4340, loss = 0.987006
I0727 02:49:12.566701 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:49:12.566746 81524 solver.cpp:252]     Train net output #1: loss = 0.843125 (* 1 = 0.843125 loss)
I0727 02:49:16.576499 81524 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0727 02:50:06.200404 81524 solver.cpp:236] Iteration 4350, loss = 0.984309
I0727 02:50:06.200626 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:50:06.200660 81524 solver.cpp:252]     Train net output #1: loss = 0.97228 (* 1 = 0.97228 loss)
I0727 02:50:10.471138 81524 sgd_solver.cpp:106] Iteration 4350, lr = 0.01
I0727 02:50:51.500778 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 02:50:57.829949 81524 solver.cpp:236] Iteration 4360, loss = 0.992698
I0727 02:50:57.830073 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 02:50:57.830106 81524 solver.cpp:252]     Train net output #1: loss = 1.29572 (* 1 = 1.29572 loss)
I0727 02:51:02.726531 81524 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0727 02:51:51.086736 81524 solver.cpp:236] Iteration 4370, loss = 0.991749
I0727 02:51:51.086908 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 02:51:51.086940 81524 solver.cpp:252]     Train net output #1: loss = 1.04586 (* 1 = 1.04586 loss)
I0727 02:51:55.728655 81524 sgd_solver.cpp:106] Iteration 4370, lr = 0.01
I0727 02:52:41.850427 81524 solver.cpp:236] Iteration 4380, loss = 0.991169
I0727 02:52:41.850663 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 02:52:41.850697 81524 solver.cpp:252]     Train net output #1: loss = 0.887566 (* 1 = 0.887566 loss)
I0727 02:52:46.662936 81524 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0727 02:53:33.144361 81524 solver.cpp:236] Iteration 4390, loss = 1.00248
I0727 02:53:33.144562 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:53:33.144583 81524 solver.cpp:252]     Train net output #1: loss = 1.00668 (* 1 = 1.00668 loss)
I0727 02:53:37.112717 81524 sgd_solver.cpp:106] Iteration 4390, lr = 0.01
I0727 02:54:23.739886 81524 solver.cpp:340] Iteration 4400, Testing net (#0)
I0727 02:57:09.520139 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5275
I0727 02:57:09.520401 81524 solver.cpp:408]     Test net output #1: loss = 0.991903 (* 1 = 0.991903 loss)
I0727 02:57:10.479275 81524 solver.cpp:236] Iteration 4400, loss = 1.00154
I0727 02:57:10.479363 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 02:57:10.479388 81524 solver.cpp:252]     Train net output #1: loss = 0.937068 (* 1 = 0.937068 loss)
I0727 02:57:12.989413 81524 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0727 02:58:03.206872 81524 solver.cpp:236] Iteration 4410, loss = 1.01184
I0727 02:58:03.207141 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 02:58:03.207170 81524 solver.cpp:252]     Train net output #1: loss = 1.18646 (* 1 = 1.18646 loss)
I0727 02:58:06.294288 81524 sgd_solver.cpp:106] Iteration 4410, lr = 0.01
I0727 02:58:54.616044 81524 solver.cpp:236] Iteration 4420, loss = 0.987679
I0727 02:58:54.616289 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 02:58:54.616309 81524 solver.cpp:252]     Train net output #1: loss = 0.973512 (* 1 = 0.973512 loss)
I0727 02:58:58.432974 81524 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0727 02:59:45.908983 81524 solver.cpp:236] Iteration 4430, loss = 0.982094
I0727 02:59:45.909236 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 02:59:45.909268 81524 solver.cpp:252]     Train net output #1: loss = 1.11547 (* 1 = 1.11547 loss)
I0727 02:59:49.750875 81524 sgd_solver.cpp:106] Iteration 4430, lr = 0.01
I0727 03:00:40.115274 81524 solver.cpp:236] Iteration 4440, loss = 0.976943
I0727 03:00:40.115574 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:00:40.115600 81524 solver.cpp:252]     Train net output #1: loss = 0.979356 (* 1 = 0.979356 loss)
I0727 03:00:44.534699 81524 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0727 03:01:31.052614 81524 solver.cpp:236] Iteration 4450, loss = 0.967202
I0727 03:01:31.052850 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 03:01:31.052876 81524 solver.cpp:252]     Train net output #1: loss = 1.18171 (* 1 = 1.18171 loss)
I0727 03:01:35.429388 81524 sgd_solver.cpp:106] Iteration 4450, lr = 0.01
I0727 03:02:22.544994 81524 solver.cpp:236] Iteration 4460, loss = 0.957741
I0727 03:02:22.545215 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:02:22.545238 81524 solver.cpp:252]     Train net output #1: loss = 1.11009 (* 1 = 1.11009 loss)
I0727 03:02:26.995527 81524 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0727 03:03:14.006610 81524 solver.cpp:236] Iteration 4470, loss = 0.97376
I0727 03:03:14.006847 81524 solver.cpp:252]     Train net output #0: accuracy = 0.875
I0727 03:03:14.006877 81524 solver.cpp:252]     Train net output #1: loss = 0.760319 (* 1 = 0.760319 loss)
I0727 03:03:18.494354 81524 sgd_solver.cpp:106] Iteration 4470, lr = 0.01
I0727 03:04:06.610424 81524 solver.cpp:236] Iteration 4480, loss = 0.978152
I0727 03:04:06.610590 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:04:06.610610 81524 solver.cpp:252]     Train net output #1: loss = 0.934017 (* 1 = 0.934017 loss)
I0727 03:04:11.727071 81524 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0727 03:05:00.959802 81524 solver.cpp:236] Iteration 4490, loss = 0.987887
I0727 03:05:00.959991 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:05:00.960016 81524 solver.cpp:252]     Train net output #1: loss = 1.03058 (* 1 = 1.03058 loss)
I0727 03:05:06.255928 81524 sgd_solver.cpp:106] Iteration 4490, lr = 0.01
I0727 03:05:53.557008 81524 solver.cpp:340] Iteration 4500, Testing net (#0)
I0727 03:08:34.986912 81524 solver.cpp:408]     Test net output #0: accuracy = 0.519
I0727 03:08:34.987226 81524 solver.cpp:408]     Test net output #1: loss = 0.998019 (* 1 = 0.998019 loss)
I0727 03:08:35.948614 81524 solver.cpp:236] Iteration 4500, loss = 0.981544
I0727 03:08:35.948685 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:08:35.948719 81524 solver.cpp:252]     Train net output #1: loss = 0.957055 (* 1 = 0.957055 loss)
I0727 03:08:37.931591 81524 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0727 03:09:27.430212 81524 solver.cpp:236] Iteration 4510, loss = 0.980186
I0727 03:09:27.430438 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:09:27.430459 81524 solver.cpp:252]     Train net output #1: loss = 0.889412 (* 1 = 0.889412 loss)
I0727 03:09:31.255604 81524 sgd_solver.cpp:106] Iteration 4510, lr = 0.01
I0727 03:09:42.756145 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 03:10:20.689807 81524 solver.cpp:236] Iteration 4520, loss = 0.982755
I0727 03:10:20.690110 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:10:20.690132 81524 solver.cpp:252]     Train net output #1: loss = 1.03302 (* 1 = 1.03302 loss)
I0727 03:10:25.035884 81524 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0727 03:11:14.439808 81524 solver.cpp:236] Iteration 4530, loss = 0.995443
I0727 03:11:14.440016 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:11:14.440062 81524 solver.cpp:252]     Train net output #1: loss = 0.899511 (* 1 = 0.899511 loss)
I0727 03:11:19.062929 81524 sgd_solver.cpp:106] Iteration 4530, lr = 0.01
I0727 03:12:06.693248 81524 solver.cpp:236] Iteration 4540, loss = 0.983068
I0727 03:12:06.693528 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 03:12:06.693558 81524 solver.cpp:252]     Train net output #1: loss = 1.11292 (* 1 = 1.11292 loss)
I0727 03:12:11.846880 81524 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0727 03:13:03.098492 81524 solver.cpp:236] Iteration 4550, loss = 1.00148
I0727 03:13:03.098726 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:13:03.098772 81524 solver.cpp:252]     Train net output #1: loss = 0.943341 (* 1 = 0.943341 loss)
I0727 03:13:05.790242 81524 sgd_solver.cpp:106] Iteration 4550, lr = 0.01
I0727 03:13:57.238181 81524 solver.cpp:236] Iteration 4560, loss = 1.011
I0727 03:13:57.238356 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 03:13:57.238378 81524 solver.cpp:252]     Train net output #1: loss = 0.942357 (* 1 = 0.942357 loss)
I0727 03:13:59.337385 81524 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0727 03:14:50.559391 81524 solver.cpp:236] Iteration 4570, loss = 0.998846
I0727 03:14:50.559631 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 03:14:50.559653 81524 solver.cpp:252]     Train net output #1: loss = 0.756141 (* 1 = 0.756141 loss)
I0727 03:14:54.772624 81524 sgd_solver.cpp:106] Iteration 4570, lr = 0.01
I0727 03:15:44.515394 81524 solver.cpp:236] Iteration 4580, loss = 0.995404
I0727 03:15:44.515641 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:15:44.515669 81524 solver.cpp:252]     Train net output #1: loss = 1.12495 (* 1 = 1.12495 loss)
I0727 03:15:49.645411 81524 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0727 03:16:41.106562 81524 solver.cpp:236] Iteration 4590, loss = 0.985706
I0727 03:16:41.106755 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:16:41.106776 81524 solver.cpp:252]     Train net output #1: loss = 1.02981 (* 1 = 1.02981 loss)
I0727 03:16:45.888555 81524 sgd_solver.cpp:106] Iteration 4590, lr = 0.01
I0727 03:17:34.259680 81524 solver.cpp:340] Iteration 4600, Testing net (#0)
I0727 03:20:10.016690 81524 solver.cpp:408]     Test net output #0: accuracy = 0.511
I0727 03:20:10.016962 81524 solver.cpp:408]     Test net output #1: loss = 1.00158 (* 1 = 1.00158 loss)
I0727 03:20:10.970919 81524 solver.cpp:236] Iteration 4600, loss = 0.966572
I0727 03:20:10.971004 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:20:10.971032 81524 solver.cpp:252]     Train net output #1: loss = 1.15162 (* 1 = 1.15162 loss)
I0727 03:20:13.708478 81524 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0727 03:21:03.619511 81524 solver.cpp:236] Iteration 4610, loss = 0.963014
I0727 03:21:03.619765 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 03:21:03.619791 81524 solver.cpp:252]     Train net output #1: loss = 0.898651 (* 1 = 0.898651 loss)
I0727 03:21:08.272892 81524 sgd_solver.cpp:106] Iteration 4610, lr = 0.01
I0727 03:22:00.874691 81524 solver.cpp:236] Iteration 4620, loss = 0.972767
I0727 03:22:00.874819 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 03:22:00.874840 81524 solver.cpp:252]     Train net output #1: loss = 0.836613 (* 1 = 0.836613 loss)
I0727 03:22:05.534932 81524 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0727 03:22:57.357764 81524 solver.cpp:236] Iteration 4630, loss = 0.961271
I0727 03:22:57.358077 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:22:57.358120 81524 solver.cpp:252]     Train net output #1: loss = 0.930143 (* 1 = 0.930143 loss)
I0727 03:23:01.848495 81524 sgd_solver.cpp:106] Iteration 4630, lr = 0.01
I0727 03:23:53.081295 81524 solver.cpp:236] Iteration 4640, loss = 0.962657
I0727 03:23:53.081470 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 03:23:53.081503 81524 solver.cpp:252]     Train net output #1: loss = 0.835012 (* 1 = 0.835012 loss)
I0727 03:23:57.619354 81524 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0727 03:24:49.444643 81524 solver.cpp:236] Iteration 4650, loss = 0.96635
I0727 03:24:49.444849 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 03:24:49.444886 81524 solver.cpp:252]     Train net output #1: loss = 0.808246 (* 1 = 0.808246 loss)
I0727 03:24:54.590670 81524 sgd_solver.cpp:106] Iteration 4650, lr = 0.01
I0727 03:25:46.375906 81524 solver.cpp:236] Iteration 4660, loss = 0.957112
I0727 03:25:46.376152 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 03:25:46.376190 81524 solver.cpp:252]     Train net output #1: loss = 0.720657 (* 1 = 0.720657 loss)
I0727 03:25:51.202455 81524 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0727 03:26:43.866173 81524 solver.cpp:236] Iteration 4670, loss = 0.957165
I0727 03:26:43.866420 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:26:43.866442 81524 solver.cpp:252]     Train net output #1: loss = 1.04884 (* 1 = 1.04884 loss)
I0727 03:26:49.053494 81524 sgd_solver.cpp:106] Iteration 4670, lr = 0.01
I0727 03:27:34.672485 81524 solver.cpp:236] Iteration 4680, loss = 0.969483
I0727 03:27:34.672672 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:27:34.672706 81524 solver.cpp:252]     Train net output #1: loss = 0.944702 (* 1 = 0.944702 loss)
I0727 03:27:39.055897 81524 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0727 03:28:24.879763 81524 solver.cpp:236] Iteration 4690, loss = 0.984839
I0727 03:28:24.879940 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 03:28:24.879961 81524 solver.cpp:252]     Train net output #1: loss = 1.17964 (* 1 = 1.17964 loss)
I0727 03:28:28.634039 81524 sgd_solver.cpp:106] Iteration 4690, lr = 0.01
I0727 03:29:13.886181 81524 solver.cpp:340] Iteration 4700, Testing net (#0)
I0727 03:30:08.681674 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 03:31:44.877585 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5215
I0727 03:31:44.877899 81524 solver.cpp:408]     Test net output #1: loss = 0.99492 (* 1 = 0.99492 loss)
I0727 03:31:45.830950 81524 solver.cpp:236] Iteration 4700, loss = 0.995518
I0727 03:31:45.831028 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:31:45.831058 81524 solver.cpp:252]     Train net output #1: loss = 0.99989 (* 1 = 0.99989 loss)
I0727 03:31:48.201503 81524 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0727 03:32:40.663980 81524 solver.cpp:236] Iteration 4710, loss = 0.998146
I0727 03:32:40.664294 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 03:32:40.664330 81524 solver.cpp:252]     Train net output #1: loss = 1.22512 (* 1 = 1.22512 loss)
I0727 03:32:41.550775 81524 sgd_solver.cpp:106] Iteration 4710, lr = 0.01
I0727 03:33:30.046959 81524 solver.cpp:236] Iteration 4720, loss = 0.998215
I0727 03:33:30.047169 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:33:30.047191 81524 solver.cpp:252]     Train net output #1: loss = 0.890977 (* 1 = 0.890977 loss)
I0727 03:33:34.578706 81524 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0727 03:34:22.221488 81524 solver.cpp:236] Iteration 4730, loss = 0.991055
I0727 03:34:22.221690 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 03:34:22.221722 81524 solver.cpp:252]     Train net output #1: loss = 0.972597 (* 1 = 0.972597 loss)
I0727 03:34:26.170249 81524 sgd_solver.cpp:106] Iteration 4730, lr = 0.01
I0727 03:35:14.434588 81524 solver.cpp:236] Iteration 4740, loss = 0.99654
I0727 03:35:14.434857 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 03:35:14.434895 81524 solver.cpp:252]     Train net output #1: loss = 1.04068 (* 1 = 1.04068 loss)
I0727 03:35:17.083398 81524 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0727 03:36:03.481895 81524 solver.cpp:236] Iteration 4750, loss = 0.981421
I0727 03:36:03.482097 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:36:03.482117 81524 solver.cpp:252]     Train net output #1: loss = 1.10923 (* 1 = 1.10923 loss)
I0727 03:36:08.214205 81524 sgd_solver.cpp:106] Iteration 4750, lr = 0.01
I0727 03:36:53.925259 81524 solver.cpp:236] Iteration 4760, loss = 0.974536
I0727 03:36:53.925436 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 03:36:53.925468 81524 solver.cpp:252]     Train net output #1: loss = 1.0049 (* 1 = 1.0049 loss)
I0727 03:36:58.857864 81524 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0727 03:37:45.990350 81524 solver.cpp:236] Iteration 4770, loss = 0.971395
I0727 03:37:45.990550 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 03:37:45.990571 81524 solver.cpp:252]     Train net output #1: loss = 0.822958 (* 1 = 0.822958 loss)
I0727 03:37:50.892674 81524 sgd_solver.cpp:106] Iteration 4770, lr = 0.01
I0727 03:38:44.042968 81524 solver.cpp:236] Iteration 4780, loss = 0.970839
I0727 03:38:44.043205 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 03:38:44.043233 81524 solver.cpp:252]     Train net output #1: loss = 0.822716 (* 1 = 0.822716 loss)
I0727 03:38:49.263134 81524 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0727 03:39:52.252976 81524 solver.cpp:236] Iteration 4790, loss = 0.966614
I0727 03:39:52.253351 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 03:39:52.253387 81524 solver.cpp:252]     Train net output #1: loss = 0.920941 (* 1 = 0.920941 loss)
I0727 03:39:53.336499 81524 sgd_solver.cpp:106] Iteration 4790, lr = 0.01
I0727 03:40:52.538825 81524 solver.cpp:340] Iteration 4800, Testing net (#0)
I0727 03:44:18.906735 81524 solver.cpp:408]     Test net output #0: accuracy = 0.546
I0727 03:44:18.906991 81524 solver.cpp:408]     Test net output #1: loss = 0.981694 (* 1 = 0.981694 loss)
I0727 03:44:19.861412 81524 solver.cpp:236] Iteration 4800, loss = 0.982242
I0727 03:44:19.861515 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 03:44:19.861580 81524 solver.cpp:252]     Train net output #1: loss = 1.03722 (* 1 = 1.03722 loss)
I0727 03:44:21.299130 81524 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0727 03:45:36.422050 81524 solver.cpp:236] Iteration 4810, loss = 0.995067
I0727 03:45:36.422245 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 03:45:36.422292 81524 solver.cpp:252]     Train net output #1: loss = 1.13252 (* 1 = 1.13252 loss)
I0727 03:45:39.777638 81524 sgd_solver.cpp:106] Iteration 4810, lr = 0.01
I0727 03:46:52.366232 81524 solver.cpp:236] Iteration 4820, loss = 1.0023
I0727 03:46:52.366489 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:46:52.366528 81524 solver.cpp:252]     Train net output #1: loss = 0.939326 (* 1 = 0.939326 loss)
I0727 03:46:58.042136 81524 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0727 03:48:14.888633 81524 solver.cpp:236] Iteration 4830, loss = 1.01594
I0727 03:48:14.888947 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 03:48:14.888988 81524 solver.cpp:252]     Train net output #1: loss = 0.925297 (* 1 = 0.925297 loss)
I0727 03:48:18.428905 81524 sgd_solver.cpp:106] Iteration 4830, lr = 0.01
I0727 03:49:34.371657 81524 solver.cpp:236] Iteration 4840, loss = 1.00617
I0727 03:49:34.371848 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:49:34.371896 81524 solver.cpp:252]     Train net output #1: loss = 0.828041 (* 1 = 0.828041 loss)
I0727 03:49:39.950079 81524 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0727 03:50:57.165171 81524 solver.cpp:236] Iteration 4850, loss = 1.01471
I0727 03:50:57.165429 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:50:57.165469 81524 solver.cpp:252]     Train net output #1: loss = 0.863549 (* 1 = 0.863549 loss)
I0727 03:50:58.800107 81524 sgd_solver.cpp:106] Iteration 4850, lr = 0.01
I0727 03:52:16.473726 81524 solver.cpp:236] Iteration 4860, loss = 1.03926
I0727 03:52:16.473984 81524 solver.cpp:252]     Train net output #0: accuracy = 0.0625
I0727 03:52:16.474019 81524 solver.cpp:252]     Train net output #1: loss = 1.28549 (* 1 = 1.28549 loss)
I0727 03:52:22.311363 81524 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0727 03:52:28.347519 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 03:53:45.341766 81524 solver.cpp:236] Iteration 4870, loss = 1.02888
I0727 03:53:45.342058 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:53:45.342113 81524 solver.cpp:252]     Train net output #1: loss = 0.892368 (* 1 = 0.892368 loss)
I0727 03:53:47.015645 81524 sgd_solver.cpp:106] Iteration 4870, lr = 0.01
I0727 03:55:04.289733 81524 solver.cpp:236] Iteration 4880, loss = 1.01691
I0727 03:55:04.290047 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 03:55:04.290221 81524 solver.cpp:252]     Train net output #1: loss = 0.788052 (* 1 = 0.788052 loss)
I0727 03:55:05.912701 81524 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0727 03:56:14.085090 81524 solver.cpp:236] Iteration 4890, loss = 1.01451
I0727 03:56:14.085337 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 03:56:14.085361 81524 solver.cpp:252]     Train net output #1: loss = 0.903133 (* 1 = 0.903133 loss)
I0727 03:56:19.483314 81524 sgd_solver.cpp:106] Iteration 4890, lr = 0.01
I0727 03:57:09.075362 81524 solver.cpp:340] Iteration 4900, Testing net (#0)
I0727 03:59:43.153167 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5125
I0727 03:59:43.153369 81524 solver.cpp:408]     Test net output #1: loss = 1.02267 (* 1 = 1.02267 loss)
I0727 03:59:44.163656 81524 solver.cpp:236] Iteration 4900, loss = 1.01013
I0727 03:59:44.163717 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 03:59:44.163738 81524 solver.cpp:252]     Train net output #1: loss = 1.0196 (* 1 = 1.0196 loss)
I0727 03:59:46.401636 81524 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0727 04:00:37.764106 81524 solver.cpp:236] Iteration 4910, loss = 0.996895
I0727 04:00:37.764377 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 04:00:37.764427 81524 solver.cpp:252]     Train net output #1: loss = 1.28304 (* 1 = 1.28304 loss)
I0727 04:00:43.419455 81524 sgd_solver.cpp:106] Iteration 4910, lr = 0.01
I0727 04:01:34.850950 81524 solver.cpp:236] Iteration 4920, loss = 1.00379
I0727 04:01:34.851157 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:01:34.851196 81524 solver.cpp:252]     Train net output #1: loss = 1.12244 (* 1 = 1.12244 loss)
I0727 04:01:39.080998 81524 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0727 04:02:30.957381 81524 solver.cpp:236] Iteration 4930, loss = 1.01296
I0727 04:02:30.957559 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:02:30.957592 81524 solver.cpp:252]     Train net output #1: loss = 0.880329 (* 1 = 0.880329 loss)
I0727 04:02:35.831984 81524 sgd_solver.cpp:106] Iteration 4930, lr = 0.01
I0727 04:03:30.218088 81524 solver.cpp:236] Iteration 4940, loss = 1.01639
I0727 04:03:30.218417 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 04:03:30.218459 81524 solver.cpp:252]     Train net output #1: loss = 0.927691 (* 1 = 0.927691 loss)
I0727 04:03:31.101632 81524 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0727 04:04:23.979418 81524 solver.cpp:236] Iteration 4950, loss = 1.00084
I0727 04:04:23.979686 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 04:04:23.979715 81524 solver.cpp:252]     Train net output #1: loss = 0.729521 (* 1 = 0.729521 loss)
I0727 04:04:28.525277 81524 sgd_solver.cpp:106] Iteration 4950, lr = 0.01
I0727 04:05:21.249094 81524 solver.cpp:236] Iteration 4960, loss = 0.988305
I0727 04:05:21.249323 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:05:21.249622 81524 solver.cpp:252]     Train net output #1: loss = 0.8348 (* 1 = 0.8348 loss)
I0727 04:05:26.513808 81524 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0727 04:06:19.336097 81524 solver.cpp:236] Iteration 4970, loss = 0.983363
I0727 04:06:19.336484 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:06:19.336542 81524 solver.cpp:252]     Train net output #1: loss = 1.14383 (* 1 = 1.14383 loss)
I0727 04:06:23.826997 81524 sgd_solver.cpp:106] Iteration 4970, lr = 0.01
I0727 04:07:18.348450 81524 solver.cpp:236] Iteration 4980, loss = 0.971825
I0727 04:07:18.348664 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:07:18.348690 81524 solver.cpp:252]     Train net output #1: loss = 1.00582 (* 1 = 1.00582 loss)
I0727 04:07:19.294646 81524 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0727 04:08:15.157676 81524 solver.cpp:236] Iteration 4990, loss = 0.977286
I0727 04:08:15.157858 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:08:15.157883 81524 solver.cpp:252]     Train net output #1: loss = 0.974649 (* 1 = 0.974649 loss)
I0727 04:08:16.003723 81524 sgd_solver.cpp:106] Iteration 4990, lr = 0.01
I0727 04:09:08.061686 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_5000.caffemodel
I0727 04:09:08.297199 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_5000.solverstate
I0727 04:09:08.300951 81524 solver.cpp:340] Iteration 5000, Testing net (#0)
I0727 04:11:41.743592 81524 solver.cpp:408]     Test net output #0: accuracy = 0.539
I0727 04:11:41.743885 81524 solver.cpp:408]     Test net output #1: loss = 0.977553 (* 1 = 0.977553 loss)
I0727 04:11:42.704974 81524 solver.cpp:236] Iteration 5000, loss = 0.967237
I0727 04:11:42.705065 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:11:42.705086 81524 solver.cpp:252]     Train net output #1: loss = 0.899425 (* 1 = 0.899425 loss)
I0727 04:11:44.355415 81524 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0727 04:11:44.360857 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 04:12:37.845156 81524 solver.cpp:236] Iteration 5010, loss = 0.953066
I0727 04:12:37.845360 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 04:12:37.845381 81524 solver.cpp:252]     Train net output #1: loss = 0.929451 (* 1 = 0.929451 loss)
I0727 04:12:42.506620 81524 sgd_solver.cpp:106] Iteration 5010, lr = 0.01
I0727 04:13:29.959451 81524 solver.cpp:236] Iteration 5020, loss = 0.946916
I0727 04:13:29.959610 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:13:29.959630 81524 solver.cpp:252]     Train net output #1: loss = 0.990441 (* 1 = 0.990441 loss)
I0727 04:13:34.805646 81524 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0727 04:14:26.527716 81524 solver.cpp:236] Iteration 5030, loss = 0.954744
I0727 04:14:26.527940 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:14:26.527961 81524 solver.cpp:252]     Train net output #1: loss = 0.746278 (* 1 = 0.746278 loss)
I0727 04:14:30.188812 81524 sgd_solver.cpp:106] Iteration 5030, lr = 0.01
I0727 04:15:19.747577 81524 solver.cpp:236] Iteration 5040, loss = 0.946236
I0727 04:15:19.747853 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:15:19.747885 81524 solver.cpp:252]     Train net output #1: loss = 0.986371 (* 1 = 0.986371 loss)
I0727 04:15:22.104925 81524 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0727 04:16:10.078696 81524 solver.cpp:236] Iteration 5050, loss = 0.968176
I0727 04:16:10.078853 81524 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0727 04:16:10.078891 81524 solver.cpp:252]     Train net output #1: loss = 1.21566 (* 1 = 1.21566 loss)
I0727 04:16:14.440352 81524 sgd_solver.cpp:106] Iteration 5050, lr = 0.01
I0727 04:17:02.986399 81524 solver.cpp:236] Iteration 5060, loss = 0.972854
I0727 04:17:02.986624 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:17:02.986650 81524 solver.cpp:252]     Train net output #1: loss = 0.970758 (* 1 = 0.970758 loss)
I0727 04:17:04.091045 81524 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0727 04:17:53.059305 81524 solver.cpp:236] Iteration 5070, loss = 0.972384
I0727 04:17:53.059557 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:17:53.059581 81524 solver.cpp:252]     Train net output #1: loss = 1.16427 (* 1 = 1.16427 loss)
I0727 04:17:55.477340 81524 sgd_solver.cpp:106] Iteration 5070, lr = 0.01
I0727 04:18:43.592932 81524 solver.cpp:236] Iteration 5080, loss = 0.971597
I0727 04:18:43.593149 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:18:43.593169 81524 solver.cpp:252]     Train net output #1: loss = 1.14456 (* 1 = 1.14456 loss)
I0727 04:18:47.704143 81524 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0727 04:19:36.528172 81524 solver.cpp:236] Iteration 5090, loss = 0.993644
I0727 04:19:36.528362 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:19:36.528384 81524 solver.cpp:252]     Train net output #1: loss = 1.17317 (* 1 = 1.17317 loss)
I0727 04:19:39.544687 81524 sgd_solver.cpp:106] Iteration 5090, lr = 0.01
I0727 04:20:27.430320 81524 solver.cpp:340] Iteration 5100, Testing net (#0)
I0727 04:22:58.607393 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5335
I0727 04:22:58.607563 81524 solver.cpp:408]     Test net output #1: loss = 0.995522 (* 1 = 0.995522 loss)
I0727 04:22:59.617674 81524 solver.cpp:236] Iteration 5100, loss = 0.986425
I0727 04:22:59.617733 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:22:59.617751 81524 solver.cpp:252]     Train net output #1: loss = 0.88249 (* 1 = 0.88249 loss)
I0727 04:23:01.765975 81524 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0727 04:23:48.744422 81524 solver.cpp:236] Iteration 5110, loss = 1.00414
I0727 04:23:48.744766 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:23:48.744842 81524 solver.cpp:252]     Train net output #1: loss = 1.0291 (* 1 = 1.0291 loss)
I0727 04:23:52.966341 81524 sgd_solver.cpp:106] Iteration 5110, lr = 0.01
I0727 04:24:40.460258 81524 solver.cpp:236] Iteration 5120, loss = 0.998601
I0727 04:24:40.460455 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 04:24:40.460479 81524 solver.cpp:252]     Train net output #1: loss = 0.750321 (* 1 = 0.750321 loss)
I0727 04:24:45.462187 81524 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0727 04:25:32.293766 81524 solver.cpp:236] Iteration 5130, loss = 0.998282
I0727 04:25:32.294004 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:25:32.294028 81524 solver.cpp:252]     Train net output #1: loss = 0.956508 (* 1 = 0.956508 loss)
I0727 04:25:36.847156 81524 sgd_solver.cpp:106] Iteration 5130, lr = 0.01
I0727 04:26:24.571522 81524 solver.cpp:236] Iteration 5140, loss = 0.980831
I0727 04:26:24.571703 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 04:26:24.571749 81524 solver.cpp:252]     Train net output #1: loss = 0.84379 (* 1 = 0.84379 loss)
I0727 04:26:29.431952 81524 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0727 04:27:17.159173 81524 solver.cpp:236] Iteration 5150, loss = 0.964083
I0727 04:27:17.159411 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 04:27:17.159446 81524 solver.cpp:252]     Train net output #1: loss = 0.824209 (* 1 = 0.824209 loss)
I0727 04:27:22.454547 81524 sgd_solver.cpp:106] Iteration 5150, lr = 0.01
I0727 04:28:08.955973 81524 solver.cpp:236] Iteration 5160, loss = 0.958466
I0727 04:28:08.956198 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:28:08.956220 81524 solver.cpp:252]     Train net output #1: loss = 0.940512 (* 1 = 0.940512 loss)
I0727 04:28:14.288501 81524 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0727 04:29:03.363126 81524 solver.cpp:236] Iteration 5170, loss = 0.980143
I0727 04:29:03.363394 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:29:03.363432 81524 solver.cpp:252]     Train net output #1: loss = 1.06981 (* 1 = 1.06981 loss)
I0727 04:29:07.869704 81524 sgd_solver.cpp:106] Iteration 5170, lr = 0.01
I0727 04:29:56.650704 81524 solver.cpp:236] Iteration 5180, loss = 0.986903
I0727 04:29:56.650995 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:29:56.651020 81524 solver.cpp:252]     Train net output #1: loss = 0.90974 (* 1 = 0.90974 loss)
I0727 04:30:01.004328 81524 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0727 04:30:50.223481 81524 solver.cpp:236] Iteration 5190, loss = 0.990899
I0727 04:30:50.223701 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:30:50.223726 81524 solver.cpp:252]     Train net output #1: loss = 1.06527 (* 1 = 1.06527 loss)
I0727 04:30:54.748924 81524 sgd_solver.cpp:106] Iteration 5190, lr = 0.01
I0727 04:31:43.633333 81524 solver.cpp:340] Iteration 5200, Testing net (#0)
I0727 04:32:30.281298 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 04:34:18.281517 81524 solver.cpp:408]     Test net output #0: accuracy = 0.551
I0727 04:34:18.281719 81524 solver.cpp:408]     Test net output #1: loss = 0.97385 (* 1 = 0.97385 loss)
I0727 04:34:19.290292 81524 solver.cpp:236] Iteration 5200, loss = 1.00929
I0727 04:34:19.290381 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 04:34:19.290418 81524 solver.cpp:252]     Train net output #1: loss = 0.965742 (* 1 = 0.965742 loss)
I0727 04:34:21.388476 81524 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0727 04:35:19.155189 81524 solver.cpp:236] Iteration 5210, loss = 1.00786
I0727 04:35:19.155520 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:35:19.155570 81524 solver.cpp:252]     Train net output #1: loss = 0.88253 (* 1 = 0.88253 loss)
I0727 04:35:19.749054 81524 sgd_solver.cpp:106] Iteration 5210, lr = 0.01
I0727 04:36:11.062144 81524 solver.cpp:236] Iteration 5220, loss = 1.01698
I0727 04:36:11.062286 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:36:11.062320 81524 solver.cpp:252]     Train net output #1: loss = 1.17679 (* 1 = 1.17679 loss)
I0727 04:36:15.658841 81524 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0727 04:37:05.236910 81524 solver.cpp:236] Iteration 5230, loss = 1.00497
I0727 04:37:05.237135 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:37:05.237159 81524 solver.cpp:252]     Train net output #1: loss = 1.08003 (* 1 = 1.08003 loss)
I0727 04:37:09.684511 81524 sgd_solver.cpp:106] Iteration 5230, lr = 0.01
I0727 04:38:01.605265 81524 solver.cpp:236] Iteration 5240, loss = 0.991363
I0727 04:38:01.605465 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:38:01.605490 81524 solver.cpp:252]     Train net output #1: loss = 0.973657 (* 1 = 0.973657 loss)
I0727 04:38:06.936496 81524 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0727 04:38:59.832721 81524 solver.cpp:236] Iteration 5250, loss = 0.975062
I0727 04:38:59.832918 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 04:38:59.832962 81524 solver.cpp:252]     Train net output #1: loss = 1.0032 (* 1 = 1.0032 loss)
I0727 04:39:04.745621 81524 sgd_solver.cpp:106] Iteration 5250, lr = 0.01
I0727 04:40:00.192404 81524 solver.cpp:236] Iteration 5260, loss = 0.964874
I0727 04:40:00.192600 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 04:40:00.192622 81524 solver.cpp:252]     Train net output #1: loss = 0.995365 (* 1 = 0.995365 loss)
I0727 04:40:04.712580 81524 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0727 04:40:58.440323 81524 solver.cpp:236] Iteration 5270, loss = 0.955969
I0727 04:40:58.440562 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 04:40:58.440583 81524 solver.cpp:252]     Train net output #1: loss = 1.31709 (* 1 = 1.31709 loss)
I0727 04:41:03.147322 81524 sgd_solver.cpp:106] Iteration 5270, lr = 0.01
I0727 04:41:55.062686 81524 solver.cpp:236] Iteration 5280, loss = 0.962819
I0727 04:41:55.062957 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 04:41:55.062989 81524 solver.cpp:252]     Train net output #1: loss = 0.932116 (* 1 = 0.932116 loss)
I0727 04:42:00.126122 81524 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0727 04:42:54.070768 81524 solver.cpp:236] Iteration 5290, loss = 0.974985
I0727 04:42:54.071004 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:42:54.071027 81524 solver.cpp:252]     Train net output #1: loss = 1.05379 (* 1 = 1.05379 loss)
I0727 04:42:58.417934 81524 sgd_solver.cpp:106] Iteration 5290, lr = 0.01
I0727 04:43:49.681859 81524 solver.cpp:340] Iteration 5300, Testing net (#0)
I0727 04:46:24.381968 81524 solver.cpp:408]     Test net output #0: accuracy = 0.528
I0727 04:46:24.382233 81524 solver.cpp:408]     Test net output #1: loss = 0.985547 (* 1 = 0.985547 loss)
I0727 04:46:25.392835 81524 solver.cpp:236] Iteration 5300, loss = 0.999162
I0727 04:46:25.392910 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 04:46:25.392940 81524 solver.cpp:252]     Train net output #1: loss = 1.12571 (* 1 = 1.12571 loss)
I0727 04:46:27.383373 81524 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0727 04:47:23.968102 81524 solver.cpp:236] Iteration 5310, loss = 1.00638
I0727 04:47:23.968304 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:47:23.968333 81524 solver.cpp:252]     Train net output #1: loss = 1.08471 (* 1 = 1.08471 loss)
I0727 04:47:24.765689 81524 sgd_solver.cpp:106] Iteration 5310, lr = 0.01
I0727 04:48:19.149377 81524 solver.cpp:236] Iteration 5320, loss = 0.982195
I0727 04:48:19.149590 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 04:48:19.149611 81524 solver.cpp:252]     Train net output #1: loss = 0.921301 (* 1 = 0.921301 loss)
I0727 04:48:23.760521 81524 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0727 04:49:17.868547 81524 solver.cpp:236] Iteration 5330, loss = 0.982452
I0727 04:49:17.868829 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 04:49:17.868856 81524 solver.cpp:252]     Train net output #1: loss = 1.19859 (* 1 = 1.19859 loss)
I0727 04:49:19.376960 81524 sgd_solver.cpp:106] Iteration 5330, lr = 0.01
I0727 04:50:12.834110 81524 solver.cpp:236] Iteration 5340, loss = 0.973288
I0727 04:50:12.834432 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 04:50:12.834470 81524 solver.cpp:252]     Train net output #1: loss = 1.0396 (* 1 = 1.0396 loss)
I0727 04:50:17.071233 81524 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0727 04:51:04.254062 81524 solver.cpp:236] Iteration 5350, loss = 0.969654
I0727 04:51:04.254310 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 04:51:04.254333 81524 solver.cpp:252]     Train net output #1: loss = 1.01898 (* 1 = 1.01898 loss)
I0727 04:51:08.441372 81524 sgd_solver.cpp:106] Iteration 5350, lr = 0.01
I0727 04:51:53.651664 81524 solver.cpp:236] Iteration 5360, loss = 0.969024
I0727 04:51:53.652055 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 04:51:53.652092 81524 solver.cpp:252]     Train net output #1: loss = 1.01628 (* 1 = 1.01628 loss)
I0727 04:51:55.061779 81557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 04:51:57.490929 81524 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0727 04:52:44.797896 81524 solver.cpp:236] Iteration 5370, loss = 0.979404
I0727 04:52:44.798151 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 04:52:44.798188 81524 solver.cpp:252]     Train net output #1: loss = 0.92576 (* 1 = 0.92576 loss)
I0727 04:52:48.689718 81524 sgd_solver.cpp:106] Iteration 5370, lr = 0.01
I0727 04:53:38.192111 81524 solver.cpp:236] Iteration 5380, loss = 0.966792
I0727 04:53:38.192368 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 04:53:38.192390 81524 solver.cpp:252]     Train net output #1: loss = 1.00207 (* 1 = 1.00207 loss)
I0727 04:53:42.414607 81524 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0727 04:54:30.060006 81524 solver.cpp:236] Iteration 5390, loss = 0.968991
I0727 04:54:30.060250 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 04:54:30.060291 81524 solver.cpp:252]     Train net output #1: loss = 0.918671 (* 1 = 0.918671 loss)
I0727 04:54:34.579646 81524 sgd_solver.cpp:106] Iteration 5390, lr = 0.01
I0727 04:55:24.402277 81524 solver.cpp:340] Iteration 5400, Testing net (#0)
I0727 04:57:57.785307 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5225
I0727 04:57:57.785477 81524 solver.cpp:408]     Test net output #1: loss = 0.999037 (* 1 = 0.999037 loss)
I0727 04:57:58.794803 81524 solver.cpp:236] Iteration 5400, loss = 0.958302
I0727 04:57:58.794869 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 04:57:58.794888 81524 solver.cpp:252]     Train net output #1: loss = 1.15352 (* 1 = 1.15352 loss)
I0727 04:58:00.914389 81524 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0727 04:58:50.886652 81524 solver.cpp:236] Iteration 5410, loss = 0.975691
I0727 04:58:50.886903 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 04:58:50.886946 81524 solver.cpp:252]     Train net output #1: loss = 0.978356 (* 1 = 0.978356 loss)
I0727 04:58:51.820261 81524 sgd_solver.cpp:106] Iteration 5410, lr = 0.01
I0727 04:59:42.066962 81524 solver.cpp:236] Iteration 5420, loss = 0.989625
I0727 04:59:42.067248 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 04:59:42.067289 81524 solver.cpp:252]     Train net output #1: loss = 0.865315 (* 1 = 0.865315 loss)
I0727 04:59:46.719868 81524 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0727 05:00:48.998838 81524 solver.cpp:236] Iteration 5430, loss = 0.99205
I0727 05:00:48.999147 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:00:48.999212 81524 solver.cpp:252]     Train net output #1: loss = 0.858828 (* 1 = 0.858828 loss)
I0727 05:00:50.170478 81524 sgd_solver.cpp:106] Iteration 5430, lr = 0.01
I0727 05:01:57.576433 81524 solver.cpp:236] Iteration 5440, loss = 1.00041
I0727 05:01:57.576784 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:01:57.576836 81524 solver.cpp:252]     Train net output #1: loss = 1.05347 (* 1 = 1.05347 loss)
I0727 05:01:58.992728 81524 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0727 05:03:02.851588 81524 solver.cpp:236] Iteration 5450, loss = 1.00845
I0727 05:03:02.851835 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:03:02.851868 81524 solver.cpp:252]     Train net output #1: loss = 0.974575 (* 1 = 0.974575 loss)
I0727 05:03:08.732254 81524 sgd_solver.cpp:106] Iteration 5450, lr = 0.01
I0727 05:04:21.675348 81524 solver.cpp:236] Iteration 5460, loss = 1.00011
I0727 05:04:21.675606 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 05:04:21.675657 81524 solver.cpp:252]     Train net output #1: loss = 1.08743 (* 1 = 1.08743 loss)
I0727 05:04:23.295907 81524 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0727 05:05:32.853538 81524 solver.cpp:236] Iteration 5470, loss = 0.988919
I0727 05:05:32.853852 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:05:32.853889 81524 solver.cpp:252]     Train net output #1: loss = 1.14568 (* 1 = 1.14568 loss)
I0727 05:05:38.395087 81524 sgd_solver.cpp:106] Iteration 5470, lr = 0.01
I0727 05:06:49.442385 81524 solver.cpp:236] Iteration 5480, loss = 0.996711
I0727 05:06:49.442579 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 05:06:49.442603 81524 solver.cpp:252]     Train net output #1: loss = 1.17349 (* 1 = 1.17349 loss)
I0727 05:06:50.492384 81524 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0727 05:08:06.408067 81524 solver.cpp:236] Iteration 5490, loss = 0.977297
I0727 05:08:06.408443 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:08:06.408501 81524 solver.cpp:252]     Train net output #1: loss = 0.962509 (* 1 = 0.962509 loss)
I0727 05:08:10.088259 81524 sgd_solver.cpp:106] Iteration 5490, lr = 0.01
I0727 05:09:17.049901 81524 solver.cpp:340] Iteration 5500, Testing net (#0)
I0727 05:12:47.711905 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 05:13:08.499016 81524 solver.cpp:408]     Test net output #0: accuracy = 0.509
I0727 05:13:08.499125 81524 solver.cpp:408]     Test net output #1: loss = 1.00888 (* 1 = 1.00888 loss)
I0727 05:13:09.456372 81524 solver.cpp:236] Iteration 5500, loss = 0.980308
I0727 05:13:09.456483 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:13:09.456514 81524 solver.cpp:252]     Train net output #1: loss = 0.937327 (* 1 = 0.937327 loss)
I0727 05:13:10.937145 81524 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0727 05:14:28.209139 81524 solver.cpp:236] Iteration 5510, loss = 0.966477
I0727 05:14:28.209398 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:14:28.209430 81524 solver.cpp:252]     Train net output #1: loss = 1.12964 (* 1 = 1.12964 loss)
I0727 05:14:32.606063 81524 sgd_solver.cpp:106] Iteration 5510, lr = 0.01
I0727 05:15:49.448199 81524 solver.cpp:236] Iteration 5520, loss = 0.966636
I0727 05:15:49.448503 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:15:49.448544 81524 solver.cpp:252]     Train net output #1: loss = 1.04553 (* 1 = 1.04553 loss)
I0727 05:15:50.966955 81524 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0727 05:16:52.717885 81524 solver.cpp:236] Iteration 5530, loss = 0.963413
I0727 05:16:52.718152 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:16:52.718196 81524 solver.cpp:252]     Train net output #1: loss = 0.836209 (* 1 = 0.836209 loss)
I0727 05:16:57.247309 81524 sgd_solver.cpp:106] Iteration 5530, lr = 0.01
I0727 05:17:46.542804 81524 solver.cpp:236] Iteration 5540, loss = 0.981188
I0727 05:17:46.543025 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:17:46.543083 81524 solver.cpp:252]     Train net output #1: loss = 0.999422 (* 1 = 0.999422 loss)
I0727 05:17:50.846654 81524 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0727 05:18:42.369778 81524 solver.cpp:236] Iteration 5550, loss = 0.960551
I0727 05:18:42.370043 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:18:42.370074 81524 solver.cpp:252]     Train net output #1: loss = 0.954184 (* 1 = 0.954184 loss)
I0727 05:18:47.707468 81524 sgd_solver.cpp:106] Iteration 5550, lr = 0.01
I0727 05:19:38.639956 81524 solver.cpp:236] Iteration 5560, loss = 0.953565
I0727 05:19:38.640117 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:19:38.640139 81524 solver.cpp:252]     Train net output #1: loss = 1.13942 (* 1 = 1.13942 loss)
I0727 05:19:42.810005 81524 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0727 05:20:34.031805 81524 solver.cpp:236] Iteration 5570, loss = 0.94997
I0727 05:20:34.032017 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 05:20:34.032040 81524 solver.cpp:252]     Train net output #1: loss = 0.839061 (* 1 = 0.839061 loss)
I0727 05:20:39.098296 81524 sgd_solver.cpp:106] Iteration 5570, lr = 0.01
I0727 05:21:31.809487 81524 solver.cpp:236] Iteration 5580, loss = 0.959698
I0727 05:21:31.809736 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:21:31.809772 81524 solver.cpp:252]     Train net output #1: loss = 1.10931 (* 1 = 1.10931 loss)
I0727 05:21:34.166854 81524 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0727 05:22:25.596305 81524 solver.cpp:236] Iteration 5590, loss = 0.955962
I0727 05:22:25.596477 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:22:25.596518 81524 solver.cpp:252]     Train net output #1: loss = 0.860137 (* 1 = 0.860137 loss)
I0727 05:22:29.459431 81524 sgd_solver.cpp:106] Iteration 5590, lr = 0.01
I0727 05:23:21.436090 81524 solver.cpp:340] Iteration 5600, Testing net (#0)
I0727 05:26:02.655585 81524 solver.cpp:408]     Test net output #0: accuracy = 0.546
I0727 05:26:02.655841 81524 solver.cpp:408]     Test net output #1: loss = 0.97345 (* 1 = 0.97345 loss)
I0727 05:26:03.629122 81524 solver.cpp:236] Iteration 5600, loss = 0.977215
I0727 05:26:03.629194 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:26:03.629215 81524 solver.cpp:252]     Train net output #1: loss = 0.878767 (* 1 = 0.878767 loss)
I0727 05:26:05.910150 81524 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0727 05:26:57.766080 81524 solver.cpp:236] Iteration 5610, loss = 0.999027
I0727 05:26:57.766465 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:26:57.766508 81524 solver.cpp:252]     Train net output #1: loss = 1.08816 (* 1 = 1.08816 loss)
I0727 05:27:02.257325 81524 sgd_solver.cpp:106] Iteration 5610, lr = 0.01
I0727 05:27:54.067600 81524 solver.cpp:236] Iteration 5620, loss = 1.01487
I0727 05:27:54.067870 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 05:27:54.067898 81524 solver.cpp:252]     Train net output #1: loss = 1.13154 (* 1 = 1.13154 loss)
I0727 05:27:58.937106 81524 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0727 05:28:53.298682 81524 solver.cpp:236] Iteration 5630, loss = 1.00725
I0727 05:28:53.298827 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:28:53.298851 81524 solver.cpp:252]     Train net output #1: loss = 1.02073 (* 1 = 1.02073 loss)
I0727 05:28:53.791445 81524 sgd_solver.cpp:106] Iteration 5630, lr = 0.01
I0727 05:29:46.917649 81524 solver.cpp:236] Iteration 5640, loss = 1.00592
I0727 05:29:46.917843 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:29:46.917870 81524 solver.cpp:252]     Train net output #1: loss = 0.959076 (* 1 = 0.959076 loss)
I0727 05:29:51.053838 81524 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0727 05:30:44.032079 81524 solver.cpp:236] Iteration 5650, loss = 1.008
I0727 05:30:44.032294 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:30:44.032366 81524 solver.cpp:252]     Train net output #1: loss = 0.912839 (* 1 = 0.912839 loss)
I0727 05:30:49.173290 81524 sgd_solver.cpp:106] Iteration 5650, lr = 0.01
I0727 05:31:44.047112 81524 solver.cpp:236] Iteration 5660, loss = 1.0088
I0727 05:31:44.047319 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:31:44.047353 81524 solver.cpp:252]     Train net output #1: loss = 0.966052 (* 1 = 0.966052 loss)
I0727 05:31:48.447382 81524 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0727 05:32:40.718030 81524 solver.cpp:236] Iteration 5670, loss = 1.00165
I0727 05:32:40.718257 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:32:40.718287 81524 solver.cpp:252]     Train net output #1: loss = 0.981195 (* 1 = 0.981195 loss)
I0727 05:32:46.459566 81524 sgd_solver.cpp:106] Iteration 5670, lr = 0.01
I0727 05:33:35.171892 81524 solver.cpp:236] Iteration 5680, loss = 1.01638
I0727 05:33:35.172058 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:33:35.172091 81524 solver.cpp:252]     Train net output #1: loss = 1.07574 (* 1 = 1.07574 loss)
I0727 05:33:38.945966 81524 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0727 05:34:26.376225 81524 solver.cpp:236] Iteration 5690, loss = 1.01141
I0727 05:34:26.376441 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 05:34:26.376463 81524 solver.cpp:252]     Train net output #1: loss = 1.0084 (* 1 = 1.0084 loss)
I0727 05:34:30.284854 81524 sgd_solver.cpp:106] Iteration 5690, lr = 0.01
I0727 05:35:19.184342 81524 solver.cpp:340] Iteration 5700, Testing net (#0)
I0727 05:35:26.911931 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 05:38:02.682519 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5205
I0727 05:38:02.682750 81524 solver.cpp:408]     Test net output #1: loss = 1.0043 (* 1 = 1.0043 loss)
I0727 05:38:03.693403 81524 solver.cpp:236] Iteration 5700, loss = 0.988622
I0727 05:38:03.693472 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:38:03.693493 81524 solver.cpp:252]     Train net output #1: loss = 1.02659 (* 1 = 1.02659 loss)
I0727 05:38:05.605098 81524 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0727 05:38:52.449013 81524 solver.cpp:236] Iteration 5710, loss = 0.98197
I0727 05:38:52.449175 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:38:52.449194 81524 solver.cpp:252]     Train net output #1: loss = 1.04694 (* 1 = 1.04694 loss)
I0727 05:38:56.480406 81524 sgd_solver.cpp:106] Iteration 5710, lr = 0.01
I0727 05:39:41.589354 81524 solver.cpp:236] Iteration 5720, loss = 0.975496
I0727 05:39:41.589565 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:39:41.589598 81524 solver.cpp:252]     Train net output #1: loss = 1.03313 (* 1 = 1.03313 loss)
I0727 05:39:45.003841 81524 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0727 05:40:33.429208 81524 solver.cpp:236] Iteration 5730, loss = 0.963472
I0727 05:40:33.429477 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:40:33.429512 81524 solver.cpp:252]     Train net output #1: loss = 1.04661 (* 1 = 1.04661 loss)
I0727 05:40:37.752519 81524 sgd_solver.cpp:106] Iteration 5730, lr = 0.01
I0727 05:41:34.042861 81524 solver.cpp:236] Iteration 5740, loss = 0.968858
I0727 05:41:34.043025 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:41:34.043053 81524 solver.cpp:252]     Train net output #1: loss = 0.974708 (* 1 = 0.974708 loss)
I0727 05:41:35.048810 81524 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0727 05:42:26.044116 81524 solver.cpp:236] Iteration 5750, loss = 0.974734
I0727 05:42:26.044306 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:42:26.044328 81524 solver.cpp:252]     Train net output #1: loss = 1.09404 (* 1 = 1.09404 loss)
I0727 05:42:28.588623 81524 sgd_solver.cpp:106] Iteration 5750, lr = 0.01
I0727 05:43:20.916749 81524 solver.cpp:236] Iteration 5760, loss = 0.974862
I0727 05:43:20.917022 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:43:20.917043 81524 solver.cpp:252]     Train net output #1: loss = 1.04297 (* 1 = 1.04297 loss)
I0727 05:43:25.221292 81524 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0727 05:44:11.670114 81524 solver.cpp:236] Iteration 5770, loss = 0.97424
I0727 05:44:11.670320 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:44:11.670343 81524 solver.cpp:252]     Train net output #1: loss = 0.96967 (* 1 = 0.96967 loss)
I0727 05:44:16.000730 81524 sgd_solver.cpp:106] Iteration 5770, lr = 0.01
I0727 05:45:04.978813 81524 solver.cpp:236] Iteration 5780, loss = 0.966063
I0727 05:45:04.979061 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:45:04.979091 81524 solver.cpp:252]     Train net output #1: loss = 0.845099 (* 1 = 0.845099 loss)
I0727 05:45:09.257874 81524 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0727 05:45:57.004205 81524 solver.cpp:236] Iteration 5790, loss = 0.970792
I0727 05:45:57.004426 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:45:57.004459 81524 solver.cpp:252]     Train net output #1: loss = 0.975813 (* 1 = 0.975813 loss)
I0727 05:46:01.435642 81524 sgd_solver.cpp:106] Iteration 5790, lr = 0.01
I0727 05:46:49.459158 81524 solver.cpp:340] Iteration 5800, Testing net (#0)
I0727 05:49:31.597265 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5235
I0727 05:49:31.597486 81524 solver.cpp:408]     Test net output #1: loss = 0.988288 (* 1 = 0.988288 loss)
I0727 05:49:32.562014 81524 solver.cpp:236] Iteration 5800, loss = 0.972498
I0727 05:49:32.562084 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 05:49:32.562104 81524 solver.cpp:252]     Train net output #1: loss = 1.00181 (* 1 = 1.00181 loss)
I0727 05:49:35.464257 81524 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0727 05:50:22.816323 81524 solver.cpp:236] Iteration 5810, loss = 0.95581
I0727 05:50:22.816509 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:50:22.816532 81524 solver.cpp:252]     Train net output #1: loss = 1.02533 (* 1 = 1.02533 loss)
I0727 05:50:27.783041 81524 sgd_solver.cpp:106] Iteration 5810, lr = 0.01
I0727 05:51:14.361662 81524 solver.cpp:236] Iteration 5820, loss = 0.963931
I0727 05:51:14.361896 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:51:14.361941 81524 solver.cpp:252]     Train net output #1: loss = 1.09291 (* 1 = 1.09291 loss)
I0727 05:51:19.522927 81524 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0727 05:52:07.368955 81524 solver.cpp:236] Iteration 5830, loss = 0.959758
I0727 05:52:07.369318 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:52:07.369341 81524 solver.cpp:252]     Train net output #1: loss = 0.78204 (* 1 = 0.78204 loss)
I0727 05:52:11.559761 81524 sgd_solver.cpp:106] Iteration 5830, lr = 0.01
I0727 05:52:59.624346 81524 solver.cpp:236] Iteration 5840, loss = 0.96036
I0727 05:52:59.624580 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:52:59.624606 81524 solver.cpp:252]     Train net output #1: loss = 0.760379 (* 1 = 0.760379 loss)
I0727 05:53:03.590832 81524 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0727 05:53:53.831729 81524 solver.cpp:236] Iteration 5850, loss = 0.96877
I0727 05:53:53.831913 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 05:53:53.831933 81524 solver.cpp:252]     Train net output #1: loss = 1.07184 (* 1 = 1.07184 loss)
I0727 05:53:54.282860 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 05:53:58.133358 81524 sgd_solver.cpp:106] Iteration 5850, lr = 0.01
I0727 05:54:48.283787 81524 solver.cpp:236] Iteration 5860, loss = 0.982884
I0727 05:54:48.283987 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:54:48.284016 81524 solver.cpp:252]     Train net output #1: loss = 1.02141 (* 1 = 1.02141 loss)
I0727 05:54:52.888911 81524 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0727 05:55:42.034090 81524 solver.cpp:236] Iteration 5870, loss = 0.981511
I0727 05:55:42.034346 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 05:55:42.034368 81524 solver.cpp:252]     Train net output #1: loss = 1.04333 (* 1 = 1.04333 loss)
I0727 05:55:46.862215 81524 sgd_solver.cpp:106] Iteration 5870, lr = 0.01
I0727 05:56:38.604215 81524 solver.cpp:236] Iteration 5880, loss = 0.986595
I0727 05:56:38.604539 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 05:56:38.604574 81524 solver.cpp:252]     Train net output #1: loss = 1.08658 (* 1 = 1.08658 loss)
I0727 05:56:41.063019 81524 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0727 05:57:35.768743 81524 solver.cpp:236] Iteration 5890, loss = 0.980786
I0727 05:57:35.768975 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 05:57:35.768996 81524 solver.cpp:252]     Train net output #1: loss = 0.827757 (* 1 = 0.827757 loss)
I0727 05:57:41.888133 81524 sgd_solver.cpp:106] Iteration 5890, lr = 0.01
I0727 05:58:37.450565 81524 solver.cpp:340] Iteration 5900, Testing net (#0)
I0727 06:01:08.319247 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5265
I0727 06:01:08.319494 81524 solver.cpp:408]     Test net output #1: loss = 0.987617 (* 1 = 0.987617 loss)
I0727 06:01:09.277714 81524 solver.cpp:236] Iteration 5900, loss = 0.979757
I0727 06:01:09.277770 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:01:09.277788 81524 solver.cpp:252]     Train net output #1: loss = 1.15089 (* 1 = 1.15089 loss)
I0727 06:01:11.987562 81524 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0727 06:02:04.393168 81524 solver.cpp:236] Iteration 5910, loss = 0.965572
I0727 06:02:04.393431 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:02:04.393474 81524 solver.cpp:252]     Train net output #1: loss = 0.927978 (* 1 = 0.927978 loss)
I0727 06:02:09.090585 81524 sgd_solver.cpp:106] Iteration 5910, lr = 0.01
I0727 06:03:06.918720 81524 solver.cpp:236] Iteration 5920, loss = 0.967768
I0727 06:03:06.919080 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:03:06.919121 81524 solver.cpp:252]     Train net output #1: loss = 1.09682 (* 1 = 1.09682 loss)
I0727 06:03:07.988180 81524 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0727 06:04:02.936353 81524 solver.cpp:236] Iteration 5930, loss = 0.994431
I0727 06:04:02.936542 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:04:02.936573 81524 solver.cpp:252]     Train net output #1: loss = 1.108 (* 1 = 1.108 loss)
I0727 06:04:07.592279 81524 sgd_solver.cpp:106] Iteration 5930, lr = 0.01
I0727 06:04:59.143347 81524 solver.cpp:236] Iteration 5940, loss = 0.999238
I0727 06:04:59.143594 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:04:59.143615 81524 solver.cpp:252]     Train net output #1: loss = 1.1833 (* 1 = 1.1833 loss)
I0727 06:05:03.820484 81524 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0727 06:05:55.097036 81524 solver.cpp:236] Iteration 5950, loss = 0.988242
I0727 06:05:55.097270 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:05:55.097290 81524 solver.cpp:252]     Train net output #1: loss = 0.880776 (* 1 = 0.880776 loss)
I0727 06:05:59.648434 81524 sgd_solver.cpp:106] Iteration 5950, lr = 0.01
I0727 06:06:52.471518 81524 solver.cpp:236] Iteration 5960, loss = 0.987486
I0727 06:06:52.471774 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 06:06:52.471796 81524 solver.cpp:252]     Train net output #1: loss = 0.844481 (* 1 = 0.844481 loss)
I0727 06:06:57.321671 81524 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0727 06:07:50.039523 81524 solver.cpp:236] Iteration 5970, loss = 0.972587
I0727 06:07:50.039717 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:07:50.039741 81524 solver.cpp:252]     Train net output #1: loss = 0.912668 (* 1 = 0.912668 loss)
I0727 06:07:52.502743 81524 sgd_solver.cpp:106] Iteration 5970, lr = 0.01
I0727 06:08:46.177502 81524 solver.cpp:236] Iteration 5980, loss = 0.942925
I0727 06:08:46.177721 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 06:08:46.177750 81524 solver.cpp:252]     Train net output #1: loss = 0.763098 (* 1 = 0.763098 loss)
I0727 06:08:50.822921 81524 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0727 06:09:43.055454 81524 solver.cpp:236] Iteration 5990, loss = 0.93819
I0727 06:09:43.055734 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 06:09:43.055763 81524 solver.cpp:252]     Train net output #1: loss = 1.02525 (* 1 = 1.02525 loss)
I0727 06:09:48.498467 81524 sgd_solver.cpp:106] Iteration 5990, lr = 0.01
I0727 06:10:40.592999 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_6000.caffemodel
I0727 06:10:40.734412 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_6000.solverstate
I0727 06:10:40.738246 81524 solver.cpp:340] Iteration 6000, Testing net (#0)
I0727 06:12:50.115619 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 06:13:15.637830 81524 solver.cpp:408]     Test net output #0: accuracy = 0.505
I0727 06:13:15.637972 81524 solver.cpp:408]     Test net output #1: loss = 1.01861 (* 1 = 1.01861 loss)
I0727 06:13:16.631759 81524 solver.cpp:236] Iteration 6000, loss = 0.945064
I0727 06:13:16.631814 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 06:13:16.631834 81524 solver.cpp:252]     Train net output #1: loss = 0.777916 (* 1 = 0.777916 loss)
I0727 06:13:19.311190 81524 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0727 06:14:11.216536 81524 solver.cpp:236] Iteration 6010, loss = 0.953215
I0727 06:14:11.216743 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 06:14:11.216765 81524 solver.cpp:252]     Train net output #1: loss = 0.812225 (* 1 = 0.812225 loss)
I0727 06:14:15.507580 81524 sgd_solver.cpp:106] Iteration 6010, lr = 0.01
I0727 06:15:02.575328 81524 solver.cpp:236] Iteration 6020, loss = 0.961648
I0727 06:15:02.575594 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:15:02.575621 81524 solver.cpp:252]     Train net output #1: loss = 0.913646 (* 1 = 0.913646 loss)
I0727 06:15:06.925878 81524 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0727 06:15:59.024039 81524 solver.cpp:236] Iteration 6030, loss = 0.955047
I0727 06:15:59.024312 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 06:15:59.024332 81524 solver.cpp:252]     Train net output #1: loss = 0.79684 (* 1 = 0.79684 loss)
I0727 06:16:04.099474 81524 sgd_solver.cpp:106] Iteration 6030, lr = 0.01
I0727 06:16:53.216629 81524 solver.cpp:236] Iteration 6040, loss = 0.955802
I0727 06:16:53.216898 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:16:53.216938 81524 solver.cpp:252]     Train net output #1: loss = 0.94606 (* 1 = 0.94606 loss)
I0727 06:16:54.034924 81524 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0727 06:17:46.235860 81524 solver.cpp:236] Iteration 6050, loss = 0.960251
I0727 06:17:46.236212 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 06:17:46.236248 81524 solver.cpp:252]     Train net output #1: loss = 1.01179 (* 1 = 1.01179 loss)
I0727 06:17:50.753844 81524 sgd_solver.cpp:106] Iteration 6050, lr = 0.01
I0727 06:18:37.176925 81524 solver.cpp:236] Iteration 6060, loss = 0.969176
I0727 06:18:37.177139 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 06:18:37.177178 81524 solver.cpp:252]     Train net output #1: loss = 0.932247 (* 1 = 0.932247 loss)
I0727 06:18:41.695055 81524 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0727 06:19:30.247866 81524 solver.cpp:236] Iteration 6070, loss = 0.971438
I0727 06:19:30.248162 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 06:19:30.248210 81524 solver.cpp:252]     Train net output #1: loss = 1.18718 (* 1 = 1.18718 loss)
I0727 06:19:34.231845 81524 sgd_solver.cpp:106] Iteration 6070, lr = 0.01
I0727 06:20:21.700109 81524 solver.cpp:236] Iteration 6080, loss = 0.996647
I0727 06:20:21.700343 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:20:21.700373 81524 solver.cpp:252]     Train net output #1: loss = 1.00661 (* 1 = 1.00661 loss)
I0727 06:20:25.953994 81524 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0727 06:21:19.960654 81524 solver.cpp:236] Iteration 6090, loss = 0.976138
I0727 06:21:19.960815 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 06:21:19.960839 81524 solver.cpp:252]     Train net output #1: loss = 1.17274 (* 1 = 1.17274 loss)
I0727 06:21:20.931696 81524 sgd_solver.cpp:106] Iteration 6090, lr = 0.01
I0727 06:22:16.838078 81524 solver.cpp:340] Iteration 6100, Testing net (#0)
I0727 06:25:38.524729 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5315
I0727 06:25:38.524960 81524 solver.cpp:408]     Test net output #1: loss = 0.970511 (* 1 = 0.970511 loss)
I0727 06:25:39.608048 81524 solver.cpp:236] Iteration 6100, loss = 0.973642
I0727 06:25:39.608151 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:25:39.608193 81524 solver.cpp:252]     Train net output #1: loss = 1.00827 (* 1 = 1.00827 loss)
I0727 06:25:40.711710 81524 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0727 06:26:56.488878 81524 solver.cpp:236] Iteration 6110, loss = 0.958821
I0727 06:26:56.489142 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 06:26:56.489192 81524 solver.cpp:252]     Train net output #1: loss = 0.843473 (* 1 = 0.843473 loss)
I0727 06:26:57.868160 81524 sgd_solver.cpp:106] Iteration 6110, lr = 0.01
I0727 06:28:13.137110 81524 solver.cpp:236] Iteration 6120, loss = 0.956636
I0727 06:28:13.137292 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 06:28:13.137338 81524 solver.cpp:252]     Train net output #1: loss = 0.985324 (* 1 = 0.985324 loss)
I0727 06:28:16.362809 81524 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0727 06:29:34.314651 81524 solver.cpp:236] Iteration 6130, loss = 0.946606
I0727 06:29:34.315001 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:29:34.315053 81524 solver.cpp:252]     Train net output #1: loss = 1.02937 (* 1 = 1.02937 loss)
I0727 06:29:36.261863 81524 sgd_solver.cpp:106] Iteration 6130, lr = 0.01
I0727 06:30:53.283200 81524 solver.cpp:236] Iteration 6140, loss = 0.960863
I0727 06:30:53.283388 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 06:30:53.283421 81524 solver.cpp:252]     Train net output #1: loss = 1.11208 (* 1 = 1.11208 loss)
I0727 06:30:58.518116 81524 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0727 06:32:21.442978 81524 solver.cpp:236] Iteration 6150, loss = 0.970295
I0727 06:32:21.443217 81524 solver.cpp:252]     Train net output #0: accuracy = 0.8125
I0727 06:32:21.443262 81524 solver.cpp:252]     Train net output #1: loss = 0.932901 (* 1 = 0.932901 loss)
I0727 06:32:22.525637 81524 sgd_solver.cpp:106] Iteration 6150, lr = 0.01
I0727 06:33:36.848143 81524 solver.cpp:236] Iteration 6160, loss = 0.984764
I0727 06:33:36.851997 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 06:33:36.852046 81524 solver.cpp:252]     Train net output #1: loss = 0.885857 (* 1 = 0.885857 loss)
I0727 06:33:37.934267 81524 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0727 06:34:42.418702 81524 solver.cpp:236] Iteration 6170, loss = 0.978158
I0727 06:34:42.419036 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 06:34:42.419090 81524 solver.cpp:252]     Train net output #1: loss = 1.01817 (* 1 = 1.01817 loss)
I0727 06:34:43.569038 81524 sgd_solver.cpp:106] Iteration 6170, lr = 0.01
I0727 06:35:42.542526 81524 solver.cpp:236] Iteration 6180, loss = 0.988442
I0727 06:35:42.542740 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 06:35:42.542784 81524 solver.cpp:252]     Train net output #1: loss = 1.07361 (* 1 = 1.07361 loss)
I0727 06:35:46.917412 81524 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0727 06:36:38.104076 81524 solver.cpp:236] Iteration 6190, loss = 0.996496
I0727 06:36:38.104336 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 06:36:38.104372 81524 solver.cpp:252]     Train net output #1: loss = 1.06635 (* 1 = 1.06635 loss)
I0727 06:36:38.879135 81558 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 06:36:43.231420 81524 sgd_solver.cpp:106] Iteration 6190, lr = 0.01
I0727 06:37:32.887686 81524 solver.cpp:340] Iteration 6200, Testing net (#0)
I0727 06:39:58.195209 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5395
I0727 06:39:58.195480 81524 solver.cpp:408]     Test net output #1: loss = 0.969185 (* 1 = 0.969185 loss)
I0727 06:39:59.160940 81524 solver.cpp:236] Iteration 6200, loss = 0.991721
I0727 06:39:59.161031 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 06:39:59.161062 81524 solver.cpp:252]     Train net output #1: loss = 0.986384 (* 1 = 0.986384 loss)
I0727 06:40:02.191442 81524 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0727 06:40:57.198946 81524 solver.cpp:236] Iteration 6210, loss = 0.985632
I0727 06:40:57.199185 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 06:40:57.199218 81524 solver.cpp:252]     Train net output #1: loss = 1.08883 (* 1 = 1.08883 loss)
I0727 06:41:02.370419 81524 sgd_solver.cpp:106] Iteration 6210, lr = 0.01
I0727 06:41:57.329527 81524 solver.cpp:236] Iteration 6220, loss = 0.998569
I0727 06:41:57.329790 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:41:57.329823 81524 solver.cpp:252]     Train net output #1: loss = 1.14962 (* 1 = 1.14962 loss)
I0727 06:41:58.421200 81524 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0727 06:42:52.219501 81524 solver.cpp:236] Iteration 6230, loss = 0.988433
I0727 06:42:52.219705 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 06:42:52.219739 81524 solver.cpp:252]     Train net output #1: loss = 0.969434 (* 1 = 0.969434 loss)
I0727 06:42:56.799479 81524 sgd_solver.cpp:106] Iteration 6230, lr = 0.01
I0727 06:43:52.132755 81524 solver.cpp:236] Iteration 6240, loss = 0.990677
I0727 06:43:52.133038 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:43:52.133080 81524 solver.cpp:252]     Train net output #1: loss = 0.931132 (* 1 = 0.931132 loss)
I0727 06:43:56.885274 81524 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0727 06:44:46.557556 81524 solver.cpp:236] Iteration 6250, loss = 0.992226
I0727 06:44:46.557762 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 06:44:46.557799 81524 solver.cpp:252]     Train net output #1: loss = 1.06457 (* 1 = 1.06457 loss)
I0727 06:44:50.977205 81524 sgd_solver.cpp:106] Iteration 6250, lr = 0.01
I0727 06:45:42.217428 81524 solver.cpp:236] Iteration 6260, loss = 0.991094
I0727 06:45:42.217618 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 06:45:42.217644 81524 solver.cpp:252]     Train net output #1: loss = 1.06728 (* 1 = 1.06728 loss)
I0727 06:45:47.279166 81524 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0727 06:46:37.453833 81524 solver.cpp:236] Iteration 6270, loss = 0.992611
I0727 06:46:37.454097 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:46:37.454119 81524 solver.cpp:252]     Train net output #1: loss = 0.99885 (* 1 = 0.99885 loss)
I0727 06:46:41.613318 81524 sgd_solver.cpp:106] Iteration 6270, lr = 0.01
I0727 06:47:32.484223 81524 solver.cpp:236] Iteration 6280, loss = 0.990876
I0727 06:47:32.484450 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:47:32.484472 81524 solver.cpp:252]     Train net output #1: loss = 0.891525 (* 1 = 0.891525 loss)
I0727 06:47:36.866442 81524 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0727 06:48:26.839733 81524 solver.cpp:236] Iteration 6290, loss = 0.987692
I0727 06:48:26.839923 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 06:48:26.839967 81524 solver.cpp:252]     Train net output #1: loss = 0.880746 (* 1 = 0.880746 loss)
I0727 06:48:31.638521 81524 sgd_solver.cpp:106] Iteration 6290, lr = 0.01
I0727 06:49:19.623368 81524 solver.cpp:340] Iteration 6300, Testing net (#0)
I0727 06:52:02.632028 81524 solver.cpp:408]     Test net output #0: accuracy = 0.528
I0727 06:52:02.632256 81524 solver.cpp:408]     Test net output #1: loss = 0.992441 (* 1 = 0.992441 loss)
I0727 06:52:03.627846 81524 solver.cpp:236] Iteration 6300, loss = 0.975608
I0727 06:52:03.627918 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 06:52:03.627939 81524 solver.cpp:252]     Train net output #1: loss = 0.977895 (* 1 = 0.977895 loss)
I0727 06:52:05.844117 81524 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0727 06:52:57.231879 81524 solver.cpp:236] Iteration 6310, loss = 0.977952
I0727 06:52:57.232112 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 06:52:57.232146 81524 solver.cpp:252]     Train net output #1: loss = 0.846386 (* 1 = 0.846386 loss)
I0727 06:53:01.499321 81524 sgd_solver.cpp:106] Iteration 6310, lr = 0.01
I0727 06:53:53.230027 81524 solver.cpp:236] Iteration 6320, loss = 0.965911
I0727 06:53:53.230268 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:53:53.230301 81524 solver.cpp:252]     Train net output #1: loss = 1.06124 (* 1 = 1.06124 loss)
I0727 06:53:58.190912 81524 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0727 06:54:51.690987 81524 solver.cpp:236] Iteration 6330, loss = 0.969735
I0727 06:54:51.691227 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 06:54:51.691256 81524 solver.cpp:252]     Train net output #1: loss = 0.75537 (* 1 = 0.75537 loss)
I0727 06:54:52.526337 81524 sgd_solver.cpp:106] Iteration 6330, lr = 0.01
I0727 06:54:56.708336 81557 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 06:55:44.251785 81524 solver.cpp:236] Iteration 6340, loss = 0.960093
I0727 06:55:44.252037 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 06:55:44.252058 81524 solver.cpp:252]     Train net output #1: loss = 0.821603 (* 1 = 0.821603 loss)
I0727 06:55:48.517081 81524 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0727 06:56:35.398918 81524 solver.cpp:236] Iteration 6350, loss = 0.969366
I0727 06:56:35.399175 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 06:56:35.399200 81524 solver.cpp:252]     Train net output #1: loss = 1.14965 (* 1 = 1.14965 loss)
I0727 06:56:39.229924 81524 sgd_solver.cpp:106] Iteration 6350, lr = 0.01
I0727 06:57:26.165699 81524 solver.cpp:236] Iteration 6360, loss = 0.979358
I0727 06:57:26.165954 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 06:57:26.165992 81524 solver.cpp:252]     Train net output #1: loss = 1.21864 (* 1 = 1.21864 loss)
I0727 06:57:28.013767 81524 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0727 06:58:15.472720 81524 solver.cpp:236] Iteration 6370, loss = 0.97952
I0727 06:58:15.472916 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 06:58:15.472949 81524 solver.cpp:252]     Train net output #1: loss = 0.915197 (* 1 = 0.915197 loss)
I0727 06:58:16.193091 81524 sgd_solver.cpp:106] Iteration 6370, lr = 0.01
I0727 06:59:01.723577 81524 solver.cpp:236] Iteration 6380, loss = 0.962746
I0727 06:59:01.723803 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 06:59:01.723831 81524 solver.cpp:252]     Train net output #1: loss = 0.964645 (* 1 = 0.964645 loss)
I0727 06:59:06.558481 81524 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0727 06:59:52.709712 81524 solver.cpp:236] Iteration 6390, loss = 0.963232
I0727 06:59:52.709893 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 06:59:52.709930 81524 solver.cpp:252]     Train net output #1: loss = 0.944377 (* 1 = 0.944377 loss)
I0727 06:59:57.820196 81524 sgd_solver.cpp:106] Iteration 6390, lr = 0.01
I0727 07:00:43.386509 81524 solver.cpp:340] Iteration 6400, Testing net (#0)
I0727 07:03:06.169412 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5505
I0727 07:03:06.169661 81524 solver.cpp:408]     Test net output #1: loss = 0.96641 (* 1 = 0.96641 loss)
I0727 07:03:07.175606 81524 solver.cpp:236] Iteration 6400, loss = 0.953366
I0727 07:03:07.175674 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 07:03:07.175704 81524 solver.cpp:252]     Train net output #1: loss = 0.728024 (* 1 = 0.728024 loss)
I0727 07:03:09.630849 81524 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0727 07:03:55.701259 81524 solver.cpp:236] Iteration 6410, loss = 0.952852
I0727 07:03:55.701486 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:03:55.701514 81524 solver.cpp:252]     Train net output #1: loss = 1.04269 (* 1 = 1.04269 loss)
I0727 07:03:59.457649 81524 sgd_solver.cpp:106] Iteration 6410, lr = 0.01
I0727 07:04:47.666934 81524 solver.cpp:236] Iteration 6420, loss = 0.944428
I0727 07:04:47.667189 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 07:04:47.667219 81524 solver.cpp:252]     Train net output #1: loss = 0.891753 (* 1 = 0.891753 loss)
I0727 07:04:52.008644 81524 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0727 07:05:37.825513 81524 solver.cpp:236] Iteration 6430, loss = 0.934621
I0727 07:05:37.825712 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:05:37.825749 81524 solver.cpp:252]     Train net output #1: loss = 0.854556 (* 1 = 0.854556 loss)
I0727 07:05:42.125044 81524 sgd_solver.cpp:106] Iteration 6430, lr = 0.01
I0727 07:06:29.105373 81524 solver.cpp:236] Iteration 6440, loss = 0.947723
I0727 07:06:29.105542 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:06:29.105581 81524 solver.cpp:252]     Train net output #1: loss = 1.00952 (* 1 = 1.00952 loss)
I0727 07:06:33.121872 81524 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0727 07:07:19.861503 81524 solver.cpp:236] Iteration 6450, loss = 0.960529
I0727 07:07:19.861696 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:07:19.861717 81524 solver.cpp:252]     Train net output #1: loss = 0.984063 (* 1 = 0.984063 loss)
I0727 07:07:24.063446 81524 sgd_solver.cpp:106] Iteration 6450, lr = 0.01
I0727 07:08:12.104872 81524 solver.cpp:236] Iteration 6460, loss = 0.946257
I0727 07:08:12.105079 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:08:12.105110 81524 solver.cpp:252]     Train net output #1: loss = 0.813977 (* 1 = 0.813977 loss)
I0727 07:08:16.263257 81524 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0727 07:09:04.424743 81524 solver.cpp:236] Iteration 6470, loss = 0.958666
I0727 07:09:04.424928 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:09:04.424959 81524 solver.cpp:252]     Train net output #1: loss = 1.07851 (* 1 = 1.07851 loss)
I0727 07:09:08.665153 81524 sgd_solver.cpp:106] Iteration 6470, lr = 0.01
I0727 07:09:57.169039 81524 solver.cpp:236] Iteration 6480, loss = 0.9886
I0727 07:09:57.169224 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:09:57.169252 81524 solver.cpp:252]     Train net output #1: loss = 1.00757 (* 1 = 1.00757 loss)
I0727 07:10:01.381548 81524 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0727 07:10:48.690639 81524 solver.cpp:236] Iteration 6490, loss = 0.989834
I0727 07:10:48.690995 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:10:48.691026 81524 solver.cpp:252]     Train net output #1: loss = 1.09295 (* 1 = 1.09295 loss)
I0727 07:10:52.984123 81524 sgd_solver.cpp:106] Iteration 6490, lr = 0.01
I0727 07:11:38.559128 81524 solver.cpp:340] Iteration 6500, Testing net (#0)
I0727 07:13:35.401202 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 07:14:04.485973 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5175
I0727 07:14:04.486057 81524 solver.cpp:408]     Test net output #1: loss = 1.01132 (* 1 = 1.01132 loss)
I0727 07:14:05.494345 81524 solver.cpp:236] Iteration 6500, loss = 0.979801
I0727 07:14:05.494493 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:14:05.494515 81524 solver.cpp:252]     Train net output #1: loss = 1.0099 (* 1 = 1.0099 loss)
I0727 07:14:07.602121 81524 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0727 07:14:55.052376 81524 solver.cpp:236] Iteration 6510, loss = 0.991268
I0727 07:14:55.052553 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:14:55.052577 81524 solver.cpp:252]     Train net output #1: loss = 0.998572 (* 1 = 0.998572 loss)
I0727 07:14:59.366497 81524 sgd_solver.cpp:106] Iteration 6510, lr = 0.01
I0727 07:15:49.613854 81524 solver.cpp:236] Iteration 6520, loss = 0.997253
I0727 07:15:49.614095 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 07:15:49.614133 81524 solver.cpp:252]     Train net output #1: loss = 0.866699 (* 1 = 0.866699 loss)
I0727 07:15:54.826515 81524 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0727 07:16:48.312029 81524 solver.cpp:236] Iteration 6530, loss = 0.979295
I0727 07:16:48.312233 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:16:48.312258 81524 solver.cpp:252]     Train net output #1: loss = 1.00642 (* 1 = 1.00642 loss)
I0727 07:16:50.630565 81524 sgd_solver.cpp:106] Iteration 6530, lr = 0.01
I0727 07:17:40.988334 81524 solver.cpp:236] Iteration 6540, loss = 0.971833
I0727 07:17:40.988555 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:17:40.988581 81524 solver.cpp:252]     Train net output #1: loss = 0.924247 (* 1 = 0.924247 loss)
I0727 07:17:45.266290 81524 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0727 07:18:35.625705 81524 solver.cpp:236] Iteration 6550, loss = 0.963973
I0727 07:18:35.625879 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:18:35.625921 81524 solver.cpp:252]     Train net output #1: loss = 0.945036 (* 1 = 0.945036 loss)
I0727 07:18:40.270649 81524 sgd_solver.cpp:106] Iteration 6550, lr = 0.01
I0727 07:19:31.310803 81524 solver.cpp:236] Iteration 6560, loss = 0.967767
I0727 07:19:31.311022 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:19:31.311054 81524 solver.cpp:252]     Train net output #1: loss = 1.00057 (* 1 = 1.00057 loss)
I0727 07:19:35.767648 81524 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0727 07:20:26.739425 81524 solver.cpp:236] Iteration 6570, loss = 0.972075
I0727 07:20:26.739676 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:20:26.739711 81524 solver.cpp:252]     Train net output #1: loss = 0.941259 (* 1 = 0.941259 loss)
I0727 07:20:30.613235 81524 sgd_solver.cpp:106] Iteration 6570, lr = 0.01
I0727 07:21:21.331182 81524 solver.cpp:236] Iteration 6580, loss = 0.984079
I0727 07:21:21.331490 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:21:21.331547 81524 solver.cpp:252]     Train net output #1: loss = 0.940007 (* 1 = 0.940007 loss)
I0727 07:21:25.843185 81524 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0727 07:22:19.234169 81524 solver.cpp:236] Iteration 6590, loss = 0.981448
I0727 07:22:19.234352 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 07:22:19.234385 81524 solver.cpp:252]     Train net output #1: loss = 1.07989 (* 1 = 1.07989 loss)
I0727 07:22:19.957990 81524 sgd_solver.cpp:106] Iteration 6590, lr = 0.01
I0727 07:23:12.291862 81524 solver.cpp:340] Iteration 6600, Testing net (#0)
I0727 07:25:36.947429 81524 solver.cpp:408]     Test net output #0: accuracy = 0.549
I0727 07:25:36.947695 81524 solver.cpp:408]     Test net output #1: loss = 0.969991 (* 1 = 0.969991 loss)
I0727 07:25:37.916707 81524 solver.cpp:236] Iteration 6600, loss = 1.00174
I0727 07:25:37.916785 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 07:25:37.916815 81524 solver.cpp:252]     Train net output #1: loss = 0.78722 (* 1 = 0.78722 loss)
I0727 07:25:39.913312 81524 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0727 07:26:31.498849 81524 solver.cpp:236] Iteration 6610, loss = 1.00481
I0727 07:26:31.499042 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:26:31.499068 81524 solver.cpp:252]     Train net output #1: loss = 0.888223 (* 1 = 0.888223 loss)
I0727 07:26:35.875262 81524 sgd_solver.cpp:106] Iteration 6610, lr = 0.01
I0727 07:27:27.460410 81524 solver.cpp:236] Iteration 6620, loss = 1.00093
I0727 07:27:27.460571 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 07:27:27.460594 81524 solver.cpp:252]     Train net output #1: loss = 1.13494 (* 1 = 1.13494 loss)
I0727 07:27:32.658397 81524 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0727 07:28:23.241008 81524 solver.cpp:236] Iteration 6630, loss = 1.00917
I0727 07:28:23.241216 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:28:23.241238 81524 solver.cpp:252]     Train net output #1: loss = 0.961439 (* 1 = 0.961439 loss)
I0727 07:28:27.183439 81524 sgd_solver.cpp:106] Iteration 6630, lr = 0.01
I0727 07:29:19.552263 81524 solver.cpp:236] Iteration 6640, loss = 1.01649
I0727 07:29:19.552460 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:29:19.552505 81524 solver.cpp:252]     Train net output #1: loss = 0.890126 (* 1 = 0.890126 loss)
I0727 07:29:23.882304 81524 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0727 07:30:15.394847 81524 solver.cpp:236] Iteration 6650, loss = 1.00893
I0727 07:30:15.395153 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:30:15.395191 81524 solver.cpp:252]     Train net output #1: loss = 0.945962 (* 1 = 0.945962 loss)
I0727 07:30:21.379106 81524 sgd_solver.cpp:106] Iteration 6650, lr = 0.01
I0727 07:31:14.067704 81524 solver.cpp:236] Iteration 6660, loss = 1.01746
I0727 07:31:14.067898 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 07:31:14.067934 81524 solver.cpp:252]     Train net output #1: loss = 1.11731 (* 1 = 1.11731 loss)
I0727 07:31:18.411792 81524 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0727 07:32:10.196482 81524 solver.cpp:236] Iteration 6670, loss = 1.01431
I0727 07:32:10.196693 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:32:10.196713 81524 solver.cpp:252]     Train net output #1: loss = 1.0527 (* 1 = 1.0527 loss)
I0727 07:32:15.096137 81524 sgd_solver.cpp:106] Iteration 6670, lr = 0.01
I0727 07:33:07.396095 81524 solver.cpp:236] Iteration 6680, loss = 1.01781
I0727 07:33:07.396359 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:33:07.396394 81524 solver.cpp:252]     Train net output #1: loss = 0.910999 (* 1 = 0.910999 loss)
I0727 07:33:08.196851 81524 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0727 07:33:56.087429 81524 solver.cpp:236] Iteration 6690, loss = 1.02144
I0727 07:33:56.087674 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:33:56.087704 81524 solver.cpp:252]     Train net output #1: loss = 1.0028 (* 1 = 1.0028 loss)
I0727 07:34:00.402547 81524 sgd_solver.cpp:106] Iteration 6690, lr = 0.01
I0727 07:34:34.802592 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 07:34:44.585501 81524 solver.cpp:340] Iteration 6700, Testing net (#0)
I0727 07:37:15.500383 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5315
I0727 07:37:15.500551 81524 solver.cpp:408]     Test net output #1: loss = 0.983353 (* 1 = 0.983353 loss)
I0727 07:37:16.507362 81524 solver.cpp:236] Iteration 6700, loss = 1.02792
I0727 07:37:16.507431 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:37:16.507453 81524 solver.cpp:252]     Train net output #1: loss = 1.10908 (* 1 = 1.10908 loss)
I0727 07:37:18.585566 81524 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0727 07:38:03.684818 81524 solver.cpp:236] Iteration 6710, loss = 1.02335
I0727 07:38:03.685096 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 07:38:03.685119 81524 solver.cpp:252]     Train net output #1: loss = 1.25975 (* 1 = 1.25975 loss)
I0727 07:38:08.108695 81524 sgd_solver.cpp:106] Iteration 6710, lr = 0.01
I0727 07:38:53.227567 81524 solver.cpp:236] Iteration 6720, loss = 1.01857
I0727 07:38:53.227800 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:38:53.227854 81524 solver.cpp:252]     Train net output #1: loss = 0.870347 (* 1 = 0.870347 loss)
I0727 07:38:57.671113 81524 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0727 07:39:42.835758 81524 solver.cpp:236] Iteration 6730, loss = 1.00343
I0727 07:39:42.835952 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 07:39:42.835978 81524 solver.cpp:252]     Train net output #1: loss = 1.19155 (* 1 = 1.19155 loss)
I0727 07:39:47.692190 81524 sgd_solver.cpp:106] Iteration 6730, lr = 0.01
I0727 07:40:31.865546 81524 solver.cpp:236] Iteration 6740, loss = 0.994429
I0727 07:40:31.865751 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:40:31.865772 81524 solver.cpp:252]     Train net output #1: loss = 1.10389 (* 1 = 1.10389 loss)
I0727 07:40:35.857105 81524 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0727 07:41:25.550287 81524 solver.cpp:236] Iteration 6750, loss = 0.976236
I0727 07:41:25.553190 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 07:41:25.553236 81524 solver.cpp:252]     Train net output #1: loss = 0.888419 (* 1 = 0.888419 loss)
I0727 07:41:26.645474 81524 sgd_solver.cpp:106] Iteration 6750, lr = 0.01
I0727 07:42:22.047915 81524 solver.cpp:236] Iteration 6760, loss = 0.967769
I0727 07:42:22.048243 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:42:22.048300 81524 solver.cpp:252]     Train net output #1: loss = 0.860477 (* 1 = 0.860477 loss)
I0727 07:42:26.108103 81524 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0727 07:43:26.496438 81524 solver.cpp:236] Iteration 6770, loss = 0.986334
I0727 07:43:26.496640 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 07:43:26.496677 81524 solver.cpp:252]     Train net output #1: loss = 1.10066 (* 1 = 1.10066 loss)
I0727 07:43:27.641846 81524 sgd_solver.cpp:106] Iteration 6770, lr = 0.01
I0727 07:44:22.525825 81524 solver.cpp:236] Iteration 6780, loss = 0.993663
I0727 07:44:22.526000 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 07:44:22.526021 81524 solver.cpp:252]     Train net output #1: loss = 1.02293 (* 1 = 1.02293 loss)
I0727 07:44:27.683801 81524 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0727 07:45:30.839450 81524 solver.cpp:236] Iteration 6790, loss = 0.981533
I0727 07:45:30.839709 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:45:30.839738 81524 solver.cpp:252]     Train net output #1: loss = 1.04606 (* 1 = 1.04606 loss)
I0727 07:45:31.691993 81524 sgd_solver.cpp:106] Iteration 6790, lr = 0.01
I0727 07:46:30.915541 81524 solver.cpp:340] Iteration 6800, Testing net (#0)
I0727 07:49:26.357461 81524 solver.cpp:408]     Test net output #0: accuracy = 0.542
I0727 07:49:26.357791 81524 solver.cpp:408]     Test net output #1: loss = 0.98276 (* 1 = 0.98276 loss)
I0727 07:49:27.315541 81524 solver.cpp:236] Iteration 6800, loss = 0.984045
I0727 07:49:27.315609 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 07:49:27.315631 81524 solver.cpp:252]     Train net output #1: loss = 0.794256 (* 1 = 0.794256 loss)
I0727 07:49:28.071859 81524 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0727 07:50:25.310358 81524 solver.cpp:236] Iteration 6810, loss = 0.968659
I0727 07:50:25.310678 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 07:50:25.310730 81524 solver.cpp:252]     Train net output #1: loss = 1.14161 (* 1 = 1.14161 loss)
I0727 07:50:26.507912 81524 sgd_solver.cpp:106] Iteration 6810, lr = 0.01
I0727 07:51:25.135993 81524 solver.cpp:236] Iteration 6820, loss = 0.951167
I0727 07:51:25.136198 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 07:51:25.136224 81524 solver.cpp:252]     Train net output #1: loss = 1.06214 (* 1 = 1.06214 loss)
I0727 07:51:25.797847 81524 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0727 07:52:13.912335 81524 solver.cpp:236] Iteration 6830, loss = 0.953185
I0727 07:52:13.912516 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 07:52:13.912547 81524 solver.cpp:252]     Train net output #1: loss = 0.863057 (* 1 = 0.863057 loss)
I0727 07:52:18.177105 81524 sgd_solver.cpp:106] Iteration 6830, lr = 0.01
I0727 07:53:01.598451 81556 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 07:53:07.782582 81524 solver.cpp:236] Iteration 6840, loss = 0.951286
I0727 07:53:07.782703 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 07:53:07.782724 81524 solver.cpp:252]     Train net output #1: loss = 0.889656 (* 1 = 0.889656 loss)
I0727 07:53:12.468433 81524 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0727 07:54:03.062981 81524 solver.cpp:236] Iteration 6850, loss = 0.954916
I0727 07:54:03.063130 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:54:03.063153 81524 solver.cpp:252]     Train net output #1: loss = 0.868522 (* 1 = 0.868522 loss)
I0727 07:54:06.352499 81524 sgd_solver.cpp:106] Iteration 6850, lr = 0.01
I0727 07:54:57.301686 81524 solver.cpp:236] Iteration 6860, loss = 0.965202
I0727 07:54:57.301898 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:54:57.301933 81524 solver.cpp:252]     Train net output #1: loss = 0.903348 (* 1 = 0.903348 loss)
I0727 07:55:01.503722 81524 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0727 07:55:51.236538 81524 solver.cpp:236] Iteration 6870, loss = 0.951311
I0727 07:55:51.236734 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 07:55:51.236757 81524 solver.cpp:252]     Train net output #1: loss = 0.801193 (* 1 = 0.801193 loss)
I0727 07:55:55.541817 81524 sgd_solver.cpp:106] Iteration 6870, lr = 0.01
I0727 07:56:50.180140 81524 solver.cpp:236] Iteration 6880, loss = 0.929393
I0727 07:56:50.180304 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:56:50.180341 81524 solver.cpp:252]     Train net output #1: loss = 0.902004 (* 1 = 0.902004 loss)
I0727 07:56:51.285871 81524 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0727 07:57:42.204787 81524 solver.cpp:236] Iteration 6890, loss = 0.949408
I0727 07:57:42.205056 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 07:57:42.205080 81524 solver.cpp:252]     Train net output #1: loss = 0.943652 (* 1 = 0.943652 loss)
I0727 07:57:46.874699 81524 sgd_solver.cpp:106] Iteration 6890, lr = 0.01
I0727 07:58:34.977102 81524 solver.cpp:340] Iteration 6900, Testing net (#0)
I0727 08:01:03.639046 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5455
I0727 08:01:03.639276 81524 solver.cpp:408]     Test net output #1: loss = 0.956822 (* 1 = 0.956822 loss)
I0727 08:01:04.650095 81524 solver.cpp:236] Iteration 6900, loss = 0.954608
I0727 08:01:04.650164 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:01:04.650194 81524 solver.cpp:252]     Train net output #1: loss = 1.06278 (* 1 = 1.06278 loss)
I0727 08:01:06.579299 81524 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0727 08:01:55.203826 81524 solver.cpp:236] Iteration 6910, loss = 0.952833
I0727 08:01:55.204026 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 08:01:55.204048 81524 solver.cpp:252]     Train net output #1: loss = 0.902387 (* 1 = 0.902387 loss)
I0727 08:01:59.761605 81524 sgd_solver.cpp:106] Iteration 6910, lr = 0.01
I0727 08:02:52.483422 81524 solver.cpp:236] Iteration 6920, loss = 0.956585
I0727 08:02:52.483649 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:02:52.483674 81524 solver.cpp:252]     Train net output #1: loss = 0.855808 (* 1 = 0.855808 loss)
I0727 08:02:57.090241 81524 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0727 08:03:47.550230 81524 solver.cpp:236] Iteration 6930, loss = 0.949451
I0727 08:03:47.550451 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:03:47.550482 81524 solver.cpp:252]     Train net output #1: loss = 0.850307 (* 1 = 0.850307 loss)
I0727 08:03:50.804821 81524 sgd_solver.cpp:106] Iteration 6930, lr = 0.01
I0727 08:04:43.422132 81524 solver.cpp:236] Iteration 6940, loss = 0.93897
I0727 08:04:43.422318 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 08:04:43.422341 81524 solver.cpp:252]     Train net output #1: loss = 1.03576 (* 1 = 1.03576 loss)
I0727 08:04:48.210765 81524 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0727 08:05:38.888790 81524 solver.cpp:236] Iteration 6950, loss = 0.922901
I0727 08:05:38.888991 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:05:38.889013 81524 solver.cpp:252]     Train net output #1: loss = 0.887198 (* 1 = 0.887198 loss)
I0727 08:05:44.127388 81524 sgd_solver.cpp:106] Iteration 6950, lr = 0.01
I0727 08:06:37.008514 81524 solver.cpp:236] Iteration 6960, loss = 0.918511
I0727 08:06:37.008720 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:06:37.008757 81524 solver.cpp:252]     Train net output #1: loss = 0.929745 (* 1 = 0.929745 loss)
I0727 08:06:41.387832 81524 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0727 08:07:37.156476 81524 solver.cpp:236] Iteration 6970, loss = 0.924729
I0727 08:07:37.156666 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:07:37.156710 81524 solver.cpp:252]     Train net output #1: loss = 1.08246 (* 1 = 1.08246 loss)
I0727 08:07:40.548807 81524 sgd_solver.cpp:106] Iteration 6970, lr = 0.01
I0727 08:08:32.983471 81524 solver.cpp:236] Iteration 6980, loss = 0.94005
I0727 08:08:32.983680 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 08:08:32.983701 81524 solver.cpp:252]     Train net output #1: loss = 0.918312 (* 1 = 0.918312 loss)
I0727 08:08:37.607007 81524 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0727 08:09:31.741266 81524 solver.cpp:236] Iteration 6990, loss = 0.944336
I0727 08:09:31.741449 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:09:31.741472 81524 solver.cpp:252]     Train net output #1: loss = 0.942823 (* 1 = 0.942823 loss)
I0727 08:09:36.205070 81524 sgd_solver.cpp:106] Iteration 6990, lr = 0.01
I0727 08:10:26.370487 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_7000.caffemodel
I0727 08:10:26.575196 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_7000.solverstate
I0727 08:10:26.578755 81524 solver.cpp:340] Iteration 7000, Testing net (#0)
I0727 08:12:25.653442 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 08:13:06.928871 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5535
I0727 08:13:06.929065 81524 solver.cpp:408]     Test net output #1: loss = 0.957161 (* 1 = 0.957161 loss)
I0727 08:13:07.940208 81524 solver.cpp:236] Iteration 7000, loss = 0.955215
I0727 08:13:07.940305 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:13:07.940336 81524 solver.cpp:252]     Train net output #1: loss = 1.08824 (* 1 = 1.08824 loss)
I0727 08:13:10.086412 81524 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0727 08:14:01.475097 81524 solver.cpp:236] Iteration 7010, loss = 0.955229
I0727 08:14:01.475301 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:14:01.475334 81524 solver.cpp:252]     Train net output #1: loss = 0.88583 (* 1 = 0.88583 loss)
I0727 08:14:05.399896 81524 sgd_solver.cpp:106] Iteration 7010, lr = 0.01
I0727 08:14:49.431357 81524 solver.cpp:236] Iteration 7020, loss = 0.938656
I0727 08:14:49.431651 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:14:49.431681 81524 solver.cpp:252]     Train net output #1: loss = 0.905057 (* 1 = 0.905057 loss)
I0727 08:14:53.588677 81524 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0727 08:15:40.551306 81524 solver.cpp:236] Iteration 7030, loss = 0.949559
I0727 08:15:40.551605 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:15:40.551646 81524 solver.cpp:252]     Train net output #1: loss = 0.911113 (* 1 = 0.911113 loss)
I0727 08:15:44.530458 81524 sgd_solver.cpp:106] Iteration 7030, lr = 0.01
I0727 08:16:30.448124 81524 solver.cpp:236] Iteration 7040, loss = 0.941458
I0727 08:16:30.448424 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:16:30.448448 81524 solver.cpp:252]     Train net output #1: loss = 1.02059 (* 1 = 1.02059 loss)
I0727 08:16:32.401223 81524 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0727 08:17:16.723776 81524 solver.cpp:236] Iteration 7050, loss = 0.942253
I0727 08:17:16.723965 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:17:16.723994 81524 solver.cpp:252]     Train net output #1: loss = 1.03205 (* 1 = 1.03205 loss)
I0727 08:17:21.631247 81524 sgd_solver.cpp:106] Iteration 7050, lr = 0.01
I0727 08:18:08.574174 81524 solver.cpp:236] Iteration 7060, loss = 0.937629
I0727 08:18:08.574393 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 08:18:08.574415 81524 solver.cpp:252]     Train net output #1: loss = 1.21258 (* 1 = 1.21258 loss)
I0727 08:18:13.335194 81524 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0727 08:19:00.746589 81524 solver.cpp:236] Iteration 7070, loss = 0.940716
I0727 08:19:00.746799 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:19:00.746842 81524 solver.cpp:252]     Train net output #1: loss = 1.0113 (* 1 = 1.0113 loss)
I0727 08:19:01.243080 81524 sgd_solver.cpp:106] Iteration 7070, lr = 0.01
I0727 08:19:51.251845 81524 solver.cpp:236] Iteration 7080, loss = 0.930271
I0727 08:19:51.252023 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:19:51.252070 81524 solver.cpp:252]     Train net output #1: loss = 1.19339 (* 1 = 1.19339 loss)
I0727 08:19:51.772708 81524 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0727 08:20:38.685930 81524 solver.cpp:236] Iteration 7090, loss = 0.941233
I0727 08:20:38.686159 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:20:38.686180 81524 solver.cpp:252]     Train net output #1: loss = 0.962157 (* 1 = 0.962157 loss)
I0727 08:20:43.799072 81524 sgd_solver.cpp:106] Iteration 7090, lr = 0.01
I0727 08:21:29.133190 81524 solver.cpp:340] Iteration 7100, Testing net (#0)
I0727 08:23:59.568593 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5455
I0727 08:23:59.568794 81524 solver.cpp:408]     Test net output #1: loss = 0.972802 (* 1 = 0.972802 loss)
I0727 08:24:00.522235 81524 solver.cpp:236] Iteration 7100, loss = 0.952282
I0727 08:24:00.522305 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:24:00.522328 81524 solver.cpp:252]     Train net output #1: loss = 1.03848 (* 1 = 1.03848 loss)
I0727 08:24:03.149405 81524 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0727 08:24:52.730118 81524 solver.cpp:236] Iteration 7110, loss = 0.956684
I0727 08:24:52.730300 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 08:24:52.730326 81524 solver.cpp:252]     Train net output #1: loss = 0.7386 (* 1 = 0.7386 loss)
I0727 08:24:55.012794 81524 sgd_solver.cpp:106] Iteration 7110, lr = 0.01
I0727 08:25:45.943621 81524 solver.cpp:236] Iteration 7120, loss = 0.967313
I0727 08:25:45.943799 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 08:25:45.943835 81524 solver.cpp:252]     Train net output #1: loss = 0.76771 (* 1 = 0.76771 loss)
I0727 08:25:49.881098 81524 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0727 08:26:38.376128 81524 solver.cpp:236] Iteration 7130, loss = 0.965738
I0727 08:26:38.376303 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 08:26:38.376348 81524 solver.cpp:252]     Train net output #1: loss = 0.940286 (* 1 = 0.940286 loss)
I0727 08:26:40.151478 81524 sgd_solver.cpp:106] Iteration 7130, lr = 0.01
I0727 08:27:28.270607 81524 solver.cpp:236] Iteration 7140, loss = 0.954165
I0727 08:27:28.270926 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:27:28.270949 81524 solver.cpp:252]     Train net output #1: loss = 1.13533 (* 1 = 1.13533 loss)
I0727 08:27:32.426584 81524 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0727 08:28:21.689668 81524 solver.cpp:236] Iteration 7150, loss = 0.950214
I0727 08:28:21.689901 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:28:21.689925 81524 solver.cpp:252]     Train net output #1: loss = 1.1114 (* 1 = 1.1114 loss)
I0727 08:28:25.972888 81524 sgd_solver.cpp:106] Iteration 7150, lr = 0.01
I0727 08:29:15.412935 81524 solver.cpp:236] Iteration 7160, loss = 0.949143
I0727 08:29:15.413130 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 08:29:15.413163 81524 solver.cpp:252]     Train net output #1: loss = 0.766164 (* 1 = 0.766164 loss)
I0727 08:29:20.172838 81524 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0727 08:30:12.154230 81524 solver.cpp:236] Iteration 7170, loss = 0.959831
I0727 08:30:12.154533 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 08:30:12.154558 81524 solver.cpp:252]     Train net output #1: loss = 0.995257 (* 1 = 0.995257 loss)
I0727 08:30:12.664719 81524 sgd_solver.cpp:106] Iteration 7170, lr = 0.01
I0727 08:31:01.713433 81524 solver.cpp:236] Iteration 7180, loss = 0.965714
I0727 08:31:01.713644 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 08:31:01.713667 81524 solver.cpp:252]     Train net output #1: loss = 0.838953 (* 1 = 0.838953 loss)
I0727 08:31:06.474673 81524 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0727 08:31:57.548702 81524 solver.cpp:236] Iteration 7190, loss = 0.973117
I0727 08:31:57.548990 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:31:57.549016 81524 solver.cpp:252]     Train net output #1: loss = 1.00249 (* 1 = 1.00249 loss)
I0727 08:31:58.172926 81524 sgd_solver.cpp:106] Iteration 7190, lr = 0.01
I0727 08:32:48.575294 81524 solver.cpp:340] Iteration 7200, Testing net (#0)
I0727 08:33:02.634603 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 08:35:24.862018 81524 solver.cpp:408]     Test net output #0: accuracy = 0.502
I0727 08:35:24.862226 81524 solver.cpp:408]     Test net output #1: loss = 1.02812 (* 1 = 1.02812 loss)
I0727 08:35:25.844990 81524 solver.cpp:236] Iteration 7200, loss = 0.969619
I0727 08:35:25.845059 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 08:35:25.845079 81524 solver.cpp:252]     Train net output #1: loss = 0.919577 (* 1 = 0.919577 loss)
I0727 08:35:28.472071 81524 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0727 08:36:19.094177 81524 solver.cpp:236] Iteration 7210, loss = 0.98017
I0727 08:36:19.094450 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 08:36:19.094487 81524 solver.cpp:252]     Train net output #1: loss = 1.08087 (* 1 = 1.08087 loss)
I0727 08:36:23.296780 81524 sgd_solver.cpp:106] Iteration 7210, lr = 0.01
I0727 08:37:13.942587 81524 solver.cpp:236] Iteration 7220, loss = 0.979485
I0727 08:37:13.942775 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:37:13.942807 81524 solver.cpp:252]     Train net output #1: loss = 1.07736 (* 1 = 1.07736 loss)
I0727 08:37:18.330262 81524 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0727 08:38:08.936280 81524 solver.cpp:236] Iteration 7230, loss = 0.968425
I0727 08:38:08.936480 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 08:38:08.936501 81524 solver.cpp:252]     Train net output #1: loss = 0.851367 (* 1 = 0.851367 loss)
I0727 08:38:14.509609 81524 sgd_solver.cpp:106] Iteration 7230, lr = 0.01
I0727 08:39:07.382184 81524 solver.cpp:236] Iteration 7240, loss = 0.964179
I0727 08:39:07.382369 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:39:07.382385 81524 solver.cpp:252]     Train net output #1: loss = 1.21202 (* 1 = 1.21202 loss)
I0727 08:39:11.804105 81524 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0727 08:40:06.724179 81524 solver.cpp:236] Iteration 7250, loss = 0.948705
I0727 08:40:06.724503 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:40:06.724550 81524 solver.cpp:252]     Train net output #1: loss = 1.01338 (* 1 = 1.01338 loss)
I0727 08:40:07.376924 81524 sgd_solver.cpp:106] Iteration 7250, lr = 0.01
I0727 08:41:01.119832 81524 solver.cpp:236] Iteration 7260, loss = 0.937637
I0727 08:41:01.120057 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 08:41:01.120084 81524 solver.cpp:252]     Train net output #1: loss = 0.793001 (* 1 = 0.793001 loss)
I0727 08:41:05.171453 81524 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0727 08:41:55.588450 81524 solver.cpp:236] Iteration 7270, loss = 0.942587
I0727 08:41:55.588680 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:41:55.588706 81524 solver.cpp:252]     Train net output #1: loss = 0.990884 (* 1 = 0.990884 loss)
I0727 08:42:00.301033 81524 sgd_solver.cpp:106] Iteration 7270, lr = 0.01
I0727 08:42:51.338320 81524 solver.cpp:236] Iteration 7280, loss = 0.945642
I0727 08:42:51.338544 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:42:51.338582 81524 solver.cpp:252]     Train net output #1: loss = 0.837309 (* 1 = 0.837309 loss)
I0727 08:42:56.882779 81524 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0727 08:43:48.916124 81524 solver.cpp:236] Iteration 7290, loss = 0.941335
I0727 08:43:48.916319 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 08:43:48.916352 81524 solver.cpp:252]     Train net output #1: loss = 1.05608 (* 1 = 1.05608 loss)
I0727 08:43:53.419348 81524 sgd_solver.cpp:106] Iteration 7290, lr = 0.01
I0727 08:44:45.478412 81524 solver.cpp:340] Iteration 7300, Testing net (#0)
I0727 08:47:28.940155 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5585
I0727 08:47:28.940459 81524 solver.cpp:408]     Test net output #1: loss = 0.970964 (* 1 = 0.970964 loss)
I0727 08:47:29.921890 81524 solver.cpp:236] Iteration 7300, loss = 0.944779
I0727 08:47:29.921954 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 08:47:29.921979 81524 solver.cpp:252]     Train net output #1: loss = 0.821666 (* 1 = 0.821666 loss)
I0727 08:47:31.914994 81524 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0727 08:48:27.053323 81524 solver.cpp:236] Iteration 7310, loss = 0.95455
I0727 08:48:27.053506 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 08:48:27.053540 81524 solver.cpp:252]     Train net output #1: loss = 0.96267 (* 1 = 0.96267 loss)
I0727 08:48:32.039361 81524 sgd_solver.cpp:106] Iteration 7310, lr = 0.01
I0727 08:49:25.457989 81524 solver.cpp:236] Iteration 7320, loss = 0.932007
I0727 08:49:25.458274 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:49:25.458307 81524 solver.cpp:252]     Train net output #1: loss = 0.970681 (* 1 = 0.970681 loss)
I0727 08:49:28.265350 81524 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0727 08:50:28.220808 81524 solver.cpp:236] Iteration 7330, loss = 0.932406
I0727 08:50:28.221024 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 08:50:28.221055 81524 solver.cpp:252]     Train net output #1: loss = 0.78935 (* 1 = 0.78935 loss)
I0727 08:50:32.932586 81524 sgd_solver.cpp:106] Iteration 7330, lr = 0.01
I0727 08:51:24.274669 81524 solver.cpp:236] Iteration 7340, loss = 0.944746
I0727 08:51:24.274919 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:51:24.274950 81524 solver.cpp:252]     Train net output #1: loss = 0.947613 (* 1 = 0.947613 loss)
I0727 08:51:28.599689 81524 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0727 08:51:58.384551 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 08:52:14.718297 81524 solver.cpp:236] Iteration 7350, loss = 0.95044
I0727 08:52:14.718384 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:52:14.718402 81524 solver.cpp:252]     Train net output #1: loss = 0.887871 (* 1 = 0.887871 loss)
I0727 08:52:18.460706 81524 sgd_solver.cpp:106] Iteration 7350, lr = 0.01
I0727 08:53:05.648536 81524 solver.cpp:236] Iteration 7360, loss = 0.931154
I0727 08:53:05.648875 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 08:53:05.648910 81524 solver.cpp:252]     Train net output #1: loss = 0.598715 (* 1 = 0.598715 loss)
I0727 08:53:10.099123 81524 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0727 08:53:57.255448 81524 solver.cpp:236] Iteration 7370, loss = 0.928959
I0727 08:53:57.255688 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 08:53:57.255720 81524 solver.cpp:252]     Train net output #1: loss = 1.11817 (* 1 = 1.11817 loss)
I0727 08:54:01.441946 81524 sgd_solver.cpp:106] Iteration 7370, lr = 0.01
I0727 08:54:49.701596 81524 solver.cpp:236] Iteration 7380, loss = 0.925628
I0727 08:54:49.701793 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 08:54:49.701817 81524 solver.cpp:252]     Train net output #1: loss = 0.723457 (* 1 = 0.723457 loss)
I0727 08:54:54.268451 81524 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0727 08:55:47.599315 81524 solver.cpp:236] Iteration 7390, loss = 0.908985
I0727 08:55:47.599534 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 08:55:47.599556 81524 solver.cpp:252]     Train net output #1: loss = 0.760073 (* 1 = 0.760073 loss)
I0727 08:55:48.388639 81524 sgd_solver.cpp:106] Iteration 7390, lr = 0.01
I0727 08:56:34.775434 81524 solver.cpp:340] Iteration 7400, Testing net (#0)
I0727 08:59:25.718874 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5215
I0727 08:59:25.719182 81524 solver.cpp:408]     Test net output #1: loss = 1.00811 (* 1 = 1.00811 loss)
I0727 08:59:26.677603 81524 solver.cpp:236] Iteration 7400, loss = 0.898763
I0727 08:59:26.677667 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 08:59:26.677690 81524 solver.cpp:252]     Train net output #1: loss = 0.987259 (* 1 = 0.987259 loss)
I0727 08:59:27.982411 81524 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0727 09:00:26.350040 81524 solver.cpp:236] Iteration 7410, loss = 0.905613
I0727 09:00:26.350275 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:00:26.350296 81524 solver.cpp:252]     Train net output #1: loss = 0.900296 (* 1 = 0.900296 loss)
I0727 09:00:27.084373 81524 sgd_solver.cpp:106] Iteration 7410, lr = 0.01
I0727 09:01:23.923410 81524 solver.cpp:236] Iteration 7420, loss = 0.91326
I0727 09:01:23.926738 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:01:23.926782 81524 solver.cpp:252]     Train net output #1: loss = 0.998713 (* 1 = 0.998713 loss)
I0727 09:01:24.849766 81524 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0727 09:02:19.119580 81524 solver.cpp:236] Iteration 7430, loss = 0.919562
I0727 09:02:19.119715 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 09:02:19.119740 81524 solver.cpp:252]     Train net output #1: loss = 0.785334 (* 1 = 0.785334 loss)
I0727 09:02:23.193202 81524 sgd_solver.cpp:106] Iteration 7430, lr = 0.01
I0727 09:03:17.305907 81524 solver.cpp:236] Iteration 7440, loss = 0.945337
I0727 09:03:17.306107 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:03:17.306146 81524 solver.cpp:252]     Train net output #1: loss = 0.999431 (* 1 = 0.999431 loss)
I0727 09:03:21.169423 81524 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0727 09:04:19.825294 81524 solver.cpp:236] Iteration 7450, loss = 0.967936
I0727 09:04:19.825999 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 09:04:19.826030 81524 solver.cpp:252]     Train net output #1: loss = 1.2027 (* 1 = 1.2027 loss)
I0727 09:04:23.594086 81524 sgd_solver.cpp:106] Iteration 7450, lr = 0.01
I0727 09:05:24.228407 81524 solver.cpp:236] Iteration 7460, loss = 0.960686
I0727 09:05:24.228620 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:05:24.228670 81524 solver.cpp:252]     Train net output #1: loss = 0.917852 (* 1 = 0.917852 loss)
I0727 09:05:25.595921 81524 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0727 09:06:30.807935 81524 solver.cpp:236] Iteration 7470, loss = 0.975865
I0727 09:06:30.808254 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:06:30.808305 81524 solver.cpp:252]     Train net output #1: loss = 0.923565 (* 1 = 0.923565 loss)
I0727 09:06:31.899307 81524 sgd_solver.cpp:106] Iteration 7470, lr = 0.01
I0727 09:07:26.868978 81524 solver.cpp:236] Iteration 7480, loss = 0.981756
I0727 09:07:26.869134 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:07:26.869169 81524 solver.cpp:252]     Train net output #1: loss = 0.951316 (* 1 = 0.951316 loss)
I0727 09:07:31.988723 81524 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0727 09:08:23.046627 81524 solver.cpp:236] Iteration 7490, loss = 0.984648
I0727 09:08:23.047042 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 09:08:23.047067 81524 solver.cpp:252]     Train net output #1: loss = 1.02465 (* 1 = 1.02465 loss)
I0727 09:08:27.136603 81524 sgd_solver.cpp:106] Iteration 7490, lr = 0.01
I0727 09:09:18.279958 81524 solver.cpp:340] Iteration 7500, Testing net (#0)
I0727 09:11:47.003741 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 09:12:23.279381 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5335
I0727 09:12:23.279664 81524 solver.cpp:408]     Test net output #1: loss = 0.975943 (* 1 = 0.975943 loss)
I0727 09:12:24.322207 81524 solver.cpp:236] Iteration 7500, loss = 0.965355
I0727 09:12:24.322268 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:12:24.322288 81524 solver.cpp:252]     Train net output #1: loss = 0.928694 (* 1 = 0.928694 loss)
I0727 09:12:26.415551 81524 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0727 09:13:21.463078 81524 solver.cpp:236] Iteration 7510, loss = 0.981881
I0727 09:13:21.463302 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:13:21.463336 81524 solver.cpp:252]     Train net output #1: loss = 1.02593 (* 1 = 1.02593 loss)
I0727 09:13:22.051312 81524 sgd_solver.cpp:106] Iteration 7510, lr = 0.01
I0727 09:14:16.164378 81524 solver.cpp:236] Iteration 7520, loss = 0.982738
I0727 09:14:16.164681 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 09:14:16.164722 81524 solver.cpp:252]     Train net output #1: loss = 1.13207 (* 1 = 1.13207 loss)
I0727 09:14:20.193996 81524 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0727 09:15:14.429364 81524 solver.cpp:236] Iteration 7530, loss = 0.984793
I0727 09:15:14.429546 81524 solver.cpp:252]     Train net output #0: accuracy = 0.375
I0727 09:15:14.429597 81524 solver.cpp:252]     Train net output #1: loss = 1.05959 (* 1 = 1.05959 loss)
I0727 09:15:19.125036 81524 sgd_solver.cpp:106] Iteration 7530, lr = 0.01
I0727 09:16:13.732066 81524 solver.cpp:236] Iteration 7540, loss = 0.949607
I0727 09:16:13.732250 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 09:16:13.732301 81524 solver.cpp:252]     Train net output #1: loss = 0.71027 (* 1 = 0.71027 loss)
I0727 09:16:18.005623 81524 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0727 09:17:09.683238 81524 solver.cpp:236] Iteration 7550, loss = 0.960128
I0727 09:17:09.683419 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 09:17:09.683451 81524 solver.cpp:252]     Train net output #1: loss = 1.14868 (* 1 = 1.14868 loss)
I0727 09:17:14.353754 81524 sgd_solver.cpp:106] Iteration 7550, lr = 0.01
I0727 09:18:05.907714 81524 solver.cpp:236] Iteration 7560, loss = 0.941938
I0727 09:18:05.907896 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:18:05.907930 81524 solver.cpp:252]     Train net output #1: loss = 0.990284 (* 1 = 0.990284 loss)
I0727 09:18:09.736297 81524 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0727 09:19:00.629262 81524 solver.cpp:236] Iteration 7570, loss = 0.937602
I0727 09:19:00.629451 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:19:00.629483 81524 solver.cpp:252]     Train net output #1: loss = 1.00975 (* 1 = 1.00975 loss)
I0727 09:19:05.208705 81524 sgd_solver.cpp:106] Iteration 7570, lr = 0.01
I0727 09:19:56.727551 81524 solver.cpp:236] Iteration 7580, loss = 0.943543
I0727 09:19:56.727838 81524 solver.cpp:252]     Train net output #0: accuracy = 0.1875
I0727 09:19:56.727865 81524 solver.cpp:252]     Train net output #1: loss = 1.44198 (* 1 = 1.44198 loss)
I0727 09:20:01.837939 81524 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0727 09:20:55.020045 81524 solver.cpp:236] Iteration 7590, loss = 0.962583
I0727 09:20:55.020308 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:20:55.020339 81524 solver.cpp:252]     Train net output #1: loss = 0.873348 (* 1 = 0.873348 loss)
I0727 09:20:55.578649 81524 sgd_solver.cpp:106] Iteration 7590, lr = 0.01
I0727 09:21:46.076362 81524 solver.cpp:340] Iteration 7600, Testing net (#0)
I0727 09:24:47.385923 81524 solver.cpp:408]     Test net output #0: accuracy = 0.535
I0727 09:24:47.386078 81524 solver.cpp:408]     Test net output #1: loss = 0.975666 (* 1 = 0.975666 loss)
I0727 09:24:49.297340 81524 solver.cpp:236] Iteration 7600, loss = 0.955719
I0727 09:24:49.297408 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:24:49.297436 81524 solver.cpp:252]     Train net output #1: loss = 0.892595 (* 1 = 0.892595 loss)
I0727 09:24:52.198412 81524 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0727 09:25:41.857364 81524 solver.cpp:236] Iteration 7610, loss = 0.968006
I0727 09:25:41.857666 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:25:41.857692 81524 solver.cpp:252]     Train net output #1: loss = 0.927246 (* 1 = 0.927246 loss)
I0727 09:25:46.553316 81524 sgd_solver.cpp:106] Iteration 7610, lr = 0.01
I0727 09:26:39.815769 81524 solver.cpp:236] Iteration 7620, loss = 0.957227
I0727 09:26:39.815987 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 09:26:39.816011 81524 solver.cpp:252]     Train net output #1: loss = 0.981444 (* 1 = 0.981444 loss)
I0727 09:26:45.133913 81524 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0727 09:27:37.113086 81524 solver.cpp:236] Iteration 7630, loss = 0.950946
I0727 09:27:37.113282 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 09:27:37.113329 81524 solver.cpp:252]     Train net output #1: loss = 0.999026 (* 1 = 0.999026 loss)
I0727 09:27:41.697757 81524 sgd_solver.cpp:106] Iteration 7630, lr = 0.01
I0727 09:28:34.056108 81524 solver.cpp:236] Iteration 7640, loss = 0.946606
I0727 09:28:34.056432 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 09:28:34.056476 81524 solver.cpp:252]     Train net output #1: loss = 0.879986 (* 1 = 0.879986 loss)
I0727 09:28:39.138676 81524 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0727 09:29:47.095924 81524 solver.cpp:236] Iteration 7650, loss = 0.946958
I0727 09:29:47.096076 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 09:29:47.096122 81524 solver.cpp:252]     Train net output #1: loss = 1.03299 (* 1 = 1.03299 loss)
I0727 09:29:51.313311 81524 sgd_solver.cpp:106] Iteration 7650, lr = 0.01
I0727 09:31:25.497062 81524 solver.cpp:236] Iteration 7660, loss = 0.949815
I0727 09:31:25.497251 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 09:31:25.497275 81524 solver.cpp:252]     Train net output #1: loss = 0.815207 (* 1 = 0.815207 loss)
I0727 09:31:30.390463 81524 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0727 09:32:53.277456 81524 solver.cpp:236] Iteration 7670, loss = 0.96319
I0727 09:32:53.277672 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:32:53.277701 81524 solver.cpp:252]     Train net output #1: loss = 0.946983 (* 1 = 0.946983 loss)
I0727 09:32:57.890602 81524 sgd_solver.cpp:106] Iteration 7670, lr = 0.01
I0727 09:34:21.953686 81524 solver.cpp:236] Iteration 7680, loss = 0.956191
I0727 09:34:21.953851 81524 solver.cpp:252]     Train net output #0: accuracy = 0.3125
I0727 09:34:21.953896 81524 solver.cpp:252]     Train net output #1: loss = 1.08891 (* 1 = 1.08891 loss)
I0727 09:34:26.237172 81524 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0727 09:35:43.319159 81524 solver.cpp:236] Iteration 7690, loss = 0.959656
I0727 09:35:43.319404 81524 solver.cpp:252]     Train net output #0: accuracy = 0.25
I0727 09:35:43.319425 81524 solver.cpp:252]     Train net output #1: loss = 1.15351 (* 1 = 1.15351 loss)
I0727 09:35:48.548441 81524 sgd_solver.cpp:106] Iteration 7690, lr = 0.01
I0727 09:36:15.735522 81524 blocking_queue.cpp:50] Data layer prefetch queue empty
I0727 09:36:43.619532 81524 solver.cpp:340] Iteration 7700, Testing net (#0)
I0727 09:39:59.613306 81524 solver.cpp:408]     Test net output #0: accuracy = 0.5535
I0727 09:39:59.613626 81524 solver.cpp:408]     Test net output #1: loss = 0.960952 (* 1 = 0.960952 loss)
I0727 09:40:00.608605 81524 solver.cpp:236] Iteration 7700, loss = 0.958698
I0727 09:40:00.608664 81524 solver.cpp:252]     Train net output #0: accuracy = 0.75
I0727 09:40:00.608682 81524 solver.cpp:252]     Train net output #1: loss = 0.927507 (* 1 = 0.927507 loss)
I0727 09:40:02.197779 81524 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0727 09:40:54.388865 81524 solver.cpp:236] Iteration 7710, loss = 0.960306
I0727 09:40:54.389062 81524 solver.cpp:252]     Train net output #0: accuracy = 0.4375
I0727 09:40:54.389083 81524 solver.cpp:252]     Train net output #1: loss = 1.0779 (* 1 = 1.0779 loss)
I0727 09:40:58.638696 81524 sgd_solver.cpp:106] Iteration 7710, lr = 0.01
I0727 09:41:47.910326 81524 solver.cpp:236] Iteration 7720, loss = 0.95198
I0727 09:41:47.910542 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:41:47.910570 81524 solver.cpp:252]     Train net output #1: loss = 0.940575 (* 1 = 0.940575 loss)
I0727 09:41:52.340821 81524 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0727 09:42:45.256284 81524 solver.cpp:236] Iteration 7730, loss = 0.959438
I0727 09:42:45.256477 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:42:45.256500 81524 solver.cpp:252]     Train net output #1: loss = 0.963196 (* 1 = 0.963196 loss)
I0727 09:42:46.035987 81524 sgd_solver.cpp:106] Iteration 7730, lr = 0.01
I0727 09:43:41.478193 81524 solver.cpp:236] Iteration 7740, loss = 0.964102
I0727 09:43:41.478415 81524 solver.cpp:252]     Train net output #0: accuracy = 0.6875
I0727 09:43:41.478440 81524 solver.cpp:252]     Train net output #1: loss = 0.978321 (* 1 = 0.978321 loss)
I0727 09:43:42.135283 81524 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0727 09:44:30.882963 81524 solver.cpp:236] Iteration 7750, loss = 0.957831
I0727 09:44:30.883157 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:44:30.883203 81524 solver.cpp:252]     Train net output #1: loss = 0.93107 (* 1 = 0.93107 loss)
I0727 09:44:35.391582 81524 sgd_solver.cpp:106] Iteration 7750, lr = 0.01
I0727 09:45:27.098278 81524 solver.cpp:236] Iteration 7760, loss = 0.945124
I0727 09:45:27.098474 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:45:27.098503 81524 solver.cpp:252]     Train net output #1: loss = 0.976488 (* 1 = 0.976488 loss)
I0727 09:45:32.109745 81524 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0727 09:46:22.424218 81524 solver.cpp:236] Iteration 7770, loss = 0.94764
I0727 09:46:22.424471 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:46:22.424501 81524 solver.cpp:252]     Train net output #1: loss = 0.982854 (* 1 = 0.982854 loss)
I0727 09:46:23.228859 81524 sgd_solver.cpp:106] Iteration 7770, lr = 0.01
I0727 09:47:14.177330 81524 solver.cpp:236] Iteration 7780, loss = 0.947163
I0727 09:47:14.177528 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:47:14.177564 81524 solver.cpp:252]     Train net output #1: loss = 1.00816 (* 1 = 1.00816 loss)
I0727 09:47:18.174468 81524 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0727 09:48:13.738030 81524 solver.cpp:236] Iteration 7790, loss = 0.942739
I0727 09:48:13.738215 81524 solver.cpp:252]     Train net output #0: accuracy = 0.625
I0727 09:48:13.738247 81524 solver.cpp:252]     Train net output #1: loss = 0.841272 (* 1 = 0.841272 loss)
I0727 09:48:14.546563 81524 sgd_solver.cpp:106] Iteration 7790, lr = 0.01
I0727 09:49:05.120748 81524 solver.cpp:340] Iteration 7800, Testing net (#0)
I0727 09:52:30.580960 81524 solver.cpp:408]     Test net output #0: accuracy = 0.557
I0727 09:52:30.581125 81524 solver.cpp:408]     Test net output #1: loss = 0.961408 (* 1 = 0.961408 loss)
I0727 09:52:32.552008 81524 solver.cpp:236] Iteration 7800, loss = 0.94889
I0727 09:52:32.552079 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5
I0727 09:52:32.552103 81524 solver.cpp:252]     Train net output #1: loss = 1.02963 (* 1 = 1.02963 loss)
I0727 09:52:33.473402 81524 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0727 09:53:32.003273 81524 solver.cpp:236] Iteration 7810, loss = 0.960303
I0727 09:53:32.003476 81524 solver.cpp:252]     Train net output #0: accuracy = 0.5625
I0727 09:53:32.003500 81524 solver.cpp:252]     Train net output #1: loss = 0.961629 (* 1 = 0.961629 loss)
I0727 09:53:37.643628 81524 sgd_solver.cpp:106] Iteration 7810, lr = 0.01
I0727 09:53:59.475632 81524 solver.cpp:461] Snapshotting to binary proto file models-resultlayer/_iter_7814.caffemodel
I0727 09:53:59.952924 81524 sgd_solver.cpp:269] Snapshotting solver state to binary proto file models-resultlayer/_iter_7814.solverstate
I0727 09:53:59.956308 81524 solver.cpp:308] Optimization stopped early.
I0727 09:54:01.139192 81524 caffe.cpp:215] Optimization Done.
