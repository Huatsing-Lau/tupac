Log file created at: 2016/09/05 01:39:05
Running on machine: deepath-01
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0905 01:39:05.116587 90901 caffe.cpp:217] Using GPUs 3
I0905 01:39:05.137466 90901 caffe.cpp:222] GPU 3: Tesla K80
I0905 01:39:05.425410 90901 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 800
base_lr: 0.1
display: 10
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
device_id: 3
net: "train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 50000
stepvalue: 75000
type: "Nesterov"
I0905 01:39:05.425546 90901 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0905 01:39:05.429000 90901 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0905 01:39:05.429177 90901 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0905 01:39:05.430105 90901 net.cpp:58] Initializing net from parameters: 
name: "DenseNN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 150
    mean_value: 150
    mean_value: 150
  }
  image_data_param {
    source: "../list_bias-1_tr.lst"
    batch_size: 16
    shuffle: true
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout1"
  type: "Dropout"
  bottom: "Convolution1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Dropout1"
  top: "BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "Convolution2"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout2"
  type: "Dropout"
  bottom: "Convolution2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Dropout1"
  bottom: "Dropout2"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Concat1"
  top: "BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "Convolution3"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout3"
  type: "Dropout"
  bottom: "Convolution3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Concat1"
  bottom: "Dropout3"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Concat2"
  top: "BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "BatchNorm3"
  top: "Convolution4"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout4"
  type: "Dropout"
  bottom: "Convolution4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Concat2"
  bottom: "Dropout4"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Concat3"
  top: "BatchNorm4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "BatchNorm4"
  top: "BatchNorm4"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "BatchNorm4"
  top: "BatchNorm4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "BatchNorm4"
  top: "Convolution5"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout5"
  type: "Dropout"
  bottom: "Convolution5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "Concat3"
  bottom: "Dropout5"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Concat4"
  top: "BatchNorm5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "BatchNorm5"
  top: "BatchNorm5"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "BatchNorm5"
  top: "BatchNorm5"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "BatchNorm5"
  top: "Convolution6"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout6"
  type: "Dropout"
  bottom: "Convolution6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "Concat4"
  bottom: "Dropout6"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Concat5"
  top: "BatchNorm6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "BatchNorm6"
  top: "BatchNorm6"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "BatchNorm6"
  top: "BatchNorm6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "BatchNorm6"
  top: "Convolution7"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout7"
  type: "Dropout"
  bottom: "Convolution7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "Concat5"
  bottom: "Dropout7"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Concat6"
  top: "BatchNorm7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "BatchNorm7"
  top: "BatchNorm7"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "BatchNorm7"
  top: "BatchNorm7"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "BatchNorm7"
  top: "Convolution8"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout8"
  type: "Dropout"
  bottom: "Convolution8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "Concat6"
  bottom: "Dropout8"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Concat7"
  top: "BatchNorm8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "BatchNorm8"
  top: "BatchNorm8"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "BatchNorm8"
  top: "BatchNorm8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "BatchNorm8"
  top: "Convolution9"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout9"
  type: "Dropout"
  bottom: "Convolution9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "Concat7"
  bottom: "Dropout9"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Concat8"
  top: "BatchNorm9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "BatchNorm9"
  top: "BatchNorm9"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "BatchNorm9"
  top: "BatchNorm9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "BatchNorm9"
  top: "Convolution10"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout10"
  type: "Dropout"
  bottom: "Convolution10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "Concat8"
  bottom: "Dropout10"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Concat9"
  top: "BatchNorm10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "BatchNorm10"
  top: "BatchNorm10"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "BatchNorm10"
  top: "BatchNorm10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "BatchNorm10"
  top: "Convolution11"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout11"
  type: "Dropout"
  bottom: "Convolution11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "Concat9"
  bottom: "Dropout11"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Concat10"
  top: "BatchNorm11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "BatchNorm11"
  top: "BatchNorm11"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "BatchNorm11"
  top: "BatchNorm11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "BatchNorm11"
  top: "Convolution12"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout12"
  type: "Dropout"
  bottom: "Convolution12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "Concat10"
  bottom: "Dropout12"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Concat11"
  top: "BatchNorm12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "BatchNorm12"
  top: "Convolution13"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout13"
  type: "Dropout"
  bottom: "Convolution13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "Concat11"
  bottom: "Dropout13"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Concat12"
  top: "BatchNorm13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "BatchNorm13"
  top: "BatchNorm13"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "BatchNorm13"
  top: "BatchNorm13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "BatchNorm13"
  top: "Convolution14"
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout14"
  type: "Dropout"
  bottom: "Convolution14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Dropout14"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Pooling1"
  top: "BatchNorm14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "BatchNorm14"
  top: "BatchNorm14"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "BatchNorm14"
  top: "BatchNorm14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "BatchNorm14"
  top: "Convolution15"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout15"
  type: "Dropout"
  bottom: "Convolution15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Dropout15"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Concat13"
  top: "BatchNorm15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "BatchNorm15"
  top: "BatchNorm15"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "BatchNorm15"
  top: "BatchNorm15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "BatchNorm15"
  top: "Convolution16"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout16"
  type: "Dropout"
  bottom: "Convolution16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "Concat13"
  bottom: "Dropout16"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Concat14"
  top: "BatchNorm16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "BatchNorm16"
  top: "BatchNorm16"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "BatchNorm16"
  top: "BatchNorm16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "BatchNorm16"
  top: "Convolution17"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout17"
  type: "Dropout"
  bottom: "Convolution17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "Concat14"
  bottom: "Dropout17"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Concat15"
  top: "BatchNorm17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "BatchNorm17"
  top: "BatchNorm17"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "BatchNorm17"
  top: "BatchNorm17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "BatchNorm17"
  top: "Convolution18"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout18"
  type: "Dropout"
  bottom: "Convolution18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "Concat15"
  bottom: "Dropout18"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Concat16"
  top: "BatchNorm18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "BatchNorm18"
  top: "BatchNorm18"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "BatchNorm18"
  top: "BatchNorm18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "BatchNorm18"
  top: "Convolution19"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout19"
  type: "Dropout"
  bottom: "Convolution19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "Concat16"
  bottom: "Dropout19"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Concat17"
  top: "BatchNorm19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "BatchNorm19"
  top: "BatchNorm19"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "BatchNorm19"
  top: "BatchNorm19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "BatchNorm19"
  top: "Convolution20"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout20"
  type: "Dropout"
  bottom: "Convolution20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "Concat17"
  bottom: "Dropout20"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Concat18"
  top: "BatchNorm20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "BatchNorm20"
  top: "BatchNorm20"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "BatchNorm20"
  top: "BatchNorm20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "BatchNorm20"
  top: "Convolution21"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout21"
  type: "Dropout"
  bottom: "Convolution21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "Concat18"
  bottom: "Dropout21"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Concat19"
  top: "BatchNorm21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "BatchNorm21"
  top: "BatchNorm21"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "BatchNorm21"
  top: "BatchNorm21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "BatchNorm21"
  top: "Convolution22"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout22"
  type: "Dropout"
  bottom: "Convolution22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat20"
  type: "Concat"
  bottom: "Concat19"
  bottom: "Dropout22"
  top: "Concat20"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Concat20"
  top: "BatchNorm22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "BatchNorm22"
  top: "BatchNorm22"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "BatchNorm22"
  top: "BatchNorm22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "BatchNorm22"
  top: "Convolution23"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout23"
  type: "Dropout"
  bottom: "Convolution23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat21"
  type: "Concat"
  bottom: "Concat20"
  bottom: "Dropout23"
  top: "Concat21"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Concat21"
  top: "BatchNorm23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "BatchNorm23"
  top: "BatchNorm23"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "BatchNorm23"
  top: "BatchNorm23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "BatchNorm23"
  top: "Convolution24"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout24"
  type: "Dropout"
  bottom: "Convolution24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat22"
  type: "Concat"
  bottom: "Concat21"
  bottom: "Dropout24"
  top: "Concat22"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Concat22"
  top: "BatchNorm24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "BatchNorm24"
  top: "BatchNorm24"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "BatchNorm24"
  top: "BatchNorm24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "BatchNorm24"
  top: "Convolution25"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout25"
  type: "Dropout"
  bottom: "Convolution25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat23"
  type: "Concat"
  bottom: "Concat22"
  bottom: "Dropout25"
  top: "Concat23"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Concat23"
  top: "BatchNorm25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "BatchNorm25"
  top: "Convolution26"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout26"
  type: "Dropout"
  bottom: "Convolution26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat24"
  type: "Concat"
  bottom: "Concat23"
  bottom: "Dropout26"
  top: "Concat24"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Concat24"
  top: "BatchNorm26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "BatchNorm26"
  top: "BatchNorm26"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "BatchNorm26"
  top: "BatchNorm26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "BatchNorm26"
  top: "Convolution27"
  convolution_param {
    num_output: 304
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout27"
  type: "Dropout"
  bottom: "Convolution27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Dropout27"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Pooling2"
  top: "BatchNorm27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "BatchNorm27"
  top: "BatchNorm27"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU27"
  type
I0905 01:39:05.435802 90901 layer_factory.hpp:77] Creating layer Data1
I0905 01:39:05.435850 90901 net.cpp:100] Creating Layer Data1
I0905 01:39:05.435863 90901 net.cpp:408] Data1 -> Data1
I0905 01:39:05.435896 90901 net.cpp:408] Data1 -> Data2
I0905 01:39:05.436303 90901 image_data_layer.cpp:38] Opening file ../list_bias-1_tr.lst
I0905 01:39:05.992410 90901 image_data_layer.cpp:53] Shuffling data
I0905 01:39:06.187783 90901 image_data_layer.cpp:58] A total of 1056600 images.
I0905 01:39:06.198362 90901 image_data_layer.cpp:85] output data size: 16,3,64,64
I0905 01:39:06.201557 90901 net.cpp:150] Setting up Data1
I0905 01:39:06.201678 90901 net.cpp:157] Top shape: 16 3 64 64 (196608)
I0905 01:39:06.201719 90901 net.cpp:157] Top shape: 16 (16)
I0905 01:39:06.201730 90901 net.cpp:165] Memory required for data: 786496
I0905 01:39:06.201743 90901 layer_factory.hpp:77] Creating layer Convolution1
I0905 01:39:06.201793 90901 net.cpp:100] Creating Layer Convolution1
I0905 01:39:06.201820 90901 net.cpp:434] Convolution1 <- Data1
I0905 01:39:06.201841 90901 net.cpp:408] Convolution1 -> Convolution1
I0905 01:39:06.399050 90901 net.cpp:150] Setting up Convolution1
I0905 01:39:06.399124 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.399135 90901 net.cpp:165] Memory required for data: 4980800
I0905 01:39:06.399163 90901 layer_factory.hpp:77] Creating layer Dropout1
I0905 01:39:06.399183 90901 net.cpp:100] Creating Layer Dropout1
I0905 01:39:06.399194 90901 net.cpp:434] Dropout1 <- Convolution1
I0905 01:39:06.399221 90901 net.cpp:408] Dropout1 -> Dropout1
I0905 01:39:06.399296 90901 net.cpp:150] Setting up Dropout1
I0905 01:39:06.399312 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.399322 90901 net.cpp:165] Memory required for data: 9175104
I0905 01:39:06.399333 90901 layer_factory.hpp:77] Creating layer Dropout1_Dropout1_0_split
I0905 01:39:06.399379 90901 net.cpp:100] Creating Layer Dropout1_Dropout1_0_split
I0905 01:39:06.399389 90901 net.cpp:434] Dropout1_Dropout1_0_split <- Dropout1
I0905 01:39:06.399446 90901 net.cpp:408] Dropout1_Dropout1_0_split -> Dropout1_Dropout1_0_split_0
I0905 01:39:06.399477 90901 net.cpp:408] Dropout1_Dropout1_0_split -> Dropout1_Dropout1_0_split_1
I0905 01:39:06.399564 90901 net.cpp:150] Setting up Dropout1_Dropout1_0_split
I0905 01:39:06.399590 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.399600 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.399619 90901 net.cpp:165] Memory required for data: 17563712
I0905 01:39:06.399628 90901 layer_factory.hpp:77] Creating layer BatchNorm1
I0905 01:39:06.399655 90901 net.cpp:100] Creating Layer BatchNorm1
I0905 01:39:06.399668 90901 net.cpp:434] BatchNorm1 <- Dropout1_Dropout1_0_split_0
I0905 01:39:06.399679 90901 net.cpp:408] BatchNorm1 -> BatchNorm1
I0905 01:39:06.399879 90901 net.cpp:150] Setting up BatchNorm1
I0905 01:39:06.399894 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.399902 90901 net.cpp:165] Memory required for data: 21758016
I0905 01:39:06.399919 90901 layer_factory.hpp:77] Creating layer Scale1
I0905 01:39:06.399940 90901 net.cpp:100] Creating Layer Scale1
I0905 01:39:06.399948 90901 net.cpp:434] Scale1 <- BatchNorm1
I0905 01:39:06.399961 90901 net.cpp:395] Scale1 -> BatchNorm1 (in-place)
I0905 01:39:06.400060 90901 net.cpp:150] Setting up Scale1
I0905 01:39:06.400075 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.400084 90901 net.cpp:165] Memory required for data: 25952320
I0905 01:39:06.400094 90901 layer_factory.hpp:77] Creating layer ReLU1
I0905 01:39:06.400112 90901 net.cpp:100] Creating Layer ReLU1
I0905 01:39:06.400121 90901 net.cpp:434] ReLU1 <- BatchNorm1
I0905 01:39:06.400140 90901 net.cpp:395] ReLU1 -> BatchNorm1 (in-place)
I0905 01:39:06.400332 90901 net.cpp:150] Setting up ReLU1
I0905 01:39:06.400360 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.400368 90901 net.cpp:165] Memory required for data: 30146624
I0905 01:39:06.400378 90901 layer_factory.hpp:77] Creating layer Convolution2
I0905 01:39:06.400400 90901 net.cpp:100] Creating Layer Convolution2
I0905 01:39:06.400413 90901 net.cpp:434] Convolution2 <- BatchNorm1
I0905 01:39:06.400424 90901 net.cpp:408] Convolution2 -> Convolution2
I0905 01:39:06.401805 90901 net.cpp:150] Setting up Convolution2
I0905 01:39:06.401836 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.401846 90901 net.cpp:165] Memory required for data: 33292352
I0905 01:39:06.401859 90901 layer_factory.hpp:77] Creating layer Dropout2
I0905 01:39:06.401873 90901 net.cpp:100] Creating Layer Dropout2
I0905 01:39:06.401882 90901 net.cpp:434] Dropout2 <- Convolution2
I0905 01:39:06.401896 90901 net.cpp:408] Dropout2 -> Dropout2
I0905 01:39:06.401945 90901 net.cpp:150] Setting up Dropout2
I0905 01:39:06.401962 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.401971 90901 net.cpp:165] Memory required for data: 36438080
I0905 01:39:06.401980 90901 layer_factory.hpp:77] Creating layer Concat1
I0905 01:39:06.402004 90901 net.cpp:100] Creating Layer Concat1
I0905 01:39:06.402014 90901 net.cpp:434] Concat1 <- Dropout1_Dropout1_0_split_1
I0905 01:39:06.402027 90901 net.cpp:434] Concat1 <- Dropout2
I0905 01:39:06.402050 90901 net.cpp:408] Concat1 -> Concat1
I0905 01:39:06.402082 90901 net.cpp:150] Setting up Concat1
I0905 01:39:06.402096 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.402107 90901 net.cpp:165] Memory required for data: 43778112
I0905 01:39:06.402122 90901 layer_factory.hpp:77] Creating layer Concat1_Concat1_0_split
I0905 01:39:06.402137 90901 net.cpp:100] Creating Layer Concat1_Concat1_0_split
I0905 01:39:06.402146 90901 net.cpp:434] Concat1_Concat1_0_split <- Concat1
I0905 01:39:06.402164 90901 net.cpp:408] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_0
I0905 01:39:06.402178 90901 net.cpp:408] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_1
I0905 01:39:06.402225 90901 net.cpp:150] Setting up Concat1_Concat1_0_split
I0905 01:39:06.402237 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.402261 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.402272 90901 net.cpp:165] Memory required for data: 58458176
I0905 01:39:06.402279 90901 layer_factory.hpp:77] Creating layer BatchNorm2
I0905 01:39:06.402290 90901 net.cpp:100] Creating Layer BatchNorm2
I0905 01:39:06.402298 90901 net.cpp:434] BatchNorm2 <- Concat1_Concat1_0_split_0
I0905 01:39:06.402309 90901 net.cpp:408] BatchNorm2 -> BatchNorm2
I0905 01:39:06.402477 90901 net.cpp:150] Setting up BatchNorm2
I0905 01:39:06.402490 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.402498 90901 net.cpp:165] Memory required for data: 65798208
I0905 01:39:06.402516 90901 layer_factory.hpp:77] Creating layer Scale2
I0905 01:39:06.402529 90901 net.cpp:100] Creating Layer Scale2
I0905 01:39:06.402540 90901 net.cpp:434] Scale2 <- BatchNorm2
I0905 01:39:06.402554 90901 net.cpp:395] Scale2 -> BatchNorm2 (in-place)
I0905 01:39:06.402652 90901 net.cpp:150] Setting up Scale2
I0905 01:39:06.402667 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.402675 90901 net.cpp:165] Memory required for data: 73138240
I0905 01:39:06.402688 90901 layer_factory.hpp:77] Creating layer ReLU2
I0905 01:39:06.402699 90901 net.cpp:100] Creating Layer ReLU2
I0905 01:39:06.402707 90901 net.cpp:434] ReLU2 <- BatchNorm2
I0905 01:39:06.402724 90901 net.cpp:395] ReLU2 -> BatchNorm2 (in-place)
I0905 01:39:06.403028 90901 net.cpp:150] Setting up ReLU2
I0905 01:39:06.403046 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.403054 90901 net.cpp:165] Memory required for data: 80478272
I0905 01:39:06.403062 90901 layer_factory.hpp:77] Creating layer Convolution3
I0905 01:39:06.403079 90901 net.cpp:100] Creating Layer Convolution3
I0905 01:39:06.403087 90901 net.cpp:434] Convolution3 <- BatchNorm2
I0905 01:39:06.403100 90901 net.cpp:408] Convolution3 -> Convolution3
I0905 01:39:06.404070 90901 net.cpp:150] Setting up Convolution3
I0905 01:39:06.404090 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.404099 90901 net.cpp:165] Memory required for data: 83624000
I0905 01:39:06.404110 90901 layer_factory.hpp:77] Creating layer Dropout3
I0905 01:39:06.404124 90901 net.cpp:100] Creating Layer Dropout3
I0905 01:39:06.404134 90901 net.cpp:434] Dropout3 <- Convolution3
I0905 01:39:06.404144 90901 net.cpp:408] Dropout3 -> Dropout3
I0905 01:39:06.404186 90901 net.cpp:150] Setting up Dropout3
I0905 01:39:06.404196 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.404204 90901 net.cpp:165] Memory required for data: 86769728
I0905 01:39:06.404212 90901 layer_factory.hpp:77] Creating layer Concat2
I0905 01:39:06.404227 90901 net.cpp:100] Creating Layer Concat2
I0905 01:39:06.404235 90901 net.cpp:434] Concat2 <- Concat1_Concat1_0_split_1
I0905 01:39:06.404245 90901 net.cpp:434] Concat2 <- Dropout3
I0905 01:39:06.404256 90901 net.cpp:408] Concat2 -> Concat2
I0905 01:39:06.404284 90901 net.cpp:150] Setting up Concat2
I0905 01:39:06.404299 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.404312 90901 net.cpp:165] Memory required for data: 97255488
I0905 01:39:06.404320 90901 layer_factory.hpp:77] Creating layer Concat2_Concat2_0_split
I0905 01:39:06.404331 90901 net.cpp:100] Creating Layer Concat2_Concat2_0_split
I0905 01:39:06.404340 90901 net.cpp:434] Concat2_Concat2_0_split <- Concat2
I0905 01:39:06.404348 90901 net.cpp:408] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_0
I0905 01:39:06.404361 90901 net.cpp:408] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_1
I0905 01:39:06.404397 90901 net.cpp:150] Setting up Concat2_Concat2_0_split
I0905 01:39:06.404408 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.404417 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.404424 90901 net.cpp:165] Memory required for data: 118227008
I0905 01:39:06.404431 90901 layer_factory.hpp:77] Creating layer BatchNorm3
I0905 01:39:06.404443 90901 net.cpp:100] Creating Layer BatchNorm3
I0905 01:39:06.404451 90901 net.cpp:434] BatchNorm3 <- Concat2_Concat2_0_split_0
I0905 01:39:06.404474 90901 net.cpp:408] BatchNorm3 -> BatchNorm3
I0905 01:39:06.404641 90901 net.cpp:150] Setting up BatchNorm3
I0905 01:39:06.404655 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.404664 90901 net.cpp:165] Memory required for data: 128712768
I0905 01:39:06.404678 90901 layer_factory.hpp:77] Creating layer Scale3
I0905 01:39:06.404690 90901 net.cpp:100] Creating Layer Scale3
I0905 01:39:06.404701 90901 net.cpp:434] Scale3 <- BatchNorm3
I0905 01:39:06.404712 90901 net.cpp:395] Scale3 -> BatchNorm3 (in-place)
I0905 01:39:06.404793 90901 net.cpp:150] Setting up Scale3
I0905 01:39:06.404806 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.404817 90901 net.cpp:165] Memory required for data: 139198528
I0905 01:39:06.404826 90901 layer_factory.hpp:77] Creating layer ReLU3
I0905 01:39:06.404837 90901 net.cpp:100] Creating Layer ReLU3
I0905 01:39:06.404845 90901 net.cpp:434] ReLU3 <- BatchNorm3
I0905 01:39:06.404853 90901 net.cpp:395] ReLU3 -> BatchNorm3 (in-place)
I0905 01:39:06.405005 90901 net.cpp:150] Setting up ReLU3
I0905 01:39:06.405020 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.405030 90901 net.cpp:165] Memory required for data: 149684288
I0905 01:39:06.405037 90901 layer_factory.hpp:77] Creating layer Convolution4
I0905 01:39:06.405051 90901 net.cpp:100] Creating Layer Convolution4
I0905 01:39:06.405063 90901 net.cpp:434] Convolution4 <- BatchNorm3
I0905 01:39:06.405076 90901 net.cpp:408] Convolution4 -> Convolution4
I0905 01:39:06.406891 90901 net.cpp:150] Setting up Convolution4
I0905 01:39:06.406914 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.406924 90901 net.cpp:165] Memory required for data: 152830016
I0905 01:39:06.406936 90901 layer_factory.hpp:77] Creating layer Dropout4
I0905 01:39:06.406949 90901 net.cpp:100] Creating Layer Dropout4
I0905 01:39:06.406958 90901 net.cpp:434] Dropout4 <- Convolution4
I0905 01:39:06.406970 90901 net.cpp:408] Dropout4 -> Dropout4
I0905 01:39:06.407017 90901 net.cpp:150] Setting up Dropout4
I0905 01:39:06.407032 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.407053 90901 net.cpp:165] Memory required for data: 155975744
I0905 01:39:06.407063 90901 layer_factory.hpp:77] Creating layer Concat3
I0905 01:39:06.407078 90901 net.cpp:100] Creating Layer Concat3
I0905 01:39:06.407088 90901 net.cpp:434] Concat3 <- Concat2_Concat2_0_split_1
I0905 01:39:06.407097 90901 net.cpp:434] Concat3 <- Dropout4
I0905 01:39:06.407107 90901 net.cpp:408] Concat3 -> Concat3
I0905 01:39:06.407138 90901 net.cpp:150] Setting up Concat3
I0905 01:39:06.407151 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.407160 90901 net.cpp:165] Memory required for data: 169607232
I0905 01:39:06.407168 90901 layer_factory.hpp:77] Creating layer Concat3_Concat3_0_split
I0905 01:39:06.407182 90901 net.cpp:100] Creating Layer Concat3_Concat3_0_split
I0905 01:39:06.407191 90901 net.cpp:434] Concat3_Concat3_0_split <- Concat3
I0905 01:39:06.407207 90901 net.cpp:408] Concat3_Concat3_0_split -> Concat3_Concat3_0_split_0
I0905 01:39:06.407228 90901 net.cpp:408] Concat3_Concat3_0_split -> Concat3_Concat3_0_split_1
I0905 01:39:06.407269 90901 net.cpp:150] Setting up Concat3_Concat3_0_split
I0905 01:39:06.407284 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.407294 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.407302 90901 net.cpp:165] Memory required for data: 196870208
I0905 01:39:06.407313 90901 layer_factory.hpp:77] Creating layer BatchNorm4
I0905 01:39:06.407328 90901 net.cpp:100] Creating Layer BatchNorm4
I0905 01:39:06.407338 90901 net.cpp:434] BatchNorm4 <- Concat3_Concat3_0_split_0
I0905 01:39:06.407351 90901 net.cpp:408] BatchNorm4 -> BatchNorm4
I0905 01:39:06.407590 90901 net.cpp:150] Setting up BatchNorm4
I0905 01:39:06.407606 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.407614 90901 net.cpp:165] Memory required for data: 210501696
I0905 01:39:06.407627 90901 layer_factory.hpp:77] Creating layer Scale4
I0905 01:39:06.407656 90901 net.cpp:100] Creating Layer Scale4
I0905 01:39:06.407670 90901 net.cpp:434] Scale4 <- BatchNorm4
I0905 01:39:06.407680 90901 net.cpp:395] Scale4 -> BatchNorm4 (in-place)
I0905 01:39:06.407768 90901 net.cpp:150] Setting up Scale4
I0905 01:39:06.407783 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.407793 90901 net.cpp:165] Memory required for data: 224133184
I0905 01:39:06.407802 90901 layer_factory.hpp:77] Creating layer ReLU4
I0905 01:39:06.407820 90901 net.cpp:100] Creating Layer ReLU4
I0905 01:39:06.407831 90901 net.cpp:434] ReLU4 <- BatchNorm4
I0905 01:39:06.407841 90901 net.cpp:395] ReLU4 -> BatchNorm4 (in-place)
I0905 01:39:06.408012 90901 net.cpp:150] Setting up ReLU4
I0905 01:39:06.408028 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.408037 90901 net.cpp:165] Memory required for data: 237764672
I0905 01:39:06.408046 90901 layer_factory.hpp:77] Creating layer Convolution5
I0905 01:39:06.408061 90901 net.cpp:100] Creating Layer Convolution5
I0905 01:39:06.408071 90901 net.cpp:434] Convolution5 <- BatchNorm4
I0905 01:39:06.408083 90901 net.cpp:408] Convolution5 -> Convolution5
I0905 01:39:06.409610 90901 net.cpp:150] Setting up Convolution5
I0905 01:39:06.409633 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.409642 90901 net.cpp:165] Memory required for data: 240910400
I0905 01:39:06.409656 90901 layer_factory.hpp:77] Creating layer Dropout5
I0905 01:39:06.409673 90901 net.cpp:100] Creating Layer Dropout5
I0905 01:39:06.409683 90901 net.cpp:434] Dropout5 <- Convolution5
I0905 01:39:06.409694 90901 net.cpp:408] Dropout5 -> Dropout5
I0905 01:39:06.409744 90901 net.cpp:150] Setting up Dropout5
I0905 01:39:06.409759 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.409766 90901 net.cpp:165] Memory required for data: 244056128
I0905 01:39:06.409776 90901 layer_factory.hpp:77] Creating layer Concat4
I0905 01:39:06.409790 90901 net.cpp:100] Creating Layer Concat4
I0905 01:39:06.409799 90901 net.cpp:434] Concat4 <- Concat3_Concat3_0_split_1
I0905 01:39:06.409811 90901 net.cpp:434] Concat4 <- Dropout5
I0905 01:39:06.409821 90901 net.cpp:408] Concat4 -> Concat4
I0905 01:39:06.409852 90901 net.cpp:150] Setting up Concat4
I0905 01:39:06.409865 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.409873 90901 net.cpp:165] Memory required for data: 260833344
I0905 01:39:06.409883 90901 layer_factory.hpp:77] Creating layer Concat4_Concat4_0_split
I0905 01:39:06.409895 90901 net.cpp:100] Creating Layer Concat4_Concat4_0_split
I0905 01:39:06.409904 90901 net.cpp:434] Concat4_Concat4_0_split <- Concat4
I0905 01:39:06.409916 90901 net.cpp:408] Concat4_Concat4_0_split -> Concat4_Concat4_0_split_0
I0905 01:39:06.409927 90901 net.cpp:408] Concat4_Concat4_0_split -> Concat4_Concat4_0_split_1
I0905 01:39:06.409967 90901 net.cpp:150] Setting up Concat4_Concat4_0_split
I0905 01:39:06.409981 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.409992 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.410002 90901 net.cpp:165] Memory required for data: 294387776
I0905 01:39:06.410012 90901 layer_factory.hpp:77] Creating layer BatchNorm5
I0905 01:39:06.410027 90901 net.cpp:100] Creating Layer BatchNorm5
I0905 01:39:06.410039 90901 net.cpp:434] BatchNorm5 <- Concat4_Concat4_0_split_0
I0905 01:39:06.410055 90901 net.cpp:408] BatchNorm5 -> BatchNorm5
I0905 01:39:06.410234 90901 net.cpp:150] Setting up BatchNorm5
I0905 01:39:06.410248 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.410257 90901 net.cpp:165] Memory required for data: 311164992
I0905 01:39:06.410270 90901 layer_factory.hpp:77] Creating layer Scale5
I0905 01:39:06.410282 90901 net.cpp:100] Creating Layer Scale5
I0905 01:39:06.410291 90901 net.cpp:434] Scale5 <- BatchNorm5
I0905 01:39:06.410301 90901 net.cpp:395] Scale5 -> BatchNorm5 (in-place)
I0905 01:39:06.410392 90901 net.cpp:150] Setting up Scale5
I0905 01:39:06.410405 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.410413 90901 net.cpp:165] Memory required for data: 327942208
I0905 01:39:06.410437 90901 layer_factory.hpp:77] Creating layer ReLU5
I0905 01:39:06.410454 90901 net.cpp:100] Creating Layer ReLU5
I0905 01:39:06.410462 90901 net.cpp:434] ReLU5 <- BatchNorm5
I0905 01:39:06.410480 90901 net.cpp:395] ReLU5 -> BatchNorm5 (in-place)
I0905 01:39:06.411073 90901 net.cpp:150] Setting up ReLU5
I0905 01:39:06.411097 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.411106 90901 net.cpp:165] Memory required for data: 344719424
I0905 01:39:06.411115 90901 layer_factory.hpp:77] Creating layer Convolution6
I0905 01:39:06.411133 90901 net.cpp:100] Creating Layer Convolution6
I0905 01:39:06.411142 90901 net.cpp:434] Convolution6 <- BatchNorm5
I0905 01:39:06.411156 90901 net.cpp:408] Convolution6 -> Convolution6
I0905 01:39:06.412719 90901 net.cpp:150] Setting up Convolution6
I0905 01:39:06.412744 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.412753 90901 net.cpp:165] Memory required for data: 347865152
I0905 01:39:06.412765 90901 layer_factory.hpp:77] Creating layer Dropout6
I0905 01:39:06.412781 90901 net.cpp:100] Creating Layer Dropout6
I0905 01:39:06.412791 90901 net.cpp:434] Dropout6 <- Convolution6
I0905 01:39:06.412801 90901 net.cpp:408] Dropout6 -> Dropout6
I0905 01:39:06.412850 90901 net.cpp:150] Setting up Dropout6
I0905 01:39:06.412866 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.412874 90901 net.cpp:165] Memory required for data: 351010880
I0905 01:39:06.412886 90901 layer_factory.hpp:77] Creating layer Concat5
I0905 01:39:06.412899 90901 net.cpp:100] Creating Layer Concat5
I0905 01:39:06.412907 90901 net.cpp:434] Concat5 <- Concat4_Concat4_0_split_1
I0905 01:39:06.412917 90901 net.cpp:434] Concat5 <- Dropout6
I0905 01:39:06.412931 90901 net.cpp:408] Concat5 -> Concat5
I0905 01:39:06.412963 90901 net.cpp:150] Setting up Concat5
I0905 01:39:06.412977 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.412986 90901 net.cpp:165] Memory required for data: 370933824
I0905 01:39:06.412994 90901 layer_factory.hpp:77] Creating layer Concat5_Concat5_0_split
I0905 01:39:06.413007 90901 net.cpp:100] Creating Layer Concat5_Concat5_0_split
I0905 01:39:06.413014 90901 net.cpp:434] Concat5_Concat5_0_split <- Concat5
I0905 01:39:06.413028 90901 net.cpp:408] Concat5_Concat5_0_split -> Concat5_Concat5_0_split_0
I0905 01:39:06.413039 90901 net.cpp:408] Concat5_Concat5_0_split -> Concat5_Concat5_0_split_1
I0905 01:39:06.413079 90901 net.cpp:150] Setting up Concat5_Concat5_0_split
I0905 01:39:06.413096 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.413118 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.413127 90901 net.cpp:165] Memory required for data: 410779712
I0905 01:39:06.413136 90901 layer_factory.hpp:77] Creating layer BatchNorm6
I0905 01:39:06.413153 90901 net.cpp:100] Creating Layer BatchNorm6
I0905 01:39:06.413163 90901 net.cpp:434] BatchNorm6 <- Concat5_Concat5_0_split_0
I0905 01:39:06.413177 90901 net.cpp:408] BatchNorm6 -> BatchNorm6
I0905 01:39:06.413373 90901 net.cpp:150] Setting up BatchNorm6
I0905 01:39:06.413389 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.413403 90901 net.cpp:165] Memory required for data: 430702656
I0905 01:39:06.413419 90901 layer_factory.hpp:77] Creating layer Scale6
I0905 01:39:06.413434 90901 net.cpp:100] Creating Layer Scale6
I0905 01:39:06.413444 90901 net.cpp:434] Scale6 <- BatchNorm6
I0905 01:39:06.413453 90901 net.cpp:395] Scale6 -> BatchNorm6 (in-place)
I0905 01:39:06.413547 90901 net.cpp:150] Setting up Scale6
I0905 01:39:06.413561 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.413569 90901 net.cpp:165] Memory required for data: 450625600
I0905 01:39:06.413580 90901 layer_factory.hpp:77] Creating layer ReLU6
I0905 01:39:06.413594 90901 net.cpp:100] Creating Layer ReLU6
I0905 01:39:06.413604 90901 net.cpp:434] ReLU6 <- BatchNorm6
I0905 01:39:06.413614 90901 net.cpp:395] ReLU6 -> BatchNorm6 (in-place)
I0905 01:39:06.413784 90901 net.cpp:150] Setting up ReLU6
I0905 01:39:06.413801 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.413825 90901 net.cpp:165] Memory required for data: 470548544
I0905 01:39:06.413838 90901 layer_factory.hpp:77] Creating layer Convolution7
I0905 01:39:06.413856 90901 net.cpp:100] Creating Layer Convolution7
I0905 01:39:06.413866 90901 net.cpp:434] Convolution7 <- BatchNorm6
I0905 01:39:06.413878 90901 net.cpp:408] Convolution7 -> Convolution7
I0905 01:39:06.415592 90901 net.cpp:150] Setting up Convolution7
I0905 01:39:06.415618 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.415628 90901 net.cpp:165] Memory required for data: 473694272
I0905 01:39:06.415642 90901 layer_factory.hpp:77] Creating layer Dropout7
I0905 01:39:06.415653 90901 net.cpp:100] Creating Layer Dropout7
I0905 01:39:06.415663 90901 net.cpp:434] Dropout7 <- Convolution7
I0905 01:39:06.415676 90901 net.cpp:408] Dropout7 -> Dropout7
I0905 01:39:06.415724 90901 net.cpp:150] Setting up Dropout7
I0905 01:39:06.415737 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.415746 90901 net.cpp:165] Memory required for data: 476840000
I0905 01:39:06.415755 90901 layer_factory.hpp:77] Creating layer Concat6
I0905 01:39:06.415769 90901 net.cpp:100] Creating Layer Concat6
I0905 01:39:06.415778 90901 net.cpp:434] Concat6 <- Concat5_Concat5_0_split_1
I0905 01:39:06.415788 90901 net.cpp:434] Concat6 <- Dropout7
I0905 01:39:06.415801 90901 net.cpp:408] Concat6 -> Concat6
I0905 01:39:06.415830 90901 net.cpp:150] Setting up Concat6
I0905 01:39:06.415843 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.415853 90901 net.cpp:165] Memory required for data: 499908672
I0905 01:39:06.415860 90901 layer_factory.hpp:77] Creating layer Concat6_Concat6_0_split
I0905 01:39:06.415871 90901 net.cpp:100] Creating Layer Concat6_Concat6_0_split
I0905 01:39:06.415880 90901 net.cpp:434] Concat6_Concat6_0_split <- Concat6
I0905 01:39:06.415890 90901 net.cpp:408] Concat6_Concat6_0_split -> Concat6_Concat6_0_split_0
I0905 01:39:06.415902 90901 net.cpp:408] Concat6_Concat6_0_split -> Concat6_Concat6_0_split_1
I0905 01:39:06.415942 90901 net.cpp:150] Setting up Concat6_Concat6_0_split
I0905 01:39:06.415956 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.415966 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.415973 90901 net.cpp:165] Memory required for data: 546046016
I0905 01:39:06.415984 90901 layer_factory.hpp:77] Creating layer BatchNorm7
I0905 01:39:06.416002 90901 net.cpp:100] Creating Layer BatchNorm7
I0905 01:39:06.416012 90901 net.cpp:434] BatchNorm7 <- Concat6_Concat6_0_split_0
I0905 01:39:06.416023 90901 net.cpp:408] BatchNorm7 -> BatchNorm7
I0905 01:39:06.416206 90901 net.cpp:150] Setting up BatchNorm7
I0905 01:39:06.416220 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.416229 90901 net.cpp:165] Memory required for data: 569114688
I0905 01:39:06.416241 90901 layer_factory.hpp:77] Creating layer Scale7
I0905 01:39:06.416254 90901 net.cpp:100] Creating Layer Scale7
I0905 01:39:06.416263 90901 net.cpp:434] Scale7 <- BatchNorm7
I0905 01:39:06.416275 90901 net.cpp:395] Scale7 -> BatchNorm7 (in-place)
I0905 01:39:06.416359 90901 net.cpp:150] Setting up Scale7
I0905 01:39:06.416373 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.416383 90901 net.cpp:165] Memory required for data: 592183360
I0905 01:39:06.416391 90901 layer_factory.hpp:77] Creating layer ReLU7
I0905 01:39:06.416405 90901 net.cpp:100] Creating Layer ReLU7
I0905 01:39:06.416415 90901 net.cpp:434] ReLU7 <- BatchNorm7
I0905 01:39:06.416425 90901 net.cpp:395] ReLU7 -> BatchNorm7 (in-place)
I0905 01:39:06.416601 90901 net.cpp:150] Setting up ReLU7
I0905 01:39:06.416617 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.416626 90901 net.cpp:165] Memory required for data: 615252032
I0905 01:39:06.416636 90901 layer_factory.hpp:77] Creating layer Convolution8
I0905 01:39:06.416658 90901 net.cpp:100] Creating Layer Convolution8
I0905 01:39:06.416667 90901 net.cpp:434] Convolution8 <- BatchNorm7
I0905 01:39:06.416679 90901 net.cpp:408] Convolution8 -> Convolution8
I0905 01:39:06.418822 90901 net.cpp:150] Setting up Convolution8
I0905 01:39:06.418853 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.418864 90901 net.cpp:165] Memory required for data: 618397760
I0905 01:39:06.418876 90901 layer_factory.hpp:77] Creating layer Dropout8
I0905 01:39:06.418889 90901 net.cpp:100] Creating Layer Dropout8
I0905 01:39:06.418898 90901 net.cpp:434] Dropout8 <- Convolution8
I0905 01:39:06.418910 90901 net.cpp:408] Dropout8 -> Dropout8
I0905 01:39:06.418963 90901 net.cpp:150] Setting up Dropout8
I0905 01:39:06.418977 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.418987 90901 net.cpp:165] Memory required for data: 621543488
I0905 01:39:06.418995 90901 layer_factory.hpp:77] Creating layer Concat7
I0905 01:39:06.419015 90901 net.cpp:100] Creating Layer Concat7
I0905 01:39:06.419025 90901 net.cpp:434] Concat7 <- Concat6_Concat6_0_split_1
I0905 01:39:06.419039 90901 net.cpp:434] Concat7 <- Dropout8
I0905 01:39:06.419050 90901 net.cpp:408] Concat7 -> Concat7
I0905 01:39:06.419081 90901 net.cpp:150] Setting up Concat7
I0905 01:39:06.419103 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.419116 90901 net.cpp:165] Memory required for data: 647757888
I0905 01:39:06.419126 90901 layer_factory.hpp:77] Creating layer Concat7_Concat7_0_split
I0905 01:39:06.419139 90901 net.cpp:100] Creating Layer Concat7_Concat7_0_split
I0905 01:39:06.419148 90901 net.cpp:434] Concat7_Concat7_0_split <- Concat7
I0905 01:39:06.419165 90901 net.cpp:408] Concat7_Concat7_0_split -> Concat7_Concat7_0_split_0
I0905 01:39:06.419176 90901 net.cpp:408] Concat7_Concat7_0_split -> Concat7_Concat7_0_split_1
I0905 01:39:06.419216 90901 net.cpp:150] Setting up Concat7_Concat7_0_split
I0905 01:39:06.419229 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.419245 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.419255 90901 net.cpp:165] Memory required for data: 700186688
I0905 01:39:06.419263 90901 layer_factory.hpp:77] Creating layer BatchNorm8
I0905 01:39:06.419275 90901 net.cpp:100] Creating Layer BatchNorm8
I0905 01:39:06.419284 90901 net.cpp:434] BatchNorm8 <- Concat7_Concat7_0_split_0
I0905 01:39:06.419296 90901 net.cpp:408] BatchNorm8 -> BatchNorm8
I0905 01:39:06.419483 90901 net.cpp:150] Setting up BatchNorm8
I0905 01:39:06.419502 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.419509 90901 net.cpp:165] Memory required for data: 726401088
I0905 01:39:06.419523 90901 layer_factory.hpp:77] Creating layer Scale8
I0905 01:39:06.419535 90901 net.cpp:100] Creating Layer Scale8
I0905 01:39:06.419543 90901 net.cpp:434] Scale8 <- BatchNorm8
I0905 01:39:06.419554 90901 net.cpp:395] Scale8 -> BatchNorm8 (in-place)
I0905 01:39:06.419651 90901 net.cpp:150] Setting up Scale8
I0905 01:39:06.419672 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.419682 90901 net.cpp:165] Memory required for data: 752615488
I0905 01:39:06.419692 90901 layer_factory.hpp:77] Creating layer ReLU8
I0905 01:39:06.419706 90901 net.cpp:100] Creating Layer ReLU8
I0905 01:39:06.419721 90901 net.cpp:434] ReLU8 <- BatchNorm8
I0905 01:39:06.419730 90901 net.cpp:395] ReLU8 -> BatchNorm8 (in-place)
I0905 01:39:06.420245 90901 net.cpp:150] Setting up ReLU8
I0905 01:39:06.420266 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.420275 90901 net.cpp:165] Memory required for data: 778829888
I0905 01:39:06.420284 90901 layer_factory.hpp:77] Creating layer Convolution9
I0905 01:39:06.420305 90901 net.cpp:100] Creating Layer Convolution9
I0905 01:39:06.420315 90901 net.cpp:434] Convolution9 <- BatchNorm8
I0905 01:39:06.420328 90901 net.cpp:408] Convolution9 -> Convolution9
I0905 01:39:06.422067 90901 net.cpp:150] Setting up Convolution9
I0905 01:39:06.422088 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.422099 90901 net.cpp:165] Memory required for data: 781975616
I0905 01:39:06.422112 90901 layer_factory.hpp:77] Creating layer Dropout9
I0905 01:39:06.422127 90901 net.cpp:100] Creating Layer Dropout9
I0905 01:39:06.422150 90901 net.cpp:434] Dropout9 <- Convolution9
I0905 01:39:06.422163 90901 net.cpp:408] Dropout9 -> Dropout9
I0905 01:39:06.422209 90901 net.cpp:150] Setting up Dropout9
I0905 01:39:06.422225 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.422235 90901 net.cpp:165] Memory required for data: 785121344
I0905 01:39:06.422243 90901 layer_factory.hpp:77] Creating layer Concat8
I0905 01:39:06.422256 90901 net.cpp:100] Creating Layer Concat8
I0905 01:39:06.422266 90901 net.cpp:434] Concat8 <- Concat7_Concat7_0_split_1
I0905 01:39:06.422276 90901 net.cpp:434] Concat8 <- Dropout9
I0905 01:39:06.422286 90901 net.cpp:408] Concat8 -> Concat8
I0905 01:39:06.422319 90901 net.cpp:150] Setting up Concat8
I0905 01:39:06.422333 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.422343 90901 net.cpp:165] Memory required for data: 814481472
I0905 01:39:06.422351 90901 layer_factory.hpp:77] Creating layer Concat8_Concat8_0_split
I0905 01:39:06.422363 90901 net.cpp:100] Creating Layer Concat8_Concat8_0_split
I0905 01:39:06.422374 90901 net.cpp:434] Concat8_Concat8_0_split <- Concat8
I0905 01:39:06.422384 90901 net.cpp:408] Concat8_Concat8_0_split -> Concat8_Concat8_0_split_0
I0905 01:39:06.422395 90901 net.cpp:408] Concat8_Concat8_0_split -> Concat8_Concat8_0_split_1
I0905 01:39:06.422441 90901 net.cpp:150] Setting up Concat8_Concat8_0_split
I0905 01:39:06.422454 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.422464 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.422475 90901 net.cpp:165] Memory required for data: 873201728
I0905 01:39:06.422483 90901 layer_factory.hpp:77] Creating layer BatchNorm9
I0905 01:39:06.422494 90901 net.cpp:100] Creating Layer BatchNorm9
I0905 01:39:06.422503 90901 net.cpp:434] BatchNorm9 <- Concat8_Concat8_0_split_0
I0905 01:39:06.422515 90901 net.cpp:408] BatchNorm9 -> BatchNorm9
I0905 01:39:06.422777 90901 net.cpp:150] Setting up BatchNorm9
I0905 01:39:06.422793 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.422802 90901 net.cpp:165] Memory required for data: 902561856
I0905 01:39:06.422816 90901 layer_factory.hpp:77] Creating layer Scale9
I0905 01:39:06.422827 90901 net.cpp:100] Creating Layer Scale9
I0905 01:39:06.422837 90901 net.cpp:434] Scale9 <- BatchNorm9
I0905 01:39:06.422848 90901 net.cpp:395] Scale9 -> BatchNorm9 (in-place)
I0905 01:39:06.422945 90901 net.cpp:150] Setting up Scale9
I0905 01:39:06.422966 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.422976 90901 net.cpp:165] Memory required for data: 931921984
I0905 01:39:06.422989 90901 layer_factory.hpp:77] Creating layer ReLU9
I0905 01:39:06.422999 90901 net.cpp:100] Creating Layer ReLU9
I0905 01:39:06.423008 90901 net.cpp:434] ReLU9 <- BatchNorm9
I0905 01:39:06.423025 90901 net.cpp:395] ReLU9 -> BatchNorm9 (in-place)
I0905 01:39:06.423441 90901 net.cpp:150] Setting up ReLU9
I0905 01:39:06.423458 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.423466 90901 net.cpp:165] Memory required for data: 961282112
I0905 01:39:06.423475 90901 layer_factory.hpp:77] Creating layer Convolution10
I0905 01:39:06.423492 90901 net.cpp:100] Creating Layer Convolution10
I0905 01:39:06.423502 90901 net.cpp:434] Convolution10 <- BatchNorm9
I0905 01:39:06.423516 90901 net.cpp:408] Convolution10 -> Convolution10
I0905 01:39:06.426923 90901 net.cpp:150] Setting up Convolution10
I0905 01:39:06.426944 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.426954 90901 net.cpp:165] Memory required for data: 964427840
I0905 01:39:06.426965 90901 layer_factory.hpp:77] Creating layer Dropout10
I0905 01:39:06.426990 90901 net.cpp:100] Creating Layer Dropout10
I0905 01:39:06.427000 90901 net.cpp:434] Dropout10 <- Convolution10
I0905 01:39:06.427011 90901 net.cpp:408] Dropout10 -> Dropout10
I0905 01:39:06.427059 90901 net.cpp:150] Setting up Dropout10
I0905 01:39:06.427076 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.427085 90901 net.cpp:165] Memory required for data: 967573568
I0905 01:39:06.427098 90901 layer_factory.hpp:77] Creating layer Concat9
I0905 01:39:06.427124 90901 net.cpp:100] Creating Layer Concat9
I0905 01:39:06.427134 90901 net.cpp:434] Concat9 <- Concat8_Concat8_0_split_1
I0905 01:39:06.427144 90901 net.cpp:434] Concat9 <- Dropout10
I0905 01:39:06.427153 90901 net.cpp:408] Concat9 -> Concat9
I0905 01:39:06.427186 90901 net.cpp:150] Setting up Concat9
I0905 01:39:06.427198 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.427211 90901 net.cpp:165] Memory required for data: 1000079424
I0905 01:39:06.427219 90901 layer_factory.hpp:77] Creating layer Concat9_Concat9_0_split
I0905 01:39:06.427232 90901 net.cpp:100] Creating Layer Concat9_Concat9_0_split
I0905 01:39:06.427242 90901 net.cpp:434] Concat9_Concat9_0_split <- Concat9
I0905 01:39:06.427251 90901 net.cpp:408] Concat9_Concat9_0_split -> Concat9_Concat9_0_split_0
I0905 01:39:06.427263 90901 net.cpp:408] Concat9_Concat9_0_split -> Concat9_Concat9_0_split_1
I0905 01:39:06.427312 90901 net.cpp:150] Setting up Concat9_Concat9_0_split
I0905 01:39:06.427326 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.427335 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.427347 90901 net.cpp:165] Memory required for data: 1065091136
I0905 01:39:06.427356 90901 layer_factory.hpp:77] Creating layer BatchNorm10
I0905 01:39:06.427372 90901 net.cpp:100] Creating Layer BatchNorm10
I0905 01:39:06.427381 90901 net.cpp:434] BatchNorm10 <- Concat9_Concat9_0_split_0
I0905 01:39:06.427392 90901 net.cpp:408] BatchNorm10 -> BatchNorm10
I0905 01:39:06.427582 90901 net.cpp:150] Setting up BatchNorm10
I0905 01:39:06.427595 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.427604 90901 net.cpp:165] Memory required for data: 1097596992
I0905 01:39:06.427618 90901 layer_factory.hpp:77] Creating layer Scale10
I0905 01:39:06.427629 90901 net.cpp:100] Creating Layer Scale10
I0905 01:39:06.427639 90901 net.cpp:434] Scale10 <- BatchNorm10
I0905 01:39:06.427649 90901 net.cpp:395] Scale10 -> BatchNorm10 (in-place)
I0905 01:39:06.427738 90901 net.cpp:150] Setting up Scale10
I0905 01:39:06.427752 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.427767 90901 net.cpp:165] Memory required for data: 1130102848
I0905 01:39:06.427778 90901 layer_factory.hpp:77] Creating layer ReLU10
I0905 01:39:06.427790 90901 net.cpp:100] Creating Layer ReLU10
I0905 01:39:06.427799 90901 net.cpp:434] ReLU10 <- BatchNorm10
I0905 01:39:06.427810 90901 net.cpp:395] ReLU10 -> BatchNorm10 (in-place)
I0905 01:39:06.427980 90901 net.cpp:150] Setting up ReLU10
I0905 01:39:06.427996 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.428005 90901 net.cpp:165] Memory required for data: 1162608704
I0905 01:39:06.428016 90901 layer_factory.hpp:77] Creating layer Convolution11
I0905 01:39:06.428033 90901 net.cpp:100] Creating Layer Convolution11
I0905 01:39:06.428043 90901 net.cpp:434] Convolution11 <- BatchNorm10
I0905 01:39:06.428056 90901 net.cpp:408] Convolution11 -> Convolution11
I0905 01:39:06.433634 90901 net.cpp:150] Setting up Convolution11
I0905 01:39:06.433655 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.433663 90901 net.cpp:165] Memory required for data: 1165754432
I0905 01:39:06.433676 90901 layer_factory.hpp:77] Creating layer Dropout11
I0905 01:39:06.433691 90901 net.cpp:100] Creating Layer Dropout11
I0905 01:39:06.433699 90901 net.cpp:434] Dropout11 <- Convolution11
I0905 01:39:06.433712 90901 net.cpp:408] Dropout11 -> Dropout11
I0905 01:39:06.433760 90901 net.cpp:150] Setting up Dropout11
I0905 01:39:06.433774 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.433784 90901 net.cpp:165] Memory required for data: 1168900160
I0905 01:39:06.433792 90901 layer_factory.hpp:77] Creating layer Concat10
I0905 01:39:06.433809 90901 net.cpp:100] Creating Layer Concat10
I0905 01:39:06.433820 90901 net.cpp:434] Concat10 <- Concat9_Concat9_0_split_1
I0905 01:39:06.433830 90901 net.cpp:434] Concat10 <- Dropout11
I0905 01:39:06.433840 90901 net.cpp:408] Concat10 -> Concat10
I0905 01:39:06.433883 90901 net.cpp:150] Setting up Concat10
I0905 01:39:06.433904 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.433912 90901 net.cpp:165] Memory required for data: 1204551744
I0905 01:39:06.433922 90901 layer_factory.hpp:77] Creating layer Concat10_Concat10_0_split
I0905 01:39:06.433935 90901 net.cpp:100] Creating Layer Concat10_Concat10_0_split
I0905 01:39:06.433946 90901 net.cpp:434] Concat10_Concat10_0_split <- Concat10
I0905 01:39:06.433959 90901 net.cpp:408] Concat10_Concat10_0_split -> Concat10_Concat10_0_split_0
I0905 01:39:06.433977 90901 net.cpp:408] Concat10_Concat10_0_split -> Concat10_Concat10_0_split_1
I0905 01:39:06.434020 90901 net.cpp:150] Setting up Concat10_Concat10_0_split
I0905 01:39:06.434042 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.434052 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.434061 90901 net.cpp:165] Memory required for data: 1275854912
I0905 01:39:06.434072 90901 layer_factory.hpp:77] Creating layer BatchNorm11
I0905 01:39:06.434085 90901 net.cpp:100] Creating Layer BatchNorm11
I0905 01:39:06.434098 90901 net.cpp:434] BatchNorm11 <- Concat10_Concat10_0_split_0
I0905 01:39:06.434110 90901 net.cpp:408] BatchNorm11 -> BatchNorm11
I0905 01:39:06.434293 90901 net.cpp:150] Setting up BatchNorm11
I0905 01:39:06.434308 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.434316 90901 net.cpp:165] Memory required for data: 1311506496
I0905 01:39:06.434339 90901 layer_factory.hpp:77] Creating layer Scale11
I0905 01:39:06.434353 90901 net.cpp:100] Creating Layer Scale11
I0905 01:39:06.434365 90901 net.cpp:434] Scale11 <- BatchNorm11
I0905 01:39:06.434376 90901 net.cpp:395] Scale11 -> BatchNorm11 (in-place)
I0905 01:39:06.434469 90901 net.cpp:150] Setting up Scale11
I0905 01:39:06.434492 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.434501 90901 net.cpp:165] Memory required for data: 1347158080
I0905 01:39:06.434514 90901 layer_factory.hpp:77] Creating layer ReLU11
I0905 01:39:06.434525 90901 net.cpp:100] Creating Layer ReLU11
I0905 01:39:06.434538 90901 net.cpp:434] ReLU11 <- BatchNorm11
I0905 01:39:06.434550 90901 net.cpp:395] ReLU11 -> BatchNorm11 (in-place)
I0905 01:39:06.440390 90901 net.cpp:150] Setting up ReLU11
I0905 01:39:06.440414 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.440423 90901 net.cpp:165] Memory required for data: 1382809664
I0905 01:39:06.440433 90901 layer_factory.hpp:77] Creating layer Convolution12
I0905 01:39:06.440450 90901 net.cpp:100] Creating Layer Convolution12
I0905 01:39:06.440460 90901 net.cpp:434] Convolution12 <- BatchNorm11
I0905 01:39:06.440474 90901 net.cpp:408] Convolution12 -> Convolution12
I0905 01:39:06.458142 90901 net.cpp:150] Setting up Convolution12
I0905 01:39:06.458168 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.458178 90901 net.cpp:165] Memory required for data: 1385955392
I0905 01:39:06.458191 90901 layer_factory.hpp:77] Creating layer Dropout12
I0905 01:39:06.458204 90901 net.cpp:100] Creating Layer Dropout12
I0905 01:39:06.458212 90901 net.cpp:434] Dropout12 <- Convolution12
I0905 01:39:06.458226 90901 net.cpp:408] Dropout12 -> Dropout12
I0905 01:39:06.458273 90901 net.cpp:150] Setting up Dropout12
I0905 01:39:06.458288 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.458297 90901 net.cpp:165] Memory required for data: 1389101120
I0905 01:39:06.458307 90901 layer_factory.hpp:77] Creating layer Concat11
I0905 01:39:06.458319 90901 net.cpp:100] Creating Layer Concat11
I0905 01:39:06.458329 90901 net.cpp:434] Concat11 <- Concat10_Concat10_0_split_1
I0905 01:39:06.458338 90901 net.cpp:434] Concat11 <- Dropout12
I0905 01:39:06.458349 90901 net.cpp:408] Concat11 -> Concat11
I0905 01:39:06.458379 90901 net.cpp:150] Setting up Concat11
I0905 01:39:06.458392 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.458401 90901 net.cpp:165] Memory required for data: 1427898432
I0905 01:39:06.458410 90901 layer_factory.hpp:77] Creating layer Concat11_Concat11_0_split
I0905 01:39:06.458437 90901 net.cpp:100] Creating Layer Concat11_Concat11_0_split
I0905 01:39:06.458451 90901 net.cpp:434] Concat11_Concat11_0_split <- Concat11
I0905 01:39:06.458472 90901 net.cpp:408] Concat11_Concat11_0_split -> Concat11_Concat11_0_split_0
I0905 01:39:06.458483 90901 net.cpp:408] Concat11_Concat11_0_split -> Concat11_Concat11_0_split_1
I0905 01:39:06.458533 90901 net.cpp:150] Setting up Concat11_Concat11_0_split
I0905 01:39:06.458547 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.458560 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.458571 90901 net.cpp:165] Memory required for data: 1505493056
I0905 01:39:06.458585 90901 layer_factory.hpp:77] Creating layer BatchNorm12
I0905 01:39:06.458595 90901 net.cpp:100] Creating Layer BatchNorm12
I0905 01:39:06.458605 90901 net.cpp:434] BatchNorm12 <- Concat11_Concat11_0_split_0
I0905 01:39:06.458619 90901 net.cpp:408] BatchNorm12 -> BatchNorm12
I0905 01:39:06.458889 90901 net.cpp:150] Setting up BatchNorm12
I0905 01:39:06.458904 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.458914 90901 net.cpp:165] Memory required for data: 1544290368
I0905 01:39:06.458925 90901 layer_factory.hpp:77] Creating layer Scale12
I0905 01:39:06.458940 90901 net.cpp:100] Creating Layer Scale12
I0905 01:39:06.458951 90901 net.cpp:434] Scale12 <- BatchNorm12
I0905 01:39:06.458961 90901 net.cpp:395] Scale12 -> BatchNorm12 (in-place)
I0905 01:39:06.459050 90901 net.cpp:150] Setting up Scale12
I0905 01:39:06.459066 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.459075 90901 net.cpp:165] Memory required for data: 1583087680
I0905 01:39:06.459090 90901 layer_factory.hpp:77] Creating layer ReLU12
I0905 01:39:06.459103 90901 net.cpp:100] Creating Layer ReLU12
I0905 01:39:06.459120 90901 net.cpp:434] ReLU12 <- BatchNorm12
I0905 01:39:06.459128 90901 net.cpp:395] ReLU12 -> BatchNorm12 (in-place)
I0905 01:39:06.459297 90901 net.cpp:150] Setting up ReLU12
I0905 01:39:06.459313 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.459321 90901 net.cpp:165] Memory required for data: 1621884992
I0905 01:39:06.459331 90901 layer_factory.hpp:77] Creating layer Convolution13
I0905 01:39:06.459347 90901 net.cpp:100] Creating Layer Convolution13
I0905 01:39:06.459358 90901 net.cpp:434] Convolution13 <- BatchNorm12
I0905 01:39:06.459373 90901 net.cpp:408] Convolution13 -> Convolution13
I0905 01:39:06.467540 90901 net.cpp:150] Setting up Convolution13
I0905 01:39:06.467564 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.467577 90901 net.cpp:165] Memory required for data: 1625030720
I0905 01:39:06.467589 90901 layer_factory.hpp:77] Creating layer Dropout13
I0905 01:39:06.467602 90901 net.cpp:100] Creating Layer Dropout13
I0905 01:39:06.467612 90901 net.cpp:434] Dropout13 <- Convolution13
I0905 01:39:06.467625 90901 net.cpp:408] Dropout13 -> Dropout13
I0905 01:39:06.467674 90901 net.cpp:150] Setting up Dropout13
I0905 01:39:06.467689 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.467697 90901 net.cpp:165] Memory required for data: 1628176448
I0905 01:39:06.467706 90901 layer_factory.hpp:77] Creating layer Concat12
I0905 01:39:06.467722 90901 net.cpp:100] Creating Layer Concat12
I0905 01:39:06.467731 90901 net.cpp:434] Concat12 <- Concat11_Concat11_0_split_1
I0905 01:39:06.467741 90901 net.cpp:434] Concat12 <- Dropout13
I0905 01:39:06.467753 90901 net.cpp:408] Concat12 -> Concat12
I0905 01:39:06.467787 90901 net.cpp:150] Setting up Concat12
I0905 01:39:06.467803 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.467819 90901 net.cpp:165] Memory required for data: 1670119488
I0905 01:39:06.467828 90901 layer_factory.hpp:77] Creating layer BatchNorm13
I0905 01:39:06.467841 90901 net.cpp:100] Creating Layer BatchNorm13
I0905 01:39:06.467850 90901 net.cpp:434] BatchNorm13 <- Concat12
I0905 01:39:06.467870 90901 net.cpp:408] BatchNorm13 -> BatchNorm13
I0905 01:39:06.468060 90901 net.cpp:150] Setting up BatchNorm13
I0905 01:39:06.468075 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.468097 90901 net.cpp:165] Memory required for data: 1712062528
I0905 01:39:06.468111 90901 layer_factory.hpp:77] Creating layer Scale13
I0905 01:39:06.468123 90901 net.cpp:100] Creating Layer Scale13
I0905 01:39:06.468133 90901 net.cpp:434] Scale13 <- BatchNorm13
I0905 01:39:06.468143 90901 net.cpp:395] Scale13 -> BatchNorm13 (in-place)
I0905 01:39:06.468238 90901 net.cpp:150] Setting up Scale13
I0905 01:39:06.468262 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.468271 90901 net.cpp:165] Memory required for data: 1754005568
I0905 01:39:06.468281 90901 layer_factory.hpp:77] Creating layer ReLU13
I0905 01:39:06.468297 90901 net.cpp:100] Creating Layer ReLU13
I0905 01:39:06.468307 90901 net.cpp:434] ReLU13 <- BatchNorm13
I0905 01:39:06.468317 90901 net.cpp:395] ReLU13 -> BatchNorm13 (in-place)
I0905 01:39:06.468487 90901 net.cpp:150] Setting up ReLU13
I0905 01:39:06.468510 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.468520 90901 net.cpp:165] Memory required for data: 1795948608
I0905 01:39:06.468528 90901 layer_factory.hpp:77] Creating layer Convolution14
I0905 01:39:06.468546 90901 net.cpp:100] Creating Layer Convolution14
I0905 01:39:06.468556 90901 net.cpp:434] Convolution14 <- BatchNorm13
I0905 01:39:06.468569 90901 net.cpp:408] Convolution14 -> Convolution14
I0905 01:39:06.471146 90901 net.cpp:150] Setting up Convolution14
I0905 01:39:06.471168 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.471177 90901 net.cpp:165] Memory required for data: 1837891648
I0905 01:39:06.471190 90901 layer_factory.hpp:77] Creating layer Dropout14
I0905 01:39:06.471205 90901 net.cpp:100] Creating Layer Dropout14
I0905 01:39:06.471215 90901 net.cpp:434] Dropout14 <- Convolution14
I0905 01:39:06.471225 90901 net.cpp:408] Dropout14 -> Dropout14
I0905 01:39:06.471276 90901 net.cpp:150] Setting up Dropout14
I0905 01:39:06.471292 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.471302 90901 net.cpp:165] Memory required for data: 1879834688
I0905 01:39:06.471309 90901 layer_factory.hpp:77] Creating layer Pooling1
I0905 01:39:06.471324 90901 net.cpp:100] Creating Layer Pooling1
I0905 01:39:06.471333 90901 net.cpp:434] Pooling1 <- Dropout14
I0905 01:39:06.471343 90901 net.cpp:408] Pooling1 -> Pooling1
I0905 01:39:06.471699 90901 net.cpp:150] Setting up Pooling1
I0905 01:39:06.471719 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.471729 90901 net.cpp:165] Memory required for data: 1890320448
I0905 01:39:06.471737 90901 layer_factory.hpp:77] Creating layer Pooling1_Pooling1_0_split
I0905 01:39:06.471750 90901 net.cpp:100] Creating Layer Pooling1_Pooling1_0_split
I0905 01:39:06.471760 90901 net.cpp:434] Pooling1_Pooling1_0_split <- Pooling1
I0905 01:39:06.471771 90901 net.cpp:408] Pooling1_Pooling1_0_split -> Pooling1_Pooling1_0_split_0
I0905 01:39:06.471781 90901 net.cpp:408] Pooling1_Pooling1_0_split -> Pooling1_Pooling1_0_split_1
I0905 01:39:06.471827 90901 net.cpp:150] Setting up Pooling1_Pooling1_0_split
I0905 01:39:06.471839 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.471848 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.471856 90901 net.cpp:165] Memory required for data: 1911291968
I0905 01:39:06.471865 90901 layer_factory.hpp:77] Creating layer BatchNorm14
I0905 01:39:06.471881 90901 net.cpp:100] Creating Layer BatchNorm14
I0905 01:39:06.471890 90901 net.cpp:434] BatchNorm14 <- Pooling1_Pooling1_0_split_0
I0905 01:39:06.471901 90901 net.cpp:408] BatchNorm14 -> BatchNorm14
I0905 01:39:06.472103 90901 net.cpp:150] Setting up BatchNorm14
I0905 01:39:06.472118 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.472126 90901 net.cpp:165] Memory required for data: 1921777728
I0905 01:39:06.472139 90901 layer_factory.hpp:77] Creating layer Scale14
I0905 01:39:06.472154 90901 net.cpp:100] Creating Layer Scale14
I0905 01:39:06.472164 90901 net.cpp:434] Scale14 <- BatchNorm14
I0905 01:39:06.472174 90901 net.cpp:395] Scale14 -> BatchNorm14 (in-place)
I0905 01:39:06.472290 90901 net.cpp:150] Setting up Scale14
I0905 01:39:06.472311 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.472321 90901 net.cpp:165] Memory required for data: 1932263488
I0905 01:39:06.472334 90901 layer_factory.hpp:77] Creating layer ReLU14
I0905 01:39:06.472345 90901 net.cpp:100] Creating Layer ReLU14
I0905 01:39:06.472365 90901 net.cpp:434] ReLU14 <- BatchNorm14
I0905 01:39:06.472378 90901 net.cpp:395] ReLU14 -> BatchNorm14 (in-place)
I0905 01:39:06.472542 90901 net.cpp:150] Setting up ReLU14
I0905 01:39:06.472559 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.472568 90901 net.cpp:165] Memory required for data: 1942749248
I0905 01:39:06.472578 90901 layer_factory.hpp:77] Creating layer Convolution15
I0905 01:39:06.472594 90901 net.cpp:100] Creating Layer Convolution15
I0905 01:39:06.472604 90901 net.cpp:434] Convolution15 <- BatchNorm14
I0905 01:39:06.472615 90901 net.cpp:408] Convolution15 -> Convolution15
I0905 01:39:06.474166 90901 net.cpp:150] Setting up Convolution15
I0905 01:39:06.474187 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.474196 90901 net.cpp:165] Memory required for data: 1943535680
I0905 01:39:06.474208 90901 layer_factory.hpp:77] Creating layer Dropout15
I0905 01:39:06.474220 90901 net.cpp:100] Creating Layer Dropout15
I0905 01:39:06.474231 90901 net.cpp:434] Dropout15 <- Convolution15
I0905 01:39:06.474243 90901 net.cpp:408] Dropout15 -> Dropout15
I0905 01:39:06.474290 90901 net.cpp:150] Setting up Dropout15
I0905 01:39:06.474305 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.474314 90901 net.cpp:165] Memory required for data: 1944322112
I0905 01:39:06.474323 90901 layer_factory.hpp:77] Creating layer Concat13
I0905 01:39:06.474336 90901 net.cpp:100] Creating Layer Concat13
I0905 01:39:06.474346 90901 net.cpp:434] Concat13 <- Pooling1_Pooling1_0_split_1
I0905 01:39:06.474355 90901 net.cpp:434] Concat13 <- Dropout15
I0905 01:39:06.474370 90901 net.cpp:408] Concat13 -> Concat13
I0905 01:39:06.474401 90901 net.cpp:150] Setting up Concat13
I0905 01:39:06.474413 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.474422 90901 net.cpp:165] Memory required for data: 1955594304
I0905 01:39:06.474431 90901 layer_factory.hpp:77] Creating layer Concat13_Concat13_0_split
I0905 01:39:06.474442 90901 net.cpp:100] Creating Layer Concat13_Concat13_0_split
I0905 01:39:06.474450 90901 net.cpp:434] Concat13_Concat13_0_split <- Concat13
I0905 01:39:06.474462 90901 net.cpp:408] Concat13_Concat13_0_split -> Concat13_Concat13_0_split_0
I0905 01:39:06.474473 90901 net.cpp:408] Concat13_Concat13_0_split -> Concat13_Concat13_0_split_1
I0905 01:39:06.474514 90901 net.cpp:150] Setting up Concat13_Concat13_0_split
I0905 01:39:06.474526 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.474535 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.474544 90901 net.cpp:165] Memory required for data: 1978138688
I0905 01:39:06.474552 90901 layer_factory.hpp:77] Creating layer BatchNorm15
I0905 01:39:06.474566 90901 net.cpp:100] Creating Layer BatchNorm15
I0905 01:39:06.474575 90901 net.cpp:434] BatchNorm15 <- Concat13_Concat13_0_split_0
I0905 01:39:06.474586 90901 net.cpp:408] BatchNorm15 -> BatchNorm15
I0905 01:39:06.474810 90901 net.cpp:150] Setting up BatchNorm15
I0905 01:39:06.474825 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.474833 90901 net.cpp:165] Memory required for data: 1989410880
I0905 01:39:06.474846 90901 layer_factory.hpp:77] Creating layer Scale15
I0905 01:39:06.474858 90901 net.cpp:100] Creating Layer Scale15
I0905 01:39:06.474867 90901 net.cpp:434] Scale15 <- BatchNorm15
I0905 01:39:06.474879 90901 net.cpp:395] Scale15 -> BatchNorm15 (in-place)
I0905 01:39:06.474973 90901 net.cpp:150] Setting up Scale15
I0905 01:39:06.474988 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.475000 90901 net.cpp:165] Memory required for data: 2000683072
I0905 01:39:06.475015 90901 layer_factory.hpp:77] Creating layer ReLU15
I0905 01:39:06.475039 90901 net.cpp:100] Creating Layer ReLU15
I0905 01:39:06.475049 90901 net.cpp:434] ReLU15 <- BatchNorm15
I0905 01:39:06.475059 90901 net.cpp:395] ReLU15 -> BatchNorm15 (in-place)
I0905 01:39:06.475381 90901 net.cpp:150] Setting up ReLU15
I0905 01:39:06.475399 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.475409 90901 net.cpp:165] Memory required for data: 2011955264
I0905 01:39:06.475417 90901 layer_factory.hpp:77] Creating layer Convolution16
I0905 01:39:06.475436 90901 net.cpp:100] Creating Layer Convolution16
I0905 01:39:06.475446 90901 net.cpp:434] Convolution16 <- BatchNorm15
I0905 01:39:06.475461 90901 net.cpp:408] Convolution16 -> Convolution16
I0905 01:39:06.477046 90901 net.cpp:150] Setting up Convolution16
I0905 01:39:06.477067 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.477077 90901 net.cpp:165] Memory required for data: 2012741696
I0905 01:39:06.477089 90901 layer_factory.hpp:77] Creating layer Dropout16
I0905 01:39:06.477103 90901 net.cpp:100] Creating Layer Dropout16
I0905 01:39:06.477113 90901 net.cpp:434] Dropout16 <- Convolution16
I0905 01:39:06.477124 90901 net.cpp:408] Dropout16 -> Dropout16
I0905 01:39:06.477174 90901 net.cpp:150] Setting up Dropout16
I0905 01:39:06.477188 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.477200 90901 net.cpp:165] Memory required for data: 2013528128
I0905 01:39:06.477208 90901 layer_factory.hpp:77] Creating layer Concat14
I0905 01:39:06.477224 90901 net.cpp:100] Creating Layer Concat14
I0905 01:39:06.477233 90901 net.cpp:434] Concat14 <- Concat13_Concat13_0_split_1
I0905 01:39:06.477243 90901 net.cpp:434] Concat14 <- Dropout16
I0905 01:39:06.477264 90901 net.cpp:408] Concat14 -> Concat14
I0905 01:39:06.477293 90901 net.cpp:150] Setting up Concat14
I0905 01:39:06.477304 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.477314 90901 net.cpp:165] Memory required for data: 2025586752
I0905 01:39:06.477322 90901 layer_factory.hpp:77] Creating layer Concat14_Concat14_0_split
I0905 01:39:06.477335 90901 net.cpp:100] Creating Layer Concat14_Concat14_0_split
I0905 01:39:06.477344 90901 net.cpp:434] Concat14_Concat14_0_split <- Concat14
I0905 01:39:06.477356 90901 net.cpp:408] Concat14_Concat14_0_split -> Concat14_Concat14_0_split_0
I0905 01:39:06.477367 90901 net.cpp:408] Concat14_Concat14_0_split -> Concat14_Concat14_0_split_1
I0905 01:39:06.477407 90901 net.cpp:150] Setting up Concat14_Concat14_0_split
I0905 01:39:06.477428 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.477437 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.477445 90901 net.cpp:165] Memory required for data: 2049704000
I0905 01:39:06.477454 90901 layer_factory.hpp:77] Creating layer BatchNorm16
I0905 01:39:06.477466 90901 net.cpp:100] Creating Layer BatchNorm16
I0905 01:39:06.477475 90901 net.cpp:434] BatchNorm16 <- Concat14_Concat14_0_split_0
I0905 01:39:06.477486 90901 net.cpp:408] BatchNorm16 -> BatchNorm16
I0905 01:39:06.477679 90901 net.cpp:150] Setting up BatchNorm16
I0905 01:39:06.477694 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.477701 90901 net.cpp:165] Memory required for data: 2061762624
I0905 01:39:06.477713 90901 layer_factory.hpp:77] Creating layer Scale16
I0905 01:39:06.477728 90901 net.cpp:100] Creating Layer Scale16
I0905 01:39:06.477737 90901 net.cpp:434] Scale16 <- BatchNorm16
I0905 01:39:06.477751 90901 net.cpp:395] Scale16 -> BatchNorm16 (in-place)
I0905 01:39:06.477844 90901 net.cpp:150] Setting up Scale16
I0905 01:39:06.477867 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.477877 90901 net.cpp:165] Memory required for data: 2073821248
I0905 01:39:06.477890 90901 layer_factory.hpp:77] Creating layer ReLU16
I0905 01:39:06.477900 90901 net.cpp:100] Creating Layer ReLU16
I0905 01:39:06.477919 90901 net.cpp:434] ReLU16 <- BatchNorm16
I0905 01:39:06.477931 90901 net.cpp:395] ReLU16 -> BatchNorm16 (in-place)
I0905 01:39:06.478241 90901 net.cpp:150] Setting up ReLU16
I0905 01:39:06.478260 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.478281 90901 net.cpp:165] Memory required for data: 2085879872
I0905 01:39:06.478291 90901 layer_factory.hpp:77] Creating layer Convolution17
I0905 01:39:06.478309 90901 net.cpp:100] Creating Layer Convolution17
I0905 01:39:06.478319 90901 net.cpp:434] Convolution17 <- BatchNorm16
I0905 01:39:06.478340 90901 net.cpp:408] Convolution17 -> Convolution17
I0905 01:39:06.479976 90901 net.cpp:150] Setting up Convolution17
I0905 01:39:06.480005 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.480015 90901 net.cpp:165] Memory required for data: 2086666304
I0905 01:39:06.480026 90901 layer_factory.hpp:77] Creating layer Dropout17
I0905 01:39:06.480039 90901 net.cpp:100] Creating Layer Dropout17
I0905 01:39:06.480048 90901 net.cpp:434] Dropout17 <- Convolution17
I0905 01:39:06.480062 90901 net.cpp:408] Dropout17 -> Dropout17
I0905 01:39:06.480116 90901 net.cpp:150] Setting up Dropout17
I0905 01:39:06.480130 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.480139 90901 net.cpp:165] Memory required for data: 2087452736
I0905 01:39:06.480149 90901 layer_factory.hpp:77] Creating layer Concat15
I0905 01:39:06.480165 90901 net.cpp:100] Creating Layer Concat15
I0905 01:39:06.480175 90901 net.cpp:434] Concat15 <- Concat14_Concat14_0_split_1
I0905 01:39:06.480195 90901 net.cpp:434] Concat15 <- Dropout17
I0905 01:39:06.480204 90901 net.cpp:408] Concat15 -> Concat15
I0905 01:39:06.480237 90901 net.cpp:150] Setting up Concat15
I0905 01:39:06.480248 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.480257 90901 net.cpp:165] Memory required for data: 2100297792
I0905 01:39:06.480265 90901 layer_factory.hpp:77] Creating layer Concat15_Concat15_0_split
I0905 01:39:06.480275 90901 net.cpp:100] Creating Layer Concat15_Concat15_0_split
I0905 01:39:06.480284 90901 net.cpp:434] Concat15_Concat15_0_split <- Concat15
I0905 01:39:06.480298 90901 net.cpp:408] Concat15_Concat15_0_split -> Concat15_Concat15_0_split_0
I0905 01:39:06.480309 90901 net.cpp:408] Concat15_Concat15_0_split -> Concat15_Concat15_0_split_1
I0905 01:39:06.480348 90901 net.cpp:150] Setting up Concat15_Concat15_0_split
I0905 01:39:06.480362 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.480372 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.480383 90901 net.cpp:165] Memory required for data: 2125987904
I0905 01:39:06.480391 90901 layer_factory.hpp:77] Creating layer BatchNorm17
I0905 01:39:06.480402 90901 net.cpp:100] Creating Layer BatchNorm17
I0905 01:39:06.480412 90901 net.cpp:434] BatchNorm17 <- Concat15_Concat15_0_split_0
I0905 01:39:06.480424 90901 net.cpp:408] BatchNorm17 -> BatchNorm17
I0905 01:39:06.480625 90901 net.cpp:150] Setting up BatchNorm17
I0905 01:39:06.480639 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.480648 90901 net.cpp:165] Memory required for data: 2138832960
I0905 01:39:06.480660 90901 layer_factory.hpp:77] Creating layer Scale17
I0905 01:39:06.480674 90901 net.cpp:100] Creating Layer Scale17
I0905 01:39:06.480697 90901 net.cpp:434] Scale17 <- BatchNorm17
I0905 01:39:06.480707 90901 net.cpp:395] Scale17 -> BatchNorm17 (in-place)
I0905 01:39:06.480815 90901 net.cpp:150] Setting up Scale17
I0905 01:39:06.480836 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.480845 90901 net.cpp:165] Memory required for data: 2151678016
I0905 01:39:06.480857 90901 layer_factory.hpp:77] Creating layer ReLU17
I0905 01:39:06.480870 90901 net.cpp:100] Creating Layer ReLU17
I0905 01:39:06.480880 90901 net.cpp:434] ReLU17 <- BatchNorm17
I0905 01:39:06.480890 90901 net.cpp:395] ReLU17 -> BatchNorm17 (in-place)
I0905 01:39:06.481068 90901 net.cpp:150] Setting up ReLU17
I0905 01:39:06.481084 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.481097 90901 net.cpp:165] Memory required for data: 2164523072
I0905 01:39:06.481107 90901 layer_factory.hpp:77] Creating layer Convolution18
I0905 01:39:06.481123 90901 net.cpp:100] Creating Layer Convolution18
I0905 01:39:06.481133 90901 net.cpp:434] Convolution18 <- BatchNorm17
I0905 01:39:06.481163 90901 net.cpp:408] Convolution18 -> Convolution18
I0905 01:39:06.482882 90901 net.cpp:150] Setting up Convolution18
I0905 01:39:06.482905 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.482914 90901 net.cpp:165] Memory required for data: 2165309504
I0905 01:39:06.482928 90901 layer_factory.hpp:77] Creating layer Dropout18
I0905 01:39:06.482939 90901 net.cpp:100] Creating Layer Dropout18
I0905 01:39:06.482950 90901 net.cpp:434] Dropout18 <- Convolution18
I0905 01:39:06.482964 90901 net.cpp:408] Dropout18 -> Dropout18
I0905 01:39:06.483023 90901 net.cpp:150] Setting up Dropout18
I0905 01:39:06.483037 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.483047 90901 net.cpp:165] Memory required for data: 2166095936
I0905 01:39:06.483055 90901 layer_factory.hpp:77] Creating layer Concat16
I0905 01:39:06.483073 90901 net.cpp:100] Creating Layer Concat16
I0905 01:39:06.483083 90901 net.cpp:434] Concat16 <- Concat15_Concat15_0_split_1
I0905 01:39:06.483100 90901 net.cpp:434] Concat16 <- Dropout18
I0905 01:39:06.483109 90901 net.cpp:408] Concat16 -> Concat16
I0905 01:39:06.483142 90901 net.cpp:150] Setting up Concat16
I0905 01:39:06.483155 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.483163 90901 net.cpp:165] Memory required for data: 2179727424
I0905 01:39:06.483171 90901 layer_factory.hpp:77] Creating layer Concat16_Concat16_0_split
I0905 01:39:06.483181 90901 net.cpp:100] Creating Layer Concat16_Concat16_0_split
I0905 01:39:06.483191 90901 net.cpp:434] Concat16_Concat16_0_split <- Concat16
I0905 01:39:06.483202 90901 net.cpp:408] Concat16_Concat16_0_split -> Concat16_Concat16_0_split_0
I0905 01:39:06.483214 90901 net.cpp:408] Concat16_Concat16_0_split -> Concat16_Concat16_0_split_1
I0905 01:39:06.483255 90901 net.cpp:150] Setting up Concat16_Concat16_0_split
I0905 01:39:06.483269 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.483278 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.483286 90901 net.cpp:165] Memory required for data: 2206990400
I0905 01:39:06.483294 90901 layer_factory.hpp:77] Creating layer BatchNorm18
I0905 01:39:06.483305 90901 net.cpp:100] Creating Layer BatchNorm18
I0905 01:39:06.483314 90901 net.cpp:434] BatchNorm18 <- Concat16_Concat16_0_split_0
I0905 01:39:06.483330 90901 net.cpp:408] BatchNorm18 -> BatchNorm18
I0905 01:39:06.483530 90901 net.cpp:150] Setting up BatchNorm18
I0905 01:39:06.483544 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.483552 90901 net.cpp:165] Memory required for data: 2220621888
I0905 01:39:06.483566 90901 layer_factory.hpp:77] Creating layer Scale18
I0905 01:39:06.483579 90901 net.cpp:100] Creating Layer Scale18
I0905 01:39:06.483589 90901 net.cpp:434] Scale18 <- BatchNorm18
I0905 01:39:06.483599 90901 net.cpp:395] Scale18 -> BatchNorm18 (in-place)
I0905 01:39:06.483693 90901 net.cpp:150] Setting up Scale18
I0905 01:39:06.483716 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.483723 90901 net.cpp:165] Memory required for data: 2234253376
I0905 01:39:06.483734 90901 layer_factory.hpp:77] Creating layer ReLU18
I0905 01:39:06.483747 90901 net.cpp:100] Creating Layer ReLU18
I0905 01:39:06.483757 90901 net.cpp:434] ReLU18 <- BatchNorm18
I0905 01:39:06.483767 90901 net.cpp:395] ReLU18 -> BatchNorm18 (in-place)
I0905 01:39:06.484088 90901 net.cpp:150] Setting up ReLU18
I0905 01:39:06.484107 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.484117 90901 net.cpp:165] Memory required for data: 2247884864
I0905 01:39:06.484125 90901 layer_factory.hpp:77] Creating layer Convolution19
I0905 01:39:06.484144 90901 net.cpp:100] Creating Layer Convolution19
I0905 01:39:06.484153 90901 net.cpp:434] Convolution19 <- BatchNorm18
I0905 01:39:06.484166 90901 net.cpp:408] Convolution19 -> Convolution19
I0905 01:39:06.485740 90901 net.cpp:150] Setting up Convolution19
I0905 01:39:06.485762 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.485771 90901 net.cpp:165] Memory required for data: 2248671296
I0905 01:39:06.485800 90901 layer_factory.hpp:77] Creating layer Dropout19
I0905 01:39:06.485813 90901 net.cpp:100] Creating Layer Dropout19
I0905 01:39:06.485831 90901 net.cpp:434] Dropout19 <- Convolution19
I0905 01:39:06.485847 90901 net.cpp:408] Dropout19 -> Dropout19
I0905 01:39:06.485899 90901 net.cpp:150] Setting up Dropout19
I0905 01:39:06.485914 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.485923 90901 net.cpp:165] Memory required for data: 2249457728
I0905 01:39:06.485931 90901 layer_factory.hpp:77] Creating layer Concat17
I0905 01:39:06.485947 90901 net.cpp:100] Creating Layer Concat17
I0905 01:39:06.485956 90901 net.cpp:434] Concat17 <- Concat16_Concat16_0_split_1
I0905 01:39:06.485966 90901 net.cpp:434] Concat17 <- Dropout19
I0905 01:39:06.485987 90901 net.cpp:408] Concat17 -> Concat17
I0905 01:39:06.486019 90901 net.cpp:150] Setting up Concat17
I0905 01:39:06.486032 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.486040 90901 net.cpp:165] Memory required for data: 2263875648
I0905 01:39:06.486048 90901 layer_factory.hpp:77] Creating layer Concat17_Concat17_0_split
I0905 01:39:06.486071 90901 net.cpp:100] Creating Layer Concat17_Concat17_0_split
I0905 01:39:06.486081 90901 net.cpp:434] Concat17_Concat17_0_split <- Concat17
I0905 01:39:06.486093 90901 net.cpp:408] Concat17_Concat17_0_split -> Concat17_Concat17_0_split_0
I0905 01:39:06.486104 90901 net.cpp:408] Concat17_Concat17_0_split -> Concat17_Concat17_0_split_1
I0905 01:39:06.486150 90901 net.cpp:150] Setting up Concat17_Concat17_0_split
I0905 01:39:06.486161 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.486171 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.486179 90901 net.cpp:165] Memory required for data: 2292711488
I0905 01:39:06.486187 90901 layer_factory.hpp:77] Creating layer BatchNorm19
I0905 01:39:06.486202 90901 net.cpp:100] Creating Layer BatchNorm19
I0905 01:39:06.486210 90901 net.cpp:434] BatchNorm19 <- Concat17_Concat17_0_split_0
I0905 01:39:06.486220 90901 net.cpp:408] BatchNorm19 -> BatchNorm19
I0905 01:39:06.486425 90901 net.cpp:150] Setting up BatchNorm19
I0905 01:39:06.486439 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.486449 90901 net.cpp:165] Memory required for data: 2307129408
I0905 01:39:06.486461 90901 layer_factory.hpp:77] Creating layer Scale19
I0905 01:39:06.486475 90901 net.cpp:100] Creating Layer Scale19
I0905 01:39:06.486485 90901 net.cpp:434] Scale19 <- BatchNorm19
I0905 01:39:06.486495 90901 net.cpp:395] Scale19 -> BatchNorm19 (in-place)
I0905 01:39:06.486593 90901 net.cpp:150] Setting up Scale19
I0905 01:39:06.486613 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.486621 90901 net.cpp:165] Memory required for data: 2321547328
I0905 01:39:06.486647 90901 layer_factory.hpp:77] Creating layer ReLU19
I0905 01:39:06.486661 90901 net.cpp:100] Creating Layer ReLU19
I0905 01:39:06.486685 90901 net.cpp:434] ReLU19 <- BatchNorm19
I0905 01:39:06.486697 90901 net.cpp:395] ReLU19 -> BatchNorm19 (in-place)
I0905 01:39:06.487025 90901 net.cpp:150] Setting up ReLU19
I0905 01:39:06.487045 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.487053 90901 net.cpp:165] Memory required for data: 2335965248
I0905 01:39:06.487062 90901 layer_factory.hpp:77] Creating layer Convolution20
I0905 01:39:06.487079 90901 net.cpp:100] Creating Layer Convolution20
I0905 01:39:06.487090 90901 net.cpp:434] Convolution20 <- BatchNorm19
I0905 01:39:06.487103 90901 net.cpp:408] Convolution20 -> Convolution20
I0905 01:39:06.488829 90901 net.cpp:150] Setting up Convolution20
I0905 01:39:06.488849 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.488858 90901 net.cpp:165] Memory required for data: 2336751680
I0905 01:39:06.488870 90901 layer_factory.hpp:77] Creating layer Dropout20
I0905 01:39:06.488884 90901 net.cpp:100] Creating Layer Dropout20
I0905 01:39:06.488894 90901 net.cpp:434] Dropout20 <- Convolution20
I0905 01:39:06.488905 90901 net.cpp:408] Dropout20 -> Dropout20
I0905 01:39:06.488960 90901 net.cpp:150] Setting up Dropout20
I0905 01:39:06.488986 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.488994 90901 net.cpp:165] Memory required for data: 2337538112
I0905 01:39:06.489007 90901 layer_factory.hpp:77] Creating layer Concat18
I0905 01:39:06.489019 90901 net.cpp:100] Creating Layer Concat18
I0905 01:39:06.489030 90901 net.cpp:434] Concat18 <- Concat17_Concat17_0_split_1
I0905 01:39:06.489048 90901 net.cpp:434] Concat18 <- Dropout20
I0905 01:39:06.489058 90901 net.cpp:408] Concat18 -> Concat18
I0905 01:39:06.489089 90901 net.cpp:150] Setting up Concat18
I0905 01:39:06.489102 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.489114 90901 net.cpp:165] Memory required for data: 2352742464
I0905 01:39:06.489122 90901 layer_factory.hpp:77] Creating layer Concat18_Concat18_0_split
I0905 01:39:06.489137 90901 net.cpp:100] Creating Layer Concat18_Concat18_0_split
I0905 01:39:06.489146 90901 net.cpp:434] Concat18_Concat18_0_split <- Concat18
I0905 01:39:06.489162 90901 net.cpp:408] Concat18_Concat18_0_split -> Concat18_Concat18_0_split_0
I0905 01:39:06.489181 90901 net.cpp:408] Concat18_Concat18_0_split -> Concat18_Concat18_0_split_1
I0905 01:39:06.489223 90901 net.cpp:150] Setting up Concat18_Concat18_0_split
I0905 01:39:06.489234 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.489244 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.489253 90901 net.cpp:165] Memory required for data: 2383151168
I0905 01:39:06.489261 90901 layer_factory.hpp:77] Creating layer BatchNorm20
I0905 01:39:06.489274 90901 net.cpp:100] Creating Layer BatchNorm20
I0905 01:39:06.489282 90901 net.cpp:434] BatchNorm20 <- Concat18_Concat18_0_split_0
I0905 01:39:06.489294 90901 net.cpp:408] BatchNorm20 -> BatchNorm20
I0905 01:39:06.489495 90901 net.cpp:150] Setting up BatchNorm20
I0905 01:39:06.489509 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.489518 90901 net.cpp:165] Memory required for data: 2398355520
I0905 01:39:06.489531 90901 layer_factory.hpp:77] Creating layer Scale20
I0905 01:39:06.489545 90901 net.cpp:100] Creating Layer Scale20
I0905 01:39:06.489554 90901 net.cpp:434] Scale20 <- BatchNorm20
I0905 01:39:06.489565 90901 net.cpp:395] Scale20 -> BatchNorm20 (in-place)
I0905 01:39:06.489660 90901 net.cpp:150] Setting up Scale20
I0905 01:39:06.489675 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.489684 90901 net.cpp:165] Memory required for data: 2413559872
I0905 01:39:06.489697 90901 layer_factory.hpp:77] Creating layer ReLU20
I0905 01:39:06.489708 90901 net.cpp:100] Creating Layer ReLU20
I0905 01:39:06.489719 90901 net.cpp:434] ReLU20 <- BatchNorm20
I0905 01:39:06.489732 90901 net.cpp:395] ReLU20 -> BatchNorm20 (in-place)
I0905 01:39:06.489914 90901 net.cpp:150] Setting up ReLU20
I0905 01:39:06.489930 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.489938 90901 net.cpp:165] Memory required for data: 2428764224
I0905 01:39:06.489948 90901 layer_factory.hpp:77] Creating layer Convolution21
I0905 01:39:06.489966 90901 net.cpp:100] Creating Layer Convolution21
I0905 01:39:06.489975 90901 net.cpp:434] Convolution21 <- BatchNorm20
I0905 01:39:06.489989 90901 net.cpp:408] Convolution21 -> Convolution21
I0905 01:39:06.491788 90901 net.cpp:150] Setting up Convolution21
I0905 01:39:06.491809 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.491819 90901 net.cpp:165] Memory required for data: 2429550656
I0905 01:39:06.491832 90901 layer_factory.hpp:77] Creating layer Dropout21
I0905 01:39:06.491847 90901 net.cpp:100] Creating Layer Dropout21
I0905 01:39:06.491857 90901 net.cpp:434] Dropout21 <- Convolution21
I0905 01:39:06.491868 90901 net.cpp:408] Dropout21 -> Dropout21
I0905 01:39:06.491930 90901 net.cpp:150] Setting up Dropout21
I0905 01:39:06.491943 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.491955 90901 net.cpp:165] Memory required for data: 2430337088
I0905 01:39:06.491963 90901 layer_factory.hpp:77] Creating layer Concat19
I0905 01:39:06.491982 90901 net.cpp:100] Creating Layer Concat19
I0905 01:39:06.492012 90901 net.cpp:434] Concat19 <- Concat18_Concat18_0_split_1
I0905 01:39:06.492027 90901 net.cpp:434] Concat19 <- Dropout21
I0905 01:39:06.492036 90901 net.cpp:408] Concat19 -> Concat19
I0905 01:39:06.492069 90901 net.cpp:150] Setting up Concat19
I0905 01:39:06.492082 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.492091 90901 net.cpp:165] Memory required for data: 2446327872
I0905 01:39:06.492103 90901 layer_factory.hpp:77] Creating layer Concat19_Concat19_0_split
I0905 01:39:06.492117 90901 net.cpp:100] Creating Layer Concat19_Concat19_0_split
I0905 01:39:06.492125 90901 net.cpp:434] Concat19_Concat19_0_split <- Concat19
I0905 01:39:06.492139 90901 net.cpp:408] Concat19_Concat19_0_split -> Concat19_Concat19_0_split_0
I0905 01:39:06.492152 90901 net.cpp:408] Concat19_Concat19_0_split -> Concat19_Concat19_0_split_1
I0905 01:39:06.492194 90901 net.cpp:150] Setting up Concat19_Concat19_0_split
I0905 01:39:06.492207 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.492223 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.492233 90901 net.cpp:165] Memory required for data: 2478309440
I0905 01:39:06.492240 90901 layer_factory.hpp:77] Creating layer BatchNorm21
I0905 01:39:06.492254 90901 net.cpp:100] Creating Layer BatchNorm21
I0905 01:39:06.492264 90901 net.cpp:434] BatchNorm21 <- Concat19_Concat19_0_split_0
I0905 01:39:06.492274 90901 net.cpp:408] BatchNorm21 -> BatchNorm21
I0905 01:39:06.492478 90901 net.cpp:150] Setting up BatchNorm21
I0905 01:39:06.492493 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.492502 90901 net.cpp:165] Memory required for data: 2494300224
I0905 01:39:06.492514 90901 layer_factory.hpp:77] Creating layer Scale21
I0905 01:39:06.492532 90901 net.cpp:100] Creating Layer Scale21
I0905 01:39:06.492540 90901 net.cpp:434] Scale21 <- BatchNorm21
I0905 01:39:06.492550 90901 net.cpp:395] Scale21 -> BatchNorm21 (in-place)
I0905 01:39:06.492648 90901 net.cpp:150] Setting up Scale21
I0905 01:39:06.492671 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.492681 90901 net.cpp:165] Memory required for data: 2510291008
I0905 01:39:06.492691 90901 layer_factory.hpp:77] Creating layer ReLU21
I0905 01:39:06.492703 90901 net.cpp:100] Creating Layer ReLU21
I0905 01:39:06.492712 90901 net.cpp:434] ReLU21 <- BatchNorm21
I0905 01:39:06.492723 90901 net.cpp:395] ReLU21 -> BatchNorm21 (in-place)
I0905 01:39:06.493051 90901 net.cpp:150] Setting up ReLU21
I0905 01:39:06.493069 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.493077 90901 net.cpp:165] Memory required for data: 2526281792
I0905 01:39:06.493086 90901 layer_factory.hpp:77] Creating layer Convolution22
I0905 01:39:06.493108 90901 net.cpp:100] Creating Layer Convolution22
I0905 01:39:06.493118 90901 net.cpp:434] Convolution22 <- BatchNorm21
I0905 01:39:06.493129 90901 net.cpp:408] Convolution22 -> Convolution22
I0905 01:39:06.494838 90901 net.cpp:150] Setting up Convolution22
I0905 01:39:06.494859 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.494868 90901 net.cpp:165] Memory required for data: 2527068224
I0905 01:39:06.494880 90901 layer_factory.hpp:77] Creating layer Dropout22
I0905 01:39:06.494895 90901 net.cpp:100] Creating Layer Dropout22
I0905 01:39:06.494904 90901 net.cpp:434] Dropout22 <- Convolution22
I0905 01:39:06.494918 90901 net.cpp:408] Dropout22 -> Dropout22
I0905 01:39:06.494968 90901 net.cpp:150] Setting up Dropout22
I0905 01:39:06.494982 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.494992 90901 net.cpp:165] Memory required for data: 2527854656
I0905 01:39:06.494999 90901 layer_factory.hpp:77] Creating layer Concat20
I0905 01:39:06.495013 90901 net.cpp:100] Creating Layer Concat20
I0905 01:39:06.495023 90901 net.cpp:434] Concat20 <- Concat19_Concat19_0_split_1
I0905 01:39:06.495031 90901 net.cpp:434] Concat20 <- Dropout22
I0905 01:39:06.495043 90901 net.cpp:408] Concat20 -> Concat20
I0905 01:39:06.495088 90901 net.cpp:150] Setting up Concat20
I0905 01:39:06.495120 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.495127 90901 net.cpp:165] Memory required for data: 2544631872
I0905 01:39:06.495139 90901 layer_factory.hpp:77] Creating layer Concat20_Concat20_0_split
I0905 01:39:06.495149 90901 net.cpp:100] Creating Layer Concat20_Concat20_0_split
I0905 01:39:06.495157 90901 net.cpp:434] Concat20_Concat20_0_split <- Concat20
I0905 01:39:06.495172 90901 net.cpp:408] Concat20_Concat20_0_split -> Concat20_Concat20_0_split_0
I0905 01:39:06.495196 90901 net.cpp:408] Concat20_Concat20_0_split -> Concat20_Concat20_0_split_1
I0905 01:39:06.495244 90901 net.cpp:150] Setting up Concat20_Concat20_0_split
I0905 01:39:06.495256 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.495266 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.495275 90901 net.cpp:165] Memory required for data: 2578186304
I0905 01:39:06.495282 90901 layer_factory.hpp:77] Creating layer BatchNorm22
I0905 01:39:06.495296 90901 net.cpp:100] Creating Layer BatchNorm22
I0905 01:39:06.495306 90901 net.cpp:434] BatchNorm22 <- Concat20_Concat20_0_split_0
I0905 01:39:06.495317 90901 net.cpp:408] BatchNorm22 -> BatchNorm22
I0905 01:39:06.495512 90901 net.cpp:150] Setting up BatchNorm22
I0905 01:39:06.495525 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.495534 90901 net.cpp:165] Memory required for data: 2594963520
I0905 01:39:06.495564 90901 layer_factory.hpp:77] Creating layer Scale22
I0905 01:39:06.495579 90901 net.cpp:100] Creating Layer Scale22
I0905 01:39:06.495589 90901 net.cpp:434] Scale22 <- BatchNorm22
I0905 01:39:06.495599 90901 net.cpp:395] Scale22 -> BatchNorm22 (in-place)
I0905 01:39:06.495693 90901 net.cpp:150] Setting up Scale22
I0905 01:39:06.495707 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.495718 90901 net.cpp:165] Memory required for data: 2611740736
I0905 01:39:06.495728 90901 layer_factory.hpp:77] Creating layer ReLU22
I0905 01:39:06.495740 90901 net.cpp:100] Creating Layer ReLU22
I0905 01:39:06.495749 90901 net.cpp:434] ReLU22 <- BatchNorm22
I0905 01:39:06.495764 90901 net.cpp:395] ReLU22 -> BatchNorm22 (in-place)
I0905 01:39:06.496248 90901 net.cpp:150] Setting up ReLU22
I0905 01:39:06.496266 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.496275 90901 net.cpp:165] Memory required for data: 2628517952
I0905 01:39:06.496284 90901 layer_factory.hpp:77] Creating layer Convolution23
I0905 01:39:06.496304 90901 net.cpp:100] Creating Layer Convolution23
I0905 01:39:06.496312 90901 net.cpp:434] Convolution23 <- BatchNorm22
I0905 01:39:06.496327 90901 net.cpp:408] Convolution23 -> Convolution23
I0905 01:39:06.498193 90901 net.cpp:150] Setting up Convolution23
I0905 01:39:06.498214 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.498224 90901 net.cpp:165] Memory required for data: 2629304384
I0905 01:39:06.498235 90901 layer_factory.hpp:77] Creating layer Dropout23
I0905 01:39:06.498247 90901 net.cpp:100] Creating Layer Dropout23
I0905 01:39:06.498257 90901 net.cpp:434] Dropout23 <- Convolution23
I0905 01:39:06.498270 90901 net.cpp:408] Dropout23 -> Dropout23
I0905 01:39:06.498320 90901 net.cpp:150] Setting up Dropout23
I0905 01:39:06.498335 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.498347 90901 net.cpp:165] Memory required for data: 2630090816
I0905 01:39:06.498355 90901 layer_factory.hpp:77] Creating layer Concat21
I0905 01:39:06.498368 90901 net.cpp:100] Creating Layer Concat21
I0905 01:39:06.498378 90901 net.cpp:434] Concat21 <- Concat20_Concat20_0_split_1
I0905 01:39:06.498388 90901 net.cpp:434] Concat21 <- Dropout23
I0905 01:39:06.498412 90901 net.cpp:408] Concat21 -> Concat21
I0905 01:39:06.498447 90901 net.cpp:150] Setting up Concat21
I0905 01:39:06.498461 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.498469 90901 net.cpp:165] Memory required for data: 2647654464
I0905 01:39:06.498478 90901 layer_factory.hpp:77] Creating layer Concat21_Concat21_0_split
I0905 01:39:06.498489 90901 net.cpp:100] Creating Layer Concat21_Concat21_0_split
I0905 01:39:06.498512 90901 net.cpp:434] Concat21_Concat21_0_split <- Concat21
I0905 01:39:06.498524 90901 net.cpp:408] Concat21_Concat21_0_split -> Concat21_Concat21_0_split_0
I0905 01:39:06.498538 90901 net.cpp:408] Concat21_Concat21_0_split -> Concat21_Concat21_0_split_1
I0905 01:39:06.498581 90901 net.cpp:150] Setting up Concat21_Concat21_0_split
I0905 01:39:06.498594 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.498603 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.498611 90901 net.cpp:165] Memory required for data: 2682781760
I0905 01:39:06.498620 90901 layer_factory.hpp:77] Creating layer BatchNorm23
I0905 01:39:06.498651 90901 net.cpp:100] Creating Layer BatchNorm23
I0905 01:39:06.498674 90901 net.cpp:434] BatchNorm23 <- Concat21_Concat21_0_split_0
I0905 01:39:06.498704 90901 net.cpp:408] BatchNorm23 -> BatchNorm23
I0905 01:39:06.498956 90901 net.cpp:150] Setting up BatchNorm23
I0905 01:39:06.498971 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.498980 90901 net.cpp:165] Memory required for data: 2700345408
I0905 01:39:06.498996 90901 layer_factory.hpp:77] Creating layer Scale23
I0905 01:39:06.499009 90901 net.cpp:100] Creating Layer Scale23
I0905 01:39:06.499018 90901 net.cpp:434] Scale23 <- BatchNorm23
I0905 01:39:06.499030 90901 net.cpp:395] Scale23 -> BatchNorm23 (in-place)
I0905 01:39:06.499126 90901 net.cpp:150] Setting up Scale23
I0905 01:39:06.499142 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.499151 90901 net.cpp:165] Memory required for data: 2717909056
I0905 01:39:06.499162 90901 layer_factory.hpp:77] Creating layer ReLU23
I0905 01:39:06.499173 90901 net.cpp:100] Creating Layer ReLU23
I0905 01:39:06.499182 90901 net.cpp:434] ReLU23 <- BatchNorm23
I0905 01:39:06.499191 90901 net.cpp:395] ReLU23 -> BatchNorm23 (in-place)
I0905 01:39:06.499369 90901 net.cpp:150] Setting up ReLU23
I0905 01:39:06.499387 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.499395 90901 net.cpp:165] Memory required for data: 2735472704
I0905 01:39:06.499416 90901 layer_factory.hpp:77] Creating layer Convolution24
I0905 01:39:06.499433 90901 net.cpp:100] Creating Layer Convolution24
I0905 01:39:06.499444 90901 net.cpp:434] Convolution24 <- BatchNorm23
I0905 01:39:06.499457 90901 net.cpp:408] Convolution24 -> Convolution24
I0905 01:39:06.501377 90901 net.cpp:150] Setting up Convolution24
I0905 01:39:06.501399 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.501408 90901 net.cpp:165] Memory required for data: 2736259136
I0905 01:39:06.501420 90901 layer_factory.hpp:77] Creating layer Dropout24
I0905 01:39:06.501435 90901 net.cpp:100] Creating Layer Dropout24
I0905 01:39:06.501444 90901 net.cpp:434] Dropout24 <- Convolution24
I0905 01:39:06.501456 90901 net.cpp:408] Dropout24 -> Dropout24
I0905 01:39:06.501508 90901 net.cpp:150] Setting up Dropout24
I0905 01:39:06.501523 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.501533 90901 net.cpp:165] Memory required for data: 2737045568
I0905 01:39:06.501541 90901 layer_factory.hpp:77] Creating layer Concat22
I0905 01:39:06.501552 90901 net.cpp:100] Creating Layer Concat22
I0905 01:39:06.501561 90901 net.cpp:434] Concat22 <- Concat21_Concat21_0_split_1
I0905 01:39:06.501572 90901 net.cpp:434] Concat22 <- Dropout24
I0905 01:39:06.501596 90901 net.cpp:408] Concat22 -> Concat22
I0905 01:39:06.501626 90901 net.cpp:150] Setting up Concat22
I0905 01:39:06.501644 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.501653 90901 net.cpp:165] Memory required for data: 2755395648
I0905 01:39:06.501662 90901 layer_factory.hpp:77] Creating layer Concat22_Concat22_0_split
I0905 01:39:06.501672 90901 net.cpp:100] Creating Layer Concat22_Concat22_0_split
I0905 01:39:06.501680 90901 net.cpp:434] Concat22_Concat22_0_split <- Concat22
I0905 01:39:06.501690 90901 net.cpp:408] Concat22_Concat22_0_split -> Concat22_Concat22_0_split_0
I0905 01:39:06.501701 90901 net.cpp:408] Concat22_Concat22_0_split -> Concat22_Concat22_0_split_1
I0905 01:39:06.501749 90901 net.cpp:150] Setting up Concat22_Concat22_0_split
I0905 01:39:06.501775 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.501785 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.501793 90901 net.cpp:165] Memory required for data: 2792095808
I0905 01:39:06.501802 90901 layer_factory.hpp:77] Creating layer BatchNorm24
I0905 01:39:06.501816 90901 net.cpp:100] Creating Layer BatchNorm24
I0905 01:39:06.501828 90901 net.cpp:434] BatchNorm24 <- Concat22_Concat22_0_split_0
I0905 01:39:06.501838 90901 net.cpp:408] BatchNorm24 -> BatchNorm24
I0905 01:39:06.502054 90901 net.cpp:150] Setting up BatchNorm24
I0905 01:39:06.502068 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.502076 90901 net.cpp:165] Memory required for data: 2810445888
I0905 01:39:06.502089 90901 layer_factory.hpp:77] Creating layer Scale24
I0905 01:39:06.502101 90901 net.cpp:100] Creating Layer Scale24
I0905 01:39:06.502110 90901 net.cpp:434] Scale24 <- BatchNorm24
I0905 01:39:06.502121 90901 net.cpp:395] Scale24 -> BatchNorm24 (in-place)
I0905 01:39:06.502218 90901 net.cpp:150] Setting up Scale24
I0905 01:39:06.502233 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.502240 90901 net.cpp:165] Memory required for data: 2828795968
I0905 01:39:06.502250 90901 layer_factory.hpp:77] Creating layer ReLU24
I0905 01:39:06.502261 90901 net.cpp:100] Creating Layer ReLU24
I0905 01:39:06.502270 90901 net.cpp:434] ReLU24 <- BatchNorm24
I0905 01:39:06.502282 90901 net.cpp:395] ReLU24 -> BatchNorm24 (in-place)
I0905 01:39:06.502605 90901 net.cpp:150] Setting up ReLU24
I0905 01:39:06.502624 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.502637 90901 net.cpp:165] Memory required for data: 2847146048
I0905 01:39:06.502661 90901 layer_factory.hpp:77] Creating layer Convolution25
I0905 01:39:06.502678 90901 net.cpp:100] Creating Layer Convolution25
I0905 01:39:06.502688 90901 net.cpp:434] Convolution25 <- BatchNorm24
I0905 01:39:06.502714 90901 net.cpp:408] Convolution25 -> Convolution25
I0905 01:39:06.505252 90901 net.cpp:150] Setting up Convolution25
I0905 01:39:06.505276 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.505286 90901 net.cpp:165] Memory required for data: 2847932480
I0905 01:39:06.505298 90901 layer_factory.hpp:77] Creating layer Dropout25
I0905 01:39:06.505311 90901 net.cpp:100] Creating Layer Dropout25
I0905 01:39:06.505319 90901 net.cpp:434] Dropout25 <- Convolution25
I0905 01:39:06.505331 90901 net.cpp:408] Dropout25 -> Dropout25
I0905 01:39:06.505383 90901 net.cpp:150] Setting up Dropout25
I0905 01:39:06.505398 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.505409 90901 net.cpp:165] Memory required for data: 2848718912
I0905 01:39:06.505417 90901 layer_factory.hpp:77] Creating layer Concat23
I0905 01:39:06.505431 90901 net.cpp:100] Creating Layer Concat23
I0905 01:39:06.505440 90901 net.cpp:434] Concat23 <- Concat22_Concat22_0_split_1
I0905 01:39:06.505455 90901 net.cpp:434] Concat23 <- Dropout25
I0905 01:39:06.505466 90901 net.cpp:408] Concat23 -> Concat23
I0905 01:39:06.505499 90901 net.cpp:150] Setting up Concat23
I0905 01:39:06.505512 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.505522 90901 net.cpp:165] Memory required for data: 2867855424
I0905 01:39:06.505532 90901 layer_factory.hpp:77] Creating layer Concat23_Concat23_0_split
I0905 01:39:06.505542 90901 net.cpp:100] Creating Layer Concat23_Concat23_0_split
I0905 01:39:06.505551 90901 net.cpp:434] Concat23_Concat23_0_split <- Concat23
I0905 01:39:06.505564 90901 net.cpp:408] Concat23_Concat23_0_split -> Concat23_Concat23_0_split_0
I0905 01:39:06.505578 90901 net.cpp:408] Concat23_Concat23_0_split -> Concat23_Concat23_0_split_1
I0905 01:39:06.505620 90901 net.cpp:150] Setting up Concat23_Concat23_0_split
I0905 01:39:06.505633 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.505643 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.505656 90901 net.cpp:165] Memory required for data: 2906128448
I0905 01:39:06.505679 90901 layer_factory.hpp:77] Creating layer BatchNorm25
I0905 01:39:06.505693 90901 net.cpp:100] Creating Layer BatchNorm25
I0905 01:39:06.505702 90901 net.cpp:434] BatchNorm25 <- Concat23_Concat23_0_split_0
I0905 01:39:06.505714 90901 net.cpp:408] BatchNorm25 -> BatchNorm25
I0905 01:39:06.505928 90901 net.cpp:150] Setting up BatchNorm25
I0905 01:39:06.505944 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.505951 90901 net.cpp:165] Memory required for data: 2925264960
I0905 01:39:06.505964 90901 layer_factory.hpp:77] Creating layer Scale25
I0905 01:39:06.505976 90901 net.cpp:100] Creating Layer Scale25
I0905 01:39:06.505985 90901 net.cpp:434] Scale25 <- BatchNorm25
I0905 01:39:06.505998 90901 net.cpp:395] Scale25 -> BatchNorm25 (in-place)
I0905 01:39:06.506096 90901 net.cpp:150] Setting up Scale25
I0905 01:39:06.506119 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.506127 90901 net.cpp:165] Memory required for data: 2944401472
I0905 01:39:06.506139 90901 layer_factory.hpp:77] Creating layer ReLU25
I0905 01:39:06.506151 90901 net.cpp:100] Creating Layer ReLU25
I0905 01:39:06.506161 90901 net.cpp:434] ReLU25 <- BatchNorm25
I0905 01:39:06.506171 90901 net.cpp:395] ReLU25 -> BatchNorm25 (in-place)
I0905 01:39:06.506494 90901 net.cpp:150] Setting up ReLU25
I0905 01:39:06.506515 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.506525 90901 net.cpp:165] Memory required for data: 2963537984
I0905 01:39:06.506534 90901 layer_factory.hpp:77] Creating layer Convolution26
I0905 01:39:06.506551 90901 net.cpp:100] Creating Layer Convolution26
I0905 01:39:06.506574 90901 net.cpp:434] Convolution26 <- BatchNorm25
I0905 01:39:06.506587 90901 net.cpp:408] Convolution26 -> Convolution26
I0905 01:39:06.508699 90901 net.cpp:150] Setting up Convolution26
I0905 01:39:06.508720 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.508729 90901 net.cpp:165] Memory required for data: 2964324416
I0905 01:39:06.508741 90901 layer_factory.hpp:77] Creating layer Dropout26
I0905 01:39:06.508764 90901 net.cpp:100] Creating Layer Dropout26
I0905 01:39:06.508772 90901 net.cpp:434] Dropout26 <- Convolution26
I0905 01:39:06.508785 90901 net.cpp:408] Dropout26 -> Dropout26
I0905 01:39:06.508838 90901 net.cpp:150] Setting up Dropout26
I0905 01:39:06.508853 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.508862 90901 net.cpp:165] Memory required for data: 2965110848
I0905 01:39:06.508870 90901 layer_factory.hpp:77] Creating layer Concat24
I0905 01:39:06.508882 90901 net.cpp:100] Creating Layer Concat24
I0905 01:39:06.508898 90901 net.cpp:434] Concat24 <- Concat23_Concat23_0_split_1
I0905 01:39:06.508909 90901 net.cpp:434] Concat24 <- Dropout26
I0905 01:39:06.508921 90901 net.cpp:408] Concat24 -> Concat24
I0905 01:39:06.508952 90901 net.cpp:150] Setting up Concat24
I0905 01:39:06.508965 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.508973 90901 net.cpp:165] Memory required for data: 2985033792
I0905 01:39:06.508983 90901 layer_factory.hpp:77] Creating layer BatchNorm26
I0905 01:39:06.508996 90901 net.cpp:100] Creating Layer BatchNorm26
I0905 01:39:06.509006 90901 net.cpp:434] BatchNorm26 <- Concat24
I0905 01:39:06.509018 90901 net.cpp:408] BatchNorm26 -> BatchNorm26
I0905 01:39:06.509232 90901 net.cpp:150] Setting up BatchNorm26
I0905 01:39:06.509245 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.509254 90901 net.cpp:165] Memory required for data: 3004956736
I0905 01:39:06.509266 90901 layer_factory.hpp:77] Creating layer Scale26
I0905 01:39:06.509279 90901 net.cpp:100] Creating Layer Scale26
I0905 01:39:06.509289 90901 net.cpp:434] Scale26 <- BatchNorm26
I0905 01:39:06.509301 90901 net.cpp:395] Scale26 -> BatchNorm26 (in-place)
I0905 01:39:06.509400 90901 net.cpp:150] Setting up Scale26
I0905 01:39:06.509418 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.509426 90901 net.cpp:165] Memory required for data: 3024879680
I0905 01:39:06.509438 90901 layer_factory.hpp:77] Creating layer ReLU26
I0905 01:39:06.509464 90901 net.cpp:100] Creating Layer ReLU26
I0905 01:39:06.509480 90901 net.cpp:434] ReLU26 <- BatchNorm26
I0905 01:39:06.509490 90901 net.cpp:395] ReLU26 -> BatchNorm26 (in-place)
I0905 01:39:06.509677 90901 net.cpp:150] Setting up ReLU26
I0905 01:39:06.509693 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.509702 90901 net.cpp:165] Memory required for data: 3044802624
I0905 01:39:06.509711 90901 layer_factory.hpp:77] Creating layer Convolution27
I0905 01:39:06.509730 90901 net.cpp:100] Creating Layer Convolution27
I0905 01:39:06.509740 90901 net.cpp:434] Convolution27 <- BatchNorm26
I0905 01:39:06.509753 90901 net.cpp:408] Convolution27 -> Convolution27
I0905 01:39:06.514176 90901 net.cpp:150] Setting up Convolution27
I0905 01:39:06.514199 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.514207 90901 net.cpp:165] Memory required for data: 3064725568
I0905 01:39:06.514219 90901 layer_factory.hpp:77] Creating layer Dropout27
I0905 01:39:06.514235 90901 net.cpp:100] Creating Layer Dropout27
I0905 01:39:06.514245 90901 net.cpp:434] Dropout27 <- Convolution27
I0905 01:39:06.514258 90901 net.cpp:408] Dropout27 -> Dropout27
I0905 01:39:06.514317 90901 net.cpp:150] Setting up Dropout27
I0905 01:39:06.514333 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.514343 90901 net.cpp:165] Memory required for data: 3084648512
I0905 01:39:06.514351 90901 layer_factory.hpp:77] Creating layer Pooling2
I0905 01:39:06.514364 90901 net.cpp:100] Creating Layer Pooling2
I0905 01:39:06.514374 90901 net.cpp:434] Pooling2 <- Dropout27
I0905 01:39:06.514385 90901 net.cpp:408] Pooling2 -> Pooling2
I0905 01:39:06.514781 90901 net.cpp:150] Setting up Pooling2
I0905 01:39:06.514801 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.514811 90901 net.cpp:165] Memory required for data: 3089629248
I0905 01:39:06.514819 90901 layer_factory.hpp:77] Creating layer Pooling2_Pooling2_0_split
I0905 01:39:06.514832 90901 net.cpp:100] Creating Layer Pooling2_Pooling2_0_split
I0905 01:39:06.514842 90901 net.cpp:434] Pooling2_Pooling2_0_split <- Pooling2
I0905 01:39:06.514854 90901 net.cpp:408] Pooling2_Pooling2_0_split -> Pooling2_Pooling2_0_split_0
I0905 01:39:06.514866 90901 net.cpp:408] Pooling2_Pooling2_0_split -> Pooling2_Pooling2_0_split_1
I0905 01:39:06.514926 90901 net.cpp:150] Setting up Pooling2_Pooling2_0_split
I0905 01:39:06.514940 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.514955 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.514962 90901 net.cpp:165] Memory required for data: 3099590720
I0905 01:39:06.514973 90901 layer_factory.hpp:77] Creating layer BatchNorm27
I0905 01:39:06.514986 90901 net.cpp:100] Creating Layer BatchNorm27
I0905 01:39:06.515002 90901 net.cpp:434] BatchNorm27 <- Pooling2_Pooling2_0_split_0
I0905 01:39:06.515013 90901 net.cpp:408] BatchNorm27 -> BatchNorm27
I0905 01:39:06.515242 90901 net.cpp:150] Setting up BatchNorm27
I0905 01:39:06.515257 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.515266 90901 net.cpp:165] Memory required for data: 3104571456
I0905 01:39:06.515278 90901 layer_factory.hpp:77] Creating layer Scale27
I0905 01:39:06.515291 90901 net.cpp:100] Creating Layer Scale27
I0905 01:39:06.515300 90901 net.cpp:434] Scale27 <- BatchNorm27
I0905 01:39:06.515312 90901 net.cpp:395] Scale27 -> BatchNorm27 (in-place)
I0905 01:39:06.515419 90901 net.cpp:150] Setting up Scale27
I0905 01:39:06.515441 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.515450 90901 net.cpp:165] Memory required for data: 3109552192
I0905 01:39:06.515460 90901 layer_factory.hpp:77] Creating layer ReLU27
I0905 01:39:06.515472 90901 net.cpp:100] Creating Layer ReLU27
I0905 01:39:06.515481 90901 net.cpp:434] ReLU27 <- BatchNorm27
I0905 01:39:06.515507 90901 net.cpp:395] ReLU27 -> BatchNorm27 (in-place)
I0905 01:39:06.515687 90901 net.cpp:150] Setting up ReLU27
I0905 01:39:06.515703 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.515712 90901 net.cpp:165] Memory required for data: 3114532928
I0905 01:39:06.515734 90901 layer_factory.hpp:77] Creating layer Convolution28
I0905 01:39:06.515751 90901 net.cpp:100] Creating Layer Convolution28
I0905 01:39:06.515760 90901 net.cpp:434] Convolution28 <- BatchNorm27
I0905 01:39:06.515777 90901 net.cpp:408] Convolution28 -> Convolution28
I0905 01:39:06.517796 90901 net.cpp:150] Setting up Convolution28
I0905 01:39:06.517818 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.517828 90901 net.cpp:165] Memory required for data: 3114729536
I0905 01:39:06.517840 90901 layer_factory.hpp:77] Creating layer Dropout28
I0905 01:39:06.517853 90901 net.cpp:100] Creating Layer Dropout28
I0905 01:39:06.517865 90901 net.cpp:434] Dropout28 <- Convolution28
I0905 01:39:06.517876 90901 net.cpp:408] Dropout28 -> Dropout28
I0905 01:39:06.517925 90901 net.cpp:150] Setting up Dropout28
I0905 01:39:06.517940 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.517952 90901 net.cpp:165] Memory required for data: 3114926144
I0905 01:39:06.517961 90901 layer_factory.hpp:77] Creating layer Concat25
I0905 01:39:06.517972 90901 net.cpp:100] Creating Layer Concat25
I0905 01:39:06.517982 90901 net.cpp:434] Concat25 <- Pooling2_Pooling2_0_split_1
I0905 01:39:06.517992 90901 net.cpp:434] Concat25 <- Dropout28
I0905 01:39:06.518010 90901 net.cpp:408] Concat25 -> Concat25
I0905 01:39:06.518044 90901 net.cpp:150] Setting up Concat25
I0905 01:39:06.518059 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.518069 90901 net.cpp:165] Memory required for data: 3120103488
I0905 01:39:06.518077 90901 layer_factory.hpp:77] Creating layer Concat25_Concat25_0_split
I0905 01:39:06.518088 90901 net.cpp:100] Creating Layer Concat25_Concat25_0_split
I0905 01:39:06.518100 90901 net.cpp:434] Concat25_Concat25_0_split <- Concat25
I0905 01:39:06.518110 90901 net.cpp:408] Concat25_Concat25_0_split -> Concat25_Concat25_0_split_0
I0905 01:39:06.518121 90901 net.cpp:408] Concat25_Concat25_0_split -> Concat25_Concat25_0_split_1
I0905 01:39:06.518167 90901 net.cpp:150] Setting up Concat25_Concat25_0_split
I0905 01:39:06.518179 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.518195 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.518204 90901 net.cpp:165] Memory required for data: 3130458176
I0905 01:39:06.518213 90901 layer_factory.hpp:77] Creating layer BatchNorm28
I0905 01:39:06.518225 90901 net.cpp:100] Creating Layer BatchNorm28
I0905 01:39:06.518235 90901 net.cpp:434] BatchNorm28 <- Concat25_Concat25_0_split_0
I0905 01:39:06.518246 90901 net.cpp:408] BatchNorm28 -> BatchNorm28
I0905 01:39:06.518462 90901 net.cpp:150] Setting up BatchNorm28
I0905 01:39:06.518477 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.518486 90901 net.cpp:165] Memory required for data: 3135635520
I0905 01:39:06.518498 90901 layer_factory.hpp:77] Creating layer Scale28
I0905 01:39:06.518510 90901 net.cpp:100] Creating Layer Scale28
I0905 01:39:06.518520 90901 net.cpp:434] Scale28 <- BatchNorm28
I0905 01:39:06.518529 90901 net.cpp:395] Scale28 -> BatchNorm28 (in-place)
I0905 01:39:06.518661 90901 net.cpp:150] Setting up Scale28
I0905 01:39:06.518681 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.518689 90901 net.cpp:165] Memory required for data: 3140812864
I0905 01:39:06.518700 90901 layer_factory.hpp:77] Creating layer ReLU28
I0905 01:39:06.518715 90901 net.cpp:100] Creating Layer ReLU28
I0905 01:39:06.518725 90901 net.cpp:434] ReLU28 <- BatchNorm28
I0905 01:39:06.518736 90901 net.cpp:395] ReLU28 -> BatchNorm28 (in-place)
I0905 01:39:06.519080 90901 net.cpp:150] Setting up ReLU28
I0905 01:39:06.519103 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.519111 90901 net.cpp:165] Memory required for data: 3145990208
I0905 01:39:06.519121 90901 layer_factory.hpp:77] Creating layer Convolution29
I0905 01:39:06.519139 90901 net.cpp:100] Creating Layer Convolution29
I0905 01:39:06.519151 90901 net.cpp:434] Convolution29 <- BatchNorm28
I0905 01:39:06.519163 90901 net.cpp:408] Convolution29 -> Convolution29
I0905 01:39:06.521318 90901 net.cpp:150] Setting up Convolution29
I0905 01:39:06.521339 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.521349 90901 net.cpp:165] Memory required for data: 3146186816
I0905 01:39:06.521361 90901 layer_factory.hpp:77] Creating layer Dropout29
I0905 01:39:06.521376 90901 net.cpp:100] Creating Layer Dropout29
I0905 01:39:06.521386 90901 net.cpp:434] Dropout29 <- Convolution29
I0905 01:39:06.521397 90901 net.cpp:408] Dropout29 -> Dropout29
I0905 01:39:06.521456 90901 net.cpp:150] Setting up Dropout29
I0905 01:39:06.521469 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.521478 90901 net.cpp:165] Memory required for data: 3146383424
I0905 01:39:06.521487 90901 layer_factory.hpp:77] Creating layer Concat26
I0905 01:39:06.521502 90901 net.cpp:100] Creating Layer Concat26
I0905 01:39:06.521510 90901 net.cpp:434] Concat26 <- Concat25_Concat25_0_split_1
I0905 01:39:06.521520 90901 net.cpp:434] Concat26 <- Dropout29
I0905 01:39:06.521539 90901 net.cpp:408] Concat26 -> Concat26
I0905 01:39:06.521570 90901 net.cpp:150] Setting up Concat26
I0905 01:39:06.521590 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.521600 90901 net.cpp:165] Memory required for data: 3151757376
I0905 01:39:06.521607 90901 layer_factory.hpp:77] Creating layer Concat26_Concat26_0_split
I0905 01:39:06.521620 90901 net.cpp:100] Creating Layer Concat26_Concat26_0_split
I0905 01:39:06.521628 90901 net.cpp:434] Concat26_Concat26_0_split <- Concat26
I0905 01:39:06.521644 90901 net.cpp:408] Concat26_Concat26_0_split -> Concat26_Concat26_0_split_0
I0905 01:39:06.521656 90901 net.cpp:408] Concat26_Concat26_0_split -> Concat26_Concat26_0_split_1
I0905 01:39:06.521702 90901 net.cpp:150] Setting up Concat26_Concat26_0_split
I0905 01:39:06.521714 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.521724 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.521731 90901 net.cpp:165] Memory required for data: 3162505280
I0905 01:39:06.521744 90901 layer_factory.hpp:77] Creating layer BatchNorm29
I0905 01:39:06.521756 90901 net.cpp:100] Creating Layer BatchNorm29
I0905 01:39:06.521765 90901 net.cpp:434] BatchNorm29 <- Concat26_Concat26_0_split_0
I0905 01:39:06.521785 90901 net.cpp:408] BatchNorm29 -> BatchNorm29
I0905 01:39:06.522003 90901 net.cpp:150] Setting up BatchNorm29
I0905 01:39:06.522018 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.522027 90901 net.cpp:165] Memory required for data: 3167879232
I0905 01:39:06.522039 90901 layer_factory.hpp:77] Creating layer Scale29
I0905 01:39:06.522053 90901 net.cpp:100] Creating Layer Scale29
I0905 01:39:06.522061 90901 net.cpp:434] Scale29 <- BatchNorm29
I0905 01:39:06.522073 90901 net.cpp:395] Scale29 -> BatchNorm29 (in-place)
I0905 01:39:06.522184 90901 net.cpp:150] Setting up Scale29
I0905 01:39:06.522205 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.522214 90901 net.cpp:165] Memory required for data: 3173253184
I0905 01:39:06.522224 90901 layer_factory.hpp:77] Creating layer ReLU29
I0905 01:39:06.522235 90901 net.cpp:100] Creating Layer ReLU29
I0905 01:39:06.522246 90901 net.cpp:434] ReLU29 <- BatchNorm29
I0905 01:39:06.522258 90901 net.cpp:395] ReLU29 -> BatchNorm29 (in-place)
I0905 01:39:06.522584 90901 net.cpp:150] Setting up ReLU29
I0905 01:39:06.522603 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.522611 90901 net.cpp:165] Memory required for data: 3178627136
I0905 01:39:06.522620 90901 layer_factory.hpp:77] Creating layer Convolution30
I0905 01:39:06.522656 90901 net.cpp:100] Creating Layer Convolution30
I0905 01:39:06.522668 90901 net.cpp:434] Convolution30 <- BatchNorm29
I0905 01:39:06.522691 90901 net.cpp:408] Convolution30 -> Convolution30
I0905 01:39:06.524804 90901 net.cpp:150] Setting up Convolution30
I0905 01:39:06.524826 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.524834 90901 net.cpp:165] Memory required for data: 3178823744
I0905 01:39:06.524847 90901 layer_factory.hpp:77] Creating layer Dropout30
I0905 01:39:06.524873 90901 net.cpp:100] Creating Layer Dropout30
I0905 01:39:06.524884 90901 net.cpp:434] Dropout30 <- Convolution30
I0905 01:39:06.524898 90901 net.cpp:408] Dropout30 -> Dropout30
I0905 01:39:06.524950 90901 net.cpp:150] Setting up Dropout30
I0905 01:39:06.524966 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.524976 90901 net.cpp:165] Memory required for data: 3179020352
I0905 01:39:06.524983 90901 layer_factory.hpp:77] Creating layer Concat27
I0905 01:39:06.524996 90901 net.cpp:100] Creating Layer Concat27
I0905 01:39:06.525010 90901 net.cpp:434] Concat27 <- Concat26_Concat26_0_split_1
I0905 01:39:06.525019 90901 net.cpp:434] Concat27 <- Dropout30
I0905 01:39:06.525046 90901 net.cpp:408] Concat27 -> Concat27
I0905 01:39:06.525079 90901 net.cpp:150] Setting up Concat27
I0905 01:39:06.525097 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.525106 90901 net.cpp:165] Memory required for data: 3184590912
I0905 01:39:06.525115 90901 layer_factory.hpp:77] Creating layer Concat27_Concat27_0_split
I0905 01:39:06.525127 90901 net.cpp:100] Creating Layer Concat27_Concat27_0_split
I0905 01:39:06.525136 90901 net.cpp:434] Concat27_Concat27_0_split <- Concat27
I0905 01:39:06.525153 90901 net.cpp:408] Concat27_Concat27_0_split -> Concat27_Concat27_0_split_0
I0905 01:39:06.525168 90901 net.cpp:408] Concat27_Concat27_0_split -> Concat27_Concat27_0_split_1
I0905 01:39:06.525213 90901 net.cpp:150] Setting up Concat27_Concat27_0_split
I0905 01:39:06.525225 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.525234 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.525243 90901 net.cpp:165] Memory required for data: 3195732032
I0905 01:39:06.525254 90901 layer_factory.hpp:77] Creating layer BatchNorm30
I0905 01:39:06.525267 90901 net.cpp:100] Creating Layer BatchNorm30
I0905 01:39:06.525276 90901 net.cpp:434] BatchNorm30 <- Concat27_Concat27_0_split_0
I0905 01:39:06.525296 90901 net.cpp:408] BatchNorm30 -> BatchNorm30
I0905 01:39:06.525530 90901 net.cpp:150] Setting up BatchNorm30
I0905 01:39:06.525545 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.525553 90901 net.cpp:165] Memory required for data: 3201302592
I0905 01:39:06.525566 90901 layer_factory.hpp:77] Creating layer Scale30
I0905 01:39:06.525583 90901 net.cpp:100] Creating Layer Scale30
I0905 01:39:06.525593 90901 net.cpp:434] Scale30 <- BatchNorm30
I0905 01:39:06.525602 90901 net.cpp:395] Scale30 -> BatchNorm30 (in-place)
I0905 01:39:06.525713 90901 net.cpp:150] Setting up Scale30
I0905 01:39:06.525728 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.525738 90901 net.cpp:165] Memory required for data: 3206873152
I0905 01:39:06.525748 90901 layer_factory.hpp:77] Creating layer ReLU30
I0905 01:39:06.525763 90901 net.cpp:100] Creating Layer ReLU30
I0905 01:39:06.525773 90901 net.cpp:434] ReLU30 <- BatchNorm30
I0905 01:39:06.525789 90901 net.cpp:395] ReLU30 -> BatchNorm30 (in-place)
I0905 01:39:06.525966 90901 net.cpp:150] Setting up ReLU30
I0905 01:39:06.525984 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.525991 90901 net.cpp:165] Memory required for data: 3212443712
I0905 01:39:06.526000 90901 layer_factory.hpp:77] Creating layer Convolution31
I0905 01:39:06.526020 90901 net.cpp:100] Creating Layer Convolution31
I0905 01:39:06.526029 90901 net.cpp:434] Convolution31 <- BatchNorm30
I0905 01:39:06.526043 90901 net.cpp:408] Convolution31 -> Convolution31
I0905 01:39:06.528225 90901 net.cpp:150] Setting up Convolution31
I0905 01:39:06.528247 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.528256 90901 net.cpp:165] Memory required for data: 3212640320
I0905 01:39:06.528270 90901 layer_factory.hpp:77] Creating layer Dropout31
I0905 01:39:06.528283 90901 net.cpp:100] Creating Layer Dropout31
I0905 01:39:06.528293 90901 net.cpp:434] Dropout31 <- Convolution31
I0905 01:39:06.528307 90901 net.cpp:408] Dropout31 -> Dropout31
I0905 01:39:06.528368 90901 net.cpp:150] Setting up Dropout31
I0905 01:39:06.528383 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.528405 90901 net.cpp:165] Memory required for data: 3212836928
I0905 01:39:06.528414 90901 layer_factory.hpp:77] Creating layer Concat28
I0905 01:39:06.528429 90901 net.cpp:100] Creating Layer Concat28
I0905 01:39:06.528439 90901 net.cpp:434] Concat28 <- Concat27_Concat27_0_split_1
I0905 01:39:06.528451 90901 net.cpp:434] Concat28 <- Dropout31
I0905 01:39:06.528463 90901 net.cpp:408] Concat28 -> Concat28
I0905 01:39:06.528502 90901 net.cpp:150] Setting up Concat28
I0905 01:39:06.528514 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.528523 90901 net.cpp:165] Memory required for data: 3218604096
I0905 01:39:06.528532 90901 layer_factory.hpp:77] Creating layer Concat28_Concat28_0_split
I0905 01:39:06.528545 90901 net.cpp:100] Creating Layer Concat28_Concat28_0_split
I0905 01:39:06.528556 90901 net.cpp:434] Concat28_Concat28_0_split <- Concat28
I0905 01:39:06.528566 90901 net.cpp:408] Concat28_Concat28_0_split -> Concat28_Concat28_0_split_0
I0905 01:39:06.528579 90901 net.cpp:408] Concat28_Concat28_0_split -> Concat28_Concat28_0_split_1
I0905 01:39:06.528622 90901 net.cpp:150] Setting up Concat28_Concat28_0_split
I0905 01:39:06.528635 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.528655 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.528662 90901 net.cpp:165] Memory required for data: 3230138432
I0905 01:39:06.528671 90901 layer_factory.hpp:77] Creating layer BatchNorm31
I0905 01:39:06.528686 90901 net.cpp:100] Creating Layer BatchNorm31
I0905 01:39:06.528694 90901 net.cpp:434] BatchNorm31 <- Concat28_Concat28_0_split_0
I0905 01:39:06.528705 90901 net.cpp:408] BatchNorm31 -> BatchNorm31
I0905 01:39:06.528928 90901 net.cpp:150] Setting up BatchNorm31
I0905 01:39:06.528942 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.528951 90901 net.cpp:165] Memory required for data: 3235905600
I0905 01:39:06.528964 90901 layer_factory.hpp:77] Creating layer Scale31
I0905 01:39:06.528978 90901 net.cpp:100] Creating Layer Scale31
I0905 01:39:06.528988 90901 net.cpp:434] Scale31 <- BatchNorm31
I0905 01:39:06.529000 90901 net.cpp:395] Scale31 -> BatchNorm31 (in-place)
I0905 01:39:06.529117 90901 net.cpp:150] Setting up Scale31
I0905 01:39:06.529139 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.529147 90901 net.cpp:165] Memory required for data: 3241672768
I0905 01:39:06.529160 90901 layer_factory.hpp:77] Creating layer ReLU31
I0905 01:39:06.529173 90901 net.cpp:100] Creating Layer ReLU31
I0905 01:39:06.529183 90901 net.cpp:434] ReLU31 <- BatchNorm31
I0905 01:39:06.529192 90901 net.cpp:395] ReLU31 -> BatchNorm31 (in-place)
I0905 01:39:06.529515 90901 net.cpp:150] Setting up ReLU31
I0905 01:39:06.529534 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.529543 90901 net.cpp:165] Memory required for data: 3247439936
I0905 01:39:06.529552 90901 layer_factory.hpp:77] Creating layer Convolution32
I0905 01:39:06.529573 90901 net.cpp:100] Creating Layer Convolution32
I0905 01:39:06.529582 90901 net.cpp:434] Convolution32 <- BatchNorm31
I0905 01:39:06.529595 90901 net.cpp:408] Convolution32 -> Convolution32
I0905 01:39:06.531680 90901 net.cpp:150] Setting up Convolution32
I0905 01:39:06.531702 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.531710 90901 net.cpp:165] Memory required for data: 3247636544
I0905 01:39:06.531723 90901 layer_factory.hpp:77] Creating layer Dropout32
I0905 01:39:06.531738 90901 net.cpp:100] Creating Layer Dropout32
I0905 01:39:06.531747 90901 net.cpp:434] Dropout32 <- Convolution32
I0905 01:39:06.531760 90901 net.cpp:408] Dropout32 -> Dropout32
I0905 01:39:06.531808 90901 net.cpp:150] Setting up Dropout32
I0905 01:39:06.531823 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.531832 90901 net.cpp:165] Memory required for data: 3247833152
I0905 01:39:06.531841 90901 layer_factory.hpp:77] Creating layer Concat29
I0905 01:39:06.531855 90901 net.cpp:100] Creating Layer Concat29
I0905 01:39:06.531870 90901 net.cpp:434] Concat29 <- Concat28_Concat28_0_split_1
I0905 01:39:06.531893 90901 net.cpp:434] Concat29 <- Dropout32
I0905 01:39:06.531913 90901 net.cpp:408] Concat29 -> Concat29
I0905 01:39:06.531946 90901 net.cpp:150] Setting up Concat29
I0905 01:39:06.531958 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.531967 90901 net.cpp:165] Memory required for data: 3253796928
I0905 01:39:06.531978 90901 layer_factory.hpp:77] Creating layer Concat29_Concat29_0_split
I0905 01:39:06.531991 90901 net.cpp:100] Creating Layer Concat29_Concat29_0_split
I0905 01:39:06.532001 90901 net.cpp:434] Concat29_Concat29_0_split <- Concat29
I0905 01:39:06.532014 90901 net.cpp:408] Concat29_Concat29_0_split -> Concat29_Concat29_0_split_0
I0905 01:39:06.532027 90901 net.cpp:408] Concat29_Concat29_0_split -> Concat29_Concat29_0_split_1
I0905 01:39:06.532073 90901 net.cpp:150] Setting up Concat29_Concat29_0_split
I0905 01:39:06.532086 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.532099 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.532106 90901 net.cpp:165] Memory required for data: 3265724480
I0905 01:39:06.532115 90901 layer_factory.hpp:77] Creating layer BatchNorm32
I0905 01:39:06.532129 90901 net.cpp:100] Creating Layer BatchNorm32
I0905 01:39:06.532137 90901 net.cpp:434] BatchNorm32 <- Concat29_Concat29_0_split_0
I0905 01:39:06.532147 90901 net.cpp:408] BatchNorm32 -> BatchNorm32
I0905 01:39:06.532371 90901 net.cpp:150] Setting up BatchNorm32
I0905 01:39:06.532385 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.532394 90901 net.cpp:165] Memory required for data: 3271688256
I0905 01:39:06.532419 90901 layer_factory.hpp:77] Creating layer Scale32
I0905 01:39:06.532435 90901 net.cpp:100] Creating Layer Scale32
I0905 01:39:06.532445 90901 net.cpp:434] Scale32 <- BatchNorm32
I0905 01:39:06.532459 90901 net.cpp:395] Scale32 -> BatchNorm32 (in-place)
I0905 01:39:06.532579 90901 net.cpp:150] Setting up Scale32
I0905 01:39:06.532595 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.532603 90901 net.cpp:165] Memory required for data: 3277652032
I0905 01:39:06.532614 90901 layer_factory.hpp:77] Creating layer ReLU32
I0905 01:39:06.532629 90901 net.cpp:100] Creating Layer ReLU32
I0905 01:39:06.532639 90901 net.cpp:434] ReLU32 <- BatchNorm32
I0905 01:39:06.532649 90901 net.cpp:395] ReLU32 -> BatchNorm32 (in-place)
I0905 01:39:06.532981 90901 net.cpp:150] Setting up ReLU32
I0905 01:39:06.533000 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.533010 90901 net.cpp:165] Memory required for data: 3283615808
I0905 01:39:06.533018 90901 layer_factory.hpp:77] Creating layer Convolution33
I0905 01:39:06.533036 90901 net.cpp:100] Creating Layer Convolution33
I0905 01:39:06.533046 90901 net.cpp:434] Convolution33 <- BatchNorm32
I0905 01:39:06.533058 90901 net.cpp:408] Convolution33 -> Convolution33
I0905 01:39:06.535931 90901 net.cpp:150] Setting up Convolution33
I0905 01:39:06.535955 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.535965 90901 net.cpp:165] Memory required for data: 3283812416
I0905 01:39:06.535977 90901 layer_factory.hpp:77] Creating layer Dropout33
I0905 01:39:06.535989 90901 net.cpp:100] Creating Layer Dropout33
I0905 01:39:06.535998 90901 net.cpp:434] Dropout33 <- Convolution33
I0905 01:39:06.536010 90901 net.cpp:408] Dropout33 -> Dropout33
I0905 01:39:06.536068 90901 net.cpp:150] Setting up Dropout33
I0905 01:39:06.536082 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.536095 90901 net.cpp:165] Memory required for data: 3284009024
I0905 01:39:06.536104 90901 layer_factory.hpp:77] Creating layer Concat30
I0905 01:39:06.536116 90901 net.cpp:100] Creating Layer Concat30
I0905 01:39:06.536128 90901 net.cpp:434] Concat30 <- Concat29_Concat29_0_split_1
I0905 01:39:06.536139 90901 net.cpp:434] Concat30 <- Dropout33
I0905 01:39:06.536150 90901 net.cpp:408] Concat30 -> Concat30
I0905 01:39:06.536182 90901 net.cpp:150] Setting up Concat30
I0905 01:39:06.536198 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.536206 90901 net.cpp:165] Memory required for data: 3290169408
I0905 01:39:06.536228 90901 layer_factory.hpp:77] Creating layer Concat30_Concat30_0_split
I0905 01:39:06.536239 90901 net.cpp:100] Creating Layer Concat30_Concat30_0_split
I0905 01:39:06.536254 90901 net.cpp:434] Concat30_Concat30_0_split <- Concat30
I0905 01:39:06.536264 90901 net.cpp:408] Concat30_Concat30_0_split -> Concat30_Concat30_0_split_0
I0905 01:39:06.536283 90901 net.cpp:408] Concat30_Concat30_0_split -> Concat30_Concat30_0_split_1
I0905 01:39:06.536346 90901 net.cpp:150] Setting up Concat30_Concat30_0_split
I0905 01:39:06.536360 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.536375 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.536381 90901 net.cpp:165] Memory required for data: 3302490176
I0905 01:39:06.536391 90901 layer_factory.hpp:77] Creating layer BatchNorm33
I0905 01:39:06.536403 90901 net.cpp:100] Creating Layer BatchNorm33
I0905 01:39:06.536412 90901 net.cpp:434] BatchNorm33 <- Concat30_Concat30_0_split_0
I0905 01:39:06.536422 90901 net.cpp:408] BatchNorm33 -> BatchNorm33
I0905 01:39:06.536658 90901 net.cpp:150] Setting up BatchNorm33
I0905 01:39:06.536691 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.536700 90901 net.cpp:165] Memory required for data: 3308650560
I0905 01:39:06.536713 90901 layer_factory.hpp:77] Creating layer Scale33
I0905 01:39:06.536725 90901 net.cpp:100] Creating Layer Scale33
I0905 01:39:06.536736 90901 net.cpp:434] Scale33 <- BatchNorm33
I0905 01:39:06.536751 90901 net.cpp:395] Scale33 -> BatchNorm33 (in-place)
I0905 01:39:06.536864 90901 net.cpp:150] Setting up Scale33
I0905 01:39:06.536878 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.536892 90901 net.cpp:165] Memory required for data: 3314810944
I0905 01:39:06.536902 90901 layer_factory.hpp:77] Creating layer ReLU33
I0905 01:39:06.536916 90901 net.cpp:100] Creating Layer ReLU33
I0905 01:39:06.536926 90901 net.cpp:434] ReLU33 <- BatchNorm33
I0905 01:39:06.536934 90901 net.cpp:395] ReLU33 -> BatchNorm33 (in-place)
I0905 01:39:06.537122 90901 net.cpp:150] Setting up ReLU33
I0905 01:39:06.537138 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.537147 90901 net.cpp:165] Memory required for data: 3320971328
I0905 01:39:06.537155 90901 layer_factory.hpp:77] Creating layer Convolution34
I0905 01:39:06.537173 90901 net.cpp:100] Creating Layer Convolution34
I0905 01:39:06.537181 90901 net.cpp:434] Convolution34 <- BatchNorm33
I0905 01:39:06.537194 90901 net.cpp:408] Convolution34 -> Convolution34
I0905 01:39:06.539491 90901 net.cpp:150] Setting up Convolution34
I0905 01:39:06.539515 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.539523 90901 net.cpp:165] Memory required for data: 3321167936
I0905 01:39:06.539537 90901 layer_factory.hpp:77] Creating layer Dropout34
I0905 01:39:06.539551 90901 net.cpp:100] Creating Layer Dropout34
I0905 01:39:06.539559 90901 net.cpp:434] Dropout34 <- Convolution34
I0905 01:39:06.539571 90901 net.cpp:408] Dropout34 -> Dropout34
I0905 01:39:06.539625 90901 net.cpp:150] Setting up Dropout34
I0905 01:39:06.539638 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.539647 90901 net.cpp:165] Memory required for data: 3321364544
I0905 01:39:06.539655 90901 layer_factory.hpp:77] Creating layer Concat31
I0905 01:39:06.539666 90901 net.cpp:100] Creating Layer Concat31
I0905 01:39:06.539675 90901 net.cpp:434] Concat31 <- Concat30_Concat30_0_split_1
I0905 01:39:06.539686 90901 net.cpp:434] Concat31 <- Dropout34
I0905 01:39:06.539706 90901 net.cpp:408] Concat31 -> Concat31
I0905 01:39:06.539738 90901 net.cpp:150] Setting up Concat31
I0905 01:39:06.539752 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.539767 90901 net.cpp:165] Memory required for data: 3327721536
I0905 01:39:06.539775 90901 layer_factory.hpp:77] Creating layer Concat31_Concat31_0_split
I0905 01:39:06.539785 90901 net.cpp:100] Creating Layer Concat31_Concat31_0_split
I0905 01:39:06.539794 90901 net.cpp:434] Concat31_Concat31_0_split <- Concat31
I0905 01:39:06.539831 90901 net.cpp:408] Concat31_Concat31_0_split -> Concat31_Concat31_0_split_0
I0905 01:39:06.539844 90901 net.cpp:408] Concat31_Concat31_0_split -> Concat31_Concat31_0_split_1
I0905 01:39:06.539892 90901 net.cpp:150] Setting up Concat31_Concat31_0_split
I0905 01:39:06.539904 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.539914 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.539921 90901 net.cpp:165] Memory required for data: 3340435520
I0905 01:39:06.539935 90901 layer_factory.hpp:77] Creating layer BatchNorm34
I0905 01:39:06.539948 90901 net.cpp:100] Creating Layer BatchNorm34
I0905 01:39:06.539958 90901 net.cpp:434] BatchNorm34 <- Concat31_Concat31_0_split_0
I0905 01:39:06.539973 90901 net.cpp:408] BatchNorm34 -> BatchNorm34
I0905 01:39:06.540197 90901 net.cpp:150] Setting up BatchNorm34
I0905 01:39:06.540213 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.540222 90901 net.cpp:165] Memory required for data: 3346792512
I0905 01:39:06.540235 90901 layer_factory.hpp:77] Creating layer Scale34
I0905 01:39:06.540246 90901 net.cpp:100] Creating Layer Scale34
I0905 01:39:06.540256 90901 net.cpp:434] Scale34 <- BatchNorm34
I0905 01:39:06.540273 90901 net.cpp:395] Scale34 -> BatchNorm34 (in-place)
I0905 01:39:06.540385 90901 net.cpp:150] Setting up Scale34
I0905 01:39:06.540400 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.540408 90901 net.cpp:165] Memory required for data: 3353149504
I0905 01:39:06.540418 90901 layer_factory.hpp:77] Creating layer ReLU34
I0905 01:39:06.540431 90901 net.cpp:100] Creating Layer ReLU34
I0905 01:39:06.540446 90901 net.cpp:434] ReLU34 <- BatchNorm34
I0905 01:39:06.540454 90901 net.cpp:395] ReLU34 -> BatchNorm34 (in-place)
I0905 01:39:06.540792 90901 net.cpp:150] Setting up ReLU34
I0905 01:39:06.540813 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.540822 90901 net.cpp:165] Memory required for data: 3359506496
I0905 01:39:06.540832 90901 layer_factory.hpp:77] Creating layer Convolution35
I0905 01:39:06.540848 90901 net.cpp:100] Creating Layer Convolution35
I0905 01:39:06.540858 90901 net.cpp:434] Convolution35 <- BatchNorm34
I0905 01:39:06.540870 90901 net.cpp:408] Convolution35 -> Convolution35
I0905 01:39:06.543246 90901 net.cpp:150] Setting up Convolution35
I0905 01:39:06.543267 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.543277 90901 net.cpp:165] Memory required for data: 3359703104
I0905 01:39:06.543288 90901 layer_factory.hpp:77] Creating layer Dropout35
I0905 01:39:06.543303 90901 net.cpp:100] Creating Layer Dropout35
I0905 01:39:06.543313 90901 net.cpp:434] Dropout35 <- Convolution35
I0905 01:39:06.543323 90901 net.cpp:408] Dropout35 -> Dropout35
I0905 01:39:06.543373 90901 net.cpp:150] Setting up Dropout35
I0905 01:39:06.543393 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.543402 90901 net.cpp:165] Memory required for data: 3359899712
I0905 01:39:06.543411 90901 layer_factory.hpp:77] Creating layer Concat32
I0905 01:39:06.543421 90901 net.cpp:100] Creating Layer Concat32
I0905 01:39:06.543432 90901 net.cpp:434] Concat32 <- Concat31_Concat31_0_split_1
I0905 01:39:06.543449 90901 net.cpp:434] Concat32 <- Dropout35
I0905 01:39:06.543463 90901 net.cpp:408] Concat32 -> Concat32
I0905 01:39:06.543495 90901 net.cpp:150] Setting up Concat32
I0905 01:39:06.543507 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.543515 90901 net.cpp:165] Memory required for data: 3366453312
I0905 01:39:06.543531 90901 layer_factory.hpp:77] Creating layer Concat32_Concat32_0_split
I0905 01:39:06.543551 90901 net.cpp:100] Creating Layer Concat32_Concat32_0_split
I0905 01:39:06.543560 90901 net.cpp:434] Concat32_Concat32_0_split <- Concat32
I0905 01:39:06.543570 90901 net.cpp:408] Concat32_Concat32_0_split -> Concat32_Concat32_0_split_0
I0905 01:39:06.543582 90901 net.cpp:408] Concat32_Concat32_0_split -> Concat32_Concat32_0_split_1
I0905 01:39:06.543630 90901 net.cpp:150] Setting up Concat32_Concat32_0_split
I0905 01:39:06.543642 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.543666 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.543675 90901 net.cpp:165] Memory required for data: 3379560512
I0905 01:39:06.543684 90901 layer_factory.hpp:77] Creating layer BatchNorm35
I0905 01:39:06.543700 90901 net.cpp:100] Creating Layer BatchNorm35
I0905 01:39:06.543712 90901 net.cpp:434] BatchNorm35 <- Concat32_Concat32_0_split_0
I0905 01:39:06.543723 90901 net.cpp:408] BatchNorm35 -> BatchNorm35
I0905 01:39:06.543958 90901 net.cpp:150] Setting up BatchNorm35
I0905 01:39:06.543972 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.543982 90901 net.cpp:165] Memory required for data: 3386114112
I0905 01:39:06.543993 90901 layer_factory.hpp:77] Creating layer Scale35
I0905 01:39:06.544006 90901 net.cpp:100] Creating Layer Scale35
I0905 01:39:06.544015 90901 net.cpp:434] Scale35 <- BatchNorm35
I0905 01:39:06.544028 90901 net.cpp:395] Scale35 -> BatchNorm35 (in-place)
I0905 01:39:06.544144 90901 net.cpp:150] Setting up Scale35
I0905 01:39:06.544159 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.544173 90901 net.cpp:165] Memory required for data: 3392667712
I0905 01:39:06.544183 90901 layer_factory.hpp:77] Creating layer ReLU35
I0905 01:39:06.544194 90901 net.cpp:100] Creating Layer ReLU35
I0905 01:39:06.544208 90901 net.cpp:434] ReLU35 <- BatchNorm35
I0905 01:39:06.544219 90901 net.cpp:395] ReLU35 -> BatchNorm35 (in-place)
I0905 01:39:06.544559 90901 net.cpp:150] Setting up ReLU35
I0905 01:39:06.544577 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.544586 90901 net.cpp:165] Memory required for data: 3399221312
I0905 01:39:06.544595 90901 layer_factory.hpp:77] Creating layer Convolution36
I0905 01:39:06.544631 90901 net.cpp:100] Creating Layer Convolution36
I0905 01:39:06.544641 90901 net.cpp:434] Convolution36 <- BatchNorm35
I0905 01:39:06.544653 90901 net.cpp:408] Convolution36 -> Convolution36
I0905 01:39:06.547065 90901 net.cpp:150] Setting up Convolution36
I0905 01:39:06.547086 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.547096 90901 net.cpp:165] Memory required for data: 3399417920
I0905 01:39:06.547107 90901 layer_factory.hpp:77] Creating layer Dropout36
I0905 01:39:06.547122 90901 net.cpp:100] Creating Layer Dropout36
I0905 01:39:06.547132 90901 net.cpp:434] Dropout36 <- Convolution36
I0905 01:39:06.547144 90901 net.cpp:408] Dropout36 -> Dropout36
I0905 01:39:06.547199 90901 net.cpp:150] Setting up Dropout36
I0905 01:39:06.547212 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.547221 90901 net.cpp:165] Memory required for data: 3399614528
I0905 01:39:06.547230 90901 layer_factory.hpp:77] Creating layer Concat33
I0905 01:39:06.547240 90901 net.cpp:100] Creating Layer Concat33
I0905 01:39:06.547250 90901 net.cpp:434] Concat33 <- Concat32_Concat32_0_split_1
I0905 01:39:06.547264 90901 net.cpp:434] Concat33 <- Dropout36
I0905 01:39:06.547276 90901 net.cpp:408] Concat33 -> Concat33
I0905 01:39:06.547309 90901 net.cpp:150] Setting up Concat33
I0905 01:39:06.547322 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.547336 90901 net.cpp:165] Memory required for data: 3406364736
I0905 01:39:06.547344 90901 layer_factory.hpp:77] Creating layer Concat33_Concat33_0_split
I0905 01:39:06.547358 90901 net.cpp:100] Creating Layer Concat33_Concat33_0_split
I0905 01:39:06.547366 90901 net.cpp:434] Concat33_Concat33_0_split <- Concat33
I0905 01:39:06.547376 90901 net.cpp:408] Concat33_Concat33_0_split -> Concat33_Concat33_0_split_0
I0905 01:39:06.547389 90901 net.cpp:408] Concat33_Concat33_0_split -> Concat33_Concat33_0_split_1
I0905 01:39:06.547435 90901 net.cpp:150] Setting up Concat33_Concat33_0_split
I0905 01:39:06.547449 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.547459 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.547467 90901 net.cpp:165] Memory required for data: 3419865152
I0905 01:39:06.547475 90901 layer_factory.hpp:77] Creating layer BatchNorm36
I0905 01:39:06.547489 90901 net.cpp:100] Creating Layer BatchNorm36
I0905 01:39:06.547518 90901 net.cpp:434] BatchNorm36 <- Concat33_Concat33_0_split_0
I0905 01:39:06.547530 90901 net.cpp:408] BatchNorm36 -> BatchNorm36
I0905 01:39:06.547763 90901 net.cpp:150] Setting up BatchNorm36
I0905 01:39:06.547778 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.547787 90901 net.cpp:165] Memory required for data: 3426615360
I0905 01:39:06.547799 90901 layer_factory.hpp:77] Creating layer Scale36
I0905 01:39:06.547813 90901 net.cpp:100] Creating Layer Scale36
I0905 01:39:06.547823 90901 net.cpp:434] Scale36 <- BatchNorm36
I0905 01:39:06.547833 90901 net.cpp:395] Scale36 -> BatchNorm36 (in-place)
I0905 01:39:06.547953 90901 net.cpp:150] Setting up Scale36
I0905 01:39:06.547976 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.547986 90901 net.cpp:165] Memory required for data: 3433365568
I0905 01:39:06.547996 90901 layer_factory.hpp:77] Creating layer ReLU36
I0905 01:39:06.548008 90901 net.cpp:100] Creating Layer ReLU36
I0905 01:39:06.548017 90901 net.cpp:434] ReLU36 <- BatchNorm36
I0905 01:39:06.548027 90901 net.cpp:395] ReLU36 -> BatchNorm36 (in-place)
I0905 01:39:06.548208 90901 net.cpp:150] Setting up ReLU36
I0905 01:39:06.548228 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.548236 90901 net.cpp:165] Memory required for data: 3440115776
I0905 01:39:06.548244 90901 layer_factory.hpp:77] Creating layer Convolution37
I0905 01:39:06.548261 90901 net.cpp:100] Creating Layer Convolution37
I0905 01:39:06.548271 90901 net.cpp:434] Convolution37 <- BatchNorm36
I0905 01:39:06.548285 90901 net.cpp:408] Convolution37 -> Convolution37
I0905 01:39:06.550720 90901 net.cpp:150] Setting up Convolution37
I0905 01:39:06.550752 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.550761 90901 net.cpp:165] Memory required for data: 3440312384
I0905 01:39:06.550775 90901 layer_factory.hpp:77] Creating layer Dropout37
I0905 01:39:06.550788 90901 net.cpp:100] Creating Layer Dropout37
I0905 01:39:06.550798 90901 net.cpp:434] Dropout37 <- Convolution37
I0905 01:39:06.550812 90901 net.cpp:408] Dropout37 -> Dropout37
I0905 01:39:06.550866 90901 net.cpp:150] Setting up Dropout37
I0905 01:39:06.550879 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.550895 90901 net.cpp:165] Memory required for data: 3440508992
I0905 01:39:06.550904 90901 layer_factory.hpp:77] Creating layer Concat34
I0905 01:39:06.550915 90901 net.cpp:100] Creating Layer Concat34
I0905 01:39:06.550923 90901 net.cpp:434] Concat34 <- Concat33_Concat33_0_split_1
I0905 01:39:06.550933 90901 net.cpp:434] Concat34 <- Dropout37
I0905 01:39:06.550956 90901 net.cpp:408] Concat34 -> Concat34
I0905 01:39:06.550988 90901 net.cpp:150] Setting up Concat34
I0905 01:39:06.551000 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.551008 90901 net.cpp:165] Memory required for data: 3447455808
I0905 01:39:06.551021 90901 layer_factory.hpp:77] Creating layer Concat34_Concat34_0_split
I0905 01:39:06.551033 90901 net.cpp:100] Creating Layer Concat34_Concat34_0_split
I0905 01:39:06.551043 90901 net.cpp:434] Concat34_Concat34_0_split <- Concat34
I0905 01:39:06.551067 90901 net.cpp:408] Concat34_Concat34_0_split -> Concat34_Concat34_0_split_0
I0905 01:39:06.551081 90901 net.cpp:408] Concat34_Concat34_0_split -> Concat34_Concat34_0_split_1
I0905 01:39:06.551131 90901 net.cpp:150] Setting up Concat34_Concat34_0_split
I0905 01:39:06.551151 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.551159 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.551167 90901 net.cpp:165] Memory required for data: 3461349440
I0905 01:39:06.551183 90901 layer_factory.hpp:77] Creating layer BatchNorm37
I0905 01:39:06.551195 90901 net.cpp:100] Creating Layer BatchNorm37
I0905 01:39:06.551204 90901 net.cpp:434] BatchNorm37 <- Concat34_Concat34_0_split_0
I0905 01:39:06.551215 90901 net.cpp:408] BatchNorm37 -> BatchNorm37
I0905 01:39:06.551443 90901 net.cpp:150] Setting up BatchNorm37
I0905 01:39:06.551465 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.551486 90901 net.cpp:165] Memory required for data: 3468296256
I0905 01:39:06.551504 90901 layer_factory.hpp:77] Creating layer Scale37
I0905 01:39:06.551519 90901 net.cpp:100] Creating Layer Scale37
I0905 01:39:06.551528 90901 net.cpp:434] Scale37 <- BatchNorm37
I0905 01:39:06.551538 90901 net.cpp:395] Scale37 -> BatchNorm37 (in-place)
I0905 01:39:06.551653 90901 net.cpp:150] Setting up Scale37
I0905 01:39:06.551676 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.551687 90901 net.cpp:165] Memory required for data: 3475243072
I0905 01:39:06.551697 90901 layer_factory.hpp:77] Creating layer ReLU37
I0905 01:39:06.551740 90901 net.cpp:100] Creating Layer ReLU37
I0905 01:39:06.551750 90901 net.cpp:434] ReLU37 <- BatchNorm37
I0905 01:39:06.551761 90901 net.cpp:395] ReLU37 -> BatchNorm37 (in-place)
I0905 01:39:06.552103 90901 net.cpp:150] Setting up ReLU37
I0905 01:39:06.552122 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.552131 90901 net.cpp:165] Memory required for data: 3482189888
I0905 01:39:06.552141 90901 layer_factory.hpp:77] Creating layer Convolution38
I0905 01:39:06.552158 90901 net.cpp:100] Creating Layer Convolution38
I0905 01:39:06.552167 90901 net.cpp:434] Convolution38 <- BatchNorm37
I0905 01:39:06.552181 90901 net.cpp:408] Convolution38 -> Convolution38
I0905 01:39:06.554478 90901 net.cpp:150] Setting up Convolution38
I0905 01:39:06.554499 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.554509 90901 net.cpp:165] Memory required for data: 3482386496
I0905 01:39:06.554522 90901 layer_factory.hpp:77] Creating layer Dropout38
I0905 01:39:06.554535 90901 net.cpp:100] Creating Layer Dropout38
I0905 01:39:06.554545 90901 net.cpp:434] Dropout38 <- Convolution38
I0905 01:39:06.554556 90901 net.cpp:408] Dropout38 -> Dropout38
I0905 01:39:06.554610 90901 net.cpp:150] Setting up Dropout38
I0905 01:39:06.554626 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.554661 90901 net.cpp:165] Memory required for data: 3482583104
I0905 01:39:06.554674 90901 layer_factory.hpp:77] Creating layer Concat35
I0905 01:39:06.554687 90901 net.cpp:100] Creating Layer Concat35
I0905 01:39:06.554704 90901 net.cpp:434] Concat35 <- Concat34_Concat34_0_split_1
I0905 01:39:06.554714 90901 net.cpp:434] Concat35 <- Dropout38
I0905 01:39:06.554725 90901 net.cpp:408] Concat35 -> Concat35
I0905 01:39:06.554772 90901 net.cpp:150] Setting up Concat35
I0905 01:39:06.554785 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.554793 90901 net.cpp:165] Memory required for data: 3489726528
I0905 01:39:06.554801 90901 layer_factory.hpp:77] Creating layer Concat35_Concat35_0_split
I0905 01:39:06.554814 90901 net.cpp:100] Creating Layer Concat35_Concat35_0_split
I0905 01:39:06.554822 90901 net.cpp:434] Concat35_Concat35_0_split <- Concat35
I0905 01:39:06.554841 90901 net.cpp:408] Concat35_Concat35_0_split -> Concat35_Concat35_0_split_0
I0905 01:39:06.554852 90901 net.cpp:408] Concat35_Concat35_0_split -> Concat35_Concat35_0_split_1
I0905 01:39:06.554900 90901 net.cpp:150] Setting up Concat35_Concat35_0_split
I0905 01:39:06.554913 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.554921 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.554929 90901 net.cpp:165] Memory required for data: 3504013376
I0905 01:39:06.554937 90901 layer_factory.hpp:77] Creating layer BatchNorm38
I0905 01:39:06.554949 90901 net.cpp:100] Creating Layer BatchNorm38
I0905 01:39:06.554957 90901 net.cpp:434] BatchNorm38 <- Concat35_Concat35_0_split_0
I0905 01:39:06.554970 90901 net.cpp:408] BatchNorm38 -> BatchNorm38
I0905 01:39:06.555202 90901 net.cpp:150] Setting up BatchNorm38
I0905 01:39:06.555218 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.555228 90901 net.cpp:165] Memory required for data: 3511156800
I0905 01:39:06.555243 90901 layer_factory.hpp:77] Creating layer Scale38
I0905 01:39:06.555254 90901 net.cpp:100] Creating Layer Scale38
I0905 01:39:06.555264 90901 net.cpp:434] Scale38 <- BatchNorm38
I0905 01:39:06.555287 90901 net.cpp:395] Scale38 -> BatchNorm38 (in-place)
I0905 01:39:06.555400 90901 net.cpp:150] Setting up Scale38
I0905 01:39:06.555415 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.555433 90901 net.cpp:165] Memory required for data: 3518300224
I0905 01:39:06.555443 90901 layer_factory.hpp:77] Creating layer ReLU38
I0905 01:39:06.555456 90901 net.cpp:100] Creating Layer ReLU38
I0905 01:39:06.555467 90901 net.cpp:434] ReLU38 <- BatchNorm38
I0905 01:39:06.555482 90901 net.cpp:395] ReLU38 -> BatchNorm38 (in-place)
I0905 01:39:06.555812 90901 net.cpp:150] Setting up ReLU38
I0905 01:39:06.555831 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.555840 90901 net.cpp:165] Memory required for data: 3525443648
I0905 01:39:06.555850 90901 layer_factory.hpp:77] Creating layer Convolution39
I0905 01:39:06.555866 90901 net.cpp:100] Creating Layer Convolution39
I0905 01:39:06.555876 90901 net.cpp:434] Convolution39 <- BatchNorm38
I0905 01:39:06.555891 90901 net.cpp:408] Convolution39 -> Convolution39
I0905 01:39:06.559010 90901 net.cpp:150] Setting up Convolution39
I0905 01:39:06.559031 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.559041 90901 net.cpp:165] Memory required for data: 3525640256
I0905 01:39:06.559053 90901 layer_factory.hpp:77] Creating layer Dropout39
I0905 01:39:06.559067 90901 net.cpp:100] Creating Layer Dropout39
I0905 01:39:06.559077 90901 net.cpp:434] Dropout39 <- Convolution39
I0905 01:39:06.559092 90901 net.cpp:408] Dropout39 -> Dropout39
I0905 01:39:06.559140 90901 net.cpp:150] Setting up Dropout39
I0905 01:39:06.559156 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.559165 90901 net.cpp:165] Memory required for data: 3525836864
I0905 01:39:06.559175 90901 layer_factory.hpp:77] Creating layer Concat36
I0905 01:39:06.559186 90901 net.cpp:100] Creating Layer Concat36
I0905 01:39:06.559195 90901 net.cpp:434] Concat36 <- Concat35_Concat35_0_split_1
I0905 01:39:06.559206 90901 net.cpp:434] Concat36 <- Dropout39
I0905 01:39:06.559217 90901 net.cpp:408] Concat36 -> Concat36
I0905 01:39:06.559252 90901 net.cpp:150] Setting up Concat36
I0905 01:39:06.559272 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.559279 90901 net.cpp:165] Memory required for data: 3533176896
I0905 01:39:06.559288 90901 layer_factory.hpp:77] Creating layer BatchNorm39
I0905 01:39:06.559308 90901 net.cpp:100] Creating Layer BatchNorm39
I0905 01:39:06.559317 90901 net.cpp:434] BatchNorm39 <- Concat36
I0905 01:39:06.559329 90901 net.cpp:408] BatchNorm39 -> BatchNorm39
I0905 01:39:06.559577 90901 net.cpp:150] Setting up BatchNorm39
I0905 01:39:06.559602 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.559619 90901 net.cpp:165] Memory required for data: 3540516928
I0905 01:39:06.559631 90901 layer_factory.hpp:77] Creating layer Scale39
I0905 01:39:06.559643 90901 net.cpp:100] Creating Layer Scale39
I0905 01:39:06.559653 90901 net.cpp:434] Scale39 <- BatchNorm39
I0905 01:39:06.559669 90901 net.cpp:395] Scale39 -> BatchNorm39 (in-place)
I0905 01:39:06.559782 90901 net.cpp:150] Setting up Scale39
I0905 01:39:06.559797 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.559805 90901 net.cpp:165] Memory required for data: 3547856960
I0905 01:39:06.559815 90901 layer_factory.hpp:77] Creating layer ReLU39
I0905 01:39:06.559826 90901 net.cpp:100] Creating Layer ReLU39
I0905 01:39:06.559835 90901 net.cpp:434] ReLU39 <- BatchNorm39
I0905 01:39:06.559846 90901 net.cpp:395] ReLU39 -> BatchNorm39 (in-place)
I0905 01:39:06.560029 90901 net.cpp:150] Setting up ReLU39
I0905 01:39:06.560050 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.560060 90901 net.cpp:165] Memory required for data: 3555196992
I0905 01:39:06.560068 90901 layer_factory.hpp:77] Creating layer Pooling3
I0905 01:39:06.560082 90901 net.cpp:100] Creating Layer Pooling3
I0905 01:39:06.560092 90901 net.cpp:434] Pooling3 <- BatchNorm39
I0905 01:39:06.560102 90901 net.cpp:408] Pooling3 -> Pooling3
I0905 01:39:06.560441 90901 net.cpp:150] Setting up Pooling3
I0905 01:39:06.560472 90901 net.cpp:157] Top shape: 16 448 1 1 (7168)
I0905 01:39:06.560482 90901 net.cpp:165] Memory required for data: 3555225664
I0905 01:39:06.560492 90901 layer_factory.hpp:77] Creating layer InnerProduct1
I0905 01:39:06.560508 90901 net.cpp:100] Creating Layer InnerProduct1
I0905 01:39:06.560516 90901 net.cpp:434] InnerProduct1 <- Pooling3
I0905 01:39:06.560530 90901 net.cpp:408] InnerProduct1 -> InnerProduct1
I0905 01:39:06.560701 90901 net.cpp:150] Setting up InnerProduct1
I0905 01:39:06.560719 90901 net.cpp:157] Top shape: 16 2 (32)
I0905 01:39:06.560731 90901 net.cpp:165] Memory required for data: 3555225792
I0905 01:39:06.560744 90901 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0905 01:39:06.560757 90901 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0905 01:39:06.560766 90901 net.cpp:434] SoftmaxWithLoss1 <- InnerProduct1
I0905 01:39:06.560776 90901 net.cpp:434] SoftmaxWithLoss1 <- Data2
I0905 01:39:06.560787 90901 net.cpp:408] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0905 01:39:06.560811 90901 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0905 01:39:06.561103 90901 net.cpp:150] Setting up SoftmaxWithLoss1
I0905 01:39:06.561120 90901 net.cpp:157] Top shape: (1)
I0905 01:39:06.561131 90901 net.cpp:160]     with loss weight 1
I0905 01:39:06.561161 90901 net.cpp:165] Memory required for data: 3555225796
I0905 01:39:06.561169 90901 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0905 01:39:06.561178 90901 net.cpp:226] InnerProduct1 needs backward computation.
I0905 01:39:06.561187 90901 net.cpp:226] Pooling3 needs backward computation.
I0905 01:39:06.561198 90901 net.cpp:226] ReLU39 needs backward computation.
I0905 01:39:06.561206 90901 net.cpp:226] Scale39 needs backward computation.
I0905 01:39:06.561214 90901 net.cpp:226] BatchNorm39 needs backward computation.
I0905 01:39:06.561223 90901 net.cpp:226] Concat36 needs backward computation.
I0905 01:39:06.561230 90901 net.cpp:226] Dropout39 needs backward computation.
I0905 01:39:06.561239 90901 net.cpp:226] Convolution39 needs backward computation.
I0905 01:39:06.561252 90901 net.cpp:226] ReLU38 needs backward computation.
I0905 01:39:06.561262 90901 net.cpp:226] Scale38 needs backward computation.
I0905 01:39:06.561270 90901 net.cpp:226] BatchNorm38 needs backward computation.
I0905 01:39:06.561278 90901 net.cpp:226] Concat35_Concat35_0_split needs backward computation.
I0905 01:39:06.561287 90901 net.cpp:226] Concat35 needs backward computation.
I0905 01:39:06.561295 90901 net.cpp:226] Dropout38 needs backward computation.
I0905 01:39:06.561303 90901 net.cpp:226] Convolution38 needs backward computation.
I0905 01:39:06.561312 90901 net.cpp:226] ReLU37 needs backward computation.
I0905 01:39:06.561319 90901 net.cpp:226] Scale37 needs backward computation.
I0905 01:39:06.561327 90901 net.cpp:226] BatchNorm37 needs backward computation.
I0905 01:39:06.561336 90901 net.cpp:226] Concat34_Concat34_0_split needs backward computation.
I0905 01:39:06.561343 90901 net.cpp:226] Concat34 needs backward computation.
I0905 01:39:06.561352 90901 net.cpp:226] Dropout37 needs backward computation.
I0905 01:39:06.561360 90901 net.cpp:226] Convolution37 needs backward computation.
I0905 01:39:06.561368 90901 net.cpp:226] ReLU36 needs backward computation.
I0905 01:39:06.561377 90901 net.cpp:226] Scale36 needs backward computation.
I0905 01:39:06.561384 90901 net.cpp:226] BatchNorm36 needs backward computation.
I0905 01:39:06.561393 90901 net.cpp:226] Concat33_Concat33_0_split needs backward computation.
I0905 01:39:06.561403 90901 net.cpp:226] Concat33 needs backward computation.
I0905 01:39:06.561413 90901 net.cpp:226] Dropout36 needs backward computation.
I0905 01:39:06.561422 90901 net.cpp:226] Convolution36 needs backward computation.
I0905 01:39:06.561431 90901 net.cpp:226] ReLU35 needs backward computation.
I0905 01:39:06.561439 90901 net.cpp:226] Scale35 needs backward computation.
I0905 01:39:06.561446 90901 net.cpp:226] BatchNorm35 needs backward computation.
I0905 01:39:06.561455 90901 net.cpp:226] Concat32_Concat32_0_split needs backward computation.
I0905 01:39:06.561478 90901 net.cpp:226] Concat32 needs backward computation.
I0905 01:39:06.561487 90901 net.cpp:226] Dropout35 needs backward computation.
I0905 01:39:06.561496 90901 net.cpp:226] Convolution35 needs backward computation.
I0905 01:39:06.561504 90901 net.cpp:226] ReLU34 needs backward computation.
I0905 01:39:06.561511 90901 net.cpp:226] Scale34 needs backward computation.
I0905 01:39:06.561519 90901 net.cpp:226] BatchNorm34 needs backward computation.
I0905 01:39:06.561528 90901 net.cpp:226] Concat31_Concat31_0_split needs backward computation.
I0905 01:39:06.561537 90901 net.cpp:226] Concat31 needs backward computation.
I0905 01:39:06.561545 90901 net.cpp:226] Dropout34 needs backward computation.
I0905 01:39:06.561553 90901 net.cpp:226] Convolution34 needs backward computation.
I0905 01:39:06.561561 90901 net.cpp:226] ReLU33 needs backward computation.
I0905 01:39:06.561569 90901 net.cpp:226] Scale33 needs backward computation.
I0905 01:39:06.561578 90901 net.cpp:226] BatchNorm33 needs backward computation.
I0905 01:39:06.561585 90901 net.cpp:226] Concat30_Concat30_0_split needs backward computation.
I0905 01:39:06.561594 90901 net.cpp:226] Concat30 needs backward computation.
I0905 01:39:06.561601 90901 net.cpp:226] Dropout33 needs backward computation.
I0905 01:39:06.561609 90901 net.cpp:226] Convolution33 needs backward computation.
I0905 01:39:06.561619 90901 net.cpp:226] ReLU32 needs backward computation.
I0905 01:39:06.561625 90901 net.cpp:226] Scale32 needs backward computation.
I0905 01:39:06.561633 90901 net.cpp:226] BatchNorm32 needs backward computation.
I0905 01:39:06.561641 90901 net.cpp:226] Concat29_Concat29_0_split needs backward computation.
I0905 01:39:06.561650 90901 net.cpp:226] Concat29 needs backward computation.
I0905 01:39:06.561658 90901 net.cpp:226] Dropout32 needs backward computation.
I0905 01:39:06.561666 90901 net.cpp:226] Convolution32 needs backward computation.
I0905 01:39:06.561674 90901 net.cpp:226] ReLU31 needs backward computation.
I0905 01:39:06.561682 90901 net.cpp:226] Scale31 needs backward computation.
I0905 01:39:06.561691 90901 net.cpp:226] BatchNorm31 needs backward computation.
I0905 01:39:06.561698 90901 net.cpp:226] Concat28_Concat28_0_split needs backward computation.
I0905 01:39:06.561707 90901 net.cpp:226] Concat28 needs backward computation.
I0905 01:39:06.561715 90901 net.cpp:226] Dropout31 needs backward computation.
I0905 01:39:06.561723 90901 net.cpp:226] Convolution31 needs backward computation.
I0905 01:39:06.561733 90901 net.cpp:226] ReLU30 needs backward computation.
I0905 01:39:06.561740 90901 net.cpp:226] Scale30 needs backward computation.
I0905 01:39:06.561748 90901 net.cpp:226] BatchNorm30 needs backward computation.
I0905 01:39:06.561756 90901 net.cpp:226] Concat27_Concat27_0_split needs backward computation.
I0905 01:39:06.561764 90901 net.cpp:226] Concat27 needs backward computation.
I0905 01:39:06.561779 90901 net.cpp:226] Dropout30 needs backward computation.
I0905 01:39:06.561787 90901 net.cpp:226] Convolution30 needs backward computation.
I0905 01:39:06.561796 90901 net.cpp:226] ReLU29 needs backward computation.
I0905 01:39:06.561803 90901 net.cpp:226] Scale29 needs backward computation.
I0905 01:39:06.561811 90901 net.cpp:226] BatchNorm29 needs backward computation.
I0905 01:39:06.561820 90901 net.cpp:226] Concat26_Concat26_0_split needs backward computation.
I0905 01:39:06.561828 90901 net.cpp:226] Concat26 needs backward computation.
I0905 01:39:06.561837 90901 net.cpp:226] Dropout29 needs backward computation.
I0905 01:39:06.561846 90901 net.cpp:226] Convolution29 needs backward computation.
I0905 01:39:06.561854 90901 net.cpp:226] ReLU28 needs backward computation.
I0905 01:39:06.561861 90901 net.cpp:226] Scale28 needs backward computation.
I0905 01:39:06.561869 90901 net.cpp:226] BatchNorm28 needs backward computation.
I0905 01:39:06.561878 90901 net.cpp:226] Concat25_Concat25_0_split needs backward computation.
I0905 01:39:06.561887 90901 net.cpp:226] Concat25 needs backward computation.
I0905 01:39:06.561903 90901 net.cpp:226] Dropout28 needs backward computation.
I0905 01:39:06.561913 90901 net.cpp:226] Convolution28 needs backward computation.
I0905 01:39:06.561923 90901 net.cpp:226] ReLU27 needs backward computation.
I0905 01:39:06.561930 90901 net.cpp:226] Scale27 needs backward computation.
I0905 01:39:06.561939 90901 net.cpp:226] BatchNorm27 needs backward computation.
I0905 01:39:06.561947 90901 net.cpp:226] Pooling2_Pooling2_0_split needs backward computation.
I0905 01:39:06.561955 90901 net.cpp:226] Pooling2 needs backward computation.
I0905 01:39:06.561964 90901 net.cpp:226] Dropout27 needs backward computation.
I0905 01:39:06.561971 90901 net.cpp:226] Convolution27 needs backward computation.
I0905 01:39:06.561980 90901 net.cpp:226] ReLU26 needs backward computation.
I0905 01:39:06.561987 90901 net.cpp:226] Scale26 needs backward computation.
I0905 01:39:06.561995 90901 net.cpp:226] BatchNorm26 needs backward computation.
I0905 01:39:06.562003 90901 net.cpp:226] Concat24 needs backward computation.
I0905 01:39:06.562012 90901 net.cpp:226] Dropout26 needs backward computation.
I0905 01:39:06.562021 90901 net.cpp:226] Convolution26 needs backward computation.
I0905 01:39:06.562028 90901 net.cpp:226] ReLU25 needs backward computation.
I0905 01:39:06.562036 90901 net.cpp:226] Scale25 needs backward computation.
I0905 01:39:06.562044 90901 net.cpp:226] BatchNorm25 needs backward computation.
I0905 01:39:06.562052 90901 net.cpp:226] Concat23_Concat23_0_split needs backward computation.
I0905 01:39:06.562060 90901 net.cpp:226] Concat23 needs backward computation.
I0905 01:39:06.562069 90901 net.cpp:226] Dropout25 needs backward computation.
I0905 01:39:06.562077 90901 net.cpp:226] Convolution25 needs backward computation.
I0905 01:39:06.562085 90901 net.cpp:226] ReLU24 needs backward computation.
I0905 01:39:06.562093 90901 net.cpp:226] Scale24 needs backward computation.
I0905 01:39:06.562101 90901 net.cpp:226] BatchNorm24 needs backward computation.
I0905 01:39:06.562110 90901 net.cpp:226] Concat22_Concat22_0_split needs backward computation.
I0905 01:39:06.562119 90901 net.cpp:226] Concat22 needs backward computation.
I0905 01:39:06.562127 90901 net.cpp:226] Dropout24 needs backward computation.
I0905 01:39:06.562135 90901 net.cpp:226] Convolution24 needs backward computation.
I0905 01:39:06.562144 90901 net.cpp:226] ReLU23 needs backward computation.
I0905 01:39:06.562151 90901 net.cpp:226] Scale23 needs backward computation.
I0905 01:39:06.562160 90901 net.cpp:226] BatchNorm23 needs backward computation.
I0905 01:39:06.562167 90901 net.cpp:226] Concat21_Concat21_0_split needs backward computation.
I0905 01:39:06.562175 90901 net.cpp:226] Concat21 needs backward computation.
I0905 01:39:06.562183 90901 net.cpp:226] Dropout23 needs backward computation.
I0905 01:39:06.562191 90901 net.cpp:226] Convolution23 needs backward computation.
I0905 01:39:06.562199 90901 net.cpp:226] ReLU22 needs backward computation.
I0905 01:39:06.562208 90901 net.cpp:226] Scale22 needs backward computation.
I0905 01:39:06.562216 90901 net.cpp:226] BatchNorm22 needs backward computation.
I0905 01:39:06.562224 90901 net.cpp:226] Concat20_Concat20_0_split needs backward computation.
I0905 01:39:06.562232 90901 net.cpp:226] Concat20 needs backward computation.
I0905 01:39:06.562242 90901 net.cpp:226] Dropout22 needs backward computation.
I0905 01:39:06.562250 90901 net.cpp:226] Convolution22 needs backward computation.
I0905 01:39:06.562258 90901 net.cpp:226] ReLU21 needs backward computation.
I0905 01:39:06.562268 90901 net.cpp:226] Scale21 needs backward computation.
I0905 01:39:06.562276 90901 net.cpp:226] BatchNorm21 needs backward computation.
I0905 01:39:06.562290 90901 net.cpp:226] Concat19_Concat19_0_split needs backward computation.
I0905 01:39:06.562299 90901 net.cpp:226] Concat19 needs backward computation.
I0905 01:39:06.562307 90901 net.cpp:226] Dropout21 needs backward computation.
I0905 01:39:06.562316 90901 net.cpp:226] Convolution21 needs backward computation.
I0905 01:39:06.562325 90901 net.cpp:226] ReLU20 needs backward computation.
I0905 01:39:06.562341 90901 net.cpp:226] Scale20 needs backward computation.
I0905 01:39:06.562350 90901 net.cpp:226] BatchNorm20 needs backward computation.
I0905 01:39:06.562357 90901 net.cpp:226] Concat18_Concat18_0_split needs backward computation.
I0905 01:39:06.562366 90901 net.cpp:226] Concat18 needs backward computation.
I0905 01:39:06.562374 90901 net.cpp:226] Dropout20 needs backward computation.
I0905 01:39:06.562391 90901 net.cpp:226] Convolution20 needs backward computation.
I0905 01:39:06.562399 90901 net.cpp:226] ReLU19 needs backward computation.
I0905 01:39:06.562407 90901 net.cpp:226] Scale19 needs backward computation.
I0905 01:39:06.562415 90901 net.cpp:226] BatchNorm19 needs backward computation.
I0905 01:39:06.562423 90901 net.cpp:226] Concat17_Concat17_0_split needs backward computation.
I0905 01:39:06.562432 90901 net.cpp:226] Concat17 needs backward computation.
I0905 01:39:06.562448 90901 net.cpp:226] Dropout19 needs backward computation.
I0905 01:39:06.562456 90901 net.cpp:226] Convolution19 needs backward computation.
I0905 01:39:06.562464 90901 net.cpp:226] ReLU18 needs backward computation.
I0905 01:39:06.562472 90901 net.cpp:226] Scale18 needs backward computation.
I0905 01:39:06.562480 90901 net.cpp:226] BatchNorm18 needs backward computation.
I0905 01:39:06.562489 90901 net.cpp:226] Concat16_Concat16_0_split needs backward computation.
I0905 01:39:06.562497 90901 net.cpp:226] Concat16 needs backward computation.
I0905 01:39:06.562506 90901 net.cpp:226] Dropout18 needs backward computation.
I0905 01:39:06.562515 90901 net.cpp:226] Convolution18 needs backward computation.
I0905 01:39:06.562523 90901 net.cpp:226] ReLU17 needs backward computation.
I0905 01:39:06.562531 90901 net.cpp:226] Scale17 needs backward computation.
I0905 01:39:06.562539 90901 net.cpp:226] BatchNorm17 needs backward computation.
I0905 01:39:06.562547 90901 net.cpp:226] Concat15_Concat15_0_split needs backward computation.
I0905 01:39:06.562556 90901 net.cpp:226] Concat15 needs backward computation.
I0905 01:39:06.562564 90901 net.cpp:226] Dropout17 needs backward computation.
I0905 01:39:06.562572 90901 net.cpp:226] Convolution17 needs backward computation.
I0905 01:39:06.562580 90901 net.cpp:226] ReLU16 needs backward computation.
I0905 01:39:06.562588 90901 net.cpp:226] Scale16 needs backward computation.
I0905 01:39:06.562597 90901 net.cpp:226] BatchNorm16 needs backward computation.
I0905 01:39:06.562604 90901 net.cpp:226] Concat14_Concat14_0_split needs backward computation.
I0905 01:39:06.562613 90901 net.cpp:226] Concat14 needs backward computation.
I0905 01:39:06.562621 90901 net.cpp:226] Dropout16 needs backward computation.
I0905 01:39:06.562635 90901 net.cpp:226] Convolution16 needs backward computation.
I0905 01:39:06.562656 90901 net.cpp:226] ReLU15 needs backward computation.
I0905 01:39:06.562664 90901 net.cpp:226] Scale15 needs backward computation.
I0905 01:39:06.562674 90901 net.cpp:226] BatchNorm15 needs backward computation.
I0905 01:39:06.562683 90901 net.cpp:226] Concat13_Concat13_0_split needs backward computation.
I0905 01:39:06.562692 90901 net.cpp:226] Concat13 needs backward computation.
I0905 01:39:06.562702 90901 net.cpp:226] Dropout15 needs backward computation.
I0905 01:39:06.562711 90901 net.cpp:226] Convolution15 needs backward computation.
I0905 01:39:06.562718 90901 net.cpp:226] ReLU14 needs backward computation.
I0905 01:39:06.562726 90901 net.cpp:226] Scale14 needs backward computation.
I0905 01:39:06.562734 90901 net.cpp:226] BatchNorm14 needs backward computation.
I0905 01:39:06.562753 90901 net.cpp:226] Pooling1_Pooling1_0_split needs backward computation.
I0905 01:39:06.562764 90901 net.cpp:226] Pooling1 needs backward computation.
I0905 01:39:06.562772 90901 net.cpp:226] Dropout14 needs backward computation.
I0905 01:39:06.562782 90901 net.cpp:226] Convolution14 needs backward computation.
I0905 01:39:06.562789 90901 net.cpp:226] ReLU13 needs backward computation.
I0905 01:39:06.562798 90901 net.cpp:226] Scale13 needs backward computation.
I0905 01:39:06.562813 90901 net.cpp:226] BatchNorm13 needs backward computation.
I0905 01:39:06.562821 90901 net.cpp:226] Concat12 needs backward computation.
I0905 01:39:06.562831 90901 net.cpp:226] Dropout13 needs backward computation.
I0905 01:39:06.562839 90901 net.cpp:226] Convolution13 needs backward computation.
I0905 01:39:06.562849 90901 net.cpp:226] ReLU12 needs backward computation.
I0905 01:39:06.562857 90901 net.cpp:226] Scale12 needs backward computation.
I0905 01:39:06.562865 90901 net.cpp:226] BatchNorm12 needs backward computation.
I0905 01:39:06.562873 90901 net.cpp:226] Concat11_Concat11_0_split needs backward computation.
I0905 01:39:06.562881 90901 net.cpp:226] Concat11 needs backward computation.
I0905 01:39:06.562891 90901 net.cpp:226] Dropout12 needs backward computation.
I0905 01:39:06.562898 90901 net.cpp:226] Convolution12 needs backward computation.
I0905 01:39:06.562907 90901 net.cpp:226] ReLU11 needs backward computation.
I0905 01:39:06.562916 90901 net.cpp:226] Scale11 needs backward computation.
I0905 01:39:06.562923 90901 net.cpp:226] BatchNorm11 needs backward computation.
I0905 01:39:06.562932 90901 net.cpp:226] Concat10_Concat10_0_split needs backward computation.
I0905 01:39:06.562939 90901 net.cpp:226] Concat10 needs backward computation.
I0905 01:39:06.562948 90901 net.cpp:226] Dropout11 needs backward computation.
I0905 01:39:06.562957 90901 net.cpp:226] Convolution11 needs backward computation.
I0905 01:39:06.562964 90901 net.cpp:226] ReLU10 needs backward computation.
I0905 01:39:06.562973 90901 net.cpp:226] Scale10 needs backward computation.
I0905 01:39:06.562980 90901 net.cpp:226] BatchNorm10 needs backward computation.
I0905 01:39:06.562988 90901 net.cpp:226] Concat9_Concat9_0_split needs backward computation.
I0905 01:39:06.562997 90901 net.cpp:226] Concat9 needs backward computation.
I0905 01:39:06.563006 90901 net.cpp:226] Dropout10 needs backward computation.
I0905 01:39:06.563014 90901 net.cpp:226] Convolution10 needs backward computation.
I0905 01:39:06.563024 90901 net.cpp:226] ReLU9 needs backward computation.
I0905 01:39:06.563031 90901 net.cpp:226] Scale9 needs backward computation.
I0905 01:39:06.563040 90901 net.cpp:226] BatchNorm9 needs backward computation.
I0905 01:39:06.563048 90901 net.cpp:226] Concat8_Concat8_0_split needs backward computation.
I0905 01:39:06.563057 90901 net.cpp:226] Concat8 needs backward computation.
I0905 01:39:06.563066 90901 net.cpp:226] Dropout9 needs backward computation.
I0905 01:39:06.563074 90901 net.cpp:226] Convolution9 needs backward computation.
I0905 01:39:06.563083 90901 net.cpp:226] ReLU8 needs backward computation.
I0905 01:39:06.563091 90901 net.cpp:226] Scale8 needs backward computation.
I0905 01:39:06.563099 90901 net.cpp:226] BatchNorm8 needs backward computation.
I0905 01:39:06.563107 90901 net.cpp:226] Concat7_Concat7_0_split needs backward computation.
I0905 01:39:06.563117 90901 net.cpp:226] Concat7 needs backward computation.
I0905 01:39:06.563125 90901 net.cpp:226] Dropout8 needs backward computation.
I0905 01:39:06.563134 90901 net.cpp:226] Convolution8 needs backward computation.
I0905 01:39:06.563143 90901 net.cpp:226] ReLU7 needs backward computation.
I0905 01:39:06.563151 90901 net.cpp:226] Scale7 needs backward computation.
I0905 01:39:06.563159 90901 net.cpp:226] BatchNorm7 needs backward computation.
I0905 01:39:06.563175 90901 net.cpp:226] Concat6_Concat6_0_split needs backward computation.
I0905 01:39:06.563184 90901 net.cpp:226] Concat6 needs backward computation.
I0905 01:39:06.563192 90901 net.cpp:226] Dropout7 needs backward computation.
I0905 01:39:06.563202 90901 net.cpp:226] Convolution7 needs backward computation.
I0905 01:39:06.563211 90901 net.cpp:226] ReLU6 needs backward computation.
I0905 01:39:06.563220 90901 net.cpp:226] Scale6 needs backward computation.
I0905 01:39:06.563227 90901 net.cpp:226] BatchNorm6 needs backward computation.
I0905 01:39:06.563236 90901 net.cpp:226] Concat5_Concat5_0_split needs backward computation.
I0905 01:39:06.563244 90901 net.cpp:226] Concat5 needs backward computation.
I0905 01:39:06.563261 90901 net.cpp:226] Dropout6 needs backward computation.
I0905 01:39:06.563269 90901 net.cpp:226] Convolution6 needs backward computation.
I0905 01:39:06.563277 90901 net.cpp:226] ReLU5 needs backward computation.
I0905 01:39:06.563285 90901 net.cpp:226] Scale5 needs backward computation.
I0905 01:39:06.563292 90901 net.cpp:226] BatchNorm5 needs backward computation.
I0905 01:39:06.563297 90901 net.cpp:226] Concat4_Concat4_0_split needs backward computation.
I0905 01:39:06.563302 90901 net.cpp:226] Concat4 needs backward computation.
I0905 01:39:06.563308 90901 net.cpp:226] Dropout5 needs backward computation.
I0905 01:39:06.563313 90901 net.cpp:226] Convolution5 needs backward computation.
I0905 01:39:06.563318 90901 net.cpp:226] ReLU4 needs backward computation.
I0905 01:39:06.563328 90901 net.cpp:226] Scale4 needs backward computation.
I0905 01:39:06.563336 90901 net.cpp:226] BatchNorm4 needs backward computation.
I0905 01:39:06.563344 90901 net.cpp:226] Concat3_Concat3_0_split needs backward computation.
I0905 01:39:06.563354 90901 net.cpp:226] Concat3 needs backward computation.
I0905 01:39:06.563364 90901 net.cpp:226] Dropout4 needs backward computation.
I0905 01:39:06.563371 90901 net.cpp:226] Convolution4 needs backward computation.
I0905 01:39:06.563380 90901 net.cpp:226] ReLU3 needs backward computation.
I0905 01:39:06.563387 90901 net.cpp:226] Scale3 needs backward computation.
I0905 01:39:06.563395 90901 net.cpp:226] BatchNorm3 needs backward computation.
I0905 01:39:06.563403 90901 net.cpp:226] Concat2_Concat2_0_split needs backward computation.
I0905 01:39:06.563412 90901 net.cpp:226] Concat2 needs backward computation.
I0905 01:39:06.563421 90901 net.cpp:226] Dropout3 needs backward computation.
I0905 01:39:06.563429 90901 net.cpp:226] Convolution3 needs backward computation.
I0905 01:39:06.563437 90901 net.cpp:226] ReLU2 needs backward computation.
I0905 01:39:06.563446 90901 net.cpp:226] Scale2 needs backward computation.
I0905 01:39:06.563452 90901 net.cpp:226] BatchNorm2 needs backward computation.
I0905 01:39:06.563462 90901 net.cpp:226] Concat1_Concat1_0_split needs backward computation.
I0905 01:39:06.563469 90901 net.cpp:226] Concat1 needs backward computation.
I0905 01:39:06.563478 90901 net.cpp:226] Dropout2 needs backward computation.
I0905 01:39:06.563486 90901 net.cpp:226] Convolution2 needs backward computation.
I0905 01:39:06.563494 90901 net.cpp:226] ReLU1 needs backward computation.
I0905 01:39:06.563503 90901 net.cpp:226] Scale1 needs backward computation.
I0905 01:39:06.563510 90901 net.cpp:226] BatchNorm1 needs backward computation.
I0905 01:39:06.563519 90901 net.cpp:226] Dropout1_Dropout1_0_split needs backward computation.
I0905 01:39:06.563539 90901 net.cpp:226] Dropout1 needs backward computation.
I0905 01:39:06.563549 90901 net.cpp:226] Convolution1 needs backward computation.
I0905 01:39:06.563557 90901 net.cpp:228] Data1 does not need backward computation.
I0905 01:39:06.563567 90901 net.cpp:270] This network produces output SoftmaxWithLoss1
I0905 01:39:06.563727 90901 net.cpp:283] Network initialization done.
I0905 01:39:06.567687 90901 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0905 01:39:06.567931 90901 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0905 01:39:06.568881 90901 net.cpp:58] Initializing net from parameters: 
name: "DenseNN"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 150
    mean_value: 150
    mean_value: 150
  }
  image_data_param {
    source: "../list_bias-1_te.lst"
    batch_size: 16
    shuffle: true
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout1"
  type: "Dropout"
  bottom: "Convolution1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Dropout1"
  top: "BatchNorm1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "Convolution2"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout2"
  type: "Dropout"
  bottom: "Convolution2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Dropout1"
  bottom: "Dropout2"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Concat1"
  top: "BatchNorm2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "Convolution3"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout3"
  type: "Dropout"
  bottom: "Convolution3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Concat1"
  bottom: "Dropout3"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Concat2"
  top: "BatchNorm3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "BatchNorm3"
  top: "Convolution4"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout4"
  type: "Dropout"
  bottom: "Convolution4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Concat2"
  bottom: "Dropout4"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Concat3"
  top: "BatchNorm4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "BatchNorm4"
  top: "BatchNorm4"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "BatchNorm4"
  top: "BatchNorm4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "BatchNorm4"
  top: "Convolution5"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout5"
  type: "Dropout"
  bottom: "Convolution5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "Concat3"
  bottom: "Dropout5"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Concat4"
  top: "BatchNorm5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "BatchNorm5"
  top: "BatchNorm5"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "BatchNorm5"
  top: "BatchNorm5"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "BatchNorm5"
  top: "Convolution6"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout6"
  type: "Dropout"
  bottom: "Convolution6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "Concat4"
  bottom: "Dropout6"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Concat5"
  top: "BatchNorm6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "BatchNorm6"
  top: "BatchNorm6"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "BatchNorm6"
  top: "BatchNorm6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "BatchNorm6"
  top: "Convolution7"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout7"
  type: "Dropout"
  bottom: "Convolution7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "Concat5"
  bottom: "Dropout7"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Concat6"
  top: "BatchNorm7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "BatchNorm7"
  top: "BatchNorm7"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "BatchNorm7"
  top: "BatchNorm7"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "BatchNorm7"
  top: "Convolution8"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout8"
  type: "Dropout"
  bottom: "Convolution8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "Concat6"
  bottom: "Dropout8"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Concat7"
  top: "BatchNorm8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "BatchNorm8"
  top: "BatchNorm8"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "BatchNorm8"
  top: "BatchNorm8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "BatchNorm8"
  top: "Convolution9"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout9"
  type: "Dropout"
  bottom: "Convolution9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "Concat7"
  bottom: "Dropout9"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Concat8"
  top: "BatchNorm9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "BatchNorm9"
  top: "BatchNorm9"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "BatchNorm9"
  top: "BatchNorm9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "BatchNorm9"
  top: "Convolution10"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout10"
  type: "Dropout"
  bottom: "Convolution10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "Concat8"
  bottom: "Dropout10"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Concat9"
  top: "BatchNorm10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "BatchNorm10"
  top: "BatchNorm10"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "BatchNorm10"
  top: "BatchNorm10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "BatchNorm10"
  top: "Convolution11"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout11"
  type: "Dropout"
  bottom: "Convolution11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "Concat9"
  bottom: "Dropout11"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Concat10"
  top: "BatchNorm11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "BatchNorm11"
  top: "BatchNorm11"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "BatchNorm11"
  top: "BatchNorm11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "BatchNorm11"
  top: "Convolution12"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout12"
  type: "Dropout"
  bottom: "Convolution12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "Concat10"
  bottom: "Dropout12"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Concat11"
  top: "BatchNorm12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "BatchNorm12"
  top: "Convolution13"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout13"
  type: "Dropout"
  bottom: "Convolution13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "Concat11"
  bottom: "Dropout13"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Concat12"
  top: "BatchNorm13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "BatchNorm13"
  top: "BatchNorm13"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "BatchNorm13"
  top: "BatchNorm13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "BatchNorm13"
  top: "Convolution14"
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout14"
  type: "Dropout"
  bottom: "Convolution14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Dropout14"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Pooling1"
  top: "BatchNorm14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "BatchNorm14"
  top: "BatchNorm14"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "BatchNorm14"
  top: "BatchNorm14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "BatchNorm14"
  top: "Convolution15"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout15"
  type: "Dropout"
  bottom: "Convolution15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Dropout15"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Concat13"
  top: "BatchNorm15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "BatchNorm15"
  top: "BatchNorm15"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "BatchNorm15"
  top: "BatchNorm15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "BatchNorm15"
  top: "Convolution16"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout16"
  type: "Dropout"
  bottom: "Convolution16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "Concat13"
  bottom: "Dropout16"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Concat14"
  top: "BatchNorm16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "BatchNorm16"
  top: "BatchNorm16"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "BatchNorm16"
  top: "BatchNorm16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "BatchNorm16"
  top: "Convolution17"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout17"
  type: "Dropout"
  bottom: "Convolution17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "Concat14"
  bottom: "Dropout17"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Concat15"
  top: "BatchNorm17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "BatchNorm17"
  top: "BatchNorm17"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "BatchNorm17"
  top: "BatchNorm17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "BatchNorm17"
  top: "Convolution18"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout18"
  type: "Dropout"
  bottom: "Convolution18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "Concat15"
  bottom: "Dropout18"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Concat16"
  top: "BatchNorm18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "BatchNorm18"
  top: "BatchNorm18"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "BatchNorm18"
  top: "BatchNorm18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "BatchNorm18"
  top: "Convolution19"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout19"
  type: "Dropout"
  bottom: "Convolution19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "Concat16"
  bottom: "Dropout19"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Concat17"
  top: "BatchNorm19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "BatchNorm19"
  top: "BatchNorm19"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "BatchNorm19"
  top: "BatchNorm19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "BatchNorm19"
  top: "Convolution20"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout20"
  type: "Dropout"
  bottom: "Convolution20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "Concat17"
  bottom: "Dropout20"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Concat18"
  top: "BatchNorm20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "BatchNorm20"
  top: "BatchNorm20"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "BatchNorm20"
  top: "BatchNorm20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "BatchNorm20"
  top: "Convolution21"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout21"
  type: "Dropout"
  bottom: "Convolution21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "Concat18"
  bottom: "Dropout21"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Concat19"
  top: "BatchNorm21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "BatchNorm21"
  top: "BatchNorm21"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "BatchNorm21"
  top: "BatchNorm21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "BatchNorm21"
  top: "Convolution22"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout22"
  type: "Dropout"
  bottom: "Convolution22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat20"
  type: "Concat"
  bottom: "Concat19"
  bottom: "Dropout22"
  top: "Concat20"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Concat20"
  top: "BatchNorm22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "BatchNorm22"
  top: "BatchNorm22"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "BatchNorm22"
  top: "BatchNorm22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "BatchNorm22"
  top: "Convolution23"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout23"
  type: "Dropout"
  bottom: "Convolution23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat21"
  type: "Concat"
  bottom: "Concat20"
  bottom: "Dropout23"
  top: "Concat21"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Concat21"
  top: "BatchNorm23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "BatchNorm23"
  top: "BatchNorm23"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "BatchNorm23"
  top: "BatchNorm23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "BatchNorm23"
  top: "Convolution24"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout24"
  type: "Dropout"
  bottom: "Convolution24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat22"
  type: "Concat"
  bottom: "Concat21"
  bottom: "Dropout24"
  top: "Concat22"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Concat22"
  top: "BatchNorm24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "BatchNorm24"
  top: "BatchNorm24"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "BatchNorm24"
  top: "BatchNorm24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "BatchNorm24"
  top: "Convolution25"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout25"
  type: "Dropout"
  bottom: "Convolution25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat23"
  type: "Concat"
  bottom: "Concat22"
  bottom: "Dropout25"
  top: "Concat23"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Concat23"
  top: "BatchNorm25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "BatchNorm25"
  top: "Convolution26"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout26"
  type: "Dropout"
  bottom: "Convolution26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Concat24"
  type: "Concat"
  bottom: "Concat23"
  bottom: "Dropout26"
  top: "Concat24"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Concat24"
  top: "BatchNorm26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "BatchNorm26"
  top: "BatchNorm26"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "BatchNorm26"
  top: "BatchNorm26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "BatchNorm26"
  top: "Convolution27"
  convolution_param {
    num_output: 304
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Dropout27"
  type: "Dropout"
  bottom: "Convolution27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Dropout27"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Pooling2"
  top: "BatchNorm27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "BatchNorm27"
  top: "BatchNorm27"
  scale_param {
    filler {
      value: 1
    }
    bias_term: false
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Batc
I0905 01:39:06.575881 90901 layer_factory.hpp:77] Creating layer Data1
I0905 01:39:06.575906 90901 net.cpp:100] Creating Layer Data1
I0905 01:39:06.575917 90901 net.cpp:408] Data1 -> Data1
I0905 01:39:06.575932 90901 net.cpp:408] Data1 -> Data2
I0905 01:39:06.575951 90901 image_data_layer.cpp:38] Opening file ../list_bias-1_te.lst
I0905 01:39:06.624141 90901 image_data_layer.cpp:53] Shuffling data
I0905 01:39:06.639148 90901 image_data_layer.cpp:58] A total of 117400 images.
I0905 01:39:06.639555 90901 image_data_layer.cpp:85] output data size: 16,3,64,64
I0905 01:39:06.642894 90901 net.cpp:150] Setting up Data1
I0905 01:39:06.642917 90901 net.cpp:157] Top shape: 16 3 64 64 (196608)
I0905 01:39:06.642932 90901 net.cpp:157] Top shape: 16 (16)
I0905 01:39:06.642941 90901 net.cpp:165] Memory required for data: 786496
I0905 01:39:06.642952 90901 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0905 01:39:06.642973 90901 net.cpp:100] Creating Layer Data2_Data1_1_split
I0905 01:39:06.642983 90901 net.cpp:434] Data2_Data1_1_split <- Data2
I0905 01:39:06.642995 90901 net.cpp:408] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0905 01:39:06.643013 90901 net.cpp:408] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0905 01:39:06.643339 90901 net.cpp:150] Setting up Data2_Data1_1_split
I0905 01:39:06.643376 90901 net.cpp:157] Top shape: 16 (16)
I0905 01:39:06.643383 90901 net.cpp:157] Top shape: 16 (16)
I0905 01:39:06.643389 90901 net.cpp:165] Memory required for data: 786624
I0905 01:39:06.643398 90901 layer_factory.hpp:77] Creating layer Convolution1
I0905 01:39:06.643424 90901 net.cpp:100] Creating Layer Convolution1
I0905 01:39:06.643430 90901 net.cpp:434] Convolution1 <- Data1
I0905 01:39:06.643440 90901 net.cpp:408] Convolution1 -> Convolution1
I0905 01:39:06.645490 90901 net.cpp:150] Setting up Convolution1
I0905 01:39:06.645511 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.645519 90901 net.cpp:165] Memory required for data: 4980928
I0905 01:39:06.645532 90901 layer_factory.hpp:77] Creating layer Dropout1
I0905 01:39:06.645542 90901 net.cpp:100] Creating Layer Dropout1
I0905 01:39:06.645548 90901 net.cpp:434] Dropout1 <- Convolution1
I0905 01:39:06.645555 90901 net.cpp:408] Dropout1 -> Dropout1
I0905 01:39:06.645615 90901 net.cpp:150] Setting up Dropout1
I0905 01:39:06.645624 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.645629 90901 net.cpp:165] Memory required for data: 9175232
I0905 01:39:06.645635 90901 layer_factory.hpp:77] Creating layer Dropout1_Dropout1_0_split
I0905 01:39:06.645648 90901 net.cpp:100] Creating Layer Dropout1_Dropout1_0_split
I0905 01:39:06.645654 90901 net.cpp:434] Dropout1_Dropout1_0_split <- Dropout1
I0905 01:39:06.645661 90901 net.cpp:408] Dropout1_Dropout1_0_split -> Dropout1_Dropout1_0_split_0
I0905 01:39:06.645670 90901 net.cpp:408] Dropout1_Dropout1_0_split -> Dropout1_Dropout1_0_split_1
I0905 01:39:06.645720 90901 net.cpp:150] Setting up Dropout1_Dropout1_0_split
I0905 01:39:06.645727 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.645735 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.645740 90901 net.cpp:165] Memory required for data: 17563840
I0905 01:39:06.645745 90901 layer_factory.hpp:77] Creating layer BatchNorm1
I0905 01:39:06.645756 90901 net.cpp:100] Creating Layer BatchNorm1
I0905 01:39:06.645762 90901 net.cpp:434] BatchNorm1 <- Dropout1_Dropout1_0_split_0
I0905 01:39:06.645769 90901 net.cpp:408] BatchNorm1 -> BatchNorm1
I0905 01:39:06.646075 90901 net.cpp:150] Setting up BatchNorm1
I0905 01:39:06.646085 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.646090 90901 net.cpp:165] Memory required for data: 21758144
I0905 01:39:06.646105 90901 layer_factory.hpp:77] Creating layer Scale1
I0905 01:39:06.646121 90901 net.cpp:100] Creating Layer Scale1
I0905 01:39:06.646126 90901 net.cpp:434] Scale1 <- BatchNorm1
I0905 01:39:06.646134 90901 net.cpp:395] Scale1 -> BatchNorm1 (in-place)
I0905 01:39:06.646260 90901 net.cpp:150] Setting up Scale1
I0905 01:39:06.646270 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.646275 90901 net.cpp:165] Memory required for data: 25952448
I0905 01:39:06.646282 90901 layer_factory.hpp:77] Creating layer ReLU1
I0905 01:39:06.646291 90901 net.cpp:100] Creating Layer ReLU1
I0905 01:39:06.646297 90901 net.cpp:434] ReLU1 <- BatchNorm1
I0905 01:39:06.646306 90901 net.cpp:395] ReLU1 -> BatchNorm1 (in-place)
I0905 01:39:06.646679 90901 net.cpp:150] Setting up ReLU1
I0905 01:39:06.646692 90901 net.cpp:157] Top shape: 16 16 64 64 (1048576)
I0905 01:39:06.646697 90901 net.cpp:165] Memory required for data: 30146752
I0905 01:39:06.646704 90901 layer_factory.hpp:77] Creating layer Convolution2
I0905 01:39:06.646723 90901 net.cpp:100] Creating Layer Convolution2
I0905 01:39:06.646729 90901 net.cpp:434] Convolution2 <- BatchNorm1
I0905 01:39:06.646739 90901 net.cpp:408] Convolution2 -> Convolution2
I0905 01:39:06.648064 90901 net.cpp:150] Setting up Convolution2
I0905 01:39:06.648078 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.648084 90901 net.cpp:165] Memory required for data: 33292480
I0905 01:39:06.648093 90901 layer_factory.hpp:77] Creating layer Dropout2
I0905 01:39:06.648104 90901 net.cpp:100] Creating Layer Dropout2
I0905 01:39:06.648110 90901 net.cpp:434] Dropout2 <- Convolution2
I0905 01:39:06.648118 90901 net.cpp:408] Dropout2 -> Dropout2
I0905 01:39:06.648180 90901 net.cpp:150] Setting up Dropout2
I0905 01:39:06.648190 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.648195 90901 net.cpp:165] Memory required for data: 36438208
I0905 01:39:06.648200 90901 layer_factory.hpp:77] Creating layer Concat1
I0905 01:39:06.648211 90901 net.cpp:100] Creating Layer Concat1
I0905 01:39:06.648216 90901 net.cpp:434] Concat1 <- Dropout1_Dropout1_0_split_1
I0905 01:39:06.648223 90901 net.cpp:434] Concat1 <- Dropout2
I0905 01:39:06.648233 90901 net.cpp:408] Concat1 -> Concat1
I0905 01:39:06.648265 90901 net.cpp:150] Setting up Concat1
I0905 01:39:06.648273 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.648278 90901 net.cpp:165] Memory required for data: 43778240
I0905 01:39:06.648283 90901 layer_factory.hpp:77] Creating layer Concat1_Concat1_0_split
I0905 01:39:06.648293 90901 net.cpp:100] Creating Layer Concat1_Concat1_0_split
I0905 01:39:06.648298 90901 net.cpp:434] Concat1_Concat1_0_split <- Concat1
I0905 01:39:06.648305 90901 net.cpp:408] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_0
I0905 01:39:06.648314 90901 net.cpp:408] Concat1_Concat1_0_split -> Concat1_Concat1_0_split_1
I0905 01:39:06.648636 90901 net.cpp:150] Setting up Concat1_Concat1_0_split
I0905 01:39:06.648661 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.648674 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.648682 90901 net.cpp:165] Memory required for data: 58458304
I0905 01:39:06.648692 90901 layer_factory.hpp:77] Creating layer BatchNorm2
I0905 01:39:06.648707 90901 net.cpp:100] Creating Layer BatchNorm2
I0905 01:39:06.648718 90901 net.cpp:434] BatchNorm2 <- Concat1_Concat1_0_split_0
I0905 01:39:06.648730 90901 net.cpp:408] BatchNorm2 -> BatchNorm2
I0905 01:39:06.649015 90901 net.cpp:150] Setting up BatchNorm2
I0905 01:39:06.649034 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.649049 90901 net.cpp:165] Memory required for data: 65798336
I0905 01:39:06.649066 90901 layer_factory.hpp:77] Creating layer Scale2
I0905 01:39:06.649082 90901 net.cpp:100] Creating Layer Scale2
I0905 01:39:06.649114 90901 net.cpp:434] Scale2 <- BatchNorm2
I0905 01:39:06.649133 90901 net.cpp:395] Scale2 -> BatchNorm2 (in-place)
I0905 01:39:06.649278 90901 net.cpp:150] Setting up Scale2
I0905 01:39:06.649305 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.649314 90901 net.cpp:165] Memory required for data: 73138368
I0905 01:39:06.649327 90901 layer_factory.hpp:77] Creating layer ReLU2
I0905 01:39:06.649343 90901 net.cpp:100] Creating Layer ReLU2
I0905 01:39:06.649351 90901 net.cpp:434] ReLU2 <- BatchNorm2
I0905 01:39:06.649368 90901 net.cpp:395] ReLU2 -> BatchNorm2 (in-place)
I0905 01:39:06.649739 90901 net.cpp:150] Setting up ReLU2
I0905 01:39:06.649760 90901 net.cpp:157] Top shape: 16 28 64 64 (1835008)
I0905 01:39:06.649770 90901 net.cpp:165] Memory required for data: 80478400
I0905 01:39:06.649781 90901 layer_factory.hpp:77] Creating layer Convolution3
I0905 01:39:06.649801 90901 net.cpp:100] Creating Layer Convolution3
I0905 01:39:06.649811 90901 net.cpp:434] Convolution3 <- BatchNorm2
I0905 01:39:06.649824 90901 net.cpp:408] Convolution3 -> Convolution3
I0905 01:39:06.651206 90901 net.cpp:150] Setting up Convolution3
I0905 01:39:06.651229 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.651240 90901 net.cpp:165] Memory required for data: 83624128
I0905 01:39:06.651255 90901 layer_factory.hpp:77] Creating layer Dropout3
I0905 01:39:06.651273 90901 net.cpp:100] Creating Layer Dropout3
I0905 01:39:06.651285 90901 net.cpp:434] Dropout3 <- Convolution3
I0905 01:39:06.651300 90901 net.cpp:408] Dropout3 -> Dropout3
I0905 01:39:06.651365 90901 net.cpp:150] Setting up Dropout3
I0905 01:39:06.651389 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.651399 90901 net.cpp:165] Memory required for data: 86769856
I0905 01:39:06.651409 90901 layer_factory.hpp:77] Creating layer Concat2
I0905 01:39:06.651422 90901 net.cpp:100] Creating Layer Concat2
I0905 01:39:06.651433 90901 net.cpp:434] Concat2 <- Concat1_Concat1_0_split_1
I0905 01:39:06.651444 90901 net.cpp:434] Concat2 <- Dropout3
I0905 01:39:06.651455 90901 net.cpp:408] Concat2 -> Concat2
I0905 01:39:06.651504 90901 net.cpp:150] Setting up Concat2
I0905 01:39:06.651520 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.651540 90901 net.cpp:165] Memory required for data: 97255616
I0905 01:39:06.651549 90901 layer_factory.hpp:77] Creating layer Concat2_Concat2_0_split
I0905 01:39:06.651563 90901 net.cpp:100] Creating Layer Concat2_Concat2_0_split
I0905 01:39:06.651576 90901 net.cpp:434] Concat2_Concat2_0_split <- Concat2
I0905 01:39:06.651587 90901 net.cpp:408] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_0
I0905 01:39:06.651600 90901 net.cpp:408] Concat2_Concat2_0_split -> Concat2_Concat2_0_split_1
I0905 01:39:06.651671 90901 net.cpp:150] Setting up Concat2_Concat2_0_split
I0905 01:39:06.651687 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.651697 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.651706 90901 net.cpp:165] Memory required for data: 118227136
I0905 01:39:06.651716 90901 layer_factory.hpp:77] Creating layer BatchNorm3
I0905 01:39:06.651729 90901 net.cpp:100] Creating Layer BatchNorm3
I0905 01:39:06.651741 90901 net.cpp:434] BatchNorm3 <- Concat2_Concat2_0_split_0
I0905 01:39:06.651754 90901 net.cpp:408] BatchNorm3 -> BatchNorm3
I0905 01:39:06.652228 90901 net.cpp:150] Setting up BatchNorm3
I0905 01:39:06.652256 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.652266 90901 net.cpp:165] Memory required for data: 128712896
I0905 01:39:06.652287 90901 layer_factory.hpp:77] Creating layer Scale3
I0905 01:39:06.652303 90901 net.cpp:100] Creating Layer Scale3
I0905 01:39:06.652314 90901 net.cpp:434] Scale3 <- BatchNorm3
I0905 01:39:06.652326 90901 net.cpp:395] Scale3 -> BatchNorm3 (in-place)
I0905 01:39:06.652462 90901 net.cpp:150] Setting up Scale3
I0905 01:39:06.652489 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.652498 90901 net.cpp:165] Memory required for data: 139198656
I0905 01:39:06.652510 90901 layer_factory.hpp:77] Creating layer ReLU3
I0905 01:39:06.652539 90901 net.cpp:100] Creating Layer ReLU3
I0905 01:39:06.652552 90901 net.cpp:434] ReLU3 <- BatchNorm3
I0905 01:39:06.652564 90901 net.cpp:395] ReLU3 -> BatchNorm3 (in-place)
I0905 01:39:06.652779 90901 net.cpp:150] Setting up ReLU3
I0905 01:39:06.652798 90901 net.cpp:157] Top shape: 16 40 64 64 (2621440)
I0905 01:39:06.652808 90901 net.cpp:165] Memory required for data: 149684416
I0905 01:39:06.652819 90901 layer_factory.hpp:77] Creating layer Convolution4
I0905 01:39:06.652842 90901 net.cpp:100] Creating Layer Convolution4
I0905 01:39:06.652853 90901 net.cpp:434] Convolution4 <- BatchNorm3
I0905 01:39:06.652866 90901 net.cpp:408] Convolution4 -> Convolution4
I0905 01:39:06.654253 90901 net.cpp:150] Setting up Convolution4
I0905 01:39:06.654278 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.654289 90901 net.cpp:165] Memory required for data: 152830144
I0905 01:39:06.654301 90901 layer_factory.hpp:77] Creating layer Dropout4
I0905 01:39:06.654319 90901 net.cpp:100] Creating Layer Dropout4
I0905 01:39:06.654328 90901 net.cpp:434] Dropout4 <- Convolution4
I0905 01:39:06.654341 90901 net.cpp:408] Dropout4 -> Dropout4
I0905 01:39:06.654408 90901 net.cpp:150] Setting up Dropout4
I0905 01:39:06.654424 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.654433 90901 net.cpp:165] Memory required for data: 155975872
I0905 01:39:06.654443 90901 layer_factory.hpp:77] Creating layer Concat3
I0905 01:39:06.654458 90901 net.cpp:100] Creating Layer Concat3
I0905 01:39:06.654469 90901 net.cpp:434] Concat3 <- Concat2_Concat2_0_split_1
I0905 01:39:06.654481 90901 net.cpp:434] Concat3 <- Dropout4
I0905 01:39:06.654495 90901 net.cpp:408] Concat3 -> Concat3
I0905 01:39:06.654539 90901 net.cpp:150] Setting up Concat3
I0905 01:39:06.654557 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.654574 90901 net.cpp:165] Memory required for data: 169607360
I0905 01:39:06.654584 90901 layer_factory.hpp:77] Creating layer Concat3_Concat3_0_split
I0905 01:39:06.654609 90901 net.cpp:100] Creating Layer Concat3_Concat3_0_split
I0905 01:39:06.654619 90901 net.cpp:434] Concat3_Concat3_0_split <- Concat3
I0905 01:39:06.654635 90901 net.cpp:408] Concat3_Concat3_0_split -> Concat3_Concat3_0_split_0
I0905 01:39:06.654654 90901 net.cpp:408] Concat3_Concat3_0_split -> Concat3_Concat3_0_split_1
I0905 01:39:06.654711 90901 net.cpp:150] Setting up Concat3_Concat3_0_split
I0905 01:39:06.654726 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.654737 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.654748 90901 net.cpp:165] Memory required for data: 196870336
I0905 01:39:06.654762 90901 layer_factory.hpp:77] Creating layer BatchNorm4
I0905 01:39:06.654775 90901 net.cpp:100] Creating Layer BatchNorm4
I0905 01:39:06.654785 90901 net.cpp:434] BatchNorm4 <- Concat3_Concat3_0_split_0
I0905 01:39:06.654796 90901 net.cpp:408] BatchNorm4 -> BatchNorm4
I0905 01:39:06.655084 90901 net.cpp:150] Setting up BatchNorm4
I0905 01:39:06.655102 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.655110 90901 net.cpp:165] Memory required for data: 210501824
I0905 01:39:06.655124 90901 layer_factory.hpp:77] Creating layer Scale4
I0905 01:39:06.655140 90901 net.cpp:100] Creating Layer Scale4
I0905 01:39:06.655150 90901 net.cpp:434] Scale4 <- BatchNorm4
I0905 01:39:06.655163 90901 net.cpp:395] Scale4 -> BatchNorm4 (in-place)
I0905 01:39:06.655292 90901 net.cpp:150] Setting up Scale4
I0905 01:39:06.655308 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.655321 90901 net.cpp:165] Memory required for data: 224133312
I0905 01:39:06.655333 90901 layer_factory.hpp:77] Creating layer ReLU4
I0905 01:39:06.655344 90901 net.cpp:100] Creating Layer ReLU4
I0905 01:39:06.655354 90901 net.cpp:434] ReLU4 <- BatchNorm4
I0905 01:39:06.655367 90901 net.cpp:395] ReLU4 -> BatchNorm4 (in-place)
I0905 01:39:06.655722 90901 net.cpp:150] Setting up ReLU4
I0905 01:39:06.655743 90901 net.cpp:157] Top shape: 16 52 64 64 (3407872)
I0905 01:39:06.655753 90901 net.cpp:165] Memory required for data: 237764800
I0905 01:39:06.655777 90901 layer_factory.hpp:77] Creating layer Convolution5
I0905 01:39:06.655797 90901 net.cpp:100] Creating Layer Convolution5
I0905 01:39:06.655809 90901 net.cpp:434] Convolution5 <- BatchNorm4
I0905 01:39:06.655825 90901 net.cpp:408] Convolution5 -> Convolution5
I0905 01:39:06.657088 90901 net.cpp:150] Setting up Convolution5
I0905 01:39:06.657110 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.657120 90901 net.cpp:165] Memory required for data: 240910528
I0905 01:39:06.657133 90901 layer_factory.hpp:77] Creating layer Dropout5
I0905 01:39:06.657146 90901 net.cpp:100] Creating Layer Dropout5
I0905 01:39:06.657157 90901 net.cpp:434] Dropout5 <- Convolution5
I0905 01:39:06.657169 90901 net.cpp:408] Dropout5 -> Dropout5
I0905 01:39:06.657232 90901 net.cpp:150] Setting up Dropout5
I0905 01:39:06.657258 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.657268 90901 net.cpp:165] Memory required for data: 244056256
I0905 01:39:06.657277 90901 layer_factory.hpp:77] Creating layer Concat4
I0905 01:39:06.657291 90901 net.cpp:100] Creating Layer Concat4
I0905 01:39:06.657302 90901 net.cpp:434] Concat4 <- Concat3_Concat3_0_split_1
I0905 01:39:06.657315 90901 net.cpp:434] Concat4 <- Dropout5
I0905 01:39:06.657335 90901 net.cpp:408] Concat4 -> Concat4
I0905 01:39:06.657376 90901 net.cpp:150] Setting up Concat4
I0905 01:39:06.657394 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.657404 90901 net.cpp:165] Memory required for data: 260833472
I0905 01:39:06.657414 90901 layer_factory.hpp:77] Creating layer Concat4_Concat4_0_split
I0905 01:39:06.657430 90901 net.cpp:100] Creating Layer Concat4_Concat4_0_split
I0905 01:39:06.657441 90901 net.cpp:434] Concat4_Concat4_0_split <- Concat4
I0905 01:39:06.657454 90901 net.cpp:408] Concat4_Concat4_0_split -> Concat4_Concat4_0_split_0
I0905 01:39:06.657472 90901 net.cpp:408] Concat4_Concat4_0_split -> Concat4_Concat4_0_split_1
I0905 01:39:06.657532 90901 net.cpp:150] Setting up Concat4_Concat4_0_split
I0905 01:39:06.657548 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.657558 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.657567 90901 net.cpp:165] Memory required for data: 294387904
I0905 01:39:06.657578 90901 layer_factory.hpp:77] Creating layer BatchNorm5
I0905 01:39:06.657593 90901 net.cpp:100] Creating Layer BatchNorm5
I0905 01:39:06.657603 90901 net.cpp:434] BatchNorm5 <- Concat4_Concat4_0_split_0
I0905 01:39:06.657614 90901 net.cpp:408] BatchNorm5 -> BatchNorm5
I0905 01:39:06.657886 90901 net.cpp:150] Setting up BatchNorm5
I0905 01:39:06.657904 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.657913 90901 net.cpp:165] Memory required for data: 311165120
I0905 01:39:06.657927 90901 layer_factory.hpp:77] Creating layer Scale5
I0905 01:39:06.657943 90901 net.cpp:100] Creating Layer Scale5
I0905 01:39:06.657953 90901 net.cpp:434] Scale5 <- BatchNorm5
I0905 01:39:06.657968 90901 net.cpp:395] Scale5 -> BatchNorm5 (in-place)
I0905 01:39:06.658102 90901 net.cpp:150] Setting up Scale5
I0905 01:39:06.658121 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.658130 90901 net.cpp:165] Memory required for data: 327942336
I0905 01:39:06.658141 90901 layer_factory.hpp:77] Creating layer ReLU5
I0905 01:39:06.658154 90901 net.cpp:100] Creating Layer ReLU5
I0905 01:39:06.658164 90901 net.cpp:434] ReLU5 <- BatchNorm5
I0905 01:39:06.658176 90901 net.cpp:395] ReLU5 -> BatchNorm5 (in-place)
I0905 01:39:06.658527 90901 net.cpp:150] Setting up ReLU5
I0905 01:39:06.658548 90901 net.cpp:157] Top shape: 16 64 64 64 (4194304)
I0905 01:39:06.658558 90901 net.cpp:165] Memory required for data: 344719552
I0905 01:39:06.658568 90901 layer_factory.hpp:77] Creating layer Convolution6
I0905 01:39:06.658591 90901 net.cpp:100] Creating Layer Convolution6
I0905 01:39:06.658601 90901 net.cpp:434] Convolution6 <- BatchNorm5
I0905 01:39:06.658614 90901 net.cpp:408] Convolution6 -> Convolution6
I0905 01:39:06.660064 90901 net.cpp:150] Setting up Convolution6
I0905 01:39:06.660099 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.660110 90901 net.cpp:165] Memory required for data: 347865280
I0905 01:39:06.660123 90901 layer_factory.hpp:77] Creating layer Dropout6
I0905 01:39:06.660140 90901 net.cpp:100] Creating Layer Dropout6
I0905 01:39:06.660151 90901 net.cpp:434] Dropout6 <- Convolution6
I0905 01:39:06.660162 90901 net.cpp:408] Dropout6 -> Dropout6
I0905 01:39:06.660228 90901 net.cpp:150] Setting up Dropout6
I0905 01:39:06.660243 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.660253 90901 net.cpp:165] Memory required for data: 351011008
I0905 01:39:06.660262 90901 layer_factory.hpp:77] Creating layer Concat5
I0905 01:39:06.660276 90901 net.cpp:100] Creating Layer Concat5
I0905 01:39:06.660286 90901 net.cpp:434] Concat5 <- Concat4_Concat4_0_split_1
I0905 01:39:06.660297 90901 net.cpp:434] Concat5 <- Dropout6
I0905 01:39:06.660308 90901 net.cpp:408] Concat5 -> Concat5
I0905 01:39:06.660347 90901 net.cpp:150] Setting up Concat5
I0905 01:39:06.660362 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.660372 90901 net.cpp:165] Memory required for data: 370933952
I0905 01:39:06.660382 90901 layer_factory.hpp:77] Creating layer Concat5_Concat5_0_split
I0905 01:39:06.660395 90901 net.cpp:100] Creating Layer Concat5_Concat5_0_split
I0905 01:39:06.660405 90901 net.cpp:434] Concat5_Concat5_0_split <- Concat5
I0905 01:39:06.660420 90901 net.cpp:408] Concat5_Concat5_0_split -> Concat5_Concat5_0_split_0
I0905 01:39:06.660435 90901 net.cpp:408] Concat5_Concat5_0_split -> Concat5_Concat5_0_split_1
I0905 01:39:06.660493 90901 net.cpp:150] Setting up Concat5_Concat5_0_split
I0905 01:39:06.660512 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.660523 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.660532 90901 net.cpp:165] Memory required for data: 410779840
I0905 01:39:06.660542 90901 layer_factory.hpp:77] Creating layer BatchNorm6
I0905 01:39:06.660555 90901 net.cpp:100] Creating Layer BatchNorm6
I0905 01:39:06.660564 90901 net.cpp:434] BatchNorm6 <- Concat5_Concat5_0_split_0
I0905 01:39:06.660578 90901 net.cpp:408] BatchNorm6 -> BatchNorm6
I0905 01:39:06.660848 90901 net.cpp:150] Setting up BatchNorm6
I0905 01:39:06.660864 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.660873 90901 net.cpp:165] Memory required for data: 430702784
I0905 01:39:06.660894 90901 layer_factory.hpp:77] Creating layer Scale6
I0905 01:39:06.660908 90901 net.cpp:100] Creating Layer Scale6
I0905 01:39:06.660919 90901 net.cpp:434] Scale6 <- BatchNorm6
I0905 01:39:06.660930 90901 net.cpp:395] Scale6 -> BatchNorm6 (in-place)
I0905 01:39:06.661062 90901 net.cpp:150] Setting up Scale6
I0905 01:39:06.661087 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.661095 90901 net.cpp:165] Memory required for data: 450625728
I0905 01:39:06.661106 90901 layer_factory.hpp:77] Creating layer ReLU6
I0905 01:39:06.661121 90901 net.cpp:100] Creating Layer ReLU6
I0905 01:39:06.661133 90901 net.cpp:434] ReLU6 <- BatchNorm6
I0905 01:39:06.661142 90901 net.cpp:395] ReLU6 -> BatchNorm6 (in-place)
I0905 01:39:06.661345 90901 net.cpp:150] Setting up ReLU6
I0905 01:39:06.661362 90901 net.cpp:157] Top shape: 16 76 64 64 (4980736)
I0905 01:39:06.661371 90901 net.cpp:165] Memory required for data: 470548672
I0905 01:39:06.661381 90901 layer_factory.hpp:77] Creating layer Convolution7
I0905 01:39:06.661406 90901 net.cpp:100] Creating Layer Convolution7
I0905 01:39:06.661417 90901 net.cpp:434] Convolution7 <- BatchNorm6
I0905 01:39:06.661430 90901 net.cpp:408] Convolution7 -> Convolution7
I0905 01:39:06.662932 90901 net.cpp:150] Setting up Convolution7
I0905 01:39:06.662955 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.662966 90901 net.cpp:165] Memory required for data: 473694400
I0905 01:39:06.662978 90901 layer_factory.hpp:77] Creating layer Dropout7
I0905 01:39:06.662992 90901 net.cpp:100] Creating Layer Dropout7
I0905 01:39:06.663002 90901 net.cpp:434] Dropout7 <- Convolution7
I0905 01:39:06.663030 90901 net.cpp:408] Dropout7 -> Dropout7
I0905 01:39:06.663099 90901 net.cpp:150] Setting up Dropout7
I0905 01:39:06.663116 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.663128 90901 net.cpp:165] Memory required for data: 476840128
I0905 01:39:06.663141 90901 layer_factory.hpp:77] Creating layer Concat6
I0905 01:39:06.663164 90901 net.cpp:100] Creating Layer Concat6
I0905 01:39:06.663175 90901 net.cpp:434] Concat6 <- Concat5_Concat5_0_split_1
I0905 01:39:06.663187 90901 net.cpp:434] Concat6 <- Dropout7
I0905 01:39:06.663203 90901 net.cpp:408] Concat6 -> Concat6
I0905 01:39:06.663244 90901 net.cpp:150] Setting up Concat6
I0905 01:39:06.663259 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.663267 90901 net.cpp:165] Memory required for data: 499908800
I0905 01:39:06.663285 90901 layer_factory.hpp:77] Creating layer Concat6_Concat6_0_split
I0905 01:39:06.663297 90901 net.cpp:100] Creating Layer Concat6_Concat6_0_split
I0905 01:39:06.663307 90901 net.cpp:434] Concat6_Concat6_0_split <- Concat6
I0905 01:39:06.663318 90901 net.cpp:408] Concat6_Concat6_0_split -> Concat6_Concat6_0_split_0
I0905 01:39:06.663332 90901 net.cpp:408] Concat6_Concat6_0_split -> Concat6_Concat6_0_split_1
I0905 01:39:06.663388 90901 net.cpp:150] Setting up Concat6_Concat6_0_split
I0905 01:39:06.663404 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.663415 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.663424 90901 net.cpp:165] Memory required for data: 546046144
I0905 01:39:06.663434 90901 layer_factory.hpp:77] Creating layer BatchNorm7
I0905 01:39:06.663449 90901 net.cpp:100] Creating Layer BatchNorm7
I0905 01:39:06.663460 90901 net.cpp:434] BatchNorm7 <- Concat6_Concat6_0_split_0
I0905 01:39:06.663471 90901 net.cpp:408] BatchNorm7 -> BatchNorm7
I0905 01:39:06.663756 90901 net.cpp:150] Setting up BatchNorm7
I0905 01:39:06.663774 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.663784 90901 net.cpp:165] Memory required for data: 569114816
I0905 01:39:06.663799 90901 layer_factory.hpp:77] Creating layer Scale7
I0905 01:39:06.663811 90901 net.cpp:100] Creating Layer Scale7
I0905 01:39:06.663825 90901 net.cpp:434] Scale7 <- BatchNorm7
I0905 01:39:06.663842 90901 net.cpp:395] Scale7 -> BatchNorm7 (in-place)
I0905 01:39:06.663986 90901 net.cpp:150] Setting up Scale7
I0905 01:39:06.664002 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.664011 90901 net.cpp:165] Memory required for data: 592183488
I0905 01:39:06.664022 90901 layer_factory.hpp:77] Creating layer ReLU7
I0905 01:39:06.664034 90901 net.cpp:100] Creating Layer ReLU7
I0905 01:39:06.664043 90901 net.cpp:434] ReLU7 <- BatchNorm7
I0905 01:39:06.664054 90901 net.cpp:395] ReLU7 -> BatchNorm7 (in-place)
I0905 01:39:06.664396 90901 net.cpp:150] Setting up ReLU7
I0905 01:39:06.664415 90901 net.cpp:157] Top shape: 16 88 64 64 (5767168)
I0905 01:39:06.664425 90901 net.cpp:165] Memory required for data: 615252160
I0905 01:39:06.664434 90901 layer_factory.hpp:77] Creating layer Convolution8
I0905 01:39:06.664451 90901 net.cpp:100] Creating Layer Convolution8
I0905 01:39:06.664464 90901 net.cpp:434] Convolution8 <- BatchNorm7
I0905 01:39:06.664481 90901 net.cpp:408] Convolution8 -> Convolution8
I0905 01:39:06.666479 90901 net.cpp:150] Setting up Convolution8
I0905 01:39:06.666502 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.666512 90901 net.cpp:165] Memory required for data: 618397888
I0905 01:39:06.666527 90901 layer_factory.hpp:77] Creating layer Dropout8
I0905 01:39:06.666541 90901 net.cpp:100] Creating Layer Dropout8
I0905 01:39:06.666553 90901 net.cpp:434] Dropout8 <- Convolution8
I0905 01:39:06.666564 90901 net.cpp:408] Dropout8 -> Dropout8
I0905 01:39:06.666640 90901 net.cpp:150] Setting up Dropout8
I0905 01:39:06.666657 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.666666 90901 net.cpp:165] Memory required for data: 621543616
I0905 01:39:06.666676 90901 layer_factory.hpp:77] Creating layer Concat7
I0905 01:39:06.666690 90901 net.cpp:100] Creating Layer Concat7
I0905 01:39:06.666717 90901 net.cpp:434] Concat7 <- Concat6_Concat6_0_split_1
I0905 01:39:06.666728 90901 net.cpp:434] Concat7 <- Dropout8
I0905 01:39:06.666745 90901 net.cpp:408] Concat7 -> Concat7
I0905 01:39:06.666788 90901 net.cpp:150] Setting up Concat7
I0905 01:39:06.666805 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.666813 90901 net.cpp:165] Memory required for data: 647758016
I0905 01:39:06.666822 90901 layer_factory.hpp:77] Creating layer Concat7_Concat7_0_split
I0905 01:39:06.666836 90901 net.cpp:100] Creating Layer Concat7_Concat7_0_split
I0905 01:39:06.666847 90901 net.cpp:434] Concat7_Concat7_0_split <- Concat7
I0905 01:39:06.666858 90901 net.cpp:408] Concat7_Concat7_0_split -> Concat7_Concat7_0_split_0
I0905 01:39:06.666875 90901 net.cpp:408] Concat7_Concat7_0_split -> Concat7_Concat7_0_split_1
I0905 01:39:06.666932 90901 net.cpp:150] Setting up Concat7_Concat7_0_split
I0905 01:39:06.666957 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.666967 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.666976 90901 net.cpp:165] Memory required for data: 700186816
I0905 01:39:06.666985 90901 layer_factory.hpp:77] Creating layer BatchNorm8
I0905 01:39:06.666999 90901 net.cpp:100] Creating Layer BatchNorm8
I0905 01:39:06.667009 90901 net.cpp:434] BatchNorm8 <- Concat7_Concat7_0_split_0
I0905 01:39:06.667024 90901 net.cpp:408] BatchNorm8 -> BatchNorm8
I0905 01:39:06.667284 90901 net.cpp:150] Setting up BatchNorm8
I0905 01:39:06.667300 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.667309 90901 net.cpp:165] Memory required for data: 726401216
I0905 01:39:06.667322 90901 layer_factory.hpp:77] Creating layer Scale8
I0905 01:39:06.667341 90901 net.cpp:100] Creating Layer Scale8
I0905 01:39:06.667351 90901 net.cpp:434] Scale8 <- BatchNorm8
I0905 01:39:06.667362 90901 net.cpp:395] Scale8 -> BatchNorm8 (in-place)
I0905 01:39:06.667484 90901 net.cpp:150] Setting up Scale8
I0905 01:39:06.667505 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.667513 90901 net.cpp:165] Memory required for data: 752615616
I0905 01:39:06.667524 90901 layer_factory.hpp:77] Creating layer ReLU8
I0905 01:39:06.667536 90901 net.cpp:100] Creating Layer ReLU8
I0905 01:39:06.667546 90901 net.cpp:434] ReLU8 <- BatchNorm8
I0905 01:39:06.667558 90901 net.cpp:395] ReLU8 -> BatchNorm8 (in-place)
I0905 01:39:06.667901 90901 net.cpp:150] Setting up ReLU8
I0905 01:39:06.667922 90901 net.cpp:157] Top shape: 16 100 64 64 (6553600)
I0905 01:39:06.667932 90901 net.cpp:165] Memory required for data: 778830016
I0905 01:39:06.667940 90901 layer_factory.hpp:77] Creating layer Convolution9
I0905 01:39:06.667961 90901 net.cpp:100] Creating Layer Convolution9
I0905 01:39:06.667973 90901 net.cpp:434] Convolution9 <- BatchNorm8
I0905 01:39:06.667986 90901 net.cpp:408] Convolution9 -> Convolution9
I0905 01:39:06.669524 90901 net.cpp:150] Setting up Convolution9
I0905 01:39:06.669546 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.669556 90901 net.cpp:165] Memory required for data: 781975744
I0905 01:39:06.669569 90901 layer_factory.hpp:77] Creating layer Dropout9
I0905 01:39:06.669584 90901 net.cpp:100] Creating Layer Dropout9
I0905 01:39:06.669595 90901 net.cpp:434] Dropout9 <- Convolution9
I0905 01:39:06.669606 90901 net.cpp:408] Dropout9 -> Dropout9
I0905 01:39:06.669670 90901 net.cpp:150] Setting up Dropout9
I0905 01:39:06.669685 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.669695 90901 net.cpp:165] Memory required for data: 785121472
I0905 01:39:06.669703 90901 layer_factory.hpp:77] Creating layer Concat8
I0905 01:39:06.669718 90901 net.cpp:100] Creating Layer Concat8
I0905 01:39:06.669740 90901 net.cpp:434] Concat8 <- Concat7_Concat7_0_split_1
I0905 01:39:06.669751 90901 net.cpp:434] Concat8 <- Dropout9
I0905 01:39:06.669761 90901 net.cpp:408] Concat8 -> Concat8
I0905 01:39:06.669798 90901 net.cpp:150] Setting up Concat8
I0905 01:39:06.669812 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.669836 90901 net.cpp:165] Memory required for data: 814481600
I0905 01:39:06.669847 90901 layer_factory.hpp:77] Creating layer Concat8_Concat8_0_split
I0905 01:39:06.669860 90901 net.cpp:100] Creating Layer Concat8_Concat8_0_split
I0905 01:39:06.669870 90901 net.cpp:434] Concat8_Concat8_0_split <- Concat8
I0905 01:39:06.669883 90901 net.cpp:408] Concat8_Concat8_0_split -> Concat8_Concat8_0_split_0
I0905 01:39:06.669896 90901 net.cpp:408] Concat8_Concat8_0_split -> Concat8_Concat8_0_split_1
I0905 01:39:06.669952 90901 net.cpp:150] Setting up Concat8_Concat8_0_split
I0905 01:39:06.669971 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.669982 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.669991 90901 net.cpp:165] Memory required for data: 873201856
I0905 01:39:06.670001 90901 layer_factory.hpp:77] Creating layer BatchNorm9
I0905 01:39:06.670013 90901 net.cpp:100] Creating Layer BatchNorm9
I0905 01:39:06.670034 90901 net.cpp:434] BatchNorm9 <- Concat8_Concat8_0_split_0
I0905 01:39:06.670047 90901 net.cpp:408] BatchNorm9 -> BatchNorm9
I0905 01:39:06.670934 90901 net.cpp:150] Setting up BatchNorm9
I0905 01:39:06.670956 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.670966 90901 net.cpp:165] Memory required for data: 902561984
I0905 01:39:06.670980 90901 layer_factory.hpp:77] Creating layer Scale9
I0905 01:39:06.670995 90901 net.cpp:100] Creating Layer Scale9
I0905 01:39:06.671005 90901 net.cpp:434] Scale9 <- BatchNorm9
I0905 01:39:06.671017 90901 net.cpp:395] Scale9 -> BatchNorm9 (in-place)
I0905 01:39:06.671125 90901 net.cpp:150] Setting up Scale9
I0905 01:39:06.671140 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.671149 90901 net.cpp:165] Memory required for data: 931922112
I0905 01:39:06.671160 90901 layer_factory.hpp:77] Creating layer ReLU9
I0905 01:39:06.671177 90901 net.cpp:100] Creating Layer ReLU9
I0905 01:39:06.671186 90901 net.cpp:434] ReLU9 <- BatchNorm9
I0905 01:39:06.671200 90901 net.cpp:395] ReLU9 -> BatchNorm9 (in-place)
I0905 01:39:06.671391 90901 net.cpp:150] Setting up ReLU9
I0905 01:39:06.671408 90901 net.cpp:157] Top shape: 16 112 64 64 (7340032)
I0905 01:39:06.671421 90901 net.cpp:165] Memory required for data: 961282240
I0905 01:39:06.671430 90901 layer_factory.hpp:77] Creating layer Convolution10
I0905 01:39:06.671455 90901 net.cpp:100] Creating Layer Convolution10
I0905 01:39:06.671469 90901 net.cpp:434] Convolution10 <- BatchNorm9
I0905 01:39:06.671481 90901 net.cpp:408] Convolution10 -> Convolution10
I0905 01:39:06.673164 90901 net.cpp:150] Setting up Convolution10
I0905 01:39:06.673187 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.673197 90901 net.cpp:165] Memory required for data: 964427968
I0905 01:39:06.673210 90901 layer_factory.hpp:77] Creating layer Dropout10
I0905 01:39:06.673225 90901 net.cpp:100] Creating Layer Dropout10
I0905 01:39:06.673235 90901 net.cpp:434] Dropout10 <- Convolution10
I0905 01:39:06.673247 90901 net.cpp:408] Dropout10 -> Dropout10
I0905 01:39:06.673298 90901 net.cpp:150] Setting up Dropout10
I0905 01:39:06.673315 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.673324 90901 net.cpp:165] Memory required for data: 967573696
I0905 01:39:06.673334 90901 layer_factory.hpp:77] Creating layer Concat9
I0905 01:39:06.673346 90901 net.cpp:100] Creating Layer Concat9
I0905 01:39:06.673357 90901 net.cpp:434] Concat9 <- Concat8_Concat8_0_split_1
I0905 01:39:06.673367 90901 net.cpp:434] Concat9 <- Dropout10
I0905 01:39:06.673382 90901 net.cpp:408] Concat9 -> Concat9
I0905 01:39:06.673411 90901 net.cpp:150] Setting up Concat9
I0905 01:39:06.673429 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.673441 90901 net.cpp:165] Memory required for data: 1000079552
I0905 01:39:06.673449 90901 layer_factory.hpp:77] Creating layer Concat9_Concat9_0_split
I0905 01:39:06.673461 90901 net.cpp:100] Creating Layer Concat9_Concat9_0_split
I0905 01:39:06.673471 90901 net.cpp:434] Concat9_Concat9_0_split <- Concat9
I0905 01:39:06.673482 90901 net.cpp:408] Concat9_Concat9_0_split -> Concat9_Concat9_0_split_0
I0905 01:39:06.673519 90901 net.cpp:408] Concat9_Concat9_0_split -> Concat9_Concat9_0_split_1
I0905 01:39:06.673564 90901 net.cpp:150] Setting up Concat9_Concat9_0_split
I0905 01:39:06.673578 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.673588 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.673598 90901 net.cpp:165] Memory required for data: 1065091264
I0905 01:39:06.673607 90901 layer_factory.hpp:77] Creating layer BatchNorm10
I0905 01:39:06.673631 90901 net.cpp:100] Creating Layer BatchNorm10
I0905 01:39:06.673642 90901 net.cpp:434] BatchNorm10 <- Concat9_Concat9_0_split_0
I0905 01:39:06.673655 90901 net.cpp:408] BatchNorm10 -> BatchNorm10
I0905 01:39:06.673856 90901 net.cpp:150] Setting up BatchNorm10
I0905 01:39:06.673872 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.673882 90901 net.cpp:165] Memory required for data: 1097597120
I0905 01:39:06.673895 90901 layer_factory.hpp:77] Creating layer Scale10
I0905 01:39:06.673910 90901 net.cpp:100] Creating Layer Scale10
I0905 01:39:06.673919 90901 net.cpp:434] Scale10 <- BatchNorm10
I0905 01:39:06.673930 90901 net.cpp:395] Scale10 -> BatchNorm10 (in-place)
I0905 01:39:06.674028 90901 net.cpp:150] Setting up Scale10
I0905 01:39:06.674043 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.674052 90901 net.cpp:165] Memory required for data: 1130102976
I0905 01:39:06.674062 90901 layer_factory.hpp:77] Creating layer ReLU10
I0905 01:39:06.674080 90901 net.cpp:100] Creating Layer ReLU10
I0905 01:39:06.674090 90901 net.cpp:434] ReLU10 <- BatchNorm10
I0905 01:39:06.674104 90901 net.cpp:395] ReLU10 -> BatchNorm10 (in-place)
I0905 01:39:06.674448 90901 net.cpp:150] Setting up ReLU10
I0905 01:39:06.674468 90901 net.cpp:157] Top shape: 16 124 64 64 (8126464)
I0905 01:39:06.674479 90901 net.cpp:165] Memory required for data: 1162608832
I0905 01:39:06.674487 90901 layer_factory.hpp:77] Creating layer Convolution11
I0905 01:39:06.674509 90901 net.cpp:100] Creating Layer Convolution11
I0905 01:39:06.674518 90901 net.cpp:434] Convolution11 <- BatchNorm10
I0905 01:39:06.674532 90901 net.cpp:408] Convolution11 -> Convolution11
I0905 01:39:06.675956 90901 net.cpp:150] Setting up Convolution11
I0905 01:39:06.675977 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.675987 90901 net.cpp:165] Memory required for data: 1165754560
I0905 01:39:06.676000 90901 layer_factory.hpp:77] Creating layer Dropout11
I0905 01:39:06.676015 90901 net.cpp:100] Creating Layer Dropout11
I0905 01:39:06.676025 90901 net.cpp:434] Dropout11 <- Convolution11
I0905 01:39:06.676041 90901 net.cpp:408] Dropout11 -> Dropout11
I0905 01:39:06.676097 90901 net.cpp:150] Setting up Dropout11
I0905 01:39:06.676113 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.676122 90901 net.cpp:165] Memory required for data: 1168900288
I0905 01:39:06.676132 90901 layer_factory.hpp:77] Creating layer Concat10
I0905 01:39:06.676146 90901 net.cpp:100] Creating Layer Concat10
I0905 01:39:06.676156 90901 net.cpp:434] Concat10 <- Concat9_Concat9_0_split_1
I0905 01:39:06.676165 90901 net.cpp:434] Concat10 <- Dropout11
I0905 01:39:06.676178 90901 net.cpp:408] Concat10 -> Concat10
I0905 01:39:06.676213 90901 net.cpp:150] Setting up Concat10
I0905 01:39:06.676229 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.676237 90901 net.cpp:165] Memory required for data: 1204551872
I0905 01:39:06.676246 90901 layer_factory.hpp:77] Creating layer Concat10_Concat10_0_split
I0905 01:39:06.676257 90901 net.cpp:100] Creating Layer Concat10_Concat10_0_split
I0905 01:39:06.676267 90901 net.cpp:434] Concat10_Concat10_0_split <- Concat10
I0905 01:39:06.676277 90901 net.cpp:408] Concat10_Concat10_0_split -> Concat10_Concat10_0_split_0
I0905 01:39:06.676292 90901 net.cpp:408] Concat10_Concat10_0_split -> Concat10_Concat10_0_split_1
I0905 01:39:06.676332 90901 net.cpp:150] Setting up Concat10_Concat10_0_split
I0905 01:39:06.676347 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.676375 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.676384 90901 net.cpp:165] Memory required for data: 1275855040
I0905 01:39:06.676394 90901 layer_factory.hpp:77] Creating layer BatchNorm11
I0905 01:39:06.676409 90901 net.cpp:100] Creating Layer BatchNorm11
I0905 01:39:06.676429 90901 net.cpp:434] BatchNorm11 <- Concat10_Concat10_0_split_0
I0905 01:39:06.676442 90901 net.cpp:408] BatchNorm11 -> BatchNorm11
I0905 01:39:06.676641 90901 net.cpp:150] Setting up BatchNorm11
I0905 01:39:06.676656 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.676666 90901 net.cpp:165] Memory required for data: 1311506624
I0905 01:39:06.676688 90901 layer_factory.hpp:77] Creating layer Scale11
I0905 01:39:06.676704 90901 net.cpp:100] Creating Layer Scale11
I0905 01:39:06.676714 90901 net.cpp:434] Scale11 <- BatchNorm11
I0905 01:39:06.676726 90901 net.cpp:395] Scale11 -> BatchNorm11 (in-place)
I0905 01:39:06.676826 90901 net.cpp:150] Setting up Scale11
I0905 01:39:06.676842 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.676851 90901 net.cpp:165] Memory required for data: 1347158208
I0905 01:39:06.676862 90901 layer_factory.hpp:77] Creating layer ReLU11
I0905 01:39:06.676873 90901 net.cpp:100] Creating Layer ReLU11
I0905 01:39:06.676882 90901 net.cpp:434] ReLU11 <- BatchNorm11
I0905 01:39:06.676895 90901 net.cpp:395] ReLU11 -> BatchNorm11 (in-place)
I0905 01:39:06.677238 90901 net.cpp:150] Setting up ReLU11
I0905 01:39:06.677258 90901 net.cpp:157] Top shape: 16 136 64 64 (8912896)
I0905 01:39:06.677268 90901 net.cpp:165] Memory required for data: 1382809792
I0905 01:39:06.677278 90901 layer_factory.hpp:77] Creating layer Convolution12
I0905 01:39:06.677295 90901 net.cpp:100] Creating Layer Convolution12
I0905 01:39:06.677307 90901 net.cpp:434] Convolution12 <- BatchNorm11
I0905 01:39:06.677322 90901 net.cpp:408] Convolution12 -> Convolution12
I0905 01:39:06.678923 90901 net.cpp:150] Setting up Convolution12
I0905 01:39:06.678946 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.678954 90901 net.cpp:165] Memory required for data: 1385955520
I0905 01:39:06.678967 90901 layer_factory.hpp:77] Creating layer Dropout12
I0905 01:39:06.678980 90901 net.cpp:100] Creating Layer Dropout12
I0905 01:39:06.678997 90901 net.cpp:434] Dropout12 <- Convolution12
I0905 01:39:06.679008 90901 net.cpp:408] Dropout12 -> Dropout12
I0905 01:39:06.679055 90901 net.cpp:150] Setting up Dropout12
I0905 01:39:06.679072 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.679082 90901 net.cpp:165] Memory required for data: 1389101248
I0905 01:39:06.679092 90901 layer_factory.hpp:77] Creating layer Concat11
I0905 01:39:06.679103 90901 net.cpp:100] Creating Layer Concat11
I0905 01:39:06.679114 90901 net.cpp:434] Concat11 <- Concat10_Concat10_0_split_1
I0905 01:39:06.679126 90901 net.cpp:434] Concat11 <- Dropout12
I0905 01:39:06.679137 90901 net.cpp:408] Concat11 -> Concat11
I0905 01:39:06.679169 90901 net.cpp:150] Setting up Concat11
I0905 01:39:06.679184 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.679193 90901 net.cpp:165] Memory required for data: 1427898560
I0905 01:39:06.679205 90901 layer_factory.hpp:77] Creating layer Concat11_Concat11_0_split
I0905 01:39:06.679217 90901 net.cpp:100] Creating Layer Concat11_Concat11_0_split
I0905 01:39:06.679227 90901 net.cpp:434] Concat11_Concat11_0_split <- Concat11
I0905 01:39:06.679239 90901 net.cpp:408] Concat11_Concat11_0_split -> Concat11_Concat11_0_split_0
I0905 01:39:06.679252 90901 net.cpp:408] Concat11_Concat11_0_split -> Concat11_Concat11_0_split_1
I0905 01:39:06.679299 90901 net.cpp:150] Setting up Concat11_Concat11_0_split
I0905 01:39:06.679314 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.679324 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.679333 90901 net.cpp:165] Memory required for data: 1505493184
I0905 01:39:06.679344 90901 layer_factory.hpp:77] Creating layer BatchNorm12
I0905 01:39:06.679355 90901 net.cpp:100] Creating Layer BatchNorm12
I0905 01:39:06.679381 90901 net.cpp:434] BatchNorm12 <- Concat11_Concat11_0_split_0
I0905 01:39:06.679396 90901 net.cpp:408] BatchNorm12 -> BatchNorm12
I0905 01:39:06.679600 90901 net.cpp:150] Setting up BatchNorm12
I0905 01:39:06.679615 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.679625 90901 net.cpp:165] Memory required for data: 1544290496
I0905 01:39:06.679638 90901 layer_factory.hpp:77] Creating layer Scale12
I0905 01:39:06.679652 90901 net.cpp:100] Creating Layer Scale12
I0905 01:39:06.679663 90901 net.cpp:434] Scale12 <- BatchNorm12
I0905 01:39:06.679674 90901 net.cpp:395] Scale12 -> BatchNorm12 (in-place)
I0905 01:39:06.679769 90901 net.cpp:150] Setting up Scale12
I0905 01:39:06.679783 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.679792 90901 net.cpp:165] Memory required for data: 1583087808
I0905 01:39:06.679803 90901 layer_factory.hpp:77] Creating layer ReLU12
I0905 01:39:06.679821 90901 net.cpp:100] Creating Layer ReLU12
I0905 01:39:06.679833 90901 net.cpp:434] ReLU12 <- BatchNorm12
I0905 01:39:06.679847 90901 net.cpp:395] ReLU12 -> BatchNorm12 (in-place)
I0905 01:39:06.680049 90901 net.cpp:150] Setting up ReLU12
I0905 01:39:06.680066 90901 net.cpp:157] Top shape: 16 148 64 64 (9699328)
I0905 01:39:06.680075 90901 net.cpp:165] Memory required for data: 1621885120
I0905 01:39:06.680085 90901 layer_factory.hpp:77] Creating layer Convolution13
I0905 01:39:06.680102 90901 net.cpp:100] Creating Layer Convolution13
I0905 01:39:06.680114 90901 net.cpp:434] Convolution13 <- BatchNorm12
I0905 01:39:06.680129 90901 net.cpp:408] Convolution13 -> Convolution13
I0905 01:39:06.681769 90901 net.cpp:150] Setting up Convolution13
I0905 01:39:06.681792 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.681802 90901 net.cpp:165] Memory required for data: 1625030848
I0905 01:39:06.681814 90901 layer_factory.hpp:77] Creating layer Dropout13
I0905 01:39:06.681829 90901 net.cpp:100] Creating Layer Dropout13
I0905 01:39:06.681840 90901 net.cpp:434] Dropout13 <- Convolution13
I0905 01:39:06.681854 90901 net.cpp:408] Dropout13 -> Dropout13
I0905 01:39:06.681905 90901 net.cpp:150] Setting up Dropout13
I0905 01:39:06.681920 90901 net.cpp:157] Top shape: 16 12 64 64 (786432)
I0905 01:39:06.681928 90901 net.cpp:165] Memory required for data: 1628176576
I0905 01:39:06.681938 90901 layer_factory.hpp:77] Creating layer Concat12
I0905 01:39:06.681951 90901 net.cpp:100] Creating Layer Concat12
I0905 01:39:06.681960 90901 net.cpp:434] Concat12 <- Concat11_Concat11_0_split_1
I0905 01:39:06.681972 90901 net.cpp:434] Concat12 <- Dropout13
I0905 01:39:06.681989 90901 net.cpp:408] Concat12 -> Concat12
I0905 01:39:06.682021 90901 net.cpp:150] Setting up Concat12
I0905 01:39:06.682035 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.682044 90901 net.cpp:165] Memory required for data: 1670119616
I0905 01:39:06.682054 90901 layer_factory.hpp:77] Creating layer BatchNorm13
I0905 01:39:06.682068 90901 net.cpp:100] Creating Layer BatchNorm13
I0905 01:39:06.682077 90901 net.cpp:434] BatchNorm13 <- Concat12
I0905 01:39:06.682091 90901 net.cpp:408] BatchNorm13 -> BatchNorm13
I0905 01:39:06.682296 90901 net.cpp:150] Setting up BatchNorm13
I0905 01:39:06.682312 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.682322 90901 net.cpp:165] Memory required for data: 1712062656
I0905 01:39:06.682335 90901 layer_factory.hpp:77] Creating layer Scale13
I0905 01:39:06.682348 90901 net.cpp:100] Creating Layer Scale13
I0905 01:39:06.682360 90901 net.cpp:434] Scale13 <- BatchNorm13
I0905 01:39:06.682374 90901 net.cpp:395] Scale13 -> BatchNorm13 (in-place)
I0905 01:39:06.682474 90901 net.cpp:150] Setting up Scale13
I0905 01:39:06.682492 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.682500 90901 net.cpp:165] Memory required for data: 1754005696
I0905 01:39:06.682512 90901 layer_factory.hpp:77] Creating layer ReLU13
I0905 01:39:06.682523 90901 net.cpp:100] Creating Layer ReLU13
I0905 01:39:06.682533 90901 net.cpp:434] ReLU13 <- BatchNorm13
I0905 01:39:06.682543 90901 net.cpp:395] ReLU13 -> BatchNorm13 (in-place)
I0905 01:39:06.682910 90901 net.cpp:150] Setting up ReLU13
I0905 01:39:06.682934 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.682943 90901 net.cpp:165] Memory required for data: 1795948736
I0905 01:39:06.682952 90901 layer_factory.hpp:77] Creating layer Convolution14
I0905 01:39:06.682970 90901 net.cpp:100] Creating Layer Convolution14
I0905 01:39:06.682981 90901 net.cpp:434] Convolution14 <- BatchNorm13
I0905 01:39:06.682996 90901 net.cpp:408] Convolution14 -> Convolution14
I0905 01:39:06.684845 90901 net.cpp:150] Setting up Convolution14
I0905 01:39:06.684867 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.684877 90901 net.cpp:165] Memory required for data: 1837891776
I0905 01:39:06.684890 90901 layer_factory.hpp:77] Creating layer Dropout14
I0905 01:39:06.684903 90901 net.cpp:100] Creating Layer Dropout14
I0905 01:39:06.684916 90901 net.cpp:434] Dropout14 <- Convolution14
I0905 01:39:06.684931 90901 net.cpp:408] Dropout14 -> Dropout14
I0905 01:39:06.684983 90901 net.cpp:150] Setting up Dropout14
I0905 01:39:06.684998 90901 net.cpp:157] Top shape: 16 160 64 64 (10485760)
I0905 01:39:06.685008 90901 net.cpp:165] Memory required for data: 1879834816
I0905 01:39:06.685016 90901 layer_factory.hpp:77] Creating layer Pooling1
I0905 01:39:06.685031 90901 net.cpp:100] Creating Layer Pooling1
I0905 01:39:06.685045 90901 net.cpp:434] Pooling1 <- Dropout14
I0905 01:39:06.685062 90901 net.cpp:408] Pooling1 -> Pooling1
I0905 01:39:06.685422 90901 net.cpp:150] Setting up Pooling1
I0905 01:39:06.685442 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.685452 90901 net.cpp:165] Memory required for data: 1890320576
I0905 01:39:06.685461 90901 layer_factory.hpp:77] Creating layer Pooling1_Pooling1_0_split
I0905 01:39:06.685477 90901 net.cpp:100] Creating Layer Pooling1_Pooling1_0_split
I0905 01:39:06.685485 90901 net.cpp:434] Pooling1_Pooling1_0_split <- Pooling1
I0905 01:39:06.685497 90901 net.cpp:408] Pooling1_Pooling1_0_split -> Pooling1_Pooling1_0_split_0
I0905 01:39:06.685509 90901 net.cpp:408] Pooling1_Pooling1_0_split -> Pooling1_Pooling1_0_split_1
I0905 01:39:06.685555 90901 net.cpp:150] Setting up Pooling1_Pooling1_0_split
I0905 01:39:06.685570 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.685580 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.685590 90901 net.cpp:165] Memory required for data: 1911292096
I0905 01:39:06.685598 90901 layer_factory.hpp:77] Creating layer BatchNorm14
I0905 01:39:06.685613 90901 net.cpp:100] Creating Layer BatchNorm14
I0905 01:39:06.685626 90901 net.cpp:434] BatchNorm14 <- Pooling1_Pooling1_0_split_0
I0905 01:39:06.685653 90901 net.cpp:408] BatchNorm14 -> BatchNorm14
I0905 01:39:06.685886 90901 net.cpp:150] Setting up BatchNorm14
I0905 01:39:06.685904 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.685912 90901 net.cpp:165] Memory required for data: 1921777856
I0905 01:39:06.685926 90901 layer_factory.hpp:77] Creating layer Scale14
I0905 01:39:06.685940 90901 net.cpp:100] Creating Layer Scale14
I0905 01:39:06.685950 90901 net.cpp:434] Scale14 <- BatchNorm14
I0905 01:39:06.685962 90901 net.cpp:395] Scale14 -> BatchNorm14 (in-place)
I0905 01:39:06.686069 90901 net.cpp:150] Setting up Scale14
I0905 01:39:06.686087 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.686097 90901 net.cpp:165] Memory required for data: 1932263616
I0905 01:39:06.686107 90901 layer_factory.hpp:77] Creating layer ReLU14
I0905 01:39:06.686121 90901 net.cpp:100] Creating Layer ReLU14
I0905 01:39:06.686131 90901 net.cpp:434] ReLU14 <- BatchNorm14
I0905 01:39:06.686141 90901 net.cpp:395] ReLU14 -> BatchNorm14 (in-place)
I0905 01:39:06.686481 90901 net.cpp:150] Setting up ReLU14
I0905 01:39:06.686504 90901 net.cpp:157] Top shape: 16 160 32 32 (2621440)
I0905 01:39:06.686513 90901 net.cpp:165] Memory required for data: 1942749376
I0905 01:39:06.686523 90901 layer_factory.hpp:77] Creating layer Convolution15
I0905 01:39:06.686540 90901 net.cpp:100] Creating Layer Convolution15
I0905 01:39:06.686563 90901 net.cpp:434] Convolution15 <- BatchNorm14
I0905 01:39:06.686578 90901 net.cpp:408] Convolution15 -> Convolution15
I0905 01:39:06.688153 90901 net.cpp:150] Setting up Convolution15
I0905 01:39:06.688176 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.688185 90901 net.cpp:165] Memory required for data: 1943535808
I0905 01:39:06.688199 90901 layer_factory.hpp:77] Creating layer Dropout15
I0905 01:39:06.688211 90901 net.cpp:100] Creating Layer Dropout15
I0905 01:39:06.688221 90901 net.cpp:434] Dropout15 <- Convolution15
I0905 01:39:06.688235 90901 net.cpp:408] Dropout15 -> Dropout15
I0905 01:39:06.688284 90901 net.cpp:150] Setting up Dropout15
I0905 01:39:06.688308 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.688318 90901 net.cpp:165] Memory required for data: 1944322240
I0905 01:39:06.688328 90901 layer_factory.hpp:77] Creating layer Concat13
I0905 01:39:06.688341 90901 net.cpp:100] Creating Layer Concat13
I0905 01:39:06.688350 90901 net.cpp:434] Concat13 <- Pooling1_Pooling1_0_split_1
I0905 01:39:06.688370 90901 net.cpp:434] Concat13 <- Dropout15
I0905 01:39:06.688381 90901 net.cpp:408] Concat13 -> Concat13
I0905 01:39:06.688413 90901 net.cpp:150] Setting up Concat13
I0905 01:39:06.688436 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.688446 90901 net.cpp:165] Memory required for data: 1955594432
I0905 01:39:06.688455 90901 layer_factory.hpp:77] Creating layer Concat13_Concat13_0_split
I0905 01:39:06.688469 90901 net.cpp:100] Creating Layer Concat13_Concat13_0_split
I0905 01:39:06.688479 90901 net.cpp:434] Concat13_Concat13_0_split <- Concat13
I0905 01:39:06.688494 90901 net.cpp:408] Concat13_Concat13_0_split -> Concat13_Concat13_0_split_0
I0905 01:39:06.688515 90901 net.cpp:408] Concat13_Concat13_0_split -> Concat13_Concat13_0_split_1
I0905 01:39:06.688558 90901 net.cpp:150] Setting up Concat13_Concat13_0_split
I0905 01:39:06.688577 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.688588 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.688597 90901 net.cpp:165] Memory required for data: 1978138816
I0905 01:39:06.688606 90901 layer_factory.hpp:77] Creating layer BatchNorm15
I0905 01:39:06.688618 90901 net.cpp:100] Creating Layer BatchNorm15
I0905 01:39:06.688637 90901 net.cpp:434] BatchNorm15 <- Concat13_Concat13_0_split_0
I0905 01:39:06.688652 90901 net.cpp:408] BatchNorm15 -> BatchNorm15
I0905 01:39:06.688858 90901 net.cpp:150] Setting up BatchNorm15
I0905 01:39:06.688874 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.688884 90901 net.cpp:165] Memory required for data: 1989411008
I0905 01:39:06.688896 90901 layer_factory.hpp:77] Creating layer Scale15
I0905 01:39:06.688913 90901 net.cpp:100] Creating Layer Scale15
I0905 01:39:06.688923 90901 net.cpp:434] Scale15 <- BatchNorm15
I0905 01:39:06.688937 90901 net.cpp:395] Scale15 -> BatchNorm15 (in-place)
I0905 01:39:06.689043 90901 net.cpp:150] Setting up Scale15
I0905 01:39:06.689059 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.689067 90901 net.cpp:165] Memory required for data: 2000683200
I0905 01:39:06.689079 90901 layer_factory.hpp:77] Creating layer ReLU15
I0905 01:39:06.689095 90901 net.cpp:100] Creating Layer ReLU15
I0905 01:39:06.689105 90901 net.cpp:434] ReLU15 <- BatchNorm15
I0905 01:39:06.689116 90901 net.cpp:395] ReLU15 -> BatchNorm15 (in-place)
I0905 01:39:06.689472 90901 net.cpp:150] Setting up ReLU15
I0905 01:39:06.689492 90901 net.cpp:157] Top shape: 16 172 32 32 (2818048)
I0905 01:39:06.689502 90901 net.cpp:165] Memory required for data: 2011955392
I0905 01:39:06.689512 90901 layer_factory.hpp:77] Creating layer Convolution16
I0905 01:39:06.689532 90901 net.cpp:100] Creating Layer Convolution16
I0905 01:39:06.689543 90901 net.cpp:434] Convolution16 <- BatchNorm15
I0905 01:39:06.689554 90901 net.cpp:408] Convolution16 -> Convolution16
I0905 01:39:06.691294 90901 net.cpp:150] Setting up Convolution16
I0905 01:39:06.691316 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.691339 90901 net.cpp:165] Memory required for data: 2012741824
I0905 01:39:06.691354 90901 layer_factory.hpp:77] Creating layer Dropout16
I0905 01:39:06.691368 90901 net.cpp:100] Creating Layer Dropout16
I0905 01:39:06.691380 90901 net.cpp:434] Dropout16 <- Convolution16
I0905 01:39:06.691391 90901 net.cpp:408] Dropout16 -> Dropout16
I0905 01:39:06.691443 90901 net.cpp:150] Setting up Dropout16
I0905 01:39:06.691458 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.691471 90901 net.cpp:165] Memory required for data: 2013528256
I0905 01:39:06.691481 90901 layer_factory.hpp:77] Creating layer Concat14
I0905 01:39:06.691493 90901 net.cpp:100] Creating Layer Concat14
I0905 01:39:06.691503 90901 net.cpp:434] Concat14 <- Concat13_Concat13_0_split_1
I0905 01:39:06.691512 90901 net.cpp:434] Concat14 <- Dropout16
I0905 01:39:06.691525 90901 net.cpp:408] Concat14 -> Concat14
I0905 01:39:06.691556 90901 net.cpp:150] Setting up Concat14
I0905 01:39:06.691570 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.691581 90901 net.cpp:165] Memory required for data: 2025586880
I0905 01:39:06.691589 90901 layer_factory.hpp:77] Creating layer Concat14_Concat14_0_split
I0905 01:39:06.691601 90901 net.cpp:100] Creating Layer Concat14_Concat14_0_split
I0905 01:39:06.691611 90901 net.cpp:434] Concat14_Concat14_0_split <- Concat14
I0905 01:39:06.691622 90901 net.cpp:408] Concat14_Concat14_0_split -> Concat14_Concat14_0_split_0
I0905 01:39:06.691634 90901 net.cpp:408] Concat14_Concat14_0_split -> Concat14_Concat14_0_split_1
I0905 01:39:06.691678 90901 net.cpp:150] Setting up Concat14_Concat14_0_split
I0905 01:39:06.691700 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.691711 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.691720 90901 net.cpp:165] Memory required for data: 2049704128
I0905 01:39:06.691732 90901 layer_factory.hpp:77] Creating layer BatchNorm16
I0905 01:39:06.691746 90901 net.cpp:100] Creating Layer BatchNorm16
I0905 01:39:06.691756 90901 net.cpp:434] BatchNorm16 <- Concat14_Concat14_0_split_0
I0905 01:39:06.691776 90901 net.cpp:408] BatchNorm16 -> BatchNorm16
I0905 01:39:06.691998 90901 net.cpp:150] Setting up BatchNorm16
I0905 01:39:06.692013 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.692023 90901 net.cpp:165] Memory required for data: 2061762752
I0905 01:39:06.692036 90901 layer_factory.hpp:77] Creating layer Scale16
I0905 01:39:06.692049 90901 net.cpp:100] Creating Layer Scale16
I0905 01:39:06.692059 90901 net.cpp:434] Scale16 <- BatchNorm16
I0905 01:39:06.692070 90901 net.cpp:395] Scale16 -> BatchNorm16 (in-place)
I0905 01:39:06.692178 90901 net.cpp:150] Setting up Scale16
I0905 01:39:06.692193 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.692203 90901 net.cpp:165] Memory required for data: 2073821376
I0905 01:39:06.692212 90901 layer_factory.hpp:77] Creating layer ReLU16
I0905 01:39:06.692232 90901 net.cpp:100] Creating Layer ReLU16
I0905 01:39:06.692242 90901 net.cpp:434] ReLU16 <- BatchNorm16
I0905 01:39:06.692257 90901 net.cpp:395] ReLU16 -> BatchNorm16 (in-place)
I0905 01:39:06.692486 90901 net.cpp:150] Setting up ReLU16
I0905 01:39:06.692503 90901 net.cpp:157] Top shape: 16 184 32 32 (3014656)
I0905 01:39:06.692515 90901 net.cpp:165] Memory required for data: 2085880000
I0905 01:39:06.692525 90901 layer_factory.hpp:77] Creating layer Convolution17
I0905 01:39:06.692546 90901 net.cpp:100] Creating Layer Convolution17
I0905 01:39:06.692558 90901 net.cpp:434] Convolution17 <- BatchNorm16
I0905 01:39:06.692570 90901 net.cpp:408] Convolution17 -> Convolution17
I0905 01:39:06.694516 90901 net.cpp:150] Setting up Convolution17
I0905 01:39:06.694538 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.694547 90901 net.cpp:165] Memory required for data: 2086666432
I0905 01:39:06.694561 90901 layer_factory.hpp:77] Creating layer Dropout17
I0905 01:39:06.694572 90901 net.cpp:100] Creating Layer Dropout17
I0905 01:39:06.694582 90901 net.cpp:434] Dropout17 <- Convolution17
I0905 01:39:06.694608 90901 net.cpp:408] Dropout17 -> Dropout17
I0905 01:39:06.694664 90901 net.cpp:150] Setting up Dropout17
I0905 01:39:06.694682 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.694694 90901 net.cpp:165] Memory required for data: 2087452864
I0905 01:39:06.694705 90901 layer_factory.hpp:77] Creating layer Concat15
I0905 01:39:06.694720 90901 net.cpp:100] Creating Layer Concat15
I0905 01:39:06.694730 90901 net.cpp:434] Concat15 <- Concat14_Concat14_0_split_1
I0905 01:39:06.694743 90901 net.cpp:434] Concat15 <- Dropout17
I0905 01:39:06.694756 90901 net.cpp:408] Concat15 -> Concat15
I0905 01:39:06.694787 90901 net.cpp:150] Setting up Concat15
I0905 01:39:06.694800 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.694809 90901 net.cpp:165] Memory required for data: 2100297920
I0905 01:39:06.694818 90901 layer_factory.hpp:77] Creating layer Concat15_Concat15_0_split
I0905 01:39:06.694833 90901 net.cpp:100] Creating Layer Concat15_Concat15_0_split
I0905 01:39:06.694842 90901 net.cpp:434] Concat15_Concat15_0_split <- Concat15
I0905 01:39:06.694855 90901 net.cpp:408] Concat15_Concat15_0_split -> Concat15_Concat15_0_split_0
I0905 01:39:06.694869 90901 net.cpp:408] Concat15_Concat15_0_split -> Concat15_Concat15_0_split_1
I0905 01:39:06.694911 90901 net.cpp:150] Setting up Concat15_Concat15_0_split
I0905 01:39:06.694926 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.694936 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.694944 90901 net.cpp:165] Memory required for data: 2125988032
I0905 01:39:06.694952 90901 layer_factory.hpp:77] Creating layer BatchNorm17
I0905 01:39:06.694965 90901 net.cpp:100] Creating Layer BatchNorm17
I0905 01:39:06.694974 90901 net.cpp:434] BatchNorm17 <- Concat15_Concat15_0_split_0
I0905 01:39:06.694986 90901 net.cpp:408] BatchNorm17 -> BatchNorm17
I0905 01:39:06.695202 90901 net.cpp:150] Setting up BatchNorm17
I0905 01:39:06.695219 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.695227 90901 net.cpp:165] Memory required for data: 2138833088
I0905 01:39:06.695240 90901 layer_factory.hpp:77] Creating layer Scale17
I0905 01:39:06.695256 90901 net.cpp:100] Creating Layer Scale17
I0905 01:39:06.695266 90901 net.cpp:434] Scale17 <- BatchNorm17
I0905 01:39:06.695278 90901 net.cpp:395] Scale17 -> BatchNorm17 (in-place)
I0905 01:39:06.695382 90901 net.cpp:150] Setting up Scale17
I0905 01:39:06.695399 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.695406 90901 net.cpp:165] Memory required for data: 2151678144
I0905 01:39:06.695416 90901 layer_factory.hpp:77] Creating layer ReLU17
I0905 01:39:06.695427 90901 net.cpp:100] Creating Layer ReLU17
I0905 01:39:06.695437 90901 net.cpp:434] ReLU17 <- BatchNorm17
I0905 01:39:06.695447 90901 net.cpp:395] ReLU17 -> BatchNorm17 (in-place)
I0905 01:39:06.695798 90901 net.cpp:150] Setting up ReLU17
I0905 01:39:06.695818 90901 net.cpp:157] Top shape: 16 196 32 32 (3211264)
I0905 01:39:06.695827 90901 net.cpp:165] Memory required for data: 2164523200
I0905 01:39:06.695837 90901 layer_factory.hpp:77] Creating layer Convolution18
I0905 01:39:06.695854 90901 net.cpp:100] Creating Layer Convolution18
I0905 01:39:06.695865 90901 net.cpp:434] Convolution18 <- BatchNorm17
I0905 01:39:06.695879 90901 net.cpp:408] Convolution18 -> Convolution18
I0905 01:39:06.697552 90901 net.cpp:150] Setting up Convolution18
I0905 01:39:06.697573 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.697583 90901 net.cpp:165] Memory required for data: 2165309632
I0905 01:39:06.697595 90901 layer_factory.hpp:77] Creating layer Dropout18
I0905 01:39:06.697608 90901 net.cpp:100] Creating Layer Dropout18
I0905 01:39:06.697623 90901 net.cpp:434] Dropout18 <- Convolution18
I0905 01:39:06.697633 90901 net.cpp:408] Dropout18 -> Dropout18
I0905 01:39:06.697685 90901 net.cpp:150] Setting up Dropout18
I0905 01:39:06.697700 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.697708 90901 net.cpp:165] Memory required for data: 2166096064
I0905 01:39:06.697717 90901 layer_factory.hpp:77] Creating layer Concat16
I0905 01:39:06.697749 90901 net.cpp:100] Creating Layer Concat16
I0905 01:39:06.697767 90901 net.cpp:434] Concat16 <- Concat15_Concat15_0_split_1
I0905 01:39:06.697778 90901 net.cpp:434] Concat16 <- Dropout18
I0905 01:39:06.697790 90901 net.cpp:408] Concat16 -> Concat16
I0905 01:39:06.697824 90901 net.cpp:150] Setting up Concat16
I0905 01:39:06.697837 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.697849 90901 net.cpp:165] Memory required for data: 2179727552
I0905 01:39:06.697857 90901 layer_factory.hpp:77] Creating layer Concat16_Concat16_0_split
I0905 01:39:06.697867 90901 net.cpp:100] Creating Layer Concat16_Concat16_0_split
I0905 01:39:06.697893 90901 net.cpp:434] Concat16_Concat16_0_split <- Concat16
I0905 01:39:06.697906 90901 net.cpp:408] Concat16_Concat16_0_split -> Concat16_Concat16_0_split_0
I0905 01:39:06.697921 90901 net.cpp:408] Concat16_Concat16_0_split -> Concat16_Concat16_0_split_1
I0905 01:39:06.697978 90901 net.cpp:150] Setting up Concat16_Concat16_0_split
I0905 01:39:06.697993 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.698004 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.698014 90901 net.cpp:165] Memory required for data: 2206990528
I0905 01:39:06.698026 90901 layer_factory.hpp:77] Creating layer BatchNorm18
I0905 01:39:06.698041 90901 net.cpp:100] Creating Layer BatchNorm18
I0905 01:39:06.698051 90901 net.cpp:434] BatchNorm18 <- Concat16_Concat16_0_split_0
I0905 01:39:06.698065 90901 net.cpp:408] BatchNorm18 -> BatchNorm18
I0905 01:39:06.698292 90901 net.cpp:150] Setting up BatchNorm18
I0905 01:39:06.698308 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.698318 90901 net.cpp:165] Memory required for data: 2220622016
I0905 01:39:06.698333 90901 layer_factory.hpp:77] Creating layer Scale18
I0905 01:39:06.698345 90901 net.cpp:100] Creating Layer Scale18
I0905 01:39:06.698359 90901 net.cpp:434] Scale18 <- BatchNorm18
I0905 01:39:06.698371 90901 net.cpp:395] Scale18 -> BatchNorm18 (in-place)
I0905 01:39:06.698483 90901 net.cpp:150] Setting up Scale18
I0905 01:39:06.698500 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.698510 90901 net.cpp:165] Memory required for data: 2234253504
I0905 01:39:06.698521 90901 layer_factory.hpp:77] Creating layer ReLU18
I0905 01:39:06.698537 90901 net.cpp:100] Creating Layer ReLU18
I0905 01:39:06.698551 90901 net.cpp:434] ReLU18 <- BatchNorm18
I0905 01:39:06.698562 90901 net.cpp:395] ReLU18 -> BatchNorm18 (in-place)
I0905 01:39:06.698950 90901 net.cpp:150] Setting up ReLU18
I0905 01:39:06.698971 90901 net.cpp:157] Top shape: 16 208 32 32 (3407872)
I0905 01:39:06.698982 90901 net.cpp:165] Memory required for data: 2247884992
I0905 01:39:06.698992 90901 layer_factory.hpp:77] Creating layer Convolution19
I0905 01:39:06.699009 90901 net.cpp:100] Creating Layer Convolution19
I0905 01:39:06.699021 90901 net.cpp:434] Convolution19 <- BatchNorm18
I0905 01:39:06.699035 90901 net.cpp:408] Convolution19 -> Convolution19
I0905 01:39:06.703930 90901 net.cpp:150] Setting up Convolution19
I0905 01:39:06.703972 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.703982 90901 net.cpp:165] Memory required for data: 2248671424
I0905 01:39:06.703999 90901 layer_factory.hpp:77] Creating layer Dropout19
I0905 01:39:06.704041 90901 net.cpp:100] Creating Layer Dropout19
I0905 01:39:06.704068 90901 net.cpp:434] Dropout19 <- Convolution19
I0905 01:39:06.704085 90901 net.cpp:408] Dropout19 -> Dropout19
I0905 01:39:06.704144 90901 net.cpp:150] Setting up Dropout19
I0905 01:39:06.704159 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.704169 90901 net.cpp:165] Memory required for data: 2249457856
I0905 01:39:06.704177 90901 layer_factory.hpp:77] Creating layer Concat17
I0905 01:39:06.704257 90901 net.cpp:100] Creating Layer Concat17
I0905 01:39:06.704269 90901 net.cpp:434] Concat17 <- Concat16_Concat16_0_split_1
I0905 01:39:06.704291 90901 net.cpp:434] Concat17 <- Dropout19
I0905 01:39:06.704303 90901 net.cpp:408] Concat17 -> Concat17
I0905 01:39:06.704356 90901 net.cpp:150] Setting up Concat17
I0905 01:39:06.704371 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.704381 90901 net.cpp:165] Memory required for data: 2263875776
I0905 01:39:06.704391 90901 layer_factory.hpp:77] Creating layer Concat17_Concat17_0_split
I0905 01:39:06.704433 90901 net.cpp:100] Creating Layer Concat17_Concat17_0_split
I0905 01:39:06.704445 90901 net.cpp:434] Concat17_Concat17_0_split <- Concat17
I0905 01:39:06.704459 90901 net.cpp:408] Concat17_Concat17_0_split -> Concat17_Concat17_0_split_0
I0905 01:39:06.704473 90901 net.cpp:408] Concat17_Concat17_0_split -> Concat17_Concat17_0_split_1
I0905 01:39:06.704517 90901 net.cpp:150] Setting up Concat17_Concat17_0_split
I0905 01:39:06.704531 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.704542 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.704551 90901 net.cpp:165] Memory required for data: 2292711616
I0905 01:39:06.704562 90901 layer_factory.hpp:77] Creating layer BatchNorm19
I0905 01:39:06.704576 90901 net.cpp:100] Creating Layer BatchNorm19
I0905 01:39:06.704588 90901 net.cpp:434] BatchNorm19 <- Concat17_Concat17_0_split_0
I0905 01:39:06.704603 90901 net.cpp:408] BatchNorm19 -> BatchNorm19
I0905 01:39:06.704840 90901 net.cpp:150] Setting up BatchNorm19
I0905 01:39:06.704856 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.704865 90901 net.cpp:165] Memory required for data: 2307129536
I0905 01:39:06.704879 90901 layer_factory.hpp:77] Creating layer Scale19
I0905 01:39:06.704895 90901 net.cpp:100] Creating Layer Scale19
I0905 01:39:06.704905 90901 net.cpp:434] Scale19 <- BatchNorm19
I0905 01:39:06.704919 90901 net.cpp:395] Scale19 -> BatchNorm19 (in-place)
I0905 01:39:06.705024 90901 net.cpp:150] Setting up Scale19
I0905 01:39:06.705042 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.705051 90901 net.cpp:165] Memory required for data: 2321547456
I0905 01:39:06.705062 90901 layer_factory.hpp:77] Creating layer ReLU19
I0905 01:39:06.705083 90901 net.cpp:100] Creating Layer ReLU19
I0905 01:39:06.705093 90901 net.cpp:434] ReLU19 <- BatchNorm19
I0905 01:39:06.705106 90901 net.cpp:395] ReLU19 -> BatchNorm19 (in-place)
I0905 01:39:06.705379 90901 net.cpp:150] Setting up ReLU19
I0905 01:39:06.705396 90901 net.cpp:157] Top shape: 16 220 32 32 (3604480)
I0905 01:39:06.705406 90901 net.cpp:165] Memory required for data: 2335965376
I0905 01:39:06.705415 90901 layer_factory.hpp:77] Creating layer Convolution20
I0905 01:39:06.705436 90901 net.cpp:100] Creating Layer Convolution20
I0905 01:39:06.705446 90901 net.cpp:434] Convolution20 <- BatchNorm19
I0905 01:39:06.705461 90901 net.cpp:408] Convolution20 -> Convolution20
I0905 01:39:06.710073 90901 net.cpp:150] Setting up Convolution20
I0905 01:39:06.710095 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.710105 90901 net.cpp:165] Memory required for data: 2336751808
I0905 01:39:06.710119 90901 layer_factory.hpp:77] Creating layer Dropout20
I0905 01:39:06.710135 90901 net.cpp:100] Creating Layer Dropout20
I0905 01:39:06.710145 90901 net.cpp:434] Dropout20 <- Convolution20
I0905 01:39:06.710161 90901 net.cpp:408] Dropout20 -> Dropout20
I0905 01:39:06.710221 90901 net.cpp:150] Setting up Dropout20
I0905 01:39:06.710237 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.710245 90901 net.cpp:165] Memory required for data: 2337538240
I0905 01:39:06.710254 90901 layer_factory.hpp:77] Creating layer Concat18
I0905 01:39:06.710270 90901 net.cpp:100] Creating Layer Concat18
I0905 01:39:06.710280 90901 net.cpp:434] Concat18 <- Concat17_Concat17_0_split_1
I0905 01:39:06.710290 90901 net.cpp:434] Concat18 <- Dropout20
I0905 01:39:06.710304 90901 net.cpp:408] Concat18 -> Concat18
I0905 01:39:06.710332 90901 net.cpp:150] Setting up Concat18
I0905 01:39:06.710350 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.710360 90901 net.cpp:165] Memory required for data: 2352742592
I0905 01:39:06.710368 90901 layer_factory.hpp:77] Creating layer Concat18_Concat18_0_split
I0905 01:39:06.710397 90901 net.cpp:100] Creating Layer Concat18_Concat18_0_split
I0905 01:39:06.710407 90901 net.cpp:434] Concat18_Concat18_0_split <- Concat18
I0905 01:39:06.710418 90901 net.cpp:408] Concat18_Concat18_0_split -> Concat18_Concat18_0_split_0
I0905 01:39:06.710431 90901 net.cpp:408] Concat18_Concat18_0_split -> Concat18_Concat18_0_split_1
I0905 01:39:06.710475 90901 net.cpp:150] Setting up Concat18_Concat18_0_split
I0905 01:39:06.710489 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.710500 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.710508 90901 net.cpp:165] Memory required for data: 2383151296
I0905 01:39:06.710520 90901 layer_factory.hpp:77] Creating layer BatchNorm20
I0905 01:39:06.710532 90901 net.cpp:100] Creating Layer BatchNorm20
I0905 01:39:06.710542 90901 net.cpp:434] BatchNorm20 <- Concat18_Concat18_0_split_0
I0905 01:39:06.710554 90901 net.cpp:408] BatchNorm20 -> BatchNorm20
I0905 01:39:06.710803 90901 net.cpp:150] Setting up BatchNorm20
I0905 01:39:06.710819 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.710829 90901 net.cpp:165] Memory required for data: 2398355648
I0905 01:39:06.710841 90901 layer_factory.hpp:77] Creating layer Scale20
I0905 01:39:06.710855 90901 net.cpp:100] Creating Layer Scale20
I0905 01:39:06.710865 90901 net.cpp:434] Scale20 <- BatchNorm20
I0905 01:39:06.710875 90901 net.cpp:395] Scale20 -> BatchNorm20 (in-place)
I0905 01:39:06.710976 90901 net.cpp:150] Setting up Scale20
I0905 01:39:06.710991 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.711000 90901 net.cpp:165] Memory required for data: 2413560000
I0905 01:39:06.711011 90901 layer_factory.hpp:77] Creating layer ReLU20
I0905 01:39:06.711024 90901 net.cpp:100] Creating Layer ReLU20
I0905 01:39:06.711033 90901 net.cpp:434] ReLU20 <- BatchNorm20
I0905 01:39:06.711045 90901 net.cpp:395] ReLU20 -> BatchNorm20 (in-place)
I0905 01:39:06.712162 90901 net.cpp:150] Setting up ReLU20
I0905 01:39:06.712182 90901 net.cpp:157] Top shape: 16 232 32 32 (3801088)
I0905 01:39:06.712193 90901 net.cpp:165] Memory required for data: 2428764352
I0905 01:39:06.712203 90901 layer_factory.hpp:77] Creating layer Convolution21
I0905 01:39:06.712221 90901 net.cpp:100] Creating Layer Convolution21
I0905 01:39:06.712231 90901 net.cpp:434] Convolution21 <- BatchNorm20
I0905 01:39:06.712246 90901 net.cpp:408] Convolution21 -> Convolution21
I0905 01:39:06.716055 90901 net.cpp:150] Setting up Convolution21
I0905 01:39:06.716078 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.716087 90901 net.cpp:165] Memory required for data: 2429550784
I0905 01:39:06.716100 90901 layer_factory.hpp:77] Creating layer Dropout21
I0905 01:39:06.716123 90901 net.cpp:100] Creating Layer Dropout21
I0905 01:39:06.716135 90901 net.cpp:434] Dropout21 <- Convolution21
I0905 01:39:06.716150 90901 net.cpp:408] Dropout21 -> Dropout21
I0905 01:39:06.716198 90901 net.cpp:150] Setting up Dropout21
I0905 01:39:06.716212 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.716223 90901 net.cpp:165] Memory required for data: 2430337216
I0905 01:39:06.716231 90901 layer_factory.hpp:77] Creating layer Concat19
I0905 01:39:06.716244 90901 net.cpp:100] Creating Layer Concat19
I0905 01:39:06.716254 90901 net.cpp:434] Concat19 <- Concat18_Concat18_0_split_1
I0905 01:39:06.716269 90901 net.cpp:434] Concat19 <- Dropout21
I0905 01:39:06.716282 90901 net.cpp:408] Concat19 -> Concat19
I0905 01:39:06.716312 90901 net.cpp:150] Setting up Concat19
I0905 01:39:06.716328 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.716338 90901 net.cpp:165] Memory required for data: 2446328000
I0905 01:39:06.716347 90901 layer_factory.hpp:77] Creating layer Concat19_Concat19_0_split
I0905 01:39:06.716358 90901 net.cpp:100] Creating Layer Concat19_Concat19_0_split
I0905 01:39:06.716373 90901 net.cpp:434] Concat19_Concat19_0_split <- Concat19
I0905 01:39:06.716384 90901 net.cpp:408] Concat19_Concat19_0_split -> Concat19_Concat19_0_split_0
I0905 01:39:06.716397 90901 net.cpp:408] Concat19_Concat19_0_split -> Concat19_Concat19_0_split_1
I0905 01:39:06.716454 90901 net.cpp:150] Setting up Concat19_Concat19_0_split
I0905 01:39:06.716470 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.716480 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.716488 90901 net.cpp:165] Memory required for data: 2478309568
I0905 01:39:06.716501 90901 layer_factory.hpp:77] Creating layer BatchNorm21
I0905 01:39:06.716514 90901 net.cpp:100] Creating Layer BatchNorm21
I0905 01:39:06.716524 90901 net.cpp:434] BatchNorm21 <- Concat19_Concat19_0_split_0
I0905 01:39:06.716537 90901 net.cpp:408] BatchNorm21 -> BatchNorm21
I0905 01:39:06.716747 90901 net.cpp:150] Setting up BatchNorm21
I0905 01:39:06.716763 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.716771 90901 net.cpp:165] Memory required for data: 2494300352
I0905 01:39:06.716784 90901 layer_factory.hpp:77] Creating layer Scale21
I0905 01:39:06.716796 90901 net.cpp:100] Creating Layer Scale21
I0905 01:39:06.716806 90901 net.cpp:434] Scale21 <- BatchNorm21
I0905 01:39:06.716816 90901 net.cpp:395] Scale21 -> BatchNorm21 (in-place)
I0905 01:39:06.716918 90901 net.cpp:150] Setting up Scale21
I0905 01:39:06.716934 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.716943 90901 net.cpp:165] Memory required for data: 2510291136
I0905 01:39:06.716953 90901 layer_factory.hpp:77] Creating layer ReLU21
I0905 01:39:06.716967 90901 net.cpp:100] Creating Layer ReLU21
I0905 01:39:06.716976 90901 net.cpp:434] ReLU21 <- BatchNorm21
I0905 01:39:06.716989 90901 net.cpp:395] ReLU21 -> BatchNorm21 (in-place)
I0905 01:39:06.717365 90901 net.cpp:150] Setting up ReLU21
I0905 01:39:06.717387 90901 net.cpp:157] Top shape: 16 244 32 32 (3997696)
I0905 01:39:06.717397 90901 net.cpp:165] Memory required for data: 2526281920
I0905 01:39:06.717406 90901 layer_factory.hpp:77] Creating layer Convolution22
I0905 01:39:06.717427 90901 net.cpp:100] Creating Layer Convolution22
I0905 01:39:06.717437 90901 net.cpp:434] Convolution22 <- BatchNorm21
I0905 01:39:06.717453 90901 net.cpp:408] Convolution22 -> Convolution22
I0905 01:39:06.719485 90901 net.cpp:150] Setting up Convolution22
I0905 01:39:06.719507 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.719517 90901 net.cpp:165] Memory required for data: 2527068352
I0905 01:39:06.719530 90901 layer_factory.hpp:77] Creating layer Dropout22
I0905 01:39:06.719543 90901 net.cpp:100] Creating Layer Dropout22
I0905 01:39:06.719554 90901 net.cpp:434] Dropout22 <- Convolution22
I0905 01:39:06.719573 90901 net.cpp:408] Dropout22 -> Dropout22
I0905 01:39:06.719648 90901 net.cpp:150] Setting up Dropout22
I0905 01:39:06.719668 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.719677 90901 net.cpp:165] Memory required for data: 2527854784
I0905 01:39:06.719686 90901 layer_factory.hpp:77] Creating layer Concat20
I0905 01:39:06.719707 90901 net.cpp:100] Creating Layer Concat20
I0905 01:39:06.719717 90901 net.cpp:434] Concat20 <- Concat19_Concat19_0_split_1
I0905 01:39:06.719727 90901 net.cpp:434] Concat20 <- Dropout22
I0905 01:39:06.719738 90901 net.cpp:408] Concat20 -> Concat20
I0905 01:39:06.719769 90901 net.cpp:150] Setting up Concat20
I0905 01:39:06.719782 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.719792 90901 net.cpp:165] Memory required for data: 2544632000
I0905 01:39:06.719801 90901 layer_factory.hpp:77] Creating layer Concat20_Concat20_0_split
I0905 01:39:06.719812 90901 net.cpp:100] Creating Layer Concat20_Concat20_0_split
I0905 01:39:06.719822 90901 net.cpp:434] Concat20_Concat20_0_split <- Concat20
I0905 01:39:06.719837 90901 net.cpp:408] Concat20_Concat20_0_split -> Concat20_Concat20_0_split_0
I0905 01:39:06.719852 90901 net.cpp:408] Concat20_Concat20_0_split -> Concat20_Concat20_0_split_1
I0905 01:39:06.719894 90901 net.cpp:150] Setting up Concat20_Concat20_0_split
I0905 01:39:06.719909 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.719919 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.719944 90901 net.cpp:165] Memory required for data: 2578186432
I0905 01:39:06.719954 90901 layer_factory.hpp:77] Creating layer BatchNorm22
I0905 01:39:06.719971 90901 net.cpp:100] Creating Layer BatchNorm22
I0905 01:39:06.719981 90901 net.cpp:434] BatchNorm22 <- Concat20_Concat20_0_split_0
I0905 01:39:06.719995 90901 net.cpp:408] BatchNorm22 -> BatchNorm22
I0905 01:39:06.720206 90901 net.cpp:150] Setting up BatchNorm22
I0905 01:39:06.720222 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.720230 90901 net.cpp:165] Memory required for data: 2594963648
I0905 01:39:06.720268 90901 layer_factory.hpp:77] Creating layer Scale22
I0905 01:39:06.720281 90901 net.cpp:100] Creating Layer Scale22
I0905 01:39:06.720293 90901 net.cpp:434] Scale22 <- BatchNorm22
I0905 01:39:06.720304 90901 net.cpp:395] Scale22 -> BatchNorm22 (in-place)
I0905 01:39:06.720410 90901 net.cpp:150] Setting up Scale22
I0905 01:39:06.720427 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.720435 90901 net.cpp:165] Memory required for data: 2611740864
I0905 01:39:06.720445 90901 layer_factory.hpp:77] Creating layer ReLU22
I0905 01:39:06.720458 90901 net.cpp:100] Creating Layer ReLU22
I0905 01:39:06.720466 90901 net.cpp:434] ReLU22 <- BatchNorm22
I0905 01:39:06.720479 90901 net.cpp:395] ReLU22 -> BatchNorm22 (in-place)
I0905 01:39:06.720680 90901 net.cpp:150] Setting up ReLU22
I0905 01:39:06.720697 90901 net.cpp:157] Top shape: 16 256 32 32 (4194304)
I0905 01:39:06.720706 90901 net.cpp:165] Memory required for data: 2628518080
I0905 01:39:06.720715 90901 layer_factory.hpp:77] Creating layer Convolution23
I0905 01:39:06.720733 90901 net.cpp:100] Creating Layer Convolution23
I0905 01:39:06.720746 90901 net.cpp:434] Convolution23 <- BatchNorm22
I0905 01:39:06.720759 90901 net.cpp:408] Convolution23 -> Convolution23
I0905 01:39:06.723433 90901 net.cpp:150] Setting up Convolution23
I0905 01:39:06.723455 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.723465 90901 net.cpp:165] Memory required for data: 2629304512
I0905 01:39:06.723479 90901 layer_factory.hpp:77] Creating layer Dropout23
I0905 01:39:06.723492 90901 net.cpp:100] Creating Layer Dropout23
I0905 01:39:06.723503 90901 net.cpp:434] Dropout23 <- Convolution23
I0905 01:39:06.723520 90901 net.cpp:408] Dropout23 -> Dropout23
I0905 01:39:06.723578 90901 net.cpp:150] Setting up Dropout23
I0905 01:39:06.723593 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.723603 90901 net.cpp:165] Memory required for data: 2630090944
I0905 01:39:06.723611 90901 layer_factory.hpp:77] Creating layer Concat21
I0905 01:39:06.723625 90901 net.cpp:100] Creating Layer Concat21
I0905 01:39:06.723635 90901 net.cpp:434] Concat21 <- Concat20_Concat20_0_split_1
I0905 01:39:06.723646 90901 net.cpp:434] Concat21 <- Dropout23
I0905 01:39:06.723660 90901 net.cpp:408] Concat21 -> Concat21
I0905 01:39:06.723691 90901 net.cpp:150] Setting up Concat21
I0905 01:39:06.723704 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.723713 90901 net.cpp:165] Memory required for data: 2647654592
I0905 01:39:06.723722 90901 layer_factory.hpp:77] Creating layer Concat21_Concat21_0_split
I0905 01:39:06.723733 90901 net.cpp:100] Creating Layer Concat21_Concat21_0_split
I0905 01:39:06.723742 90901 net.cpp:434] Concat21_Concat21_0_split <- Concat21
I0905 01:39:06.723755 90901 net.cpp:408] Concat21_Concat21_0_split -> Concat21_Concat21_0_split_0
I0905 01:39:06.723767 90901 net.cpp:408] Concat21_Concat21_0_split -> Concat21_Concat21_0_split_1
I0905 01:39:06.723810 90901 net.cpp:150] Setting up Concat21_Concat21_0_split
I0905 01:39:06.723827 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.723837 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.723846 90901 net.cpp:165] Memory required for data: 2682781888
I0905 01:39:06.723860 90901 layer_factory.hpp:77] Creating layer BatchNorm23
I0905 01:39:06.723872 90901 net.cpp:100] Creating Layer BatchNorm23
I0905 01:39:06.723886 90901 net.cpp:434] BatchNorm23 <- Concat21_Concat21_0_split_0
I0905 01:39:06.723917 90901 net.cpp:408] BatchNorm23 -> BatchNorm23
I0905 01:39:06.724159 90901 net.cpp:150] Setting up BatchNorm23
I0905 01:39:06.724174 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.724184 90901 net.cpp:165] Memory required for data: 2700345536
I0905 01:39:06.724197 90901 layer_factory.hpp:77] Creating layer Scale23
I0905 01:39:06.724212 90901 net.cpp:100] Creating Layer Scale23
I0905 01:39:06.724225 90901 net.cpp:434] Scale23 <- BatchNorm23
I0905 01:39:06.724236 90901 net.cpp:395] Scale23 -> BatchNorm23 (in-place)
I0905 01:39:06.724346 90901 net.cpp:150] Setting up Scale23
I0905 01:39:06.724362 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.724370 90901 net.cpp:165] Memory required for data: 2717909184
I0905 01:39:06.724381 90901 layer_factory.hpp:77] Creating layer ReLU23
I0905 01:39:06.724397 90901 net.cpp:100] Creating Layer ReLU23
I0905 01:39:06.724411 90901 net.cpp:434] ReLU23 <- BatchNorm23
I0905 01:39:06.724421 90901 net.cpp:395] ReLU23 -> BatchNorm23 (in-place)
I0905 01:39:06.724993 90901 net.cpp:150] Setting up ReLU23
I0905 01:39:06.725014 90901 net.cpp:157] Top shape: 16 268 32 32 (4390912)
I0905 01:39:06.725023 90901 net.cpp:165] Memory required for data: 2735472832
I0905 01:39:06.725033 90901 layer_factory.hpp:77] Creating layer Convolution24
I0905 01:39:06.725050 90901 net.cpp:100] Creating Layer Convolution24
I0905 01:39:06.725064 90901 net.cpp:434] Convolution24 <- BatchNorm23
I0905 01:39:06.725080 90901 net.cpp:408] Convolution24 -> Convolution24
I0905 01:39:06.727006 90901 net.cpp:150] Setting up Convolution24
I0905 01:39:06.727028 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.727037 90901 net.cpp:165] Memory required for data: 2736259264
I0905 01:39:06.727051 90901 layer_factory.hpp:77] Creating layer Dropout24
I0905 01:39:06.727066 90901 net.cpp:100] Creating Layer Dropout24
I0905 01:39:06.727077 90901 net.cpp:434] Dropout24 <- Convolution24
I0905 01:39:06.727087 90901 net.cpp:408] Dropout24 -> Dropout24
I0905 01:39:06.727154 90901 net.cpp:150] Setting up Dropout24
I0905 01:39:06.727169 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.727177 90901 net.cpp:165] Memory required for data: 2737045696
I0905 01:39:06.727188 90901 layer_factory.hpp:77] Creating layer Concat22
I0905 01:39:06.727200 90901 net.cpp:100] Creating Layer Concat22
I0905 01:39:06.727210 90901 net.cpp:434] Concat22 <- Concat21_Concat21_0_split_1
I0905 01:39:06.727219 90901 net.cpp:434] Concat22 <- Dropout24
I0905 01:39:06.727231 90901 net.cpp:408] Concat22 -> Concat22
I0905 01:39:06.727263 90901 net.cpp:150] Setting up Concat22
I0905 01:39:06.727277 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.727286 90901 net.cpp:165] Memory required for data: 2755395776
I0905 01:39:06.727295 90901 layer_factory.hpp:77] Creating layer Concat22_Concat22_0_split
I0905 01:39:06.727308 90901 net.cpp:100] Creating Layer Concat22_Concat22_0_split
I0905 01:39:06.727319 90901 net.cpp:434] Concat22_Concat22_0_split <- Concat22
I0905 01:39:06.727329 90901 net.cpp:408] Concat22_Concat22_0_split -> Concat22_Concat22_0_split_0
I0905 01:39:06.727347 90901 net.cpp:408] Concat22_Concat22_0_split -> Concat22_Concat22_0_split_1
I0905 01:39:06.727392 90901 net.cpp:150] Setting up Concat22_Concat22_0_split
I0905 01:39:06.727407 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.727417 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.727427 90901 net.cpp:165] Memory required for data: 2792095936
I0905 01:39:06.727438 90901 layer_factory.hpp:77] Creating layer BatchNorm24
I0905 01:39:06.727450 90901 net.cpp:100] Creating Layer BatchNorm24
I0905 01:39:06.727459 90901 net.cpp:434] BatchNorm24 <- Concat22_Concat22_0_split_0
I0905 01:39:06.727476 90901 net.cpp:408] BatchNorm24 -> BatchNorm24
I0905 01:39:06.727725 90901 net.cpp:150] Setting up BatchNorm24
I0905 01:39:06.727740 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.727749 90901 net.cpp:165] Memory required for data: 2810446016
I0905 01:39:06.727778 90901 layer_factory.hpp:77] Creating layer Scale24
I0905 01:39:06.727792 90901 net.cpp:100] Creating Layer Scale24
I0905 01:39:06.727803 90901 net.cpp:434] Scale24 <- BatchNorm24
I0905 01:39:06.727814 90901 net.cpp:395] Scale24 -> BatchNorm24 (in-place)
I0905 01:39:06.727934 90901 net.cpp:150] Setting up Scale24
I0905 01:39:06.727951 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.727959 90901 net.cpp:165] Memory required for data: 2828796096
I0905 01:39:06.727970 90901 layer_factory.hpp:77] Creating layer ReLU24
I0905 01:39:06.727982 90901 net.cpp:100] Creating Layer ReLU24
I0905 01:39:06.727991 90901 net.cpp:434] ReLU24 <- BatchNorm24
I0905 01:39:06.728004 90901 net.cpp:395] ReLU24 -> BatchNorm24 (in-place)
I0905 01:39:06.728417 90901 net.cpp:150] Setting up ReLU24
I0905 01:39:06.728437 90901 net.cpp:157] Top shape: 16 280 32 32 (4587520)
I0905 01:39:06.728447 90901 net.cpp:165] Memory required for data: 2847146176
I0905 01:39:06.728457 90901 layer_factory.hpp:77] Creating layer Convolution25
I0905 01:39:06.728476 90901 net.cpp:100] Creating Layer Convolution25
I0905 01:39:06.728487 90901 net.cpp:434] Convolution25 <- BatchNorm24
I0905 01:39:06.728504 90901 net.cpp:408] Convolution25 -> Convolution25
I0905 01:39:06.730643 90901 net.cpp:150] Setting up Convolution25
I0905 01:39:06.730666 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.730676 90901 net.cpp:165] Memory required for data: 2847932608
I0905 01:39:06.730690 90901 layer_factory.hpp:77] Creating layer Dropout25
I0905 01:39:06.730703 90901 net.cpp:100] Creating Layer Dropout25
I0905 01:39:06.730715 90901 net.cpp:434] Dropout25 <- Convolution25
I0905 01:39:06.730726 90901 net.cpp:408] Dropout25 -> Dropout25
I0905 01:39:06.730782 90901 net.cpp:150] Setting up Dropout25
I0905 01:39:06.730798 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.730808 90901 net.cpp:165] Memory required for data: 2848719040
I0905 01:39:06.730818 90901 layer_factory.hpp:77] Creating layer Concat23
I0905 01:39:06.730831 90901 net.cpp:100] Creating Layer Concat23
I0905 01:39:06.730841 90901 net.cpp:434] Concat23 <- Concat22_Concat22_0_split_1
I0905 01:39:06.730854 90901 net.cpp:434] Concat23 <- Dropout25
I0905 01:39:06.730865 90901 net.cpp:408] Concat23 -> Concat23
I0905 01:39:06.730900 90901 net.cpp:150] Setting up Concat23
I0905 01:39:06.730913 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.730924 90901 net.cpp:165] Memory required for data: 2867855552
I0905 01:39:06.730934 90901 layer_factory.hpp:77] Creating layer Concat23_Concat23_0_split
I0905 01:39:06.730947 90901 net.cpp:100] Creating Layer Concat23_Concat23_0_split
I0905 01:39:06.730957 90901 net.cpp:434] Concat23_Concat23_0_split <- Concat23
I0905 01:39:06.730969 90901 net.cpp:408] Concat23_Concat23_0_split -> Concat23_Concat23_0_split_0
I0905 01:39:06.730983 90901 net.cpp:408] Concat23_Concat23_0_split -> Concat23_Concat23_0_split_1
I0905 01:39:06.731027 90901 net.cpp:150] Setting up Concat23_Concat23_0_split
I0905 01:39:06.731042 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.731055 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.731066 90901 net.cpp:165] Memory required for data: 2906128576
I0905 01:39:06.731076 90901 layer_factory.hpp:77] Creating layer BatchNorm25
I0905 01:39:06.731091 90901 net.cpp:100] Creating Layer BatchNorm25
I0905 01:39:06.731101 90901 net.cpp:434] BatchNorm25 <- Concat23_Concat23_0_split_0
I0905 01:39:06.731114 90901 net.cpp:408] BatchNorm25 -> BatchNorm25
I0905 01:39:06.731354 90901 net.cpp:150] Setting up BatchNorm25
I0905 01:39:06.731370 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.731379 90901 net.cpp:165] Memory required for data: 2925265088
I0905 01:39:06.731394 90901 layer_factory.hpp:77] Creating layer Scale25
I0905 01:39:06.731405 90901 net.cpp:100] Creating Layer Scale25
I0905 01:39:06.731415 90901 net.cpp:434] Scale25 <- BatchNorm25
I0905 01:39:06.731429 90901 net.cpp:395] Scale25 -> BatchNorm25 (in-place)
I0905 01:39:06.731545 90901 net.cpp:150] Setting up Scale25
I0905 01:39:06.731577 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.731586 90901 net.cpp:165] Memory required for data: 2944401600
I0905 01:39:06.731598 90901 layer_factory.hpp:77] Creating layer ReLU25
I0905 01:39:06.731611 90901 net.cpp:100] Creating Layer ReLU25
I0905 01:39:06.731623 90901 net.cpp:434] ReLU25 <- BatchNorm25
I0905 01:39:06.731633 90901 net.cpp:395] ReLU25 -> BatchNorm25 (in-place)
I0905 01:39:06.731842 90901 net.cpp:150] Setting up ReLU25
I0905 01:39:06.731860 90901 net.cpp:157] Top shape: 16 292 32 32 (4784128)
I0905 01:39:06.731869 90901 net.cpp:165] Memory required for data: 2963538112
I0905 01:39:06.731880 90901 layer_factory.hpp:77] Creating layer Convolution26
I0905 01:39:06.731897 90901 net.cpp:100] Creating Layer Convolution26
I0905 01:39:06.731909 90901 net.cpp:434] Convolution26 <- BatchNorm25
I0905 01:39:06.731922 90901 net.cpp:408] Convolution26 -> Convolution26
I0905 01:39:06.734086 90901 net.cpp:150] Setting up Convolution26
I0905 01:39:06.734107 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.734115 90901 net.cpp:165] Memory required for data: 2964324544
I0905 01:39:06.734128 90901 layer_factory.hpp:77] Creating layer Dropout26
I0905 01:39:06.734143 90901 net.cpp:100] Creating Layer Dropout26
I0905 01:39:06.734156 90901 net.cpp:434] Dropout26 <- Convolution26
I0905 01:39:06.734167 90901 net.cpp:408] Dropout26 -> Dropout26
I0905 01:39:06.734220 90901 net.cpp:150] Setting up Dropout26
I0905 01:39:06.734233 90901 net.cpp:157] Top shape: 16 12 32 32 (196608)
I0905 01:39:06.734242 90901 net.cpp:165] Memory required for data: 2965110976
I0905 01:39:06.734251 90901 layer_factory.hpp:77] Creating layer Concat24
I0905 01:39:06.734263 90901 net.cpp:100] Creating Layer Concat24
I0905 01:39:06.734273 90901 net.cpp:434] Concat24 <- Concat23_Concat23_0_split_1
I0905 01:39:06.734283 90901 net.cpp:434] Concat24 <- Dropout26
I0905 01:39:06.734295 90901 net.cpp:408] Concat24 -> Concat24
I0905 01:39:06.734324 90901 net.cpp:150] Setting up Concat24
I0905 01:39:06.734340 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.734350 90901 net.cpp:165] Memory required for data: 2985033920
I0905 01:39:06.734359 90901 layer_factory.hpp:77] Creating layer BatchNorm26
I0905 01:39:06.734370 90901 net.cpp:100] Creating Layer BatchNorm26
I0905 01:39:06.734380 90901 net.cpp:434] BatchNorm26 <- Concat24
I0905 01:39:06.734392 90901 net.cpp:408] BatchNorm26 -> BatchNorm26
I0905 01:39:06.734634 90901 net.cpp:150] Setting up BatchNorm26
I0905 01:39:06.734658 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.734673 90901 net.cpp:165] Memory required for data: 3004956864
I0905 01:39:06.734688 90901 layer_factory.hpp:77] Creating layer Scale26
I0905 01:39:06.734709 90901 net.cpp:100] Creating Layer Scale26
I0905 01:39:06.734720 90901 net.cpp:434] Scale26 <- BatchNorm26
I0905 01:39:06.734730 90901 net.cpp:395] Scale26 -> BatchNorm26 (in-place)
I0905 01:39:06.734843 90901 net.cpp:150] Setting up Scale26
I0905 01:39:06.734858 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.734865 90901 net.cpp:165] Memory required for data: 3024879808
I0905 01:39:06.734875 90901 layer_factory.hpp:77] Creating layer ReLU26
I0905 01:39:06.734889 90901 net.cpp:100] Creating Layer ReLU26
I0905 01:39:06.734899 90901 net.cpp:434] ReLU26 <- BatchNorm26
I0905 01:39:06.734907 90901 net.cpp:395] ReLU26 -> BatchNorm26 (in-place)
I0905 01:39:06.735409 90901 net.cpp:150] Setting up ReLU26
I0905 01:39:06.735433 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.735442 90901 net.cpp:165] Memory required for data: 3044802752
I0905 01:39:06.735452 90901 layer_factory.hpp:77] Creating layer Convolution27
I0905 01:39:06.735471 90901 net.cpp:100] Creating Layer Convolution27
I0905 01:39:06.735482 90901 net.cpp:434] Convolution27 <- BatchNorm26
I0905 01:39:06.735494 90901 net.cpp:408] Convolution27 -> Convolution27
I0905 01:39:06.739308 90901 net.cpp:150] Setting up Convolution27
I0905 01:39:06.739331 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.739353 90901 net.cpp:165] Memory required for data: 3064725696
I0905 01:39:06.739367 90901 layer_factory.hpp:77] Creating layer Dropout27
I0905 01:39:06.739382 90901 net.cpp:100] Creating Layer Dropout27
I0905 01:39:06.739392 90901 net.cpp:434] Dropout27 <- Convolution27
I0905 01:39:06.739403 90901 net.cpp:408] Dropout27 -> Dropout27
I0905 01:39:06.739457 90901 net.cpp:150] Setting up Dropout27
I0905 01:39:06.739475 90901 net.cpp:157] Top shape: 16 304 32 32 (4980736)
I0905 01:39:06.739483 90901 net.cpp:165] Memory required for data: 3084648640
I0905 01:39:06.739495 90901 layer_factory.hpp:77] Creating layer Pooling2
I0905 01:39:06.739508 90901 net.cpp:100] Creating Layer Pooling2
I0905 01:39:06.739526 90901 net.cpp:434] Pooling2 <- Dropout27
I0905 01:39:06.739542 90901 net.cpp:408] Pooling2 -> Pooling2
I0905 01:39:06.739900 90901 net.cpp:150] Setting up Pooling2
I0905 01:39:06.739919 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.739929 90901 net.cpp:165] Memory required for data: 3089629376
I0905 01:39:06.739938 90901 layer_factory.hpp:77] Creating layer Pooling2_Pooling2_0_split
I0905 01:39:06.739951 90901 net.cpp:100] Creating Layer Pooling2_Pooling2_0_split
I0905 01:39:06.739960 90901 net.cpp:434] Pooling2_Pooling2_0_split <- Pooling2
I0905 01:39:06.739970 90901 net.cpp:408] Pooling2_Pooling2_0_split -> Pooling2_Pooling2_0_split_0
I0905 01:39:06.739982 90901 net.cpp:408] Pooling2_Pooling2_0_split -> Pooling2_Pooling2_0_split_1
I0905 01:39:06.740028 90901 net.cpp:150] Setting up Pooling2_Pooling2_0_split
I0905 01:39:06.740041 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.740054 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.740062 90901 net.cpp:165] Memory required for data: 3099590848
I0905 01:39:06.740070 90901 layer_factory.hpp:77] Creating layer BatchNorm27
I0905 01:39:06.740083 90901 net.cpp:100] Creating Layer BatchNorm27
I0905 01:39:06.740093 90901 net.cpp:434] BatchNorm27 <- Pooling2_Pooling2_0_split_0
I0905 01:39:06.740104 90901 net.cpp:408] BatchNorm27 -> BatchNorm27
I0905 01:39:06.740335 90901 net.cpp:150] Setting up BatchNorm27
I0905 01:39:06.740350 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.740360 90901 net.cpp:165] Memory required for data: 3104571584
I0905 01:39:06.740372 90901 layer_factory.hpp:77] Creating layer Scale27
I0905 01:39:06.740387 90901 net.cpp:100] Creating Layer Scale27
I0905 01:39:06.740396 90901 net.cpp:434] Scale27 <- BatchNorm27
I0905 01:39:06.740408 90901 net.cpp:395] Scale27 -> BatchNorm27 (in-place)
I0905 01:39:06.740525 90901 net.cpp:150] Setting up Scale27
I0905 01:39:06.740540 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.740550 90901 net.cpp:165] Memory required for data: 3109552320
I0905 01:39:06.740561 90901 layer_factory.hpp:77] Creating layer ReLU27
I0905 01:39:06.740572 90901 net.cpp:100] Creating Layer ReLU27
I0905 01:39:06.740581 90901 net.cpp:434] ReLU27 <- BatchNorm27
I0905 01:39:06.740593 90901 net.cpp:395] ReLU27 -> BatchNorm27 (in-place)
I0905 01:39:06.740780 90901 net.cpp:150] Setting up ReLU27
I0905 01:39:06.740799 90901 net.cpp:157] Top shape: 16 304 16 16 (1245184)
I0905 01:39:06.740808 90901 net.cpp:165] Memory required for data: 3114533056
I0905 01:39:06.740816 90901 layer_factory.hpp:77] Creating layer Convolution28
I0905 01:39:06.740830 90901 net.cpp:100] Creating Layer Convolution28
I0905 01:39:06.740840 90901 net.cpp:434] Convolution28 <- BatchNorm27
I0905 01:39:06.740855 90901 net.cpp:408] Convolution28 -> Convolution28
I0905 01:39:06.742944 90901 net.cpp:150] Setting up Convolution28
I0905 01:39:06.742965 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.742974 90901 net.cpp:165] Memory required for data: 3114729664
I0905 01:39:06.742986 90901 layer_factory.hpp:77] Creating layer Dropout28
I0905 01:39:06.742998 90901 net.cpp:100] Creating Layer Dropout28
I0905 01:39:06.743007 90901 net.cpp:434] Dropout28 <- Convolution28
I0905 01:39:06.743019 90901 net.cpp:408] Dropout28 -> Dropout28
I0905 01:39:06.743067 90901 net.cpp:150] Setting up Dropout28
I0905 01:39:06.743093 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.743103 90901 net.cpp:165] Memory required for data: 3114926272
I0905 01:39:06.743111 90901 layer_factory.hpp:77] Creating layer Concat25
I0905 01:39:06.743127 90901 net.cpp:100] Creating Layer Concat25
I0905 01:39:06.743144 90901 net.cpp:434] Concat25 <- Pooling2_Pooling2_0_split_1
I0905 01:39:06.743160 90901 net.cpp:434] Concat25 <- Dropout28
I0905 01:39:06.743171 90901 net.cpp:408] Concat25 -> Concat25
I0905 01:39:06.743203 90901 net.cpp:150] Setting up Concat25
I0905 01:39:06.743221 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.743229 90901 net.cpp:165] Memory required for data: 3120103616
I0905 01:39:06.743242 90901 layer_factory.hpp:77] Creating layer Concat25_Concat25_0_split
I0905 01:39:06.743252 90901 net.cpp:100] Creating Layer Concat25_Concat25_0_split
I0905 01:39:06.743264 90901 net.cpp:434] Concat25_Concat25_0_split <- Concat25
I0905 01:39:06.743278 90901 net.cpp:408] Concat25_Concat25_0_split -> Concat25_Concat25_0_split_0
I0905 01:39:06.743289 90901 net.cpp:408] Concat25_Concat25_0_split -> Concat25_Concat25_0_split_1
I0905 01:39:06.743333 90901 net.cpp:150] Setting up Concat25_Concat25_0_split
I0905 01:39:06.743348 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.743358 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.743366 90901 net.cpp:165] Memory required for data: 3130458304
I0905 01:39:06.743377 90901 layer_factory.hpp:77] Creating layer BatchNorm28
I0905 01:39:06.743391 90901 net.cpp:100] Creating Layer BatchNorm28
I0905 01:39:06.743402 90901 net.cpp:434] BatchNorm28 <- Concat25_Concat25_0_split_0
I0905 01:39:06.743414 90901 net.cpp:408] BatchNorm28 -> BatchNorm28
I0905 01:39:06.743636 90901 net.cpp:150] Setting up BatchNorm28
I0905 01:39:06.743651 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.743659 90901 net.cpp:165] Memory required for data: 3135635648
I0905 01:39:06.743671 90901 layer_factory.hpp:77] Creating layer Scale28
I0905 01:39:06.743687 90901 net.cpp:100] Creating Layer Scale28
I0905 01:39:06.743696 90901 net.cpp:434] Scale28 <- BatchNorm28
I0905 01:39:06.743706 90901 net.cpp:395] Scale28 -> BatchNorm28 (in-place)
I0905 01:39:06.743813 90901 net.cpp:150] Setting up Scale28
I0905 01:39:06.743829 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.743836 90901 net.cpp:165] Memory required for data: 3140812992
I0905 01:39:06.743846 90901 layer_factory.hpp:77] Creating layer ReLU28
I0905 01:39:06.743862 90901 net.cpp:100] Creating Layer ReLU28
I0905 01:39:06.743872 90901 net.cpp:434] ReLU28 <- BatchNorm28
I0905 01:39:06.743881 90901 net.cpp:395] ReLU28 -> BatchNorm28 (in-place)
I0905 01:39:06.744235 90901 net.cpp:150] Setting up ReLU28
I0905 01:39:06.744253 90901 net.cpp:157] Top shape: 16 316 16 16 (1294336)
I0905 01:39:06.744262 90901 net.cpp:165] Memory required for data: 3145990336
I0905 01:39:06.744272 90901 layer_factory.hpp:77] Creating layer Convolution29
I0905 01:39:06.744288 90901 net.cpp:100] Creating Layer Convolution29
I0905 01:39:06.744300 90901 net.cpp:434] Convolution29 <- BatchNorm28
I0905 01:39:06.744313 90901 net.cpp:408] Convolution29 -> Convolution29
I0905 01:39:06.746422 90901 net.cpp:150] Setting up Convolution29
I0905 01:39:06.746443 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.746451 90901 net.cpp:165] Memory required for data: 3146186944
I0905 01:39:06.746464 90901 layer_factory.hpp:77] Creating layer Dropout29
I0905 01:39:06.746479 90901 net.cpp:100] Creating Layer Dropout29
I0905 01:39:06.746491 90901 net.cpp:434] Dropout29 <- Convolution29
I0905 01:39:06.746502 90901 net.cpp:408] Dropout29 -> Dropout29
I0905 01:39:06.746547 90901 net.cpp:150] Setting up Dropout29
I0905 01:39:06.746562 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.746570 90901 net.cpp:165] Memory required for data: 3146383552
I0905 01:39:06.746579 90901 layer_factory.hpp:77] Creating layer Concat26
I0905 01:39:06.746595 90901 net.cpp:100] Creating Layer Concat26
I0905 01:39:06.746616 90901 net.cpp:434] Concat26 <- Concat25_Concat25_0_split_1
I0905 01:39:06.746634 90901 net.cpp:434] Concat26 <- Dropout29
I0905 01:39:06.746649 90901 net.cpp:408] Concat26 -> Concat26
I0905 01:39:06.746685 90901 net.cpp:150] Setting up Concat26
I0905 01:39:06.746700 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.746708 90901 net.cpp:165] Memory required for data: 3151757504
I0905 01:39:06.746716 90901 layer_factory.hpp:77] Creating layer Concat26_Concat26_0_split
I0905 01:39:06.746731 90901 net.cpp:100] Creating Layer Concat26_Concat26_0_split
I0905 01:39:06.746739 90901 net.cpp:434] Concat26_Concat26_0_split <- Concat26
I0905 01:39:06.746752 90901 net.cpp:408] Concat26_Concat26_0_split -> Concat26_Concat26_0_split_0
I0905 01:39:06.746764 90901 net.cpp:408] Concat26_Concat26_0_split -> Concat26_Concat26_0_split_1
I0905 01:39:06.746808 90901 net.cpp:150] Setting up Concat26_Concat26_0_split
I0905 01:39:06.746821 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.746831 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.746840 90901 net.cpp:165] Memory required for data: 3162505408
I0905 01:39:06.746851 90901 layer_factory.hpp:77] Creating layer BatchNorm29
I0905 01:39:06.746863 90901 net.cpp:100] Creating Layer BatchNorm29
I0905 01:39:06.746873 90901 net.cpp:434] BatchNorm29 <- Concat26_Concat26_0_split_0
I0905 01:39:06.746887 90901 net.cpp:408] BatchNorm29 -> BatchNorm29
I0905 01:39:06.747117 90901 net.cpp:150] Setting up BatchNorm29
I0905 01:39:06.747133 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.747140 90901 net.cpp:165] Memory required for data: 3167879360
I0905 01:39:06.747153 90901 layer_factory.hpp:77] Creating layer Scale29
I0905 01:39:06.747169 90901 net.cpp:100] Creating Layer Scale29
I0905 01:39:06.747177 90901 net.cpp:434] Scale29 <- BatchNorm29
I0905 01:39:06.747189 90901 net.cpp:395] Scale29 -> BatchNorm29 (in-place)
I0905 01:39:06.747301 90901 net.cpp:150] Setting up Scale29
I0905 01:39:06.747316 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.747324 90901 net.cpp:165] Memory required for data: 3173253312
I0905 01:39:06.747334 90901 layer_factory.hpp:77] Creating layer ReLU29
I0905 01:39:06.747349 90901 net.cpp:100] Creating Layer ReLU29
I0905 01:39:06.747357 90901 net.cpp:434] ReLU29 <- BatchNorm29
I0905 01:39:06.747373 90901 net.cpp:395] ReLU29 -> BatchNorm29 (in-place)
I0905 01:39:06.747591 90901 net.cpp:150] Setting up ReLU29
I0905 01:39:06.747607 90901 net.cpp:157] Top shape: 16 328 16 16 (1343488)
I0905 01:39:06.747615 90901 net.cpp:165] Memory required for data: 3178627264
I0905 01:39:06.747624 90901 layer_factory.hpp:77] Creating layer Convolution30
I0905 01:39:06.747642 90901 net.cpp:100] Creating Layer Convolution30
I0905 01:39:06.747653 90901 net.cpp:434] Convolution30 <- BatchNorm29
I0905 01:39:06.747665 90901 net.cpp:408] Convolution30 -> Convolution30
I0905 01:39:06.749985 90901 net.cpp:150] Setting up Convolution30
I0905 01:39:06.750007 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.750016 90901 net.cpp:165] Memory required for data: 3178823872
I0905 01:39:06.750030 90901 layer_factory.hpp:77] Creating layer Dropout30
I0905 01:39:06.750044 90901 net.cpp:100] Creating Layer Dropout30
I0905 01:39:06.750054 90901 net.cpp:434] Dropout30 <- Convolution30
I0905 01:39:06.750066 90901 net.cpp:408] Dropout30 -> Dropout30
I0905 01:39:06.750110 90901 net.cpp:150] Setting up Dropout30
I0905 01:39:06.750126 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.750136 90901 net.cpp:165] Memory required for data: 3179020480
I0905 01:39:06.750144 90901 layer_factory.hpp:77] Creating layer Concat27
I0905 01:39:06.750155 90901 net.cpp:100] Creating Layer Concat27
I0905 01:39:06.750165 90901 net.cpp:434] Concat27 <- Concat26_Concat26_0_split_1
I0905 01:39:06.750179 90901 net.cpp:434] Concat27 <- Dropout30
I0905 01:39:06.750188 90901 net.cpp:408] Concat27 -> Concat27
I0905 01:39:06.750221 90901 net.cpp:150] Setting up Concat27
I0905 01:39:06.750247 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.750257 90901 net.cpp:165] Memory required for data: 3184591040
I0905 01:39:06.750265 90901 layer_factory.hpp:77] Creating layer Concat27_Concat27_0_split
I0905 01:39:06.750284 90901 net.cpp:100] Creating Layer Concat27_Concat27_0_split
I0905 01:39:06.750294 90901 net.cpp:434] Concat27_Concat27_0_split <- Concat27
I0905 01:39:06.750313 90901 net.cpp:408] Concat27_Concat27_0_split -> Concat27_Concat27_0_split_0
I0905 01:39:06.750325 90901 net.cpp:408] Concat27_Concat27_0_split -> Concat27_Concat27_0_split_1
I0905 01:39:06.750375 90901 net.cpp:150] Setting up Concat27_Concat27_0_split
I0905 01:39:06.750388 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.750399 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.750408 90901 net.cpp:165] Memory required for data: 3195732160
I0905 01:39:06.750416 90901 layer_factory.hpp:77] Creating layer BatchNorm30
I0905 01:39:06.750427 90901 net.cpp:100] Creating Layer BatchNorm30
I0905 01:39:06.750440 90901 net.cpp:434] BatchNorm30 <- Concat27_Concat27_0_split_0
I0905 01:39:06.750452 90901 net.cpp:408] BatchNorm30 -> BatchNorm30
I0905 01:39:06.750725 90901 net.cpp:150] Setting up BatchNorm30
I0905 01:39:06.750741 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.750749 90901 net.cpp:165] Memory required for data: 3201302720
I0905 01:39:06.750763 90901 layer_factory.hpp:77] Creating layer Scale30
I0905 01:39:06.750780 90901 net.cpp:100] Creating Layer Scale30
I0905 01:39:06.750789 90901 net.cpp:434] Scale30 <- BatchNorm30
I0905 01:39:06.750800 90901 net.cpp:395] Scale30 -> BatchNorm30 (in-place)
I0905 01:39:06.750911 90901 net.cpp:150] Setting up Scale30
I0905 01:39:06.750926 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.750934 90901 net.cpp:165] Memory required for data: 3206873280
I0905 01:39:06.750944 90901 layer_factory.hpp:77] Creating layer ReLU30
I0905 01:39:06.750957 90901 net.cpp:100] Creating Layer ReLU30
I0905 01:39:06.750965 90901 net.cpp:434] ReLU30 <- BatchNorm30
I0905 01:39:06.750982 90901 net.cpp:395] ReLU30 -> BatchNorm30 (in-place)
I0905 01:39:06.751179 90901 net.cpp:150] Setting up ReLU30
I0905 01:39:06.751196 90901 net.cpp:157] Top shape: 16 340 16 16 (1392640)
I0905 01:39:06.751204 90901 net.cpp:165] Memory required for data: 3212443840
I0905 01:39:06.751214 90901 layer_factory.hpp:77] Creating layer Convolution31
I0905 01:39:06.751230 90901 net.cpp:100] Creating Layer Convolution31
I0905 01:39:06.751240 90901 net.cpp:434] Convolution31 <- BatchNorm30
I0905 01:39:06.751252 90901 net.cpp:408] Convolution31 -> Convolution31
I0905 01:39:06.753415 90901 net.cpp:150] Setting up Convolution31
I0905 01:39:06.753437 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.753445 90901 net.cpp:165] Memory required for data: 3212640448
I0905 01:39:06.753456 90901 layer_factory.hpp:77] Creating layer Dropout31
I0905 01:39:06.753468 90901 net.cpp:100] Creating Layer Dropout31
I0905 01:39:06.753478 90901 net.cpp:434] Dropout31 <- Convolution31
I0905 01:39:06.753490 90901 net.cpp:408] Dropout31 -> Dropout31
I0905 01:39:06.753533 90901 net.cpp:150] Setting up Dropout31
I0905 01:39:06.753547 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.753556 90901 net.cpp:165] Memory required for data: 3212837056
I0905 01:39:06.753564 90901 layer_factory.hpp:77] Creating layer Concat28
I0905 01:39:06.753576 90901 net.cpp:100] Creating Layer Concat28
I0905 01:39:06.753587 90901 net.cpp:434] Concat28 <- Concat27_Concat27_0_split_1
I0905 01:39:06.753597 90901 net.cpp:434] Concat28 <- Dropout31
I0905 01:39:06.753609 90901 net.cpp:408] Concat28 -> Concat28
I0905 01:39:06.753636 90901 net.cpp:150] Setting up Concat28
I0905 01:39:06.753649 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.753657 90901 net.cpp:165] Memory required for data: 3218604224
I0905 01:39:06.753665 90901 layer_factory.hpp:77] Creating layer Concat28_Concat28_0_split
I0905 01:39:06.753676 90901 net.cpp:100] Creating Layer Concat28_Concat28_0_split
I0905 01:39:06.753698 90901 net.cpp:434] Concat28_Concat28_0_split <- Concat28
I0905 01:39:06.753715 90901 net.cpp:408] Concat28_Concat28_0_split -> Concat28_Concat28_0_split_0
I0905 01:39:06.753726 90901 net.cpp:408] Concat28_Concat28_0_split -> Concat28_Concat28_0_split_1
I0905 01:39:06.753768 90901 net.cpp:150] Setting up Concat28_Concat28_0_split
I0905 01:39:06.753782 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.753790 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.753798 90901 net.cpp:165] Memory required for data: 3230138560
I0905 01:39:06.753806 90901 layer_factory.hpp:77] Creating layer BatchNorm31
I0905 01:39:06.753818 90901 net.cpp:100] Creating Layer BatchNorm31
I0905 01:39:06.753829 90901 net.cpp:434] BatchNorm31 <- Concat28_Concat28_0_split_0
I0905 01:39:06.753839 90901 net.cpp:408] BatchNorm31 -> BatchNorm31
I0905 01:39:06.754045 90901 net.cpp:150] Setting up BatchNorm31
I0905 01:39:06.754057 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.754065 90901 net.cpp:165] Memory required for data: 3235905728
I0905 01:39:06.754077 90901 layer_factory.hpp:77] Creating layer Scale31
I0905 01:39:06.754091 90901 net.cpp:100] Creating Layer Scale31
I0905 01:39:06.754099 90901 net.cpp:434] Scale31 <- BatchNorm31
I0905 01:39:06.754108 90901 net.cpp:395] Scale31 -> BatchNorm31 (in-place)
I0905 01:39:06.754214 90901 net.cpp:150] Setting up Scale31
I0905 01:39:06.754226 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.754235 90901 net.cpp:165] Memory required for data: 3241672896
I0905 01:39:06.754245 90901 layer_factory.hpp:77] Creating layer ReLU31
I0905 01:39:06.754258 90901 net.cpp:100] Creating Layer ReLU31
I0905 01:39:06.754267 90901 net.cpp:434] ReLU31 <- BatchNorm31
I0905 01:39:06.754276 90901 net.cpp:395] ReLU31 -> BatchNorm31 (in-place)
I0905 01:39:06.754607 90901 net.cpp:150] Setting up ReLU31
I0905 01:39:06.754624 90901 net.cpp:157] Top shape: 16 352 16 16 (1441792)
I0905 01:39:06.754643 90901 net.cpp:165] Memory required for data: 3247440064
I0905 01:39:06.754663 90901 layer_factory.hpp:77] Creating layer Convolution32
I0905 01:39:06.754680 90901 net.cpp:100] Creating Layer Convolution32
I0905 01:39:06.754690 90901 net.cpp:434] Convolution32 <- BatchNorm31
I0905 01:39:06.754703 90901 net.cpp:408] Convolution32 -> Convolution32
I0905 01:39:06.757321 90901 net.cpp:150] Setting up Convolution32
I0905 01:39:06.757341 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.757349 90901 net.cpp:165] Memory required for data: 3247636672
I0905 01:39:06.757365 90901 layer_factory.hpp:77] Creating layer Dropout32
I0905 01:39:06.757376 90901 net.cpp:100] Creating Layer Dropout32
I0905 01:39:06.757385 90901 net.cpp:434] Dropout32 <- Convolution32
I0905 01:39:06.757397 90901 net.cpp:408] Dropout32 -> Dropout32
I0905 01:39:06.757438 90901 net.cpp:150] Setting up Dropout32
I0905 01:39:06.757457 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.757465 90901 net.cpp:165] Memory required for data: 3247833280
I0905 01:39:06.757474 90901 layer_factory.hpp:77] Creating layer Concat29
I0905 01:39:06.757485 90901 net.cpp:100] Creating Layer Concat29
I0905 01:39:06.757495 90901 net.cpp:434] Concat29 <- Concat28_Concat28_0_split_1
I0905 01:39:06.757504 90901 net.cpp:434] Concat29 <- Dropout32
I0905 01:39:06.757516 90901 net.cpp:408] Concat29 -> Concat29
I0905 01:39:06.757546 90901 net.cpp:150] Setting up Concat29
I0905 01:39:06.757560 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.757568 90901 net.cpp:165] Memory required for data: 3253797056
I0905 01:39:06.757576 90901 layer_factory.hpp:77] Creating layer Concat29_Concat29_0_split
I0905 01:39:06.757588 90901 net.cpp:100] Creating Layer Concat29_Concat29_0_split
I0905 01:39:06.757597 90901 net.cpp:434] Concat29_Concat29_0_split <- Concat29
I0905 01:39:06.757611 90901 net.cpp:408] Concat29_Concat29_0_split -> Concat29_Concat29_0_split_0
I0905 01:39:06.757622 90901 net.cpp:408] Concat29_Concat29_0_split -> Concat29_Concat29_0_split_1
I0905 01:39:06.757675 90901 net.cpp:150] Setting up Concat29_Concat29_0_split
I0905 01:39:06.757689 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.757699 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.757706 90901 net.cpp:165] Memory required for data: 3265724608
I0905 01:39:06.757714 90901 layer_factory.hpp:77] Creating layer BatchNorm32
I0905 01:39:06.757726 90901 net.cpp:100] Creating Layer BatchNorm32
I0905 01:39:06.757735 90901 net.cpp:434] BatchNorm32 <- Concat29_Concat29_0_split_0
I0905 01:39:06.757747 90901 net.cpp:408] BatchNorm32 -> BatchNorm32
I0905 01:39:06.757967 90901 net.cpp:150] Setting up BatchNorm32
I0905 01:39:06.757982 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.757988 90901 net.cpp:165] Memory required for data: 3271688384
I0905 01:39:06.758000 90901 layer_factory.hpp:77] Creating layer Scale32
I0905 01:39:06.758011 90901 net.cpp:100] Creating Layer Scale32
I0905 01:39:06.758019 90901 net.cpp:434] Scale32 <- BatchNorm32
I0905 01:39:06.758031 90901 net.cpp:395] Scale32 -> BatchNorm32 (in-place)
I0905 01:39:06.758134 90901 net.cpp:150] Setting up Scale32
I0905 01:39:06.758148 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.758157 90901 net.cpp:165] Memory required for data: 3277652160
I0905 01:39:06.758164 90901 layer_factory.hpp:77] Creating layer ReLU32
I0905 01:39:06.758175 90901 net.cpp:100] Creating Layer ReLU32
I0905 01:39:06.758183 90901 net.cpp:434] ReLU32 <- BatchNorm32
I0905 01:39:06.758191 90901 net.cpp:395] ReLU32 -> BatchNorm32 (in-place)
I0905 01:39:06.758370 90901 net.cpp:150] Setting up ReLU32
I0905 01:39:06.758388 90901 net.cpp:157] Top shape: 16 364 16 16 (1490944)
I0905 01:39:06.758395 90901 net.cpp:165] Memory required for data: 3283615936
I0905 01:39:06.758404 90901 layer_factory.hpp:77] Creating layer Convolution33
I0905 01:39:06.758419 90901 net.cpp:100] Creating Layer Convolution33
I0905 01:39:06.758427 90901 net.cpp:434] Convolution33 <- BatchNorm32
I0905 01:39:06.758440 90901 net.cpp:408] Convolution33 -> Convolution33
I0905 01:39:06.760512 90901 net.cpp:150] Setting up Convolution33
I0905 01:39:06.760532 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.760541 90901 net.cpp:165] Memory required for data: 3283812544
I0905 01:39:06.760552 90901 layer_factory.hpp:77] Creating layer Dropout33
I0905 01:39:06.760563 90901 net.cpp:100] Creating Layer Dropout33
I0905 01:39:06.760571 90901 net.cpp:434] Dropout33 <- Convolution33
I0905 01:39:06.760584 90901 net.cpp:408] Dropout33 -> Dropout33
I0905 01:39:06.760625 90901 net.cpp:150] Setting up Dropout33
I0905 01:39:06.760638 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.760646 90901 net.cpp:165] Memory required for data: 3284009152
I0905 01:39:06.760654 90901 layer_factory.hpp:77] Creating layer Concat30
I0905 01:39:06.760664 90901 net.cpp:100] Creating Layer Concat30
I0905 01:39:06.760673 90901 net.cpp:434] Concat30 <- Concat29_Concat29_0_split_1
I0905 01:39:06.760685 90901 net.cpp:434] Concat30 <- Dropout33
I0905 01:39:06.760697 90901 net.cpp:408] Concat30 -> Concat30
I0905 01:39:06.760728 90901 net.cpp:150] Setting up Concat30
I0905 01:39:06.760741 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.760749 90901 net.cpp:165] Memory required for data: 3290169536
I0905 01:39:06.760757 90901 layer_factory.hpp:77] Creating layer Concat30_Concat30_0_split
I0905 01:39:06.760767 90901 net.cpp:100] Creating Layer Concat30_Concat30_0_split
I0905 01:39:06.760776 90901 net.cpp:434] Concat30_Concat30_0_split <- Concat30
I0905 01:39:06.760789 90901 net.cpp:408] Concat30_Concat30_0_split -> Concat30_Concat30_0_split_0
I0905 01:39:06.760812 90901 net.cpp:408] Concat30_Concat30_0_split -> Concat30_Concat30_0_split_1
I0905 01:39:06.760850 90901 net.cpp:150] Setting up Concat30_Concat30_0_split
I0905 01:39:06.760864 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.760872 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.760879 90901 net.cpp:165] Memory required for data: 3302490304
I0905 01:39:06.760900 90901 layer_factory.hpp:77] Creating layer BatchNorm33
I0905 01:39:06.760913 90901 net.cpp:100] Creating Layer BatchNorm33
I0905 01:39:06.760922 90901 net.cpp:434] BatchNorm33 <- Concat30_Concat30_0_split_0
I0905 01:39:06.760936 90901 net.cpp:408] BatchNorm33 -> BatchNorm33
I0905 01:39:06.761147 90901 net.cpp:150] Setting up BatchNorm33
I0905 01:39:06.761162 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.761168 90901 net.cpp:165] Memory required for data: 3308650688
I0905 01:39:06.761180 90901 layer_factory.hpp:77] Creating layer Scale33
I0905 01:39:06.761191 90901 net.cpp:100] Creating Layer Scale33
I0905 01:39:06.761199 90901 net.cpp:434] Scale33 <- BatchNorm33
I0905 01:39:06.761212 90901 net.cpp:395] Scale33 -> BatchNorm33 (in-place)
I0905 01:39:06.761322 90901 net.cpp:150] Setting up Scale33
I0905 01:39:06.761337 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.761344 90901 net.cpp:165] Memory required for data: 3314811072
I0905 01:39:06.761353 90901 layer_factory.hpp:77] Creating layer ReLU33
I0905 01:39:06.761366 90901 net.cpp:100] Creating Layer ReLU33
I0905 01:39:06.761374 90901 net.cpp:434] ReLU33 <- BatchNorm33
I0905 01:39:06.761382 90901 net.cpp:395] ReLU33 -> BatchNorm33 (in-place)
I0905 01:39:06.761564 90901 net.cpp:150] Setting up ReLU33
I0905 01:39:06.761579 90901 net.cpp:157] Top shape: 16 376 16 16 (1540096)
I0905 01:39:06.761587 90901 net.cpp:165] Memory required for data: 3320971456
I0905 01:39:06.761595 90901 layer_factory.hpp:77] Creating layer Convolution34
I0905 01:39:06.761610 90901 net.cpp:100] Creating Layer Convolution34
I0905 01:39:06.761620 90901 net.cpp:434] Convolution34 <- BatchNorm33
I0905 01:39:06.761632 90901 net.cpp:408] Convolution34 -> Convolution34
I0905 01:39:06.763744 90901 net.cpp:150] Setting up Convolution34
I0905 01:39:06.763763 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.763779 90901 net.cpp:165] Memory required for data: 3321168064
I0905 01:39:06.763794 90901 layer_factory.hpp:77] Creating layer Dropout34
I0905 01:39:06.763809 90901 net.cpp:100] Creating Layer Dropout34
I0905 01:39:06.763821 90901 net.cpp:434] Dropout34 <- Convolution34
I0905 01:39:06.763833 90901 net.cpp:408] Dropout34 -> Dropout34
I0905 01:39:06.763873 90901 net.cpp:150] Setting up Dropout34
I0905 01:39:06.763896 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.763905 90901 net.cpp:165] Memory required for data: 3321364672
I0905 01:39:06.763912 90901 layer_factory.hpp:77] Creating layer Concat31
I0905 01:39:06.763922 90901 net.cpp:100] Creating Layer Concat31
I0905 01:39:06.763931 90901 net.cpp:434] Concat31 <- Concat30_Concat30_0_split_1
I0905 01:39:06.763942 90901 net.cpp:434] Concat31 <- Dropout34
I0905 01:39:06.763953 90901 net.cpp:408] Concat31 -> Concat31
I0905 01:39:06.763983 90901 net.cpp:150] Setting up Concat31
I0905 01:39:06.763996 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.764004 90901 net.cpp:165] Memory required for data: 3327721664
I0905 01:39:06.764013 90901 layer_factory.hpp:77] Creating layer Concat31_Concat31_0_split
I0905 01:39:06.764039 90901 net.cpp:100] Creating Layer Concat31_Concat31_0_split
I0905 01:39:06.764048 90901 net.cpp:434] Concat31_Concat31_0_split <- Concat31
I0905 01:39:06.764062 90901 net.cpp:408] Concat31_Concat31_0_split -> Concat31_Concat31_0_split_0
I0905 01:39:06.764075 90901 net.cpp:408] Concat31_Concat31_0_split -> Concat31_Concat31_0_split_1
I0905 01:39:06.764128 90901 net.cpp:150] Setting up Concat31_Concat31_0_split
I0905 01:39:06.764142 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.764149 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.764158 90901 net.cpp:165] Memory required for data: 3340435648
I0905 01:39:06.764169 90901 layer_factory.hpp:77] Creating layer BatchNorm34
I0905 01:39:06.764181 90901 net.cpp:100] Creating Layer BatchNorm34
I0905 01:39:06.764190 90901 net.cpp:434] BatchNorm34 <- Concat31_Concat31_0_split_0
I0905 01:39:06.764200 90901 net.cpp:408] BatchNorm34 -> BatchNorm34
I0905 01:39:06.764410 90901 net.cpp:150] Setting up BatchNorm34
I0905 01:39:06.764436 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.764444 90901 net.cpp:165] Memory required for data: 3346792640
I0905 01:39:06.764456 90901 layer_factory.hpp:77] Creating layer Scale34
I0905 01:39:06.764467 90901 net.cpp:100] Creating Layer Scale34
I0905 01:39:06.764475 90901 net.cpp:434] Scale34 <- BatchNorm34
I0905 01:39:06.764488 90901 net.cpp:395] Scale34 -> BatchNorm34 (in-place)
I0905 01:39:06.764595 90901 net.cpp:150] Setting up Scale34
I0905 01:39:06.764610 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.764616 90901 net.cpp:165] Memory required for data: 3353149632
I0905 01:39:06.764626 90901 layer_factory.hpp:77] Creating layer ReLU34
I0905 01:39:06.764637 90901 net.cpp:100] Creating Layer ReLU34
I0905 01:39:06.764647 90901 net.cpp:434] ReLU34 <- BatchNorm34
I0905 01:39:06.764657 90901 net.cpp:395] ReLU34 -> BatchNorm34 (in-place)
I0905 01:39:06.765010 90901 net.cpp:150] Setting up ReLU34
I0905 01:39:06.765030 90901 net.cpp:157] Top shape: 16 388 16 16 (1589248)
I0905 01:39:06.765038 90901 net.cpp:165] Memory required for data: 3359506624
I0905 01:39:06.765048 90901 layer_factory.hpp:77] Creating layer Convolution35
I0905 01:39:06.765061 90901 net.cpp:100] Creating Layer Convolution35
I0905 01:39:06.765069 90901 net.cpp:434] Convolution35 <- BatchNorm34
I0905 01:39:06.765084 90901 net.cpp:408] Convolution35 -> Convolution35
I0905 01:39:06.767247 90901 net.cpp:150] Setting up Convolution35
I0905 01:39:06.767266 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.767276 90901 net.cpp:165] Memory required for data: 3359703232
I0905 01:39:06.767287 90901 layer_factory.hpp:77] Creating layer Dropout35
I0905 01:39:06.767297 90901 net.cpp:100] Creating Layer Dropout35
I0905 01:39:06.767307 90901 net.cpp:434] Dropout35 <- Convolution35
I0905 01:39:06.767319 90901 net.cpp:408] Dropout35 -> Dropout35
I0905 01:39:06.767360 90901 net.cpp:150] Setting up Dropout35
I0905 01:39:06.767374 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.767382 90901 net.cpp:165] Memory required for data: 3359899840
I0905 01:39:06.767390 90901 layer_factory.hpp:77] Creating layer Concat32
I0905 01:39:06.767402 90901 net.cpp:100] Creating Layer Concat32
I0905 01:39:06.767411 90901 net.cpp:434] Concat32 <- Concat31_Concat31_0_split_1
I0905 01:39:06.767421 90901 net.cpp:434] Concat32 <- Dropout35
I0905 01:39:06.767433 90901 net.cpp:408] Concat32 -> Concat32
I0905 01:39:06.767463 90901 net.cpp:150] Setting up Concat32
I0905 01:39:06.767477 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.767484 90901 net.cpp:165] Memory required for data: 3366453440
I0905 01:39:06.767493 90901 layer_factory.hpp:77] Creating layer Concat32_Concat32_0_split
I0905 01:39:06.767501 90901 net.cpp:100] Creating Layer Concat32_Concat32_0_split
I0905 01:39:06.767510 90901 net.cpp:434] Concat32_Concat32_0_split <- Concat32
I0905 01:39:06.767521 90901 net.cpp:408] Concat32_Concat32_0_split -> Concat32_Concat32_0_split_0
I0905 01:39:06.767534 90901 net.cpp:408] Concat32_Concat32_0_split -> Concat32_Concat32_0_split_1
I0905 01:39:06.767577 90901 net.cpp:150] Setting up Concat32_Concat32_0_split
I0905 01:39:06.767588 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.767598 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.767606 90901 net.cpp:165] Memory required for data: 3379560640
I0905 01:39:06.767616 90901 layer_factory.hpp:77] Creating layer BatchNorm35
I0905 01:39:06.767632 90901 net.cpp:100] Creating Layer BatchNorm35
I0905 01:39:06.767642 90901 net.cpp:434] BatchNorm35 <- Concat32_Concat32_0_split_0
I0905 01:39:06.767654 90901 net.cpp:408] BatchNorm35 -> BatchNorm35
I0905 01:39:06.767868 90901 net.cpp:150] Setting up BatchNorm35
I0905 01:39:06.767882 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.767889 90901 net.cpp:165] Memory required for data: 3386114240
I0905 01:39:06.767902 90901 layer_factory.hpp:77] Creating layer Scale35
I0905 01:39:06.767915 90901 net.cpp:100] Creating Layer Scale35
I0905 01:39:06.767935 90901 net.cpp:434] Scale35 <- BatchNorm35
I0905 01:39:06.767947 90901 net.cpp:395] Scale35 -> BatchNorm35 (in-place)
I0905 01:39:06.768059 90901 net.cpp:150] Setting up Scale35
I0905 01:39:06.768074 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.768081 90901 net.cpp:165] Memory required for data: 3392667840
I0905 01:39:06.768090 90901 layer_factory.hpp:77] Creating layer ReLU35
I0905 01:39:06.768103 90901 net.cpp:100] Creating Layer ReLU35
I0905 01:39:06.768111 90901 net.cpp:434] ReLU35 <- BatchNorm35
I0905 01:39:06.768120 90901 net.cpp:395] ReLU35 -> BatchNorm35 (in-place)
I0905 01:39:06.768304 90901 net.cpp:150] Setting up ReLU35
I0905 01:39:06.768322 90901 net.cpp:157] Top shape: 16 400 16 16 (1638400)
I0905 01:39:06.768331 90901 net.cpp:165] Memory required for data: 3399221440
I0905 01:39:06.768338 90901 layer_factory.hpp:77] Creating layer Convolution36
I0905 01:39:06.768352 90901 net.cpp:100] Creating Layer Convolution36
I0905 01:39:06.768360 90901 net.cpp:434] Convolution36 <- BatchNorm35
I0905 01:39:06.768374 90901 net.cpp:408] Convolution36 -> Convolution36
I0905 01:39:06.770784 90901 net.cpp:150] Setting up Convolution36
I0905 01:39:06.770804 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.770812 90901 net.cpp:165] Memory required for data: 3399418048
I0905 01:39:06.770823 90901 layer_factory.hpp:77] Creating layer Dropout36
I0905 01:39:06.770838 90901 net.cpp:100] Creating Layer Dropout36
I0905 01:39:06.770846 90901 net.cpp:434] Dropout36 <- Convolution36
I0905 01:39:06.770858 90901 net.cpp:408] Dropout36 -> Dropout36
I0905 01:39:06.770900 90901 net.cpp:150] Setting up Dropout36
I0905 01:39:06.770915 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.770922 90901 net.cpp:165] Memory required for data: 3399614656
I0905 01:39:06.770931 90901 layer_factory.hpp:77] Creating layer Concat33
I0905 01:39:06.770941 90901 net.cpp:100] Creating Layer Concat33
I0905 01:39:06.770949 90901 net.cpp:434] Concat33 <- Concat32_Concat32_0_split_1
I0905 01:39:06.770961 90901 net.cpp:434] Concat33 <- Dropout36
I0905 01:39:06.770974 90901 net.cpp:408] Concat33 -> Concat33
I0905 01:39:06.771003 90901 net.cpp:150] Setting up Concat33
I0905 01:39:06.771014 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.771023 90901 net.cpp:165] Memory required for data: 3406364864
I0905 01:39:06.771031 90901 layer_factory.hpp:77] Creating layer Concat33_Concat33_0_split
I0905 01:39:06.771042 90901 net.cpp:100] Creating Layer Concat33_Concat33_0_split
I0905 01:39:06.771051 90901 net.cpp:434] Concat33_Concat33_0_split <- Concat33
I0905 01:39:06.771066 90901 net.cpp:408] Concat33_Concat33_0_split -> Concat33_Concat33_0_split_0
I0905 01:39:06.771077 90901 net.cpp:408] Concat33_Concat33_0_split -> Concat33_Concat33_0_split_1
I0905 01:39:06.771117 90901 net.cpp:150] Setting up Concat33_Concat33_0_split
I0905 01:39:06.771131 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.771139 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.771147 90901 net.cpp:165] Memory required for data: 3419865280
I0905 01:39:06.771154 90901 layer_factory.hpp:77] Creating layer BatchNorm36
I0905 01:39:06.771167 90901 net.cpp:100] Creating Layer BatchNorm36
I0905 01:39:06.771176 90901 net.cpp:434] BatchNorm36 <- Concat33_Concat33_0_split_0
I0905 01:39:06.771185 90901 net.cpp:408] BatchNorm36 -> BatchNorm36
I0905 01:39:06.771401 90901 net.cpp:150] Setting up BatchNorm36
I0905 01:39:06.771416 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.771425 90901 net.cpp:165] Memory required for data: 3426615488
I0905 01:39:06.771435 90901 layer_factory.hpp:77] Creating layer Scale36
I0905 01:39:06.771448 90901 net.cpp:100] Creating Layer Scale36
I0905 01:39:06.771458 90901 net.cpp:434] Scale36 <- BatchNorm36
I0905 01:39:06.771467 90901 net.cpp:395] Scale36 -> BatchNorm36 (in-place)
I0905 01:39:06.771575 90901 net.cpp:150] Setting up Scale36
I0905 01:39:06.771589 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.771610 90901 net.cpp:165] Memory required for data: 3433365696
I0905 01:39:06.771620 90901 layer_factory.hpp:77] Creating layer ReLU36
I0905 01:39:06.771631 90901 net.cpp:100] Creating Layer ReLU36
I0905 01:39:06.771639 90901 net.cpp:434] ReLU36 <- BatchNorm36
I0905 01:39:06.771653 90901 net.cpp:395] ReLU36 -> BatchNorm36 (in-place)
I0905 01:39:06.771836 90901 net.cpp:150] Setting up ReLU36
I0905 01:39:06.771852 90901 net.cpp:157] Top shape: 16 412 16 16 (1687552)
I0905 01:39:06.771859 90901 net.cpp:165] Memory required for data: 3440115904
I0905 01:39:06.771867 90901 layer_factory.hpp:77] Creating layer Convolution37
I0905 01:39:06.771885 90901 net.cpp:100] Creating Layer Convolution37
I0905 01:39:06.771894 90901 net.cpp:434] Convolution37 <- BatchNorm36
I0905 01:39:06.771908 90901 net.cpp:408] Convolution37 -> Convolution37
I0905 01:39:06.774170 90901 net.cpp:150] Setting up Convolution37
I0905 01:39:06.774191 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.774201 90901 net.cpp:165] Memory required for data: 3440312512
I0905 01:39:06.774214 90901 layer_factory.hpp:77] Creating layer Dropout37
I0905 01:39:06.774229 90901 net.cpp:100] Creating Layer Dropout37
I0905 01:39:06.774240 90901 net.cpp:434] Dropout37 <- Convolution37
I0905 01:39:06.774252 90901 net.cpp:408] Dropout37 -> Dropout37
I0905 01:39:06.774299 90901 net.cpp:150] Setting up Dropout37
I0905 01:39:06.774314 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.774323 90901 net.cpp:165] Memory required for data: 3440509120
I0905 01:39:06.774333 90901 layer_factory.hpp:77] Creating layer Concat34
I0905 01:39:06.774348 90901 net.cpp:100] Creating Layer Concat34
I0905 01:39:06.774361 90901 net.cpp:434] Concat34 <- Concat33_Concat33_0_split_1
I0905 01:39:06.774387 90901 net.cpp:434] Concat34 <- Dropout37
I0905 01:39:06.774399 90901 net.cpp:408] Concat34 -> Concat34
I0905 01:39:06.774431 90901 net.cpp:150] Setting up Concat34
I0905 01:39:06.774446 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.774454 90901 net.cpp:165] Memory required for data: 3447455936
I0905 01:39:06.774463 90901 layer_factory.hpp:77] Creating layer Concat34_Concat34_0_split
I0905 01:39:06.774479 90901 net.cpp:100] Creating Layer Concat34_Concat34_0_split
I0905 01:39:06.774495 90901 net.cpp:434] Concat34_Concat34_0_split <- Concat34
I0905 01:39:06.774507 90901 net.cpp:408] Concat34_Concat34_0_split -> Concat34_Concat34_0_split_0
I0905 01:39:06.774518 90901 net.cpp:408] Concat34_Concat34_0_split -> Concat34_Concat34_0_split_1
I0905 01:39:06.774564 90901 net.cpp:150] Setting up Concat34_Concat34_0_split
I0905 01:39:06.774579 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.774588 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.774597 90901 net.cpp:165] Memory required for data: 3461349568
I0905 01:39:06.774610 90901 layer_factory.hpp:77] Creating layer BatchNorm37
I0905 01:39:06.774623 90901 net.cpp:100] Creating Layer BatchNorm37
I0905 01:39:06.774641 90901 net.cpp:434] BatchNorm37 <- Concat34_Concat34_0_split_0
I0905 01:39:06.774654 90901 net.cpp:408] BatchNorm37 -> BatchNorm37
I0905 01:39:06.774893 90901 net.cpp:150] Setting up BatchNorm37
I0905 01:39:06.774909 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.774919 90901 net.cpp:165] Memory required for data: 3468296384
I0905 01:39:06.774931 90901 layer_factory.hpp:77] Creating layer Scale37
I0905 01:39:06.774981 90901 net.cpp:100] Creating Layer Scale37
I0905 01:39:06.774992 90901 net.cpp:434] Scale37 <- BatchNorm37
I0905 01:39:06.775004 90901 net.cpp:395] Scale37 -> BatchNorm37 (in-place)
I0905 01:39:06.775121 90901 net.cpp:150] Setting up Scale37
I0905 01:39:06.775137 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.775146 90901 net.cpp:165] Memory required for data: 3475243200
I0905 01:39:06.775157 90901 layer_factory.hpp:77] Creating layer ReLU37
I0905 01:39:06.775171 90901 net.cpp:100] Creating Layer ReLU37
I0905 01:39:06.775182 90901 net.cpp:434] ReLU37 <- BatchNorm37
I0905 01:39:06.775192 90901 net.cpp:395] ReLU37 -> BatchNorm37 (in-place)
I0905 01:39:06.775578 90901 net.cpp:150] Setting up ReLU37
I0905 01:39:06.775600 90901 net.cpp:157] Top shape: 16 424 16 16 (1736704)
I0905 01:39:06.775610 90901 net.cpp:165] Memory required for data: 3482190016
I0905 01:39:06.775620 90901 layer_factory.hpp:77] Creating layer Convolution38
I0905 01:39:06.775637 90901 net.cpp:100] Creating Layer Convolution38
I0905 01:39:06.775648 90901 net.cpp:434] Convolution38 <- BatchNorm37
I0905 01:39:06.775660 90901 net.cpp:408] Convolution38 -> Convolution38
I0905 01:39:06.778906 90901 net.cpp:150] Setting up Convolution38
I0905 01:39:06.778928 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.778939 90901 net.cpp:165] Memory required for data: 3482386624
I0905 01:39:06.778952 90901 layer_factory.hpp:77] Creating layer Dropout38
I0905 01:39:06.778965 90901 net.cpp:100] Creating Layer Dropout38
I0905 01:39:06.778975 90901 net.cpp:434] Dropout38 <- Convolution38
I0905 01:39:06.779002 90901 net.cpp:408] Dropout38 -> Dropout38
I0905 01:39:06.779048 90901 net.cpp:150] Setting up Dropout38
I0905 01:39:06.779063 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.779072 90901 net.cpp:165] Memory required for data: 3482583232
I0905 01:39:06.779081 90901 layer_factory.hpp:77] Creating layer Concat35
I0905 01:39:06.779095 90901 net.cpp:100] Creating Layer Concat35
I0905 01:39:06.779105 90901 net.cpp:434] Concat35 <- Concat34_Concat34_0_split_1
I0905 01:39:06.779115 90901 net.cpp:434] Concat35 <- Dropout38
I0905 01:39:06.779126 90901 net.cpp:408] Concat35 -> Concat35
I0905 01:39:06.779157 90901 net.cpp:150] Setting up Concat35
I0905 01:39:06.779171 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.779181 90901 net.cpp:165] Memory required for data: 3489726656
I0905 01:39:06.779189 90901 layer_factory.hpp:77] Creating layer Concat35_Concat35_0_split
I0905 01:39:06.779201 90901 net.cpp:100] Creating Layer Concat35_Concat35_0_split
I0905 01:39:06.779213 90901 net.cpp:434] Concat35_Concat35_0_split <- Concat35
I0905 01:39:06.779228 90901 net.cpp:408] Concat35_Concat35_0_split -> Concat35_Concat35_0_split_0
I0905 01:39:06.779242 90901 net.cpp:408] Concat35_Concat35_0_split -> Concat35_Concat35_0_split_1
I0905 01:39:06.779284 90901 net.cpp:150] Setting up Concat35_Concat35_0_split
I0905 01:39:06.779301 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.779312 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.779320 90901 net.cpp:165] Memory required for data: 3504013504
I0905 01:39:06.779330 90901 layer_factory.hpp:77] Creating layer BatchNorm38
I0905 01:39:06.779340 90901 net.cpp:100] Creating Layer BatchNorm38
I0905 01:39:06.779355 90901 net.cpp:434] BatchNorm38 <- Concat35_Concat35_0_split_0
I0905 01:39:06.779367 90901 net.cpp:408] BatchNorm38 -> BatchNorm38
I0905 01:39:06.779605 90901 net.cpp:150] Setting up BatchNorm38
I0905 01:39:06.779620 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.779628 90901 net.cpp:165] Memory required for data: 3511156928
I0905 01:39:06.779641 90901 layer_factory.hpp:77] Creating layer Scale38
I0905 01:39:06.779659 90901 net.cpp:100] Creating Layer Scale38
I0905 01:39:06.779670 90901 net.cpp:434] Scale38 <- BatchNorm38
I0905 01:39:06.779680 90901 net.cpp:395] Scale38 -> BatchNorm38 (in-place)
I0905 01:39:06.779794 90901 net.cpp:150] Setting up Scale38
I0905 01:39:06.779809 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.779817 90901 net.cpp:165] Memory required for data: 3518300352
I0905 01:39:06.779827 90901 layer_factory.hpp:77] Creating layer ReLU38
I0905 01:39:06.779841 90901 net.cpp:100] Creating Layer ReLU38
I0905 01:39:06.779850 90901 net.cpp:434] ReLU38 <- BatchNorm38
I0905 01:39:06.779860 90901 net.cpp:395] ReLU38 -> BatchNorm38 (in-place)
I0905 01:39:06.780059 90901 net.cpp:150] Setting up ReLU38
I0905 01:39:06.780076 90901 net.cpp:157] Top shape: 16 436 16 16 (1785856)
I0905 01:39:06.780084 90901 net.cpp:165] Memory required for data: 3525443776
I0905 01:39:06.780092 90901 layer_factory.hpp:77] Creating layer Convolution39
I0905 01:39:06.780122 90901 net.cpp:100] Creating Layer Convolution39
I0905 01:39:06.780133 90901 net.cpp:434] Convolution39 <- BatchNorm38
I0905 01:39:06.780148 90901 net.cpp:408] Convolution39 -> Convolution39
I0905 01:39:06.782656 90901 net.cpp:150] Setting up Convolution39
I0905 01:39:06.782676 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.782686 90901 net.cpp:165] Memory required for data: 3525640384
I0905 01:39:06.782698 90901 layer_factory.hpp:77] Creating layer Dropout39
I0905 01:39:06.782712 90901 net.cpp:100] Creating Layer Dropout39
I0905 01:39:06.782723 90901 net.cpp:434] Dropout39 <- Convolution39
I0905 01:39:06.782735 90901 net.cpp:408] Dropout39 -> Dropout39
I0905 01:39:06.782781 90901 net.cpp:150] Setting up Dropout39
I0905 01:39:06.782796 90901 net.cpp:157] Top shape: 16 12 16 16 (49152)
I0905 01:39:06.782805 90901 net.cpp:165] Memory required for data: 3525836992
I0905 01:39:06.782817 90901 layer_factory.hpp:77] Creating layer Concat36
I0905 01:39:06.782831 90901 net.cpp:100] Creating Layer Concat36
I0905 01:39:06.782841 90901 net.cpp:434] Concat36 <- Concat35_Concat35_0_split_1
I0905 01:39:06.782851 90901 net.cpp:434] Concat36 <- Dropout39
I0905 01:39:06.782865 90901 net.cpp:408] Concat36 -> Concat36
I0905 01:39:06.782896 90901 net.cpp:150] Setting up Concat36
I0905 01:39:06.782909 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.782918 90901 net.cpp:165] Memory required for data: 3533177024
I0905 01:39:06.782927 90901 layer_factory.hpp:77] Creating layer BatchNorm39
I0905 01:39:06.782946 90901 net.cpp:100] Creating Layer BatchNorm39
I0905 01:39:06.782958 90901 net.cpp:434] BatchNorm39 <- Concat36
I0905 01:39:06.782971 90901 net.cpp:408] BatchNorm39 -> BatchNorm39
I0905 01:39:06.783211 90901 net.cpp:150] Setting up BatchNorm39
I0905 01:39:06.783227 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.783236 90901 net.cpp:165] Memory required for data: 3540517056
I0905 01:39:06.783248 90901 layer_factory.hpp:77] Creating layer Scale39
I0905 01:39:06.783262 90901 net.cpp:100] Creating Layer Scale39
I0905 01:39:06.783272 90901 net.cpp:434] Scale39 <- BatchNorm39
I0905 01:39:06.783280 90901 net.cpp:395] Scale39 -> BatchNorm39 (in-place)
I0905 01:39:06.783396 90901 net.cpp:150] Setting up Scale39
I0905 01:39:06.783412 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.783421 90901 net.cpp:165] Memory required for data: 3547857088
I0905 01:39:06.783432 90901 layer_factory.hpp:77] Creating layer ReLU39
I0905 01:39:06.783442 90901 net.cpp:100] Creating Layer ReLU39
I0905 01:39:06.783458 90901 net.cpp:434] ReLU39 <- BatchNorm39
I0905 01:39:06.783468 90901 net.cpp:395] ReLU39 -> BatchNorm39 (in-place)
I0905 01:39:06.783676 90901 net.cpp:150] Setting up ReLU39
I0905 01:39:06.783694 90901 net.cpp:157] Top shape: 16 448 16 16 (1835008)
I0905 01:39:06.783702 90901 net.cpp:165] Memory required for data: 3555197120
I0905 01:39:06.783711 90901 layer_factory.hpp:77] Creating layer Pooling3
I0905 01:39:06.783725 90901 net.cpp:100] Creating Layer Pooling3
I0905 01:39:06.783735 90901 net.cpp:434] Pooling3 <- BatchNorm39
I0905 01:39:06.783746 90901 net.cpp:408] Pooling3 -> Pooling3
I0905 01:39:06.785228 90901 net.cpp:150] Setting up Pooling3
I0905 01:39:06.785248 90901 net.cpp:157] Top shape: 16 448 1 1 (7168)
I0905 01:39:06.785257 90901 net.cpp:165] Memory required for data: 3555225792
I0905 01:39:06.785266 90901 layer_factory.hpp:77] Creating layer InnerProduct1
I0905 01:39:06.785284 90901 net.cpp:100] Creating Layer InnerProduct1
I0905 01:39:06.785292 90901 net.cpp:434] InnerProduct1 <- Pooling3
I0905 01:39:06.785305 90901 net.cpp:408] InnerProduct1 -> InnerProduct1
I0905 01:39:06.785446 90901 net.cpp:150] Setting up InnerProduct1
I0905 01:39:06.785461 90901 net.cpp:157] Top shape: 16 2 (32)
I0905 01:39:06.785470 90901 net.cpp:165] Memory required for data: 3555225920
I0905 01:39:06.785481 90901 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0905 01:39:06.785495 90901 net.cpp:100] Creating Layer InnerProduct1_InnerProduct1_0_split
I0905 01:39:06.785517 90901 net.cpp:434] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0905 01:39:06.785528 90901 net.cpp:408] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0905 01:39:06.785540 90901 net.cpp:408] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0905 01:39:06.785590 90901 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0905 01:39:06.785604 90901 net.cpp:157] Top shape: 16 2 (32)
I0905 01:39:06.785614 90901 net.cpp:157] Top shape: 16 2 (32)
I0905 01:39:06.785624 90901 net.cpp:165] Memory required for data: 3555226176
I0905 01:39:06.785632 90901 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0905 01:39:06.785643 90901 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0905 01:39:06.785652 90901 net.cpp:434] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0905 01:39:06.785662 90901 net.cpp:434] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0905 01:39:06.785676 90901 net.cpp:408] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0905 01:39:06.785692 90901 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0905 01:39:06.787070 90901 net.cpp:150] Setting up SoftmaxWithLoss1
I0905 01:39:06.787089 90901 net.cpp:157] Top shape: (1)
I0905 01:39:06.787098 90901 net.cpp:160]     with loss weight 1
I0905 01:39:06.787132 90901 net.cpp:165] Memory required for data: 3555226180
I0905 01:39:06.787142 90901 layer_factory.hpp:77] Creating layer Accuracy1
I0905 01:39:06.787163 90901 net.cpp:100] Creating Layer Accuracy1
I0905 01:39:06.787173 90901 net.cpp:434] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0905 01:39:06.787184 90901 net.cpp:434] Accuracy1 <- Data2_Data1_1_split_1
I0905 01:39:06.787195 90901 net.cpp:408] Accuracy1 -> Accuracy1
I0905 01:39:06.787212 90901 net.cpp:150] Setting up Accuracy1
I0905 01:39:06.787225 90901 net.cpp:157] Top shape: (1)
I0905 01:39:06.787232 90901 net.cpp:165] Memory required for data: 3555226184
I0905 01:39:06.787245 90901 net.cpp:228] Accuracy1 does not need backward computation.
I0905 01:39:06.787255 90901 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0905 01:39:06.787264 90901 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0905 01:39:06.787274 90901 net.cpp:226] InnerProduct1 needs backward computation.
I0905 01:39:06.787283 90901 net.cpp:226] Pooling3 needs backward computation.
I0905 01:39:06.787292 90901 net.cpp:226] ReLU39 needs backward computation.
I0905 01:39:06.787299 90901 net.cpp:226] Scale39 needs backward computation.
I0905 01:39:06.787308 90901 net.cpp:226] BatchNorm39 needs backward computation.
I0905 01:39:06.787317 90901 net.cpp:226] Concat36 needs backward computation.
I0905 01:39:06.787325 90901 net.cpp:226] Dropout39 needs backward computation.
I0905 01:39:06.787334 90901 net.cpp:226] Convolution39 needs backward computation.
I0905 01:39:06.787343 90901 net.cpp:226] ReLU38 needs backward computation.
I0905 01:39:06.787350 90901 net.cpp:226] Scale38 needs backward computation.
I0905 01:39:06.787358 90901 net.cpp:226] BatchNorm38 needs backward computation.
I0905 01:39:06.787367 90901 net.cpp:226] Concat35_Concat35_0_split needs backward computation.
I0905 01:39:06.787375 90901 net.cpp:226] Concat35 needs backward computation.
I0905 01:39:06.787387 90901 net.cpp:226] Dropout38 needs backward computation.
I0905 01:39:06.787395 90901 net.cpp:226] Convolution38 needs backward computation.
I0905 01:39:06.787405 90901 net.cpp:226] ReLU37 needs backward computation.
I0905 01:39:06.787412 90901 net.cpp:226] Scale37 needs backward computation.
I0905 01:39:06.787420 90901 net.cpp:226] BatchNorm37 needs backward computation.
I0905 01:39:06.787428 90901 net.cpp:226] Concat34_Concat34_0_split needs backward computation.
I0905 01:39:06.787437 90901 net.cpp:226] Concat34 needs backward computation.
I0905 01:39:06.787446 90901 net.cpp:226] Dropout37 needs backward computation.
I0905 01:39:06.787454 90901 net.cpp:226] Convolution37 needs backward computation.
I0905 01:39:06.787467 90901 net.cpp:226] ReLU36 needs backward computation.
I0905 01:39:06.787487 90901 net.cpp:226] Scale36 needs backward computation.
I0905 01:39:06.787494 90901 net.cpp:226] BatchNorm36 needs backward computation.
I0905 01:39:06.787503 90901 net.cpp:226] Concat33_Concat33_0_split needs backward computation.
I0905 01:39:06.787513 90901 net.cpp:226] Concat33 needs backward computation.
I0905 01:39:06.787520 90901 net.cpp:226] Dropout36 needs backward computation.
I0905 01:39:06.787529 90901 net.cpp:226] Convolution36 needs backward computation.
I0905 01:39:06.787538 90901 net.cpp:226] ReLU35 needs backward computation.
I0905 01:39:06.787545 90901 net.cpp:226] Scale35 needs backward computation.
I0905 01:39:06.787554 90901 net.cpp:226] BatchNorm35 needs backward computation.
I0905 01:39:06.787564 90901 net.cpp:226] Concat32_Concat32_0_split needs backward computation.
I0905 01:39:06.787572 90901 net.cpp:226] Concat32 needs backward computation.
I0905 01:39:06.787580 90901 net.cpp:226] Dropout35 needs backward computation.
I0905 01:39:06.787588 90901 net.cpp:226] Convolution35 needs backward computation.
I0905 01:39:06.787597 90901 net.cpp:226] ReLU34 needs backward computation.
I0905 01:39:06.787606 90901 net.cpp:226] Scale34 needs backward computation.
I0905 01:39:06.787613 90901 net.cpp:226] BatchNorm34 needs backward computation.
I0905 01:39:06.787622 90901 net.cpp:226] Concat31_Concat31_0_split needs backward computation.
I0905 01:39:06.787631 90901 net.cpp:226] Concat31 needs backward computation.
I0905 01:39:06.787639 90901 net.cpp:226] Dropout34 needs backward computation.
I0905 01:39:06.787647 90901 net.cpp:226] Convolution34 needs backward computation.
I0905 01:39:06.787655 90901 net.cpp:226] ReLU33 needs backward computation.
I0905 01:39:06.787663 90901 net.cpp:226] Scale33 needs backward computation.
I0905 01:39:06.787672 90901 net.cpp:226] BatchNorm33 needs backward computation.
I0905 01:39:06.787680 90901 net.cpp:226] Concat30_Concat30_0_split needs backward computation.
I0905 01:39:06.787688 90901 net.cpp:226] Concat30 needs backward computation.
I0905 01:39:06.787696 90901 net.cpp:226] Dropout33 needs backward computation.
I0905 01:39:06.787705 90901 net.cpp:226] Convolution33 needs backward computation.
I0905 01:39:06.787714 90901 net.cpp:226] ReLU32 needs backward computation.
I0905 01:39:06.787722 90901 net.cpp:226] Scale32 needs backward computation.
I0905 01:39:06.787729 90901 net.cpp:226] BatchNorm32 needs backward computation.
I0905 01:39:06.787739 90901 net.cpp:226] Concat29_Concat29_0_split needs backward computation.
I0905 01:39:06.787749 90901 net.cpp:226] Concat29 needs backward computation.
I0905 01:39:06.787758 90901 net.cpp:226] Dropout32 needs backward computation.
I0905 01:39:06.787766 90901 net.cpp:226] Convolution32 needs backward computation.
I0905 01:39:06.787775 90901 net.cpp:226] ReLU31 needs backward computation.
I0905 01:39:06.787782 90901 net.cpp:226] Scale31 needs backward computation.
I0905 01:39:06.787789 90901 net.cpp:226] BatchNorm31 needs backward computation.
I0905 01:39:06.787798 90901 net.cpp:226] Concat28_Concat28_0_split needs backward computation.
I0905 01:39:06.787807 90901 net.cpp:226] Concat28 needs backward computation.
I0905 01:39:06.787816 90901 net.cpp:226] Dropout31 needs backward computation.
I0905 01:39:06.787823 90901 net.cpp:226] Convolution31 needs backward computation.
I0905 01:39:06.787832 90901 net.cpp:226] ReLU30 needs backward computation.
I0905 01:39:06.787839 90901 net.cpp:226] Scale30 needs backward computation.
I0905 01:39:06.787848 90901 net.cpp:226] BatchNorm30 needs backward computation.
I0905 01:39:06.787856 90901 net.cpp:226] Concat27_Concat27_0_split needs backward computation.
I0905 01:39:06.787865 90901 net.cpp:226] Concat27 needs backward computation.
I0905 01:39:06.787873 90901 net.cpp:226] Dropout30 needs backward computation.
I0905 01:39:06.787883 90901 net.cpp:226] Convolution30 needs backward computation.
I0905 01:39:06.787890 90901 net.cpp:226] ReLU29 needs backward computation.
I0905 01:39:06.787899 90901 net.cpp:226] Scale29 needs backward computation.
I0905 01:39:06.787916 90901 net.cpp:226] BatchNorm29 needs backward computation.
I0905 01:39:06.787925 90901 net.cpp:226] Concat26_Concat26_0_split needs backward computation.
I0905 01:39:06.787933 90901 net.cpp:226] Concat26 needs backward computation.
I0905 01:39:06.787942 90901 net.cpp:226] Dropout29 needs backward computation.
I0905 01:39:06.787950 90901 net.cpp:226] Convolution29 needs backward computation.
I0905 01:39:06.787960 90901 net.cpp:226] ReLU28 needs backward computation.
I0905 01:39:06.787968 90901 net.cpp:226] Scale28 needs backward computation.
I0905 01:39:06.787976 90901 net.cpp:226] BatchNorm28 needs backward computation.
I0905 01:39:06.787984 90901 net.cpp:226] Concat25_Concat25_0_split needs backward computation.
I0905 01:39:06.787992 90901 net.cpp:226] Concat25 needs backward computation.
I0905 01:39:06.788002 90901 net.cpp:226] Dropout28 needs backward computation.
I0905 01:39:06.788010 90901 net.cpp:226] Convolution28 needs backward computation.
I0905 01:39:06.788019 90901 net.cpp:226] ReLU27 needs backward computation.
I0905 01:39:06.788028 90901 net.cpp:226] Scale27 needs backward computation.
I0905 01:39:06.788035 90901 net.cpp:226] BatchNorm27 needs backward computation.
I0905 01:39:06.788043 90901 net.cpp:226] Pooling2_Pooling2_0_split needs backward computation.
I0905 01:39:06.788053 90901 net.cpp:226] Pooling2 needs backward computation.
I0905 01:39:06.788060 90901 net.cpp:226] Dropout27 needs backward computation.
I0905 01:39:06.788069 90901 net.cpp:226] Convolution27 needs backward computation.
I0905 01:39:06.788077 90901 net.cpp:226] ReLU26 needs backward computation.
I0905 01:39:06.788085 90901 net.cpp:226] Scale26 needs backward computation.
I0905 01:39:06.788094 90901 net.cpp:226] BatchNorm26 needs backward computation.
I0905 01:39:06.788102 90901 net.cpp:226] Concat24 needs backward computation.
I0905 01:39:06.788110 90901 net.cpp:226] Dropout26 needs backward computation.
I0905 01:39:06.788118 90901 net.cpp:226] Convolution26 needs backward computation.
I0905 01:39:06.788128 90901 net.cpp:226] ReLU25 needs backward computation.
I0905 01:39:06.788136 90901 net.cpp:226] Scale25 needs backward computation.
I0905 01:39:06.788144 90901 net.cpp:226] BatchNorm25 needs backward computation.
I0905 01:39:06.788153 90901 net.cpp:226] Concat23_Concat23_0_split needs backward computation.
I0905 01:39:06.788161 90901 net.cpp:226] Concat23 needs backward computation.
I0905 01:39:06.788170 90901 net.cpp:226] Dropout25 needs backward computation.
I0905 01:39:06.788178 90901 net.cpp:226] Convolution25 needs backward computation.
I0905 01:39:06.788187 90901 net.cpp:226] ReLU24 needs backward computation.
I0905 01:39:06.788195 90901 net.cpp:226] Scale24 needs backward computation.
I0905 01:39:06.788203 90901 net.cpp:226] BatchNorm24 needs backward computation.
I0905 01:39:06.788213 90901 net.cpp:226] Concat22_Concat22_0_split needs backward computation.
I0905 01:39:06.788220 90901 net.cpp:226] Concat22 needs backward computation.
I0905 01:39:06.788229 90901 net.cpp:226] Dropout24 needs backward computation.
I0905 01:39:06.788238 90901 net.cpp:226] Convolution24 needs backward computation.
I0905 01:39:06.788246 90901 net.cpp:226] ReLU23 needs backward computation.
I0905 01:39:06.788254 90901 net.cpp:226] Scale23 needs backward computation.
I0905 01:39:06.788264 90901 net.cpp:226] BatchNorm23 needs backward computation.
I0905 01:39:06.788274 90901 net.cpp:226] Concat21_Concat21_0_split needs backward computation.
I0905 01:39:06.788282 90901 net.cpp:226] Concat21 needs backward computation.
I0905 01:39:06.788290 90901 net.cpp:226] Dropout23 needs backward computation.
I0905 01:39:06.788300 90901 net.cpp:226] Convolution23 needs backward computation.
I0905 01:39:06.788308 90901 net.cpp:226] ReLU22 needs backward computation.
I0905 01:39:06.788317 90901 net.cpp:226] Scale22 needs backward computation.
I0905 01:39:06.788326 90901 net.cpp:226] BatchNorm22 needs backward computation.
I0905 01:39:06.788334 90901 net.cpp:226] Concat20_Concat20_0_split needs backward computation.
I0905 01:39:06.788342 90901 net.cpp:226] Concat20 needs backward computation.
I0905 01:39:06.788360 90901 net.cpp:226] Dropout22 needs backward computation.
I0905 01:39:06.788369 90901 net.cpp:226] Convolution22 needs backward computation.
I0905 01:39:06.788378 90901 net.cpp:226] ReLU21 needs backward computation.
I0905 01:39:06.788389 90901 net.cpp:226] Scale21 needs backward computation.
I0905 01:39:06.788398 90901 net.cpp:226] BatchNorm21 needs backward computation.
I0905 01:39:06.788405 90901 net.cpp:226] Concat19_Concat19_0_split needs backward computation.
I0905 01:39:06.788414 90901 net.cpp:226] Concat19 needs backward computation.
I0905 01:39:06.788424 90901 net.cpp:226] Dropout21 needs backward computation.
I0905 01:39:06.788431 90901 net.cpp:226] Convolution21 needs backward computation.
I0905 01:39:06.788440 90901 net.cpp:226] ReLU20 needs backward computation.
I0905 01:39:06.788451 90901 net.cpp:226] Scale20 needs backward computation.
I0905 01:39:06.788460 90901 net.cpp:226] BatchNorm20 needs backward computation.
I0905 01:39:06.788467 90901 net.cpp:226] Concat18_Concat18_0_split needs backward computation.
I0905 01:39:06.788476 90901 net.cpp:226] Concat18 needs backward computation.
I0905 01:39:06.788486 90901 net.cpp:226] Dropout20 needs backward computation.
I0905 01:39:06.788493 90901 net.cpp:226] Convolution20 needs backward computation.
I0905 01:39:06.788502 90901 net.cpp:226] ReLU19 needs backward computation.
I0905 01:39:06.788511 90901 net.cpp:226] Scale19 needs backward computation.
I0905 01:39:06.788519 90901 net.cpp:226] BatchNorm19 needs backward computation.
I0905 01:39:06.788527 90901 net.cpp:226] Concat17_Concat17_0_split needs backward computation.
I0905 01:39:06.788537 90901 net.cpp:226] Concat17 needs backward computation.
I0905 01:39:06.788545 90901 net.cpp:226] Dropout19 needs backward computation.
I0905 01:39:06.788553 90901 net.cpp:226] Convolution19 needs backward computation.
I0905 01:39:06.788563 90901 net.cpp:226] ReLU18 needs backward computation.
I0905 01:39:06.788573 90901 net.cpp:226] Scale18 needs backward computation.
I0905 01:39:06.788581 90901 net.cpp:226] BatchNorm18 needs backward computation.
I0905 01:39:06.788589 90901 net.cpp:226] Concat16_Concat16_0_split needs backward computation.
I0905 01:39:06.788599 90901 net.cpp:226] Concat16 needs backward computation.
I0905 01:39:06.788607 90901 net.cpp:226] Dropout18 needs backward computation.
I0905 01:39:06.788615 90901 net.cpp:226] Convolution18 needs backward computation.
I0905 01:39:06.788626 90901 net.cpp:226] ReLU17 needs backward computation.
I0905 01:39:06.788635 90901 net.cpp:226] Scale17 needs backward computation.
I0905 01:39:06.788643 90901 net.cpp:226] BatchNorm17 needs backward computation.
I0905 01:39:06.788652 90901 net.cpp:226] Concat15_Concat15_0_split needs backward computation.
I0905 01:39:06.788661 90901 net.cpp:226] Concat15 needs backward computation.
I0905 01:39:06.788669 90901 net.cpp:226] Dropout17 needs backward computation.
I0905 01:39:06.788677 90901 net.cpp:226] Convolution17 needs backward computation.
I0905 01:39:06.788686 90901 net.cpp:226] ReLU16 needs backward computation.
I0905 01:39:06.788694 90901 net.cpp:226] Scale16 needs backward computation.
I0905 01:39:06.788702 90901 net.cpp:226] BatchNorm16 needs backward computation.
I0905 01:39:06.788712 90901 net.cpp:226] Concat14_Concat14_0_split needs backward computation.
I0905 01:39:06.788719 90901 net.cpp:226] Concat14 needs backward computation.
I0905 01:39:06.788728 90901 net.cpp:226] Dropout16 needs backward computation.
I0905 01:39:06.788738 90901 net.cpp:226] Convolution16 needs backward computation.
I0905 01:39:06.788745 90901 net.cpp:226] ReLU15 needs backward computation.
I0905 01:39:06.788753 90901 net.cpp:226] Scale15 needs backward computation.
I0905 01:39:06.788761 90901 net.cpp:226] BatchNorm15 needs backward computation.
I0905 01:39:06.788770 90901 net.cpp:226] Concat13_Concat13_0_split needs backward computation.
I0905 01:39:06.788779 90901 net.cpp:226] Concat13 needs backward computation.
I0905 01:39:06.788789 90901 net.cpp:226] Dropout15 needs backward computation.
I0905 01:39:06.788803 90901 net.cpp:226] Convolution15 needs backward computation.
I0905 01:39:06.788812 90901 net.cpp:226] ReLU14 needs backward computation.
I0905 01:39:06.788820 90901 net.cpp:226] Scale14 needs backward computation.
I0905 01:39:06.788828 90901 net.cpp:226] BatchNorm14 needs backward computation.
I0905 01:39:06.788838 90901 net.cpp:226] Pooling1_Pooling1_0_split needs backward computation.
I0905 01:39:06.788846 90901 net.cpp:226] Pooling1 needs backward computation.
I0905 01:39:06.788856 90901 net.cpp:226] Dropout14 needs backward computation.
I0905 01:39:06.788863 90901 net.cpp:226] Convolution14 needs backward computation.
I0905 01:39:06.788872 90901 net.cpp:226] ReLU13 needs backward computation.
I0905 01:39:06.788880 90901 net.cpp:226] Scale13 needs backward computation.
I0905 01:39:06.788888 90901 net.cpp:226] BatchNorm13 needs backward computation.
I0905 01:39:06.788897 90901 net.cpp:226] Concat12 needs backward computation.
I0905 01:39:06.788907 90901 net.cpp:226] Dropout13 needs backward computation.
I0905 01:39:06.788914 90901 net.cpp:226] Convolution13 needs backward computation.
I0905 01:39:06.788923 90901 net.cpp:226] ReLU12 needs backward computation.
I0905 01:39:06.788931 90901 net.cpp:226] Scale12 needs backward computation.
I0905 01:39:06.788939 90901 net.cpp:226] BatchNorm12 needs backward computation.
I0905 01:39:06.788949 90901 net.cpp:226] Concat11_Concat11_0_split needs backward computation.
I0905 01:39:06.788956 90901 net.cpp:226] Concat11 needs backward computation.
I0905 01:39:06.788965 90901 net.cpp:226] Dropout12 needs backward computation.
I0905 01:39:06.788975 90901 net.cpp:226] Convolution12 needs backward computation.
I0905 01:39:06.788982 90901 net.cpp:226] ReLU11 needs backward computation.
I0905 01:39:06.788991 90901 net.cpp:226] Scale11 needs backward computation.
I0905 01:39:06.789000 90901 net.cpp:226] BatchNorm11 needs backward computation.
I0905 01:39:06.789007 90901 net.cpp:226] Concat10_Concat10_0_split needs backward computation.
I0905 01:39:06.789016 90901 net.cpp:226] Concat10 needs backward computation.
I0905 01:39:06.789026 90901 net.cpp:226] Dropout11 needs backward computation.
I0905 01:39:06.789034 90901 net.cpp:226] Convolution11 needs backward computation.
I0905 01:39:06.789042 90901 net.cpp:226] ReLU10 needs backward computation.
I0905 01:39:06.789052 90901 net.cpp:226] Scale10 needs backward computation.
I0905 01:39:06.789059 90901 net.cpp:226] BatchNorm10 needs backward computation.
I0905 01:39:06.789067 90901 net.cpp:226] Concat9_Concat9_0_split needs backward computation.
I0905 01:39:06.789077 90901 net.cpp:226] Concat9 needs backward computation.
I0905 01:39:06.789085 90901 net.cpp:226] Dropout10 needs backward computation.
I0905 01:39:06.789094 90901 net.cpp:226] Convolution10 needs backward computation.
I0905 01:39:06.789103 90901 net.cpp:226] ReLU9 needs backward computation.
I0905 01:39:06.789113 90901 net.cpp:226] Scale9 needs backward computation.
I0905 01:39:06.789120 90901 net.cpp:226] BatchNorm9 needs backward computation.
I0905 01:39:06.789129 90901 net.cpp:226] Concat8_Concat8_0_split needs backward computation.
I0905 01:39:06.789139 90901 net.cpp:226] Concat8 needs backward computation.
I0905 01:39:06.789149 90901 net.cpp:226] Dropout9 needs backward computation.
I0905 01:39:06.789157 90901 net.cpp:226] Convolution9 needs backward computation.
I0905 01:39:06.789170 90901 net.cpp:226] ReLU8 needs backward computation.
I0905 01:39:06.789178 90901 net.cpp:226] Scale8 needs backward computation.
I0905 01:39:06.789186 90901 net.cpp:226] BatchNorm8 needs backward computation.
I0905 01:39:06.789196 90901 net.cpp:226] Concat7_Concat7_0_split needs backward computation.
I0905 01:39:06.789203 90901 net.cpp:226] Concat7 needs backward computation.
I0905 01:39:06.789213 90901 net.cpp:226] Dropout8 needs backward computation.
I0905 01:39:06.789222 90901 net.cpp:226] Convolution8 needs backward computation.
I0905 01:39:06.789230 90901 net.cpp:226] ReLU7 needs backward computation.
I0905 01:39:06.789242 90901 net.cpp:226] Scale7 needs backward computation.
I0905 01:39:06.789255 90901 net.cpp:226] BatchNorm7 needs backward computation.
I0905 01:39:06.789265 90901 net.cpp:226] Concat6_Concat6_0_split needs backward computation.
I0905 01:39:06.789273 90901 net.cpp:226] Concat6 needs backward computation.
I0905 01:39:06.789283 90901 net.cpp:226] Dropout7 needs backward computation.
I0905 01:39:06.789291 90901 net.cpp:226] Convolution7 needs backward computation.
I0905 01:39:06.789299 90901 net.cpp:226] ReLU6 needs backward computation.
I0905 01:39:06.789311 90901 net.cpp:226] Scale6 needs backward computation.
I0905 01:39:06.789319 90901 net.cpp:226] BatchNorm6 needs backward computation.
I0905 01:39:06.789329 90901 net.cpp:226] Concat5_Concat5_0_split needs backward computation.
I0905 01:39:06.789336 90901 net.cpp:226] Concat5 needs backward computation.
I0905 01:39:06.789345 90901 net.cpp:226] Dropout6 needs backward computation.
I0905 01:39:06.789355 90901 net.cpp:226] Convolution6 needs backward computation.
I0905 01:39:06.789363 90901 net.cpp:226] ReLU5 needs backward computation.
I0905 01:39:06.789372 90901 net.cpp:226] Scale5 needs backward computation.
I0905 01:39:06.789381 90901 net.cpp:226] BatchNorm5 needs backward computation.
I0905 01:39:06.789389 90901 net.cpp:226] Concat4_Concat4_0_split needs backward computation.
I0905 01:39:06.789397 90901 net.cpp:226] Concat4 needs backward computation.
I0905 01:39:06.789407 90901 net.cpp:226] Dropout5 needs backward computation.
I0905 01:39:06.789415 90901 net.cpp:226] Convolution5 needs backward computation.
I0905 01:39:06.789423 90901 net.cpp:226] ReLU4 needs backward computation.
I0905 01:39:06.789435 90901 net.cpp:226] Scale4 needs backward computation.
I0905 01:39:06.789443 90901 net.cpp:226] BatchNorm4 needs backward computation.
I0905 01:39:06.789453 90901 net.cpp:226] Concat3_Concat3_0_split needs backward computation.
I0905 01:39:06.789460 90901 net.cpp:226] Concat3 needs backward computation.
I0905 01:39:06.789469 90901 net.cpp:226] Dropout4 needs backward computation.
I0905 01:39:06.789479 90901 net.cpp:226] Convolution4 needs backward computation.
I0905 01:39:06.789487 90901 net.cpp:226] ReLU3 needs backward computation.
I0905 01:39:06.789496 90901 net.cpp:226] Scale3 needs backward computation.
I0905 01:39:06.789505 90901 net.cpp:226] BatchNorm3 needs backward computation.
I0905 01:39:06.789512 90901 net.cpp:226] Concat2_Concat2_0_split needs backward computation.
I0905 01:39:06.789521 90901 net.cpp:226] Concat2 needs backward computation.
I0905 01:39:06.789532 90901 net.cpp:226] Dropout3 needs backward computation.
I0905 01:39:06.789541 90901 net.cpp:226] Convolution3 needs backward computation.
I0905 01:39:06.789549 90901 net.cpp:226] ReLU2 needs backward computation.
I0905 01:39:06.789558 90901 net.cpp:226] Scale2 needs backward computation.
I0905 01:39:06.789566 90901 net.cpp:226] BatchNorm2 needs backward computation.
I0905 01:39:06.789574 90901 net.cpp:226] Concat1_Concat1_0_split needs backward computation.
I0905 01:39:06.789583 90901 net.cpp:226] Concat1 needs backward computation.
I0905 01:39:06.789592 90901 net.cpp:226] Dropout2 needs backward computation.
I0905 01:39:06.789602 90901 net.cpp:226] Convolution2 needs backward computation.
I0905 01:39:06.789609 90901 net.cpp:226] ReLU1 needs backward computation.
I0905 01:39:06.789619 90901 net.cpp:226] Scale1 needs backward computation.
I0905 01:39:06.789626 90901 net.cpp:226] BatchNorm1 needs backward computation.
I0905 01:39:06.789635 90901 net.cpp:226] Dropout1_Dropout1_0_split needs backward computation.
I0905 01:39:06.789644 90901 net.cpp:226] Dropout1 needs backward computation.
I0905 01:39:06.789652 90901 net.cpp:226] Convolution1 needs backward computation.
I0905 01:39:06.789662 90901 net.cpp:228] Data2_Data1_1_split does not need backward computation.
I0905 01:39:06.789675 90901 net.cpp:228] Data1 does not need backward computation.
I0905 01:39:06.789683 90901 net.cpp:270] This network produces output Accuracy1
I0905 01:39:06.789692 90901 net.cpp:270] This network produces output SoftmaxWithLoss1
I0905 01:39:06.789842 90901 net.cpp:283] Network initialization done.
I0905 01:39:06.790818 90901 solver.cpp:60] Solver scaffolding done.
I0905 01:39:06.799275 90901 caffe.cpp:251] Starting Optimization
I0905 01:39:06.799293 90901 solver.cpp:279] Solving DenseNN
I0905 01:39:06.799306 90901 solver.cpp:280] Learning Rate Policy: multistep
I0905 01:39:06.806432 90901 solver.cpp:337] Iteration 0, Testing net (#0)
I0905 01:39:49.129768 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.496875
I0905 01:39:49.130039 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 87.3366 (* 1 = 87.3366 loss)
I0905 01:39:49.874310 90901 solver.cpp:228] Iteration 0, loss = 0.655748
I0905 01:39:49.874368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.655748 (* 1 = 0.655748 loss)
I0905 01:39:49.874406 90901 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0905 01:39:55.498955 90901 solver.cpp:228] Iteration 10, loss = 2.15917
I0905 01:39:55.499018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 2.15917 (* 1 = 2.15917 loss)
I0905 01:39:55.499034 90901 sgd_solver.cpp:106] Iteration 10, lr = 0.1
I0905 01:40:01.905280 90901 solver.cpp:228] Iteration 20, loss = 1.17734
I0905 01:40:01.905375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.17734 (* 1 = 1.17734 loss)
I0905 01:40:01.905391 90901 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0905 01:40:08.017868 90901 solver.cpp:228] Iteration 30, loss = 0.826756
I0905 01:40:08.017927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.826756 (* 1 = 0.826756 loss)
I0905 01:40:08.017942 90901 sgd_solver.cpp:106] Iteration 30, lr = 0.1
I0905 01:40:14.132181 90901 solver.cpp:228] Iteration 40, loss = 0.474478
I0905 01:40:14.132247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.474478 (* 1 = 0.474478 loss)
I0905 01:40:14.132262 90901 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0905 01:40:19.524544 90901 solver.cpp:228] Iteration 50, loss = 0.555356
I0905 01:40:19.524683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555356 (* 1 = 0.555356 loss)
I0905 01:40:19.524710 90901 sgd_solver.cpp:106] Iteration 50, lr = 0.1
I0905 01:40:25.096740 90901 solver.cpp:228] Iteration 60, loss = 1.00874
I0905 01:40:25.096809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.00874 (* 1 = 1.00874 loss)
I0905 01:40:25.096827 90901 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0905 01:40:30.840667 90901 solver.cpp:228] Iteration 70, loss = 0.475236
I0905 01:40:30.840721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475236 (* 1 = 0.475236 loss)
I0905 01:40:30.840735 90901 sgd_solver.cpp:106] Iteration 70, lr = 0.1
I0905 01:40:37.114743 90901 solver.cpp:228] Iteration 80, loss = 0.675258
I0905 01:40:37.114801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.675258 (* 1 = 0.675258 loss)
I0905 01:40:37.114815 90901 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0905 01:40:43.005728 90901 solver.cpp:228] Iteration 90, loss = 0.295794
I0905 01:40:43.005821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295794 (* 1 = 0.295794 loss)
I0905 01:40:43.005841 90901 sgd_solver.cpp:106] Iteration 90, lr = 0.1
I0905 01:40:49.421044 90901 solver.cpp:228] Iteration 100, loss = 0.76314
I0905 01:40:49.421095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.76314 (* 1 = 0.76314 loss)
I0905 01:40:49.421109 90901 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0905 01:40:55.554330 90901 solver.cpp:228] Iteration 110, loss = 0.68897
I0905 01:40:55.556545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.688969 (* 1 = 0.688969 loss)
I0905 01:40:55.556565 90901 sgd_solver.cpp:106] Iteration 110, lr = 0.1
I0905 01:41:01.661814 90901 solver.cpp:228] Iteration 120, loss = 0.4949
I0905 01:41:01.661862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.494899 (* 1 = 0.494899 loss)
I0905 01:41:01.661876 90901 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0905 01:41:07.730413 90901 solver.cpp:228] Iteration 130, loss = 0.557903
I0905 01:41:07.730458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.557903 (* 1 = 0.557903 loss)
I0905 01:41:07.730471 90901 sgd_solver.cpp:106] Iteration 130, lr = 0.1
I0905 01:41:13.843905 90901 solver.cpp:228] Iteration 140, loss = 0.513311
I0905 01:41:13.844027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513311 (* 1 = 0.513311 loss)
I0905 01:41:13.844048 90901 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0905 01:41:20.262903 90901 solver.cpp:228] Iteration 150, loss = 0.549727
I0905 01:41:20.262979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.549727 (* 1 = 0.549727 loss)
I0905 01:41:20.262998 90901 sgd_solver.cpp:106] Iteration 150, lr = 0.1
I0905 01:41:26.356398 90901 solver.cpp:228] Iteration 160, loss = 0.236934
I0905 01:41:26.356590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236934 (* 1 = 0.236934 loss)
I0905 01:41:26.356631 90901 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0905 01:41:32.510385 90901 solver.cpp:228] Iteration 170, loss = 0.567833
I0905 01:41:32.510453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.567833 (* 1 = 0.567833 loss)
I0905 01:41:32.510467 90901 sgd_solver.cpp:106] Iteration 170, lr = 0.1
I0905 01:41:38.639202 90901 solver.cpp:228] Iteration 180, loss = 0.578795
I0905 01:41:38.639258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578794 (* 1 = 0.578794 loss)
I0905 01:41:38.639271 90901 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0905 01:41:44.811910 90901 solver.cpp:228] Iteration 190, loss = 0.578094
I0905 01:41:44.811960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578094 (* 1 = 0.578094 loss)
I0905 01:41:44.811975 90901 sgd_solver.cpp:106] Iteration 190, lr = 0.1
I0905 01:41:50.750191 90901 solver.cpp:228] Iteration 200, loss = 0.700327
I0905 01:41:50.750263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.700327 (* 1 = 0.700327 loss)
I0905 01:41:50.750283 90901 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0905 01:41:56.722620 90901 solver.cpp:228] Iteration 210, loss = 0.736725
I0905 01:41:56.722903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.736725 (* 1 = 0.736725 loss)
I0905 01:41:56.722925 90901 sgd_solver.cpp:106] Iteration 210, lr = 0.1
I0905 01:42:03.006955 90901 solver.cpp:228] Iteration 220, loss = 0.440002
I0905 01:42:03.007035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440001 (* 1 = 0.440001 loss)
I0905 01:42:03.007051 90901 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0905 01:42:08.288305 90901 solver.cpp:228] Iteration 230, loss = 0.461024
I0905 01:42:08.288354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461024 (* 1 = 0.461024 loss)
I0905 01:42:08.288367 90901 sgd_solver.cpp:106] Iteration 230, lr = 0.1
I0905 01:42:13.978142 90901 solver.cpp:228] Iteration 240, loss = 0.557452
I0905 01:42:13.978204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.557452 (* 1 = 0.557452 loss)
I0905 01:42:13.978219 90901 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0905 01:42:20.132630 90901 solver.cpp:228] Iteration 250, loss = 0.457466
I0905 01:42:20.132691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457466 (* 1 = 0.457466 loss)
I0905 01:42:20.132704 90901 sgd_solver.cpp:106] Iteration 250, lr = 0.1
I0905 01:42:26.422875 90901 solver.cpp:228] Iteration 260, loss = 0.366181
I0905 01:42:26.422950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366181 (* 1 = 0.366181 loss)
I0905 01:42:26.422973 90901 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0905 01:42:32.684592 90901 solver.cpp:228] Iteration 270, loss = 0.742041
I0905 01:42:32.684749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.742041 (* 1 = 0.742041 loss)
I0905 01:42:32.684765 90901 sgd_solver.cpp:106] Iteration 270, lr = 0.1
I0905 01:42:38.776424 90901 solver.cpp:228] Iteration 280, loss = 0.468436
I0905 01:42:38.776476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468436 (* 1 = 0.468436 loss)
I0905 01:42:38.776492 90901 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0905 01:42:44.974809 90901 solver.cpp:228] Iteration 290, loss = 0.767948
I0905 01:42:44.974865 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.767948 (* 1 = 0.767948 loss)
I0905 01:42:44.974879 90901 sgd_solver.cpp:106] Iteration 290, lr = 0.1
I0905 01:42:51.111397 90901 solver.cpp:228] Iteration 300, loss = 0.586684
I0905 01:42:51.111515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.586684 (* 1 = 0.586684 loss)
I0905 01:42:51.111538 90901 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0905 01:42:57.252125 90901 solver.cpp:228] Iteration 310, loss = 0.438225
I0905 01:42:57.252207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438225 (* 1 = 0.438225 loss)
I0905 01:42:57.252226 90901 sgd_solver.cpp:106] Iteration 310, lr = 0.1
I0905 01:43:03.053000 90901 solver.cpp:228] Iteration 320, loss = 0.63994
I0905 01:43:03.053298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.63994 (* 1 = 0.63994 loss)
I0905 01:43:03.053320 90901 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0905 01:43:09.358223 90901 solver.cpp:228] Iteration 330, loss = 0.709479
I0905 01:43:09.358273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.709479 (* 1 = 0.709479 loss)
I0905 01:43:09.358288 90901 sgd_solver.cpp:106] Iteration 330, lr = 0.1
I0905 01:43:15.296862 90901 solver.cpp:228] Iteration 340, loss = 0.715965
I0905 01:43:15.296946 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.715964 (* 1 = 0.715964 loss)
I0905 01:43:15.296962 90901 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0905 01:43:21.743118 90901 solver.cpp:228] Iteration 350, loss = 0.715773
I0905 01:43:21.743216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.715773 (* 1 = 0.715773 loss)
I0905 01:43:21.743232 90901 sgd_solver.cpp:106] Iteration 350, lr = 0.1
I0905 01:43:27.873538 90901 solver.cpp:228] Iteration 360, loss = 0.389237
I0905 01:43:27.873612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389237 (* 1 = 0.389237 loss)
I0905 01:43:27.873630 90901 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0905 01:43:33.945384 90901 solver.cpp:228] Iteration 370, loss = 0.827228
I0905 01:43:33.945574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.827228 (* 1 = 0.827228 loss)
I0905 01:43:33.945605 90901 sgd_solver.cpp:106] Iteration 370, lr = 0.1
I0905 01:43:40.034215 90901 solver.cpp:228] Iteration 380, loss = 0.379867
I0905 01:43:40.034273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379867 (* 1 = 0.379867 loss)
I0905 01:43:40.034286 90901 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0905 01:43:46.169999 90901 solver.cpp:228] Iteration 390, loss = 0.36253
I0905 01:43:46.170073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36253 (* 1 = 0.36253 loss)
I0905 01:43:46.170089 90901 sgd_solver.cpp:106] Iteration 390, lr = 0.1
I0905 01:43:51.879207 90901 solver.cpp:228] Iteration 400, loss = 0.662976
I0905 01:43:51.879257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.662976 (* 1 = 0.662976 loss)
I0905 01:43:51.879271 90901 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0905 01:43:57.461794 90901 solver.cpp:228] Iteration 410, loss = 0.434003
I0905 01:43:57.461865 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434003 (* 1 = 0.434003 loss)
I0905 01:43:57.461879 90901 sgd_solver.cpp:106] Iteration 410, lr = 0.1
I0905 01:44:03.170096 90901 solver.cpp:228] Iteration 420, loss = 0.505346
I0905 01:44:03.170153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505346 (* 1 = 0.505346 loss)
I0905 01:44:03.170168 90901 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0905 01:44:09.613759 90901 solver.cpp:228] Iteration 430, loss = 0.666469
I0905 01:44:09.613976 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.666469 (* 1 = 0.666469 loss)
I0905 01:44:09.614008 90901 sgd_solver.cpp:106] Iteration 430, lr = 0.1
I0905 01:44:15.736490 90901 solver.cpp:228] Iteration 440, loss = 0.611082
I0905 01:44:15.736542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.611081 (* 1 = 0.611081 loss)
I0905 01:44:15.736557 90901 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0905 01:44:22.213441 90901 solver.cpp:228] Iteration 450, loss = 0.439912
I0905 01:44:22.213500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439912 (* 1 = 0.439912 loss)
I0905 01:44:22.213513 90901 sgd_solver.cpp:106] Iteration 450, lr = 0.1
I0905 01:44:28.243168 90901 solver.cpp:228] Iteration 460, loss = 0.385301
I0905 01:44:28.243224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385301 (* 1 = 0.385301 loss)
I0905 01:44:28.243239 90901 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0905 01:44:34.324023 90901 solver.cpp:228] Iteration 470, loss = 0.731876
I0905 01:44:34.324070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.731876 (* 1 = 0.731876 loss)
I0905 01:44:34.324084 90901 sgd_solver.cpp:106] Iteration 470, lr = 0.1
I0905 01:44:40.491891 90901 solver.cpp:228] Iteration 480, loss = 0.362314
I0905 01:44:40.492174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362313 (* 1 = 0.362313 loss)
I0905 01:44:40.492193 90901 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0905 01:44:46.616853 90901 solver.cpp:228] Iteration 490, loss = 0.464133
I0905 01:44:46.616899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464133 (* 1 = 0.464133 loss)
I0905 01:44:46.616914 90901 sgd_solver.cpp:106] Iteration 490, lr = 0.1
I0905 01:44:52.384593 90901 solver.cpp:228] Iteration 500, loss = 0.529585
I0905 01:44:52.384651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529585 (* 1 = 0.529585 loss)
I0905 01:44:52.384666 90901 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0905 01:44:58.845433 90901 solver.cpp:228] Iteration 510, loss = 0.652524
I0905 01:44:58.845497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.652523 (* 1 = 0.652523 loss)
I0905 01:44:58.845513 90901 sgd_solver.cpp:106] Iteration 510, lr = 0.1
I0905 01:45:04.936401 90901 solver.cpp:228] Iteration 520, loss = 0.628294
I0905 01:45:04.936460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.628294 (* 1 = 0.628294 loss)
I0905 01:45:04.936475 90901 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0905 01:45:10.821365 90901 solver.cpp:228] Iteration 530, loss = 0.521645
I0905 01:45:10.821676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.521644 (* 1 = 0.521644 loss)
I0905 01:45:10.821691 90901 sgd_solver.cpp:106] Iteration 530, lr = 0.1
I0905 01:45:17.191176 90901 solver.cpp:228] Iteration 540, loss = 0.634398
I0905 01:45:17.191249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.634398 (* 1 = 0.634398 loss)
I0905 01:45:17.191265 90901 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0905 01:45:23.609118 90901 solver.cpp:228] Iteration 550, loss = 1.66939
I0905 01:45:23.609185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.66939 (* 1 = 1.66939 loss)
I0905 01:45:23.609201 90901 sgd_solver.cpp:106] Iteration 550, lr = 0.1
I0905 01:45:29.419881 90901 solver.cpp:228] Iteration 560, loss = 0.457259
I0905 01:45:29.419940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457259 (* 1 = 0.457259 loss)
I0905 01:45:29.419956 90901 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0905 01:45:35.463151 90901 solver.cpp:228] Iteration 570, loss = 0.468857
I0905 01:45:35.463213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468857 (* 1 = 0.468857 loss)
I0905 01:45:35.463228 90901 sgd_solver.cpp:106] Iteration 570, lr = 0.1
I0905 01:45:40.748790 90901 solver.cpp:228] Iteration 580, loss = 0.598614
I0905 01:45:40.748850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.598614 (* 1 = 0.598614 loss)
I0905 01:45:40.748867 90901 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0905 01:45:46.486574 90901 solver.cpp:228] Iteration 590, loss = 0.492292
I0905 01:45:46.486824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492292 (* 1 = 0.492292 loss)
I0905 01:45:46.486860 90901 sgd_solver.cpp:106] Iteration 590, lr = 0.1
I0905 01:45:52.926677 90901 solver.cpp:228] Iteration 600, loss = 0.605019
I0905 01:45:52.926743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.605018 (* 1 = 0.605018 loss)
I0905 01:45:52.926759 90901 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0905 01:45:59.034368 90901 solver.cpp:228] Iteration 610, loss = 0.459675
I0905 01:45:59.034422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459675 (* 1 = 0.459675 loss)
I0905 01:45:59.034436 90901 sgd_solver.cpp:106] Iteration 610, lr = 0.1
I0905 01:46:05.145064 90901 solver.cpp:228] Iteration 620, loss = 0.96563
I0905 01:46:05.145120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.96563 (* 1 = 0.96563 loss)
I0905 01:46:05.145134 90901 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0905 01:46:10.993849 90901 solver.cpp:228] Iteration 630, loss = 0.438362
I0905 01:46:10.993901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438362 (* 1 = 0.438362 loss)
I0905 01:46:10.993914 90901 sgd_solver.cpp:106] Iteration 630, lr = 0.1
I0905 01:46:17.084126 90901 solver.cpp:228] Iteration 640, loss = 0.457176
I0905 01:46:17.084300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457176 (* 1 = 0.457176 loss)
I0905 01:46:17.084319 90901 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0905 01:46:23.189393 90901 solver.cpp:228] Iteration 650, loss = 0.606382
I0905 01:46:23.189436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.606382 (* 1 = 0.606382 loss)
I0905 01:46:23.189451 90901 sgd_solver.cpp:106] Iteration 650, lr = 0.1
I0905 01:46:29.302608 90901 solver.cpp:228] Iteration 660, loss = 0.572787
I0905 01:46:29.302678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572787 (* 1 = 0.572787 loss)
I0905 01:46:29.302695 90901 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0905 01:46:35.346830 90901 solver.cpp:228] Iteration 670, loss = 0.385849
I0905 01:46:35.346887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385849 (* 1 = 0.385849 loss)
I0905 01:46:35.346904 90901 sgd_solver.cpp:106] Iteration 670, lr = 0.1
I0905 01:46:41.441664 90901 solver.cpp:228] Iteration 680, loss = 0.633196
I0905 01:46:41.441722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633196 (* 1 = 0.633196 loss)
I0905 01:46:41.441736 90901 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0905 01:46:47.572130 90901 solver.cpp:228] Iteration 690, loss = 0.696775
I0905 01:46:47.572284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696775 (* 1 = 0.696775 loss)
I0905 01:46:47.572335 90901 sgd_solver.cpp:106] Iteration 690, lr = 0.1
I0905 01:46:54.010622 90901 solver.cpp:228] Iteration 700, loss = 0.535943
I0905 01:46:54.010692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535942 (* 1 = 0.535942 loss)
I0905 01:46:54.010707 90901 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0905 01:47:00.114409 90901 solver.cpp:228] Iteration 710, loss = 0.636919
I0905 01:47:00.114471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.636919 (* 1 = 0.636919 loss)
I0905 01:47:00.114486 90901 sgd_solver.cpp:106] Iteration 710, lr = 0.1
I0905 01:47:06.208904 90901 solver.cpp:228] Iteration 720, loss = 0.706536
I0905 01:47:06.208961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.706535 (* 1 = 0.706535 loss)
I0905 01:47:06.208977 90901 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0905 01:47:12.360666 90901 solver.cpp:228] Iteration 730, loss = 0.706572
I0905 01:47:12.360726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.706572 (* 1 = 0.706572 loss)
I0905 01:47:12.360743 90901 sgd_solver.cpp:106] Iteration 730, lr = 0.1
I0905 01:47:18.379596 90901 solver.cpp:228] Iteration 740, loss = 0.631572
I0905 01:47:18.379775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.631572 (* 1 = 0.631572 loss)
I0905 01:47:18.379793 90901 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0905 01:47:24.257668 90901 solver.cpp:228] Iteration 750, loss = 0.641443
I0905 01:47:24.257722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.641443 (* 1 = 0.641443 loss)
I0905 01:47:24.257737 90901 sgd_solver.cpp:106] Iteration 750, lr = 0.1
I0905 01:47:29.716514 90901 solver.cpp:228] Iteration 760, loss = 0.546497
I0905 01:47:29.716578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546497 (* 1 = 0.546497 loss)
I0905 01:47:29.716593 90901 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0905 01:47:35.397846 90901 solver.cpp:228] Iteration 770, loss = 0.429958
I0905 01:47:35.397897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429958 (* 1 = 0.429958 loss)
I0905 01:47:35.397912 90901 sgd_solver.cpp:106] Iteration 770, lr = 0.1
I0905 01:47:41.458906 90901 solver.cpp:228] Iteration 780, loss = 0.500349
I0905 01:47:41.458953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.500349 (* 1 = 0.500349 loss)
I0905 01:47:41.458968 90901 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0905 01:47:47.570762 90901 solver.cpp:228] Iteration 790, loss = 1.14766
I0905 01:47:47.570804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.14766 (* 1 = 1.14766 loss)
I0905 01:47:47.570817 90901 sgd_solver.cpp:106] Iteration 790, lr = 0.1
I0905 01:47:53.444506 90901 solver.cpp:337] Iteration 800, Testing net (#0)
I0905 01:48:36.149170 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.64375
I0905 01:48:36.149322 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.618243 (* 1 = 0.618243 loss)
I0905 01:48:36.366189 90901 solver.cpp:228] Iteration 800, loss = 0.437128
I0905 01:48:36.366219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437128 (* 1 = 0.437128 loss)
I0905 01:48:36.366236 90901 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0905 01:48:42.736135 90901 solver.cpp:228] Iteration 810, loss = 0.795213
I0905 01:48:42.736202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.795213 (* 1 = 0.795213 loss)
I0905 01:48:42.736217 90901 sgd_solver.cpp:106] Iteration 810, lr = 0.1
I0905 01:48:48.623543 90901 solver.cpp:228] Iteration 820, loss = 0.542457
I0905 01:48:48.623601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.542457 (* 1 = 0.542457 loss)
I0905 01:48:48.623617 90901 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0905 01:48:54.733182 90901 solver.cpp:228] Iteration 830, loss = 0.586044
I0905 01:48:54.733227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.586044 (* 1 = 0.586044 loss)
I0905 01:48:54.733240 90901 sgd_solver.cpp:106] Iteration 830, lr = 0.1
I0905 01:49:00.881785 90901 solver.cpp:228] Iteration 840, loss = 0.355179
I0905 01:49:00.881829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355179 (* 1 = 0.355179 loss)
I0905 01:49:00.881841 90901 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0905 01:49:06.977677 90901 solver.cpp:228] Iteration 850, loss = 0.349018
I0905 01:49:06.977844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349017 (* 1 = 0.349017 loss)
I0905 01:49:06.977875 90901 sgd_solver.cpp:106] Iteration 850, lr = 0.1
I0905 01:49:12.777753 90901 solver.cpp:228] Iteration 860, loss = 0.638526
I0905 01:49:12.777804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.638526 (* 1 = 0.638526 loss)
I0905 01:49:12.777820 90901 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0905 01:49:18.222805 90901 solver.cpp:228] Iteration 870, loss = 0.80727
I0905 01:49:18.222862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.80727 (* 1 = 0.80727 loss)
I0905 01:49:18.222877 90901 sgd_solver.cpp:106] Iteration 870, lr = 0.1
I0905 01:49:24.271312 90901 solver.cpp:228] Iteration 880, loss = 0.966184
I0905 01:49:24.271380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.966184 (* 1 = 0.966184 loss)
I0905 01:49:24.271397 90901 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0905 01:49:30.350942 90901 solver.cpp:228] Iteration 890, loss = 0.759777
I0905 01:49:30.351003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.759777 (* 1 = 0.759777 loss)
I0905 01:49:30.351018 90901 sgd_solver.cpp:106] Iteration 890, lr = 0.1
I0905 01:49:36.470713 90901 solver.cpp:228] Iteration 900, loss = 0.585902
I0905 01:49:36.470782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.585902 (* 1 = 0.585902 loss)
I0905 01:49:36.470795 90901 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0905 01:49:42.600293 90901 solver.cpp:228] Iteration 910, loss = 0.419784
I0905 01:49:42.600510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419784 (* 1 = 0.419784 loss)
I0905 01:49:42.600538 90901 sgd_solver.cpp:106] Iteration 910, lr = 0.1
I0905 01:49:48.727156 90901 solver.cpp:228] Iteration 920, loss = 0.506041
I0905 01:49:48.727200 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.506041 (* 1 = 0.506041 loss)
I0905 01:49:48.727215 90901 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0905 01:49:54.828003 90901 solver.cpp:228] Iteration 930, loss = 0.334007
I0905 01:49:54.828048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334007 (* 1 = 0.334007 loss)
I0905 01:49:54.828063 90901 sgd_solver.cpp:106] Iteration 930, lr = 0.1
I0905 01:50:01.084585 90901 solver.cpp:228] Iteration 940, loss = 0.455982
I0905 01:50:01.084626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455982 (* 1 = 0.455982 loss)
I0905 01:50:01.084638 90901 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0905 01:50:07.326313 90901 solver.cpp:228] Iteration 950, loss = 0.708182
I0905 01:50:07.326356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.708181 (* 1 = 0.708181 loss)
I0905 01:50:07.326370 90901 sgd_solver.cpp:106] Iteration 950, lr = 0.1
I0905 01:50:13.420610 90901 solver.cpp:228] Iteration 960, loss = 0.635795
I0905 01:50:13.420810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.635794 (* 1 = 0.635794 loss)
I0905 01:50:13.420827 90901 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0905 01:50:19.497468 90901 solver.cpp:228] Iteration 970, loss = 0.508299
I0905 01:50:19.497522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.508299 (* 1 = 0.508299 loss)
I0905 01:50:19.497537 90901 sgd_solver.cpp:106] Iteration 970, lr = 0.1
I0905 01:50:25.945971 90901 solver.cpp:228] Iteration 980, loss = 0.914782
I0905 01:50:25.946025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.914782 (* 1 = 0.914782 loss)
I0905 01:50:25.946039 90901 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0905 01:50:32.048537 90901 solver.cpp:228] Iteration 990, loss = 1.20889
I0905 01:50:32.048584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.20889 (* 1 = 1.20889 loss)
I0905 01:50:32.048598 90901 sgd_solver.cpp:106] Iteration 990, lr = 0.1
I0905 01:50:38.346246 90901 solver.cpp:228] Iteration 1000, loss = 0.732879
I0905 01:50:38.346328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.732879 (* 1 = 0.732879 loss)
I0905 01:50:38.346354 90901 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0905 01:50:44.566828 90901 solver.cpp:228] Iteration 1010, loss = 0.435272
I0905 01:50:44.567049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435272 (* 1 = 0.435272 loss)
I0905 01:50:44.567065 90901 sgd_solver.cpp:106] Iteration 1010, lr = 0.1
I0905 01:50:50.681479 90901 solver.cpp:228] Iteration 1020, loss = 0.595899
I0905 01:50:50.681524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.595899 (* 1 = 0.595899 loss)
I0905 01:50:50.681538 90901 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0905 01:50:56.767623 90901 solver.cpp:228] Iteration 1030, loss = 0.771977
I0905 01:50:56.767668 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.771976 (* 1 = 0.771976 loss)
I0905 01:50:56.767683 90901 sgd_solver.cpp:106] Iteration 1030, lr = 0.1
I0905 01:51:02.044109 90901 solver.cpp:228] Iteration 1040, loss = 0.576715
I0905 01:51:02.044155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.576715 (* 1 = 0.576715 loss)
I0905 01:51:02.044170 90901 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0905 01:51:07.378365 90901 solver.cpp:228] Iteration 1050, loss = 0.495675
I0905 01:51:07.378424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.495674 (* 1 = 0.495674 loss)
I0905 01:51:07.378438 90901 sgd_solver.cpp:106] Iteration 1050, lr = 0.1
I0905 01:51:13.760215 90901 solver.cpp:228] Iteration 1060, loss = 0.541752
I0905 01:51:13.760259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541752 (* 1 = 0.541752 loss)
I0905 01:51:13.760272 90901 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0905 01:51:19.861196 90901 solver.cpp:228] Iteration 1070, loss = 0.670183
I0905 01:51:19.861413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.670183 (* 1 = 0.670183 loss)
I0905 01:51:19.861426 90901 sgd_solver.cpp:106] Iteration 1070, lr = 0.1
I0905 01:51:25.982090 90901 solver.cpp:228] Iteration 1080, loss = 0.855295
I0905 01:51:25.982141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.855295 (* 1 = 0.855295 loss)
I0905 01:51:25.982156 90901 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0905 01:51:32.195412 90901 solver.cpp:228] Iteration 1090, loss = 0.759147
I0905 01:51:32.195458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.759146 (* 1 = 0.759146 loss)
I0905 01:51:32.195472 90901 sgd_solver.cpp:106] Iteration 1090, lr = 0.1
I0905 01:51:38.496405 90901 solver.cpp:228] Iteration 1100, loss = 0.707256
I0905 01:51:38.496448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.707255 (* 1 = 0.707255 loss)
I0905 01:51:38.496462 90901 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0905 01:51:44.458600 90901 solver.cpp:228] Iteration 1110, loss = 0.513798
I0905 01:51:44.458680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513797 (* 1 = 0.513797 loss)
I0905 01:51:44.458696 90901 sgd_solver.cpp:106] Iteration 1110, lr = 0.1
I0905 01:51:50.543995 90901 solver.cpp:228] Iteration 1120, loss = 0.608766
I0905 01:51:50.544150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.608766 (* 1 = 0.608766 loss)
I0905 01:51:50.544194 90901 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0905 01:51:56.800024 90901 solver.cpp:228] Iteration 1130, loss = 0.410098
I0905 01:51:56.800071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410098 (* 1 = 0.410098 loss)
I0905 01:51:56.800083 90901 sgd_solver.cpp:106] Iteration 1130, lr = 0.1
I0905 01:52:02.903928 90901 solver.cpp:228] Iteration 1140, loss = 0.483943
I0905 01:52:02.903961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.483943 (* 1 = 0.483943 loss)
I0905 01:52:02.903975 90901 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0905 01:52:09.345621 90901 solver.cpp:228] Iteration 1150, loss = 0.385206
I0905 01:52:09.345666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385206 (* 1 = 0.385206 loss)
I0905 01:52:09.345679 90901 sgd_solver.cpp:106] Iteration 1150, lr = 0.1
I0905 01:52:15.459159 90901 solver.cpp:228] Iteration 1160, loss = 0.39073
I0905 01:52:15.459208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39073 (* 1 = 0.39073 loss)
I0905 01:52:15.459223 90901 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0905 01:52:21.229105 90901 solver.cpp:228] Iteration 1170, loss = 0.572784
I0905 01:52:21.229257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572784 (* 1 = 0.572784 loss)
I0905 01:52:21.229290 90901 sgd_solver.cpp:106] Iteration 1170, lr = 0.1
I0905 01:52:27.662415 90901 solver.cpp:228] Iteration 1180, loss = 0.582666
I0905 01:52:27.662478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.582666 (* 1 = 0.582666 loss)
I0905 01:52:27.662493 90901 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0905 01:52:33.761353 90901 solver.cpp:228] Iteration 1190, loss = 0.44568
I0905 01:52:33.761389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44568 (* 1 = 0.44568 loss)
I0905 01:52:33.761401 90901 sgd_solver.cpp:106] Iteration 1190, lr = 0.1
I0905 01:52:39.858176 90901 solver.cpp:228] Iteration 1200, loss = 0.501299
I0905 01:52:39.858232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501298 (* 1 = 0.501298 loss)
I0905 01:52:39.858247 90901 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0905 01:52:45.729650 90901 solver.cpp:228] Iteration 1210, loss = 0.643528
I0905 01:52:45.729689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.643528 (* 1 = 0.643528 loss)
I0905 01:52:45.729702 90901 sgd_solver.cpp:106] Iteration 1210, lr = 0.1
I0905 01:52:51.304249 90901 solver.cpp:228] Iteration 1220, loss = 0.512918
I0905 01:52:51.304515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.512918 (* 1 = 0.512918 loss)
I0905 01:52:51.304533 90901 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0905 01:52:56.882380 90901 solver.cpp:228] Iteration 1230, loss = 0.604956
I0905 01:52:56.882438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.604956 (* 1 = 0.604956 loss)
I0905 01:52:56.882452 90901 sgd_solver.cpp:106] Iteration 1230, lr = 0.1
I0905 01:53:02.961828 90901 solver.cpp:228] Iteration 1240, loss = 0.422753
I0905 01:53:02.961879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422753 (* 1 = 0.422753 loss)
I0905 01:53:02.961891 90901 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0905 01:53:09.064764 90901 solver.cpp:228] Iteration 1250, loss = 0.421747
I0905 01:53:09.064816 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421746 (* 1 = 0.421746 loss)
I0905 01:53:09.064829 90901 sgd_solver.cpp:106] Iteration 1250, lr = 0.1
I0905 01:53:15.180187 90901 solver.cpp:228] Iteration 1260, loss = 0.400486
I0905 01:53:15.180232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400486 (* 1 = 0.400486 loss)
I0905 01:53:15.180244 90901 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0905 01:53:21.304677 90901 solver.cpp:228] Iteration 1270, loss = 0.445779
I0905 01:53:21.304832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445778 (* 1 = 0.445778 loss)
I0905 01:53:21.304859 90901 sgd_solver.cpp:106] Iteration 1270, lr = 0.1
I0905 01:53:27.399096 90901 solver.cpp:228] Iteration 1280, loss = 0.732304
I0905 01:53:27.399145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.732304 (* 1 = 0.732304 loss)
I0905 01:53:27.399159 90901 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0905 01:53:33.873740 90901 solver.cpp:228] Iteration 1290, loss = 0.591758
I0905 01:53:33.873785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.591757 (* 1 = 0.591757 loss)
I0905 01:53:33.873798 90901 sgd_solver.cpp:106] Iteration 1290, lr = 0.1
I0905 01:53:39.965657 90901 solver.cpp:228] Iteration 1300, loss = 0.438148
I0905 01:53:39.965698 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438148 (* 1 = 0.438148 loss)
I0905 01:53:39.965711 90901 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0905 01:53:46.106163 90901 solver.cpp:228] Iteration 1310, loss = 0.565428
I0905 01:53:46.106211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565427 (* 1 = 0.565427 loss)
I0905 01:53:46.106225 90901 sgd_solver.cpp:106] Iteration 1310, lr = 0.1
I0905 01:53:52.202075 90901 solver.cpp:228] Iteration 1320, loss = 0.48746
I0905 01:53:52.202252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487459 (* 1 = 0.487459 loss)
I0905 01:53:52.202294 90901 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0905 01:53:58.008711 90901 solver.cpp:228] Iteration 1330, loss = 0.607419
I0905 01:53:58.008751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607418 (* 1 = 0.607418 loss)
I0905 01:53:58.008764 90901 sgd_solver.cpp:106] Iteration 1330, lr = 0.1
I0905 01:54:03.740762 90901 solver.cpp:228] Iteration 1340, loss = 0.670758
I0905 01:54:03.740816 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.670758 (* 1 = 0.670758 loss)
I0905 01:54:03.740830 90901 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0905 01:54:10.188078 90901 solver.cpp:228] Iteration 1350, loss = 0.450018
I0905 01:54:10.188132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450018 (* 1 = 0.450018 loss)
I0905 01:54:10.188145 90901 sgd_solver.cpp:106] Iteration 1350, lr = 0.1
I0905 01:54:16.298058 90901 solver.cpp:228] Iteration 1360, loss = 0.676559
I0905 01:54:16.298096 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.676558 (* 1 = 0.676558 loss)
I0905 01:54:16.298110 90901 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0905 01:54:22.399246 90901 solver.cpp:228] Iteration 1370, loss = 0.51334
I0905 01:54:22.399466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513339 (* 1 = 0.513339 loss)
I0905 01:54:22.399508 90901 sgd_solver.cpp:106] Iteration 1370, lr = 0.1
I0905 01:54:28.793666 90901 solver.cpp:228] Iteration 1380, loss = 0.587107
I0905 01:54:28.793710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.587107 (* 1 = 0.587107 loss)
I0905 01:54:28.793727 90901 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0905 01:54:34.067031 90901 solver.cpp:228] Iteration 1390, loss = 0.699648
I0905 01:54:34.067073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.699648 (* 1 = 0.699648 loss)
I0905 01:54:34.067086 90901 sgd_solver.cpp:106] Iteration 1390, lr = 0.1
I0905 01:54:39.454455 90901 solver.cpp:228] Iteration 1400, loss = 0.502574
I0905 01:54:39.454497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502574 (* 1 = 0.502574 loss)
I0905 01:54:39.454512 90901 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0905 01:54:45.858547 90901 solver.cpp:228] Iteration 1410, loss = 0.508269
I0905 01:54:45.858597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.508269 (* 1 = 0.508269 loss)
I0905 01:54:45.858610 90901 sgd_solver.cpp:106] Iteration 1410, lr = 0.1
I0905 01:54:50.941069 90901 solver.cpp:228] Iteration 1420, loss = 0.602926
I0905 01:54:50.941117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.602925 (* 1 = 0.602925 loss)
I0905 01:54:50.941131 90901 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0905 01:54:55.989019 90901 solver.cpp:228] Iteration 1430, loss = 0.589024
I0905 01:54:55.989219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.589024 (* 1 = 0.589024 loss)
I0905 01:54:55.989256 90901 sgd_solver.cpp:106] Iteration 1430, lr = 0.1
I0905 01:55:01.043776 90901 solver.cpp:228] Iteration 1440, loss = 0.299634
I0905 01:55:01.043828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299634 (* 1 = 0.299634 loss)
I0905 01:55:01.043843 90901 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0905 01:55:06.128919 90901 solver.cpp:228] Iteration 1450, loss = 0.4618
I0905 01:55:06.128973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4618 (* 1 = 0.4618 loss)
I0905 01:55:06.128985 90901 sgd_solver.cpp:106] Iteration 1450, lr = 0.1
I0905 01:55:11.173357 90901 solver.cpp:228] Iteration 1460, loss = 0.369133
I0905 01:55:11.173408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369133 (* 1 = 0.369133 loss)
I0905 01:55:11.173423 90901 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0905 01:55:16.217953 90901 solver.cpp:228] Iteration 1470, loss = 0.807862
I0905 01:55:16.218013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.807862 (* 1 = 0.807862 loss)
I0905 01:55:16.218026 90901 sgd_solver.cpp:106] Iteration 1470, lr = 0.1
I0905 01:55:21.264991 90901 solver.cpp:228] Iteration 1480, loss = 0.729367
I0905 01:55:21.265049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.729367 (* 1 = 0.729367 loss)
I0905 01:55:21.265064 90901 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0905 01:55:26.337666 90901 solver.cpp:228] Iteration 1490, loss = 0.711494
I0905 01:55:26.337882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.711494 (* 1 = 0.711494 loss)
I0905 01:55:26.337898 90901 sgd_solver.cpp:106] Iteration 1490, lr = 0.1
I0905 01:55:31.404068 90901 solver.cpp:228] Iteration 1500, loss = 0.593299
I0905 01:55:31.404126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.593298 (* 1 = 0.593298 loss)
I0905 01:55:31.404141 90901 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0905 01:55:36.488814 90901 solver.cpp:228] Iteration 1510, loss = 0.463046
I0905 01:55:36.488880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463045 (* 1 = 0.463045 loss)
I0905 01:55:36.488899 90901 sgd_solver.cpp:106] Iteration 1510, lr = 0.1
I0905 01:55:41.558758 90901 solver.cpp:228] Iteration 1520, loss = 0.53265
I0905 01:55:41.558815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.53265 (* 1 = 0.53265 loss)
I0905 01:55:41.558830 90901 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0905 01:55:46.620074 90901 solver.cpp:228] Iteration 1530, loss = 0.451784
I0905 01:55:46.620137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451784 (* 1 = 0.451784 loss)
I0905 01:55:46.620152 90901 sgd_solver.cpp:106] Iteration 1530, lr = 0.1
I0905 01:55:51.693536 90901 solver.cpp:228] Iteration 1540, loss = 0.801733
I0905 01:55:51.693595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.801733 (* 1 = 0.801733 loss)
I0905 01:55:51.693610 90901 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0905 01:55:56.733769 90901 solver.cpp:228] Iteration 1550, loss = 0.541846
I0905 01:55:56.734051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541846 (* 1 = 0.541846 loss)
I0905 01:55:56.734067 90901 sgd_solver.cpp:106] Iteration 1550, lr = 0.1
I0905 01:56:01.775687 90901 solver.cpp:228] Iteration 1560, loss = 0.475288
I0905 01:56:01.775739 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475288 (* 1 = 0.475288 loss)
I0905 01:56:01.775753 90901 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0905 01:56:06.829836 90901 solver.cpp:228] Iteration 1570, loss = 0.753387
I0905 01:56:06.829898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.753387 (* 1 = 0.753387 loss)
I0905 01:56:06.829911 90901 sgd_solver.cpp:106] Iteration 1570, lr = 0.1
I0905 01:56:12.913519 90901 solver.cpp:228] Iteration 1580, loss = 0.631102
I0905 01:56:12.913565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.631102 (* 1 = 0.631102 loss)
I0905 01:56:12.913579 90901 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0905 01:56:18.978262 90901 solver.cpp:228] Iteration 1590, loss = 0.558709
I0905 01:56:18.978307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.558709 (* 1 = 0.558709 loss)
I0905 01:56:18.978320 90901 sgd_solver.cpp:106] Iteration 1590, lr = 0.1
I0905 01:56:24.498594 90901 solver.cpp:337] Iteration 1600, Testing net (#0)
I0905 01:57:06.108630 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.775625
I0905 01:57:06.108855 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.495123 (* 1 = 0.495123 loss)
I0905 01:57:06.325063 90901 solver.cpp:228] Iteration 1600, loss = 0.320126
I0905 01:57:06.325093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320125 (* 1 = 0.320125 loss)
I0905 01:57:06.325109 90901 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0905 01:57:12.392673 90901 solver.cpp:228] Iteration 1610, loss = 0.455267
I0905 01:57:12.392720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455267 (* 1 = 0.455267 loss)
I0905 01:57:12.392734 90901 sgd_solver.cpp:106] Iteration 1610, lr = 0.1
I0905 01:57:18.489449 90901 solver.cpp:228] Iteration 1620, loss = 0.611897
I0905 01:57:18.489500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.611897 (* 1 = 0.611897 loss)
I0905 01:57:18.489513 90901 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0905 01:57:24.626910 90901 solver.cpp:228] Iteration 1630, loss = 0.77344
I0905 01:57:24.626962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.77344 (* 1 = 0.77344 loss)
I0905 01:57:24.626976 90901 sgd_solver.cpp:106] Iteration 1630, lr = 0.1
I0905 01:57:30.741267 90901 solver.cpp:228] Iteration 1640, loss = 0.444126
I0905 01:57:30.741319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444126 (* 1 = 0.444126 loss)
I0905 01:57:30.741333 90901 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0905 01:57:36.847196 90901 solver.cpp:228] Iteration 1650, loss = 0.399856
I0905 01:57:36.847388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399856 (* 1 = 0.399856 loss)
I0905 01:57:36.847405 90901 sgd_solver.cpp:106] Iteration 1650, lr = 0.1
I0905 01:57:43.275099 90901 solver.cpp:228] Iteration 1660, loss = 0.331169
I0905 01:57:43.275138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331168 (* 1 = 0.331168 loss)
I0905 01:57:43.275152 90901 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0905 01:57:49.050587 90901 solver.cpp:228] Iteration 1670, loss = 0.55814
I0905 01:57:49.050637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55814 (* 1 = 0.55814 loss)
I0905 01:57:49.050658 90901 sgd_solver.cpp:106] Iteration 1670, lr = 0.1
I0905 01:57:55.298491 90901 solver.cpp:228] Iteration 1680, loss = 0.293
I0905 01:57:55.298550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293 (* 1 = 0.293 loss)
I0905 01:57:55.298564 90901 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0905 01:58:01.221436 90901 solver.cpp:228] Iteration 1690, loss = 0.549652
I0905 01:58:01.221478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.549651 (* 1 = 0.549651 loss)
I0905 01:58:01.221493 90901 sgd_solver.cpp:106] Iteration 1690, lr = 0.1
I0905 01:58:07.395253 90901 solver.cpp:228] Iteration 1700, loss = 0.603912
I0905 01:58:07.395385 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.603911 (* 1 = 0.603911 loss)
I0905 01:58:07.395417 90901 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0905 01:58:13.319913 90901 solver.cpp:228] Iteration 1710, loss = 0.806958
I0905 01:58:13.319963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.806958 (* 1 = 0.806958 loss)
I0905 01:58:13.319977 90901 sgd_solver.cpp:106] Iteration 1710, lr = 0.1
I0905 01:58:18.625169 90901 solver.cpp:228] Iteration 1720, loss = 0.482127
I0905 01:58:18.625216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482126 (* 1 = 0.482126 loss)
I0905 01:58:18.625229 90901 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0905 01:58:24.638321 90901 solver.cpp:228] Iteration 1730, loss = 0.467885
I0905 01:58:24.638378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467885 (* 1 = 0.467885 loss)
I0905 01:58:24.638391 90901 sgd_solver.cpp:106] Iteration 1730, lr = 0.1
I0905 01:58:30.775872 90901 solver.cpp:228] Iteration 1740, loss = 0.263939
I0905 01:58:30.775907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263938 (* 1 = 0.263938 loss)
I0905 01:58:30.775916 90901 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0905 01:58:36.890120 90901 solver.cpp:228] Iteration 1750, loss = 0.560799
I0905 01:58:36.890166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.560798 (* 1 = 0.560798 loss)
I0905 01:58:36.890180 90901 sgd_solver.cpp:106] Iteration 1750, lr = 0.1
I0905 01:58:42.959368 90901 solver.cpp:228] Iteration 1760, loss = 0.506949
I0905 01:58:42.959571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.506949 (* 1 = 0.506949 loss)
I0905 01:58:42.959589 90901 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0905 01:58:49.394749 90901 solver.cpp:228] Iteration 1770, loss = 0.535758
I0905 01:58:49.394798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535758 (* 1 = 0.535758 loss)
I0905 01:58:49.394810 90901 sgd_solver.cpp:106] Iteration 1770, lr = 0.1
I0905 01:58:55.557178 90901 solver.cpp:228] Iteration 1780, loss = 0.255839
I0905 01:58:55.557226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255839 (* 1 = 0.255839 loss)
I0905 01:58:55.557240 90901 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0905 01:59:01.903568 90901 solver.cpp:228] Iteration 1790, loss = 0.395134
I0905 01:59:01.903614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395134 (* 1 = 0.395134 loss)
I0905 01:59:01.903628 90901 sgd_solver.cpp:106] Iteration 1790, lr = 0.1
I0905 01:59:08.002876 90901 solver.cpp:228] Iteration 1800, loss = 0.502419
I0905 01:59:08.002923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502418 (* 1 = 0.502418 loss)
I0905 01:59:08.002938 90901 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0905 01:59:14.063063 90901 solver.cpp:228] Iteration 1810, loss = 0.640874
I0905 01:59:14.063290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.640873 (* 1 = 0.640873 loss)
I0905 01:59:14.063305 90901 sgd_solver.cpp:106] Iteration 1810, lr = 0.1
I0905 01:59:20.140736 90901 solver.cpp:228] Iteration 1820, loss = 0.451984
I0905 01:59:20.140779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451983 (* 1 = 0.451983 loss)
I0905 01:59:20.140791 90901 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0905 01:59:26.216944 90901 solver.cpp:228] Iteration 1830, loss = 0.448165
I0905 01:59:26.217003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448165 (* 1 = 0.448165 loss)
I0905 01:59:26.217017 90901 sgd_solver.cpp:106] Iteration 1830, lr = 0.1
I0905 01:59:32.553567 90901 solver.cpp:228] Iteration 1840, loss = 0.320103
I0905 01:59:32.553616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320103 (* 1 = 0.320103 loss)
I0905 01:59:32.553628 90901 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0905 01:59:38.741900 90901 solver.cpp:228] Iteration 1850, loss = 0.673185
I0905 01:59:38.741958 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.673185 (* 1 = 0.673185 loss)
I0905 01:59:38.741973 90901 sgd_solver.cpp:106] Iteration 1850, lr = 0.1
I0905 01:59:44.489239 90901 solver.cpp:228] Iteration 1860, loss = 0.649576
I0905 01:59:44.489383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.649576 (* 1 = 0.649576 loss)
I0905 01:59:44.489413 90901 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0905 01:59:50.914480 90901 solver.cpp:228] Iteration 1870, loss = 0.231448
I0905 01:59:50.914528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231447 (* 1 = 0.231447 loss)
I0905 01:59:50.914542 90901 sgd_solver.cpp:106] Iteration 1870, lr = 0.1
I0905 01:59:56.993297 90901 solver.cpp:228] Iteration 1880, loss = 0.462945
I0905 01:59:56.993362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462945 (* 1 = 0.462945 loss)
I0905 01:59:56.993378 90901 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0905 02:00:02.569933 90901 solver.cpp:228] Iteration 1890, loss = 0.603045
I0905 02:00:02.569991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.603045 (* 1 = 0.603045 loss)
I0905 02:00:02.570004 90901 sgd_solver.cpp:106] Iteration 1890, lr = 0.1
I0905 02:00:07.915843 90901 solver.cpp:228] Iteration 1900, loss = 0.700748
I0905 02:00:07.915907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.700748 (* 1 = 0.700748 loss)
I0905 02:00:07.915936 90901 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0905 02:00:13.681172 90901 solver.cpp:228] Iteration 1910, loss = 0.345146
I0905 02:00:13.681219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345146 (* 1 = 0.345146 loss)
I0905 02:00:13.681234 90901 sgd_solver.cpp:106] Iteration 1910, lr = 0.1
I0905 02:00:19.779151 90901 solver.cpp:228] Iteration 1920, loss = 0.899236
I0905 02:00:19.779317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.899235 (* 1 = 0.899235 loss)
I0905 02:00:19.779362 90901 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0905 02:00:25.857079 90901 solver.cpp:228] Iteration 1930, loss = 0.418687
I0905 02:00:25.857131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418687 (* 1 = 0.418687 loss)
I0905 02:00:25.857146 90901 sgd_solver.cpp:106] Iteration 1930, lr = 0.1
I0905 02:00:31.969746 90901 solver.cpp:228] Iteration 1940, loss = 0.573391
I0905 02:00:31.969792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.573391 (* 1 = 0.573391 loss)
I0905 02:00:31.969806 90901 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0905 02:00:38.046254 90901 solver.cpp:228] Iteration 1950, loss = 0.578079
I0905 02:00:38.046319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578079 (* 1 = 0.578079 loss)
I0905 02:00:38.046335 90901 sgd_solver.cpp:106] Iteration 1950, lr = 0.1
I0905 02:00:44.125504 90901 solver.cpp:228] Iteration 1960, loss = 0.901437
I0905 02:00:44.125540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.901436 (* 1 = 0.901436 loss)
I0905 02:00:44.125552 90901 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0905 02:00:50.535248 90901 solver.cpp:228] Iteration 1970, loss = 0.253797
I0905 02:00:50.535454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253796 (* 1 = 0.253796 loss)
I0905 02:00:50.535481 90901 sgd_solver.cpp:106] Iteration 1970, lr = 0.1
I0905 02:00:56.658623 90901 solver.cpp:228] Iteration 1980, loss = 0.804381
I0905 02:00:56.658679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.80438 (* 1 = 0.80438 loss)
I0905 02:00:56.658694 90901 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0905 02:01:02.437541 90901 solver.cpp:228] Iteration 1990, loss = 0.285347
I0905 02:01:02.437599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285346 (* 1 = 0.285346 loss)
I0905 02:01:02.437613 90901 sgd_solver.cpp:106] Iteration 1990, lr = 0.1
I0905 02:01:08.522121 90901 solver.cpp:228] Iteration 2000, loss = 0.24409
I0905 02:01:08.522172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24409 (* 1 = 0.24409 loss)
I0905 02:01:08.522186 90901 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0905 02:01:14.937111 90901 solver.cpp:228] Iteration 2010, loss = 0.96831
I0905 02:01:14.937157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.96831 (* 1 = 0.96831 loss)
I0905 02:01:14.937171 90901 sgd_solver.cpp:106] Iteration 2010, lr = 0.1
I0905 02:01:21.008183 90901 solver.cpp:228] Iteration 2020, loss = 0.895853
I0905 02:01:21.008340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.895852 (* 1 = 0.895852 loss)
I0905 02:01:21.008368 90901 sgd_solver.cpp:106] Iteration 2020, lr = 0.1
I0905 02:01:27.099082 90901 solver.cpp:228] Iteration 2030, loss = 0.47007
I0905 02:01:27.099138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.470069 (* 1 = 0.470069 loss)
I0905 02:01:27.099153 90901 sgd_solver.cpp:106] Iteration 2030, lr = 0.1
I0905 02:01:33.218433 90901 solver.cpp:228] Iteration 2040, loss = 0.412112
I0905 02:01:33.218477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412112 (* 1 = 0.412112 loss)
I0905 02:01:33.218489 90901 sgd_solver.cpp:106] Iteration 2040, lr = 0.1
I0905 02:01:39.310909 90901 solver.cpp:228] Iteration 2050, loss = 0.480473
I0905 02:01:39.310950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480473 (* 1 = 0.480473 loss)
I0905 02:01:39.310961 90901 sgd_solver.cpp:106] Iteration 2050, lr = 0.1
I0905 02:01:44.995779 90901 solver.cpp:228] Iteration 2060, loss = 0.701398
I0905 02:01:44.995821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.701398 (* 1 = 0.701398 loss)
I0905 02:01:44.995836 90901 sgd_solver.cpp:106] Iteration 2060, lr = 0.1
I0905 02:01:50.892838 90901 solver.cpp:228] Iteration 2070, loss = 0.55624
I0905 02:01:50.892894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55624 (* 1 = 0.55624 loss)
I0905 02:01:50.892909 90901 sgd_solver.cpp:106] Iteration 2070, lr = 0.1
I0905 02:01:56.662760 90901 solver.cpp:228] Iteration 2080, loss = 0.557767
I0905 02:01:56.662884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.557767 (* 1 = 0.557767 loss)
I0905 02:01:56.662914 90901 sgd_solver.cpp:106] Iteration 2080, lr = 0.1
I0905 02:02:02.418931 90901 solver.cpp:228] Iteration 2090, loss = 0.555692
I0905 02:02:02.418970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555691 (* 1 = 0.555691 loss)
I0905 02:02:02.418983 90901 sgd_solver.cpp:106] Iteration 2090, lr = 0.1
I0905 02:02:08.456780 90901 solver.cpp:228] Iteration 2100, loss = 0.476596
I0905 02:02:08.456825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476596 (* 1 = 0.476596 loss)
I0905 02:02:08.456837 90901 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0905 02:02:14.558686 90901 solver.cpp:228] Iteration 2110, loss = 0.446913
I0905 02:02:14.558737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446913 (* 1 = 0.446913 loss)
I0905 02:02:14.558749 90901 sgd_solver.cpp:106] Iteration 2110, lr = 0.1
I0905 02:02:20.968726 90901 solver.cpp:228] Iteration 2120, loss = 0.575167
I0905 02:02:20.968770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.575167 (* 1 = 0.575167 loss)
I0905 02:02:20.968782 90901 sgd_solver.cpp:106] Iteration 2120, lr = 0.1
I0905 02:02:27.040138 90901 solver.cpp:228] Iteration 2130, loss = 0.691163
I0905 02:02:27.040375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.691162 (* 1 = 0.691162 loss)
I0905 02:02:27.040393 90901 sgd_solver.cpp:106] Iteration 2130, lr = 0.1
I0905 02:02:33.163502 90901 solver.cpp:228] Iteration 2140, loss = 0.420447
I0905 02:02:33.163552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.420447 (* 1 = 0.420447 loss)
I0905 02:02:33.163566 90901 sgd_solver.cpp:106] Iteration 2140, lr = 0.1
I0905 02:02:39.263291 90901 solver.cpp:228] Iteration 2150, loss = 0.647462
I0905 02:02:39.263355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.647462 (* 1 = 0.647462 loss)
I0905 02:02:39.263367 90901 sgd_solver.cpp:106] Iteration 2150, lr = 0.1
I0905 02:02:45.604358 90901 solver.cpp:228] Iteration 2160, loss = 0.535439
I0905 02:02:45.604406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535439 (* 1 = 0.535439 loss)
I0905 02:02:45.604420 90901 sgd_solver.cpp:106] Iteration 2160, lr = 0.1
I0905 02:02:51.598655 90901 solver.cpp:228] Iteration 2170, loss = 0.570659
I0905 02:02:51.598701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.570659 (* 1 = 0.570659 loss)
I0905 02:02:51.598718 90901 sgd_solver.cpp:106] Iteration 2170, lr = 0.1
I0905 02:02:57.842272 90901 solver.cpp:228] Iteration 2180, loss = 0.414563
I0905 02:02:57.842442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414563 (* 1 = 0.414563 loss)
I0905 02:02:57.842483 90901 sgd_solver.cpp:106] Iteration 2180, lr = 0.1
I0905 02:03:03.938185 90901 solver.cpp:228] Iteration 2190, loss = 0.400711
I0905 02:03:03.938235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400711 (* 1 = 0.400711 loss)
I0905 02:03:03.938251 90901 sgd_solver.cpp:106] Iteration 2190, lr = 0.1
I0905 02:03:10.068045 90901 solver.cpp:228] Iteration 2200, loss = 0.465993
I0905 02:03:10.068102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465992 (* 1 = 0.465992 loss)
I0905 02:03:10.068116 90901 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0905 02:03:15.816473 90901 solver.cpp:228] Iteration 2210, loss = 0.628087
I0905 02:03:15.816524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.628087 (* 1 = 0.628087 loss)
I0905 02:03:15.816543 90901 sgd_solver.cpp:106] Iteration 2210, lr = 0.1
I0905 02:03:21.906263 90901 solver.cpp:228] Iteration 2220, loss = 0.484242
I0905 02:03:21.906319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484242 (* 1 = 0.484242 loss)
I0905 02:03:21.906334 90901 sgd_solver.cpp:106] Iteration 2220, lr = 0.1
I0905 02:03:28.015141 90901 solver.cpp:228] Iteration 2230, loss = 0.64153
I0905 02:03:28.015276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64153 (* 1 = 0.64153 loss)
I0905 02:03:28.015323 90901 sgd_solver.cpp:106] Iteration 2230, lr = 0.1
I0905 02:03:34.213711 90901 solver.cpp:228] Iteration 2240, loss = 0.390042
I0905 02:03:34.213752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390042 (* 1 = 0.390042 loss)
I0905 02:03:34.213765 90901 sgd_solver.cpp:106] Iteration 2240, lr = 0.1
I0905 02:03:39.505239 90901 solver.cpp:228] Iteration 2250, loss = 0.454501
I0905 02:03:39.505301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4545 (* 1 = 0.4545 loss)
I0905 02:03:39.505318 90901 sgd_solver.cpp:106] Iteration 2250, lr = 0.1
I0905 02:03:45.276873 90901 solver.cpp:228] Iteration 2260, loss = 0.58526
I0905 02:03:45.276916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.58526 (* 1 = 0.58526 loss)
I0905 02:03:45.276928 90901 sgd_solver.cpp:106] Iteration 2260, lr = 0.1
I0905 02:03:51.361521 90901 solver.cpp:228] Iteration 2270, loss = 0.509537
I0905 02:03:51.361574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.509536 (* 1 = 0.509536 loss)
I0905 02:03:51.361588 90901 sgd_solver.cpp:106] Iteration 2270, lr = 0.1
I0905 02:03:57.418360 90901 solver.cpp:228] Iteration 2280, loss = 0.459743
I0905 02:03:57.418403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459743 (* 1 = 0.459743 loss)
I0905 02:03:57.418416 90901 sgd_solver.cpp:106] Iteration 2280, lr = 0.1
I0905 02:04:03.830206 90901 solver.cpp:228] Iteration 2290, loss = 0.610456
I0905 02:04:03.830410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.610456 (* 1 = 0.610456 loss)
I0905 02:04:03.830440 90901 sgd_solver.cpp:106] Iteration 2290, lr = 0.1
I0905 02:04:09.400161 90901 solver.cpp:228] Iteration 2300, loss = 0.461372
I0905 02:04:09.400210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461372 (* 1 = 0.461372 loss)
I0905 02:04:09.400224 90901 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0905 02:04:15.759413 90901 solver.cpp:228] Iteration 2310, loss = 0.396692
I0905 02:04:15.759467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396691 (* 1 = 0.396691 loss)
I0905 02:04:15.759481 90901 sgd_solver.cpp:106] Iteration 2310, lr = 0.1
I0905 02:04:21.862979 90901 solver.cpp:228] Iteration 2320, loss = 0.409016
I0905 02:04:21.863034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409015 (* 1 = 0.409015 loss)
I0905 02:04:21.863049 90901 sgd_solver.cpp:106] Iteration 2320, lr = 0.1
I0905 02:04:27.931741 90901 solver.cpp:228] Iteration 2330, loss = 0.356954
I0905 02:04:27.931810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356953 (* 1 = 0.356953 loss)
I0905 02:04:27.931823 90901 sgd_solver.cpp:106] Iteration 2330, lr = 0.1
I0905 02:04:34.067749 90901 solver.cpp:228] Iteration 2340, loss = 0.558796
I0905 02:04:34.067901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.558795 (* 1 = 0.558795 loss)
I0905 02:04:34.067929 90901 sgd_solver.cpp:106] Iteration 2340, lr = 0.1
I0905 02:04:40.150769 90901 solver.cpp:228] Iteration 2350, loss = 0.38493
I0905 02:04:40.150827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38493 (* 1 = 0.38493 loss)
I0905 02:04:40.150842 90901 sgd_solver.cpp:106] Iteration 2350, lr = 0.1
I0905 02:04:46.588548 90901 solver.cpp:228] Iteration 2360, loss = 0.401083
I0905 02:04:46.588592 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401083 (* 1 = 0.401083 loss)
I0905 02:04:46.588604 90901 sgd_solver.cpp:106] Iteration 2360, lr = 0.1
I0905 02:04:52.712682 90901 solver.cpp:228] Iteration 2370, loss = 0.504175
I0905 02:04:52.712735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504175 (* 1 = 0.504175 loss)
I0905 02:04:52.712751 90901 sgd_solver.cpp:106] Iteration 2370, lr = 0.1
I0905 02:04:58.951021 90901 solver.cpp:228] Iteration 2380, loss = 0.469158
I0905 02:04:58.951066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469158 (* 1 = 0.469158 loss)
I0905 02:04:58.951081 90901 sgd_solver.cpp:106] Iteration 2380, lr = 0.1
I0905 02:05:04.879755 90901 solver.cpp:228] Iteration 2390, loss = 0.320135
I0905 02:05:04.879914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320134 (* 1 = 0.320134 loss)
I0905 02:05:04.879941 90901 sgd_solver.cpp:106] Iteration 2390, lr = 0.1
I0905 02:05:11.076295 90901 solver.cpp:337] Iteration 2400, Testing net (#0)
I0905 02:05:52.411262 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.614688
I0905 02:05:52.411397 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.82832 (* 1 = 0.82832 loss)
I0905 02:05:52.633030 90901 solver.cpp:228] Iteration 2400, loss = 0.606676
I0905 02:05:52.633071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.606676 (* 1 = 0.606676 loss)
I0905 02:05:52.633088 90901 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0905 02:05:58.417206 90901 solver.cpp:228] Iteration 2410, loss = 0.505497
I0905 02:05:58.417258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505496 (* 1 = 0.505496 loss)
I0905 02:05:58.417271 90901 sgd_solver.cpp:106] Iteration 2410, lr = 0.1
I0905 02:06:04.496278 90901 solver.cpp:228] Iteration 2420, loss = 0.782197
I0905 02:06:04.496323 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.782196 (* 1 = 0.782196 loss)
I0905 02:06:04.496337 90901 sgd_solver.cpp:106] Iteration 2420, lr = 0.1
I0905 02:06:10.619518 90901 solver.cpp:228] Iteration 2430, loss = 0.486298
I0905 02:06:10.619561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486297 (* 1 = 0.486297 loss)
I0905 02:06:10.619575 90901 sgd_solver.cpp:106] Iteration 2430, lr = 0.1
I0905 02:06:17.063995 90901 solver.cpp:228] Iteration 2440, loss = 0.232418
I0905 02:06:17.064038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232418 (* 1 = 0.232418 loss)
I0905 02:06:17.064051 90901 sgd_solver.cpp:106] Iteration 2440, lr = 0.1
I0905 02:06:23.153887 90901 solver.cpp:228] Iteration 2450, loss = 0.293667
I0905 02:06:23.154063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293667 (* 1 = 0.293667 loss)
I0905 02:06:23.154094 90901 sgd_solver.cpp:106] Iteration 2450, lr = 0.1
I0905 02:06:29.241775 90901 solver.cpp:228] Iteration 2460, loss = 0.365073
I0905 02:06:29.241822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365073 (* 1 = 0.365073 loss)
I0905 02:06:29.241834 90901 sgd_solver.cpp:106] Iteration 2460, lr = 0.1
I0905 02:06:35.353866 90901 solver.cpp:228] Iteration 2470, loss = 0.561869
I0905 02:06:35.353909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.561869 (* 1 = 0.561869 loss)
I0905 02:06:35.353922 90901 sgd_solver.cpp:106] Iteration 2470, lr = 0.1
I0905 02:06:41.455605 90901 solver.cpp:228] Iteration 2480, loss = 0.391022
I0905 02:06:41.455657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391022 (* 1 = 0.391022 loss)
I0905 02:06:41.455672 90901 sgd_solver.cpp:106] Iteration 2480, lr = 0.1
I0905 02:06:47.534013 90901 solver.cpp:228] Iteration 2490, loss = 0.367052
I0905 02:06:47.534060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367052 (* 1 = 0.367052 loss)
I0905 02:06:47.534073 90901 sgd_solver.cpp:106] Iteration 2490, lr = 0.1
I0905 02:06:53.988270 90901 solver.cpp:228] Iteration 2500, loss = 0.348551
I0905 02:06:53.988391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348551 (* 1 = 0.348551 loss)
I0905 02:06:53.988420 90901 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0905 02:07:00.082986 90901 solver.cpp:228] Iteration 2510, loss = 0.607947
I0905 02:07:00.083029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607947 (* 1 = 0.607947 loss)
I0905 02:07:00.083040 90901 sgd_solver.cpp:106] Iteration 2510, lr = 0.1
I0905 02:07:06.192998 90901 solver.cpp:228] Iteration 2520, loss = 0.448812
I0905 02:07:06.193071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448811 (* 1 = 0.448811 loss)
I0905 02:07:06.193087 90901 sgd_solver.cpp:106] Iteration 2520, lr = 0.1
I0905 02:07:11.492187 90901 solver.cpp:228] Iteration 2530, loss = 0.327701
I0905 02:07:11.492230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327701 (* 1 = 0.327701 loss)
I0905 02:07:11.492249 90901 sgd_solver.cpp:106] Iteration 2530, lr = 0.1
I0905 02:07:17.141183 90901 solver.cpp:228] Iteration 2540, loss = 0.784636
I0905 02:07:17.141229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.784635 (* 1 = 0.784635 loss)
I0905 02:07:17.141242 90901 sgd_solver.cpp:106] Iteration 2540, lr = 0.1
I0905 02:07:23.250700 90901 solver.cpp:228] Iteration 2550, loss = 0.368479
I0905 02:07:23.250756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368479 (* 1 = 0.368479 loss)
I0905 02:07:23.250769 90901 sgd_solver.cpp:106] Iteration 2550, lr = 0.1
I0905 02:07:29.355327 90901 solver.cpp:228] Iteration 2560, loss = 0.583677
I0905 02:07:29.355561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.583677 (* 1 = 0.583677 loss)
I0905 02:07:29.355599 90901 sgd_solver.cpp:106] Iteration 2560, lr = 0.1
I0905 02:07:35.481931 90901 solver.cpp:228] Iteration 2570, loss = 0.663524
I0905 02:07:35.482000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.663524 (* 1 = 0.663524 loss)
I0905 02:07:35.482017 90901 sgd_solver.cpp:106] Iteration 2570, lr = 0.1
I0905 02:07:41.909368 90901 solver.cpp:228] Iteration 2580, loss = 0.631442
I0905 02:07:41.909412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.631442 (* 1 = 0.631442 loss)
I0905 02:07:41.909431 90901 sgd_solver.cpp:106] Iteration 2580, lr = 0.1
I0905 02:07:47.970476 90901 solver.cpp:228] Iteration 2590, loss = 0.373865
I0905 02:07:47.970518 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373865 (* 1 = 0.373865 loss)
I0905 02:07:47.970530 90901 sgd_solver.cpp:106] Iteration 2590, lr = 0.1
I0905 02:07:54.094377 90901 solver.cpp:228] Iteration 2600, loss = 0.523868
I0905 02:07:54.094424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523867 (* 1 = 0.523867 loss)
I0905 02:07:54.094436 90901 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0905 02:08:00.152787 90901 solver.cpp:228] Iteration 2610, loss = 0.522981
I0905 02:08:00.152942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.52298 (* 1 = 0.52298 loss)
I0905 02:08:00.152979 90901 sgd_solver.cpp:106] Iteration 2610, lr = 0.1
I0905 02:08:06.445456 90901 solver.cpp:228] Iteration 2620, loss = 0.359688
I0905 02:08:06.445526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359688 (* 1 = 0.359688 loss)
I0905 02:08:06.445540 90901 sgd_solver.cpp:106] Iteration 2620, lr = 0.1
I0905 02:08:12.570859 90901 solver.cpp:228] Iteration 2630, loss = 0.477486
I0905 02:08:12.570910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477486 (* 1 = 0.477486 loss)
I0905 02:08:12.570924 90901 sgd_solver.cpp:106] Iteration 2630, lr = 0.1
I0905 02:08:18.645750 90901 solver.cpp:228] Iteration 2640, loss = 0.393837
I0905 02:08:18.645794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393837 (* 1 = 0.393837 loss)
I0905 02:08:18.645809 90901 sgd_solver.cpp:106] Iteration 2640, lr = 0.1
I0905 02:08:24.807523 90901 solver.cpp:228] Iteration 2650, loss = 0.327017
I0905 02:08:24.807571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327017 (* 1 = 0.327017 loss)
I0905 02:08:24.807585 90901 sgd_solver.cpp:106] Iteration 2650, lr = 0.1
I0905 02:08:30.920832 90901 solver.cpp:228] Iteration 2660, loss = 0.834598
I0905 02:08:30.920996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.834598 (* 1 = 0.834598 loss)
I0905 02:08:30.921026 90901 sgd_solver.cpp:106] Iteration 2660, lr = 0.1
I0905 02:08:37.028717 90901 solver.cpp:228] Iteration 2670, loss = 0.339036
I0905 02:08:37.028775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339035 (* 1 = 0.339035 loss)
I0905 02:08:37.028790 90901 sgd_solver.cpp:106] Iteration 2670, lr = 0.1
I0905 02:08:43.165691 90901 solver.cpp:228] Iteration 2680, loss = 0.444408
I0905 02:08:43.165729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444408 (* 1 = 0.444408 loss)
I0905 02:08:43.165742 90901 sgd_solver.cpp:106] Iteration 2680, lr = 0.1
I0905 02:08:49.295002 90901 solver.cpp:228] Iteration 2690, loss = 1.00068
I0905 02:08:49.295042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.00068 (* 1 = 1.00068 loss)
I0905 02:08:49.295054 90901 sgd_solver.cpp:106] Iteration 2690, lr = 0.1
I0905 02:08:55.175668 90901 solver.cpp:228] Iteration 2700, loss = 0.343279
I0905 02:08:55.175724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343279 (* 1 = 0.343279 loss)
I0905 02:08:55.175742 90901 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0905 02:09:00.767998 90901 solver.cpp:228] Iteration 2710, loss = 0.632468
I0905 02:09:00.768044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.632468 (* 1 = 0.632468 loss)
I0905 02:09:00.768059 90901 sgd_solver.cpp:106] Iteration 2710, lr = 0.1
I0905 02:09:06.312691 90901 solver.cpp:228] Iteration 2720, loss = 0.483982
I0905 02:09:06.312887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.483982 (* 1 = 0.483982 loss)
I0905 02:09:06.312927 90901 sgd_solver.cpp:106] Iteration 2720, lr = 0.1
I0905 02:09:12.384387 90901 solver.cpp:228] Iteration 2730, loss = 0.625305
I0905 02:09:12.384440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.625305 (* 1 = 0.625305 loss)
I0905 02:09:12.384455 90901 sgd_solver.cpp:106] Iteration 2730, lr = 0.1
I0905 02:09:18.798712 90901 solver.cpp:228] Iteration 2740, loss = 0.372398
I0905 02:09:18.798784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372398 (* 1 = 0.372398 loss)
I0905 02:09:18.798797 90901 sgd_solver.cpp:106] Iteration 2740, lr = 0.1
I0905 02:09:24.898733 90901 solver.cpp:228] Iteration 2750, loss = 0.488098
I0905 02:09:24.898808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488098 (* 1 = 0.488098 loss)
I0905 02:09:24.898823 90901 sgd_solver.cpp:106] Iteration 2750, lr = 0.1
I0905 02:09:31.363499 90901 solver.cpp:228] Iteration 2760, loss = 0.357184
I0905 02:09:31.363550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357183 (* 1 = 0.357183 loss)
I0905 02:09:31.363565 90901 sgd_solver.cpp:106] Iteration 2760, lr = 0.1
I0905 02:09:37.449700 90901 solver.cpp:228] Iteration 2770, loss = 0.823872
I0905 02:09:37.449869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.823872 (* 1 = 0.823872 loss)
I0905 02:09:37.449890 90901 sgd_solver.cpp:106] Iteration 2770, lr = 0.1
I0905 02:09:43.606124 90901 solver.cpp:228] Iteration 2780, loss = 0.337975
I0905 02:09:43.606166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337975 (* 1 = 0.337975 loss)
I0905 02:09:43.606179 90901 sgd_solver.cpp:106] Iteration 2780, lr = 0.1
I0905 02:09:49.711380 90901 solver.cpp:228] Iteration 2790, loss = 0.43013
I0905 02:09:49.711454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430129 (* 1 = 0.430129 loss)
I0905 02:09:49.711470 90901 sgd_solver.cpp:106] Iteration 2790, lr = 0.1
I0905 02:09:55.813446 90901 solver.cpp:228] Iteration 2800, loss = 0.599107
I0905 02:09:55.813489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.599107 (* 1 = 0.599107 loss)
I0905 02:09:55.813503 90901 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0905 02:10:01.933212 90901 solver.cpp:228] Iteration 2810, loss = 0.451609
I0905 02:10:01.933265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451609 (* 1 = 0.451609 loss)
I0905 02:10:01.933279 90901 sgd_solver.cpp:106] Iteration 2810, lr = 0.1
I0905 02:10:07.720468 90901 solver.cpp:228] Iteration 2820, loss = 0.528722
I0905 02:10:07.720618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528722 (* 1 = 0.528722 loss)
I0905 02:10:07.720645 90901 sgd_solver.cpp:106] Iteration 2820, lr = 0.1
I0905 02:10:14.100996 90901 solver.cpp:228] Iteration 2830, loss = 0.439034
I0905 02:10:14.101071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439033 (* 1 = 0.439033 loss)
I0905 02:10:14.101086 90901 sgd_solver.cpp:106] Iteration 2830, lr = 0.1
I0905 02:10:20.213347 90901 solver.cpp:228] Iteration 2840, loss = 0.453064
I0905 02:10:20.213404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453064 (* 1 = 0.453064 loss)
I0905 02:10:20.213418 90901 sgd_solver.cpp:106] Iteration 2840, lr = 0.1
I0905 02:10:26.355903 90901 solver.cpp:228] Iteration 2850, loss = 0.435372
I0905 02:10:26.355960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435371 (* 1 = 0.435371 loss)
I0905 02:10:26.355974 90901 sgd_solver.cpp:106] Iteration 2850, lr = 0.1
I0905 02:10:32.768894 90901 solver.cpp:228] Iteration 2860, loss = 0.433108
I0905 02:10:32.768944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433107 (* 1 = 0.433107 loss)
I0905 02:10:32.768956 90901 sgd_solver.cpp:106] Iteration 2860, lr = 0.1
I0905 02:10:38.837677 90901 solver.cpp:228] Iteration 2870, loss = 0.57846
I0905 02:10:38.837874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.57846 (* 1 = 0.57846 loss)
I0905 02:10:38.837924 90901 sgd_solver.cpp:106] Iteration 2870, lr = 0.1
I0905 02:10:44.476996 90901 solver.cpp:228] Iteration 2880, loss = 0.464332
I0905 02:10:44.477056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464332 (* 1 = 0.464332 loss)
I0905 02:10:44.477072 90901 sgd_solver.cpp:106] Iteration 2880, lr = 0.1
I0905 02:10:49.779566 90901 solver.cpp:228] Iteration 2890, loss = 0.528664
I0905 02:10:49.779599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528664 (* 1 = 0.528664 loss)
I0905 02:10:49.779613 90901 sgd_solver.cpp:106] Iteration 2890, lr = 0.1
I0905 02:10:55.832048 90901 solver.cpp:228] Iteration 2900, loss = 0.917684
I0905 02:10:55.832103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.917684 (* 1 = 0.917684 loss)
I0905 02:10:55.832118 90901 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0905 02:11:01.614909 90901 solver.cpp:228] Iteration 2910, loss = 0.510107
I0905 02:11:01.614948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.510107 (* 1 = 0.510107 loss)
I0905 02:11:01.614960 90901 sgd_solver.cpp:106] Iteration 2910, lr = 0.1
I0905 02:11:08.050659 90901 solver.cpp:228] Iteration 2920, loss = 0.493202
I0905 02:11:08.050705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493202 (* 1 = 0.493202 loss)
I0905 02:11:08.050719 90901 sgd_solver.cpp:106] Iteration 2920, lr = 0.1
I0905 02:11:14.161609 90901 solver.cpp:228] Iteration 2930, loss = 0.414208
I0905 02:11:14.161751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414208 (* 1 = 0.414208 loss)
I0905 02:11:14.161790 90901 sgd_solver.cpp:106] Iteration 2930, lr = 0.1
I0905 02:11:20.242362 90901 solver.cpp:228] Iteration 2940, loss = 0.502127
I0905 02:11:20.242413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502127 (* 1 = 0.502127 loss)
I0905 02:11:20.242426 90901 sgd_solver.cpp:106] Iteration 2940, lr = 0.1
I0905 02:11:26.329322 90901 solver.cpp:228] Iteration 2950, loss = 0.215368
I0905 02:11:26.329381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215368 (* 1 = 0.215368 loss)
I0905 02:11:26.329394 90901 sgd_solver.cpp:106] Iteration 2950, lr = 0.1
I0905 02:11:32.455430 90901 solver.cpp:228] Iteration 2960, loss = 0.318708
I0905 02:11:32.455489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318708 (* 1 = 0.318708 loss)
I0905 02:11:32.455502 90901 sgd_solver.cpp:106] Iteration 2960, lr = 0.1
I0905 02:11:38.595659 90901 solver.cpp:228] Iteration 2970, loss = 0.580456
I0905 02:11:38.595701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.580456 (* 1 = 0.580456 loss)
I0905 02:11:38.595715 90901 sgd_solver.cpp:106] Iteration 2970, lr = 0.1
I0905 02:11:44.343555 90901 solver.cpp:228] Iteration 2980, loss = 0.343374
I0905 02:11:44.343763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343373 (* 1 = 0.343373 loss)
I0905 02:11:44.343794 90901 sgd_solver.cpp:106] Iteration 2980, lr = 0.1
I0905 02:11:50.791559 90901 solver.cpp:228] Iteration 2990, loss = 0.410479
I0905 02:11:50.791611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410479 (* 1 = 0.410479 loss)
I0905 02:11:50.791625 90901 sgd_solver.cpp:106] Iteration 2990, lr = 0.1
I0905 02:11:56.885329 90901 solver.cpp:228] Iteration 3000, loss = 0.309459
I0905 02:11:56.885391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309458 (* 1 = 0.309458 loss)
I0905 02:11:56.885407 90901 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0905 02:12:03.264605 90901 solver.cpp:228] Iteration 3010, loss = 0.30201
I0905 02:12:03.264653 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30201 (* 1 = 0.30201 loss)
I0905 02:12:03.264668 90901 sgd_solver.cpp:106] Iteration 3010, lr = 0.1
I0905 02:12:09.375974 90901 solver.cpp:228] Iteration 3020, loss = 0.239294
I0905 02:12:09.376042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239294 (* 1 = 0.239294 loss)
I0905 02:12:09.376060 90901 sgd_solver.cpp:106] Iteration 3020, lr = 0.1
I0905 02:12:15.428917 90901 solver.cpp:228] Iteration 3030, loss = 0.510766
I0905 02:12:15.429158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.510765 (* 1 = 0.510765 loss)
I0905 02:12:15.429177 90901 sgd_solver.cpp:106] Iteration 3030, lr = 0.1
I0905 02:12:21.521293 90901 solver.cpp:228] Iteration 3040, loss = 0.249775
I0905 02:12:21.521349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249774 (* 1 = 0.249774 loss)
I0905 02:12:21.521363 90901 sgd_solver.cpp:106] Iteration 3040, lr = 0.1
I0905 02:12:27.601374 90901 solver.cpp:228] Iteration 3050, loss = 0.723912
I0905 02:12:27.601424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.723912 (* 1 = 0.723912 loss)
I0905 02:12:27.601438 90901 sgd_solver.cpp:106] Iteration 3050, lr = 0.1
I0905 02:12:33.078222 90901 solver.cpp:228] Iteration 3060, loss = 0.807638
I0905 02:12:33.078269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.807638 (* 1 = 0.807638 loss)
I0905 02:12:33.078281 90901 sgd_solver.cpp:106] Iteration 3060, lr = 0.1
I0905 02:12:38.594527 90901 solver.cpp:228] Iteration 3070, loss = 0.599274
I0905 02:12:38.594574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.599273 (* 1 = 0.599273 loss)
I0905 02:12:38.594588 90901 sgd_solver.cpp:106] Iteration 3070, lr = 0.1
I0905 02:12:43.999766 90901 solver.cpp:228] Iteration 3080, loss = 0.457497
I0905 02:12:43.999800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457496 (* 1 = 0.457496 loss)
I0905 02:12:43.999814 90901 sgd_solver.cpp:106] Iteration 3080, lr = 0.1
I0905 02:12:49.077978 90901 solver.cpp:228] Iteration 3090, loss = 0.217217
I0905 02:12:49.078188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217217 (* 1 = 0.217217 loss)
I0905 02:12:49.078207 90901 sgd_solver.cpp:106] Iteration 3090, lr = 0.1
I0905 02:12:54.109268 90901 solver.cpp:228] Iteration 3100, loss = 0.366309
I0905 02:12:54.109304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366309 (* 1 = 0.366309 loss)
I0905 02:12:54.109321 90901 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0905 02:12:59.201617 90901 solver.cpp:228] Iteration 3110, loss = 0.439797
I0905 02:12:59.201665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439797 (* 1 = 0.439797 loss)
I0905 02:12:59.201678 90901 sgd_solver.cpp:106] Iteration 3110, lr = 0.1
I0905 02:13:04.284224 90901 solver.cpp:228] Iteration 3120, loss = 0.867043
I0905 02:13:04.284265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.867043 (* 1 = 0.867043 loss)
I0905 02:13:04.284279 90901 sgd_solver.cpp:106] Iteration 3120, lr = 0.1
I0905 02:13:09.337608 90901 solver.cpp:228] Iteration 3130, loss = 0.308889
I0905 02:13:09.337661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308889 (* 1 = 0.308889 loss)
I0905 02:13:09.337673 90901 sgd_solver.cpp:106] Iteration 3130, lr = 0.1
I0905 02:13:14.401296 90901 solver.cpp:228] Iteration 3140, loss = 0.680723
I0905 02:13:14.401345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.680722 (* 1 = 0.680722 loss)
I0905 02:13:14.401360 90901 sgd_solver.cpp:106] Iteration 3140, lr = 0.1
I0905 02:13:19.450814 90901 solver.cpp:228] Iteration 3150, loss = 0.233682
I0905 02:13:19.451017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233682 (* 1 = 0.233682 loss)
I0905 02:13:19.451035 90901 sgd_solver.cpp:106] Iteration 3150, lr = 0.1
I0905 02:13:24.586912 90901 solver.cpp:228] Iteration 3160, loss = 0.779414
I0905 02:13:24.586959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.779414 (* 1 = 0.779414 loss)
I0905 02:13:24.586972 90901 sgd_solver.cpp:106] Iteration 3160, lr = 0.1
I0905 02:13:29.669765 90901 solver.cpp:228] Iteration 3170, loss = 0.392997
I0905 02:13:29.669816 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392997 (* 1 = 0.392997 loss)
I0905 02:13:29.669829 90901 sgd_solver.cpp:106] Iteration 3170, lr = 0.1
I0905 02:13:34.731009 90901 solver.cpp:228] Iteration 3180, loss = 0.266608
I0905 02:13:34.731050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266608 (* 1 = 0.266608 loss)
I0905 02:13:34.731063 90901 sgd_solver.cpp:106] Iteration 3180, lr = 0.1
I0905 02:13:39.799931 90901 solver.cpp:228] Iteration 3190, loss = 0.506416
I0905 02:13:39.799974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.506416 (* 1 = 0.506416 loss)
I0905 02:13:39.799988 90901 sgd_solver.cpp:106] Iteration 3190, lr = 0.1
I0905 02:13:44.644721 90901 solver.cpp:337] Iteration 3200, Testing net (#0)
I0905 02:14:22.605559 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.5025
I0905 02:14:22.605835 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.82605 (* 1 = 2.82605 loss)
I0905 02:14:22.806228 90901 solver.cpp:228] Iteration 3200, loss = 0.235071
I0905 02:14:22.806270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235071 (* 1 = 0.235071 loss)
I0905 02:14:22.806293 90901 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0905 02:14:28.237074 90901 solver.cpp:228] Iteration 3210, loss = 0.527213
I0905 02:14:28.237117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.527213 (* 1 = 0.527213 loss)
I0905 02:14:28.237129 90901 sgd_solver.cpp:106] Iteration 3210, lr = 0.1
I0905 02:14:34.323422 90901 solver.cpp:228] Iteration 3220, loss = 0.481075
I0905 02:14:34.323478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.481075 (* 1 = 0.481075 loss)
I0905 02:14:34.323494 90901 sgd_solver.cpp:106] Iteration 3220, lr = 0.1
I0905 02:14:40.742460 90901 solver.cpp:228] Iteration 3230, loss = 0.523091
I0905 02:14:40.742516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523091 (* 1 = 0.523091 loss)
I0905 02:14:40.742528 90901 sgd_solver.cpp:106] Iteration 3230, lr = 0.1
I0905 02:14:46.827601 90901 solver.cpp:228] Iteration 3240, loss = 0.473195
I0905 02:14:46.827646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473195 (* 1 = 0.473195 loss)
I0905 02:14:46.827661 90901 sgd_solver.cpp:106] Iteration 3240, lr = 0.1
I0905 02:14:52.930295 90901 solver.cpp:228] Iteration 3250, loss = 0.791417
I0905 02:14:52.930428 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.791417 (* 1 = 0.791417 loss)
I0905 02:14:52.930456 90901 sgd_solver.cpp:106] Iteration 3250, lr = 0.1
I0905 02:14:59.066881 90901 solver.cpp:228] Iteration 3260, loss = 0.576587
I0905 02:14:59.066925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.576587 (* 1 = 0.576587 loss)
I0905 02:14:59.066939 90901 sgd_solver.cpp:106] Iteration 3260, lr = 0.1
I0905 02:15:05.177073 90901 solver.cpp:228] Iteration 3270, loss = 0.556746
I0905 02:15:05.177125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556746 (* 1 = 0.556746 loss)
I0905 02:15:05.177139 90901 sgd_solver.cpp:106] Iteration 3270, lr = 0.1
I0905 02:15:10.971148 90901 solver.cpp:228] Iteration 3280, loss = 0.547319
I0905 02:15:10.971215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547319 (* 1 = 0.547319 loss)
I0905 02:15:10.971230 90901 sgd_solver.cpp:106] Iteration 3280, lr = 0.1
I0905 02:15:17.072958 90901 solver.cpp:228] Iteration 3290, loss = 0.50104
I0905 02:15:17.073012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.50104 (* 1 = 0.50104 loss)
I0905 02:15:17.073029 90901 sgd_solver.cpp:106] Iteration 3290, lr = 0.1
I0905 02:15:23.164139 90901 solver.cpp:228] Iteration 3300, loss = 0.613299
I0905 02:15:23.164300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.613299 (* 1 = 0.613299 loss)
I0905 02:15:23.164355 90901 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0905 02:15:29.271029 90901 solver.cpp:228] Iteration 3310, loss = 0.716531
I0905 02:15:29.271086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.716531 (* 1 = 0.716531 loss)
I0905 02:15:29.271100 90901 sgd_solver.cpp:106] Iteration 3310, lr = 0.1
I0905 02:15:35.649852 90901 solver.cpp:228] Iteration 3320, loss = 0.504407
I0905 02:15:35.649899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504407 (* 1 = 0.504407 loss)
I0905 02:15:35.649915 90901 sgd_solver.cpp:106] Iteration 3320, lr = 0.1
I0905 02:15:41.774459 90901 solver.cpp:228] Iteration 3330, loss = 0.416749
I0905 02:15:41.774499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416749 (* 1 = 0.416749 loss)
I0905 02:15:41.774512 90901 sgd_solver.cpp:106] Iteration 3330, lr = 0.1
I0905 02:15:47.879945 90901 solver.cpp:228] Iteration 3340, loss = 0.362206
I0905 02:15:47.879997 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362205 (* 1 = 0.362205 loss)
I0905 02:15:47.880010 90901 sgd_solver.cpp:106] Iteration 3340, lr = 0.1
I0905 02:15:53.948513 90901 solver.cpp:228] Iteration 3350, loss = 0.359386
I0905 02:15:53.948695 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359386 (* 1 = 0.359386 loss)
I0905 02:15:53.948727 90901 sgd_solver.cpp:106] Iteration 3350, lr = 0.1
I0905 02:16:00.062429 90901 solver.cpp:228] Iteration 3360, loss = 0.549146
I0905 02:16:00.062487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.549145 (* 1 = 0.549145 loss)
I0905 02:16:00.062502 90901 sgd_solver.cpp:106] Iteration 3360, lr = 0.1
I0905 02:16:05.850761 90901 solver.cpp:228] Iteration 3370, loss = 0.376446
I0905 02:16:05.850831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376446 (* 1 = 0.376446 loss)
I0905 02:16:05.850847 90901 sgd_solver.cpp:106] Iteration 3370, lr = 0.1
I0905 02:16:11.424382 90901 solver.cpp:228] Iteration 3380, loss = 0.446609
I0905 02:16:11.424450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446608 (* 1 = 0.446608 loss)
I0905 02:16:11.424466 90901 sgd_solver.cpp:106] Iteration 3380, lr = 0.1
I0905 02:16:17.265116 90901 solver.cpp:228] Iteration 3390, loss = 0.861909
I0905 02:16:17.265164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.861908 (* 1 = 0.861908 loss)
I0905 02:16:17.265180 90901 sgd_solver.cpp:106] Iteration 3390, lr = 0.1
I0905 02:16:23.362498 90901 solver.cpp:228] Iteration 3400, loss = 0.217274
I0905 02:16:23.362551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217274 (* 1 = 0.217274 loss)
I0905 02:16:23.362565 90901 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0905 02:16:29.787438 90901 solver.cpp:228] Iteration 3410, loss = 0.361614
I0905 02:16:29.787600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361613 (* 1 = 0.361613 loss)
I0905 02:16:29.787642 90901 sgd_solver.cpp:106] Iteration 3410, lr = 0.1
I0905 02:16:35.558928 90901 solver.cpp:228] Iteration 3420, loss = 0.413724
I0905 02:16:35.558972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413724 (* 1 = 0.413724 loss)
I0905 02:16:35.558985 90901 sgd_solver.cpp:106] Iteration 3420, lr = 0.1
I0905 02:16:41.694828 90901 solver.cpp:228] Iteration 3430, loss = 0.630875
I0905 02:16:41.694885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.630874 (* 1 = 0.630874 loss)
I0905 02:16:41.694900 90901 sgd_solver.cpp:106] Iteration 3430, lr = 0.1
I0905 02:16:47.797824 90901 solver.cpp:228] Iteration 3440, loss = 0.455771
I0905 02:16:47.797871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455771 (* 1 = 0.455771 loss)
I0905 02:16:47.797888 90901 sgd_solver.cpp:106] Iteration 3440, lr = 0.1
I0905 02:16:54.205709 90901 solver.cpp:228] Iteration 3450, loss = 0.607453
I0905 02:16:54.205760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607453 (* 1 = 0.607453 loss)
I0905 02:16:54.205777 90901 sgd_solver.cpp:106] Iteration 3450, lr = 0.1
I0905 02:17:00.293602 90901 solver.cpp:228] Iteration 3460, loss = 0.573878
I0905 02:17:00.293813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.573877 (* 1 = 0.573877 loss)
I0905 02:17:00.293839 90901 sgd_solver.cpp:106] Iteration 3460, lr = 0.1
I0905 02:17:06.378859 90901 solver.cpp:228] Iteration 3470, loss = 0.320528
I0905 02:17:06.378909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320528 (* 1 = 0.320528 loss)
I0905 02:17:06.378921 90901 sgd_solver.cpp:106] Iteration 3470, lr = 0.1
I0905 02:17:12.410907 90901 solver.cpp:228] Iteration 3480, loss = 0.468203
I0905 02:17:12.410951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468202 (* 1 = 0.468202 loss)
I0905 02:17:12.410964 90901 sgd_solver.cpp:106] Iteration 3480, lr = 0.1
I0905 02:17:18.546118 90901 solver.cpp:228] Iteration 3490, loss = 0.378137
I0905 02:17:18.546181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378136 (* 1 = 0.378136 loss)
I0905 02:17:18.546195 90901 sgd_solver.cpp:106] Iteration 3490, lr = 0.1
I0905 02:17:24.981421 90901 solver.cpp:228] Iteration 3500, loss = 0.433246
I0905 02:17:24.981468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433245 (* 1 = 0.433245 loss)
I0905 02:17:24.981483 90901 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0905 02:17:31.080657 90901 solver.cpp:228] Iteration 3510, loss = 0.772459
I0905 02:17:31.080819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.772459 (* 1 = 0.772459 loss)
I0905 02:17:31.080865 90901 sgd_solver.cpp:106] Iteration 3510, lr = 0.1
I0905 02:17:36.852789 90901 solver.cpp:228] Iteration 3520, loss = 0.466503
I0905 02:17:36.852845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.466503 (* 1 = 0.466503 loss)
I0905 02:17:36.852860 90901 sgd_solver.cpp:106] Iteration 3520, lr = 0.1
I0905 02:17:42.949012 90901 solver.cpp:228] Iteration 3530, loss = 0.693712
I0905 02:17:42.949059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.693711 (* 1 = 0.693711 loss)
I0905 02:17:42.949074 90901 sgd_solver.cpp:106] Iteration 3530, lr = 0.1
I0905 02:17:49.318797 90901 solver.cpp:228] Iteration 3540, loss = 0.47713
I0905 02:17:49.318845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.47713 (* 1 = 0.47713 loss)
I0905 02:17:49.318859 90901 sgd_solver.cpp:106] Iteration 3540, lr = 0.1
I0905 02:17:54.734696 90901 solver.cpp:228] Iteration 3550, loss = 0.522994
I0905 02:17:54.734741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.522994 (* 1 = 0.522994 loss)
I0905 02:17:54.734755 90901 sgd_solver.cpp:106] Iteration 3550, lr = 0.1
I0905 02:18:00.302953 90901 solver.cpp:228] Iteration 3560, loss = 0.763199
I0905 02:18:00.302995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.763198 (* 1 = 0.763198 loss)
I0905 02:18:00.303009 90901 sgd_solver.cpp:106] Iteration 3560, lr = 0.1
I0905 02:18:05.936094 90901 solver.cpp:228] Iteration 3570, loss = 0.509005
I0905 02:18:05.936228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.509004 (* 1 = 0.509004 loss)
I0905 02:18:05.936257 90901 sgd_solver.cpp:106] Iteration 3570, lr = 0.1
I0905 02:18:12.069349 90901 solver.cpp:228] Iteration 3580, loss = 0.439445
I0905 02:18:12.069416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439445 (* 1 = 0.439445 loss)
I0905 02:18:12.069432 90901 sgd_solver.cpp:106] Iteration 3580, lr = 0.1
I0905 02:18:18.170156 90901 solver.cpp:228] Iteration 3590, loss = 0.519778
I0905 02:18:18.170219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519778 (* 1 = 0.519778 loss)
I0905 02:18:18.170233 90901 sgd_solver.cpp:106] Iteration 3590, lr = 0.1
I0905 02:18:24.584249 90901 solver.cpp:228] Iteration 3600, loss = 0.560453
I0905 02:18:24.584303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.560453 (* 1 = 0.560453 loss)
I0905 02:18:24.584319 90901 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0905 02:18:30.690547 90901 solver.cpp:228] Iteration 3610, loss = 0.4318
I0905 02:18:30.690589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4318 (* 1 = 0.4318 loss)
I0905 02:18:30.690603 90901 sgd_solver.cpp:106] Iteration 3610, lr = 0.1
I0905 02:18:36.766427 90901 solver.cpp:228] Iteration 3620, loss = 0.375481
I0905 02:18:36.766598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375481 (* 1 = 0.375481 loss)
I0905 02:18:36.766625 90901 sgd_solver.cpp:106] Iteration 3620, lr = 0.1
I0905 02:18:42.812791 90901 solver.cpp:228] Iteration 3630, loss = 0.487939
I0905 02:18:42.812855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487939 (* 1 = 0.487939 loss)
I0905 02:18:42.812870 90901 sgd_solver.cpp:106] Iteration 3630, lr = 0.1
I0905 02:18:48.892894 90901 solver.cpp:228] Iteration 3640, loss = 0.473915
I0905 02:18:48.892945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473915 (* 1 = 0.473915 loss)
I0905 02:18:48.892959 90901 sgd_solver.cpp:106] Iteration 3640, lr = 0.1
I0905 02:18:54.960294 90901 solver.cpp:228] Iteration 3650, loss = 0.316511
I0905 02:18:54.960332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316511 (* 1 = 0.316511 loss)
I0905 02:18:54.960345 90901 sgd_solver.cpp:106] Iteration 3650, lr = 0.1
I0905 02:19:01.037952 90901 solver.cpp:228] Iteration 3660, loss = 0.275336
I0905 02:19:01.038003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275335 (* 1 = 0.275335 loss)
I0905 02:19:01.038017 90901 sgd_solver.cpp:106] Iteration 3660, lr = 0.1
I0905 02:19:07.448181 90901 solver.cpp:228] Iteration 3670, loss = 0.409405
I0905 02:19:07.448320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409404 (* 1 = 0.409404 loss)
I0905 02:19:07.448359 90901 sgd_solver.cpp:106] Iteration 3670, lr = 0.1
I0905 02:19:13.247803 90901 solver.cpp:228] Iteration 3680, loss = 0.217462
I0905 02:19:13.247853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217462 (* 1 = 0.217462 loss)
I0905 02:19:13.247870 90901 sgd_solver.cpp:106] Iteration 3680, lr = 0.1
I0905 02:19:19.580380 90901 solver.cpp:228] Iteration 3690, loss = 0.792289
I0905 02:19:19.580440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.792289 (* 1 = 0.792289 loss)
I0905 02:19:19.580454 90901 sgd_solver.cpp:106] Iteration 3690, lr = 0.1
I0905 02:19:25.650981 90901 solver.cpp:228] Iteration 3700, loss = 0.378287
I0905 02:19:25.651065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378286 (* 1 = 0.378286 loss)
I0905 02:19:25.651083 90901 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0905 02:19:31.722894 90901 solver.cpp:228] Iteration 3710, loss = 0.48354
I0905 02:19:31.722972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48354 (* 1 = 0.48354 loss)
I0905 02:19:31.722990 90901 sgd_solver.cpp:106] Iteration 3710, lr = 0.1
I0905 02:19:37.802825 90901 solver.cpp:228] Iteration 3720, loss = 0.508113
I0905 02:19:37.803061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.508112 (* 1 = 0.508112 loss)
I0905 02:19:37.803077 90901 sgd_solver.cpp:106] Iteration 3720, lr = 0.1
I0905 02:19:43.161658 90901 solver.cpp:228] Iteration 3730, loss = 0.482332
I0905 02:19:43.161701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482332 (* 1 = 0.482332 loss)
I0905 02:19:43.161713 90901 sgd_solver.cpp:106] Iteration 3730, lr = 0.1
I0905 02:19:48.473796 90901 solver.cpp:228] Iteration 3740, loss = 0.489928
I0905 02:19:48.473899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489928 (* 1 = 0.489928 loss)
I0905 02:19:48.473927 90901 sgd_solver.cpp:106] Iteration 3740, lr = 0.1
I0905 02:19:54.853842 90901 solver.cpp:228] Iteration 3750, loss = 0.423006
I0905 02:19:54.853895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423005 (* 1 = 0.423005 loss)
I0905 02:19:54.853909 90901 sgd_solver.cpp:106] Iteration 3750, lr = 0.1
I0905 02:20:00.967541 90901 solver.cpp:228] Iteration 3760, loss = 1.102
I0905 02:20:00.967609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.102 (* 1 = 1.102 loss)
I0905 02:20:00.967624 90901 sgd_solver.cpp:106] Iteration 3760, lr = 0.1
I0905 02:20:06.714962 90901 solver.cpp:228] Iteration 3770, loss = 0.552041
I0905 02:20:06.715047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552041 (* 1 = 0.552041 loss)
I0905 02:20:06.715072 90901 sgd_solver.cpp:106] Iteration 3770, lr = 0.1
I0905 02:20:13.108456 90901 solver.cpp:228] Iteration 3780, loss = 0.60281
I0905 02:20:13.108717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.602809 (* 1 = 0.602809 loss)
I0905 02:20:13.108736 90901 sgd_solver.cpp:106] Iteration 3780, lr = 0.1
I0905 02:20:19.218988 90901 solver.cpp:228] Iteration 3790, loss = 0.338283
I0905 02:20:19.219064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338283 (* 1 = 0.338283 loss)
I0905 02:20:19.219080 90901 sgd_solver.cpp:106] Iteration 3790, lr = 0.1
I0905 02:20:25.406898 90901 solver.cpp:228] Iteration 3800, loss = 0.501223
I0905 02:20:25.406962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501223 (* 1 = 0.501223 loss)
I0905 02:20:25.406977 90901 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0905 02:20:31.431704 90901 solver.cpp:228] Iteration 3810, loss = 0.424426
I0905 02:20:31.431752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424426 (* 1 = 0.424426 loss)
I0905 02:20:31.431767 90901 sgd_solver.cpp:106] Iteration 3810, lr = 0.1
I0905 02:20:37.518996 90901 solver.cpp:228] Iteration 3820, loss = 0.608134
I0905 02:20:37.519060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.608133 (* 1 = 0.608133 loss)
I0905 02:20:37.519076 90901 sgd_solver.cpp:106] Iteration 3820, lr = 0.1
I0905 02:20:43.639447 90901 solver.cpp:228] Iteration 3830, loss = 0.496478
I0905 02:20:43.639637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496478 (* 1 = 0.496478 loss)
I0905 02:20:43.639663 90901 sgd_solver.cpp:106] Iteration 3830, lr = 0.1
I0905 02:20:49.537960 90901 solver.cpp:228] Iteration 3840, loss = 0.172567
I0905 02:20:49.538022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172567 (* 1 = 0.172567 loss)
I0905 02:20:49.538036 90901 sgd_solver.cpp:106] Iteration 3840, lr = 0.1
I0905 02:20:56.176028 90901 solver.cpp:228] Iteration 3850, loss = 0.607769
I0905 02:20:56.176090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607768 (* 1 = 0.607768 loss)
I0905 02:20:56.176106 90901 sgd_solver.cpp:106] Iteration 3850, lr = 0.1
I0905 02:21:02.250766 90901 solver.cpp:228] Iteration 3860, loss = 0.228658
I0905 02:21:02.250813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228658 (* 1 = 0.228658 loss)
I0905 02:21:02.250828 90901 sgd_solver.cpp:106] Iteration 3860, lr = 0.1
I0905 02:21:08.315768 90901 solver.cpp:228] Iteration 3870, loss = 0.591666
I0905 02:21:08.315835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.591666 (* 1 = 0.591666 loss)
I0905 02:21:08.315851 90901 sgd_solver.cpp:106] Iteration 3870, lr = 0.1
I0905 02:21:14.500396 90901 solver.cpp:228] Iteration 3880, loss = 0.493631
I0905 02:21:14.500579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.49363 (* 1 = 0.49363 loss)
I0905 02:21:14.500619 90901 sgd_solver.cpp:106] Iteration 3880, lr = 0.1
I0905 02:21:20.778230 90901 solver.cpp:228] Iteration 3890, loss = 0.495512
I0905 02:21:20.778275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.495512 (* 1 = 0.495512 loss)
I0905 02:21:20.778286 90901 sgd_solver.cpp:106] Iteration 3890, lr = 0.1
I0905 02:21:26.599601 90901 solver.cpp:228] Iteration 3900, loss = 0.62267
I0905 02:21:26.599661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.622669 (* 1 = 0.622669 loss)
I0905 02:21:26.599674 90901 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0905 02:21:31.842293 90901 solver.cpp:228] Iteration 3910, loss = 0.521902
I0905 02:21:31.842347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.521901 (* 1 = 0.521901 loss)
I0905 02:21:31.842361 90901 sgd_solver.cpp:106] Iteration 3910, lr = 0.1
I0905 02:21:37.668591 90901 solver.cpp:228] Iteration 3920, loss = 0.402985
I0905 02:21:37.668653 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402984 (* 1 = 0.402984 loss)
I0905 02:21:37.668668 90901 sgd_solver.cpp:106] Iteration 3920, lr = 0.1
I0905 02:21:44.077739 90901 solver.cpp:228] Iteration 3930, loss = 0.416348
I0905 02:21:44.077808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416347 (* 1 = 0.416347 loss)
I0905 02:21:44.077823 90901 sgd_solver.cpp:106] Iteration 3930, lr = 0.1
I0905 02:21:50.107650 90901 solver.cpp:228] Iteration 3940, loss = 0.41877
I0905 02:21:50.107889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418769 (* 1 = 0.418769 loss)
I0905 02:21:50.107911 90901 sgd_solver.cpp:106] Iteration 3940, lr = 0.1
I0905 02:21:56.175041 90901 solver.cpp:228] Iteration 3950, loss = 0.460053
I0905 02:21:56.175094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460053 (* 1 = 0.460053 loss)
I0905 02:21:56.175107 90901 sgd_solver.cpp:106] Iteration 3950, lr = 0.1
I0905 02:22:02.254297 90901 solver.cpp:228] Iteration 3960, loss = 0.554623
I0905 02:22:02.254371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.554622 (* 1 = 0.554622 loss)
I0905 02:22:02.254387 90901 sgd_solver.cpp:106] Iteration 3960, lr = 0.1
I0905 02:22:08.348023 90901 solver.cpp:228] Iteration 3970, loss = 0.596036
I0905 02:22:08.348109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.596035 (* 1 = 0.596035 loss)
I0905 02:22:08.348135 90901 sgd_solver.cpp:106] Iteration 3970, lr = 0.1
I0905 02:22:14.583794 90901 solver.cpp:228] Iteration 3980, loss = 0.27522
I0905 02:22:14.583878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275219 (* 1 = 0.275219 loss)
I0905 02:22:14.583894 90901 sgd_solver.cpp:106] Iteration 3980, lr = 0.1
I0905 02:22:20.445418 90901 solver.cpp:228] Iteration 3990, loss = 0.337907
I0905 02:22:20.445538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337906 (* 1 = 0.337906 loss)
I0905 02:22:20.445571 90901 sgd_solver.cpp:106] Iteration 3990, lr = 0.1
I0905 02:22:26.748385 90901 solver.cpp:337] Iteration 4000, Testing net (#0)
I0905 02:23:08.722867 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.499063
I0905 02:23:08.723063 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.78979 (* 1 = 1.78979 loss)
I0905 02:23:08.941612 90901 solver.cpp:228] Iteration 4000, loss = 0.505415
I0905 02:23:08.941646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505415 (* 1 = 0.505415 loss)
I0905 02:23:08.941663 90901 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0905 02:23:14.726399 90901 solver.cpp:228] Iteration 4010, loss = 0.486205
I0905 02:23:14.726465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486204 (* 1 = 0.486204 loss)
I0905 02:23:14.726480 90901 sgd_solver.cpp:106] Iteration 4010, lr = 0.1
I0905 02:23:19.984462 90901 solver.cpp:228] Iteration 4020, loss = 0.434362
I0905 02:23:19.984532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434362 (* 1 = 0.434362 loss)
I0905 02:23:19.984550 90901 sgd_solver.cpp:106] Iteration 4020, lr = 0.1
I0905 02:23:25.452643 90901 solver.cpp:228] Iteration 4030, loss = 0.480075
I0905 02:23:25.452723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480074 (* 1 = 0.480074 loss)
I0905 02:23:25.452739 90901 sgd_solver.cpp:106] Iteration 4030, lr = 0.1
I0905 02:23:31.801156 90901 solver.cpp:228] Iteration 4040, loss = 0.482479
I0905 02:23:31.801223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482479 (* 1 = 0.482479 loss)
I0905 02:23:31.801239 90901 sgd_solver.cpp:106] Iteration 4040, lr = 0.1
I0905 02:23:37.851953 90901 solver.cpp:228] Iteration 4050, loss = 0.77025
I0905 02:23:37.852012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.770249 (* 1 = 0.770249 loss)
I0905 02:23:37.852028 90901 sgd_solver.cpp:106] Iteration 4050, lr = 0.1
I0905 02:23:43.913184 90901 solver.cpp:228] Iteration 4060, loss = 0.368265
I0905 02:23:43.913434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368265 (* 1 = 0.368265 loss)
I0905 02:23:43.913455 90901 sgd_solver.cpp:106] Iteration 4060, lr = 0.1
I0905 02:23:49.638685 90901 solver.cpp:228] Iteration 4070, loss = 0.644666
I0905 02:23:49.638799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.644666 (* 1 = 0.644666 loss)
I0905 02:23:49.638835 90901 sgd_solver.cpp:106] Iteration 4070, lr = 0.1
I0905 02:23:56.082435 90901 solver.cpp:228] Iteration 4080, loss = 0.701887
I0905 02:23:56.082507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.701887 (* 1 = 0.701887 loss)
I0905 02:23:56.082525 90901 sgd_solver.cpp:106] Iteration 4080, lr = 0.1
I0905 02:24:02.147470 90901 solver.cpp:228] Iteration 4090, loss = 0.462012
I0905 02:24:02.147526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462011 (* 1 = 0.462011 loss)
I0905 02:24:02.147552 90901 sgd_solver.cpp:106] Iteration 4090, lr = 0.1
I0905 02:24:08.542734 90901 solver.cpp:228] Iteration 4100, loss = 0.518046
I0905 02:24:08.542800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.518045 (* 1 = 0.518045 loss)
I0905 02:24:08.542816 90901 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0905 02:24:14.299062 90901 solver.cpp:228] Iteration 4110, loss = 0.357626
I0905 02:24:14.299204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357626 (* 1 = 0.357626 loss)
I0905 02:24:14.299252 90901 sgd_solver.cpp:106] Iteration 4110, lr = 0.1
I0905 02:24:20.666702 90901 solver.cpp:228] Iteration 4120, loss = 0.387044
I0905 02:24:20.666756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387044 (* 1 = 0.387044 loss)
I0905 02:24:20.666770 90901 sgd_solver.cpp:106] Iteration 4120, lr = 0.1
I0905 02:24:26.786976 90901 solver.cpp:228] Iteration 4130, loss = 0.426627
I0905 02:24:26.787047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426626 (* 1 = 0.426626 loss)
I0905 02:24:26.787062 90901 sgd_solver.cpp:106] Iteration 4130, lr = 0.1
I0905 02:24:32.780975 90901 solver.cpp:228] Iteration 4140, loss = 0.384467
I0905 02:24:32.781035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384467 (* 1 = 0.384467 loss)
I0905 02:24:32.781049 90901 sgd_solver.cpp:106] Iteration 4140, lr = 0.1
I0905 02:24:38.924021 90901 solver.cpp:228] Iteration 4150, loss = 0.391223
I0905 02:24:38.924085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391222 (* 1 = 0.391222 loss)
I0905 02:24:38.924100 90901 sgd_solver.cpp:106] Iteration 4150, lr = 0.1
I0905 02:24:44.985450 90901 solver.cpp:228] Iteration 4160, loss = 0.524795
I0905 02:24:44.985620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.524794 (* 1 = 0.524794 loss)
I0905 02:24:44.985661 90901 sgd_solver.cpp:106] Iteration 4160, lr = 0.1
I0905 02:24:51.364562 90901 solver.cpp:228] Iteration 4170, loss = 0.309753
I0905 02:24:51.364611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309752 (* 1 = 0.309752 loss)
I0905 02:24:51.364625 90901 sgd_solver.cpp:106] Iteration 4170, lr = 0.1
I0905 02:24:57.071439 90901 solver.cpp:228] Iteration 4180, loss = 0.493426
I0905 02:24:57.071488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493425 (* 1 = 0.493425 loss)
I0905 02:24:57.071501 90901 sgd_solver.cpp:106] Iteration 4180, lr = 0.1
I0905 02:25:02.741077 90901 solver.cpp:228] Iteration 4190, loss = 0.368716
I0905 02:25:02.741122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368715 (* 1 = 0.368715 loss)
I0905 02:25:02.741133 90901 sgd_solver.cpp:106] Iteration 4190, lr = 0.1
I0905 02:25:08.057138 90901 solver.cpp:228] Iteration 4200, loss = 0.360456
I0905 02:25:08.057207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360456 (* 1 = 0.360456 loss)
I0905 02:25:08.057222 90901 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0905 02:25:14.089287 90901 solver.cpp:228] Iteration 4210, loss = 0.366938
I0905 02:25:14.089349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366937 (* 1 = 0.366937 loss)
I0905 02:25:14.089364 90901 sgd_solver.cpp:106] Iteration 4210, lr = 0.1
I0905 02:25:20.167893 90901 solver.cpp:228] Iteration 4220, loss = 0.337144
I0905 02:25:20.168135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337143 (* 1 = 0.337143 loss)
I0905 02:25:20.168159 90901 sgd_solver.cpp:106] Iteration 4220, lr = 0.1
I0905 02:25:26.245576 90901 solver.cpp:228] Iteration 4230, loss = 0.306992
I0905 02:25:26.245646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306991 (* 1 = 0.306991 loss)
I0905 02:25:26.245662 90901 sgd_solver.cpp:106] Iteration 4230, lr = 0.1
I0905 02:25:32.295079 90901 solver.cpp:228] Iteration 4240, loss = 0.186153
I0905 02:25:32.295142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186153 (* 1 = 0.186153 loss)
I0905 02:25:32.295156 90901 sgd_solver.cpp:106] Iteration 4240, lr = 0.1
I0905 02:25:38.438304 90901 solver.cpp:228] Iteration 4250, loss = 0.290434
I0905 02:25:38.438354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290433 (* 1 = 0.290433 loss)
I0905 02:25:38.438367 90901 sgd_solver.cpp:106] Iteration 4250, lr = 0.1
I0905 02:25:44.709142 90901 solver.cpp:228] Iteration 4260, loss = 0.494798
I0905 02:25:44.709198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.494797 (* 1 = 0.494797 loss)
I0905 02:25:44.709214 90901 sgd_solver.cpp:106] Iteration 4260, lr = 0.1
I0905 02:25:50.808176 90901 solver.cpp:228] Iteration 4270, loss = 0.464505
I0905 02:25:50.808293 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464505 (* 1 = 0.464505 loss)
I0905 02:25:50.808334 90901 sgd_solver.cpp:106] Iteration 4270, lr = 0.1
I0905 02:25:56.862934 90901 solver.cpp:228] Iteration 4280, loss = 0.768493
I0905 02:25:56.862998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.768493 (* 1 = 0.768493 loss)
I0905 02:25:56.863013 90901 sgd_solver.cpp:106] Iteration 4280, lr = 0.1
I0905 02:26:03.207485 90901 solver.cpp:228] Iteration 4290, loss = 0.362849
I0905 02:26:03.207542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362848 (* 1 = 0.362848 loss)
I0905 02:26:03.207557 90901 sgd_solver.cpp:106] Iteration 4290, lr = 0.1
I0905 02:26:08.945297 90901 solver.cpp:228] Iteration 4300, loss = 0.69428
I0905 02:26:08.945365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.694279 (* 1 = 0.694279 loss)
I0905 02:26:08.945380 90901 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0905 02:26:15.318428 90901 solver.cpp:228] Iteration 4310, loss = 0.384542
I0905 02:26:15.318491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384541 (* 1 = 0.384541 loss)
I0905 02:26:15.318511 90901 sgd_solver.cpp:106] Iteration 4310, lr = 0.1
I0905 02:26:21.380175 90901 solver.cpp:228] Iteration 4320, loss = 0.310481
I0905 02:26:21.380332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31048 (* 1 = 0.31048 loss)
I0905 02:26:21.380367 90901 sgd_solver.cpp:106] Iteration 4320, lr = 0.1
I0905 02:26:27.480425 90901 solver.cpp:228] Iteration 4330, loss = 0.480481
I0905 02:26:27.480479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48048 (* 1 = 0.48048 loss)
I0905 02:26:27.480495 90901 sgd_solver.cpp:106] Iteration 4330, lr = 0.1
I0905 02:26:33.573220 90901 solver.cpp:228] Iteration 4340, loss = 0.224999
I0905 02:26:33.573267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224998 (* 1 = 0.224998 loss)
I0905 02:26:33.573282 90901 sgd_solver.cpp:106] Iteration 4340, lr = 0.1
I0905 02:26:39.975126 90901 solver.cpp:228] Iteration 4350, loss = 0.515175
I0905 02:26:39.975169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515174 (* 1 = 0.515174 loss)
I0905 02:26:39.975181 90901 sgd_solver.cpp:106] Iteration 4350, lr = 0.1
I0905 02:26:46.004928 90901 solver.cpp:228] Iteration 4360, loss = 0.477454
I0905 02:26:46.004987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477454 (* 1 = 0.477454 loss)
I0905 02:26:46.005002 90901 sgd_solver.cpp:106] Iteration 4360, lr = 0.1
I0905 02:26:51.610762 90901 solver.cpp:228] Iteration 4370, loss = 0.307317
I0905 02:26:51.611048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307317 (* 1 = 0.307317 loss)
I0905 02:26:51.611064 90901 sgd_solver.cpp:106] Iteration 4370, lr = 0.1
I0905 02:26:56.965034 90901 solver.cpp:228] Iteration 4380, loss = 0.464077
I0905 02:26:56.965101 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464076 (* 1 = 0.464076 loss)
I0905 02:26:56.965118 90901 sgd_solver.cpp:106] Iteration 4380, lr = 0.1
I0905 02:27:03.023331 90901 solver.cpp:228] Iteration 4390, loss = 0.471358
I0905 02:27:03.023399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.471357 (* 1 = 0.471357 loss)
I0905 02:27:03.023414 90901 sgd_solver.cpp:106] Iteration 4390, lr = 0.1
I0905 02:27:09.073364 90901 solver.cpp:228] Iteration 4400, loss = 0.477205
I0905 02:27:09.073424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477204 (* 1 = 0.477204 loss)
I0905 02:27:09.073437 90901 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0905 02:27:15.125061 90901 solver.cpp:228] Iteration 4410, loss = 0.307746
I0905 02:27:15.125108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307745 (* 1 = 0.307745 loss)
I0905 02:27:15.125120 90901 sgd_solver.cpp:106] Iteration 4410, lr = 0.1
I0905 02:27:21.200390 90901 solver.cpp:228] Iteration 4420, loss = 0.423498
I0905 02:27:21.200451 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423498 (* 1 = 0.423498 loss)
I0905 02:27:21.200469 90901 sgd_solver.cpp:106] Iteration 4420, lr = 0.1
I0905 02:27:27.167022 90901 solver.cpp:228] Iteration 4430, loss = 0.470739
I0905 02:27:27.167181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.470739 (* 1 = 0.470739 loss)
I0905 02:27:27.167201 90901 sgd_solver.cpp:106] Iteration 4430, lr = 0.1
I0905 02:27:33.322532 90901 solver.cpp:228] Iteration 4440, loss = 0.633613
I0905 02:27:33.322597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633613 (* 1 = 0.633613 loss)
I0905 02:27:33.322612 90901 sgd_solver.cpp:106] Iteration 4440, lr = 0.1
I0905 02:27:39.463347 90901 solver.cpp:228] Iteration 4450, loss = 0.432216
I0905 02:27:39.463392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432216 (* 1 = 0.432216 loss)
I0905 02:27:39.463405 90901 sgd_solver.cpp:106] Iteration 4450, lr = 0.1
I0905 02:27:45.438959 90901 solver.cpp:228] Iteration 4460, loss = 0.520806
I0905 02:27:45.439007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520806 (* 1 = 0.520806 loss)
I0905 02:27:45.439024 90901 sgd_solver.cpp:106] Iteration 4460, lr = 0.1
I0905 02:27:51.832216 90901 solver.cpp:228] Iteration 4470, loss = 0.205504
I0905 02:27:51.832259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205504 (* 1 = 0.205504 loss)
I0905 02:27:51.832274 90901 sgd_solver.cpp:106] Iteration 4470, lr = 0.1
I0905 02:27:57.887841 90901 solver.cpp:228] Iteration 4480, loss = 0.382768
I0905 02:27:57.888070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382768 (* 1 = 0.382768 loss)
I0905 02:27:57.888103 90901 sgd_solver.cpp:106] Iteration 4480, lr = 0.1
I0905 02:28:03.967319 90901 solver.cpp:228] Iteration 4490, loss = 0.397901
I0905 02:28:03.967394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3979 (* 1 = 0.3979 loss)
I0905 02:28:03.967411 90901 sgd_solver.cpp:106] Iteration 4490, lr = 0.1
I0905 02:28:10.008110 90901 solver.cpp:228] Iteration 4500, loss = 0.475815
I0905 02:28:10.008165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475815 (* 1 = 0.475815 loss)
I0905 02:28:10.008180 90901 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0905 02:28:16.066659 90901 solver.cpp:228] Iteration 4510, loss = 0.448251
I0905 02:28:16.066716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448251 (* 1 = 0.448251 loss)
I0905 02:28:16.066735 90901 sgd_solver.cpp:106] Iteration 4510, lr = 0.1
I0905 02:28:22.133081 90901 solver.cpp:228] Iteration 4520, loss = 0.640119
I0905 02:28:22.133147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.640118 (* 1 = 0.640118 loss)
I0905 02:28:22.133163 90901 sgd_solver.cpp:106] Iteration 4520, lr = 0.1
I0905 02:28:28.181219 90901 solver.cpp:228] Iteration 4530, loss = 0.499879
I0905 02:28:28.181471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.499879 (* 1 = 0.499879 loss)
I0905 02:28:28.181496 90901 sgd_solver.cpp:106] Iteration 4530, lr = 0.1
I0905 02:28:34.285549 90901 solver.cpp:228] Iteration 4540, loss = 0.133392
I0905 02:28:34.285601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133392 (* 1 = 0.133392 loss)
I0905 02:28:34.285620 90901 sgd_solver.cpp:106] Iteration 4540, lr = 0.1
I0905 02:28:39.564292 90901 solver.cpp:228] Iteration 4550, loss = 0.502705
I0905 02:28:39.564348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502705 (* 1 = 0.502705 loss)
I0905 02:28:39.564363 90901 sgd_solver.cpp:106] Iteration 4550, lr = 0.1
I0905 02:28:45.251919 90901 solver.cpp:228] Iteration 4560, loss = 0.608335
I0905 02:28:45.251977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.608334 (* 1 = 0.608334 loss)
I0905 02:28:45.251992 90901 sgd_solver.cpp:106] Iteration 4560, lr = 0.1
I0905 02:28:50.987905 90901 solver.cpp:228] Iteration 4570, loss = 0.282377
I0905 02:28:50.987970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282376 (* 1 = 0.282376 loss)
I0905 02:28:50.987988 90901 sgd_solver.cpp:106] Iteration 4570, lr = 0.1
I0905 02:28:57.374529 90901 solver.cpp:228] Iteration 4580, loss = 0.423811
I0905 02:28:57.374588 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42381 (* 1 = 0.42381 loss)
I0905 02:28:57.374604 90901 sgd_solver.cpp:106] Iteration 4580, lr = 0.1
I0905 02:29:03.461500 90901 solver.cpp:228] Iteration 4590, loss = 0.327157
I0905 02:29:03.461658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327157 (* 1 = 0.327157 loss)
I0905 02:29:03.461714 90901 sgd_solver.cpp:106] Iteration 4590, lr = 0.1
I0905 02:29:09.507195 90901 solver.cpp:228] Iteration 4600, loss = 0.362658
I0905 02:29:09.507266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362657 (* 1 = 0.362657 loss)
I0905 02:29:09.507292 90901 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0905 02:29:15.566184 90901 solver.cpp:228] Iteration 4610, loss = 0.624183
I0905 02:29:15.566248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.624182 (* 1 = 0.624182 loss)
I0905 02:29:15.566263 90901 sgd_solver.cpp:106] Iteration 4610, lr = 0.1
I0905 02:29:21.643723 90901 solver.cpp:228] Iteration 4620, loss = 0.679625
I0905 02:29:21.643785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.679624 (* 1 = 0.679624 loss)
I0905 02:29:21.643800 90901 sgd_solver.cpp:106] Iteration 4620, lr = 0.1
I0905 02:29:27.740175 90901 solver.cpp:228] Iteration 4630, loss = 0.468582
I0905 02:29:27.740245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468581 (* 1 = 0.468581 loss)
I0905 02:29:27.740258 90901 sgd_solver.cpp:106] Iteration 4630, lr = 0.1
I0905 02:29:34.113865 90901 solver.cpp:228] Iteration 4640, loss = 0.408516
I0905 02:29:34.114058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408516 (* 1 = 0.408516 loss)
I0905 02:29:34.114114 90901 sgd_solver.cpp:106] Iteration 4640, lr = 0.1
I0905 02:29:40.162573 90901 solver.cpp:228] Iteration 4650, loss = 0.161999
I0905 02:29:40.162643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161998 (* 1 = 0.161998 loss)
I0905 02:29:40.162660 90901 sgd_solver.cpp:106] Iteration 4650, lr = 0.1
I0905 02:29:46.228644 90901 solver.cpp:228] Iteration 4660, loss = 0.584863
I0905 02:29:46.228713 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.584862 (* 1 = 0.584862 loss)
I0905 02:29:46.228729 90901 sgd_solver.cpp:106] Iteration 4660, lr = 0.1
I0905 02:29:52.301642 90901 solver.cpp:228] Iteration 4670, loss = 0.493133
I0905 02:29:52.301714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493132 (* 1 = 0.493132 loss)
I0905 02:29:52.301730 90901 sgd_solver.cpp:106] Iteration 4670, lr = 0.1
I0905 02:29:58.361101 90901 solver.cpp:228] Iteration 4680, loss = 0.408802
I0905 02:29:58.361166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408801 (* 1 = 0.408801 loss)
I0905 02:29:58.361181 90901 sgd_solver.cpp:106] Iteration 4680, lr = 0.1
I0905 02:30:04.689206 90901 solver.cpp:228] Iteration 4690, loss = 0.232493
I0905 02:30:04.689453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232492 (* 1 = 0.232492 loss)
I0905 02:30:04.689472 90901 sgd_solver.cpp:106] Iteration 4690, lr = 0.1
I0905 02:30:10.549309 90901 solver.cpp:228] Iteration 4700, loss = 0.299132
I0905 02:30:10.549365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299131 (* 1 = 0.299131 loss)
I0905 02:30:10.549379 90901 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0905 02:30:16.958425 90901 solver.cpp:228] Iteration 4710, loss = 0.450184
I0905 02:30:16.958494 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450184 (* 1 = 0.450184 loss)
I0905 02:30:16.958509 90901 sgd_solver.cpp:106] Iteration 4710, lr = 0.1
I0905 02:30:22.924610 90901 solver.cpp:228] Iteration 4720, loss = 0.898304
I0905 02:30:22.924685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.898304 (* 1 = 0.898304 loss)
I0905 02:30:22.924700 90901 sgd_solver.cpp:106] Iteration 4720, lr = 0.1
I0905 02:30:28.247355 90901 solver.cpp:228] Iteration 4730, loss = 0.512736
I0905 02:30:28.247406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.512736 (* 1 = 0.512736 loss)
I0905 02:30:28.247419 90901 sgd_solver.cpp:106] Iteration 4730, lr = 0.1
I0905 02:30:33.911921 90901 solver.cpp:228] Iteration 4740, loss = 0.331967
I0905 02:30:33.911981 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331967 (* 1 = 0.331967 loss)
I0905 02:30:33.911996 90901 sgd_solver.cpp:106] Iteration 4740, lr = 0.1
I0905 02:30:39.991821 90901 solver.cpp:228] Iteration 4750, loss = 0.634731
I0905 02:30:39.992041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.634731 (* 1 = 0.634731 loss)
I0905 02:30:39.992058 90901 sgd_solver.cpp:106] Iteration 4750, lr = 0.1
I0905 02:30:45.006463 90901 solver.cpp:228] Iteration 4760, loss = 0.238936
I0905 02:30:45.006532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238936 (* 1 = 0.238936 loss)
I0905 02:30:45.006547 90901 sgd_solver.cpp:106] Iteration 4760, lr = 0.1
I0905 02:30:50.048629 90901 solver.cpp:228] Iteration 4770, loss = 0.425525
I0905 02:30:50.048708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425524 (* 1 = 0.425524 loss)
I0905 02:30:50.048727 90901 sgd_solver.cpp:106] Iteration 4770, lr = 0.1
I0905 02:30:55.054991 90901 solver.cpp:228] Iteration 4780, loss = 0.439834
I0905 02:30:55.055038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439834 (* 1 = 0.439834 loss)
I0905 02:30:55.055059 90901 sgd_solver.cpp:106] Iteration 4780, lr = 0.1
I0905 02:31:00.094810 90901 solver.cpp:228] Iteration 4790, loss = 0.449454
I0905 02:31:00.094882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449453 (* 1 = 0.449453 loss)
I0905 02:31:00.094898 90901 sgd_solver.cpp:106] Iteration 4790, lr = 0.1
I0905 02:31:04.892149 90901 solver.cpp:337] Iteration 4800, Testing net (#0)
I0905 02:31:39.866113 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.56875
I0905 02:31:39.866288 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.873737 (* 1 = 0.873737 loss)
I0905 02:31:40.082727 90901 solver.cpp:228] Iteration 4800, loss = 0.309239
I0905 02:31:40.082767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309239 (* 1 = 0.309239 loss)
I0905 02:31:40.082783 90901 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0905 02:31:45.119681 90901 solver.cpp:228] Iteration 4810, loss = 0.129271
I0905 02:31:45.119743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129271 (* 1 = 0.129271 loss)
I0905 02:31:45.119756 90901 sgd_solver.cpp:106] Iteration 4810, lr = 0.1
I0905 02:31:50.156874 90901 solver.cpp:228] Iteration 4820, loss = 0.309592
I0905 02:31:50.156919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309592 (* 1 = 0.309592 loss)
I0905 02:31:50.156932 90901 sgd_solver.cpp:106] Iteration 4820, lr = 0.1
I0905 02:31:55.185448 90901 solver.cpp:228] Iteration 4830, loss = 0.358512
I0905 02:31:55.185518 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358511 (* 1 = 0.358511 loss)
I0905 02:31:55.185533 90901 sgd_solver.cpp:106] Iteration 4830, lr = 0.1
I0905 02:32:00.552664 90901 solver.cpp:228] Iteration 4840, loss = 0.467335
I0905 02:32:00.552718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467334 (* 1 = 0.467334 loss)
I0905 02:32:00.552733 90901 sgd_solver.cpp:106] Iteration 4840, lr = 0.1
I0905 02:32:06.318341 90901 solver.cpp:228] Iteration 4850, loss = 0.396611
I0905 02:32:06.318419 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39661 (* 1 = 0.39661 loss)
I0905 02:32:06.318434 90901 sgd_solver.cpp:106] Iteration 4850, lr = 0.1
I0905 02:32:12.723742 90901 solver.cpp:228] Iteration 4860, loss = 0.491623
I0905 02:32:12.723966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491622 (* 1 = 0.491622 loss)
I0905 02:32:12.723995 90901 sgd_solver.cpp:106] Iteration 4860, lr = 0.1
I0905 02:32:18.512950 90901 solver.cpp:228] Iteration 4870, loss = 0.367223
I0905 02:32:18.513017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367222 (* 1 = 0.367222 loss)
I0905 02:32:18.513031 90901 sgd_solver.cpp:106] Iteration 4870, lr = 0.1
I0905 02:32:24.069922 90901 solver.cpp:228] Iteration 4880, loss = 0.31649
I0905 02:32:24.069984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316489 (* 1 = 0.316489 loss)
I0905 02:32:24.069999 90901 sgd_solver.cpp:106] Iteration 4880, lr = 0.1
I0905 02:32:29.849181 90901 solver.cpp:228] Iteration 4890, loss = 0.338343
I0905 02:32:29.849252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338343 (* 1 = 0.338343 loss)
I0905 02:32:29.849267 90901 sgd_solver.cpp:106] Iteration 4890, lr = 0.1
I0905 02:32:35.909271 90901 solver.cpp:228] Iteration 4900, loss = 0.61603
I0905 02:32:35.909312 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.616029 (* 1 = 0.616029 loss)
I0905 02:32:35.909327 90901 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0905 02:32:41.941654 90901 solver.cpp:228] Iteration 4910, loss = 0.679195
I0905 02:32:41.941694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.679194 (* 1 = 0.679194 loss)
I0905 02:32:41.941707 90901 sgd_solver.cpp:106] Iteration 4910, lr = 0.1
I0905 02:32:48.012465 90901 solver.cpp:228] Iteration 4920, loss = 0.260742
I0905 02:32:48.012642 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260742 (* 1 = 0.260742 loss)
I0905 02:32:48.012688 90901 sgd_solver.cpp:106] Iteration 4920, lr = 0.1
I0905 02:32:54.083287 90901 solver.cpp:228] Iteration 4930, loss = 0.597464
I0905 02:32:54.083330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.597464 (* 1 = 0.597464 loss)
I0905 02:32:54.083345 90901 sgd_solver.cpp:106] Iteration 4930, lr = 0.1
I0905 02:33:00.521183 90901 solver.cpp:228] Iteration 4940, loss = 0.302668
I0905 02:33:00.521247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302667 (* 1 = 0.302667 loss)
I0905 02:33:00.521265 90901 sgd_solver.cpp:106] Iteration 4940, lr = 0.1
I0905 02:33:06.240347 90901 solver.cpp:228] Iteration 4950, loss = 0.380338
I0905 02:33:06.240389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380338 (* 1 = 0.380338 loss)
I0905 02:33:06.240404 90901 sgd_solver.cpp:106] Iteration 4950, lr = 0.1
I0905 02:33:12.595655 90901 solver.cpp:228] Iteration 4960, loss = 0.462123
I0905 02:33:12.595693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462122 (* 1 = 0.462122 loss)
I0905 02:33:12.595707 90901 sgd_solver.cpp:106] Iteration 4960, lr = 0.1
I0905 02:33:18.655969 90901 solver.cpp:228] Iteration 4970, loss = 0.297233
I0905 02:33:18.656160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297233 (* 1 = 0.297233 loss)
I0905 02:33:18.656200 90901 sgd_solver.cpp:106] Iteration 4970, lr = 0.1
I0905 02:33:24.721693 90901 solver.cpp:228] Iteration 4980, loss = 0.335813
I0905 02:33:24.721765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335813 (* 1 = 0.335813 loss)
I0905 02:33:24.721781 90901 sgd_solver.cpp:106] Iteration 4980, lr = 0.1
I0905 02:33:30.802060 90901 solver.cpp:228] Iteration 4990, loss = 0.426165
I0905 02:33:30.802109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426164 (* 1 = 0.426164 loss)
I0905 02:33:30.802122 90901 sgd_solver.cpp:106] Iteration 4990, lr = 0.1
I0905 02:33:36.888464 90901 solver.cpp:228] Iteration 5000, loss = 0.651026
I0905 02:33:36.888510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.651026 (* 1 = 0.651026 loss)
I0905 02:33:36.888528 90901 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0905 02:33:42.929095 90901 solver.cpp:228] Iteration 5010, loss = 0.78731
I0905 02:33:42.929144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.78731 (* 1 = 0.78731 loss)
I0905 02:33:42.929157 90901 sgd_solver.cpp:106] Iteration 5010, lr = 0.1
I0905 02:33:48.998675 90901 solver.cpp:228] Iteration 5020, loss = 0.233292
I0905 02:33:48.998926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233291 (* 1 = 0.233291 loss)
I0905 02:33:48.998944 90901 sgd_solver.cpp:106] Iteration 5020, lr = 0.1
I0905 02:33:55.170806 90901 solver.cpp:228] Iteration 5030, loss = 0.523972
I0905 02:33:55.170847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523972 (* 1 = 0.523972 loss)
I0905 02:33:55.170860 90901 sgd_solver.cpp:106] Iteration 5030, lr = 0.1
I0905 02:34:01.160676 90901 solver.cpp:228] Iteration 5040, loss = 0.31307
I0905 02:34:01.160717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31307 (* 1 = 0.31307 loss)
I0905 02:34:01.160730 90901 sgd_solver.cpp:106] Iteration 5040, lr = 0.1
I0905 02:34:06.980572 90901 solver.cpp:228] Iteration 5050, loss = 0.532669
I0905 02:34:06.980623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.532668 (* 1 = 0.532668 loss)
I0905 02:34:06.980636 90901 sgd_solver.cpp:106] Iteration 5050, lr = 0.1
I0905 02:34:12.529359 90901 solver.cpp:228] Iteration 5060, loss = 0.438099
I0905 02:34:12.529408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438099 (* 1 = 0.438099 loss)
I0905 02:34:12.529422 90901 sgd_solver.cpp:106] Iteration 5060, lr = 0.1
I0905 02:34:18.395112 90901 solver.cpp:228] Iteration 5070, loss = 0.482111
I0905 02:34:18.395156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482111 (* 1 = 0.482111 loss)
I0905 02:34:18.395169 90901 sgd_solver.cpp:106] Iteration 5070, lr = 0.1
I0905 02:34:24.458562 90901 solver.cpp:228] Iteration 5080, loss = 0.287762
I0905 02:34:24.458771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287762 (* 1 = 0.287762 loss)
I0905 02:34:24.458806 90901 sgd_solver.cpp:106] Iteration 5080, lr = 0.1
I0905 02:34:30.839926 90901 solver.cpp:228] Iteration 5090, loss = 0.767019
I0905 02:34:30.839979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.767018 (* 1 = 0.767018 loss)
I0905 02:34:30.839993 90901 sgd_solver.cpp:106] Iteration 5090, lr = 0.1
I0905 02:34:36.577682 90901 solver.cpp:228] Iteration 5100, loss = 0.207246
I0905 02:34:36.577719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207245 (* 1 = 0.207245 loss)
I0905 02:34:36.577733 90901 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0905 02:34:42.660090 90901 solver.cpp:228] Iteration 5110, loss = 0.420072
I0905 02:34:42.660145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.420071 (* 1 = 0.420071 loss)
I0905 02:34:42.660158 90901 sgd_solver.cpp:106] Iteration 5110, lr = 0.1
I0905 02:34:48.695389 90901 solver.cpp:228] Iteration 5120, loss = 0.790968
I0905 02:34:48.695447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.790967 (* 1 = 0.790967 loss)
I0905 02:34:48.695463 90901 sgd_solver.cpp:106] Iteration 5120, lr = 0.1
I0905 02:34:54.748487 90901 solver.cpp:228] Iteration 5130, loss = 0.513822
I0905 02:34:54.748716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513822 (* 1 = 0.513822 loss)
I0905 02:34:54.748736 90901 sgd_solver.cpp:106] Iteration 5130, lr = 0.1
I0905 02:35:01.124128 90901 solver.cpp:228] Iteration 5140, loss = 0.614303
I0905 02:35:01.124174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.614303 (* 1 = 0.614303 loss)
I0905 02:35:01.124187 90901 sgd_solver.cpp:106] Iteration 5140, lr = 0.1
I0905 02:35:07.130826 90901 solver.cpp:228] Iteration 5150, loss = 0.457761
I0905 02:35:07.130882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457761 (* 1 = 0.457761 loss)
I0905 02:35:07.130894 90901 sgd_solver.cpp:106] Iteration 5150, lr = 0.1
I0905 02:35:13.196645 90901 solver.cpp:228] Iteration 5160, loss = 0.530624
I0905 02:35:13.196692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.530624 (* 1 = 0.530624 loss)
I0905 02:35:13.196707 90901 sgd_solver.cpp:106] Iteration 5160, lr = 0.1
I0905 02:35:18.914535 90901 solver.cpp:228] Iteration 5170, loss = 0.558441
I0905 02:35:18.914588 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55844 (* 1 = 0.55844 loss)
I0905 02:35:18.914602 90901 sgd_solver.cpp:106] Iteration 5170, lr = 0.1
I0905 02:35:25.306722 90901 solver.cpp:228] Iteration 5180, loss = 0.479005
I0905 02:35:25.306911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.479005 (* 1 = 0.479005 loss)
I0905 02:35:25.306929 90901 sgd_solver.cpp:106] Iteration 5180, lr = 0.1
I0905 02:35:31.331920 90901 solver.cpp:228] Iteration 5190, loss = 0.612471
I0905 02:35:31.331974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.612471 (* 1 = 0.612471 loss)
I0905 02:35:31.331986 90901 sgd_solver.cpp:106] Iteration 5190, lr = 0.1
I0905 02:35:37.374408 90901 solver.cpp:228] Iteration 5200, loss = 0.384641
I0905 02:35:37.374486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384641 (* 1 = 0.384641 loss)
I0905 02:35:37.374505 90901 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0905 02:35:43.465127 90901 solver.cpp:228] Iteration 5210, loss = 0.363509
I0905 02:35:43.465169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363509 (* 1 = 0.363509 loss)
I0905 02:35:43.465184 90901 sgd_solver.cpp:106] Iteration 5210, lr = 0.1
I0905 02:35:49.533825 90901 solver.cpp:228] Iteration 5220, loss = 0.241071
I0905 02:35:49.533900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241071 (* 1 = 0.241071 loss)
I0905 02:35:49.533916 90901 sgd_solver.cpp:106] Iteration 5220, lr = 0.1
I0905 02:35:55.326705 90901 solver.cpp:228] Iteration 5230, loss = 0.460741
I0905 02:35:55.326974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460741 (* 1 = 0.460741 loss)
I0905 02:35:55.326992 90901 sgd_solver.cpp:106] Iteration 5230, lr = 0.1
I0905 02:36:00.571063 90901 solver.cpp:228] Iteration 5240, loss = 0.431788
I0905 02:36:00.571110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.431788 (* 1 = 0.431788 loss)
I0905 02:36:00.571123 90901 sgd_solver.cpp:106] Iteration 5240, lr = 0.1
I0905 02:36:06.198961 90901 solver.cpp:228] Iteration 5250, loss = 0.567827
I0905 02:36:06.199012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.567827 (* 1 = 0.567827 loss)
I0905 02:36:06.199025 90901 sgd_solver.cpp:106] Iteration 5250, lr = 0.1
I0905 02:36:12.312337 90901 solver.cpp:228] Iteration 5260, loss = 0.393984
I0905 02:36:12.312383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393983 (* 1 = 0.393983 loss)
I0905 02:36:12.312396 90901 sgd_solver.cpp:106] Iteration 5260, lr = 0.1
I0905 02:36:18.382488 90901 solver.cpp:228] Iteration 5270, loss = 0.304722
I0905 02:36:18.382534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304722 (* 1 = 0.304722 loss)
I0905 02:36:18.382545 90901 sgd_solver.cpp:106] Iteration 5270, lr = 0.1
I0905 02:36:24.746253 90901 solver.cpp:228] Iteration 5280, loss = 0.624201
I0905 02:36:24.746299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.624201 (* 1 = 0.624201 loss)
I0905 02:36:24.746314 90901 sgd_solver.cpp:106] Iteration 5280, lr = 0.1
I0905 02:36:30.455569 90901 solver.cpp:228] Iteration 5290, loss = 0.215131
I0905 02:36:30.455751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21513 (* 1 = 0.21513 loss)
I0905 02:36:30.455778 90901 sgd_solver.cpp:106] Iteration 5290, lr = 0.1
I0905 02:36:36.541966 90901 solver.cpp:228] Iteration 5300, loss = 0.303962
I0905 02:36:36.542026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303962 (* 1 = 0.303962 loss)
I0905 02:36:36.542042 90901 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0905 02:36:43.035830 90901 solver.cpp:228] Iteration 5310, loss = 0.457523
I0905 02:36:43.035868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457523 (* 1 = 0.457523 loss)
I0905 02:36:43.035881 90901 sgd_solver.cpp:106] Iteration 5310, lr = 0.1
I0905 02:36:49.343224 90901 solver.cpp:228] Iteration 5320, loss = 0.459718
I0905 02:36:49.343269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459718 (* 1 = 0.459718 loss)
I0905 02:36:49.343284 90901 sgd_solver.cpp:106] Iteration 5320, lr = 0.1
I0905 02:36:55.071300 90901 solver.cpp:228] Iteration 5330, loss = 0.516086
I0905 02:36:55.071341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.516086 (* 1 = 0.516086 loss)
I0905 02:36:55.071353 90901 sgd_solver.cpp:106] Iteration 5330, lr = 0.1
I0905 02:37:01.129727 90901 solver.cpp:228] Iteration 5340, loss = 0.184221
I0905 02:37:01.129894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184221 (* 1 = 0.184221 loss)
I0905 02:37:01.129935 90901 sgd_solver.cpp:106] Iteration 5340, lr = 0.1
I0905 02:37:07.195994 90901 solver.cpp:228] Iteration 5350, loss = 0.500686
I0905 02:37:07.196043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.500686 (* 1 = 0.500686 loss)
I0905 02:37:07.196058 90901 sgd_solver.cpp:106] Iteration 5350, lr = 0.1
I0905 02:37:13.574040 90901 solver.cpp:228] Iteration 5360, loss = 0.351791
I0905 02:37:13.574089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351791 (* 1 = 0.351791 loss)
I0905 02:37:13.574103 90901 sgd_solver.cpp:106] Iteration 5360, lr = 0.1
I0905 02:37:19.632387 90901 solver.cpp:228] Iteration 5370, loss = 0.395254
I0905 02:37:19.632432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395254 (* 1 = 0.395254 loss)
I0905 02:37:19.632444 90901 sgd_solver.cpp:106] Iteration 5370, lr = 0.1
I0905 02:37:25.414558 90901 solver.cpp:228] Iteration 5380, loss = 0.496294
I0905 02:37:25.414611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496294 (* 1 = 0.496294 loss)
I0905 02:37:25.414625 90901 sgd_solver.cpp:106] Iteration 5380, lr = 0.1
I0905 02:37:31.444906 90901 solver.cpp:228] Iteration 5390, loss = 0.408387
I0905 02:37:31.445163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408386 (* 1 = 0.408386 loss)
I0905 02:37:31.445178 90901 sgd_solver.cpp:106] Iteration 5390, lr = 0.1
I0905 02:37:37.840016 90901 solver.cpp:228] Iteration 5400, loss = 0.218126
I0905 02:37:37.840072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218126 (* 1 = 0.218126 loss)
I0905 02:37:37.840090 90901 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0905 02:37:43.208240 90901 solver.cpp:228] Iteration 5410, loss = 0.414193
I0905 02:37:43.208282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414193 (* 1 = 0.414193 loss)
I0905 02:37:43.208295 90901 sgd_solver.cpp:106] Iteration 5410, lr = 0.1
I0905 02:37:48.730605 90901 solver.cpp:228] Iteration 5420, loss = 0.459413
I0905 02:37:48.730679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459412 (* 1 = 0.459412 loss)
I0905 02:37:48.730702 90901 sgd_solver.cpp:106] Iteration 5420, lr = 0.1
I0905 02:37:54.845268 90901 solver.cpp:228] Iteration 5430, loss = 0.552514
I0905 02:37:54.845310 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552514 (* 1 = 0.552514 loss)
I0905 02:37:54.845324 90901 sgd_solver.cpp:106] Iteration 5430, lr = 0.1
I0905 02:38:00.924000 90901 solver.cpp:228] Iteration 5440, loss = 0.296178
I0905 02:38:00.924053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296178 (* 1 = 0.296178 loss)
I0905 02:38:00.924068 90901 sgd_solver.cpp:106] Iteration 5440, lr = 0.1
I0905 02:38:06.963016 90901 solver.cpp:228] Iteration 5450, loss = 0.603882
I0905 02:38:06.963223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.603881 (* 1 = 0.603881 loss)
I0905 02:38:06.963260 90901 sgd_solver.cpp:106] Iteration 5450, lr = 0.1
I0905 02:38:13.314215 90901 solver.cpp:228] Iteration 5460, loss = 0.546778
I0905 02:38:13.314260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546778 (* 1 = 0.546778 loss)
I0905 02:38:13.314272 90901 sgd_solver.cpp:106] Iteration 5460, lr = 0.1
I0905 02:38:19.358067 90901 solver.cpp:228] Iteration 5470, loss = 0.510561
I0905 02:38:19.358122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.510561 (* 1 = 0.510561 loss)
I0905 02:38:19.358135 90901 sgd_solver.cpp:106] Iteration 5470, lr = 0.1
I0905 02:38:25.398978 90901 solver.cpp:228] Iteration 5480, loss = 0.637773
I0905 02:38:25.399037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.637772 (* 1 = 0.637772 loss)
I0905 02:38:25.399052 90901 sgd_solver.cpp:106] Iteration 5480, lr = 0.1
I0905 02:38:31.158143 90901 solver.cpp:228] Iteration 5490, loss = 0.633309
I0905 02:38:31.158201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633309 (* 1 = 0.633309 loss)
I0905 02:38:31.158217 90901 sgd_solver.cpp:106] Iteration 5490, lr = 0.1
I0905 02:38:37.582844 90901 solver.cpp:228] Iteration 5500, loss = 0.515673
I0905 02:38:37.582998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515673 (* 1 = 0.515673 loss)
I0905 02:38:37.583041 90901 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0905 02:38:43.620476 90901 solver.cpp:228] Iteration 5510, loss = 0.520898
I0905 02:38:43.620520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520897 (* 1 = 0.520897 loss)
I0905 02:38:43.620534 90901 sgd_solver.cpp:106] Iteration 5510, lr = 0.1
I0905 02:38:49.664566 90901 solver.cpp:228] Iteration 5520, loss = 0.5593
I0905 02:38:49.664618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.5593 (* 1 = 0.5593 loss)
I0905 02:38:49.664633 90901 sgd_solver.cpp:106] Iteration 5520, lr = 0.1
I0905 02:38:55.661355 90901 solver.cpp:228] Iteration 5530, loss = 0.529404
I0905 02:38:55.661411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529404 (* 1 = 0.529404 loss)
I0905 02:38:55.661427 90901 sgd_solver.cpp:106] Iteration 5530, lr = 0.1
I0905 02:39:01.731559 90901 solver.cpp:228] Iteration 5540, loss = 0.51797
I0905 02:39:01.731608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.517969 (* 1 = 0.517969 loss)
I0905 02:39:01.731623 90901 sgd_solver.cpp:106] Iteration 5540, lr = 0.1
I0905 02:39:07.758287 90901 solver.cpp:228] Iteration 5550, loss = 0.322041
I0905 02:39:07.758440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322041 (* 1 = 0.322041 loss)
I0905 02:39:07.758486 90901 sgd_solver.cpp:106] Iteration 5550, lr = 0.1
I0905 02:39:14.099660 90901 solver.cpp:228] Iteration 5560, loss = 0.696989
I0905 02:39:14.099732 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696989 (* 1 = 0.696989 loss)
I0905 02:39:14.099748 90901 sgd_solver.cpp:106] Iteration 5560, lr = 0.1
I0905 02:39:20.129793 90901 solver.cpp:228] Iteration 5570, loss = 0.791839
I0905 02:39:20.129848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.791838 (* 1 = 0.791838 loss)
I0905 02:39:20.129859 90901 sgd_solver.cpp:106] Iteration 5570, lr = 0.1
I0905 02:39:26.138270 90901 solver.cpp:228] Iteration 5580, loss = 0.432282
I0905 02:39:26.138332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432282 (* 1 = 0.432282 loss)
I0905 02:39:26.138347 90901 sgd_solver.cpp:106] Iteration 5580, lr = 0.1
I0905 02:39:31.900563 90901 solver.cpp:228] Iteration 5590, loss = 0.317737
I0905 02:39:31.900624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317737 (* 1 = 0.317737 loss)
I0905 02:39:31.900638 90901 sgd_solver.cpp:106] Iteration 5590, lr = 0.1
I0905 02:39:36.941558 90901 solver.cpp:337] Iteration 5600, Testing net (#0)
I0905 02:40:19.271765 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.492813
I0905 02:40:19.271951 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.12673 (* 1 = 1.12673 loss)
I0905 02:40:19.488327 90901 solver.cpp:228] Iteration 5600, loss = 0.431011
I0905 02:40:19.488369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43101 (* 1 = 0.43101 loss)
I0905 02:40:19.488386 90901 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0905 02:40:25.576315 90901 solver.cpp:228] Iteration 5610, loss = 0.248566
I0905 02:40:25.576370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248565 (* 1 = 0.248565 loss)
I0905 02:40:25.576386 90901 sgd_solver.cpp:106] Iteration 5610, lr = 0.1
I0905 02:40:31.622599 90901 solver.cpp:228] Iteration 5620, loss = 0.257638
I0905 02:40:31.622720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257638 (* 1 = 0.257638 loss)
I0905 02:40:31.622738 90901 sgd_solver.cpp:106] Iteration 5620, lr = 0.1
I0905 02:40:37.347039 90901 solver.cpp:228] Iteration 5630, loss = 0.537376
I0905 02:40:37.347091 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.537376 (* 1 = 0.537376 loss)
I0905 02:40:37.347106 90901 sgd_solver.cpp:106] Iteration 5630, lr = 0.1
I0905 02:40:43.736749 90901 solver.cpp:228] Iteration 5640, loss = 0.428432
I0905 02:40:43.736793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428432 (* 1 = 0.428432 loss)
I0905 02:40:43.736807 90901 sgd_solver.cpp:106] Iteration 5640, lr = 0.1
I0905 02:40:49.795886 90901 solver.cpp:228] Iteration 5650, loss = 0.467118
I0905 02:40:49.796077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467118 (* 1 = 0.467118 loss)
I0905 02:40:49.796109 90901 sgd_solver.cpp:106] Iteration 5650, lr = 0.1
I0905 02:40:55.865591 90901 solver.cpp:228] Iteration 5660, loss = 0.550939
I0905 02:40:55.865638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.550939 (* 1 = 0.550939 loss)
I0905 02:40:55.865653 90901 sgd_solver.cpp:106] Iteration 5660, lr = 0.1
I0905 02:41:01.912130 90901 solver.cpp:228] Iteration 5670, loss = 0.551662
I0905 02:41:01.912179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.551662 (* 1 = 0.551662 loss)
I0905 02:41:01.912191 90901 sgd_solver.cpp:106] Iteration 5670, lr = 0.1
I0905 02:41:08.125314 90901 solver.cpp:228] Iteration 5680, loss = 0.455852
I0905 02:41:08.125356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455852 (* 1 = 0.455852 loss)
I0905 02:41:08.125370 90901 sgd_solver.cpp:106] Iteration 5680, lr = 0.1
I0905 02:41:14.325320 90901 solver.cpp:228] Iteration 5690, loss = 0.209385
I0905 02:41:14.325366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209385 (* 1 = 0.209385 loss)
I0905 02:41:14.325378 90901 sgd_solver.cpp:106] Iteration 5690, lr = 0.1
I0905 02:41:20.093454 90901 solver.cpp:228] Iteration 5700, loss = 0.249297
I0905 02:41:20.093595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249297 (* 1 = 0.249297 loss)
I0905 02:41:20.093636 90901 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0905 02:41:25.632134 90901 solver.cpp:228] Iteration 5710, loss = 0.360171
I0905 02:41:25.632184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360171 (* 1 = 0.360171 loss)
I0905 02:41:25.632195 90901 sgd_solver.cpp:106] Iteration 5710, lr = 0.1
I0905 02:41:31.500681 90901 solver.cpp:228] Iteration 5720, loss = 0.478539
I0905 02:41:31.500725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478539 (* 1 = 0.478539 loss)
I0905 02:41:31.500737 90901 sgd_solver.cpp:106] Iteration 5720, lr = 0.1
I0905 02:41:37.262987 90901 solver.cpp:228] Iteration 5730, loss = 0.443163
I0905 02:41:37.263023 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443163 (* 1 = 0.443163 loss)
I0905 02:41:37.263036 90901 sgd_solver.cpp:106] Iteration 5730, lr = 0.1
I0905 02:41:43.652495 90901 solver.cpp:228] Iteration 5740, loss = 0.560352
I0905 02:41:43.652544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.560352 (* 1 = 0.560352 loss)
I0905 02:41:43.652557 90901 sgd_solver.cpp:106] Iteration 5740, lr = 0.1
I0905 02:41:49.682267 90901 solver.cpp:228] Iteration 5750, loss = 0.435415
I0905 02:41:49.682313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435415 (* 1 = 0.435415 loss)
I0905 02:41:49.682329 90901 sgd_solver.cpp:106] Iteration 5750, lr = 0.1
I0905 02:41:55.737939 90901 solver.cpp:228] Iteration 5760, loss = 0.440153
I0905 02:41:55.738134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440153 (* 1 = 0.440153 loss)
I0905 02:41:55.738149 90901 sgd_solver.cpp:106] Iteration 5760, lr = 0.1
I0905 02:42:01.775200 90901 solver.cpp:228] Iteration 5770, loss = 0.329447
I0905 02:42:01.775246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329447 (* 1 = 0.329447 loss)
I0905 02:42:01.775261 90901 sgd_solver.cpp:106] Iteration 5770, lr = 0.1
I0905 02:42:07.855480 90901 solver.cpp:228] Iteration 5780, loss = 0.477731
I0905 02:42:07.855528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477731 (* 1 = 0.477731 loss)
I0905 02:42:07.855542 90901 sgd_solver.cpp:106] Iteration 5780, lr = 0.1
I0905 02:42:13.914839 90901 solver.cpp:228] Iteration 5790, loss = 0.700459
I0905 02:42:13.914883 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.700459 (* 1 = 0.700459 loss)
I0905 02:42:13.914901 90901 sgd_solver.cpp:106] Iteration 5790, lr = 0.1
I0905 02:42:19.986982 90901 solver.cpp:228] Iteration 5800, loss = 0.543919
I0905 02:42:19.987016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543919 (* 1 = 0.543919 loss)
I0905 02:42:19.987028 90901 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0905 02:42:26.037945 90901 solver.cpp:228] Iteration 5810, loss = 0.230952
I0905 02:42:26.038103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230952 (* 1 = 0.230952 loss)
I0905 02:42:26.038130 90901 sgd_solver.cpp:106] Iteration 5810, lr = 0.1
I0905 02:42:32.099139 90901 solver.cpp:228] Iteration 5820, loss = 0.602314
I0905 02:42:32.099198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.602313 (* 1 = 0.602313 loss)
I0905 02:42:32.099215 90901 sgd_solver.cpp:106] Iteration 5820, lr = 0.1
I0905 02:42:38.454310 90901 solver.cpp:228] Iteration 5830, loss = 0.40716
I0905 02:42:38.454362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40716 (* 1 = 0.40716 loss)
I0905 02:42:38.454375 90901 sgd_solver.cpp:106] Iteration 5830, lr = 0.1
I0905 02:42:44.510020 90901 solver.cpp:228] Iteration 5840, loss = 0.493192
I0905 02:42:44.510067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493191 (* 1 = 0.493191 loss)
I0905 02:42:44.510082 90901 sgd_solver.cpp:106] Iteration 5840, lr = 0.1
I0905 02:42:50.533967 90901 solver.cpp:228] Iteration 5850, loss = 0.418217
I0905 02:42:50.534008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418217 (* 1 = 0.418217 loss)
I0905 02:42:50.534019 90901 sgd_solver.cpp:106] Iteration 5850, lr = 0.1
I0905 02:42:56.793185 90901 solver.cpp:228] Iteration 5860, loss = 0.628176
I0905 02:42:56.793316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.628176 (* 1 = 0.628176 loss)
I0905 02:42:56.793345 90901 sgd_solver.cpp:106] Iteration 5860, lr = 0.1
I0905 02:43:02.762349 90901 solver.cpp:228] Iteration 5870, loss = 0.444345
I0905 02:43:02.762398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444345 (* 1 = 0.444345 loss)
I0905 02:43:02.762413 90901 sgd_solver.cpp:106] Iteration 5870, lr = 0.1
I0905 02:43:08.737649 90901 solver.cpp:228] Iteration 5880, loss = 0.429362
I0905 02:43:08.737706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429362 (* 1 = 0.429362 loss)
I0905 02:43:08.737720 90901 sgd_solver.cpp:106] Iteration 5880, lr = 0.1
I0905 02:43:13.982075 90901 solver.cpp:228] Iteration 5890, loss = 0.33898
I0905 02:43:13.982120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33898 (* 1 = 0.33898 loss)
I0905 02:43:13.982133 90901 sgd_solver.cpp:106] Iteration 5890, lr = 0.1
I0905 02:43:19.914652 90901 solver.cpp:228] Iteration 5900, loss = 0.24806
I0905 02:43:19.914696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24806 (* 1 = 0.24806 loss)
I0905 02:43:19.914710 90901 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0905 02:43:25.952496 90901 solver.cpp:228] Iteration 5910, loss = 0.601826
I0905 02:43:25.952538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.601826 (* 1 = 0.601826 loss)
I0905 02:43:25.952550 90901 sgd_solver.cpp:106] Iteration 5910, lr = 0.1
I0905 02:43:31.999091 90901 solver.cpp:228] Iteration 5920, loss = 0.381527
I0905 02:43:31.999320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381527 (* 1 = 0.381527 loss)
I0905 02:43:31.999338 90901 sgd_solver.cpp:106] Iteration 5920, lr = 0.1
I0905 02:43:38.042799 90901 solver.cpp:228] Iteration 5930, loss = 0.638743
I0905 02:43:38.042850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.638742 (* 1 = 0.638742 loss)
I0905 02:43:38.042862 90901 sgd_solver.cpp:106] Iteration 5930, lr = 0.1
I0905 02:43:44.124655 90901 solver.cpp:228] Iteration 5940, loss = 0.419082
I0905 02:43:44.124701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419082 (* 1 = 0.419082 loss)
I0905 02:43:44.124713 90901 sgd_solver.cpp:106] Iteration 5940, lr = 0.1
I0905 02:43:50.183470 90901 solver.cpp:228] Iteration 5950, loss = 0.299924
I0905 02:43:50.183531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299924 (* 1 = 0.299924 loss)
I0905 02:43:50.183543 90901 sgd_solver.cpp:106] Iteration 5950, lr = 0.1
I0905 02:43:56.230482 90901 solver.cpp:228] Iteration 5960, loss = 0.406364
I0905 02:43:56.230543 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406364 (* 1 = 0.406364 loss)
I0905 02:43:56.230571 90901 sgd_solver.cpp:106] Iteration 5960, lr = 0.1
I0905 02:44:02.297561 90901 solver.cpp:228] Iteration 5970, loss = 0.55077
I0905 02:44:02.297731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.550769 (* 1 = 0.550769 loss)
I0905 02:44:02.297777 90901 sgd_solver.cpp:106] Iteration 5970, lr = 0.1
I0905 02:44:08.420744 90901 solver.cpp:228] Iteration 5980, loss = 0.407821
I0905 02:44:08.420792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407821 (* 1 = 0.407821 loss)
I0905 02:44:08.420805 90901 sgd_solver.cpp:106] Iteration 5980, lr = 0.1
I0905 02:44:14.449666 90901 solver.cpp:228] Iteration 5990, loss = 0.538645
I0905 02:44:14.449709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.538645 (* 1 = 0.538645 loss)
I0905 02:44:14.449725 90901 sgd_solver.cpp:106] Iteration 5990, lr = 0.1
I0905 02:44:20.773473 90901 solver.cpp:228] Iteration 6000, loss = 0.285315
I0905 02:44:20.773526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285315 (* 1 = 0.285315 loss)
I0905 02:44:20.773541 90901 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0905 02:44:26.853816 90901 solver.cpp:228] Iteration 6010, loss = 0.401018
I0905 02:44:26.853869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401018 (* 1 = 0.401018 loss)
I0905 02:44:26.853884 90901 sgd_solver.cpp:106] Iteration 6010, lr = 0.1
I0905 02:44:32.892901 90901 solver.cpp:228] Iteration 6020, loss = 0.316952
I0905 02:44:32.893074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316952 (* 1 = 0.316952 loss)
I0905 02:44:32.893096 90901 sgd_solver.cpp:106] Iteration 6020, lr = 0.1
I0905 02:44:38.953253 90901 solver.cpp:228] Iteration 6030, loss = 0.473288
I0905 02:44:38.953305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473288 (* 1 = 0.473288 loss)
I0905 02:44:38.953318 90901 sgd_solver.cpp:106] Iteration 6030, lr = 0.1
I0905 02:44:45.320647 90901 solver.cpp:228] Iteration 6040, loss = 0.334732
I0905 02:44:45.320690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334732 (* 1 = 0.334732 loss)
I0905 02:44:45.320706 90901 sgd_solver.cpp:106] Iteration 6040, lr = 0.1
I0905 02:44:51.037374 90901 solver.cpp:228] Iteration 6050, loss = 0.3026
I0905 02:44:51.037415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3026 (* 1 = 0.3026 loss)
I0905 02:44:51.037428 90901 sgd_solver.cpp:106] Iteration 6050, lr = 0.1
I0905 02:44:56.857147 90901 solver.cpp:228] Iteration 6060, loss = 0.224561
I0905 02:44:56.857199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224561 (* 1 = 0.224561 loss)
I0905 02:44:56.857213 90901 sgd_solver.cpp:106] Iteration 6060, lr = 0.1
I0905 02:45:02.406803 90901 solver.cpp:228] Iteration 6070, loss = 0.324045
I0905 02:45:02.406853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324045 (* 1 = 0.324045 loss)
I0905 02:45:02.406867 90901 sgd_solver.cpp:106] Iteration 6070, lr = 0.1
I0905 02:45:08.268056 90901 solver.cpp:228] Iteration 6080, loss = 1.20738
I0905 02:45:08.268323 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.20738 (* 1 = 1.20738 loss)
I0905 02:45:08.268340 90901 sgd_solver.cpp:106] Iteration 6080, lr = 0.1
I0905 02:45:14.335866 90901 solver.cpp:228] Iteration 6090, loss = 0.410011
I0905 02:45:14.335911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410011 (* 1 = 0.410011 loss)
I0905 02:45:14.335927 90901 sgd_solver.cpp:106] Iteration 6090, lr = 0.1
I0905 02:45:20.109390 90901 solver.cpp:228] Iteration 6100, loss = 0.513484
I0905 02:45:20.109434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513483 (* 1 = 0.513483 loss)
I0905 02:45:20.109447 90901 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0905 02:45:26.170769 90901 solver.cpp:228] Iteration 6110, loss = 0.455904
I0905 02:45:26.170817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455904 (* 1 = 0.455904 loss)
I0905 02:45:26.170830 90901 sgd_solver.cpp:106] Iteration 6110, lr = 0.1
I0905 02:45:32.248805 90901 solver.cpp:228] Iteration 6120, loss = 0.489564
I0905 02:45:32.248870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489564 (* 1 = 0.489564 loss)
I0905 02:45:32.248886 90901 sgd_solver.cpp:106] Iteration 6120, lr = 0.1
I0905 02:45:38.194584 90901 solver.cpp:228] Iteration 6130, loss = 0.534957
I0905 02:45:38.194643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.534957 (* 1 = 0.534957 loss)
I0905 02:45:38.194659 90901 sgd_solver.cpp:106] Iteration 6130, lr = 0.1
I0905 02:45:44.006654 90901 solver.cpp:228] Iteration 6140, loss = 0.482886
I0905 02:45:44.006858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482885 (* 1 = 0.482885 loss)
I0905 02:45:44.006875 90901 sgd_solver.cpp:106] Iteration 6140, lr = 0.1
I0905 02:45:50.090059 90901 solver.cpp:228] Iteration 6150, loss = 0.298583
I0905 02:45:50.090106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298583 (* 1 = 0.298583 loss)
I0905 02:45:50.090118 90901 sgd_solver.cpp:106] Iteration 6150, lr = 0.1
I0905 02:45:56.438541 90901 solver.cpp:228] Iteration 6160, loss = 0.404993
I0905 02:45:56.438585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404992 (* 1 = 0.404992 loss)
I0905 02:45:56.438598 90901 sgd_solver.cpp:106] Iteration 6160, lr = 0.1
I0905 02:46:02.483070 90901 solver.cpp:228] Iteration 6170, loss = 0.364084
I0905 02:46:02.483116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364084 (* 1 = 0.364084 loss)
I0905 02:46:02.483130 90901 sgd_solver.cpp:106] Iteration 6170, lr = 0.1
I0905 02:46:08.543263 90901 solver.cpp:228] Iteration 6180, loss = 0.601314
I0905 02:46:08.543318 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.601313 (* 1 = 0.601313 loss)
I0905 02:46:08.543332 90901 sgd_solver.cpp:106] Iteration 6180, lr = 0.1
I0905 02:46:14.599964 90901 solver.cpp:228] Iteration 6190, loss = 0.63868
I0905 02:46:14.600152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.63868 (* 1 = 0.63868 loss)
I0905 02:46:14.600195 90901 sgd_solver.cpp:106] Iteration 6190, lr = 0.1
I0905 02:46:20.684629 90901 solver.cpp:228] Iteration 6200, loss = 0.276901
I0905 02:46:20.684700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276901 (* 1 = 0.276901 loss)
I0905 02:46:20.684716 90901 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0905 02:46:26.749995 90901 solver.cpp:228] Iteration 6210, loss = 0.201275
I0905 02:46:26.750043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201275 (* 1 = 0.201275 loss)
I0905 02:46:26.750056 90901 sgd_solver.cpp:106] Iteration 6210, lr = 0.1
I0905 02:46:32.517254 90901 solver.cpp:228] Iteration 6220, loss = 0.269542
I0905 02:46:32.517313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269541 (* 1 = 0.269541 loss)
I0905 02:46:32.517328 90901 sgd_solver.cpp:106] Iteration 6220, lr = 0.1
I0905 02:46:38.905946 90901 solver.cpp:228] Iteration 6230, loss = 0.251746
I0905 02:46:38.905988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251745 (* 1 = 0.251745 loss)
I0905 02:46:38.906002 90901 sgd_solver.cpp:106] Iteration 6230, lr = 0.1
I0905 02:46:44.592983 90901 solver.cpp:228] Iteration 6240, loss = 0.26805
I0905 02:46:44.593030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26805 (* 1 = 0.26805 loss)
I0905 02:46:44.593045 90901 sgd_solver.cpp:106] Iteration 6240, lr = 0.1
I0905 02:46:49.837652 90901 solver.cpp:228] Iteration 6250, loss = 0.269427
I0905 02:46:49.837815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269426 (* 1 = 0.269426 loss)
I0905 02:46:49.837875 90901 sgd_solver.cpp:106] Iteration 6250, lr = 0.1
I0905 02:46:55.465580 90901 solver.cpp:228] Iteration 6260, loss = 0.43969
I0905 02:46:55.465631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439689 (* 1 = 0.439689 loss)
I0905 02:46:55.465646 90901 sgd_solver.cpp:106] Iteration 6260, lr = 0.1
I0905 02:47:01.934806 90901 solver.cpp:228] Iteration 6270, loss = 0.328474
I0905 02:47:01.934849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328474 (* 1 = 0.328474 loss)
I0905 02:47:01.934864 90901 sgd_solver.cpp:106] Iteration 6270, lr = 0.1
I0905 02:47:08.016072 90901 solver.cpp:228] Iteration 6280, loss = 0.417638
I0905 02:47:08.016122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417638 (* 1 = 0.417638 loss)
I0905 02:47:08.016142 90901 sgd_solver.cpp:106] Iteration 6280, lr = 0.1
I0905 02:47:13.973366 90901 solver.cpp:228] Iteration 6290, loss = 0.331172
I0905 02:47:13.973417 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331172 (* 1 = 0.331172 loss)
I0905 02:47:13.973429 90901 sgd_solver.cpp:106] Iteration 6290, lr = 0.1
I0905 02:47:20.130765 90901 solver.cpp:228] Iteration 6300, loss = 0.925761
I0905 02:47:20.130918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.92576 (* 1 = 0.92576 loss)
I0905 02:47:20.130949 90901 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0905 02:47:26.202277 90901 solver.cpp:228] Iteration 6310, loss = 0.402323
I0905 02:47:26.202332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402323 (* 1 = 0.402323 loss)
I0905 02:47:26.202349 90901 sgd_solver.cpp:106] Iteration 6310, lr = 0.1
I0905 02:47:32.614089 90901 solver.cpp:228] Iteration 6320, loss = 0.536084
I0905 02:47:32.614140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.536083 (* 1 = 0.536083 loss)
I0905 02:47:32.614153 90901 sgd_solver.cpp:106] Iteration 6320, lr = 0.1
I0905 02:47:38.683346 90901 solver.cpp:228] Iteration 6330, loss = 0.375885
I0905 02:47:38.683408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375884 (* 1 = 0.375884 loss)
I0905 02:47:38.683423 90901 sgd_solver.cpp:106] Iteration 6330, lr = 0.1
I0905 02:47:44.403609 90901 solver.cpp:228] Iteration 6340, loss = 0.551222
I0905 02:47:44.403655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.551221 (* 1 = 0.551221 loss)
I0905 02:47:44.403671 90901 sgd_solver.cpp:106] Iteration 6340, lr = 0.1
I0905 02:47:50.687525 90901 solver.cpp:228] Iteration 6350, loss = 0.472783
I0905 02:47:50.687757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472782 (* 1 = 0.472782 loss)
I0905 02:47:50.687784 90901 sgd_solver.cpp:106] Iteration 6350, lr = 0.1
I0905 02:47:56.539433 90901 solver.cpp:228] Iteration 6360, loss = 0.461705
I0905 02:47:56.539494 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461705 (* 1 = 0.461705 loss)
I0905 02:47:56.539510 90901 sgd_solver.cpp:106] Iteration 6360, lr = 0.1
I0905 02:48:02.298280 90901 solver.cpp:228] Iteration 6370, loss = 0.348397
I0905 02:48:02.298358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348397 (* 1 = 0.348397 loss)
I0905 02:48:02.298388 90901 sgd_solver.cpp:106] Iteration 6370, lr = 0.1
I0905 02:48:08.758708 90901 solver.cpp:228] Iteration 6380, loss = 0.577338
I0905 02:48:08.758760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.577337 (* 1 = 0.577337 loss)
I0905 02:48:08.758774 90901 sgd_solver.cpp:106] Iteration 6380, lr = 0.1
I0905 02:48:14.827241 90901 solver.cpp:228] Iteration 6390, loss = 0.291275
I0905 02:48:14.827286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291274 (* 1 = 0.291274 loss)
I0905 02:48:14.827299 90901 sgd_solver.cpp:106] Iteration 6390, lr = 0.1
I0905 02:48:20.968542 90901 solver.cpp:337] Iteration 6400, Testing net (#0)
I0905 02:48:56.747741 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.4975
I0905 02:48:56.747915 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.969906 (* 1 = 0.969906 loss)
I0905 02:48:56.965200 90901 solver.cpp:228] Iteration 6400, loss = 0.465088
I0905 02:48:56.965230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465088 (* 1 = 0.465088 loss)
I0905 02:48:56.965247 90901 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0905 02:49:02.025153 90901 solver.cpp:228] Iteration 6410, loss = 0.572608
I0905 02:49:02.025197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572608 (* 1 = 0.572608 loss)
I0905 02:49:02.025208 90901 sgd_solver.cpp:106] Iteration 6410, lr = 0.1
I0905 02:49:07.071326 90901 solver.cpp:228] Iteration 6420, loss = 0.284519
I0905 02:49:07.071389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284519 (* 1 = 0.284519 loss)
I0905 02:49:07.071404 90901 sgd_solver.cpp:106] Iteration 6420, lr = 0.1
I0905 02:49:12.121044 90901 solver.cpp:228] Iteration 6430, loss = 0.345888
I0905 02:49:12.121088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345888 (* 1 = 0.345888 loss)
I0905 02:49:12.121100 90901 sgd_solver.cpp:106] Iteration 6430, lr = 0.1
I0905 02:49:17.122601 90901 solver.cpp:228] Iteration 6440, loss = 0.71264
I0905 02:49:17.122675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.712639 (* 1 = 0.712639 loss)
I0905 02:49:17.122690 90901 sgd_solver.cpp:106] Iteration 6440, lr = 0.1
I0905 02:49:22.185138 90901 solver.cpp:228] Iteration 6450, loss = 0.436659
I0905 02:49:22.185183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436658 (* 1 = 0.436658 loss)
I0905 02:49:22.185194 90901 sgd_solver.cpp:106] Iteration 6450, lr = 0.1
I0905 02:49:27.220122 90901 solver.cpp:228] Iteration 6460, loss = 0.880763
I0905 02:49:27.220240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.880763 (* 1 = 0.880763 loss)
I0905 02:49:27.220268 90901 sgd_solver.cpp:106] Iteration 6460, lr = 0.1
I0905 02:49:32.280704 90901 solver.cpp:228] Iteration 6470, loss = 0.367716
I0905 02:49:32.280750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367716 (* 1 = 0.367716 loss)
I0905 02:49:32.280764 90901 sgd_solver.cpp:106] Iteration 6470, lr = 0.1
I0905 02:49:37.329191 90901 solver.cpp:228] Iteration 6480, loss = 0.197164
I0905 02:49:37.329238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197164 (* 1 = 0.197164 loss)
I0905 02:49:37.329252 90901 sgd_solver.cpp:106] Iteration 6480, lr = 0.1
I0905 02:49:42.348471 90901 solver.cpp:228] Iteration 6490, loss = 0.626189
I0905 02:49:42.348516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.626188 (* 1 = 0.626188 loss)
I0905 02:49:42.348527 90901 sgd_solver.cpp:106] Iteration 6490, lr = 0.1
I0905 02:49:47.418465 90901 solver.cpp:228] Iteration 6500, loss = 0.426302
I0905 02:49:47.418509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426302 (* 1 = 0.426302 loss)
I0905 02:49:47.418522 90901 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0905 02:49:52.451364 90901 solver.cpp:228] Iteration 6510, loss = 0.351815
I0905 02:49:52.451412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351814 (* 1 = 0.351814 loss)
I0905 02:49:52.451426 90901 sgd_solver.cpp:106] Iteration 6510, lr = 0.1
I0905 02:49:58.190376 90901 solver.cpp:228] Iteration 6520, loss = 0.32398
I0905 02:49:58.190574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32398 (* 1 = 0.32398 loss)
I0905 02:49:58.190595 90901 sgd_solver.cpp:106] Iteration 6520, lr = 0.1
I0905 02:50:04.247234 90901 solver.cpp:228] Iteration 6530, loss = 0.684373
I0905 02:50:04.247305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.684372 (* 1 = 0.684372 loss)
I0905 02:50:04.247320 90901 sgd_solver.cpp:106] Iteration 6530, lr = 0.1
I0905 02:50:10.320513 90901 solver.cpp:228] Iteration 6540, loss = 0.313701
I0905 02:50:10.320566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313701 (* 1 = 0.313701 loss)
I0905 02:50:10.320582 90901 sgd_solver.cpp:106] Iteration 6540, lr = 0.1
I0905 02:50:16.376031 90901 solver.cpp:228] Iteration 6550, loss = 0.341232
I0905 02:50:16.376070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341232 (* 1 = 0.341232 loss)
I0905 02:50:16.376080 90901 sgd_solver.cpp:106] Iteration 6550, lr = 0.1
I0905 02:50:22.063753 90901 solver.cpp:228] Iteration 6560, loss = 0.621706
I0905 02:50:22.063809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.621706 (* 1 = 0.621706 loss)
I0905 02:50:22.063823 90901 sgd_solver.cpp:106] Iteration 6560, lr = 0.1
I0905 02:50:27.609848 90901 solver.cpp:228] Iteration 6570, loss = 0.277048
I0905 02:50:27.609912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277048 (* 1 = 0.277048 loss)
I0905 02:50:27.609927 90901 sgd_solver.cpp:106] Iteration 6570, lr = 0.1
I0905 02:50:33.306094 90901 solver.cpp:228] Iteration 6580, loss = 0.516756
I0905 02:50:33.306288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.516755 (* 1 = 0.516755 loss)
I0905 02:50:33.306324 90901 sgd_solver.cpp:106] Iteration 6580, lr = 0.1
I0905 02:50:39.385473 90901 solver.cpp:228] Iteration 6590, loss = 0.379176
I0905 02:50:39.385545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379176 (* 1 = 0.379176 loss)
I0905 02:50:39.385560 90901 sgd_solver.cpp:106] Iteration 6590, lr = 0.1
I0905 02:50:45.441380 90901 solver.cpp:228] Iteration 6600, loss = 0.532934
I0905 02:50:45.441411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.532933 (* 1 = 0.532933 loss)
I0905 02:50:45.441421 90901 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0905 02:50:51.556764 90901 solver.cpp:228] Iteration 6610, loss = 0.469913
I0905 02:50:51.556823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469912 (* 1 = 0.469912 loss)
I0905 02:50:51.556836 90901 sgd_solver.cpp:106] Iteration 6610, lr = 0.1
I0905 02:50:57.565412 90901 solver.cpp:228] Iteration 6620, loss = 0.613117
I0905 02:50:57.565491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.613117 (* 1 = 0.613117 loss)
I0905 02:50:57.565508 90901 sgd_solver.cpp:106] Iteration 6620, lr = 0.1
I0905 02:51:03.651507 90901 solver.cpp:228] Iteration 6630, loss = 0.203214
I0905 02:51:03.651767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203214 (* 1 = 0.203214 loss)
I0905 02:51:03.651780 90901 sgd_solver.cpp:106] Iteration 6630, lr = 0.1
I0905 02:51:10.054621 90901 solver.cpp:228] Iteration 6640, loss = 0.667872
I0905 02:51:10.054699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.667871 (* 1 = 0.667871 loss)
I0905 02:51:10.054715 90901 sgd_solver.cpp:106] Iteration 6640, lr = 0.1
I0905 02:51:16.094465 90901 solver.cpp:228] Iteration 6650, loss = 0.307801
I0905 02:51:16.094521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307801 (* 1 = 0.307801 loss)
I0905 02:51:16.094533 90901 sgd_solver.cpp:106] Iteration 6650, lr = 0.1
I0905 02:51:22.168753 90901 solver.cpp:228] Iteration 6660, loss = 0.513583
I0905 02:51:22.168814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513583 (* 1 = 0.513583 loss)
I0905 02:51:22.168830 90901 sgd_solver.cpp:106] Iteration 6660, lr = 0.1
I0905 02:51:28.429004 90901 solver.cpp:228] Iteration 6670, loss = 0.311642
I0905 02:51:28.429067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311642 (* 1 = 0.311642 loss)
I0905 02:51:28.429083 90901 sgd_solver.cpp:106] Iteration 6670, lr = 0.1
I0905 02:51:34.310921 90901 solver.cpp:228] Iteration 6680, loss = 0.327662
I0905 02:51:34.311071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327662 (* 1 = 0.327662 loss)
I0905 02:51:34.311110 90901 sgd_solver.cpp:106] Iteration 6680, lr = 0.1
I0905 02:51:40.416492 90901 solver.cpp:228] Iteration 6690, loss = 0.778941
I0905 02:51:40.416535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.77894 (* 1 = 0.77894 loss)
I0905 02:51:40.416548 90901 sgd_solver.cpp:106] Iteration 6690, lr = 0.1
I0905 02:51:46.460959 90901 solver.cpp:228] Iteration 6700, loss = 0.48532
I0905 02:51:46.461010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48532 (* 1 = 0.48532 loss)
I0905 02:51:46.461024 90901 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0905 02:51:52.528446 90901 solver.cpp:228] Iteration 6710, loss = 0.585984
I0905 02:51:52.528493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.585984 (* 1 = 0.585984 loss)
I0905 02:51:52.528506 90901 sgd_solver.cpp:106] Iteration 6710, lr = 0.1
I0905 02:51:58.660285 90901 solver.cpp:228] Iteration 6720, loss = 0.514824
I0905 02:51:58.660326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514823 (* 1 = 0.514823 loss)
I0905 02:51:58.660339 90901 sgd_solver.cpp:106] Iteration 6720, lr = 0.1
I0905 02:52:04.839196 90901 solver.cpp:228] Iteration 6730, loss = 0.424376
I0905 02:52:04.839366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424375 (* 1 = 0.424375 loss)
I0905 02:52:04.839407 90901 sgd_solver.cpp:106] Iteration 6730, lr = 0.1
I0905 02:52:10.237010 90901 solver.cpp:228] Iteration 6740, loss = 0.537614
I0905 02:52:10.237058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.537614 (* 1 = 0.537614 loss)
I0905 02:52:10.237071 90901 sgd_solver.cpp:106] Iteration 6740, lr = 0.1
I0905 02:52:15.705541 90901 solver.cpp:228] Iteration 6750, loss = 0.355321
I0905 02:52:15.705580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355321 (* 1 = 0.355321 loss)
I0905 02:52:15.705592 90901 sgd_solver.cpp:106] Iteration 6750, lr = 0.1
I0905 02:52:21.925462 90901 solver.cpp:228] Iteration 6760, loss = 0.472353
I0905 02:52:21.925501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472353 (* 1 = 0.472353 loss)
I0905 02:52:21.925516 90901 sgd_solver.cpp:106] Iteration 6760, lr = 0.1
I0905 02:52:27.788012 90901 solver.cpp:228] Iteration 6770, loss = 0.476386
I0905 02:52:27.788066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476386 (* 1 = 0.476386 loss)
I0905 02:52:27.788079 90901 sgd_solver.cpp:106] Iteration 6770, lr = 0.1
I0905 02:52:34.153390 90901 solver.cpp:228] Iteration 6780, loss = 0.255137
I0905 02:52:34.153437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255137 (* 1 = 0.255137 loss)
I0905 02:52:34.153455 90901 sgd_solver.cpp:106] Iteration 6780, lr = 0.1
I0905 02:52:40.196276 90901 solver.cpp:228] Iteration 6790, loss = 0.530785
I0905 02:52:40.196460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.530785 (* 1 = 0.530785 loss)
I0905 02:52:40.196475 90901 sgd_solver.cpp:106] Iteration 6790, lr = 0.1
I0905 02:52:46.253556 90901 solver.cpp:228] Iteration 6800, loss = 0.666877
I0905 02:52:46.253615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.666877 (* 1 = 0.666877 loss)
I0905 02:52:46.253629 90901 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0905 02:52:52.321607 90901 solver.cpp:228] Iteration 6810, loss = 0.41914
I0905 02:52:52.321663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41914 (* 1 = 0.41914 loss)
I0905 02:52:52.321677 90901 sgd_solver.cpp:106] Iteration 6810, lr = 0.1
I0905 02:52:58.380873 90901 solver.cpp:228] Iteration 6820, loss = 0.313544
I0905 02:52:58.380919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313544 (* 1 = 0.313544 loss)
I0905 02:52:58.380931 90901 sgd_solver.cpp:106] Iteration 6820, lr = 0.1
I0905 02:53:04.691311 90901 solver.cpp:228] Iteration 6830, loss = 0.2398
I0905 02:53:04.691352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239799 (* 1 = 0.239799 loss)
I0905 02:53:04.691370 90901 sgd_solver.cpp:106] Iteration 6830, lr = 0.1
I0905 02:53:10.808631 90901 solver.cpp:228] Iteration 6840, loss = 0.711156
I0905 02:53:10.808799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.711156 (* 1 = 0.711156 loss)
I0905 02:53:10.808821 90901 sgd_solver.cpp:106] Iteration 6840, lr = 0.1
I0905 02:53:16.588701 90901 solver.cpp:228] Iteration 6850, loss = 0.422604
I0905 02:53:16.588752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422604 (* 1 = 0.422604 loss)
I0905 02:53:16.588768 90901 sgd_solver.cpp:106] Iteration 6850, lr = 0.1
I0905 02:53:22.937727 90901 solver.cpp:228] Iteration 6860, loss = 0.255129
I0905 02:53:22.937772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255129 (* 1 = 0.255129 loss)
I0905 02:53:22.937788 90901 sgd_solver.cpp:106] Iteration 6860, lr = 0.1
I0905 02:53:28.953182 90901 solver.cpp:228] Iteration 6870, loss = 0.340454
I0905 02:53:28.953238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340454 (* 1 = 0.340454 loss)
I0905 02:53:28.953256 90901 sgd_solver.cpp:106] Iteration 6870, lr = 0.1
I0905 02:53:34.689821 90901 solver.cpp:228] Iteration 6880, loss = 0.227234
I0905 02:53:34.689873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227234 (* 1 = 0.227234 loss)
I0905 02:53:34.689887 90901 sgd_solver.cpp:106] Iteration 6880, lr = 0.1
I0905 02:53:41.144287 90901 solver.cpp:228] Iteration 6890, loss = 0.240371
I0905 02:53:41.144472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240371 (* 1 = 0.240371 loss)
I0905 02:53:41.144510 90901 sgd_solver.cpp:106] Iteration 6890, lr = 0.1
I0905 02:53:47.202033 90901 solver.cpp:228] Iteration 6900, loss = 0.429575
I0905 02:53:47.202072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429575 (* 1 = 0.429575 loss)
I0905 02:53:47.202085 90901 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0905 02:53:53.086638 90901 solver.cpp:228] Iteration 6910, loss = 0.34699
I0905 02:53:53.086694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34699 (* 1 = 0.34699 loss)
I0905 02:53:53.086709 90901 sgd_solver.cpp:106] Iteration 6910, lr = 0.1
I0905 02:53:58.633858 90901 solver.cpp:228] Iteration 6920, loss = 0.39078
I0905 02:53:58.633903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39078 (* 1 = 0.39078 loss)
I0905 02:53:58.633916 90901 sgd_solver.cpp:106] Iteration 6920, lr = 0.1
I0905 02:54:04.155391 90901 solver.cpp:228] Iteration 6930, loss = 0.747032
I0905 02:54:04.155455 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.747031 (* 1 = 0.747031 loss)
I0905 02:54:04.155472 90901 sgd_solver.cpp:106] Iteration 6930, lr = 0.1
I0905 02:54:10.562849 90901 solver.cpp:228] Iteration 6940, loss = 0.538745
I0905 02:54:10.562899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.538744 (* 1 = 0.538744 loss)
I0905 02:54:10.562913 90901 sgd_solver.cpp:106] Iteration 6940, lr = 0.1
I0905 02:54:16.306080 90901 solver.cpp:228] Iteration 6950, loss = 0.633984
I0905 02:54:16.306298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633984 (* 1 = 0.633984 loss)
I0905 02:54:16.306324 90901 sgd_solver.cpp:106] Iteration 6950, lr = 0.1
I0905 02:54:22.393296 90901 solver.cpp:228] Iteration 6960, loss = 0.387475
I0905 02:54:22.393338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387475 (* 1 = 0.387475 loss)
I0905 02:54:22.393352 90901 sgd_solver.cpp:106] Iteration 6960, lr = 0.1
I0905 02:54:28.398671 90901 solver.cpp:228] Iteration 6970, loss = 0.428138
I0905 02:54:28.398732 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428138 (* 1 = 0.428138 loss)
I0905 02:54:28.398757 90901 sgd_solver.cpp:106] Iteration 6970, lr = 0.1
I0905 02:54:34.494441 90901 solver.cpp:228] Iteration 6980, loss = 0.479135
I0905 02:54:34.494498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.479135 (* 1 = 0.479135 loss)
I0905 02:54:34.494511 90901 sgd_solver.cpp:106] Iteration 6980, lr = 0.1
I0905 02:54:40.562718 90901 solver.cpp:228] Iteration 6990, loss = 0.431731
I0905 02:54:40.562765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.431731 (* 1 = 0.431731 loss)
I0905 02:54:40.562779 90901 sgd_solver.cpp:106] Iteration 6990, lr = 0.1
I0905 02:54:46.639281 90901 solver.cpp:228] Iteration 7000, loss = 0.584094
I0905 02:54:46.639470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.584094 (* 1 = 0.584094 loss)
I0905 02:54:46.639497 90901 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0905 02:54:52.690212 90901 solver.cpp:228] Iteration 7010, loss = 0.413901
I0905 02:54:52.690260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413901 (* 1 = 0.413901 loss)
I0905 02:54:52.690274 90901 sgd_solver.cpp:106] Iteration 7010, lr = 0.1
I0905 02:54:59.091915 90901 solver.cpp:228] Iteration 7020, loss = 0.474142
I0905 02:54:59.091965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.474141 (* 1 = 0.474141 loss)
I0905 02:54:59.091982 90901 sgd_solver.cpp:106] Iteration 7020, lr = 0.1
I0905 02:55:05.133033 90901 solver.cpp:228] Iteration 7030, loss = 0.541083
I0905 02:55:05.133105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541083 (* 1 = 0.541083 loss)
I0905 02:55:05.133121 90901 sgd_solver.cpp:106] Iteration 7030, lr = 0.1
I0905 02:55:10.858594 90901 solver.cpp:228] Iteration 7040, loss = 0.523569
I0905 02:55:10.858674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523569 (* 1 = 0.523569 loss)
I0905 02:55:10.858690 90901 sgd_solver.cpp:106] Iteration 7040, lr = 0.1
I0905 02:55:17.225170 90901 solver.cpp:228] Iteration 7050, loss = 0.676703
I0905 02:55:17.225332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.676703 (* 1 = 0.676703 loss)
I0905 02:55:17.225380 90901 sgd_solver.cpp:106] Iteration 7050, lr = 0.1
I0905 02:55:23.459291 90901 solver.cpp:228] Iteration 7060, loss = 0.47535
I0905 02:55:23.459337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.47535 (* 1 = 0.47535 loss)
I0905 02:55:23.459349 90901 sgd_solver.cpp:106] Iteration 7060, lr = 0.1
I0905 02:55:29.391726 90901 solver.cpp:228] Iteration 7070, loss = 0.326919
I0905 02:55:29.391770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326919 (* 1 = 0.326919 loss)
I0905 02:55:29.391784 90901 sgd_solver.cpp:106] Iteration 7070, lr = 0.1
I0905 02:55:35.775243 90901 solver.cpp:228] Iteration 7080, loss = 0.30159
I0905 02:55:35.775285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30159 (* 1 = 0.30159 loss)
I0905 02:55:35.775297 90901 sgd_solver.cpp:106] Iteration 7080, lr = 0.1
I0905 02:55:41.598121 90901 solver.cpp:228] Iteration 7090, loss = 0.457447
I0905 02:55:41.598167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457447 (* 1 = 0.457447 loss)
I0905 02:55:41.598179 90901 sgd_solver.cpp:106] Iteration 7090, lr = 0.1
I0905 02:55:46.851608 90901 solver.cpp:228] Iteration 7100, loss = 0.765406
I0905 02:55:46.851662 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.765406 (* 1 = 0.765406 loss)
I0905 02:55:46.851677 90901 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0905 02:55:52.740908 90901 solver.cpp:228] Iteration 7110, loss = 0.357494
I0905 02:55:52.741065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357493 (* 1 = 0.357493 loss)
I0905 02:55:52.741078 90901 sgd_solver.cpp:106] Iteration 7110, lr = 0.1
I0905 02:55:58.781431 90901 solver.cpp:228] Iteration 7120, loss = 0.491124
I0905 02:55:58.781466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491124 (* 1 = 0.491124 loss)
I0905 02:55:58.781481 90901 sgd_solver.cpp:106] Iteration 7120, lr = 0.1
I0905 02:56:04.838516 90901 solver.cpp:228] Iteration 7130, loss = 0.561806
I0905 02:56:04.838570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.561806 (* 1 = 0.561806 loss)
I0905 02:56:04.838583 90901 sgd_solver.cpp:106] Iteration 7130, lr = 0.1
I0905 02:56:10.895158 90901 solver.cpp:228] Iteration 7140, loss = 0.421437
I0905 02:56:10.895196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421437 (* 1 = 0.421437 loss)
I0905 02:56:10.895210 90901 sgd_solver.cpp:106] Iteration 7140, lr = 0.1
I0905 02:56:16.975950 90901 solver.cpp:228] Iteration 7150, loss = 0.446696
I0905 02:56:16.976011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446696 (* 1 = 0.446696 loss)
I0905 02:56:16.976030 90901 sgd_solver.cpp:106] Iteration 7150, lr = 0.1
I0905 02:56:23.041074 90901 solver.cpp:228] Iteration 7160, loss = 0.174668
I0905 02:56:23.041229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174668 (* 1 = 0.174668 loss)
I0905 02:56:23.041259 90901 sgd_solver.cpp:106] Iteration 7160, lr = 0.1
I0905 02:56:29.169337 90901 solver.cpp:228] Iteration 7170, loss = 0.553593
I0905 02:56:29.169381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.553593 (* 1 = 0.553593 loss)
I0905 02:56:29.169394 90901 sgd_solver.cpp:106] Iteration 7170, lr = 0.1
I0905 02:56:35.178689 90901 solver.cpp:228] Iteration 7180, loss = 0.346131
I0905 02:56:35.178732 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346131 (* 1 = 0.346131 loss)
I0905 02:56:35.178750 90901 sgd_solver.cpp:106] Iteration 7180, lr = 0.1
I0905 02:56:41.556915 90901 solver.cpp:228] Iteration 7190, loss = 0.589993
I0905 02:56:41.556963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.589993 (* 1 = 0.589993 loss)
I0905 02:56:41.556977 90901 sgd_solver.cpp:106] Iteration 7190, lr = 0.1
I0905 02:56:47.423792 90901 solver.cpp:337] Iteration 7200, Testing net (#0)
I0905 02:57:29.253494 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.5075
I0905 02:57:29.253696 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.13137 (* 1 = 1.13137 loss)
I0905 02:57:29.454748 90901 solver.cpp:228] Iteration 7200, loss = 0.479661
I0905 02:57:29.454788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.479661 (* 1 = 0.479661 loss)
I0905 02:57:29.454807 90901 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0905 02:57:34.712419 90901 solver.cpp:228] Iteration 7210, loss = 0.535154
I0905 02:57:34.712467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535154 (* 1 = 0.535154 loss)
I0905 02:57:34.712481 90901 sgd_solver.cpp:106] Iteration 7210, lr = 0.1
I0905 02:57:40.726050 90901 solver.cpp:228] Iteration 7220, loss = 0.32926
I0905 02:57:40.726099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32926 (* 1 = 0.32926 loss)
I0905 02:57:40.726114 90901 sgd_solver.cpp:106] Iteration 7220, lr = 0.1
I0905 02:57:46.941038 90901 solver.cpp:228] Iteration 7230, loss = 0.229459
I0905 02:57:46.941088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229459 (* 1 = 0.229459 loss)
I0905 02:57:46.941102 90901 sgd_solver.cpp:106] Iteration 7230, lr = 0.1
I0905 02:57:52.839931 90901 solver.cpp:228] Iteration 7240, loss = 0.501833
I0905 02:57:52.839979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501832 (* 1 = 0.501832 loss)
I0905 02:57:52.839993 90901 sgd_solver.cpp:106] Iteration 7240, lr = 0.1
I0905 02:57:59.276589 90901 solver.cpp:228] Iteration 7250, loss = 0.360184
I0905 02:57:59.276789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360184 (* 1 = 0.360184 loss)
I0905 02:57:59.276818 90901 sgd_solver.cpp:106] Iteration 7250, lr = 0.1
I0905 02:58:05.307915 90901 solver.cpp:228] Iteration 7260, loss = 0.643352
I0905 02:58:05.307961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.643352 (* 1 = 0.643352 loss)
I0905 02:58:05.307976 90901 sgd_solver.cpp:106] Iteration 7260, lr = 0.1
I0905 02:58:11.671589 90901 solver.cpp:228] Iteration 7270, loss = 0.328442
I0905 02:58:11.671627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328442 (* 1 = 0.328442 loss)
I0905 02:58:11.671639 90901 sgd_solver.cpp:106] Iteration 7270, lr = 0.1
I0905 02:58:17.452589 90901 solver.cpp:228] Iteration 7280, loss = 0.40357
I0905 02:58:17.452635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403569 (* 1 = 0.403569 loss)
I0905 02:58:17.452648 90901 sgd_solver.cpp:106] Iteration 7280, lr = 0.1
I0905 02:58:23.283541 90901 solver.cpp:228] Iteration 7290, loss = 0.547081
I0905 02:58:23.283591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547081 (* 1 = 0.547081 loss)
I0905 02:58:23.283603 90901 sgd_solver.cpp:106] Iteration 7290, lr = 0.1
I0905 02:58:29.603078 90901 solver.cpp:228] Iteration 7300, loss = 0.824576
I0905 02:58:29.603236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.824576 (* 1 = 0.824576 loss)
I0905 02:58:29.603265 90901 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0905 02:58:35.982085 90901 solver.cpp:228] Iteration 7310, loss = 0.442444
I0905 02:58:35.982132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442444 (* 1 = 0.442444 loss)
I0905 02:58:35.982146 90901 sgd_solver.cpp:106] Iteration 7310, lr = 0.1
I0905 02:58:42.030221 90901 solver.cpp:228] Iteration 7320, loss = 0.51586
I0905 02:58:42.030263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.51586 (* 1 = 0.51586 loss)
I0905 02:58:42.030279 90901 sgd_solver.cpp:106] Iteration 7320, lr = 0.1
I0905 02:58:48.072474 90901 solver.cpp:228] Iteration 7330, loss = 0.239772
I0905 02:58:48.072535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239771 (* 1 = 0.239771 loss)
I0905 02:58:48.072551 90901 sgd_solver.cpp:106] Iteration 7330, lr = 0.1
I0905 02:58:54.139313 90901 solver.cpp:228] Iteration 7340, loss = 0.41259
I0905 02:58:54.139356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412589 (* 1 = 0.412589 loss)
I0905 02:58:54.139369 90901 sgd_solver.cpp:106] Iteration 7340, lr = 0.1
I0905 02:59:00.255228 90901 solver.cpp:228] Iteration 7350, loss = 0.542277
I0905 02:59:00.255373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.542277 (* 1 = 0.542277 loss)
I0905 02:59:00.255401 90901 sgd_solver.cpp:106] Iteration 7350, lr = 0.1
I0905 02:59:06.287369 90901 solver.cpp:228] Iteration 7360, loss = 0.641403
I0905 02:59:06.287431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.641403 (* 1 = 0.641403 loss)
I0905 02:59:06.287444 90901 sgd_solver.cpp:106] Iteration 7360, lr = 0.1
I0905 02:59:12.340090 90901 solver.cpp:228] Iteration 7370, loss = 0.335915
I0905 02:59:12.340142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335915 (* 1 = 0.335915 loss)
I0905 02:59:12.340154 90901 sgd_solver.cpp:106] Iteration 7370, lr = 0.1
I0905 02:59:17.645125 90901 solver.cpp:228] Iteration 7380, loss = 0.418434
I0905 02:59:17.645179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418433 (* 1 = 0.418433 loss)
I0905 02:59:17.645193 90901 sgd_solver.cpp:106] Iteration 7380, lr = 0.1
I0905 02:59:23.151949 90901 solver.cpp:228] Iteration 7390, loss = 0.332032
I0905 02:59:23.151995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332032 (* 1 = 0.332032 loss)
I0905 02:59:23.152007 90901 sgd_solver.cpp:106] Iteration 7390, lr = 0.1
I0905 02:59:29.413352 90901 solver.cpp:228] Iteration 7400, loss = 0.279356
I0905 02:59:29.413401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279356 (* 1 = 0.279356 loss)
I0905 02:59:29.413415 90901 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0905 02:59:35.473825 90901 solver.cpp:228] Iteration 7410, loss = 0.515001
I0905 02:59:35.474092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515001 (* 1 = 0.515001 loss)
I0905 02:59:35.474108 90901 sgd_solver.cpp:106] Iteration 7410, lr = 0.1
I0905 02:59:41.842532 90901 solver.cpp:228] Iteration 7420, loss = 0.478627
I0905 02:59:41.842581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478627 (* 1 = 0.478627 loss)
I0905 02:59:41.842594 90901 sgd_solver.cpp:106] Iteration 7420, lr = 0.1
I0905 02:59:47.607051 90901 solver.cpp:228] Iteration 7430, loss = 0.404028
I0905 02:59:47.607097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404028 (* 1 = 0.404028 loss)
I0905 02:59:47.607110 90901 sgd_solver.cpp:106] Iteration 7430, lr = 0.1
I0905 02:59:53.988272 90901 solver.cpp:228] Iteration 7440, loss = 0.521118
I0905 02:59:53.988317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.521117 (* 1 = 0.521117 loss)
I0905 02:59:53.988330 90901 sgd_solver.cpp:106] Iteration 7440, lr = 0.1
I0905 03:00:00.065387 90901 solver.cpp:228] Iteration 7450, loss = 0.281296
I0905 03:00:00.065426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281295 (* 1 = 0.281295 loss)
I0905 03:00:00.065443 90901 sgd_solver.cpp:106] Iteration 7450, lr = 0.1
I0905 03:00:05.845075 90901 solver.cpp:228] Iteration 7460, loss = 0.304705
I0905 03:00:05.845234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304704 (* 1 = 0.304704 loss)
I0905 03:00:05.845283 90901 sgd_solver.cpp:106] Iteration 7460, lr = 0.1
I0905 03:00:11.936262 90901 solver.cpp:228] Iteration 7470, loss = 0.58536
I0905 03:00:11.936305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.585359 (* 1 = 0.585359 loss)
I0905 03:00:11.936321 90901 sgd_solver.cpp:106] Iteration 7470, lr = 0.1
I0905 03:00:18.305845 90901 solver.cpp:228] Iteration 7480, loss = 0.556554
I0905 03:00:18.305886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556554 (* 1 = 0.556554 loss)
I0905 03:00:18.305899 90901 sgd_solver.cpp:106] Iteration 7480, lr = 0.1
I0905 03:00:24.377665 90901 solver.cpp:228] Iteration 7490, loss = 0.629086
I0905 03:00:24.377715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.629086 (* 1 = 0.629086 loss)
I0905 03:00:24.377729 90901 sgd_solver.cpp:106] Iteration 7490, lr = 0.1
I0905 03:00:30.645153 90901 solver.cpp:228] Iteration 7500, loss = 0.380361
I0905 03:00:30.645190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380361 (* 1 = 0.380361 loss)
I0905 03:00:30.645206 90901 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0905 03:00:36.654065 90901 solver.cpp:228] Iteration 7510, loss = 0.411944
I0905 03:00:36.654259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.411944 (* 1 = 0.411944 loss)
I0905 03:00:36.654289 90901 sgd_solver.cpp:106] Iteration 7510, lr = 0.1
I0905 03:00:42.882541 90901 solver.cpp:228] Iteration 7520, loss = 0.46115
I0905 03:00:42.882599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46115 (* 1 = 0.46115 loss)
I0905 03:00:42.882614 90901 sgd_solver.cpp:106] Iteration 7520, lr = 0.1
I0905 03:00:48.943660 90901 solver.cpp:228] Iteration 7530, loss = 0.379211
I0905 03:00:48.943706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379211 (* 1 = 0.379211 loss)
I0905 03:00:48.943719 90901 sgd_solver.cpp:106] Iteration 7530, lr = 0.1
I0905 03:00:55.057274 90901 solver.cpp:228] Iteration 7540, loss = 0.513005
I0905 03:00:55.057343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513005 (* 1 = 0.513005 loss)
I0905 03:00:55.057389 90901 sgd_solver.cpp:106] Iteration 7540, lr = 0.1
I0905 03:01:00.809432 90901 solver.cpp:228] Iteration 7550, loss = 0.435085
I0905 03:01:00.809496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435085 (* 1 = 0.435085 loss)
I0905 03:01:00.809511 90901 sgd_solver.cpp:106] Iteration 7550, lr = 0.1
I0905 03:01:06.369936 90901 solver.cpp:228] Iteration 7560, loss = 0.689458
I0905 03:01:06.369987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.689458 (* 1 = 0.689458 loss)
I0905 03:01:06.369999 90901 sgd_solver.cpp:106] Iteration 7560, lr = 0.1
I0905 03:01:12.077744 90901 solver.cpp:228] Iteration 7570, loss = 0.385934
I0905 03:01:12.077937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385934 (* 1 = 0.385934 loss)
I0905 03:01:12.077966 90901 sgd_solver.cpp:106] Iteration 7570, lr = 0.1
I0905 03:01:18.166486 90901 solver.cpp:228] Iteration 7580, loss = 0.30885
I0905 03:01:18.166523 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30885 (* 1 = 0.30885 loss)
I0905 03:01:18.166539 90901 sgd_solver.cpp:106] Iteration 7580, lr = 0.1
I0905 03:01:24.188593 90901 solver.cpp:228] Iteration 7590, loss = 0.468833
I0905 03:01:24.188643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468833 (* 1 = 0.468833 loss)
I0905 03:01:24.188657 90901 sgd_solver.cpp:106] Iteration 7590, lr = 0.1
I0905 03:01:30.261914 90901 solver.cpp:228] Iteration 7600, loss = 0.301758
I0905 03:01:30.261950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301758 (* 1 = 0.301758 loss)
I0905 03:01:30.261962 90901 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0905 03:01:36.360808 90901 solver.cpp:228] Iteration 7610, loss = 0.361097
I0905 03:01:36.360849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361096 (* 1 = 0.361096 loss)
I0905 03:01:36.360862 90901 sgd_solver.cpp:106] Iteration 7610, lr = 0.1
I0905 03:01:42.404353 90901 solver.cpp:228] Iteration 7620, loss = 0.296705
I0905 03:01:42.404431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296705 (* 1 = 0.296705 loss)
I0905 03:01:42.404446 90901 sgd_solver.cpp:106] Iteration 7620, lr = 0.1
I0905 03:01:48.386714 90901 solver.cpp:228] Iteration 7630, loss = 0.593582
I0905 03:01:48.386772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.593581 (* 1 = 0.593581 loss)
I0905 03:01:48.386788 90901 sgd_solver.cpp:106] Iteration 7630, lr = 0.1
I0905 03:01:54.541079 90901 solver.cpp:228] Iteration 7640, loss = 0.487049
I0905 03:01:54.541126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487049 (* 1 = 0.487049 loss)
I0905 03:01:54.541141 90901 sgd_solver.cpp:106] Iteration 7640, lr = 0.1
I0905 03:02:00.644237 90901 solver.cpp:228] Iteration 7650, loss = 0.484475
I0905 03:02:00.644291 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484475 (* 1 = 0.484475 loss)
I0905 03:02:00.644304 90901 sgd_solver.cpp:106] Iteration 7650, lr = 0.1
I0905 03:02:06.724128 90901 solver.cpp:228] Iteration 7660, loss = 0.377734
I0905 03:02:06.724187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377734 (* 1 = 0.377734 loss)
I0905 03:02:06.724203 90901 sgd_solver.cpp:106] Iteration 7660, lr = 0.1
I0905 03:02:12.748592 90901 solver.cpp:228] Iteration 7670, loss = 0.376513
I0905 03:02:12.748769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376513 (* 1 = 0.376513 loss)
I0905 03:02:12.748818 90901 sgd_solver.cpp:106] Iteration 7670, lr = 0.1
I0905 03:02:18.828805 90901 solver.cpp:228] Iteration 7680, loss = 0.432775
I0905 03:02:18.828858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432775 (* 1 = 0.432775 loss)
I0905 03:02:18.828873 90901 sgd_solver.cpp:106] Iteration 7680, lr = 0.1
I0905 03:02:25.203830 90901 solver.cpp:228] Iteration 7690, loss = 0.39418
I0905 03:02:25.203891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39418 (* 1 = 0.39418 loss)
I0905 03:02:25.203904 90901 sgd_solver.cpp:106] Iteration 7690, lr = 0.1
I0905 03:02:31.235718 90901 solver.cpp:228] Iteration 7700, loss = 0.501805
I0905 03:02:31.235780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501805 (* 1 = 0.501805 loss)
I0905 03:02:31.235795 90901 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0905 03:02:37.293815 90901 solver.cpp:228] Iteration 7710, loss = 0.39369
I0905 03:02:37.293877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39369 (* 1 = 0.39369 loss)
I0905 03:02:37.293892 90901 sgd_solver.cpp:106] Iteration 7710, lr = 0.1
I0905 03:02:43.364935 90901 solver.cpp:228] Iteration 7720, loss = 0.323416
I0905 03:02:43.365111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323416 (* 1 = 0.323416 loss)
I0905 03:02:43.365144 90901 sgd_solver.cpp:106] Iteration 7720, lr = 0.1
I0905 03:02:48.652992 90901 solver.cpp:228] Iteration 7730, loss = 0.587258
I0905 03:02:48.653050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.587258 (* 1 = 0.587258 loss)
I0905 03:02:48.653064 90901 sgd_solver.cpp:106] Iteration 7730, lr = 0.1
I0905 03:02:54.029618 90901 solver.cpp:228] Iteration 7740, loss = 0.346614
I0905 03:02:54.029681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346614 (* 1 = 0.346614 loss)
I0905 03:02:54.029696 90901 sgd_solver.cpp:106] Iteration 7740, lr = 0.1
I0905 03:03:00.054922 90901 solver.cpp:228] Iteration 7750, loss = 0.440163
I0905 03:03:00.054986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440162 (* 1 = 0.440162 loss)
I0905 03:03:00.055003 90901 sgd_solver.cpp:106] Iteration 7750, lr = 0.1
I0905 03:03:06.161527 90901 solver.cpp:228] Iteration 7760, loss = 0.671701
I0905 03:03:06.161586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.671701 (* 1 = 0.671701 loss)
I0905 03:03:06.161599 90901 sgd_solver.cpp:106] Iteration 7760, lr = 0.1
I0905 03:03:12.209405 90901 solver.cpp:228] Iteration 7770, loss = 0.500802
I0905 03:03:12.209447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.500802 (* 1 = 0.500802 loss)
I0905 03:03:12.209460 90901 sgd_solver.cpp:106] Iteration 7770, lr = 0.1
I0905 03:03:18.275660 90901 solver.cpp:228] Iteration 7780, loss = 0.365928
I0905 03:03:18.275794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365928 (* 1 = 0.365928 loss)
I0905 03:03:18.275823 90901 sgd_solver.cpp:106] Iteration 7780, lr = 0.1
I0905 03:03:24.372696 90901 solver.cpp:228] Iteration 7790, loss = 0.380252
I0905 03:03:24.372758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380252 (* 1 = 0.380252 loss)
I0905 03:03:24.372776 90901 sgd_solver.cpp:106] Iteration 7790, lr = 0.1
I0905 03:03:30.225514 90901 solver.cpp:228] Iteration 7800, loss = 0.188833
I0905 03:03:30.225574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188833 (* 1 = 0.188833 loss)
I0905 03:03:30.225589 90901 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0905 03:03:36.854130 90901 solver.cpp:228] Iteration 7810, loss = 0.595818
I0905 03:03:36.854184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.595818 (* 1 = 0.595818 loss)
I0905 03:03:36.854198 90901 sgd_solver.cpp:106] Iteration 7810, lr = 0.1
I0905 03:03:42.898738 90901 solver.cpp:228] Iteration 7820, loss = 0.252291
I0905 03:03:42.898779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25229 (* 1 = 0.25229 loss)
I0905 03:03:42.898792 90901 sgd_solver.cpp:106] Iteration 7820, lr = 0.1
I0905 03:03:48.949734 90901 solver.cpp:228] Iteration 7830, loss = 0.513593
I0905 03:03:48.949913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513593 (* 1 = 0.513593 loss)
I0905 03:03:48.949944 90901 sgd_solver.cpp:106] Iteration 7830, lr = 0.1
I0905 03:03:55.010834 90901 solver.cpp:228] Iteration 7840, loss = 0.885731
I0905 03:03:55.010877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.885731 (* 1 = 0.885731 loss)
I0905 03:03:55.010895 90901 sgd_solver.cpp:106] Iteration 7840, lr = 0.1
I0905 03:04:01.395992 90901 solver.cpp:228] Iteration 7850, loss = 0.541697
I0905 03:04:01.396049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541696 (* 1 = 0.541696 loss)
I0905 03:04:01.396062 90901 sgd_solver.cpp:106] Iteration 7850, lr = 0.1
I0905 03:04:07.268715 90901 solver.cpp:228] Iteration 7860, loss = 0.177561
I0905 03:04:07.268780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177561 (* 1 = 0.177561 loss)
I0905 03:04:07.268795 90901 sgd_solver.cpp:106] Iteration 7860, lr = 0.1
I0905 03:04:13.571787 90901 solver.cpp:228] Iteration 7870, loss = 0.506239
I0905 03:04:13.571823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.506239 (* 1 = 0.506239 loss)
I0905 03:04:13.571835 90901 sgd_solver.cpp:106] Iteration 7870, lr = 0.1
I0905 03:04:19.626339 90901 solver.cpp:228] Iteration 7880, loss = 0.437024
I0905 03:04:19.626583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437023 (* 1 = 0.437023 loss)
I0905 03:04:19.626613 90901 sgd_solver.cpp:106] Iteration 7880, lr = 0.1
I0905 03:04:25.662871 90901 solver.cpp:228] Iteration 7890, loss = 0.571066
I0905 03:04:25.662916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.571066 (* 1 = 0.571066 loss)
I0905 03:04:25.662930 90901 sgd_solver.cpp:106] Iteration 7890, lr = 0.1
I0905 03:04:31.503556 90901 solver.cpp:228] Iteration 7900, loss = 0.429869
I0905 03:04:31.503610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429868 (* 1 = 0.429868 loss)
I0905 03:04:31.503625 90901 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0905 03:04:37.068598 90901 solver.cpp:228] Iteration 7910, loss = 0.45736
I0905 03:04:37.068645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45736 (* 1 = 0.45736 loss)
I0905 03:04:37.068658 90901 sgd_solver.cpp:106] Iteration 7910, lr = 0.1
I0905 03:04:42.586426 90901 solver.cpp:228] Iteration 7920, loss = 0.252616
I0905 03:04:42.586472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252616 (* 1 = 0.252616 loss)
I0905 03:04:42.586484 90901 sgd_solver.cpp:106] Iteration 7920, lr = 0.1
I0905 03:04:48.655570 90901 solver.cpp:228] Iteration 7930, loss = 0.444225
I0905 03:04:48.655618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444225 (* 1 = 0.444225 loss)
I0905 03:04:48.655637 90901 sgd_solver.cpp:106] Iteration 7930, lr = 0.1
I0905 03:04:54.713058 90901 solver.cpp:228] Iteration 7940, loss = 0.461919
I0905 03:04:54.713213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461919 (* 1 = 0.461919 loss)
I0905 03:04:54.713279 90901 sgd_solver.cpp:106] Iteration 7940, lr = 0.1
I0905 03:05:00.770602 90901 solver.cpp:228] Iteration 7950, loss = 0.255455
I0905 03:05:00.770670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255455 (* 1 = 0.255455 loss)
I0905 03:05:00.770684 90901 sgd_solver.cpp:106] Iteration 7950, lr = 0.1
I0905 03:05:06.837095 90901 solver.cpp:228] Iteration 7960, loss = 0.432094
I0905 03:05:06.837151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432094 (* 1 = 0.432094 loss)
I0905 03:05:06.837163 90901 sgd_solver.cpp:106] Iteration 7960, lr = 0.1
I0905 03:05:13.221235 90901 solver.cpp:228] Iteration 7970, loss = 0.250795
I0905 03:05:13.221278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250794 (* 1 = 0.250794 loss)
I0905 03:05:13.221292 90901 sgd_solver.cpp:106] Iteration 7970, lr = 0.1
I0905 03:05:19.292107 90901 solver.cpp:228] Iteration 7980, loss = 0.355909
I0905 03:05:19.292158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355909 (* 1 = 0.355909 loss)
I0905 03:05:19.292172 90901 sgd_solver.cpp:106] Iteration 7980, lr = 0.1
I0905 03:05:25.679864 90901 solver.cpp:228] Iteration 7990, loss = 0.618509
I0905 03:05:25.680052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.618508 (* 1 = 0.618508 loss)
I0905 03:05:25.680085 90901 sgd_solver.cpp:106] Iteration 7990, lr = 0.1
I0905 03:05:31.515372 90901 solver.cpp:337] Iteration 8000, Testing net (#0)
I0905 03:06:13.623186 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.498125
I0905 03:06:13.623405 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.4989 (* 1 = 1.4989 loss)
I0905 03:06:13.840998 90901 solver.cpp:228] Iteration 8000, loss = 0.553991
I0905 03:06:13.841027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55399 (* 1 = 0.55399 loss)
I0905 03:06:13.841049 90901 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0905 03:06:19.663854 90901 solver.cpp:228] Iteration 8010, loss = 0.371816
I0905 03:06:19.663902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371816 (* 1 = 0.371816 loss)
I0905 03:06:19.663915 90901 sgd_solver.cpp:106] Iteration 8010, lr = 0.1
I0905 03:06:25.219558 90901 solver.cpp:228] Iteration 8020, loss = 0.403146
I0905 03:06:25.219626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403146 (* 1 = 0.403146 loss)
I0905 03:06:25.219642 90901 sgd_solver.cpp:106] Iteration 8020, lr = 0.1
I0905 03:06:30.374368 90901 solver.cpp:228] Iteration 8030, loss = 0.438837
I0905 03:06:30.374424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438836 (* 1 = 0.438836 loss)
I0905 03:06:30.374438 90901 sgd_solver.cpp:106] Iteration 8030, lr = 0.1
I0905 03:06:35.451076 90901 solver.cpp:228] Iteration 8040, loss = 0.277567
I0905 03:06:35.451120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277566 (* 1 = 0.277566 loss)
I0905 03:06:35.451133 90901 sgd_solver.cpp:106] Iteration 8040, lr = 0.1
I0905 03:06:40.489459 90901 solver.cpp:228] Iteration 8050, loss = 0.257808
I0905 03:06:40.489500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257807 (* 1 = 0.257807 loss)
I0905 03:06:40.489513 90901 sgd_solver.cpp:106] Iteration 8050, lr = 0.1
I0905 03:06:45.508414 90901 solver.cpp:228] Iteration 8060, loss = 0.529656
I0905 03:06:45.508664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529655 (* 1 = 0.529655 loss)
I0905 03:06:45.508679 90901 sgd_solver.cpp:106] Iteration 8060, lr = 0.1
I0905 03:06:50.553997 90901 solver.cpp:228] Iteration 8070, loss = 0.723089
I0905 03:06:50.554041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.723088 (* 1 = 0.723088 loss)
I0905 03:06:50.554054 90901 sgd_solver.cpp:106] Iteration 8070, lr = 0.1
I0905 03:06:55.598644 90901 solver.cpp:228] Iteration 8080, loss = 0.319394
I0905 03:06:55.598693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319394 (* 1 = 0.319394 loss)
I0905 03:06:55.598706 90901 sgd_solver.cpp:106] Iteration 8080, lr = 0.1
I0905 03:07:00.613540 90901 solver.cpp:228] Iteration 8090, loss = 0.358595
I0905 03:07:00.613587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358595 (* 1 = 0.358595 loss)
I0905 03:07:00.613605 90901 sgd_solver.cpp:106] Iteration 8090, lr = 0.1
I0905 03:07:05.700325 90901 solver.cpp:228] Iteration 8100, loss = 0.707045
I0905 03:07:05.700373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.707045 (* 1 = 0.707045 loss)
I0905 03:07:05.700387 90901 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0905 03:07:10.753901 90901 solver.cpp:228] Iteration 8110, loss = 0.305298
I0905 03:07:10.753949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305298 (* 1 = 0.305298 loss)
I0905 03:07:10.753962 90901 sgd_solver.cpp:106] Iteration 8110, lr = 0.1
I0905 03:07:15.787384 90901 solver.cpp:228] Iteration 8120, loss = 0.393068
I0905 03:07:15.787539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393067 (* 1 = 0.393067 loss)
I0905 03:07:15.787569 90901 sgd_solver.cpp:106] Iteration 8120, lr = 0.1
I0905 03:07:20.826997 90901 solver.cpp:228] Iteration 8130, loss = 0.418959
I0905 03:07:20.827033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418958 (* 1 = 0.418958 loss)
I0905 03:07:20.827044 90901 sgd_solver.cpp:106] Iteration 8130, lr = 0.1
I0905 03:07:25.906060 90901 solver.cpp:228] Iteration 8140, loss = 0.695659
I0905 03:07:25.906111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.695659 (* 1 = 0.695659 loss)
I0905 03:07:25.906123 90901 sgd_solver.cpp:106] Iteration 8140, lr = 0.1
I0905 03:07:30.980012 90901 solver.cpp:228] Iteration 8150, loss = 0.551669
I0905 03:07:30.980052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.551669 (* 1 = 0.551669 loss)
I0905 03:07:30.980067 90901 sgd_solver.cpp:106] Iteration 8150, lr = 0.1
I0905 03:07:35.982235 90901 solver.cpp:228] Iteration 8160, loss = 0.330365
I0905 03:07:35.982280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330364 (* 1 = 0.330364 loss)
I0905 03:07:35.982293 90901 sgd_solver.cpp:106] Iteration 8160, lr = 0.1
I0905 03:07:41.010380 90901 solver.cpp:228] Iteration 8170, loss = 0.486169
I0905 03:07:41.010418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486169 (* 1 = 0.486169 loss)
I0905 03:07:41.010432 90901 sgd_solver.cpp:106] Iteration 8170, lr = 0.1
I0905 03:07:46.051489 90901 solver.cpp:228] Iteration 8180, loss = 0.27664
I0905 03:07:46.051663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276639 (* 1 = 0.276639 loss)
I0905 03:07:46.051682 90901 sgd_solver.cpp:106] Iteration 8180, lr = 0.1
I0905 03:07:51.445406 90901 solver.cpp:228] Iteration 8190, loss = 0.298466
I0905 03:07:51.445452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298466 (* 1 = 0.298466 loss)
I0905 03:07:51.445466 90901 sgd_solver.cpp:106] Iteration 8190, lr = 0.1
I0905 03:07:57.505149 90901 solver.cpp:228] Iteration 8200, loss = 0.395678
I0905 03:07:57.505195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395677 (* 1 = 0.395677 loss)
I0905 03:07:57.505209 90901 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0905 03:08:03.577824 90901 solver.cpp:228] Iteration 8210, loss = 0.238597
I0905 03:08:03.577867 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238597 (* 1 = 0.238597 loss)
I0905 03:08:03.577879 90901 sgd_solver.cpp:106] Iteration 8210, lr = 0.1
I0905 03:08:09.469801 90901 solver.cpp:228] Iteration 8220, loss = 0.421106
I0905 03:08:09.469863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421106 (* 1 = 0.421106 loss)
I0905 03:08:09.469878 90901 sgd_solver.cpp:106] Iteration 8220, lr = 0.1
I0905 03:08:14.833559 90901 solver.cpp:228] Iteration 8230, loss = 0.260346
I0905 03:08:14.833602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260345 (* 1 = 0.260345 loss)
I0905 03:08:14.833618 90901 sgd_solver.cpp:106] Iteration 8230, lr = 0.1
I0905 03:08:20.528553 90901 solver.cpp:228] Iteration 8240, loss = 0.244964
I0905 03:08:20.528715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244963 (* 1 = 0.244963 loss)
I0905 03:08:20.528736 90901 sgd_solver.cpp:106] Iteration 8240, lr = 0.1
I0905 03:08:26.240104 90901 solver.cpp:228] Iteration 8250, loss = 0.488136
I0905 03:08:26.240154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488136 (* 1 = 0.488136 loss)
I0905 03:08:26.240166 90901 sgd_solver.cpp:106] Iteration 8250, lr = 0.1
I0905 03:08:32.306766 90901 solver.cpp:228] Iteration 8260, loss = 0.339908
I0905 03:08:32.306812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339908 (* 1 = 0.339908 loss)
I0905 03:08:32.306824 90901 sgd_solver.cpp:106] Iteration 8260, lr = 0.1
I0905 03:08:38.660145 90901 solver.cpp:228] Iteration 8270, loss = 0.48989
I0905 03:08:38.660192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48989 (* 1 = 0.48989 loss)
I0905 03:08:38.660205 90901 sgd_solver.cpp:106] Iteration 8270, lr = 0.1
I0905 03:08:44.744470 90901 solver.cpp:228] Iteration 8280, loss = 0.439336
I0905 03:08:44.744525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439336 (* 1 = 0.439336 loss)
I0905 03:08:44.744539 90901 sgd_solver.cpp:106] Iteration 8280, lr = 0.1
I0905 03:08:50.773491 90901 solver.cpp:228] Iteration 8290, loss = 0.550768
I0905 03:08:50.773686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.550767 (* 1 = 0.550767 loss)
I0905 03:08:50.773707 90901 sgd_solver.cpp:106] Iteration 8290, lr = 0.1
I0905 03:08:57.145933 90901 solver.cpp:228] Iteration 8300, loss = 0.325428
I0905 03:08:57.145979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325428 (* 1 = 0.325428 loss)
I0905 03:08:57.145998 90901 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0905 03:09:03.043675 90901 solver.cpp:228] Iteration 8310, loss = 0.456288
I0905 03:09:03.043753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456288 (* 1 = 0.456288 loss)
I0905 03:09:03.043782 90901 sgd_solver.cpp:106] Iteration 8310, lr = 0.1
I0905 03:09:09.033263 90901 solver.cpp:228] Iteration 8320, loss = 0.366613
I0905 03:09:09.033313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366613 (* 1 = 0.366613 loss)
I0905 03:09:09.033325 90901 sgd_solver.cpp:106] Iteration 8320, lr = 0.1
I0905 03:09:15.304278 90901 solver.cpp:228] Iteration 8330, loss = 0.411627
I0905 03:09:15.304318 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.411627 (* 1 = 0.411627 loss)
I0905 03:09:15.304330 90901 sgd_solver.cpp:106] Iteration 8330, lr = 0.1
I0905 03:09:21.378708 90901 solver.cpp:228] Iteration 8340, loss = 0.352966
I0905 03:09:21.378830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352966 (* 1 = 0.352966 loss)
I0905 03:09:21.378860 90901 sgd_solver.cpp:106] Iteration 8340, lr = 0.1
I0905 03:09:27.451987 90901 solver.cpp:228] Iteration 8350, loss = 0.541833
I0905 03:09:27.452064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541832 (* 1 = 0.541832 loss)
I0905 03:09:27.452078 90901 sgd_solver.cpp:106] Iteration 8350, lr = 0.1
I0905 03:09:33.845441 90901 solver.cpp:228] Iteration 8360, loss = 0.445396
I0905 03:09:33.845489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445395 (* 1 = 0.445395 loss)
I0905 03:09:33.845504 90901 sgd_solver.cpp:106] Iteration 8360, lr = 0.1
I0905 03:09:39.554774 90901 solver.cpp:228] Iteration 8370, loss = 0.4437
I0905 03:09:39.554826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4437 (* 1 = 0.4437 loss)
I0905 03:09:39.554841 90901 sgd_solver.cpp:106] Iteration 8370, lr = 0.1
I0905 03:09:45.980197 90901 solver.cpp:228] Iteration 8380, loss = 0.370434
I0905 03:09:45.980232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370434 (* 1 = 0.370434 loss)
I0905 03:09:45.980249 90901 sgd_solver.cpp:106] Iteration 8380, lr = 0.1
I0905 03:09:51.801184 90901 solver.cpp:228] Iteration 8390, loss = 0.600953
I0905 03:09:51.801313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.600953 (* 1 = 0.600953 loss)
I0905 03:09:51.801342 90901 sgd_solver.cpp:106] Iteration 8390, lr = 0.1
I0905 03:09:57.608068 90901 solver.cpp:228] Iteration 8400, loss = 0.505439
I0905 03:09:57.608113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505439 (* 1 = 0.505439 loss)
I0905 03:09:57.608126 90901 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0905 03:10:03.158509 90901 solver.cpp:228] Iteration 8410, loss = 0.407459
I0905 03:10:03.158571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407459 (* 1 = 0.407459 loss)
I0905 03:10:03.158584 90901 sgd_solver.cpp:106] Iteration 8410, lr = 0.1
I0905 03:10:08.834108 90901 solver.cpp:228] Iteration 8420, loss = 0.607955
I0905 03:10:08.834159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607955 (* 1 = 0.607955 loss)
I0905 03:10:08.834172 90901 sgd_solver.cpp:106] Iteration 8420, lr = 0.1
I0905 03:10:15.044390 90901 solver.cpp:228] Iteration 8430, loss = 0.21476
I0905 03:10:15.044442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21476 (* 1 = 0.21476 loss)
I0905 03:10:15.044458 90901 sgd_solver.cpp:106] Iteration 8430, lr = 0.1
I0905 03:10:21.301606 90901 solver.cpp:228] Iteration 8440, loss = 0.329333
I0905 03:10:21.301646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329332 (* 1 = 0.329332 loss)
I0905 03:10:21.301661 90901 sgd_solver.cpp:106] Iteration 8440, lr = 0.1
I0905 03:10:27.331889 90901 solver.cpp:228] Iteration 8450, loss = 0.129669
I0905 03:10:27.332088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129669 (* 1 = 0.129669 loss)
I0905 03:10:27.332109 90901 sgd_solver.cpp:106] Iteration 8450, lr = 0.1
I0905 03:10:33.412504 90901 solver.cpp:228] Iteration 8460, loss = 0.454647
I0905 03:10:33.412549 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454647 (* 1 = 0.454647 loss)
I0905 03:10:33.412561 90901 sgd_solver.cpp:106] Iteration 8460, lr = 0.1
I0905 03:10:39.490000 90901 solver.cpp:228] Iteration 8470, loss = 0.540817
I0905 03:10:39.490056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.540817 (* 1 = 0.540817 loss)
I0905 03:10:39.490070 90901 sgd_solver.cpp:106] Iteration 8470, lr = 0.1
I0905 03:10:45.246860 90901 solver.cpp:228] Iteration 8480, loss = 0.481931
I0905 03:10:45.246917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.481931 (* 1 = 0.481931 loss)
I0905 03:10:45.246934 90901 sgd_solver.cpp:106] Iteration 8480, lr = 0.1
I0905 03:10:51.642354 90901 solver.cpp:228] Iteration 8490, loss = 0.526183
I0905 03:10:51.642416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.526183 (* 1 = 0.526183 loss)
I0905 03:10:51.642429 90901 sgd_solver.cpp:106] Iteration 8490, lr = 0.1
I0905 03:10:57.710429 90901 solver.cpp:228] Iteration 8500, loss = 0.300531
I0905 03:10:57.710604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300531 (* 1 = 0.300531 loss)
I0905 03:10:57.710654 90901 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0905 03:11:03.825271 90901 solver.cpp:228] Iteration 8510, loss = 0.621211
I0905 03:11:03.825325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.621211 (* 1 = 0.621211 loss)
I0905 03:11:03.825337 90901 sgd_solver.cpp:106] Iteration 8510, lr = 0.1
I0905 03:11:09.892436 90901 solver.cpp:228] Iteration 8520, loss = 0.521827
I0905 03:11:09.892493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.521827 (* 1 = 0.521827 loss)
I0905 03:11:09.892508 90901 sgd_solver.cpp:106] Iteration 8520, lr = 0.1
I0905 03:11:15.964081 90901 solver.cpp:228] Iteration 8530, loss = 0.284438
I0905 03:11:15.964138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284438 (* 1 = 0.284438 loss)
I0905 03:11:15.964149 90901 sgd_solver.cpp:106] Iteration 8530, lr = 0.1
I0905 03:11:22.065227 90901 solver.cpp:228] Iteration 8540, loss = 0.407704
I0905 03:11:22.065269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407703 (* 1 = 0.407703 loss)
I0905 03:11:22.065281 90901 sgd_solver.cpp:106] Iteration 8540, lr = 0.1
I0905 03:11:28.130796 90901 solver.cpp:228] Iteration 8550, loss = 0.37856
I0905 03:11:28.130929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378559 (* 1 = 0.378559 loss)
I0905 03:11:28.130957 90901 sgd_solver.cpp:106] Iteration 8550, lr = 0.1
I0905 03:11:34.214788 90901 solver.cpp:228] Iteration 8560, loss = 0.509413
I0905 03:11:34.214834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.509413 (* 1 = 0.509413 loss)
I0905 03:11:34.214848 90901 sgd_solver.cpp:106] Iteration 8560, lr = 0.1
I0905 03:11:40.189645 90901 solver.cpp:228] Iteration 8570, loss = 0.577564
I0905 03:11:40.189695 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.577564 (* 1 = 0.577564 loss)
I0905 03:11:40.189708 90901 sgd_solver.cpp:106] Iteration 8570, lr = 0.1
I0905 03:11:45.735301 90901 solver.cpp:228] Iteration 8580, loss = 0.82007
I0905 03:11:45.735348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.82007 (* 1 = 0.82007 loss)
I0905 03:11:45.735363 90901 sgd_solver.cpp:106] Iteration 8580, lr = 0.1
I0905 03:11:51.112264 90901 solver.cpp:228] Iteration 8590, loss = 0.423836
I0905 03:11:51.112316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423836 (* 1 = 0.423836 loss)
I0905 03:11:51.112329 90901 sgd_solver.cpp:106] Iteration 8590, lr = 0.1
I0905 03:11:57.162652 90901 solver.cpp:228] Iteration 8600, loss = 0.941181
I0905 03:11:57.162710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.941181 (* 1 = 0.941181 loss)
I0905 03:11:57.162726 90901 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0905 03:12:03.222544 90901 solver.cpp:228] Iteration 8610, loss = 0.607725
I0905 03:12:03.222767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607725 (* 1 = 0.607725 loss)
I0905 03:12:03.222796 90901 sgd_solver.cpp:106] Iteration 8610, lr = 0.1
I0905 03:12:09.267519 90901 solver.cpp:228] Iteration 8620, loss = 0.442078
I0905 03:12:09.267566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442078 (* 1 = 0.442078 loss)
I0905 03:12:09.267578 90901 sgd_solver.cpp:106] Iteration 8620, lr = 0.1
I0905 03:12:15.349107 90901 solver.cpp:228] Iteration 8630, loss = 0.475572
I0905 03:12:15.349155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475572 (* 1 = 0.475572 loss)
I0905 03:12:15.349169 90901 sgd_solver.cpp:106] Iteration 8630, lr = 0.1
I0905 03:12:21.429709 90901 solver.cpp:228] Iteration 8640, loss = 0.423736
I0905 03:12:21.429754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423736 (* 1 = 0.423736 loss)
I0905 03:12:21.429771 90901 sgd_solver.cpp:106] Iteration 8640, lr = 0.1
I0905 03:12:27.462810 90901 solver.cpp:228] Iteration 8650, loss = 0.299199
I0905 03:12:27.462863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299198 (* 1 = 0.299198 loss)
I0905 03:12:27.462877 90901 sgd_solver.cpp:106] Iteration 8650, lr = 0.1
I0905 03:12:33.190650 90901 solver.cpp:228] Iteration 8660, loss = 0.6305
I0905 03:12:33.190702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.6305 (* 1 = 0.6305 loss)
I0905 03:12:33.190727 90901 sgd_solver.cpp:106] Iteration 8660, lr = 0.1
I0905 03:12:39.654853 90901 solver.cpp:228] Iteration 8670, loss = 0.345493
I0905 03:12:39.655062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345492 (* 1 = 0.345492 loss)
I0905 03:12:39.655078 90901 sgd_solver.cpp:106] Iteration 8670, lr = 0.1
I0905 03:12:45.722704 90901 solver.cpp:228] Iteration 8680, loss = 0.340398
I0905 03:12:45.722767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340398 (* 1 = 0.340398 loss)
I0905 03:12:45.722782 90901 sgd_solver.cpp:106] Iteration 8680, lr = 0.1
I0905 03:12:51.807256 90901 solver.cpp:228] Iteration 8690, loss = 0.495149
I0905 03:12:51.807304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.495149 (* 1 = 0.495149 loss)
I0905 03:12:51.807317 90901 sgd_solver.cpp:106] Iteration 8690, lr = 0.1
I0905 03:12:58.181236 90901 solver.cpp:228] Iteration 8700, loss = 0.561179
I0905 03:12:58.181282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.561179 (* 1 = 0.561179 loss)
I0905 03:12:58.181295 90901 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0905 03:13:04.213611 90901 solver.cpp:228] Iteration 8710, loss = 0.529411
I0905 03:13:04.213665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529411 (* 1 = 0.529411 loss)
I0905 03:13:04.213681 90901 sgd_solver.cpp:106] Iteration 8710, lr = 0.1
I0905 03:13:10.266278 90901 solver.cpp:228] Iteration 8720, loss = 0.535614
I0905 03:13:10.266402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535614 (* 1 = 0.535614 loss)
I0905 03:13:10.266419 90901 sgd_solver.cpp:106] Iteration 8720, lr = 0.1
I0905 03:13:16.634114 90901 solver.cpp:228] Iteration 8730, loss = 0.227902
I0905 03:13:16.634161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227901 (* 1 = 0.227901 loss)
I0905 03:13:16.634177 90901 sgd_solver.cpp:106] Iteration 8730, lr = 0.1
I0905 03:13:22.476330 90901 solver.cpp:228] Iteration 8740, loss = 0.367546
I0905 03:13:22.476380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367546 (* 1 = 0.367546 loss)
I0905 03:13:22.476393 90901 sgd_solver.cpp:106] Iteration 8740, lr = 0.1
I0905 03:13:28.329504 90901 solver.cpp:228] Iteration 8750, loss = 0.3103
I0905 03:13:28.329556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3103 (* 1 = 0.3103 loss)
I0905 03:13:28.329571 90901 sgd_solver.cpp:106] Iteration 8750, lr = 0.1
I0905 03:13:33.579140 90901 solver.cpp:228] Iteration 8760, loss = 0.390495
I0905 03:13:33.579227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390495 (* 1 = 0.390495 loss)
I0905 03:13:33.579296 90901 sgd_solver.cpp:106] Iteration 8760, lr = 0.1
I0905 03:13:39.479625 90901 solver.cpp:228] Iteration 8770, loss = 0.488153
I0905 03:13:39.479668 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488153 (* 1 = 0.488153 loss)
I0905 03:13:39.479681 90901 sgd_solver.cpp:106] Iteration 8770, lr = 0.1
I0905 03:13:45.554301 90901 solver.cpp:228] Iteration 8780, loss = 0.371179
I0905 03:13:45.554539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371179 (* 1 = 0.371179 loss)
I0905 03:13:45.554559 90901 sgd_solver.cpp:106] Iteration 8780, lr = 0.1
I0905 03:13:51.327165 90901 solver.cpp:228] Iteration 8790, loss = 0.722025
I0905 03:13:51.327214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.722024 (* 1 = 0.722024 loss)
I0905 03:13:51.327227 90901 sgd_solver.cpp:106] Iteration 8790, lr = 0.1
I0905 03:13:57.529232 90901 solver.cpp:337] Iteration 8800, Testing net (#0)
I0905 03:14:39.977474 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.495937
I0905 03:14:39.977614 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.40696 (* 1 = 1.40696 loss)
I0905 03:14:40.195726 90901 solver.cpp:228] Iteration 8800, loss = 0.366778
I0905 03:14:40.195754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366778 (* 1 = 0.366778 loss)
I0905 03:14:40.195770 90901 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0905 03:14:46.243341 90901 solver.cpp:228] Iteration 8810, loss = 0.288856
I0905 03:14:46.243387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288856 (* 1 = 0.288856 loss)
I0905 03:14:46.243402 90901 sgd_solver.cpp:106] Iteration 8810, lr = 0.1
I0905 03:14:52.332104 90901 solver.cpp:228] Iteration 8820, loss = 0.342426
I0905 03:14:52.332149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342426 (* 1 = 0.342426 loss)
I0905 03:14:52.332162 90901 sgd_solver.cpp:106] Iteration 8820, lr = 0.1
I0905 03:14:58.719374 90901 solver.cpp:228] Iteration 8830, loss = 0.346463
I0905 03:14:58.719420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346462 (* 1 = 0.346462 loss)
I0905 03:14:58.719432 90901 sgd_solver.cpp:106] Iteration 8830, lr = 0.1
I0905 03:15:04.771638 90901 solver.cpp:228] Iteration 8840, loss = 0.357388
I0905 03:15:04.771690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357387 (* 1 = 0.357387 loss)
I0905 03:15:04.771703 90901 sgd_solver.cpp:106] Iteration 8840, lr = 0.1
I0905 03:15:10.812453 90901 solver.cpp:228] Iteration 8850, loss = 0.40504
I0905 03:15:10.812603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40504 (* 1 = 0.40504 loss)
I0905 03:15:10.812619 90901 sgd_solver.cpp:106] Iteration 8850, lr = 0.1
I0905 03:15:16.431941 90901 solver.cpp:228] Iteration 8860, loss = 0.286325
I0905 03:15:16.432000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286324 (* 1 = 0.286324 loss)
I0905 03:15:16.432015 90901 sgd_solver.cpp:106] Iteration 8860, lr = 0.1
I0905 03:15:21.788842 90901 solver.cpp:228] Iteration 8870, loss = 0.456311
I0905 03:15:21.788898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45631 (* 1 = 0.45631 loss)
I0905 03:15:21.788913 90901 sgd_solver.cpp:106] Iteration 8870, lr = 0.1
I0905 03:15:27.536435 90901 solver.cpp:228] Iteration 8880, loss = 0.382194
I0905 03:15:27.536481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382194 (* 1 = 0.382194 loss)
I0905 03:15:27.536494 90901 sgd_solver.cpp:106] Iteration 8880, lr = 0.1
I0905 03:15:33.635609 90901 solver.cpp:228] Iteration 8890, loss = 0.403092
I0905 03:15:33.635659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403091 (* 1 = 0.403091 loss)
I0905 03:15:33.635671 90901 sgd_solver.cpp:106] Iteration 8890, lr = 0.1
I0905 03:15:39.990355 90901 solver.cpp:228] Iteration 8900, loss = 0.561893
I0905 03:15:39.990401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.561893 (* 1 = 0.561893 loss)
I0905 03:15:39.990414 90901 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0905 03:15:46.086875 90901 solver.cpp:228] Iteration 8910, loss = 0.823669
I0905 03:15:46.087054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.823669 (* 1 = 0.823669 loss)
I0905 03:15:46.087082 90901 sgd_solver.cpp:106] Iteration 8910, lr = 0.1
I0905 03:15:52.129005 90901 solver.cpp:228] Iteration 8920, loss = 0.299113
I0905 03:15:52.129093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299113 (* 1 = 0.299113 loss)
I0905 03:15:52.129117 90901 sgd_solver.cpp:106] Iteration 8920, lr = 0.1
I0905 03:15:58.542451 90901 solver.cpp:228] Iteration 8930, loss = 0.534079
I0905 03:15:58.542502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.534079 (* 1 = 0.534079 loss)
I0905 03:15:58.542515 90901 sgd_solver.cpp:106] Iteration 8930, lr = 0.1
I0905 03:16:04.604848 90901 solver.cpp:228] Iteration 8940, loss = 0.795493
I0905 03:16:04.604889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.795493 (* 1 = 0.795493 loss)
I0905 03:16:04.604904 90901 sgd_solver.cpp:106] Iteration 8940, lr = 0.1
I0905 03:16:10.633283 90901 solver.cpp:228] Iteration 8950, loss = 0.599905
I0905 03:16:10.633332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.599905 (* 1 = 0.599905 loss)
I0905 03:16:10.633345 90901 sgd_solver.cpp:106] Iteration 8950, lr = 0.1
I0905 03:16:16.694568 90901 solver.cpp:228] Iteration 8960, loss = 0.48686
I0905 03:16:16.695667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48686 (* 1 = 0.48686 loss)
I0905 03:16:16.695680 90901 sgd_solver.cpp:106] Iteration 8960, lr = 0.1
I0905 03:16:22.722440 90901 solver.cpp:228] Iteration 8970, loss = 0.401031
I0905 03:16:22.722484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40103 (* 1 = 0.40103 loss)
I0905 03:16:22.722496 90901 sgd_solver.cpp:106] Iteration 8970, lr = 0.1
I0905 03:16:28.803755 90901 solver.cpp:228] Iteration 8980, loss = 0.383531
I0905 03:16:28.803802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383531 (* 1 = 0.383531 loss)
I0905 03:16:28.803818 90901 sgd_solver.cpp:106] Iteration 8980, lr = 0.1
I0905 03:16:35.179451 90901 solver.cpp:228] Iteration 8990, loss = 0.343964
I0905 03:16:35.179498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343964 (* 1 = 0.343964 loss)
I0905 03:16:35.179509 90901 sgd_solver.cpp:106] Iteration 8990, lr = 0.1
I0905 03:16:41.213004 90901 solver.cpp:228] Iteration 9000, loss = 0.766946
I0905 03:16:41.213054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.766945 (* 1 = 0.766945 loss)
I0905 03:16:41.213071 90901 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0905 03:16:47.321094 90901 solver.cpp:228] Iteration 9010, loss = 0.562843
I0905 03:16:47.321249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.562843 (* 1 = 0.562843 loss)
I0905 03:16:47.321264 90901 sgd_solver.cpp:106] Iteration 9010, lr = 0.1
I0905 03:16:53.681520 90901 solver.cpp:228] Iteration 9020, loss = 0.547017
I0905 03:16:53.681572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547017 (* 1 = 0.547017 loss)
I0905 03:16:53.681586 90901 sgd_solver.cpp:106] Iteration 9020, lr = 0.1
I0905 03:16:59.748805 90901 solver.cpp:228] Iteration 9030, loss = 0.76208
I0905 03:16:59.748847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.762079 (* 1 = 0.762079 loss)
I0905 03:16:59.748859 90901 sgd_solver.cpp:106] Iteration 9030, lr = 0.1
I0905 03:17:04.990267 90901 solver.cpp:228] Iteration 9040, loss = 0.41785
I0905 03:17:04.990316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41785 (* 1 = 0.41785 loss)
I0905 03:17:04.990331 90901 sgd_solver.cpp:106] Iteration 9040, lr = 0.1
I0905 03:17:10.686457 90901 solver.cpp:228] Iteration 9050, loss = 0.372886
I0905 03:17:10.686506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372886 (* 1 = 0.372886 loss)
I0905 03:17:10.686519 90901 sgd_solver.cpp:106] Iteration 9050, lr = 0.1
I0905 03:17:16.748888 90901 solver.cpp:228] Iteration 9060, loss = 0.437864
I0905 03:17:16.748934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437864 (* 1 = 0.437864 loss)
I0905 03:17:16.748949 90901 sgd_solver.cpp:106] Iteration 9060, lr = 0.1
I0905 03:17:22.815728 90901 solver.cpp:228] Iteration 9070, loss = 0.299662
I0905 03:17:22.815935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299662 (* 1 = 0.299662 loss)
I0905 03:17:22.815955 90901 sgd_solver.cpp:106] Iteration 9070, lr = 0.1
I0905 03:17:28.873097 90901 solver.cpp:228] Iteration 9080, loss = 0.25268
I0905 03:17:28.873149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25268 (* 1 = 0.25268 loss)
I0905 03:17:28.873165 90901 sgd_solver.cpp:106] Iteration 9080, lr = 0.1
I0905 03:17:35.238677 90901 solver.cpp:228] Iteration 9090, loss = 0.374249
I0905 03:17:35.238724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374249 (* 1 = 0.374249 loss)
I0905 03:17:35.238736 90901 sgd_solver.cpp:106] Iteration 9090, lr = 0.1
I0905 03:17:41.334918 90901 solver.cpp:228] Iteration 9100, loss = 0.528375
I0905 03:17:41.334962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528375 (* 1 = 0.528375 loss)
I0905 03:17:41.334975 90901 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0905 03:17:47.416713 90901 solver.cpp:228] Iteration 9110, loss = 0.504142
I0905 03:17:47.416772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504142 (* 1 = 0.504142 loss)
I0905 03:17:47.416786 90901 sgd_solver.cpp:106] Iteration 9110, lr = 0.1
I0905 03:17:53.495827 90901 solver.cpp:228] Iteration 9120, loss = 0.539762
I0905 03:17:53.496018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.539761 (* 1 = 0.539761 loss)
I0905 03:17:53.496033 90901 sgd_solver.cpp:106] Iteration 9120, lr = 0.1
I0905 03:17:59.558184 90901 solver.cpp:228] Iteration 9130, loss = 0.353156
I0905 03:17:59.558226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353156 (* 1 = 0.353156 loss)
I0905 03:17:59.558240 90901 sgd_solver.cpp:106] Iteration 9130, lr = 0.1
I0905 03:18:05.607235 90901 solver.cpp:228] Iteration 9140, loss = 0.508974
I0905 03:18:05.607290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.508974 (* 1 = 0.508974 loss)
I0905 03:18:05.607303 90901 sgd_solver.cpp:106] Iteration 9140, lr = 0.1
I0905 03:18:11.666875 90901 solver.cpp:228] Iteration 9150, loss = 0.588775
I0905 03:18:11.666929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.588774 (* 1 = 0.588774 loss)
I0905 03:18:11.666944 90901 sgd_solver.cpp:106] Iteration 9150, lr = 0.1
I0905 03:18:17.895999 90901 solver.cpp:228] Iteration 9160, loss = 0.559999
I0905 03:18:17.896044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.559999 (* 1 = 0.559999 loss)
I0905 03:18:17.896060 90901 sgd_solver.cpp:106] Iteration 9160, lr = 0.1
I0905 03:18:24.103529 90901 solver.cpp:228] Iteration 9170, loss = 0.487242
I0905 03:18:24.103663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487242 (* 1 = 0.487242 loss)
I0905 03:18:24.103703 90901 sgd_solver.cpp:106] Iteration 9170, lr = 0.1
I0905 03:18:30.176194 90901 solver.cpp:228] Iteration 9180, loss = 0.502542
I0905 03:18:30.176237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502542 (* 1 = 0.502542 loss)
I0905 03:18:30.176254 90901 sgd_solver.cpp:106] Iteration 9180, lr = 0.1
I0905 03:18:36.235745 90901 solver.cpp:228] Iteration 9190, loss = 0.60777
I0905 03:18:36.235790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.60777 (* 1 = 0.60777 loss)
I0905 03:18:36.235803 90901 sgd_solver.cpp:106] Iteration 9190, lr = 0.1
I0905 03:18:42.330757 90901 solver.cpp:228] Iteration 9200, loss = 0.203475
I0905 03:18:42.330814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203474 (* 1 = 0.203474 loss)
I0905 03:18:42.330828 90901 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0905 03:18:48.170593 90901 solver.cpp:228] Iteration 9210, loss = 0.311258
I0905 03:18:48.170665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311258 (* 1 = 0.311258 loss)
I0905 03:18:48.170681 90901 sgd_solver.cpp:106] Iteration 9210, lr = 0.1
I0905 03:18:53.419172 90901 solver.cpp:228] Iteration 9220, loss = 0.563153
I0905 03:18:53.419224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.563153 (* 1 = 0.563153 loss)
I0905 03:18:53.419240 90901 sgd_solver.cpp:106] Iteration 9220, lr = 0.1
I0905 03:18:59.071955 90901 solver.cpp:228] Iteration 9230, loss = 0.379458
I0905 03:18:59.072152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379457 (* 1 = 0.379457 loss)
I0905 03:18:59.072198 90901 sgd_solver.cpp:106] Iteration 9230, lr = 0.1
I0905 03:19:05.457278 90901 solver.cpp:228] Iteration 9240, loss = 0.108282
I0905 03:19:05.457329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108282 (* 1 = 0.108282 loss)
I0905 03:19:05.457341 90901 sgd_solver.cpp:106] Iteration 9240, lr = 0.1
I0905 03:19:11.576700 90901 solver.cpp:228] Iteration 9250, loss = 0.384401
I0905 03:19:11.576746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384401 (* 1 = 0.384401 loss)
I0905 03:19:11.576761 90901 sgd_solver.cpp:106] Iteration 9250, lr = 0.1
I0905 03:19:17.721423 90901 solver.cpp:228] Iteration 9260, loss = 0.655886
I0905 03:19:17.721469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.655886 (* 1 = 0.655886 loss)
I0905 03:19:17.721483 90901 sgd_solver.cpp:106] Iteration 9260, lr = 0.1
I0905 03:19:23.966496 90901 solver.cpp:228] Iteration 9270, loss = 0.472888
I0905 03:19:23.966542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472888 (* 1 = 0.472888 loss)
I0905 03:19:23.966557 90901 sgd_solver.cpp:106] Iteration 9270, lr = 0.1
I0905 03:19:29.673514 90901 solver.cpp:228] Iteration 9280, loss = 0.482252
I0905 03:19:29.673691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482252 (* 1 = 0.482252 loss)
I0905 03:19:29.673724 90901 sgd_solver.cpp:106] Iteration 9280, lr = 0.1
I0905 03:19:35.776268 90901 solver.cpp:228] Iteration 9290, loss = 0.413602
I0905 03:19:35.776327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413602 (* 1 = 0.413602 loss)
I0905 03:19:35.776343 90901 sgd_solver.cpp:106] Iteration 9290, lr = 0.1
I0905 03:19:42.151186 90901 solver.cpp:228] Iteration 9300, loss = 0.601659
I0905 03:19:42.151231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.601659 (* 1 = 0.601659 loss)
I0905 03:19:42.151249 90901 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0905 03:19:48.172159 90901 solver.cpp:228] Iteration 9310, loss = 0.343923
I0905 03:19:48.172204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343923 (* 1 = 0.343923 loss)
I0905 03:19:48.172219 90901 sgd_solver.cpp:106] Iteration 9310, lr = 0.1
I0905 03:19:54.233885 90901 solver.cpp:228] Iteration 9320, loss = 0.22155
I0905 03:19:54.233932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22155 (* 1 = 0.22155 loss)
I0905 03:19:54.233947 90901 sgd_solver.cpp:106] Iteration 9320, lr = 0.1
I0905 03:19:59.817682 90901 solver.cpp:228] Iteration 9330, loss = 0.427648
I0905 03:19:59.817826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427647 (* 1 = 0.427647 loss)
I0905 03:19:59.817862 90901 sgd_solver.cpp:106] Iteration 9330, lr = 0.1
I0905 03:20:06.258435 90901 solver.cpp:228] Iteration 9340, loss = 0.234812
I0905 03:20:06.258498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234812 (* 1 = 0.234812 loss)
I0905 03:20:06.258514 90901 sgd_solver.cpp:106] Iteration 9340, lr = 0.1
I0905 03:20:12.402878 90901 solver.cpp:228] Iteration 9350, loss = 0.23541
I0905 03:20:12.402930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235409 (* 1 = 0.235409 loss)
I0905 03:20:12.402943 90901 sgd_solver.cpp:106] Iteration 9350, lr = 0.1
I0905 03:20:18.500449 90901 solver.cpp:228] Iteration 9360, loss = 0.59062
I0905 03:20:18.500520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59062 (* 1 = 0.59062 loss)
I0905 03:20:18.500546 90901 sgd_solver.cpp:106] Iteration 9360, lr = 0.1
I0905 03:20:24.275094 90901 solver.cpp:228] Iteration 9370, loss = 0.679554
I0905 03:20:24.275158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.679554 (* 1 = 0.679554 loss)
I0905 03:20:24.275173 90901 sgd_solver.cpp:106] Iteration 9370, lr = 0.1
I0905 03:20:30.668431 90901 solver.cpp:228] Iteration 9380, loss = 0.291203
I0905 03:20:30.668694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291203 (* 1 = 0.291203 loss)
I0905 03:20:30.668722 90901 sgd_solver.cpp:106] Iteration 9380, lr = 0.1
I0905 03:20:36.302287 90901 solver.cpp:228] Iteration 9390, loss = 0.478611
I0905 03:20:36.302346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478611 (* 1 = 0.478611 loss)
I0905 03:20:36.302359 90901 sgd_solver.cpp:106] Iteration 9390, lr = 0.1
I0905 03:20:41.554138 90901 solver.cpp:228] Iteration 9400, loss = 0.448165
I0905 03:20:41.554194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448165 (* 1 = 0.448165 loss)
I0905 03:20:41.554209 90901 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0905 03:20:47.519928 90901 solver.cpp:228] Iteration 9410, loss = 0.456175
I0905 03:20:47.519976 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456175 (* 1 = 0.456175 loss)
I0905 03:20:47.519989 90901 sgd_solver.cpp:106] Iteration 9410, lr = 0.1
I0905 03:20:53.642494 90901 solver.cpp:228] Iteration 9420, loss = 0.330305
I0905 03:20:53.642573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330305 (* 1 = 0.330305 loss)
I0905 03:20:53.642596 90901 sgd_solver.cpp:106] Iteration 9420, lr = 0.1
I0905 03:21:00.029232 90901 solver.cpp:228] Iteration 9430, loss = 0.434452
I0905 03:21:00.029289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434452 (* 1 = 0.434452 loss)
I0905 03:21:00.029302 90901 sgd_solver.cpp:106] Iteration 9430, lr = 0.1
I0905 03:21:06.089692 90901 solver.cpp:228] Iteration 9440, loss = 0.320292
I0905 03:21:06.089825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320292 (* 1 = 0.320292 loss)
I0905 03:21:06.089840 90901 sgd_solver.cpp:106] Iteration 9440, lr = 0.1
I0905 03:21:12.179206 90901 solver.cpp:228] Iteration 9450, loss = 0.422167
I0905 03:21:12.179247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422167 (* 1 = 0.422167 loss)
I0905 03:21:12.179260 90901 sgd_solver.cpp:106] Iteration 9450, lr = 0.1
I0905 03:21:18.238524 90901 solver.cpp:228] Iteration 9460, loss = 0.391874
I0905 03:21:18.238587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391874 (* 1 = 0.391874 loss)
I0905 03:21:18.238602 90901 sgd_solver.cpp:106] Iteration 9460, lr = 0.1
I0905 03:21:24.623394 90901 solver.cpp:228] Iteration 9470, loss = 1.02542
I0905 03:21:24.623461 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.02542 (* 1 = 1.02542 loss)
I0905 03:21:24.623476 90901 sgd_solver.cpp:106] Iteration 9470, lr = 0.1
I0905 03:21:30.666496 90901 solver.cpp:228] Iteration 9480, loss = 0.456054
I0905 03:21:30.666548 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456054 (* 1 = 0.456054 loss)
I0905 03:21:30.666560 90901 sgd_solver.cpp:106] Iteration 9480, lr = 0.1
I0905 03:21:36.760448 90901 solver.cpp:228] Iteration 9490, loss = 0.229332
I0905 03:21:36.760591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229332 (* 1 = 0.229332 loss)
I0905 03:21:36.760622 90901 sgd_solver.cpp:106] Iteration 9490, lr = 0.1
I0905 03:21:42.817953 90901 solver.cpp:228] Iteration 9500, loss = 0.62335
I0905 03:21:42.817998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.62335 (* 1 = 0.62335 loss)
I0905 03:21:42.818013 90901 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0905 03:21:49.056386 90901 solver.cpp:228] Iteration 9510, loss = 0.126801
I0905 03:21:49.056435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126801 (* 1 = 0.126801 loss)
I0905 03:21:49.056450 90901 sgd_solver.cpp:106] Iteration 9510, lr = 0.1
I0905 03:21:54.932196 90901 solver.cpp:228] Iteration 9520, loss = 0.470422
I0905 03:21:54.932230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.470422 (* 1 = 0.470422 loss)
I0905 03:21:54.932245 90901 sgd_solver.cpp:106] Iteration 9520, lr = 0.1
I0905 03:22:00.985759 90901 solver.cpp:228] Iteration 9530, loss = 0.451086
I0905 03:22:00.985808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451086 (* 1 = 0.451086 loss)
I0905 03:22:00.985822 90901 sgd_solver.cpp:106] Iteration 9530, lr = 0.1
I0905 03:22:07.358266 90901 solver.cpp:228] Iteration 9540, loss = 0.381233
I0905 03:22:07.358479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381233 (* 1 = 0.381233 loss)
I0905 03:22:07.358518 90901 sgd_solver.cpp:106] Iteration 9540, lr = 0.1
I0905 03:22:13.454890 90901 solver.cpp:228] Iteration 9550, loss = 0.329883
I0905 03:22:13.454942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329883 (* 1 = 0.329883 loss)
I0905 03:22:13.454957 90901 sgd_solver.cpp:106] Iteration 9550, lr = 0.1
I0905 03:22:19.164175 90901 solver.cpp:228] Iteration 9560, loss = 0.589131
I0905 03:22:19.164245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.58913 (* 1 = 0.58913 loss)
I0905 03:22:19.164263 90901 sgd_solver.cpp:106] Iteration 9560, lr = 0.1
I0905 03:22:25.079753 90901 solver.cpp:228] Iteration 9570, loss = 0.720371
I0905 03:22:25.079805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.72037 (* 1 = 0.72037 loss)
I0905 03:22:25.079818 90901 sgd_solver.cpp:106] Iteration 9570, lr = 0.1
I0905 03:22:30.394737 90901 solver.cpp:228] Iteration 9580, loss = 0.497831
I0905 03:22:30.394785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.497831 (* 1 = 0.497831 loss)
I0905 03:22:30.394798 90901 sgd_solver.cpp:106] Iteration 9580, lr = 0.1
I0905 03:22:36.443388 90901 solver.cpp:228] Iteration 9590, loss = 0.273525
I0905 03:22:36.443444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273525 (* 1 = 0.273525 loss)
I0905 03:22:36.443456 90901 sgd_solver.cpp:106] Iteration 9590, lr = 0.1
I0905 03:22:42.266094 90901 solver.cpp:337] Iteration 9600, Testing net (#0)
I0905 03:23:24.428426 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.506562
I0905 03:23:24.428655 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.00426 (* 1 = 1.00426 loss)
I0905 03:23:24.857872 90901 solver.cpp:228] Iteration 9600, loss = 0.66536
I0905 03:23:24.857908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.66536 (* 1 = 0.66536 loss)
I0905 03:23:24.857925 90901 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0905 03:23:31.009667 90901 solver.cpp:228] Iteration 9610, loss = 0.62369
I0905 03:23:31.009711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.623689 (* 1 = 0.623689 loss)
I0905 03:23:31.009722 90901 sgd_solver.cpp:106] Iteration 9610, lr = 0.1
I0905 03:23:37.065480 90901 solver.cpp:228] Iteration 9620, loss = 0.455648
I0905 03:23:37.065539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455648 (* 1 = 0.455648 loss)
I0905 03:23:37.065554 90901 sgd_solver.cpp:106] Iteration 9620, lr = 0.1
I0905 03:23:43.412236 90901 solver.cpp:228] Iteration 9630, loss = 0.72301
I0905 03:23:43.412286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.72301 (* 1 = 0.72301 loss)
I0905 03:23:43.412300 90901 sgd_solver.cpp:106] Iteration 9630, lr = 0.1
I0905 03:23:49.542194 90901 solver.cpp:228] Iteration 9640, loss = 0.520895
I0905 03:23:49.542239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520894 (* 1 = 0.520894 loss)
I0905 03:23:49.542253 90901 sgd_solver.cpp:106] Iteration 9640, lr = 0.1
I0905 03:23:55.609755 90901 solver.cpp:228] Iteration 9650, loss = 0.465818
I0905 03:23:55.609989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465817 (* 1 = 0.465817 loss)
I0905 03:23:55.610002 90901 sgd_solver.cpp:106] Iteration 9650, lr = 0.1
I0905 03:24:01.728324 90901 solver.cpp:228] Iteration 9660, loss = 0.284039
I0905 03:24:01.728379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284039 (* 1 = 0.284039 loss)
I0905 03:24:01.728394 90901 sgd_solver.cpp:106] Iteration 9660, lr = 0.1
I0905 03:24:07.962759 90901 solver.cpp:228] Iteration 9670, loss = 0.337103
I0905 03:24:07.962810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337102 (* 1 = 0.337102 loss)
I0905 03:24:07.962828 90901 sgd_solver.cpp:106] Iteration 9670, lr = 0.1
I0905 03:24:13.449133 90901 solver.cpp:228] Iteration 9680, loss = 0.293478
I0905 03:24:13.449218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293478 (* 1 = 0.293478 loss)
I0905 03:24:13.449246 90901 sgd_solver.cpp:106] Iteration 9680, lr = 0.1
I0905 03:24:18.764528 90901 solver.cpp:228] Iteration 9690, loss = 0.535588
I0905 03:24:18.764596 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535588 (* 1 = 0.535588 loss)
I0905 03:24:18.764611 90901 sgd_solver.cpp:106] Iteration 9690, lr = 0.1
I0905 03:24:23.799980 90901 solver.cpp:228] Iteration 9700, loss = 1.11188
I0905 03:24:23.800043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.11188 (* 1 = 1.11188 loss)
I0905 03:24:23.800060 90901 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0905 03:24:28.849467 90901 solver.cpp:228] Iteration 9710, loss = 0.420038
I0905 03:24:28.849649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.420038 (* 1 = 0.420038 loss)
I0905 03:24:28.849687 90901 sgd_solver.cpp:106] Iteration 9710, lr = 0.1
I0905 03:24:33.860168 90901 solver.cpp:228] Iteration 9720, loss = 0.328744
I0905 03:24:33.860216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328744 (* 1 = 0.328744 loss)
I0905 03:24:33.860230 90901 sgd_solver.cpp:106] Iteration 9720, lr = 0.1
I0905 03:24:38.901620 90901 solver.cpp:228] Iteration 9730, loss = 0.484895
I0905 03:24:38.901677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484895 (* 1 = 0.484895 loss)
I0905 03:24:38.901691 90901 sgd_solver.cpp:106] Iteration 9730, lr = 0.1
I0905 03:24:43.971660 90901 solver.cpp:228] Iteration 9740, loss = 0.305464
I0905 03:24:43.971698 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305464 (* 1 = 0.305464 loss)
I0905 03:24:43.971710 90901 sgd_solver.cpp:106] Iteration 9740, lr = 0.1
I0905 03:24:48.981130 90901 solver.cpp:228] Iteration 9750, loss = 0.407586
I0905 03:24:48.981184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407586 (* 1 = 0.407586 loss)
I0905 03:24:48.981196 90901 sgd_solver.cpp:106] Iteration 9750, lr = 0.1
I0905 03:24:53.983716 90901 solver.cpp:228] Iteration 9760, loss = 0.390324
I0905 03:24:53.983770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390323 (* 1 = 0.390323 loss)
I0905 03:24:53.983784 90901 sgd_solver.cpp:106] Iteration 9760, lr = 0.1
I0905 03:24:59.011529 90901 solver.cpp:228] Iteration 9770, loss = 0.257805
I0905 03:24:59.011728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257804 (* 1 = 0.257804 loss)
I0905 03:24:59.011744 90901 sgd_solver.cpp:106] Iteration 9770, lr = 0.1
I0905 03:25:04.062000 90901 solver.cpp:228] Iteration 9780, loss = 0.33339
I0905 03:25:04.062053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33339 (* 1 = 0.33339 loss)
I0905 03:25:04.062068 90901 sgd_solver.cpp:106] Iteration 9780, lr = 0.1
I0905 03:25:09.094398 90901 solver.cpp:228] Iteration 9790, loss = 0.256504
I0905 03:25:09.094468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256503 (* 1 = 0.256503 loss)
I0905 03:25:09.094483 90901 sgd_solver.cpp:106] Iteration 9790, lr = 0.1
I0905 03:25:14.121466 90901 solver.cpp:228] Iteration 9800, loss = 0.211921
I0905 03:25:14.121536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211921 (* 1 = 0.211921 loss)
I0905 03:25:14.121553 90901 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0905 03:25:19.161564 90901 solver.cpp:228] Iteration 9810, loss = 0.528499
I0905 03:25:19.161608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528499 (* 1 = 0.528499 loss)
I0905 03:25:19.161622 90901 sgd_solver.cpp:106] Iteration 9810, lr = 0.1
I0905 03:25:24.185622 90901 solver.cpp:228] Iteration 9820, loss = 0.294188
I0905 03:25:24.185675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294188 (* 1 = 0.294188 loss)
I0905 03:25:24.185691 90901 sgd_solver.cpp:106] Iteration 9820, lr = 0.1
I0905 03:25:29.246475 90901 solver.cpp:228] Iteration 9830, loss = 0.443221
I0905 03:25:29.246742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443221 (* 1 = 0.443221 loss)
I0905 03:25:29.246757 90901 sgd_solver.cpp:106] Iteration 9830, lr = 0.1
I0905 03:25:34.285208 90901 solver.cpp:228] Iteration 9840, loss = 0.641727
I0905 03:25:34.285254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.641727 (* 1 = 0.641727 loss)
I0905 03:25:34.285269 90901 sgd_solver.cpp:106] Iteration 9840, lr = 0.1
I0905 03:25:39.327277 90901 solver.cpp:228] Iteration 9850, loss = 0.367333
I0905 03:25:39.327337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367333 (* 1 = 0.367333 loss)
I0905 03:25:39.327353 90901 sgd_solver.cpp:106] Iteration 9850, lr = 0.1
I0905 03:25:45.722368 90901 solver.cpp:228] Iteration 9860, loss = 0.4302
I0905 03:25:45.722424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4302 (* 1 = 0.4302 loss)
I0905 03:25:45.722442 90901 sgd_solver.cpp:106] Iteration 9860, lr = 0.1
I0905 03:25:51.764596 90901 solver.cpp:228] Iteration 9870, loss = 0.207396
I0905 03:25:51.764674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207396 (* 1 = 0.207396 loss)
I0905 03:25:51.764691 90901 sgd_solver.cpp:106] Iteration 9870, lr = 0.1
I0905 03:25:58.053699 90901 solver.cpp:228] Iteration 9880, loss = 0.293068
I0905 03:25:58.053753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293067 (* 1 = 0.293067 loss)
I0905 03:25:58.053767 90901 sgd_solver.cpp:106] Iteration 9880, lr = 0.1
I0905 03:26:04.061307 90901 solver.cpp:228] Iteration 9890, loss = 0.214577
I0905 03:26:04.061512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214577 (* 1 = 0.214577 loss)
I0905 03:26:04.061534 90901 sgd_solver.cpp:106] Iteration 9890, lr = 0.1
I0905 03:26:09.015359 90901 solver.cpp:228] Iteration 9900, loss = 0.418428
I0905 03:26:09.015408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418428 (* 1 = 0.418428 loss)
I0905 03:26:09.015419 90901 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0905 03:26:14.992884 90901 solver.cpp:228] Iteration 9910, loss = 0.386139
I0905 03:26:14.992944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386139 (* 1 = 0.386139 loss)
I0905 03:26:14.992956 90901 sgd_solver.cpp:106] Iteration 9910, lr = 0.1
I0905 03:26:20.946182 90901 solver.cpp:228] Iteration 9920, loss = 0.436467
I0905 03:26:20.946234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436467 (* 1 = 0.436467 loss)
I0905 03:26:20.946249 90901 sgd_solver.cpp:106] Iteration 9920, lr = 0.1
I0905 03:26:27.085053 90901 solver.cpp:228] Iteration 9930, loss = 0.313886
I0905 03:26:27.085101 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313885 (* 1 = 0.313885 loss)
I0905 03:26:27.085114 90901 sgd_solver.cpp:106] Iteration 9930, lr = 0.1
I0905 03:26:33.250404 90901 solver.cpp:228] Iteration 9940, loss = 0.35453
I0905 03:26:33.250475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35453 (* 1 = 0.35453 loss)
I0905 03:26:33.250491 90901 sgd_solver.cpp:106] Iteration 9940, lr = 0.1
I0905 03:26:39.488371 90901 solver.cpp:228] Iteration 9950, loss = 0.169777
I0905 03:26:39.488581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169777 (* 1 = 0.169777 loss)
I0905 03:26:39.488612 90901 sgd_solver.cpp:106] Iteration 9950, lr = 0.1
I0905 03:26:45.585784 90901 solver.cpp:228] Iteration 9960, loss = 0.416593
I0905 03:26:45.585844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416592 (* 1 = 0.416592 loss)
I0905 03:26:45.585860 90901 sgd_solver.cpp:106] Iteration 9960, lr = 0.1
I0905 03:26:51.324870 90901 solver.cpp:228] Iteration 9970, loss = 0.370765
I0905 03:26:51.324915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370765 (* 1 = 0.370765 loss)
I0905 03:26:51.324928 90901 sgd_solver.cpp:106] Iteration 9970, lr = 0.1
I0905 03:26:57.709753 90901 solver.cpp:228] Iteration 9980, loss = 0.293182
I0905 03:26:57.709821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293182 (* 1 = 0.293182 loss)
I0905 03:26:57.709837 90901 sgd_solver.cpp:106] Iteration 9980, lr = 0.1
I0905 03:27:03.756613 90901 solver.cpp:228] Iteration 9990, loss = 0.504443
I0905 03:27:03.756665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504443 (* 1 = 0.504443 loss)
I0905 03:27:03.756680 90901 sgd_solver.cpp:106] Iteration 9990, lr = 0.1
I0905 03:27:09.802971 90901 solver.cpp:228] Iteration 10000, loss = 0.289721
I0905 03:27:09.803128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289721 (* 1 = 0.289721 loss)
I0905 03:27:09.803155 90901 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0905 03:27:15.531790 90901 solver.cpp:228] Iteration 10010, loss = 0.328215
I0905 03:27:15.531834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328215 (* 1 = 0.328215 loss)
I0905 03:27:15.531848 90901 sgd_solver.cpp:106] Iteration 10010, lr = 0.1
I0905 03:27:22.257488 90901 solver.cpp:228] Iteration 10020, loss = 0.349793
I0905 03:27:22.257524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349793 (* 1 = 0.349793 loss)
I0905 03:27:22.257537 90901 sgd_solver.cpp:106] Iteration 10020, lr = 0.1
I0905 03:27:28.285768 90901 solver.cpp:228] Iteration 10030, loss = 0.426881
I0905 03:27:28.285835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426881 (* 1 = 0.426881 loss)
I0905 03:27:28.285850 90901 sgd_solver.cpp:106] Iteration 10030, lr = 0.1
I0905 03:27:34.327342 90901 solver.cpp:228] Iteration 10040, loss = 0.524515
I0905 03:27:34.327388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.524515 (* 1 = 0.524515 loss)
I0905 03:27:34.327400 90901 sgd_solver.cpp:106] Iteration 10040, lr = 0.1
I0905 03:27:40.402052 90901 solver.cpp:228] Iteration 10050, loss = 0.55047
I0905 03:27:40.402297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.550469 (* 1 = 0.550469 loss)
I0905 03:27:40.402318 90901 sgd_solver.cpp:106] Iteration 10050, lr = 0.1
I0905 03:27:46.447221 90901 solver.cpp:228] Iteration 10060, loss = 0.591312
I0905 03:27:46.447279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.591312 (* 1 = 0.591312 loss)
I0905 03:27:46.447293 90901 sgd_solver.cpp:106] Iteration 10060, lr = 0.1
I0905 03:27:52.661615 90901 solver.cpp:228] Iteration 10070, loss = 0.392106
I0905 03:27:52.661669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392106 (* 1 = 0.392106 loss)
I0905 03:27:52.661685 90901 sgd_solver.cpp:106] Iteration 10070, lr = 0.1
I0905 03:27:58.234446 90901 solver.cpp:228] Iteration 10080, loss = 0.266385
I0905 03:27:58.234491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266385 (* 1 = 0.266385 loss)
I0905 03:27:58.234505 90901 sgd_solver.cpp:106] Iteration 10080, lr = 0.1
I0905 03:28:03.638638 90901 solver.cpp:228] Iteration 10090, loss = 0.43057
I0905 03:28:03.638700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43057 (* 1 = 0.43057 loss)
I0905 03:28:03.638715 90901 sgd_solver.cpp:106] Iteration 10090, lr = 0.1
I0905 03:28:09.719988 90901 solver.cpp:228] Iteration 10100, loss = 0.59784
I0905 03:28:09.720037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59784 (* 1 = 0.59784 loss)
I0905 03:28:09.720052 90901 sgd_solver.cpp:106] Iteration 10100, lr = 0.1
I0905 03:28:15.791479 90901 solver.cpp:228] Iteration 10110, loss = 0.306157
I0905 03:28:15.791717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306157 (* 1 = 0.306157 loss)
I0905 03:28:15.791734 90901 sgd_solver.cpp:106] Iteration 10110, lr = 0.1
I0905 03:28:21.857759 90901 solver.cpp:228] Iteration 10120, loss = 0.268958
I0905 03:28:21.857821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268957 (* 1 = 0.268957 loss)
I0905 03:28:21.857837 90901 sgd_solver.cpp:106] Iteration 10120, lr = 0.1
I0905 03:28:27.887473 90901 solver.cpp:228] Iteration 10130, loss = 0.329372
I0905 03:28:27.887540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329372 (* 1 = 0.329372 loss)
I0905 03:28:27.887555 90901 sgd_solver.cpp:106] Iteration 10130, lr = 0.1
I0905 03:28:33.971932 90901 solver.cpp:228] Iteration 10140, loss = 0.387995
I0905 03:28:33.971998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387995 (* 1 = 0.387995 loss)
I0905 03:28:33.972012 90901 sgd_solver.cpp:106] Iteration 10140, lr = 0.1
I0905 03:28:40.064043 90901 solver.cpp:228] Iteration 10150, loss = 0.772076
I0905 03:28:40.064101 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.772076 (* 1 = 0.772076 loss)
I0905 03:28:40.064119 90901 sgd_solver.cpp:106] Iteration 10150, lr = 0.1
I0905 03:28:46.455888 90901 solver.cpp:228] Iteration 10160, loss = 0.284388
I0905 03:28:46.456061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284388 (* 1 = 0.284388 loss)
I0905 03:28:46.456082 90901 sgd_solver.cpp:106] Iteration 10160, lr = 0.1
I0905 03:28:52.271477 90901 solver.cpp:228] Iteration 10170, loss = 0.327502
I0905 03:28:52.271523 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327502 (* 1 = 0.327502 loss)
I0905 03:28:52.271536 90901 sgd_solver.cpp:106] Iteration 10170, lr = 0.1
I0905 03:28:58.296802 90901 solver.cpp:228] Iteration 10180, loss = 0.283243
I0905 03:28:58.296875 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283243 (* 1 = 0.283243 loss)
I0905 03:28:58.296902 90901 sgd_solver.cpp:106] Iteration 10180, lr = 0.1
I0905 03:29:04.699575 90901 solver.cpp:228] Iteration 10190, loss = 0.265643
I0905 03:29:04.699638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265642 (* 1 = 0.265642 loss)
I0905 03:29:04.699653 90901 sgd_solver.cpp:106] Iteration 10190, lr = 0.1
I0905 03:29:10.773545 90901 solver.cpp:228] Iteration 10200, loss = 0.637405
I0905 03:29:10.773591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.637405 (* 1 = 0.637405 loss)
I0905 03:29:10.773604 90901 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0905 03:29:16.892606 90901 solver.cpp:228] Iteration 10210, loss = 0.316372
I0905 03:29:16.892740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316372 (* 1 = 0.316372 loss)
I0905 03:29:16.892783 90901 sgd_solver.cpp:106] Iteration 10210, lr = 0.1
I0905 03:29:23.073820 90901 solver.cpp:228] Iteration 10220, loss = 0.353897
I0905 03:29:23.073887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353897 (* 1 = 0.353897 loss)
I0905 03:29:23.073904 90901 sgd_solver.cpp:106] Iteration 10220, lr = 0.1
I0905 03:29:29.326226 90901 solver.cpp:228] Iteration 10230, loss = 0.273049
I0905 03:29:29.326277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273049 (* 1 = 0.273049 loss)
I0905 03:29:29.326290 90901 sgd_solver.cpp:106] Iteration 10230, lr = 0.1
I0905 03:29:35.171669 90901 solver.cpp:228] Iteration 10240, loss = 0.356552
I0905 03:29:35.171731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356552 (* 1 = 0.356552 loss)
I0905 03:29:35.171746 90901 sgd_solver.cpp:106] Iteration 10240, lr = 0.1
I0905 03:29:41.280030 90901 solver.cpp:228] Iteration 10250, loss = 0.529483
I0905 03:29:41.280104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529483 (* 1 = 0.529483 loss)
I0905 03:29:41.280123 90901 sgd_solver.cpp:106] Iteration 10250, lr = 0.1
I0905 03:29:46.528136 90901 solver.cpp:228] Iteration 10260, loss = 0.461773
I0905 03:29:46.528188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461772 (* 1 = 0.461772 loss)
I0905 03:29:46.528203 90901 sgd_solver.cpp:106] Iteration 10260, lr = 0.1
I0905 03:29:52.138535 90901 solver.cpp:228] Iteration 10270, loss = 0.450508
I0905 03:29:52.138818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450508 (* 1 = 0.450508 loss)
I0905 03:29:52.138836 90901 sgd_solver.cpp:106] Iteration 10270, lr = 0.1
I0905 03:29:58.559674 90901 solver.cpp:228] Iteration 10280, loss = 0.324763
I0905 03:29:58.559738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324763 (* 1 = 0.324763 loss)
I0905 03:29:58.559754 90901 sgd_solver.cpp:106] Iteration 10280, lr = 0.1
I0905 03:30:04.322901 90901 solver.cpp:228] Iteration 10290, loss = 0.238418
I0905 03:30:04.322957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238418 (* 1 = 0.238418 loss)
I0905 03:30:04.322971 90901 sgd_solver.cpp:106] Iteration 10290, lr = 0.1
I0905 03:30:10.731101 90901 solver.cpp:228] Iteration 10300, loss = 0.202303
I0905 03:30:10.731153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202302 (* 1 = 0.202302 loss)
I0905 03:30:10.731166 90901 sgd_solver.cpp:106] Iteration 10300, lr = 0.1
I0905 03:30:16.201589 90901 solver.cpp:228] Iteration 10310, loss = 0.661423
I0905 03:30:16.201652 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.661423 (* 1 = 0.661423 loss)
I0905 03:30:16.201664 90901 sgd_solver.cpp:106] Iteration 10310, lr = 0.1
I0905 03:30:22.599159 90901 solver.cpp:228] Iteration 10320, loss = 0.439724
I0905 03:30:22.599427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439724 (* 1 = 0.439724 loss)
I0905 03:30:22.599444 90901 sgd_solver.cpp:106] Iteration 10320, lr = 0.1
I0905 03:30:28.680197 90901 solver.cpp:228] Iteration 10330, loss = 0.354134
I0905 03:30:28.680274 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354134 (* 1 = 0.354134 loss)
I0905 03:30:28.680296 90901 sgd_solver.cpp:106] Iteration 10330, lr = 0.1
I0905 03:30:34.805048 90901 solver.cpp:228] Iteration 10340, loss = 0.361742
I0905 03:30:34.805107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361741 (* 1 = 0.361741 loss)
I0905 03:30:34.805122 90901 sgd_solver.cpp:106] Iteration 10340, lr = 0.1
I0905 03:30:41.196337 90901 solver.cpp:228] Iteration 10350, loss = 0.234785
I0905 03:30:41.196395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234785 (* 1 = 0.234785 loss)
I0905 03:30:41.196411 90901 sgd_solver.cpp:106] Iteration 10350, lr = 0.1
I0905 03:30:46.985152 90901 solver.cpp:228] Iteration 10360, loss = 0.388084
I0905 03:30:46.985205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388084 (* 1 = 0.388084 loss)
I0905 03:30:46.985221 90901 sgd_solver.cpp:106] Iteration 10360, lr = 0.1
I0905 03:30:53.036150 90901 solver.cpp:228] Iteration 10370, loss = 0.329727
I0905 03:30:53.036335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329727 (* 1 = 0.329727 loss)
I0905 03:30:53.036360 90901 sgd_solver.cpp:106] Iteration 10370, lr = 0.1
I0905 03:30:59.448783 90901 solver.cpp:228] Iteration 10380, loss = 0.456384
I0905 03:30:59.448843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456384 (* 1 = 0.456384 loss)
I0905 03:30:59.448858 90901 sgd_solver.cpp:106] Iteration 10380, lr = 0.1
I0905 03:31:05.195988 90901 solver.cpp:228] Iteration 10390, loss = 0.25214
I0905 03:31:05.196064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25214 (* 1 = 0.25214 loss)
I0905 03:31:05.196080 90901 sgd_solver.cpp:106] Iteration 10390, lr = 0.1
I0905 03:31:11.378239 90901 solver.cpp:337] Iteration 10400, Testing net (#0)
I0905 03:31:52.559732 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.5025
I0905 03:31:52.559885 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.60784 (* 1 = 1.60784 loss)
I0905 03:31:52.775977 90901 solver.cpp:228] Iteration 10400, loss = 0.492113
I0905 03:31:52.776048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492112 (* 1 = 0.492112 loss)
I0905 03:31:52.776064 90901 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0905 03:31:58.957468 90901 solver.cpp:228] Iteration 10410, loss = 0.514044
I0905 03:31:58.957531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514044 (* 1 = 0.514044 loss)
I0905 03:31:58.957546 90901 sgd_solver.cpp:106] Iteration 10410, lr = 0.1
I0905 03:32:05.251096 90901 solver.cpp:228] Iteration 10420, loss = 0.430195
I0905 03:32:05.251171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430194 (* 1 = 0.430194 loss)
I0905 03:32:05.251188 90901 sgd_solver.cpp:106] Iteration 10420, lr = 0.1
I0905 03:32:11.007899 90901 solver.cpp:228] Iteration 10430, loss = 0.460173
I0905 03:32:11.007969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460172 (* 1 = 0.460172 loss)
I0905 03:32:11.007985 90901 sgd_solver.cpp:106] Iteration 10430, lr = 0.1
I0905 03:32:17.135285 90901 solver.cpp:228] Iteration 10440, loss = 0.337755
I0905 03:32:17.135359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337755 (* 1 = 0.337755 loss)
I0905 03:32:17.135375 90901 sgd_solver.cpp:106] Iteration 10440, lr = 0.1
I0905 03:32:23.286686 90901 solver.cpp:228] Iteration 10450, loss = 0.507874
I0905 03:32:23.287250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507874 (* 1 = 0.507874 loss)
I0905 03:32:23.287266 90901 sgd_solver.cpp:106] Iteration 10450, lr = 0.1
I0905 03:32:29.325669 90901 solver.cpp:228] Iteration 10460, loss = 0.525431
I0905 03:32:29.325736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.52543 (* 1 = 0.52543 loss)
I0905 03:32:29.325750 90901 sgd_solver.cpp:106] Iteration 10460, lr = 0.1
I0905 03:32:35.311074 90901 solver.cpp:228] Iteration 10470, loss = 0.564002
I0905 03:32:35.311131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.564002 (* 1 = 0.564002 loss)
I0905 03:32:35.311147 90901 sgd_solver.cpp:106] Iteration 10470, lr = 0.1
I0905 03:32:41.382360 90901 solver.cpp:228] Iteration 10480, loss = 0.332536
I0905 03:32:41.382433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332536 (* 1 = 0.332536 loss)
I0905 03:32:41.382449 90901 sgd_solver.cpp:106] Iteration 10480, lr = 0.1
I0905 03:32:47.772356 90901 solver.cpp:228] Iteration 10490, loss = 0.51169
I0905 03:32:47.772403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.51169 (* 1 = 0.51169 loss)
I0905 03:32:47.772416 90901 sgd_solver.cpp:106] Iteration 10490, lr = 0.1
I0905 03:32:53.863183 90901 solver.cpp:228] Iteration 10500, loss = 0.369418
I0905 03:32:53.863378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369418 (* 1 = 0.369418 loss)
I0905 03:32:53.863409 90901 sgd_solver.cpp:106] Iteration 10500, lr = 0.1
I0905 03:32:59.912817 90901 solver.cpp:228] Iteration 10510, loss = 0.360525
I0905 03:32:59.912878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360525 (* 1 = 0.360525 loss)
I0905 03:32:59.912892 90901 sgd_solver.cpp:106] Iteration 10510, lr = 0.1
I0905 03:33:06.026191 90901 solver.cpp:228] Iteration 10520, loss = 0.385513
I0905 03:33:06.026252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385513 (* 1 = 0.385513 loss)
I0905 03:33:06.026268 90901 sgd_solver.cpp:106] Iteration 10520, lr = 0.1
I0905 03:33:11.860046 90901 solver.cpp:228] Iteration 10530, loss = 0.410187
I0905 03:33:11.860133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410187 (* 1 = 0.410187 loss)
I0905 03:33:11.860159 90901 sgd_solver.cpp:106] Iteration 10530, lr = 0.1
I0905 03:33:17.110306 90901 solver.cpp:228] Iteration 10540, loss = 0.532013
I0905 03:33:17.110369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.532013 (* 1 = 0.532013 loss)
I0905 03:33:17.110385 90901 sgd_solver.cpp:106] Iteration 10540, lr = 0.1
I0905 03:33:22.951395 90901 solver.cpp:228] Iteration 10550, loss = 0.346956
I0905 03:33:22.951462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346955 (* 1 = 0.346955 loss)
I0905 03:33:22.951477 90901 sgd_solver.cpp:106] Iteration 10550, lr = 0.1
I0905 03:33:29.350193 90901 solver.cpp:228] Iteration 10560, loss = 1.1713
I0905 03:33:29.350426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.1713 (* 1 = 1.1713 loss)
I0905 03:33:29.350445 90901 sgd_solver.cpp:106] Iteration 10560, lr = 0.1
I0905 03:33:35.426090 90901 solver.cpp:228] Iteration 10570, loss = 0.472846
I0905 03:33:35.426136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472846 (* 1 = 0.472846 loss)
I0905 03:33:35.426151 90901 sgd_solver.cpp:106] Iteration 10570, lr = 0.1
I0905 03:33:41.462839 90901 solver.cpp:228] Iteration 10580, loss = 0.353445
I0905 03:33:41.462898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353445 (* 1 = 0.353445 loss)
I0905 03:33:41.462914 90901 sgd_solver.cpp:106] Iteration 10580, lr = 0.1
I0905 03:33:47.578699 90901 solver.cpp:228] Iteration 10590, loss = 0.406696
I0905 03:33:47.578770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406696 (* 1 = 0.406696 loss)
I0905 03:33:47.578786 90901 sgd_solver.cpp:106] Iteration 10590, lr = 0.1
I0905 03:33:53.679289 90901 solver.cpp:228] Iteration 10600, loss = 0.379656
I0905 03:33:53.679390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379656 (* 1 = 0.379656 loss)
I0905 03:33:53.679406 90901 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0905 03:33:59.455647 90901 solver.cpp:228] Iteration 10610, loss = 0.338268
I0905 03:33:59.455857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338267 (* 1 = 0.338267 loss)
I0905 03:33:59.455873 90901 sgd_solver.cpp:106] Iteration 10610, lr = 0.1
I0905 03:34:05.513418 90901 solver.cpp:228] Iteration 10620, loss = 0.450718
I0905 03:34:05.513478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450718 (* 1 = 0.450718 loss)
I0905 03:34:05.513494 90901 sgd_solver.cpp:106] Iteration 10620, lr = 0.1
I0905 03:34:11.623371 90901 solver.cpp:228] Iteration 10630, loss = 0.293802
I0905 03:34:11.623412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293802 (* 1 = 0.293802 loss)
I0905 03:34:11.623425 90901 sgd_solver.cpp:106] Iteration 10630, lr = 0.1
I0905 03:34:17.699803 90901 solver.cpp:228] Iteration 10640, loss = 0.666842
I0905 03:34:17.699877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.666842 (* 1 = 0.666842 loss)
I0905 03:34:17.699893 90901 sgd_solver.cpp:106] Iteration 10640, lr = 0.1
I0905 03:34:23.791005 90901 solver.cpp:228] Iteration 10650, loss = 0.388009
I0905 03:34:23.791067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388009 (* 1 = 0.388009 loss)
I0905 03:34:23.791080 90901 sgd_solver.cpp:106] Iteration 10650, lr = 0.1
I0905 03:34:29.875803 90901 solver.cpp:228] Iteration 10660, loss = 0.401572
I0905 03:34:29.876027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401572 (* 1 = 0.401572 loss)
I0905 03:34:29.876047 90901 sgd_solver.cpp:106] Iteration 10660, lr = 0.1
I0905 03:34:35.936993 90901 solver.cpp:228] Iteration 10670, loss = 0.656684
I0905 03:34:35.937031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.656684 (* 1 = 0.656684 loss)
I0905 03:34:35.937047 90901 sgd_solver.cpp:106] Iteration 10670, lr = 0.1
I0905 03:34:42.295794 90901 solver.cpp:228] Iteration 10680, loss = 0.488344
I0905 03:34:42.295850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488343 (* 1 = 0.488343 loss)
I0905 03:34:42.295864 90901 sgd_solver.cpp:106] Iteration 10680, lr = 0.1
I0905 03:34:48.361152 90901 solver.cpp:228] Iteration 10690, loss = 0.541589
I0905 03:34:48.361203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541589 (* 1 = 0.541589 loss)
I0905 03:34:48.361213 90901 sgd_solver.cpp:106] Iteration 10690, lr = 0.1
I0905 03:34:54.440589 90901 solver.cpp:228] Iteration 10700, loss = 0.308602
I0905 03:34:54.440644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308602 (* 1 = 0.308602 loss)
I0905 03:34:54.440659 90901 sgd_solver.cpp:106] Iteration 10700, lr = 0.1
I0905 03:34:59.771158 90901 solver.cpp:228] Iteration 10710, loss = 0.603255
I0905 03:34:59.771219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.603255 (* 1 = 0.603255 loss)
I0905 03:34:59.771234 90901 sgd_solver.cpp:106] Iteration 10710, lr = 0.1
I0905 03:35:05.326313 90901 solver.cpp:228] Iteration 10720, loss = 0.268093
I0905 03:35:05.326566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268093 (* 1 = 0.268093 loss)
I0905 03:35:05.326583 90901 sgd_solver.cpp:106] Iteration 10720, lr = 0.1
I0905 03:35:11.376971 90901 solver.cpp:228] Iteration 10730, loss = 0.547885
I0905 03:35:11.377027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547884 (* 1 = 0.547884 loss)
I0905 03:35:11.377043 90901 sgd_solver.cpp:106] Iteration 10730, lr = 0.1
I0905 03:35:17.091018 90901 solver.cpp:228] Iteration 10740, loss = 0.805381
I0905 03:35:17.091069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.805381 (* 1 = 0.805381 loss)
I0905 03:35:17.091084 90901 sgd_solver.cpp:106] Iteration 10740, lr = 0.1
I0905 03:35:23.806406 90901 solver.cpp:228] Iteration 10750, loss = 0.390326
I0905 03:35:23.806449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390326 (* 1 = 0.390326 loss)
I0905 03:35:23.806463 90901 sgd_solver.cpp:106] Iteration 10750, lr = 0.1
I0905 03:35:29.843233 90901 solver.cpp:228] Iteration 10760, loss = 0.40804
I0905 03:35:29.843277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40804 (* 1 = 0.40804 loss)
I0905 03:35:29.843291 90901 sgd_solver.cpp:106] Iteration 10760, lr = 0.1
I0905 03:35:35.581719 90901 solver.cpp:228] Iteration 10770, loss = 0.170278
I0905 03:35:35.581877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170278 (* 1 = 0.170278 loss)
I0905 03:35:35.581930 90901 sgd_solver.cpp:106] Iteration 10770, lr = 0.1
I0905 03:35:41.922070 90901 solver.cpp:228] Iteration 10780, loss = 0.734258
I0905 03:35:41.922130 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.734257 (* 1 = 0.734257 loss)
I0905 03:35:41.922144 90901 sgd_solver.cpp:106] Iteration 10780, lr = 0.1
I0905 03:35:47.976783 90901 solver.cpp:228] Iteration 10790, loss = 0.812719
I0905 03:35:47.976847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.812719 (* 1 = 0.812719 loss)
I0905 03:35:47.976861 90901 sgd_solver.cpp:106] Iteration 10790, lr = 0.1
I0905 03:35:53.996994 90901 solver.cpp:228] Iteration 10800, loss = 0.48575
I0905 03:35:53.997031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48575 (* 1 = 0.48575 loss)
I0905 03:35:53.997046 90901 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0905 03:36:00.318594 90901 solver.cpp:228] Iteration 10810, loss = 0.482549
I0905 03:36:00.318650 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482549 (* 1 = 0.482549 loss)
I0905 03:36:00.318678 90901 sgd_solver.cpp:106] Iteration 10810, lr = 0.1
I0905 03:36:06.366947 90901 solver.cpp:228] Iteration 10820, loss = 0.299817
I0905 03:36:06.367143 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299817 (* 1 = 0.299817 loss)
I0905 03:36:06.367185 90901 sgd_solver.cpp:106] Iteration 10820, lr = 0.1
I0905 03:36:12.637719 90901 solver.cpp:228] Iteration 10830, loss = 0.373297
I0905 03:36:12.637786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373296 (* 1 = 0.373296 loss)
I0905 03:36:12.637802 90901 sgd_solver.cpp:106] Iteration 10830, lr = 0.1
I0905 03:36:18.767859 90901 solver.cpp:228] Iteration 10840, loss = 0.38765
I0905 03:36:18.767915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38765 (* 1 = 0.38765 loss)
I0905 03:36:18.767930 90901 sgd_solver.cpp:106] Iteration 10840, lr = 0.1
I0905 03:36:24.798177 90901 solver.cpp:228] Iteration 10850, loss = 0.357995
I0905 03:36:24.798215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357995 (* 1 = 0.357995 loss)
I0905 03:36:24.798228 90901 sgd_solver.cpp:106] Iteration 10850, lr = 0.1
I0905 03:36:31.070395 90901 solver.cpp:228] Iteration 10860, loss = 0.286927
I0905 03:36:31.070444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286927 (* 1 = 0.286927 loss)
I0905 03:36:31.070459 90901 sgd_solver.cpp:106] Iteration 10860, lr = 0.1
I0905 03:36:37.226266 90901 solver.cpp:228] Iteration 10870, loss = 0.209177
I0905 03:36:37.226507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209177 (* 1 = 0.209177 loss)
I0905 03:36:37.226543 90901 sgd_solver.cpp:106] Iteration 10870, lr = 0.1
I0905 03:36:42.945210 90901 solver.cpp:228] Iteration 10880, loss = 0.2336
I0905 03:36:42.945269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2336 (* 1 = 0.2336 loss)
I0905 03:36:42.945284 90901 sgd_solver.cpp:106] Iteration 10880, lr = 0.1
I0905 03:36:48.764459 90901 solver.cpp:228] Iteration 10890, loss = 0.313
I0905 03:36:48.764535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313 (* 1 = 0.313 loss)
I0905 03:36:48.764552 90901 sgd_solver.cpp:106] Iteration 10890, lr = 0.1
I0905 03:36:54.313591 90901 solver.cpp:228] Iteration 10900, loss = 0.620875
I0905 03:36:54.313642 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.620874 (* 1 = 0.620874 loss)
I0905 03:36:54.313657 90901 sgd_solver.cpp:106] Iteration 10900, lr = 0.1
I0905 03:37:00.222554 90901 solver.cpp:228] Iteration 10910, loss = 0.278801
I0905 03:37:00.222601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278801 (* 1 = 0.278801 loss)
I0905 03:37:00.222620 90901 sgd_solver.cpp:106] Iteration 10910, lr = 0.1
I0905 03:37:06.177448 90901 solver.cpp:228] Iteration 10920, loss = 0.430806
I0905 03:37:06.177492 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430806 (* 1 = 0.430806 loss)
I0905 03:37:06.177505 90901 sgd_solver.cpp:106] Iteration 10920, lr = 0.1
I0905 03:37:12.327924 90901 solver.cpp:228] Iteration 10930, loss = 0.281442
I0905 03:37:12.328073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281442 (* 1 = 0.281442 loss)
I0905 03:37:12.328115 90901 sgd_solver.cpp:106] Iteration 10930, lr = 0.1
I0905 03:37:18.420351 90901 solver.cpp:228] Iteration 10940, loss = 0.31758
I0905 03:37:18.420415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31758 (* 1 = 0.31758 loss)
I0905 03:37:18.420429 90901 sgd_solver.cpp:106] Iteration 10940, lr = 0.1
I0905 03:37:24.496282 90901 solver.cpp:228] Iteration 10950, loss = 0.267475
I0905 03:37:24.496345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267475 (* 1 = 0.267475 loss)
I0905 03:37:24.496358 90901 sgd_solver.cpp:106] Iteration 10950, lr = 0.1
I0905 03:37:30.555047 90901 solver.cpp:228] Iteration 10960, loss = 0.427394
I0905 03:37:30.556401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427394 (* 1 = 0.427394 loss)
I0905 03:37:30.556421 90901 sgd_solver.cpp:106] Iteration 10960, lr = 0.1
I0905 03:37:36.937458 90901 solver.cpp:228] Iteration 10970, loss = 0.377309
I0905 03:37:36.937515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377309 (* 1 = 0.377309 loss)
I0905 03:37:36.937528 90901 sgd_solver.cpp:106] Iteration 10970, lr = 0.1
I0905 03:37:42.864640 90901 solver.cpp:228] Iteration 10980, loss = 0.384703
I0905 03:37:42.864784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384702 (* 1 = 0.384702 loss)
I0905 03:37:42.864811 90901 sgd_solver.cpp:106] Iteration 10980, lr = 0.1
I0905 03:37:49.076414 90901 solver.cpp:228] Iteration 10990, loss = 0.568282
I0905 03:37:49.076472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.568282 (* 1 = 0.568282 loss)
I0905 03:37:49.076488 90901 sgd_solver.cpp:106] Iteration 10990, lr = 0.1
I0905 03:37:55.142566 90901 solver.cpp:228] Iteration 11000, loss = 0.458836
I0905 03:37:55.142614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458836 (* 1 = 0.458836 loss)
I0905 03:37:55.142634 90901 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0905 03:38:01.208876 90901 solver.cpp:228] Iteration 11010, loss = 0.404954
I0905 03:38:01.208930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404954 (* 1 = 0.404954 loss)
I0905 03:38:01.208942 90901 sgd_solver.cpp:106] Iteration 11010, lr = 0.1
I0905 03:38:07.279523 90901 solver.cpp:228] Iteration 11020, loss = 0.441111
I0905 03:38:07.279577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.441111 (* 1 = 0.441111 loss)
I0905 03:38:07.279592 90901 sgd_solver.cpp:106] Iteration 11020, lr = 0.1
I0905 03:38:13.372982 90901 solver.cpp:228] Iteration 11030, loss = 0.298666
I0905 03:38:13.373168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298666 (* 1 = 0.298666 loss)
I0905 03:38:13.373185 90901 sgd_solver.cpp:106] Iteration 11030, lr = 0.1
I0905 03:38:19.767448 90901 solver.cpp:228] Iteration 11040, loss = 0.260982
I0905 03:38:19.767493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260982 (* 1 = 0.260982 loss)
I0905 03:38:19.767508 90901 sgd_solver.cpp:106] Iteration 11040, lr = 0.1
I0905 03:38:25.833191 90901 solver.cpp:228] Iteration 11050, loss = 0.456818
I0905 03:38:25.833236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456818 (* 1 = 0.456818 loss)
I0905 03:38:25.833250 90901 sgd_solver.cpp:106] Iteration 11050, lr = 0.1
I0905 03:38:31.927933 90901 solver.cpp:228] Iteration 11060, loss = 0.547281
I0905 03:38:31.927989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.54728 (* 1 = 0.54728 loss)
I0905 03:38:31.928002 90901 sgd_solver.cpp:106] Iteration 11060, lr = 0.1
I0905 03:38:37.207352 90901 solver.cpp:228] Iteration 11070, loss = 0.490516
I0905 03:38:37.207412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490516 (* 1 = 0.490516 loss)
I0905 03:38:37.207427 90901 sgd_solver.cpp:106] Iteration 11070, lr = 0.1
I0905 03:38:42.809859 90901 solver.cpp:228] Iteration 11080, loss = 0.251136
I0905 03:38:42.809911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251136 (* 1 = 0.251136 loss)
I0905 03:38:42.809923 90901 sgd_solver.cpp:106] Iteration 11080, lr = 0.1
I0905 03:38:48.617986 90901 solver.cpp:228] Iteration 11090, loss = 0.360193
I0905 03:38:48.618129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360192 (* 1 = 0.360192 loss)
I0905 03:38:48.618178 90901 sgd_solver.cpp:106] Iteration 11090, lr = 0.1
I0905 03:38:54.744663 90901 solver.cpp:228] Iteration 11100, loss = 0.51415
I0905 03:38:54.744711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.51415 (* 1 = 0.51415 loss)
I0905 03:38:54.744726 90901 sgd_solver.cpp:106] Iteration 11100, lr = 0.1
I0905 03:39:00.762542 90901 solver.cpp:228] Iteration 11110, loss = 0.332386
I0905 03:39:00.762598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332386 (* 1 = 0.332386 loss)
I0905 03:39:00.762611 90901 sgd_solver.cpp:106] Iteration 11110, lr = 0.1
I0905 03:39:06.843446 90901 solver.cpp:228] Iteration 11120, loss = 0.423985
I0905 03:39:06.843497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423985 (* 1 = 0.423985 loss)
I0905 03:39:06.843510 90901 sgd_solver.cpp:106] Iteration 11120, lr = 0.1
I0905 03:39:12.909111 90901 solver.cpp:228] Iteration 11130, loss = 0.398848
I0905 03:39:12.909153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398848 (* 1 = 0.398848 loss)
I0905 03:39:12.909167 90901 sgd_solver.cpp:106] Iteration 11130, lr = 0.1
I0905 03:39:18.986802 90901 solver.cpp:228] Iteration 11140, loss = 0.306203
I0905 03:39:18.987037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306203 (* 1 = 0.306203 loss)
I0905 03:39:18.987048 90901 sgd_solver.cpp:106] Iteration 11140, lr = 0.1
I0905 03:39:25.104871 90901 solver.cpp:228] Iteration 11150, loss = 0.211017
I0905 03:39:25.104921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211016 (* 1 = 0.211016 loss)
I0905 03:39:25.104934 90901 sgd_solver.cpp:106] Iteration 11150, lr = 0.1
I0905 03:39:31.106461 90901 solver.cpp:228] Iteration 11160, loss = 0.308467
I0905 03:39:31.106510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308467 (* 1 = 0.308467 loss)
I0905 03:39:31.106523 90901 sgd_solver.cpp:106] Iteration 11160, lr = 0.1
I0905 03:39:37.514538 90901 solver.cpp:228] Iteration 11170, loss = 0.289093
I0905 03:39:37.514587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289093 (* 1 = 0.289093 loss)
I0905 03:39:37.514601 90901 sgd_solver.cpp:106] Iteration 11170, lr = 0.1
I0905 03:39:43.585371 90901 solver.cpp:228] Iteration 11180, loss = 0.282532
I0905 03:39:43.585423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282532 (* 1 = 0.282532 loss)
I0905 03:39:43.585435 90901 sgd_solver.cpp:106] Iteration 11180, lr = 0.1
I0905 03:39:49.626979 90901 solver.cpp:228] Iteration 11190, loss = 0.352375
I0905 03:39:49.627171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352375 (* 1 = 0.352375 loss)
I0905 03:39:49.627203 90901 sgd_solver.cpp:106] Iteration 11190, lr = 0.1
I0905 03:39:55.481770 90901 solver.cpp:337] Iteration 11200, Testing net (#0)
I0905 03:40:36.644268 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.5075
I0905 03:40:36.644415 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.59433 (* 1 = 1.59433 loss)
I0905 03:40:36.863384 90901 solver.cpp:228] Iteration 11200, loss = 0.395468
I0905 03:40:36.863411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395468 (* 1 = 0.395468 loss)
I0905 03:40:36.863425 90901 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0905 03:40:42.594287 90901 solver.cpp:228] Iteration 11210, loss = 0.309804
I0905 03:40:42.594329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309803 (* 1 = 0.309803 loss)
I0905 03:40:42.594342 90901 sgd_solver.cpp:106] Iteration 11210, lr = 0.1
I0905 03:40:48.661633 90901 solver.cpp:228] Iteration 11220, loss = 0.370998
I0905 03:40:48.661686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370998 (* 1 = 0.370998 loss)
I0905 03:40:48.661700 90901 sgd_solver.cpp:106] Iteration 11220, lr = 0.1
I0905 03:40:55.086798 90901 solver.cpp:228] Iteration 11230, loss = 0.511665
I0905 03:40:55.086845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.511665 (* 1 = 0.511665 loss)
I0905 03:40:55.086858 90901 sgd_solver.cpp:106] Iteration 11230, lr = 0.1
I0905 03:41:01.170651 90901 solver.cpp:228] Iteration 11240, loss = 0.486316
I0905 03:41:01.170691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486316 (* 1 = 0.486316 loss)
I0905 03:41:01.170706 90901 sgd_solver.cpp:106] Iteration 11240, lr = 0.1
I0905 03:41:07.570736 90901 solver.cpp:228] Iteration 11250, loss = 0.499441
I0905 03:41:07.570901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.499441 (* 1 = 0.499441 loss)
I0905 03:41:07.570930 90901 sgd_solver.cpp:106] Iteration 11250, lr = 0.1
I0905 03:41:13.649346 90901 solver.cpp:228] Iteration 11260, loss = 0.299973
I0905 03:41:13.649399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299973 (* 1 = 0.299973 loss)
I0905 03:41:13.649411 90901 sgd_solver.cpp:106] Iteration 11260, lr = 0.1
I0905 03:41:19.754441 90901 solver.cpp:228] Iteration 11270, loss = 0.407484
I0905 03:41:19.754487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407484 (* 1 = 0.407484 loss)
I0905 03:41:19.754500 90901 sgd_solver.cpp:106] Iteration 11270, lr = 0.1
I0905 03:41:25.482676 90901 solver.cpp:228] Iteration 11280, loss = 0.653966
I0905 03:41:25.482748 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.653966 (* 1 = 0.653966 loss)
I0905 03:41:25.482765 90901 sgd_solver.cpp:106] Iteration 11280, lr = 0.1
I0905 03:41:31.561697 90901 solver.cpp:228] Iteration 11290, loss = 0.682385
I0905 03:41:31.561738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.682385 (* 1 = 0.682385 loss)
I0905 03:41:31.561751 90901 sgd_solver.cpp:106] Iteration 11290, lr = 0.1
I0905 03:41:37.937412 90901 solver.cpp:228] Iteration 11300, loss = 0.460307
I0905 03:41:37.937623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460307 (* 1 = 0.460307 loss)
I0905 03:41:37.937654 90901 sgd_solver.cpp:106] Iteration 11300, lr = 0.1
I0905 03:41:43.896147 90901 solver.cpp:228] Iteration 11310, loss = 0.451653
I0905 03:41:43.896190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451653 (* 1 = 0.451653 loss)
I0905 03:41:43.896203 90901 sgd_solver.cpp:106] Iteration 11310, lr = 0.1
I0905 03:41:50.029036 90901 solver.cpp:228] Iteration 11320, loss = 0.369036
I0905 03:41:50.029073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369036 (* 1 = 0.369036 loss)
I0905 03:41:50.029086 90901 sgd_solver.cpp:106] Iteration 11320, lr = 0.1
I0905 03:41:56.128142 90901 solver.cpp:228] Iteration 11330, loss = 0.475518
I0905 03:41:56.128190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475517 (* 1 = 0.475517 loss)
I0905 03:41:56.128204 90901 sgd_solver.cpp:106] Iteration 11330, lr = 0.1
I0905 03:42:02.179913 90901 solver.cpp:228] Iteration 11340, loss = 0.439036
I0905 03:42:02.179963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439035 (* 1 = 0.439035 loss)
I0905 03:42:02.179975 90901 sgd_solver.cpp:106] Iteration 11340, lr = 0.1
I0905 03:42:08.118182 90901 solver.cpp:228] Iteration 11350, loss = 0.409392
I0905 03:42:08.118304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409392 (* 1 = 0.409392 loss)
I0905 03:42:08.118317 90901 sgd_solver.cpp:106] Iteration 11350, lr = 0.1
I0905 03:42:12.766314 90901 solver.cpp:228] Iteration 11360, loss = 0.259788
I0905 03:42:12.766373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259788 (* 1 = 0.259788 loss)
I0905 03:42:12.766389 90901 sgd_solver.cpp:106] Iteration 11360, lr = 0.1
I0905 03:42:17.405779 90901 solver.cpp:228] Iteration 11370, loss = 0.338133
I0905 03:42:17.405827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338133 (* 1 = 0.338133 loss)
I0905 03:42:17.405843 90901 sgd_solver.cpp:106] Iteration 11370, lr = 0.1
I0905 03:42:22.461761 90901 solver.cpp:228] Iteration 11380, loss = 0.477955
I0905 03:42:22.461805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477955 (* 1 = 0.477955 loss)
I0905 03:42:22.461817 90901 sgd_solver.cpp:106] Iteration 11380, lr = 0.1
I0905 03:42:27.558599 90901 solver.cpp:228] Iteration 11390, loss = 0.227139
I0905 03:42:27.558686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227139 (* 1 = 0.227139 loss)
I0905 03:42:27.558701 90901 sgd_solver.cpp:106] Iteration 11390, lr = 0.1
I0905 03:42:32.621315 90901 solver.cpp:228] Iteration 11400, loss = 0.446255
I0905 03:42:32.621357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446255 (* 1 = 0.446255 loss)
I0905 03:42:32.621369 90901 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0905 03:42:37.665639 90901 solver.cpp:228] Iteration 11410, loss = 0.543702
I0905 03:42:37.665688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543702 (* 1 = 0.543702 loss)
I0905 03:42:37.665701 90901 sgd_solver.cpp:106] Iteration 11410, lr = 0.1
I0905 03:42:42.697007 90901 solver.cpp:228] Iteration 11420, loss = 0.441667
I0905 03:42:42.697229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.441667 (* 1 = 0.441667 loss)
I0905 03:42:42.697242 90901 sgd_solver.cpp:106] Iteration 11420, lr = 0.1
I0905 03:42:47.759369 90901 solver.cpp:228] Iteration 11430, loss = 0.3341
I0905 03:42:47.759412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3341 (* 1 = 0.3341 loss)
I0905 03:42:47.759428 90901 sgd_solver.cpp:106] Iteration 11430, lr = 0.1
I0905 03:42:52.809157 90901 solver.cpp:228] Iteration 11440, loss = 0.614389
I0905 03:42:52.809206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.614389 (* 1 = 0.614389 loss)
I0905 03:42:52.809221 90901 sgd_solver.cpp:106] Iteration 11440, lr = 0.1
I0905 03:42:57.847838 90901 solver.cpp:228] Iteration 11450, loss = 0.302666
I0905 03:42:57.847882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302666 (* 1 = 0.302666 loss)
I0905 03:42:57.847896 90901 sgd_solver.cpp:106] Iteration 11450, lr = 0.1
I0905 03:43:02.882802 90901 solver.cpp:228] Iteration 11460, loss = 0.175782
I0905 03:43:02.882861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175782 (* 1 = 0.175782 loss)
I0905 03:43:02.882879 90901 sgd_solver.cpp:106] Iteration 11460, lr = 0.1
I0905 03:43:07.921311 90901 solver.cpp:228] Iteration 11470, loss = 0.680227
I0905 03:43:07.921353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.680227 (* 1 = 0.680227 loss)
I0905 03:43:07.921365 90901 sgd_solver.cpp:106] Iteration 11470, lr = 0.1
I0905 03:43:12.936844 90901 solver.cpp:228] Iteration 11480, loss = 0.40976
I0905 03:43:12.937022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40976 (* 1 = 0.40976 loss)
I0905 03:43:12.937072 90901 sgd_solver.cpp:106] Iteration 11480, lr = 0.1
I0905 03:43:17.999616 90901 solver.cpp:228] Iteration 11490, loss = 0.269584
I0905 03:43:17.999694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269584 (* 1 = 0.269584 loss)
I0905 03:43:17.999708 90901 sgd_solver.cpp:106] Iteration 11490, lr = 0.1
I0905 03:43:23.040621 90901 solver.cpp:228] Iteration 11500, loss = 0.53507
I0905 03:43:23.040658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.53507 (* 1 = 0.53507 loss)
I0905 03:43:23.040670 90901 sgd_solver.cpp:106] Iteration 11500, lr = 0.1
I0905 03:43:28.102715 90901 solver.cpp:228] Iteration 11510, loss = 0.468165
I0905 03:43:28.102774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468165 (* 1 = 0.468165 loss)
I0905 03:43:28.102787 90901 sgd_solver.cpp:106] Iteration 11510, lr = 0.1
I0905 03:43:33.545663 90901 solver.cpp:228] Iteration 11520, loss = 0.342802
I0905 03:43:33.545718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342802 (* 1 = 0.342802 loss)
I0905 03:43:33.545732 90901 sgd_solver.cpp:106] Iteration 11520, lr = 0.1
I0905 03:43:39.605798 90901 solver.cpp:228] Iteration 11530, loss = 0.244607
I0905 03:43:39.605844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244607 (* 1 = 0.244607 loss)
I0905 03:43:39.605857 90901 sgd_solver.cpp:106] Iteration 11530, lr = 0.1
I0905 03:43:45.930624 90901 solver.cpp:228] Iteration 11540, loss = 0.570012
I0905 03:43:45.930779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.570012 (* 1 = 0.570012 loss)
I0905 03:43:45.930820 90901 sgd_solver.cpp:106] Iteration 11540, lr = 0.1
I0905 03:43:52.036841 90901 solver.cpp:228] Iteration 11550, loss = 0.483958
I0905 03:43:52.036873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.483958 (* 1 = 0.483958 loss)
I0905 03:43:52.036892 90901 sgd_solver.cpp:106] Iteration 11550, lr = 0.1
I0905 03:43:58.079058 90901 solver.cpp:228] Iteration 11560, loss = 0.300958
I0905 03:43:58.079114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300958 (* 1 = 0.300958 loss)
I0905 03:43:58.079129 90901 sgd_solver.cpp:106] Iteration 11560, lr = 0.1
I0905 03:44:03.647673 90901 solver.cpp:228] Iteration 11570, loss = 0.229212
I0905 03:44:03.647725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229212 (* 1 = 0.229212 loss)
I0905 03:44:03.647737 90901 sgd_solver.cpp:106] Iteration 11570, lr = 0.1
I0905 03:44:08.965267 90901 solver.cpp:228] Iteration 11580, loss = 0.533542
I0905 03:44:08.965319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.533542 (* 1 = 0.533542 loss)
I0905 03:44:08.965332 90901 sgd_solver.cpp:106] Iteration 11580, lr = 0.1
I0905 03:44:15.357251 90901 solver.cpp:228] Iteration 11590, loss = 0.496264
I0905 03:44:15.357316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496264 (* 1 = 0.496264 loss)
I0905 03:44:15.357331 90901 sgd_solver.cpp:106] Iteration 11590, lr = 0.1
I0905 03:44:21.299618 90901 solver.cpp:228] Iteration 11600, loss = 0.396077
I0905 03:44:21.299757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396077 (* 1 = 0.396077 loss)
I0905 03:44:21.299803 90901 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0905 03:44:27.523016 90901 solver.cpp:228] Iteration 11610, loss = 0.454448
I0905 03:44:27.523056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454447 (* 1 = 0.454447 loss)
I0905 03:44:27.523068 90901 sgd_solver.cpp:106] Iteration 11610, lr = 0.1
I0905 03:44:33.573505 90901 solver.cpp:228] Iteration 11620, loss = 0.447371
I0905 03:44:33.573552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.447371 (* 1 = 0.447371 loss)
I0905 03:44:33.573565 90901 sgd_solver.cpp:106] Iteration 11620, lr = 0.1
I0905 03:44:39.638942 90901 solver.cpp:228] Iteration 11630, loss = 0.266225
I0905 03:44:39.638988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266225 (* 1 = 0.266225 loss)
I0905 03:44:39.638999 90901 sgd_solver.cpp:106] Iteration 11630, lr = 0.1
I0905 03:44:45.724828 90901 solver.cpp:228] Iteration 11640, loss = 0.396367
I0905 03:44:45.724896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396367 (* 1 = 0.396367 loss)
I0905 03:44:45.724913 90901 sgd_solver.cpp:106] Iteration 11640, lr = 0.1
I0905 03:44:51.813472 90901 solver.cpp:228] Iteration 11650, loss = 0.264791
I0905 03:44:51.813721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264791 (* 1 = 0.264791 loss)
I0905 03:44:51.813745 90901 sgd_solver.cpp:106] Iteration 11650, lr = 0.1
I0905 03:44:57.867339 90901 solver.cpp:228] Iteration 11660, loss = 0.345175
I0905 03:44:57.867386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345175 (* 1 = 0.345175 loss)
I0905 03:44:57.867403 90901 sgd_solver.cpp:106] Iteration 11660, lr = 0.1
I0905 03:45:03.939111 90901 solver.cpp:228] Iteration 11670, loss = 0.142162
I0905 03:45:03.939160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142162 (* 1 = 0.142162 loss)
I0905 03:45:03.939173 90901 sgd_solver.cpp:106] Iteration 11670, lr = 0.1
I0905 03:45:09.685830 90901 solver.cpp:228] Iteration 11680, loss = 0.418771
I0905 03:45:09.685873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418771 (* 1 = 0.418771 loss)
I0905 03:45:09.685885 90901 sgd_solver.cpp:106] Iteration 11680, lr = 0.1
I0905 03:45:16.137810 90901 solver.cpp:228] Iteration 11690, loss = 0.490508
I0905 03:45:16.137851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490508 (* 1 = 0.490508 loss)
I0905 03:45:16.137864 90901 sgd_solver.cpp:106] Iteration 11690, lr = 0.1
I0905 03:45:22.448227 90901 solver.cpp:228] Iteration 11700, loss = 0.280158
I0905 03:45:22.448375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280158 (* 1 = 0.280158 loss)
I0905 03:45:22.448416 90901 sgd_solver.cpp:106] Iteration 11700, lr = 0.1
I0905 03:45:28.266866 90901 solver.cpp:228] Iteration 11710, loss = 0.702963
I0905 03:45:28.266912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.702963 (* 1 = 0.702963 loss)
I0905 03:45:28.266928 90901 sgd_solver.cpp:106] Iteration 11710, lr = 0.1
I0905 03:45:34.688088 90901 solver.cpp:228] Iteration 11720, loss = 0.480439
I0905 03:45:34.688132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480439 (* 1 = 0.480439 loss)
I0905 03:45:34.688148 90901 sgd_solver.cpp:106] Iteration 11720, lr = 0.1
I0905 03:45:40.719703 90901 solver.cpp:228] Iteration 11730, loss = 0.499002
I0905 03:45:40.719756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.499002 (* 1 = 0.499002 loss)
I0905 03:45:40.719769 90901 sgd_solver.cpp:106] Iteration 11730, lr = 0.1
I0905 03:45:46.863433 90901 solver.cpp:228] Iteration 11740, loss = 0.125894
I0905 03:45:46.863481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125894 (* 1 = 0.125894 loss)
I0905 03:45:46.863494 90901 sgd_solver.cpp:106] Iteration 11740, lr = 0.1
I0905 03:45:52.168973 90901 solver.cpp:228] Iteration 11750, loss = 0.468286
I0905 03:45:52.169021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468286 (* 1 = 0.468286 loss)
I0905 03:45:52.169034 90901 sgd_solver.cpp:106] Iteration 11750, lr = 0.1
I0905 03:45:57.652547 90901 solver.cpp:228] Iteration 11760, loss = 0.651445
I0905 03:45:57.652722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.651445 (* 1 = 0.651445 loss)
I0905 03:45:57.652739 90901 sgd_solver.cpp:106] Iteration 11760, lr = 0.1
I0905 03:46:04.046602 90901 solver.cpp:228] Iteration 11770, loss = 0.659864
I0905 03:46:04.046661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.659864 (* 1 = 0.659864 loss)
I0905 03:46:04.046674 90901 sgd_solver.cpp:106] Iteration 11770, lr = 0.1
I0905 03:46:10.081472 90901 solver.cpp:228] Iteration 11780, loss = 0.450342
I0905 03:46:10.081517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450342 (* 1 = 0.450342 loss)
I0905 03:46:10.081531 90901 sgd_solver.cpp:106] Iteration 11780, lr = 0.1
I0905 03:46:16.119330 90901 solver.cpp:228] Iteration 11790, loss = 0.373273
I0905 03:46:16.119374 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373273 (* 1 = 0.373273 loss)
I0905 03:46:16.119388 90901 sgd_solver.cpp:106] Iteration 11790, lr = 0.1
I0905 03:46:22.464123 90901 solver.cpp:228] Iteration 11800, loss = 0.197297
I0905 03:46:22.464171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197297 (* 1 = 0.197297 loss)
I0905 03:46:22.464186 90901 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0905 03:46:28.505952 90901 solver.cpp:228] Iteration 11810, loss = 0.620755
I0905 03:46:28.510756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.620754 (* 1 = 0.620754 loss)
I0905 03:46:28.510799 90901 sgd_solver.cpp:106] Iteration 11810, lr = 0.1
I0905 03:46:34.863593 90901 solver.cpp:228] Iteration 11820, loss = 0.212045
I0905 03:46:34.863646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212045 (* 1 = 0.212045 loss)
I0905 03:46:34.863658 90901 sgd_solver.cpp:106] Iteration 11820, lr = 0.1
I0905 03:46:40.952369 90901 solver.cpp:228] Iteration 11830, loss = 0.405217
I0905 03:46:40.952420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.405217 (* 1 = 0.405217 loss)
I0905 03:46:40.952433 90901 sgd_solver.cpp:106] Iteration 11830, lr = 0.1
I0905 03:46:47.050125 90901 solver.cpp:228] Iteration 11840, loss = 0.383363
I0905 03:46:47.050184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383363 (* 1 = 0.383363 loss)
I0905 03:46:47.050199 90901 sgd_solver.cpp:106] Iteration 11840, lr = 0.1
I0905 03:46:53.156596 90901 solver.cpp:228] Iteration 11850, loss = 0.343961
I0905 03:46:53.156643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343961 (* 1 = 0.343961 loss)
I0905 03:46:53.156656 90901 sgd_solver.cpp:106] Iteration 11850, lr = 0.1
I0905 03:46:58.898653 90901 solver.cpp:228] Iteration 11860, loss = 0.380083
I0905 03:46:58.898876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380083 (* 1 = 0.380083 loss)
I0905 03:46:58.898893 90901 sgd_solver.cpp:106] Iteration 11860, lr = 0.1
I0905 03:47:05.312270 90901 solver.cpp:228] Iteration 11870, loss = 0.295541
I0905 03:47:05.312314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295541 (* 1 = 0.295541 loss)
I0905 03:47:05.312328 90901 sgd_solver.cpp:106] Iteration 11870, lr = 0.1
I0905 03:47:11.413689 90901 solver.cpp:228] Iteration 11880, loss = 0.203635
I0905 03:47:11.413738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203635 (* 1 = 0.203635 loss)
I0905 03:47:11.413751 90901 sgd_solver.cpp:106] Iteration 11880, lr = 0.1
I0905 03:47:17.497627 90901 solver.cpp:228] Iteration 11890, loss = 0.642643
I0905 03:47:17.497674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.642643 (* 1 = 0.642643 loss)
I0905 03:47:17.497689 90901 sgd_solver.cpp:106] Iteration 11890, lr = 0.1
I0905 03:47:23.506989 90901 solver.cpp:228] Iteration 11900, loss = 0.259389
I0905 03:47:23.507051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259389 (* 1 = 0.259389 loss)
I0905 03:47:23.507069 90901 sgd_solver.cpp:106] Iteration 11900, lr = 0.1
I0905 03:47:29.868105 90901 solver.cpp:228] Iteration 11910, loss = 0.36436
I0905 03:47:29.868337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36436 (* 1 = 0.36436 loss)
I0905 03:47:29.868351 90901 sgd_solver.cpp:106] Iteration 11910, lr = 0.1
I0905 03:47:35.734124 90901 solver.cpp:228] Iteration 11920, loss = 0.269407
I0905 03:47:35.734179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269407 (* 1 = 0.269407 loss)
I0905 03:47:35.734194 90901 sgd_solver.cpp:106] Iteration 11920, lr = 0.1
I0905 03:47:41.198345 90901 solver.cpp:228] Iteration 11930, loss = 0.348956
I0905 03:47:41.198408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348956 (* 1 = 0.348956 loss)
I0905 03:47:41.198426 90901 sgd_solver.cpp:106] Iteration 11930, lr = 0.1
I0905 03:47:46.800071 90901 solver.cpp:228] Iteration 11940, loss = 0.55246
I0905 03:47:46.800122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55246 (* 1 = 0.55246 loss)
I0905 03:47:46.800135 90901 sgd_solver.cpp:106] Iteration 11940, lr = 0.1
I0905 03:47:52.862236 90901 solver.cpp:228] Iteration 11950, loss = 0.633712
I0905 03:47:52.862285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633712 (* 1 = 0.633712 loss)
I0905 03:47:52.862300 90901 sgd_solver.cpp:106] Iteration 11950, lr = 0.1
I0905 03:47:58.924968 90901 solver.cpp:228] Iteration 11960, loss = 0.291247
I0905 03:47:58.925024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291247 (* 1 = 0.291247 loss)
I0905 03:47:58.925037 90901 sgd_solver.cpp:106] Iteration 11960, lr = 0.1
I0905 03:48:05.048885 90901 solver.cpp:228] Iteration 11970, loss = 0.450727
I0905 03:48:05.049021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450727 (* 1 = 0.450727 loss)
I0905 03:48:05.049060 90901 sgd_solver.cpp:106] Iteration 11970, lr = 0.1
I0905 03:48:11.136695 90901 solver.cpp:228] Iteration 11980, loss = 0.368707
I0905 03:48:11.136757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368707 (* 1 = 0.368707 loss)
I0905 03:48:11.136772 90901 sgd_solver.cpp:106] Iteration 11980, lr = 0.1
I0905 03:48:17.179675 90901 solver.cpp:228] Iteration 11990, loss = 0.118362
I0905 03:48:17.179718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118362 (* 1 = 0.118362 loss)
I0905 03:48:17.179733 90901 sgd_solver.cpp:106] Iteration 11990, lr = 0.1
I0905 03:48:23.030031 90901 solver.cpp:337] Iteration 12000, Testing net (#0)
I0905 03:49:05.214824 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.519375
I0905 03:49:05.214967 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.35888 (* 1 = 1.35888 loss)
I0905 03:49:05.433277 90901 solver.cpp:228] Iteration 12000, loss = 0.342323
I0905 03:49:05.433316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342323 (* 1 = 0.342323 loss)
I0905 03:49:05.433333 90901 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0905 03:49:11.772563 90901 solver.cpp:228] Iteration 12010, loss = 0.344362
I0905 03:49:11.772619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344362 (* 1 = 0.344362 loss)
I0905 03:49:11.772634 90901 sgd_solver.cpp:106] Iteration 12010, lr = 0.1
I0905 03:49:17.888751 90901 solver.cpp:228] Iteration 12020, loss = 0.174661
I0905 03:49:17.888803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174661 (* 1 = 0.174661 loss)
I0905 03:49:17.888823 90901 sgd_solver.cpp:106] Iteration 12020, lr = 0.1
I0905 03:49:23.687667 90901 solver.cpp:228] Iteration 12030, loss = 0.526505
I0905 03:49:23.687711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.526505 (* 1 = 0.526505 loss)
I0905 03:49:23.687723 90901 sgd_solver.cpp:106] Iteration 12030, lr = 0.1
I0905 03:49:29.245182 90901 solver.cpp:228] Iteration 12040, loss = 0.34545
I0905 03:49:29.245226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34545 (* 1 = 0.34545 loss)
I0905 03:49:29.245239 90901 sgd_solver.cpp:106] Iteration 12040, lr = 0.1
I0905 03:49:34.736264 90901 solver.cpp:228] Iteration 12050, loss = 0.43585
I0905 03:49:34.736315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43585 (* 1 = 0.43585 loss)
I0905 03:49:34.736328 90901 sgd_solver.cpp:106] Iteration 12050, lr = 0.1
I0905 03:49:41.134049 90901 solver.cpp:228] Iteration 12060, loss = 0.226863
I0905 03:49:41.134331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226863 (* 1 = 0.226863 loss)
I0905 03:49:41.134349 90901 sgd_solver.cpp:106] Iteration 12060, lr = 0.1
I0905 03:49:46.884629 90901 solver.cpp:228] Iteration 12070, loss = 0.456965
I0905 03:49:46.884694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456965 (* 1 = 0.456965 loss)
I0905 03:49:46.884709 90901 sgd_solver.cpp:106] Iteration 12070, lr = 0.1
I0905 03:49:53.319805 90901 solver.cpp:228] Iteration 12080, loss = 0.59939
I0905 03:49:53.319866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59939 (* 1 = 0.59939 loss)
I0905 03:49:53.319883 90901 sgd_solver.cpp:106] Iteration 12080, lr = 0.1
I0905 03:49:59.379062 90901 solver.cpp:228] Iteration 12090, loss = 0.360633
I0905 03:49:59.379122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360633 (* 1 = 0.360633 loss)
I0905 03:49:59.379137 90901 sgd_solver.cpp:106] Iteration 12090, lr = 0.1
I0905 03:50:05.638564 90901 solver.cpp:228] Iteration 12100, loss = 0.450973
I0905 03:50:05.638604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450973 (* 1 = 0.450973 loss)
I0905 03:50:05.638619 90901 sgd_solver.cpp:106] Iteration 12100, lr = 0.1
I0905 03:50:11.795954 90901 solver.cpp:228] Iteration 12110, loss = 0.448271
I0905 03:50:11.796099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448271 (* 1 = 0.448271 loss)
I0905 03:50:11.796125 90901 sgd_solver.cpp:106] Iteration 12110, lr = 0.1
I0905 03:50:17.866773 90901 solver.cpp:228] Iteration 12120, loss = 0.360201
I0905 03:50:17.866823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360201 (* 1 = 0.360201 loss)
I0905 03:50:17.866837 90901 sgd_solver.cpp:106] Iteration 12120, lr = 0.1
I0905 03:50:23.919330 90901 solver.cpp:228] Iteration 12130, loss = 0.559483
I0905 03:50:23.919390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.559483 (* 1 = 0.559483 loss)
I0905 03:50:23.919405 90901 sgd_solver.cpp:106] Iteration 12130, lr = 0.1
I0905 03:50:29.983609 90901 solver.cpp:228] Iteration 12140, loss = 0.262472
I0905 03:50:29.983670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262472 (* 1 = 0.262472 loss)
I0905 03:50:29.983685 90901 sgd_solver.cpp:106] Iteration 12140, lr = 0.1
I0905 03:50:36.373991 90901 solver.cpp:228] Iteration 12150, loss = 0.23135
I0905 03:50:36.374065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23135 (* 1 = 0.23135 loss)
I0905 03:50:36.374083 90901 sgd_solver.cpp:106] Iteration 12150, lr = 0.1
I0905 03:50:42.399004 90901 solver.cpp:228] Iteration 12160, loss = 0.181105
I0905 03:50:42.399207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181105 (* 1 = 0.181105 loss)
I0905 03:50:42.399224 90901 sgd_solver.cpp:106] Iteration 12160, lr = 0.1
I0905 03:50:48.474495 90901 solver.cpp:228] Iteration 12170, loss = 0.463236
I0905 03:50:48.474556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463236 (* 1 = 0.463236 loss)
I0905 03:50:48.474571 90901 sgd_solver.cpp:106] Iteration 12170, lr = 0.1
I0905 03:50:54.523200 90901 solver.cpp:228] Iteration 12180, loss = 0.261463
I0905 03:50:54.523275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261463 (* 1 = 0.261463 loss)
I0905 03:50:54.523293 90901 sgd_solver.cpp:106] Iteration 12180, lr = 0.1
I0905 03:51:00.620699 90901 solver.cpp:228] Iteration 12190, loss = 0.390703
I0905 03:51:00.620777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390703 (* 1 = 0.390703 loss)
I0905 03:51:00.620793 90901 sgd_solver.cpp:106] Iteration 12190, lr = 0.1
I0905 03:51:06.728226 90901 solver.cpp:228] Iteration 12200, loss = 0.378844
I0905 03:51:06.728281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378844 (* 1 = 0.378844 loss)
I0905 03:51:06.728296 90901 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0905 03:51:12.527719 90901 solver.cpp:228] Iteration 12210, loss = 0.27755
I0905 03:51:12.527968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27755 (* 1 = 0.27755 loss)
I0905 03:51:12.527987 90901 sgd_solver.cpp:106] Iteration 12210, lr = 0.1
I0905 03:51:18.074050 90901 solver.cpp:228] Iteration 12220, loss = 0.40341
I0905 03:51:18.074127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40341 (* 1 = 0.40341 loss)
I0905 03:51:18.074146 90901 sgd_solver.cpp:106] Iteration 12220, lr = 0.1
I0905 03:51:23.562033 90901 solver.cpp:228] Iteration 12230, loss = 0.29584
I0905 03:51:23.562083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29584 (* 1 = 0.29584 loss)
I0905 03:51:23.562095 90901 sgd_solver.cpp:106] Iteration 12230, lr = 0.1
I0905 03:51:29.944095 90901 solver.cpp:228] Iteration 12240, loss = 0.569293
I0905 03:51:29.944157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.569293 (* 1 = 0.569293 loss)
I0905 03:51:29.944171 90901 sgd_solver.cpp:106] Iteration 12240, lr = 0.1
I0905 03:51:36.020680 90901 solver.cpp:228] Iteration 12250, loss = 0.582101
I0905 03:51:36.020725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.582101 (* 1 = 0.582101 loss)
I0905 03:51:36.020737 90901 sgd_solver.cpp:106] Iteration 12250, lr = 0.1
I0905 03:51:42.099858 90901 solver.cpp:228] Iteration 12260, loss = 0.317314
I0905 03:51:42.099902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317314 (* 1 = 0.317314 loss)
I0905 03:51:42.099916 90901 sgd_solver.cpp:106] Iteration 12260, lr = 0.1
I0905 03:51:48.259817 90901 solver.cpp:228] Iteration 12270, loss = 0.606105
I0905 03:51:48.259968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.606105 (* 1 = 0.606105 loss)
I0905 03:51:48.260017 90901 sgd_solver.cpp:106] Iteration 12270, lr = 0.1
I0905 03:51:54.542001 90901 solver.cpp:228] Iteration 12280, loss = 0.496637
I0905 03:51:54.542064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496637 (* 1 = 0.496637 loss)
I0905 03:51:54.542079 90901 sgd_solver.cpp:106] Iteration 12280, lr = 0.1
I0905 03:52:00.563366 90901 solver.cpp:228] Iteration 12290, loss = 0.767563
I0905 03:52:00.563431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.767563 (* 1 = 0.767563 loss)
I0905 03:52:00.563455 90901 sgd_solver.cpp:106] Iteration 12290, lr = 0.1
I0905 03:52:06.637984 90901 solver.cpp:228] Iteration 12300, loss = 0.516161
I0905 03:52:06.638030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.516161 (* 1 = 0.516161 loss)
I0905 03:52:06.638044 90901 sgd_solver.cpp:106] Iteration 12300, lr = 0.1
I0905 03:52:12.767416 90901 solver.cpp:228] Iteration 12310, loss = 0.291022
I0905 03:52:12.767472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291022 (* 1 = 0.291022 loss)
I0905 03:52:12.767488 90901 sgd_solver.cpp:106] Iteration 12310, lr = 0.1
I0905 03:52:18.740212 90901 solver.cpp:228] Iteration 12320, loss = 0.290128
I0905 03:52:18.740356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290128 (* 1 = 0.290128 loss)
I0905 03:52:18.740401 90901 sgd_solver.cpp:106] Iteration 12320, lr = 0.1
I0905 03:52:25.130748 90901 solver.cpp:228] Iteration 12330, loss = 0.290905
I0905 03:52:25.130810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290905 (* 1 = 0.290905 loss)
I0905 03:52:25.130828 90901 sgd_solver.cpp:106] Iteration 12330, lr = 0.1
I0905 03:52:31.191797 90901 solver.cpp:228] Iteration 12340, loss = 0.311547
I0905 03:52:31.191856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311547 (* 1 = 0.311547 loss)
I0905 03:52:31.191870 90901 sgd_solver.cpp:106] Iteration 12340, lr = 0.1
I0905 03:52:37.592497 90901 solver.cpp:228] Iteration 12350, loss = 0.307334
I0905 03:52:37.592555 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307334 (* 1 = 0.307334 loss)
I0905 03:52:37.592569 90901 sgd_solver.cpp:106] Iteration 12350, lr = 0.1
I0905 03:52:43.620492 90901 solver.cpp:228] Iteration 12360, loss = 0.491139
I0905 03:52:43.620569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491139 (* 1 = 0.491139 loss)
I0905 03:52:43.620585 90901 sgd_solver.cpp:106] Iteration 12360, lr = 0.1
I0905 03:52:49.678983 90901 solver.cpp:228] Iteration 12370, loss = 0.374802
I0905 03:52:49.679229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374802 (* 1 = 0.374802 loss)
I0905 03:52:49.679249 90901 sgd_solver.cpp:106] Iteration 12370, lr = 0.1
I0905 03:52:55.999689 90901 solver.cpp:228] Iteration 12380, loss = 0.40683
I0905 03:52:55.999748 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40683 (* 1 = 0.40683 loss)
I0905 03:52:55.999764 90901 sgd_solver.cpp:106] Iteration 12380, lr = 0.1
I0905 03:53:01.908941 90901 solver.cpp:228] Iteration 12390, loss = 0.378079
I0905 03:53:01.908993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378079 (* 1 = 0.378079 loss)
I0905 03:53:01.909006 90901 sgd_solver.cpp:106] Iteration 12390, lr = 0.1
I0905 03:53:07.207415 90901 solver.cpp:228] Iteration 12400, loss = 0.45542
I0905 03:53:07.207460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45542 (* 1 = 0.45542 loss)
I0905 03:53:07.207473 90901 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0905 03:53:12.852290 90901 solver.cpp:228] Iteration 12410, loss = 0.358445
I0905 03:53:12.852335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358445 (* 1 = 0.358445 loss)
I0905 03:53:12.852349 90901 sgd_solver.cpp:106] Iteration 12410, lr = 0.1
I0905 03:53:18.975419 90901 solver.cpp:228] Iteration 12420, loss = 0.562112
I0905 03:53:18.975491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.562112 (* 1 = 0.562112 loss)
I0905 03:53:18.975507 90901 sgd_solver.cpp:106] Iteration 12420, lr = 0.1
I0905 03:53:25.044386 90901 solver.cpp:228] Iteration 12430, loss = 0.255943
I0905 03:53:25.044551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255943 (* 1 = 0.255943 loss)
I0905 03:53:25.044580 90901 sgd_solver.cpp:106] Iteration 12430, lr = 0.1
I0905 03:53:31.147814 90901 solver.cpp:228] Iteration 12440, loss = 0.416743
I0905 03:53:31.147868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416743 (* 1 = 0.416743 loss)
I0905 03:53:31.147881 90901 sgd_solver.cpp:106] Iteration 12440, lr = 0.1
I0905 03:53:37.209861 90901 solver.cpp:228] Iteration 12450, loss = 0.381344
I0905 03:53:37.209905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381344 (* 1 = 0.381344 loss)
I0905 03:53:37.209918 90901 sgd_solver.cpp:106] Iteration 12450, lr = 0.1
I0905 03:53:43.303758 90901 solver.cpp:228] Iteration 12460, loss = 0.344144
I0905 03:53:43.303819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344144 (* 1 = 0.344144 loss)
I0905 03:53:43.303834 90901 sgd_solver.cpp:106] Iteration 12460, lr = 0.1
I0905 03:53:49.322983 90901 solver.cpp:228] Iteration 12470, loss = 0.465683
I0905 03:53:49.323029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465683 (* 1 = 0.465683 loss)
I0905 03:53:49.323045 90901 sgd_solver.cpp:106] Iteration 12470, lr = 0.1
I0905 03:53:55.724524 90901 solver.cpp:228] Iteration 12480, loss = 0.477444
I0905 03:53:55.724629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477444 (* 1 = 0.477444 loss)
I0905 03:53:55.724645 90901 sgd_solver.cpp:106] Iteration 12480, lr = 0.1
I0905 03:54:01.766842 90901 solver.cpp:228] Iteration 12490, loss = 0.589962
I0905 03:54:01.766893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.589962 (* 1 = 0.589962 loss)
I0905 03:54:01.766907 90901 sgd_solver.cpp:106] Iteration 12490, lr = 0.1
I0905 03:54:07.792948 90901 solver.cpp:228] Iteration 12500, loss = 0.304747
I0905 03:54:07.793007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304747 (* 1 = 0.304747 loss)
I0905 03:54:07.793023 90901 sgd_solver.cpp:106] Iteration 12500, lr = 0.1
I0905 03:54:13.868986 90901 solver.cpp:228] Iteration 12510, loss = 0.472751
I0905 03:54:13.869040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472751 (* 1 = 0.472751 loss)
I0905 03:54:13.869053 90901 sgd_solver.cpp:106] Iteration 12510, lr = 0.1
I0905 03:54:19.957164 90901 solver.cpp:228] Iteration 12520, loss = 0.281285
I0905 03:54:19.957204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281285 (* 1 = 0.281285 loss)
I0905 03:54:19.957222 90901 sgd_solver.cpp:106] Iteration 12520, lr = 0.1
I0905 03:54:26.208068 90901 solver.cpp:228] Iteration 12530, loss = 0.379298
I0905 03:54:26.208268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379298 (* 1 = 0.379298 loss)
I0905 03:54:26.208302 90901 sgd_solver.cpp:106] Iteration 12530, lr = 0.1
I0905 03:54:32.121757 90901 solver.cpp:228] Iteration 12540, loss = 0.197232
I0905 03:54:32.121804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197232 (* 1 = 0.197232 loss)
I0905 03:54:32.121819 90901 sgd_solver.cpp:106] Iteration 12540, lr = 0.1
I0905 03:54:38.156095 90901 solver.cpp:228] Iteration 12550, loss = 0.214077
I0905 03:54:38.156159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214077 (* 1 = 0.214077 loss)
I0905 03:54:38.156177 90901 sgd_solver.cpp:106] Iteration 12550, lr = 0.1
I0905 03:54:44.222867 90901 solver.cpp:228] Iteration 12560, loss = 0.313827
I0905 03:54:44.222928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313827 (* 1 = 0.313827 loss)
I0905 03:54:44.222944 90901 sgd_solver.cpp:106] Iteration 12560, lr = 0.1
I0905 03:54:50.126495 90901 solver.cpp:228] Iteration 12570, loss = 0.425835
I0905 03:54:50.126544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425835 (* 1 = 0.425835 loss)
I0905 03:54:50.126556 90901 sgd_solver.cpp:106] Iteration 12570, lr = 0.1
I0905 03:54:55.383383 90901 solver.cpp:228] Iteration 12580, loss = 0.335008
I0905 03:54:55.383422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335008 (* 1 = 0.335008 loss)
I0905 03:54:55.383430 90901 sgd_solver.cpp:106] Iteration 12580, lr = 0.1
I0905 03:55:01.155058 90901 solver.cpp:228] Iteration 12590, loss = 0.548342
I0905 03:55:01.155186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.548342 (* 1 = 0.548342 loss)
I0905 03:55:01.155213 90901 sgd_solver.cpp:106] Iteration 12590, lr = 0.1
I0905 03:55:07.220700 90901 solver.cpp:228] Iteration 12600, loss = 0.271871
I0905 03:55:07.220743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271871 (* 1 = 0.271871 loss)
I0905 03:55:07.220757 90901 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0905 03:55:13.297207 90901 solver.cpp:228] Iteration 12610, loss = 0.622508
I0905 03:55:13.297282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.622508 (* 1 = 0.622508 loss)
I0905 03:55:13.297298 90901 sgd_solver.cpp:106] Iteration 12610, lr = 0.1
I0905 03:55:19.062284 90901 solver.cpp:228] Iteration 12620, loss = 0.383037
I0905 03:55:19.062328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383037 (* 1 = 0.383037 loss)
I0905 03:55:19.062341 90901 sgd_solver.cpp:106] Iteration 12620, lr = 0.1
I0905 03:55:25.423971 90901 solver.cpp:228] Iteration 12630, loss = 0.544185
I0905 03:55:25.424032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.544185 (* 1 = 0.544185 loss)
I0905 03:55:25.424059 90901 sgd_solver.cpp:106] Iteration 12630, lr = 0.1
I0905 03:55:31.439121 90901 solver.cpp:228] Iteration 12640, loss = 0.382922
I0905 03:55:31.439236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382922 (* 1 = 0.382922 loss)
I0905 03:55:31.439251 90901 sgd_solver.cpp:106] Iteration 12640, lr = 0.1
I0905 03:55:37.185473 90901 solver.cpp:228] Iteration 12650, loss = 0.46482
I0905 03:55:37.185521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46482 (* 1 = 0.46482 loss)
I0905 03:55:37.185534 90901 sgd_solver.cpp:106] Iteration 12650, lr = 0.1
I0905 03:55:43.301267 90901 solver.cpp:228] Iteration 12660, loss = 0.693174
I0905 03:55:43.301319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.693174 (* 1 = 0.693174 loss)
I0905 03:55:43.301334 90901 sgd_solver.cpp:106] Iteration 12660, lr = 0.1
I0905 03:55:49.715656 90901 solver.cpp:228] Iteration 12670, loss = 0.626144
I0905 03:55:49.715699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.626144 (* 1 = 0.626144 loss)
I0905 03:55:49.715710 90901 sgd_solver.cpp:106] Iteration 12670, lr = 0.1
I0905 03:55:55.775956 90901 solver.cpp:228] Iteration 12680, loss = 0.303827
I0905 03:55:55.776000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303827 (* 1 = 0.303827 loss)
I0905 03:55:55.776015 90901 sgd_solver.cpp:106] Iteration 12680, lr = 0.1
I0905 03:56:01.811308 90901 solver.cpp:228] Iteration 12690, loss = 0.477148
I0905 03:56:01.811594 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477148 (* 1 = 0.477148 loss)
I0905 03:56:01.811614 90901 sgd_solver.cpp:106] Iteration 12690, lr = 0.1
I0905 03:56:07.924044 90901 solver.cpp:228] Iteration 12700, loss = 0.632326
I0905 03:56:07.924085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.632325 (* 1 = 0.632325 loss)
I0905 03:56:07.924098 90901 sgd_solver.cpp:106] Iteration 12700, lr = 0.1
I0905 03:56:14.307606 90901 solver.cpp:228] Iteration 12710, loss = 0.407274
I0905 03:56:14.307652 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407274 (* 1 = 0.407274 loss)
I0905 03:56:14.307665 90901 sgd_solver.cpp:106] Iteration 12710, lr = 0.1
I0905 03:56:20.400907 90901 solver.cpp:228] Iteration 12720, loss = 0.419855
I0905 03:56:20.400952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419855 (* 1 = 0.419855 loss)
I0905 03:56:20.400965 90901 sgd_solver.cpp:106] Iteration 12720, lr = 0.1
I0905 03:56:26.431452 90901 solver.cpp:228] Iteration 12730, loss = 0.153864
I0905 03:56:26.431499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153864 (* 1 = 0.153864 loss)
I0905 03:56:26.431514 90901 sgd_solver.cpp:106] Iteration 12730, lr = 0.1
I0905 03:56:32.654423 90901 solver.cpp:228] Iteration 12740, loss = 0.353496
I0905 03:56:32.654593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353496 (* 1 = 0.353496 loss)
I0905 03:56:32.654649 90901 sgd_solver.cpp:106] Iteration 12740, lr = 0.1
I0905 03:56:38.273253 90901 solver.cpp:228] Iteration 12750, loss = 0.493418
I0905 03:56:38.273324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493418 (* 1 = 0.493418 loss)
I0905 03:56:38.273342 90901 sgd_solver.cpp:106] Iteration 12750, lr = 0.1
I0905 03:56:43.822881 90901 solver.cpp:228] Iteration 12760, loss = 0.349917
I0905 03:56:43.822927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349917 (* 1 = 0.349917 loss)
I0905 03:56:43.822940 90901 sgd_solver.cpp:106] Iteration 12760, lr = 0.1
I0905 03:56:49.448715 90901 solver.cpp:228] Iteration 12770, loss = 0.540296
I0905 03:56:49.448760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.540296 (* 1 = 0.540296 loss)
I0905 03:56:49.448772 90901 sgd_solver.cpp:106] Iteration 12770, lr = 0.1
I0905 03:56:55.213886 90901 solver.cpp:228] Iteration 12780, loss = 0.30546
I0905 03:56:55.213946 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30546 (* 1 = 0.30546 loss)
I0905 03:56:55.213963 90901 sgd_solver.cpp:106] Iteration 12780, lr = 0.1
I0905 03:57:01.609796 90901 solver.cpp:228] Iteration 12790, loss = 0.68228
I0905 03:57:01.609899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.68228 (* 1 = 0.68228 loss)
I0905 03:57:01.609944 90901 sgd_solver.cpp:106] Iteration 12790, lr = 0.1
I0905 03:57:07.437294 90901 solver.cpp:337] Iteration 12800, Testing net (#0)
I0905 03:57:49.820685 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.502187
I0905 03:57:49.820766 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.29061 (* 1 = 1.29061 loss)
I0905 03:57:50.036898 90901 solver.cpp:228] Iteration 12800, loss = 0.290018
I0905 03:57:50.036941 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290018 (* 1 = 0.290018 loss)
I0905 03:57:50.036959 90901 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0905 03:57:56.118237 90901 solver.cpp:228] Iteration 12810, loss = 0.69917
I0905 03:57:56.118294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.69917 (* 1 = 0.69917 loss)
I0905 03:57:56.118307 90901 sgd_solver.cpp:106] Iteration 12810, lr = 0.1
I0905 03:58:02.273849 90901 solver.cpp:228] Iteration 12820, loss = 0.591027
I0905 03:58:02.273905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.591027 (* 1 = 0.591027 loss)
I0905 03:58:02.273921 90901 sgd_solver.cpp:106] Iteration 12820, lr = 0.1
I0905 03:58:08.540750 90901 solver.cpp:228] Iteration 12830, loss = 0.48955
I0905 03:58:08.540817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48955 (* 1 = 0.48955 loss)
I0905 03:58:08.540833 90901 sgd_solver.cpp:106] Iteration 12830, lr = 0.1
I0905 03:58:14.581655 90901 solver.cpp:228] Iteration 12840, loss = 0.201459
I0905 03:58:14.581701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201459 (* 1 = 0.201459 loss)
I0905 03:58:14.581713 90901 sgd_solver.cpp:106] Iteration 12840, lr = 0.1
I0905 03:58:20.669348 90901 solver.cpp:228] Iteration 12850, loss = 0.723633
I0905 03:58:20.669581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.723633 (* 1 = 0.723633 loss)
I0905 03:58:20.669605 90901 sgd_solver.cpp:106] Iteration 12850, lr = 0.1
I0905 03:58:26.404788 90901 solver.cpp:228] Iteration 12860, loss = 0.442461
I0905 03:58:26.404850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442461 (* 1 = 0.442461 loss)
I0905 03:58:26.404865 90901 sgd_solver.cpp:106] Iteration 12860, lr = 0.1
I0905 03:58:31.662395 90901 solver.cpp:228] Iteration 12870, loss = 0.427548
I0905 03:58:31.662447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427548 (* 1 = 0.427548 loss)
I0905 03:58:31.662461 90901 sgd_solver.cpp:106] Iteration 12870, lr = 0.1
I0905 03:58:37.604851 90901 solver.cpp:228] Iteration 12880, loss = 0.372227
I0905 03:58:37.604897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372227 (* 1 = 0.372227 loss)
I0905 03:58:37.604912 90901 sgd_solver.cpp:106] Iteration 12880, lr = 0.1
I0905 03:58:43.656605 90901 solver.cpp:228] Iteration 12890, loss = 0.485616
I0905 03:58:43.656661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.485616 (* 1 = 0.485616 loss)
I0905 03:58:43.656675 90901 sgd_solver.cpp:106] Iteration 12890, lr = 0.1
I0905 03:58:49.749230 90901 solver.cpp:228] Iteration 12900, loss = 0.283741
I0905 03:58:49.749280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283741 (* 1 = 0.283741 loss)
I0905 03:58:49.749292 90901 sgd_solver.cpp:106] Iteration 12900, lr = 0.1
I0905 03:58:55.831133 90901 solver.cpp:228] Iteration 12910, loss = 0.365457
I0905 03:58:55.831265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365457 (* 1 = 0.365457 loss)
I0905 03:58:55.831297 90901 sgd_solver.cpp:106] Iteration 12910, lr = 0.1
I0905 03:59:01.902355 90901 solver.cpp:228] Iteration 12920, loss = 0.243043
I0905 03:59:01.902412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243043 (* 1 = 0.243043 loss)
I0905 03:59:01.902426 90901 sgd_solver.cpp:106] Iteration 12920, lr = 0.1
I0905 03:59:08.062923 90901 solver.cpp:228] Iteration 12930, loss = 0.185544
I0905 03:59:08.062965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185544 (* 1 = 0.185544 loss)
I0905 03:59:08.062978 90901 sgd_solver.cpp:106] Iteration 12930, lr = 0.1
I0905 03:59:14.395175 90901 solver.cpp:228] Iteration 12940, loss = 0.403652
I0905 03:59:14.395215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403652 (* 1 = 0.403652 loss)
I0905 03:59:14.395227 90901 sgd_solver.cpp:106] Iteration 12940, lr = 0.1
I0905 03:59:20.119081 90901 solver.cpp:228] Iteration 12950, loss = 0.440355
I0905 03:59:20.119132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440355 (* 1 = 0.440355 loss)
I0905 03:59:20.119146 90901 sgd_solver.cpp:106] Iteration 12950, lr = 0.1
I0905 03:59:26.184509 90901 solver.cpp:228] Iteration 12960, loss = 0.828441
I0905 03:59:26.184700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.828441 (* 1 = 0.828441 loss)
I0905 03:59:26.184721 90901 sgd_solver.cpp:106] Iteration 12960, lr = 0.1
I0905 03:59:32.306150 90901 solver.cpp:228] Iteration 12970, loss = 0.310971
I0905 03:59:32.306201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310971 (* 1 = 0.310971 loss)
I0905 03:59:32.306216 90901 sgd_solver.cpp:106] Iteration 12970, lr = 0.1
I0905 03:59:38.620601 90901 solver.cpp:228] Iteration 12980, loss = 0.192438
I0905 03:59:38.620678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192437 (* 1 = 0.192437 loss)
I0905 03:59:38.620697 90901 sgd_solver.cpp:106] Iteration 12980, lr = 0.1
I0905 03:59:44.663527 90901 solver.cpp:228] Iteration 12990, loss = 0.605323
I0905 03:59:44.663573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.605322 (* 1 = 0.605322 loss)
I0905 03:59:44.663589 90901 sgd_solver.cpp:106] Iteration 12990, lr = 0.1
I0905 03:59:50.735857 90901 solver.cpp:228] Iteration 13000, loss = 0.326586
I0905 03:59:50.735908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326586 (* 1 = 0.326586 loss)
I0905 03:59:50.735921 90901 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0905 03:59:56.141355 90901 solver.cpp:228] Iteration 13010, loss = 0.472777
I0905 03:59:56.141403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472777 (* 1 = 0.472777 loss)
I0905 03:59:56.141415 90901 sgd_solver.cpp:106] Iteration 13010, lr = 0.1
I0905 04:00:01.195071 90901 solver.cpp:228] Iteration 13020, loss = 0.295726
I0905 04:00:01.195238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295726 (* 1 = 0.295726 loss)
I0905 04:00:01.195283 90901 sgd_solver.cpp:106] Iteration 13020, lr = 0.1
I0905 04:00:06.237905 90901 solver.cpp:228] Iteration 13030, loss = 0.713084
I0905 04:00:06.237967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.713084 (* 1 = 0.713084 loss)
I0905 04:00:06.237982 90901 sgd_solver.cpp:106] Iteration 13030, lr = 0.1
I0905 04:00:11.286831 90901 solver.cpp:228] Iteration 13040, loss = 0.40974
I0905 04:00:11.286885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40974 (* 1 = 0.40974 loss)
I0905 04:00:11.286900 90901 sgd_solver.cpp:106] Iteration 13040, lr = 0.1
I0905 04:00:15.945281 90901 solver.cpp:228] Iteration 13050, loss = 0.41568
I0905 04:00:15.945333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41568 (* 1 = 0.41568 loss)
I0905 04:00:15.945345 90901 sgd_solver.cpp:106] Iteration 13050, lr = 0.1
I0905 04:00:20.589617 90901 solver.cpp:228] Iteration 13060, loss = 0.214328
I0905 04:00:20.589663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214328 (* 1 = 0.214328 loss)
I0905 04:00:20.589675 90901 sgd_solver.cpp:106] Iteration 13060, lr = 0.1
I0905 04:00:25.389195 90901 solver.cpp:228] Iteration 13070, loss = 0.180358
I0905 04:00:25.389243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180358 (* 1 = 0.180358 loss)
I0905 04:00:25.389257 90901 sgd_solver.cpp:106] Iteration 13070, lr = 0.1
I0905 04:00:30.343266 90901 solver.cpp:228] Iteration 13080, loss = 0.430452
I0905 04:00:30.343309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430452 (* 1 = 0.430452 loss)
I0905 04:00:30.343322 90901 sgd_solver.cpp:106] Iteration 13080, lr = 0.1
I0905 04:00:35.366610 90901 solver.cpp:228] Iteration 13090, loss = 0.443798
I0905 04:00:35.366753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443798 (* 1 = 0.443798 loss)
I0905 04:00:35.366792 90901 sgd_solver.cpp:106] Iteration 13090, lr = 0.1
I0905 04:00:40.389483 90901 solver.cpp:228] Iteration 13100, loss = 0.422284
I0905 04:00:40.389549 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422284 (* 1 = 0.422284 loss)
I0905 04:00:40.389564 90901 sgd_solver.cpp:106] Iteration 13100, lr = 0.1
I0905 04:00:45.454072 90901 solver.cpp:228] Iteration 13110, loss = 0.396304
I0905 04:00:45.454116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396304 (* 1 = 0.396304 loss)
I0905 04:00:45.454133 90901 sgd_solver.cpp:106] Iteration 13110, lr = 0.1
I0905 04:00:50.479135 90901 solver.cpp:228] Iteration 13120, loss = 0.394802
I0905 04:00:50.479197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394801 (* 1 = 0.394801 loss)
I0905 04:00:50.479212 90901 sgd_solver.cpp:106] Iteration 13120, lr = 0.1
I0905 04:00:55.509757 90901 solver.cpp:228] Iteration 13130, loss = 0.729593
I0905 04:00:55.509817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.729592 (* 1 = 0.729592 loss)
I0905 04:00:55.509831 90901 sgd_solver.cpp:106] Iteration 13130, lr = 0.1
I0905 04:01:00.555384 90901 solver.cpp:228] Iteration 13140, loss = 0.289296
I0905 04:01:00.555452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289296 (* 1 = 0.289296 loss)
I0905 04:01:00.555469 90901 sgd_solver.cpp:106] Iteration 13140, lr = 0.1
I0905 04:01:05.569182 90901 solver.cpp:228] Iteration 13150, loss = 0.288395
I0905 04:01:05.569494 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288395 (* 1 = 0.288395 loss)
I0905 04:01:05.569512 90901 sgd_solver.cpp:106] Iteration 13150, lr = 0.1
I0905 04:01:10.620594 90901 solver.cpp:228] Iteration 13160, loss = 0.387237
I0905 04:01:10.620646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387236 (* 1 = 0.387236 loss)
I0905 04:01:10.620659 90901 sgd_solver.cpp:106] Iteration 13160, lr = 0.1
I0905 04:01:16.337993 90901 solver.cpp:228] Iteration 13170, loss = 0.564191
I0905 04:01:16.338045 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.564191 (* 1 = 0.564191 loss)
I0905 04:01:16.338059 90901 sgd_solver.cpp:106] Iteration 13170, lr = 0.1
I0905 04:01:22.067157 90901 solver.cpp:228] Iteration 13180, loss = 0.399009
I0905 04:01:22.067208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399009 (* 1 = 0.399009 loss)
I0905 04:01:22.067220 90901 sgd_solver.cpp:106] Iteration 13180, lr = 0.1
I0905 04:01:28.171378 90901 solver.cpp:228] Iteration 13190, loss = 0.393092
I0905 04:01:28.171438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393092 (* 1 = 0.393092 loss)
I0905 04:01:28.171453 90901 sgd_solver.cpp:106] Iteration 13190, lr = 0.1
I0905 04:01:34.596817 90901 solver.cpp:228] Iteration 13200, loss = 0.251372
I0905 04:01:34.596868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251372 (* 1 = 0.251372 loss)
I0905 04:01:34.596882 90901 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0905 04:01:40.602067 90901 solver.cpp:228] Iteration 13210, loss = 0.292688
I0905 04:01:40.602286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292687 (* 1 = 0.292687 loss)
I0905 04:01:40.602318 90901 sgd_solver.cpp:106] Iteration 13210, lr = 0.1
I0905 04:01:46.969573 90901 solver.cpp:228] Iteration 13220, loss = 0.344226
I0905 04:01:46.969615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344226 (* 1 = 0.344226 loss)
I0905 04:01:46.969629 90901 sgd_solver.cpp:106] Iteration 13220, lr = 0.1
I0905 04:01:52.728456 90901 solver.cpp:228] Iteration 13230, loss = 0.179947
I0905 04:01:52.728507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179947 (* 1 = 0.179947 loss)
I0905 04:01:52.728518 90901 sgd_solver.cpp:106] Iteration 13230, lr = 0.1
I0905 04:01:58.787936 90901 solver.cpp:228] Iteration 13240, loss = 0.576305
I0905 04:01:58.787988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.576304 (* 1 = 0.576304 loss)
I0905 04:01:58.788002 90901 sgd_solver.cpp:106] Iteration 13240, lr = 0.1
I0905 04:02:05.167152 90901 solver.cpp:228] Iteration 13250, loss = 0.240759
I0905 04:02:05.167198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240759 (* 1 = 0.240759 loss)
I0905 04:02:05.167212 90901 sgd_solver.cpp:106] Iteration 13250, lr = 0.1
I0905 04:02:10.534972 90901 solver.cpp:228] Iteration 13260, loss = 0.200741
I0905 04:02:10.535022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20074 (* 1 = 0.20074 loss)
I0905 04:02:10.535037 90901 sgd_solver.cpp:106] Iteration 13260, lr = 0.1
I0905 04:02:16.103602 90901 solver.cpp:228] Iteration 13270, loss = 0.487195
I0905 04:02:16.103804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487195 (* 1 = 0.487195 loss)
I0905 04:02:16.103840 90901 sgd_solver.cpp:106] Iteration 13270, lr = 0.1
I0905 04:02:21.835289 90901 solver.cpp:228] Iteration 13280, loss = 0.327941
I0905 04:02:21.835342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327941 (* 1 = 0.327941 loss)
I0905 04:02:21.835355 90901 sgd_solver.cpp:106] Iteration 13280, lr = 0.1
I0905 04:02:28.231717 90901 solver.cpp:228] Iteration 13290, loss = 0.592524
I0905 04:02:28.231768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.592523 (* 1 = 0.592523 loss)
I0905 04:02:28.231782 90901 sgd_solver.cpp:106] Iteration 13290, lr = 0.1
I0905 04:02:34.216632 90901 solver.cpp:228] Iteration 13300, loss = 0.246024
I0905 04:02:34.216675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246024 (* 1 = 0.246024 loss)
I0905 04:02:34.216691 90901 sgd_solver.cpp:106] Iteration 13300, lr = 0.1
I0905 04:02:40.137572 90901 solver.cpp:228] Iteration 13310, loss = 0.503604
I0905 04:02:40.137645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.503604 (* 1 = 0.503604 loss)
I0905 04:02:40.137660 90901 sgd_solver.cpp:106] Iteration 13310, lr = 0.1
I0905 04:02:46.456764 90901 solver.cpp:228] Iteration 13320, loss = 0.619532
I0905 04:02:46.456914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.619532 (* 1 = 0.619532 loss)
I0905 04:02:46.456957 90901 sgd_solver.cpp:106] Iteration 13320, lr = 0.1
I0905 04:02:52.537807 90901 solver.cpp:228] Iteration 13330, loss = 0.444913
I0905 04:02:52.537852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444913 (* 1 = 0.444913 loss)
I0905 04:02:52.537864 90901 sgd_solver.cpp:106] Iteration 13330, lr = 0.1
I0905 04:02:58.743962 90901 solver.cpp:228] Iteration 13340, loss = 0.259495
I0905 04:02:58.744014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259495 (* 1 = 0.259495 loss)
I0905 04:02:58.744027 90901 sgd_solver.cpp:106] Iteration 13340, lr = 0.1
I0905 04:03:04.899157 90901 solver.cpp:228] Iteration 13350, loss = 0.224538
I0905 04:03:04.899207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224538 (* 1 = 0.224538 loss)
I0905 04:03:04.899222 90901 sgd_solver.cpp:106] Iteration 13350, lr = 0.1
I0905 04:03:10.847203 90901 solver.cpp:228] Iteration 13360, loss = 0.204538
I0905 04:03:10.847254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204538 (* 1 = 0.204538 loss)
I0905 04:03:10.847270 90901 sgd_solver.cpp:106] Iteration 13360, lr = 0.1
I0905 04:03:17.034626 90901 solver.cpp:228] Iteration 13370, loss = 0.314472
I0905 04:03:17.034863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314472 (* 1 = 0.314472 loss)
I0905 04:03:17.034880 90901 sgd_solver.cpp:106] Iteration 13370, lr = 0.1
I0905 04:03:22.917202 90901 solver.cpp:228] Iteration 13380, loss = 0.443422
I0905 04:03:22.917258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443422 (* 1 = 0.443422 loss)
I0905 04:03:22.917270 90901 sgd_solver.cpp:106] Iteration 13380, lr = 0.1
I0905 04:03:29.293189 90901 solver.cpp:228] Iteration 13390, loss = 0.279301
I0905 04:03:29.293237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279301 (* 1 = 0.279301 loss)
I0905 04:03:29.293249 90901 sgd_solver.cpp:106] Iteration 13390, lr = 0.1
I0905 04:03:35.333933 90901 solver.cpp:228] Iteration 13400, loss = 0.646839
I0905 04:03:35.333983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.646839 (* 1 = 0.646839 loss)
I0905 04:03:35.333997 90901 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0905 04:03:41.415105 90901 solver.cpp:228] Iteration 13410, loss = 0.336203
I0905 04:03:41.415156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336203 (* 1 = 0.336203 loss)
I0905 04:03:41.415171 90901 sgd_solver.cpp:106] Iteration 13410, lr = 0.1
I0905 04:03:47.498891 90901 solver.cpp:228] Iteration 13420, loss = 0.270608
I0905 04:03:47.499089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270608 (* 1 = 0.270608 loss)
I0905 04:03:47.499122 90901 sgd_solver.cpp:106] Iteration 13420, lr = 0.1
I0905 04:03:53.212343 90901 solver.cpp:228] Iteration 13430, loss = 0.802299
I0905 04:03:53.212390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.802299 (* 1 = 0.802299 loss)
I0905 04:03:53.212402 90901 sgd_solver.cpp:106] Iteration 13430, lr = 0.1
I0905 04:03:59.120841 90901 solver.cpp:228] Iteration 13440, loss = 0.355087
I0905 04:03:59.120893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355086 (* 1 = 0.355086 loss)
I0905 04:03:59.120904 90901 sgd_solver.cpp:106] Iteration 13440, lr = 0.1
I0905 04:04:04.421133 90901 solver.cpp:228] Iteration 13450, loss = 0.178113
I0905 04:04:04.421186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178113 (* 1 = 0.178113 loss)
I0905 04:04:04.421198 90901 sgd_solver.cpp:106] Iteration 13450, lr = 0.1
I0905 04:04:10.526844 90901 solver.cpp:228] Iteration 13460, loss = 0.853033
I0905 04:04:10.526911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.853032 (* 1 = 0.853032 loss)
I0905 04:04:10.526926 90901 sgd_solver.cpp:106] Iteration 13460, lr = 0.1
I0905 04:04:16.589514 90901 solver.cpp:228] Iteration 13470, loss = 0.380187
I0905 04:04:16.589576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380187 (* 1 = 0.380187 loss)
I0905 04:04:16.589591 90901 sgd_solver.cpp:106] Iteration 13470, lr = 0.1
I0905 04:04:22.635315 90901 solver.cpp:228] Iteration 13480, loss = 0.637491
I0905 04:04:22.635509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.637491 (* 1 = 0.637491 loss)
I0905 04:04:22.635550 90901 sgd_solver.cpp:106] Iteration 13480, lr = 0.1
I0905 04:04:29.087738 90901 solver.cpp:228] Iteration 13490, loss = 0.414001
I0905 04:04:29.087790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414001 (* 1 = 0.414001 loss)
I0905 04:04:29.087805 90901 sgd_solver.cpp:106] Iteration 13490, lr = 0.1
I0905 04:04:35.029820 90901 solver.cpp:228] Iteration 13500, loss = 0.547539
I0905 04:04:35.029860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547539 (* 1 = 0.547539 loss)
I0905 04:04:35.029872 90901 sgd_solver.cpp:106] Iteration 13500, lr = 0.1
I0905 04:04:41.211881 90901 solver.cpp:228] Iteration 13510, loss = 0.437116
I0905 04:04:41.211961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437116 (* 1 = 0.437116 loss)
I0905 04:04:41.211980 90901 sgd_solver.cpp:106] Iteration 13510, lr = 0.1
I0905 04:04:47.241582 90901 solver.cpp:228] Iteration 13520, loss = 0.174697
I0905 04:04:47.241628 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174696 (* 1 = 0.174696 loss)
I0905 04:04:47.241646 90901 sgd_solver.cpp:106] Iteration 13520, lr = 0.1
I0905 04:04:53.352071 90901 solver.cpp:228] Iteration 13530, loss = 0.28737
I0905 04:04:53.352262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28737 (* 1 = 0.28737 loss)
I0905 04:04:53.352274 90901 sgd_solver.cpp:106] Iteration 13530, lr = 0.1
I0905 04:04:59.415088 90901 solver.cpp:228] Iteration 13540, loss = 0.221698
I0905 04:04:59.415135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221698 (* 1 = 0.221698 loss)
I0905 04:04:59.415148 90901 sgd_solver.cpp:106] Iteration 13540, lr = 0.1
I0905 04:05:05.443765 90901 solver.cpp:228] Iteration 13550, loss = 0.343711
I0905 04:05:05.443823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343711 (* 1 = 0.343711 loss)
I0905 04:05:05.443837 90901 sgd_solver.cpp:106] Iteration 13550, lr = 0.1
I0905 04:05:11.537534 90901 solver.cpp:228] Iteration 13560, loss = 0.588101
I0905 04:05:11.537581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.588101 (* 1 = 0.588101 loss)
I0905 04:05:11.537595 90901 sgd_solver.cpp:106] Iteration 13560, lr = 0.1
I0905 04:05:17.848160 90901 solver.cpp:228] Iteration 13570, loss = 0.358396
I0905 04:05:17.848212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358396 (* 1 = 0.358396 loss)
I0905 04:05:17.848224 90901 sgd_solver.cpp:106] Iteration 13570, lr = 0.1
I0905 04:05:23.927407 90901 solver.cpp:228] Iteration 13580, loss = 0.194019
I0905 04:05:23.927645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194019 (* 1 = 0.194019 loss)
I0905 04:05:23.927662 90901 sgd_solver.cpp:106] Iteration 13580, lr = 0.1
I0905 04:05:29.678392 90901 solver.cpp:228] Iteration 13590, loss = 0.3054
I0905 04:05:29.678443 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3054 (* 1 = 0.3054 loss)
I0905 04:05:29.678457 90901 sgd_solver.cpp:106] Iteration 13590, lr = 0.1
I0905 04:05:35.876297 90901 solver.cpp:337] Iteration 13600, Testing net (#0)
I0905 04:06:16.998399 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.527188
I0905 04:06:16.998574 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.6355 (* 1 = 1.6355 loss)
I0905 04:06:17.347508 90901 solver.cpp:228] Iteration 13600, loss = 0.921024
I0905 04:06:17.347565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.921023 (* 1 = 0.921023 loss)
I0905 04:06:17.347584 90901 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0905 04:06:23.598306 90901 solver.cpp:228] Iteration 13610, loss = 0.37
I0905 04:06:23.598369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369999 (* 1 = 0.369999 loss)
I0905 04:06:23.598384 90901 sgd_solver.cpp:106] Iteration 13610, lr = 0.1
I0905 04:06:29.392287 90901 solver.cpp:228] Iteration 13620, loss = 0.485939
I0905 04:06:29.392343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.485939 (* 1 = 0.485939 loss)
I0905 04:06:29.392356 90901 sgd_solver.cpp:106] Iteration 13620, lr = 0.1
I0905 04:06:35.738847 90901 solver.cpp:228] Iteration 13630, loss = 0.349478
I0905 04:06:35.738889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349478 (* 1 = 0.349478 loss)
I0905 04:06:35.738903 90901 sgd_solver.cpp:106] Iteration 13630, lr = 0.1
I0905 04:06:41.508729 90901 solver.cpp:228] Iteration 13640, loss = 0.573996
I0905 04:06:41.508785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.573996 (* 1 = 0.573996 loss)
I0905 04:06:41.508800 90901 sgd_solver.cpp:106] Iteration 13640, lr = 0.1
I0905 04:06:47.663935 90901 solver.cpp:228] Iteration 13650, loss = 0.168683
I0905 04:06:47.664089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168683 (* 1 = 0.168683 loss)
I0905 04:06:47.664130 90901 sgd_solver.cpp:106] Iteration 13650, lr = 0.1
I0905 04:06:53.734339 90901 solver.cpp:228] Iteration 13660, loss = 0.425726
I0905 04:06:53.734387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425726 (* 1 = 0.425726 loss)
I0905 04:06:53.734401 90901 sgd_solver.cpp:106] Iteration 13660, lr = 0.1
I0905 04:06:59.844565 90901 solver.cpp:228] Iteration 13670, loss = 0.244471
I0905 04:06:59.844619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244471 (* 1 = 0.244471 loss)
I0905 04:06:59.844632 90901 sgd_solver.cpp:106] Iteration 13670, lr = 0.1
I0905 04:07:06.104640 90901 solver.cpp:228] Iteration 13680, loss = 0.173682
I0905 04:07:06.104687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173682 (* 1 = 0.173682 loss)
I0905 04:07:06.104703 90901 sgd_solver.cpp:106] Iteration 13680, lr = 0.1
I0905 04:07:12.147055 90901 solver.cpp:228] Iteration 13690, loss = 0.396141
I0905 04:07:12.147109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396141 (* 1 = 0.396141 loss)
I0905 04:07:12.147124 90901 sgd_solver.cpp:106] Iteration 13690, lr = 0.1
I0905 04:07:18.253304 90901 solver.cpp:228] Iteration 13700, loss = 0.342528
I0905 04:07:18.253527 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342528 (* 1 = 0.342528 loss)
I0905 04:07:18.253542 90901 sgd_solver.cpp:106] Iteration 13700, lr = 0.1
I0905 04:07:24.341787 90901 solver.cpp:228] Iteration 13710, loss = 0.225062
I0905 04:07:24.341835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225062 (* 1 = 0.225062 loss)
I0905 04:07:24.341846 90901 sgd_solver.cpp:106] Iteration 13710, lr = 0.1
I0905 04:07:30.337267 90901 solver.cpp:228] Iteration 13720, loss = 0.18167
I0905 04:07:30.337316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181669 (* 1 = 0.181669 loss)
I0905 04:07:30.337329 90901 sgd_solver.cpp:106] Iteration 13720, lr = 0.1
I0905 04:07:35.889039 90901 solver.cpp:228] Iteration 13730, loss = 0.254319
I0905 04:07:35.889086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254319 (* 1 = 0.254319 loss)
I0905 04:07:35.889098 90901 sgd_solver.cpp:106] Iteration 13730, lr = 0.1
I0905 04:07:41.488574 90901 solver.cpp:228] Iteration 13740, loss = 0.632265
I0905 04:07:41.488641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.632265 (* 1 = 0.632265 loss)
I0905 04:07:41.488657 90901 sgd_solver.cpp:106] Iteration 13740, lr = 0.1
I0905 04:07:47.224823 90901 solver.cpp:228] Iteration 13750, loss = 0.590041
I0905 04:07:47.224871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.590041 (* 1 = 0.590041 loss)
I0905 04:07:47.224885 90901 sgd_solver.cpp:106] Iteration 13750, lr = 0.1
I0905 04:07:53.274449 90901 solver.cpp:228] Iteration 13760, loss = 0.423789
I0905 04:07:53.274586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423789 (* 1 = 0.423789 loss)
I0905 04:07:53.274623 90901 sgd_solver.cpp:106] Iteration 13760, lr = 0.1
I0905 04:07:59.635565 90901 solver.cpp:228] Iteration 13770, loss = 0.564167
I0905 04:07:59.635632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.564167 (* 1 = 0.564167 loss)
I0905 04:07:59.635651 90901 sgd_solver.cpp:106] Iteration 13770, lr = 0.1
I0905 04:08:05.706887 90901 solver.cpp:228] Iteration 13780, loss = 0.254405
I0905 04:08:05.706945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254405 (* 1 = 0.254405 loss)
I0905 04:08:05.706959 90901 sgd_solver.cpp:106] Iteration 13780, lr = 0.1
I0905 04:08:11.743510 90901 solver.cpp:228] Iteration 13790, loss = 0.318228
I0905 04:08:11.743561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318228 (* 1 = 0.318228 loss)
I0905 04:08:11.743574 90901 sgd_solver.cpp:106] Iteration 13790, lr = 0.1
I0905 04:08:17.806689 90901 solver.cpp:228] Iteration 13800, loss = 0.487219
I0905 04:08:17.806740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487219 (* 1 = 0.487219 loss)
I0905 04:08:17.806752 90901 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0905 04:08:23.890444 90901 solver.cpp:228] Iteration 13810, loss = 0.37245
I0905 04:08:23.890597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37245 (* 1 = 0.37245 loss)
I0905 04:08:23.890617 90901 sgd_solver.cpp:106] Iteration 13810, lr = 0.1
I0905 04:08:29.937906 90901 solver.cpp:228] Iteration 13820, loss = 0.482138
I0905 04:08:29.937947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482138 (* 1 = 0.482138 loss)
I0905 04:08:29.937960 90901 sgd_solver.cpp:106] Iteration 13820, lr = 0.1
I0905 04:08:36.131652 90901 solver.cpp:228] Iteration 13830, loss = 0.363969
I0905 04:08:36.131711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363969 (* 1 = 0.363969 loss)
I0905 04:08:36.131729 90901 sgd_solver.cpp:106] Iteration 13830, lr = 0.1
I0905 04:08:42.022348 90901 solver.cpp:228] Iteration 13840, loss = 0.408135
I0905 04:08:42.022411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408135 (* 1 = 0.408135 loss)
I0905 04:08:42.022433 90901 sgd_solver.cpp:106] Iteration 13840, lr = 0.1
I0905 04:08:48.398253 90901 solver.cpp:228] Iteration 13850, loss = 0.292172
I0905 04:08:48.398308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292172 (* 1 = 0.292172 loss)
I0905 04:08:48.398321 90901 sgd_solver.cpp:106] Iteration 13850, lr = 0.1
I0905 04:08:54.428520 90901 solver.cpp:228] Iteration 13860, loss = 0.510766
I0905 04:08:54.428726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.510766 (* 1 = 0.510766 loss)
I0905 04:08:54.428771 90901 sgd_solver.cpp:106] Iteration 13860, lr = 0.1
I0905 04:09:00.487000 90901 solver.cpp:228] Iteration 13870, loss = 0.200699
I0905 04:09:00.487051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200699 (* 1 = 0.200699 loss)
I0905 04:09:00.487062 90901 sgd_solver.cpp:106] Iteration 13870, lr = 0.1
I0905 04:09:06.881508 90901 solver.cpp:228] Iteration 13880, loss = 0.405438
I0905 04:09:06.881566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.405438 (* 1 = 0.405438 loss)
I0905 04:09:06.881580 90901 sgd_solver.cpp:106] Iteration 13880, lr = 0.1
I0905 04:09:12.600157 90901 solver.cpp:228] Iteration 13890, loss = 0.265654
I0905 04:09:12.600208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265653 (* 1 = 0.265653 loss)
I0905 04:09:12.600222 90901 sgd_solver.cpp:106] Iteration 13890, lr = 0.1
I0905 04:09:19.028297 90901 solver.cpp:228] Iteration 13900, loss = 0.150412
I0905 04:09:19.028357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150411 (* 1 = 0.150411 loss)
I0905 04:09:19.028373 90901 sgd_solver.cpp:106] Iteration 13900, lr = 0.1
I0905 04:09:24.563097 90901 solver.cpp:228] Iteration 13910, loss = 0.560281
I0905 04:09:24.563280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.560281 (* 1 = 0.560281 loss)
I0905 04:09:24.563297 90901 sgd_solver.cpp:106] Iteration 13910, lr = 0.1
I0905 04:09:29.946090 90901 solver.cpp:228] Iteration 13920, loss = 0.370014
I0905 04:09:29.946146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370014 (* 1 = 0.370014 loss)
I0905 04:09:29.946161 90901 sgd_solver.cpp:106] Iteration 13920, lr = 0.1
I0905 04:09:36.015450 90901 solver.cpp:228] Iteration 13930, loss = 0.401738
I0905 04:09:36.015497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401738 (* 1 = 0.401738 loss)
I0905 04:09:36.015511 90901 sgd_solver.cpp:106] Iteration 13930, lr = 0.1
I0905 04:09:42.072239 90901 solver.cpp:228] Iteration 13940, loss = 0.171352
I0905 04:09:42.072288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171352 (* 1 = 0.171352 loss)
I0905 04:09:42.072300 90901 sgd_solver.cpp:106] Iteration 13940, lr = 0.1
I0905 04:09:48.136638 90901 solver.cpp:228] Iteration 13950, loss = 0.54954
I0905 04:09:48.136687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.54954 (* 1 = 0.54954 loss)
I0905 04:09:48.136700 90901 sgd_solver.cpp:106] Iteration 13950, lr = 0.1
I0905 04:09:53.891713 90901 solver.cpp:228] Iteration 13960, loss = 0.175782
I0905 04:09:53.891760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175782 (* 1 = 0.175782 loss)
I0905 04:09:53.891773 90901 sgd_solver.cpp:106] Iteration 13960, lr = 0.1
I0905 04:09:59.971921 90901 solver.cpp:228] Iteration 13970, loss = 0.463984
I0905 04:09:59.972064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463984 (* 1 = 0.463984 loss)
I0905 04:09:59.972090 90901 sgd_solver.cpp:106] Iteration 13970, lr = 0.1
I0905 04:10:06.379200 90901 solver.cpp:228] Iteration 13980, loss = 0.287565
I0905 04:10:06.379247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287565 (* 1 = 0.287565 loss)
I0905 04:10:06.379262 90901 sgd_solver.cpp:106] Iteration 13980, lr = 0.1
I0905 04:10:12.443598 90901 solver.cpp:228] Iteration 13990, loss = 0.482864
I0905 04:10:12.443645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482864 (* 1 = 0.482864 loss)
I0905 04:10:12.443658 90901 sgd_solver.cpp:106] Iteration 13990, lr = 0.1
I0905 04:10:18.522948 90901 solver.cpp:228] Iteration 14000, loss = 0.676421
I0905 04:10:18.522995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.676421 (* 1 = 0.676421 loss)
I0905 04:10:18.523008 90901 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0905 04:10:24.591939 90901 solver.cpp:228] Iteration 14010, loss = 0.358115
I0905 04:10:24.591987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358115 (* 1 = 0.358115 loss)
I0905 04:10:24.592000 90901 sgd_solver.cpp:106] Iteration 14010, lr = 0.1
I0905 04:10:30.689137 90901 solver.cpp:228] Iteration 14020, loss = 0.383163
I0905 04:10:30.689357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383163 (* 1 = 0.383163 loss)
I0905 04:10:30.689388 90901 sgd_solver.cpp:106] Iteration 14020, lr = 0.1
I0905 04:10:36.673374 90901 solver.cpp:228] Iteration 14030, loss = 0.766226
I0905 04:10:36.673429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.766226 (* 1 = 0.766226 loss)
I0905 04:10:36.673444 90901 sgd_solver.cpp:106] Iteration 14030, lr = 0.1
I0905 04:10:42.760393 90901 solver.cpp:228] Iteration 14040, loss = 0.450391
I0905 04:10:42.760462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450391 (* 1 = 0.450391 loss)
I0905 04:10:42.760476 90901 sgd_solver.cpp:106] Iteration 14040, lr = 0.1
I0905 04:10:48.490615 90901 solver.cpp:228] Iteration 14050, loss = 0.646758
I0905 04:10:48.490669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.646758 (* 1 = 0.646758 loss)
I0905 04:10:48.490682 90901 sgd_solver.cpp:106] Iteration 14050, lr = 0.1
I0905 04:10:55.244534 90901 solver.cpp:228] Iteration 14060, loss = 0.574372
I0905 04:10:55.244599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.574372 (* 1 = 0.574372 loss)
I0905 04:10:55.244616 90901 sgd_solver.cpp:106] Iteration 14060, lr = 0.1
I0905 04:11:00.976707 90901 solver.cpp:228] Iteration 14070, loss = 0.150507
I0905 04:11:00.976929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150507 (* 1 = 0.150507 loss)
I0905 04:11:00.976946 90901 sgd_solver.cpp:106] Iteration 14070, lr = 0.1
I0905 04:11:07.364136 90901 solver.cpp:228] Iteration 14080, loss = 0.457477
I0905 04:11:07.364179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457476 (* 1 = 0.457476 loss)
I0905 04:11:07.364192 90901 sgd_solver.cpp:106] Iteration 14080, lr = 0.1
I0905 04:11:12.918745 90901 solver.cpp:228] Iteration 14090, loss = 0.282262
I0905 04:11:12.918803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282262 (* 1 = 0.282262 loss)
I0905 04:11:12.918817 90901 sgd_solver.cpp:106] Iteration 14090, lr = 0.1
I0905 04:11:18.066742 90901 solver.cpp:228] Iteration 14100, loss = 0.507813
I0905 04:11:18.066790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507812 (* 1 = 0.507812 loss)
I0905 04:11:18.066803 90901 sgd_solver.cpp:106] Iteration 14100, lr = 0.1
I0905 04:11:24.302320 90901 solver.cpp:228] Iteration 14110, loss = 0.611431
I0905 04:11:24.302384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.611431 (* 1 = 0.611431 loss)
I0905 04:11:24.302398 90901 sgd_solver.cpp:106] Iteration 14110, lr = 0.1
I0905 04:11:30.331238 90901 solver.cpp:228] Iteration 14120, loss = 0.296421
I0905 04:11:30.331279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296421 (* 1 = 0.296421 loss)
I0905 04:11:30.331293 90901 sgd_solver.cpp:106] Iteration 14120, lr = 0.1
I0905 04:11:36.392124 90901 solver.cpp:228] Iteration 14130, loss = 0.444084
I0905 04:11:36.392319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444084 (* 1 = 0.444084 loss)
I0905 04:11:36.392346 90901 sgd_solver.cpp:106] Iteration 14130, lr = 0.1
I0905 04:11:42.152946 90901 solver.cpp:228] Iteration 14140, loss = 0.805862
I0905 04:11:42.152997 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.805862 (* 1 = 0.805862 loss)
I0905 04:11:42.153010 90901 sgd_solver.cpp:106] Iteration 14140, lr = 0.1
I0905 04:11:48.546586 90901 solver.cpp:228] Iteration 14150, loss = 0.491366
I0905 04:11:48.546643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491366 (* 1 = 0.491366 loss)
I0905 04:11:48.546659 90901 sgd_solver.cpp:106] Iteration 14150, lr = 0.1
I0905 04:11:54.607025 90901 solver.cpp:228] Iteration 14160, loss = 0.762129
I0905 04:11:54.607082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.762129 (* 1 = 0.762129 loss)
I0905 04:11:54.607095 90901 sgd_solver.cpp:106] Iteration 14160, lr = 0.1
I0905 04:12:00.962191 90901 solver.cpp:228] Iteration 14170, loss = 0.423274
I0905 04:12:00.962255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423274 (* 1 = 0.423274 loss)
I0905 04:12:00.962271 90901 sgd_solver.cpp:106] Iteration 14170, lr = 0.1
I0905 04:12:07.013588 90901 solver.cpp:228] Iteration 14180, loss = 0.445685
I0905 04:12:07.013806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445685 (* 1 = 0.445685 loss)
I0905 04:12:07.013829 90901 sgd_solver.cpp:106] Iteration 14180, lr = 0.1
I0905 04:12:13.064577 90901 solver.cpp:228] Iteration 14190, loss = 0.592306
I0905 04:12:13.064622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.592306 (* 1 = 0.592306 loss)
I0905 04:12:13.064635 90901 sgd_solver.cpp:106] Iteration 14190, lr = 0.1
I0905 04:12:19.430274 90901 solver.cpp:228] Iteration 14200, loss = 0.257897
I0905 04:12:19.430323 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257896 (* 1 = 0.257896 loss)
I0905 04:12:19.430337 90901 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0905 04:12:25.207693 90901 solver.cpp:228] Iteration 14210, loss = 0.510829
I0905 04:12:25.207733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.510829 (* 1 = 0.510829 loss)
I0905 04:12:25.207746 90901 sgd_solver.cpp:106] Iteration 14210, lr = 0.1
I0905 04:12:31.600956 90901 solver.cpp:228] Iteration 14220, loss = 0.780105
I0905 04:12:31.601001 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.780105 (* 1 = 0.780105 loss)
I0905 04:12:31.601016 90901 sgd_solver.cpp:106] Iteration 14220, lr = 0.1
I0905 04:12:37.674279 90901 solver.cpp:228] Iteration 14230, loss = 0.308693
I0905 04:12:37.674454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308693 (* 1 = 0.308693 loss)
I0905 04:12:37.674469 90901 sgd_solver.cpp:106] Iteration 14230, lr = 0.1
I0905 04:12:43.423424 90901 solver.cpp:228] Iteration 14240, loss = 0.296128
I0905 04:12:43.423475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296128 (* 1 = 0.296128 loss)
I0905 04:12:43.423488 90901 sgd_solver.cpp:106] Iteration 14240, lr = 0.1
I0905 04:12:49.704711 90901 solver.cpp:228] Iteration 14250, loss = 0.650989
I0905 04:12:49.704758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.650989 (* 1 = 0.650989 loss)
I0905 04:12:49.704771 90901 sgd_solver.cpp:106] Iteration 14250, lr = 0.1
I0905 04:12:55.807729 90901 solver.cpp:228] Iteration 14260, loss = 0.272357
I0905 04:12:55.807778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272357 (* 1 = 0.272357 loss)
I0905 04:12:55.807792 90901 sgd_solver.cpp:106] Iteration 14260, lr = 0.1
I0905 04:13:01.149219 90901 solver.cpp:228] Iteration 14270, loss = 0.287638
I0905 04:13:01.149267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287638 (* 1 = 0.287638 loss)
I0905 04:13:01.149279 90901 sgd_solver.cpp:106] Iteration 14270, lr = 0.1
I0905 04:13:06.436889 90901 solver.cpp:228] Iteration 14280, loss = 0.317228
I0905 04:13:06.436930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317228 (* 1 = 0.317228 loss)
I0905 04:13:06.436944 90901 sgd_solver.cpp:106] Iteration 14280, lr = 0.1
I0905 04:13:12.516624 90901 solver.cpp:228] Iteration 14290, loss = 0.306091
I0905 04:13:12.516760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306091 (* 1 = 0.306091 loss)
I0905 04:13:12.516808 90901 sgd_solver.cpp:106] Iteration 14290, lr = 0.1
I0905 04:13:18.600075 90901 solver.cpp:228] Iteration 14300, loss = 0.485615
I0905 04:13:18.600134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.485615 (* 1 = 0.485615 loss)
I0905 04:13:18.600152 90901 sgd_solver.cpp:106] Iteration 14300, lr = 0.1
I0905 04:13:24.970583 90901 solver.cpp:228] Iteration 14310, loss = 0.247163
I0905 04:13:24.970656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247163 (* 1 = 0.247163 loss)
I0905 04:13:24.970674 90901 sgd_solver.cpp:106] Iteration 14310, lr = 0.1
I0905 04:13:30.732574 90901 solver.cpp:228] Iteration 14320, loss = 0.168842
I0905 04:13:30.732619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168841 (* 1 = 0.168841 loss)
I0905 04:13:30.732631 90901 sgd_solver.cpp:106] Iteration 14320, lr = 0.1
I0905 04:13:37.125665 90901 solver.cpp:228] Iteration 14330, loss = 0.239943
I0905 04:13:37.125707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239943 (* 1 = 0.239943 loss)
I0905 04:13:37.125720 90901 sgd_solver.cpp:106] Iteration 14330, lr = 0.1
I0905 04:13:43.205409 90901 solver.cpp:228] Iteration 14340, loss = 0.875589
I0905 04:13:43.205734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.875589 (* 1 = 0.875589 loss)
I0905 04:13:43.205754 90901 sgd_solver.cpp:106] Iteration 14340, lr = 0.1
I0905 04:13:48.941262 90901 solver.cpp:228] Iteration 14350, loss = 0.238047
I0905 04:13:48.941303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238047 (* 1 = 0.238047 loss)
I0905 04:13:48.941315 90901 sgd_solver.cpp:106] Iteration 14350, lr = 0.1
I0905 04:13:55.349341 90901 solver.cpp:228] Iteration 14360, loss = 0.465702
I0905 04:13:55.349395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465702 (* 1 = 0.465702 loss)
I0905 04:13:55.349408 90901 sgd_solver.cpp:106] Iteration 14360, lr = 0.1
I0905 04:14:01.407747 90901 solver.cpp:228] Iteration 14370, loss = 0.347702
I0905 04:14:01.407802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347702 (* 1 = 0.347702 loss)
I0905 04:14:01.407817 90901 sgd_solver.cpp:106] Iteration 14370, lr = 0.1
I0905 04:14:07.796710 90901 solver.cpp:228] Iteration 14380, loss = 0.396419
I0905 04:14:07.796763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396419 (* 1 = 0.396419 loss)
I0905 04:14:07.796777 90901 sgd_solver.cpp:106] Iteration 14380, lr = 0.1
I0905 04:14:13.875486 90901 solver.cpp:228] Iteration 14390, loss = 0.3987
I0905 04:14:13.875691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3987 (* 1 = 0.3987 loss)
I0905 04:14:13.875707 90901 sgd_solver.cpp:106] Iteration 14390, lr = 0.1
I0905 04:14:19.719736 90901 solver.cpp:337] Iteration 14400, Testing net (#0)
I0905 04:15:00.793004 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.56875
I0905 04:15:00.793159 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.895758 (* 1 = 0.895758 loss)
I0905 04:15:01.009907 90901 solver.cpp:228] Iteration 14400, loss = 0.239788
I0905 04:15:01.009940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239788 (* 1 = 0.239788 loss)
I0905 04:15:01.009961 90901 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0905 04:15:07.088690 90901 solver.cpp:228] Iteration 14410, loss = 0.749384
I0905 04:15:07.088742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.749384 (* 1 = 0.749384 loss)
I0905 04:15:07.088753 90901 sgd_solver.cpp:106] Iteration 14410, lr = 0.1
I0905 04:15:13.471719 90901 solver.cpp:228] Iteration 14420, loss = 0.255203
I0905 04:15:13.471765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255203 (* 1 = 0.255203 loss)
I0905 04:15:13.471779 90901 sgd_solver.cpp:106] Iteration 14420, lr = 0.1
I0905 04:15:19.572736 90901 solver.cpp:228] Iteration 14430, loss = 0.40783
I0905 04:15:19.572783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40783 (* 1 = 0.40783 loss)
I0905 04:15:19.572798 90901 sgd_solver.cpp:106] Iteration 14430, lr = 0.1
I0905 04:15:25.318874 90901 solver.cpp:228] Iteration 14440, loss = 0.779073
I0905 04:15:25.318928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.779072 (* 1 = 0.779072 loss)
I0905 04:15:25.318940 90901 sgd_solver.cpp:106] Iteration 14440, lr = 0.1
I0905 04:15:31.696380 90901 solver.cpp:228] Iteration 14450, loss = 1.12149
I0905 04:15:31.696524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.12149 (* 1 = 1.12149 loss)
I0905 04:15:31.696564 90901 sgd_solver.cpp:106] Iteration 14450, lr = 0.1
I0905 04:15:37.113435 90901 solver.cpp:228] Iteration 14460, loss = 0.476022
I0905 04:15:37.113479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476021 (* 1 = 0.476021 loss)
I0905 04:15:37.113492 90901 sgd_solver.cpp:106] Iteration 14460, lr = 0.1
I0905 04:15:43.513188 90901 solver.cpp:228] Iteration 14470, loss = 0.375052
I0905 04:15:43.513239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375052 (* 1 = 0.375052 loss)
I0905 04:15:43.513252 90901 sgd_solver.cpp:106] Iteration 14470, lr = 0.1
I0905 04:15:49.890292 90901 solver.cpp:228] Iteration 14480, loss = 0.308439
I0905 04:15:49.890347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308439 (* 1 = 0.308439 loss)
I0905 04:15:49.890362 90901 sgd_solver.cpp:106] Iteration 14480, lr = 0.1
I0905 04:15:55.650713 90901 solver.cpp:228] Iteration 14490, loss = 0.342277
I0905 04:15:55.650756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342277 (* 1 = 0.342277 loss)
I0905 04:15:55.650768 90901 sgd_solver.cpp:106] Iteration 14490, lr = 0.1
I0905 04:16:01.999171 90901 solver.cpp:228] Iteration 14500, loss = 0.317775
I0905 04:16:01.999326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317775 (* 1 = 0.317775 loss)
I0905 04:16:01.999373 90901 sgd_solver.cpp:106] Iteration 14500, lr = 0.1
I0905 04:16:08.068002 90901 solver.cpp:228] Iteration 14510, loss = 0.253266
I0905 04:16:08.068049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253265 (* 1 = 0.253265 loss)
I0905 04:16:08.068064 90901 sgd_solver.cpp:106] Iteration 14510, lr = 0.1
I0905 04:16:14.139711 90901 solver.cpp:228] Iteration 14520, loss = 0.319881
I0905 04:16:14.139770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319881 (* 1 = 0.319881 loss)
I0905 04:16:14.139785 90901 sgd_solver.cpp:106] Iteration 14520, lr = 0.1
I0905 04:16:20.512126 90901 solver.cpp:228] Iteration 14530, loss = 0.294063
I0905 04:16:20.512171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294062 (* 1 = 0.294062 loss)
I0905 04:16:20.512186 90901 sgd_solver.cpp:106] Iteration 14530, lr = 0.1
I0905 04:16:26.576741 90901 solver.cpp:228] Iteration 14540, loss = 0.38991
I0905 04:16:26.576786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38991 (* 1 = 0.38991 loss)
I0905 04:16:26.576799 90901 sgd_solver.cpp:106] Iteration 14540, lr = 0.1
I0905 04:16:32.246943 90901 solver.cpp:228] Iteration 14550, loss = 0.570026
I0905 04:16:32.247093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.570026 (* 1 = 0.570026 loss)
I0905 04:16:32.247126 90901 sgd_solver.cpp:106] Iteration 14550, lr = 0.1
I0905 04:16:37.852285 90901 solver.cpp:228] Iteration 14560, loss = 0.610363
I0905 04:16:37.852335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.610363 (* 1 = 0.610363 loss)
I0905 04:16:37.852349 90901 sgd_solver.cpp:106] Iteration 14560, lr = 0.1
I0905 04:16:43.472262 90901 solver.cpp:228] Iteration 14570, loss = 0.698252
I0905 04:16:43.472321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.698251 (* 1 = 0.698251 loss)
I0905 04:16:43.472335 90901 sgd_solver.cpp:106] Iteration 14570, lr = 0.1
I0905 04:16:49.526144 90901 solver.cpp:228] Iteration 14580, loss = 0.653543
I0905 04:16:49.526195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.653543 (* 1 = 0.653543 loss)
I0905 04:16:49.526211 90901 sgd_solver.cpp:106] Iteration 14580, lr = 0.1
I0905 04:16:55.783216 90901 solver.cpp:228] Iteration 14590, loss = 0.404242
I0905 04:16:55.783265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404242 (* 1 = 0.404242 loss)
I0905 04:16:55.783277 90901 sgd_solver.cpp:106] Iteration 14590, lr = 0.1
I0905 04:17:01.967108 90901 solver.cpp:228] Iteration 14600, loss = 0.348953
I0905 04:17:01.967162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348953 (* 1 = 0.348953 loss)
I0905 04:17:01.967176 90901 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0905 04:17:08.009414 90901 solver.cpp:228] Iteration 14610, loss = 0.495823
I0905 04:17:08.009657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.495823 (* 1 = 0.495823 loss)
I0905 04:17:08.009673 90901 sgd_solver.cpp:106] Iteration 14610, lr = 0.1
I0905 04:17:14.100391 90901 solver.cpp:228] Iteration 14620, loss = 0.390184
I0905 04:17:14.100435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390184 (* 1 = 0.390184 loss)
I0905 04:17:14.100448 90901 sgd_solver.cpp:106] Iteration 14620, lr = 0.1
I0905 04:17:20.203282 90901 solver.cpp:228] Iteration 14630, loss = 0.29269
I0905 04:17:20.203330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29269 (* 1 = 0.29269 loss)
I0905 04:17:20.203343 90901 sgd_solver.cpp:106] Iteration 14630, lr = 0.1
I0905 04:17:26.227919 90901 solver.cpp:228] Iteration 14640, loss = 0.60357
I0905 04:17:26.227960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.60357 (* 1 = 0.60357 loss)
I0905 04:17:26.227973 90901 sgd_solver.cpp:106] Iteration 14640, lr = 0.1
I0905 04:17:32.610849 90901 solver.cpp:228] Iteration 14650, loss = 0.293698
I0905 04:17:32.610896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293698 (* 1 = 0.293698 loss)
I0905 04:17:32.610909 90901 sgd_solver.cpp:106] Iteration 14650, lr = 0.1
I0905 04:17:38.682382 90901 solver.cpp:228] Iteration 14660, loss = 0.353947
I0905 04:17:38.682569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353946 (* 1 = 0.353946 loss)
I0905 04:17:38.682608 90901 sgd_solver.cpp:106] Iteration 14660, lr = 0.1
I0905 04:17:43.730317 90901 solver.cpp:228] Iteration 14670, loss = 0.29816
I0905 04:17:43.730365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29816 (* 1 = 0.29816 loss)
I0905 04:17:43.730378 90901 sgd_solver.cpp:106] Iteration 14670, lr = 0.1
I0905 04:17:48.753868 90901 solver.cpp:228] Iteration 14680, loss = 0.610039
I0905 04:17:48.753916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.610039 (* 1 = 0.610039 loss)
I0905 04:17:48.753928 90901 sgd_solver.cpp:106] Iteration 14680, lr = 0.1
I0905 04:17:53.825330 90901 solver.cpp:228] Iteration 14690, loss = 0.783149
I0905 04:17:53.825378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.783149 (* 1 = 0.783149 loss)
I0905 04:17:53.825390 90901 sgd_solver.cpp:106] Iteration 14690, lr = 0.1
I0905 04:17:58.867563 90901 solver.cpp:228] Iteration 14700, loss = 0.245943
I0905 04:17:58.867614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245943 (* 1 = 0.245943 loss)
I0905 04:17:58.867626 90901 sgd_solver.cpp:106] Iteration 14700, lr = 0.1
I0905 04:18:03.875862 90901 solver.cpp:228] Iteration 14710, loss = 0.53031
I0905 04:18:03.875911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.530309 (* 1 = 0.530309 loss)
I0905 04:18:03.875923 90901 sgd_solver.cpp:106] Iteration 14710, lr = 0.1
I0905 04:18:08.915760 90901 solver.cpp:228] Iteration 14720, loss = 0.301217
I0905 04:18:08.915932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301216 (* 1 = 0.301216 loss)
I0905 04:18:08.915956 90901 sgd_solver.cpp:106] Iteration 14720, lr = 0.1
I0905 04:18:13.953959 90901 solver.cpp:228] Iteration 14730, loss = 0.287672
I0905 04:18:13.954010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287672 (* 1 = 0.287672 loss)
I0905 04:18:13.954025 90901 sgd_solver.cpp:106] Iteration 14730, lr = 0.1
I0905 04:18:19.039314 90901 solver.cpp:228] Iteration 14740, loss = 0.235672
I0905 04:18:19.039361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235672 (* 1 = 0.235672 loss)
I0905 04:18:19.039374 90901 sgd_solver.cpp:106] Iteration 14740, lr = 0.1
I0905 04:18:24.001955 90901 solver.cpp:228] Iteration 14750, loss = 0.284791
I0905 04:18:24.001997 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284791 (* 1 = 0.284791 loss)
I0905 04:18:24.002014 90901 sgd_solver.cpp:106] Iteration 14750, lr = 0.1
I0905 04:18:28.652312 90901 solver.cpp:228] Iteration 14760, loss = 0.196687
I0905 04:18:28.652353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196687 (* 1 = 0.196687 loss)
I0905 04:18:28.652364 90901 sgd_solver.cpp:106] Iteration 14760, lr = 0.1
I0905 04:18:33.292035 90901 solver.cpp:228] Iteration 14770, loss = 0.447562
I0905 04:18:33.292078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.447562 (* 1 = 0.447562 loss)
I0905 04:18:33.292090 90901 sgd_solver.cpp:106] Iteration 14770, lr = 0.1
I0905 04:18:38.243979 90901 solver.cpp:228] Iteration 14780, loss = 0.171959
I0905 04:18:38.244032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171958 (* 1 = 0.171958 loss)
I0905 04:18:38.244047 90901 sgd_solver.cpp:106] Iteration 14780, lr = 0.1
I0905 04:18:43.318037 90901 solver.cpp:228] Iteration 14790, loss = 0.383492
I0905 04:18:43.318207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383492 (* 1 = 0.383492 loss)
I0905 04:18:43.318248 90901 sgd_solver.cpp:106] Iteration 14790, lr = 0.1
I0905 04:18:48.367964 90901 solver.cpp:228] Iteration 14800, loss = 0.22038
I0905 04:18:48.368010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22038 (* 1 = 0.22038 loss)
I0905 04:18:48.368026 90901 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0905 04:18:53.408843 90901 solver.cpp:228] Iteration 14810, loss = 0.323732
I0905 04:18:53.408895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323731 (* 1 = 0.323731 loss)
I0905 04:18:53.408910 90901 sgd_solver.cpp:106] Iteration 14810, lr = 0.1
I0905 04:18:58.479758 90901 solver.cpp:228] Iteration 14820, loss = 0.286374
I0905 04:18:58.479805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286373 (* 1 = 0.286373 loss)
I0905 04:18:58.479817 90901 sgd_solver.cpp:106] Iteration 14820, lr = 0.1
I0905 04:19:03.873893 90901 solver.cpp:228] Iteration 14830, loss = 0.368336
I0905 04:19:03.873939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368336 (* 1 = 0.368336 loss)
I0905 04:19:03.873953 90901 sgd_solver.cpp:106] Iteration 14830, lr = 0.1
I0905 04:19:09.647186 90901 solver.cpp:228] Iteration 14840, loss = 0.299639
I0905 04:19:09.647249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299639 (* 1 = 0.299639 loss)
I0905 04:19:09.647264 90901 sgd_solver.cpp:106] Iteration 14840, lr = 0.1
I0905 04:19:16.042188 90901 solver.cpp:228] Iteration 14850, loss = 0.579024
I0905 04:19:16.042371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.579024 (* 1 = 0.579024 loss)
I0905 04:19:16.042398 90901 sgd_solver.cpp:106] Iteration 14850, lr = 0.1
I0905 04:19:22.146893 90901 solver.cpp:228] Iteration 14860, loss = 0.782052
I0905 04:19:22.146936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.782051 (* 1 = 0.782051 loss)
I0905 04:19:22.146950 90901 sgd_solver.cpp:106] Iteration 14860, lr = 0.1
I0905 04:19:28.347692 90901 solver.cpp:228] Iteration 14870, loss = 0.303604
I0905 04:19:28.347738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303604 (* 1 = 0.303604 loss)
I0905 04:19:28.347753 90901 sgd_solver.cpp:106] Iteration 14870, lr = 0.1
I0905 04:19:34.607631 90901 solver.cpp:228] Iteration 14880, loss = 0.317766
I0905 04:19:34.607674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317766 (* 1 = 0.317766 loss)
I0905 04:19:34.607688 90901 sgd_solver.cpp:106] Iteration 14880, lr = 0.1
I0905 04:19:40.348989 90901 solver.cpp:228] Iteration 14890, loss = 0.502514
I0905 04:19:40.349040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502514 (* 1 = 0.502514 loss)
I0905 04:19:40.349056 90901 sgd_solver.cpp:106] Iteration 14890, lr = 0.1
I0905 04:19:46.794153 90901 solver.cpp:228] Iteration 14900, loss = 0.346469
I0905 04:19:46.794402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346469 (* 1 = 0.346469 loss)
I0905 04:19:46.794425 90901 sgd_solver.cpp:106] Iteration 14900, lr = 0.1
I0905 04:19:52.875780 90901 solver.cpp:228] Iteration 14910, loss = 0.340304
I0905 04:19:52.875828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340304 (* 1 = 0.340304 loss)
I0905 04:19:52.875843 90901 sgd_solver.cpp:106] Iteration 14910, lr = 0.1
I0905 04:19:58.923063 90901 solver.cpp:228] Iteration 14920, loss = 0.165608
I0905 04:19:58.923125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165608 (* 1 = 0.165608 loss)
I0905 04:19:58.923142 90901 sgd_solver.cpp:106] Iteration 14920, lr = 0.1
I0905 04:20:05.295686 90901 solver.cpp:228] Iteration 14930, loss = 0.139215
I0905 04:20:05.295727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139215 (* 1 = 0.139215 loss)
I0905 04:20:05.295740 90901 sgd_solver.cpp:106] Iteration 14930, lr = 0.1
I0905 04:20:11.051898 90901 solver.cpp:228] Iteration 14940, loss = 0.511663
I0905 04:20:11.051940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.511663 (* 1 = 0.511663 loss)
I0905 04:20:11.051954 90901 sgd_solver.cpp:106] Iteration 14940, lr = 0.1
I0905 04:20:16.617684 90901 solver.cpp:228] Iteration 14950, loss = 0.721735
I0905 04:20:16.617740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.721735 (* 1 = 0.721735 loss)
I0905 04:20:16.617754 90901 sgd_solver.cpp:106] Iteration 14950, lr = 0.1
I0905 04:20:22.012941 90901 solver.cpp:228] Iteration 14960, loss = 0.630434
I0905 04:20:22.013108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.630434 (* 1 = 0.630434 loss)
I0905 04:20:22.013136 90901 sgd_solver.cpp:106] Iteration 14960, lr = 0.1
I0905 04:20:28.399423 90901 solver.cpp:228] Iteration 14970, loss = 0.526155
I0905 04:20:28.399471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.526155 (* 1 = 0.526155 loss)
I0905 04:20:28.399485 90901 sgd_solver.cpp:106] Iteration 14970, lr = 0.1
I0905 04:20:34.483479 90901 solver.cpp:228] Iteration 14980, loss = 0.582722
I0905 04:20:34.483522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.582722 (* 1 = 0.582722 loss)
I0905 04:20:34.483537 90901 sgd_solver.cpp:106] Iteration 14980, lr = 0.1
I0905 04:20:40.526244 90901 solver.cpp:228] Iteration 14990, loss = 0.273416
I0905 04:20:40.526289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273415 (* 1 = 0.273415 loss)
I0905 04:20:40.526304 90901 sgd_solver.cpp:106] Iteration 14990, lr = 0.1
I0905 04:20:46.590128 90901 solver.cpp:228] Iteration 15000, loss = 0.240234
I0905 04:20:46.590181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240234 (* 1 = 0.240234 loss)
I0905 04:20:46.590204 90901 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0905 04:20:52.711781 90901 solver.cpp:228] Iteration 15010, loss = 0.259434
I0905 04:20:52.712003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259434 (* 1 = 0.259434 loss)
I0905 04:20:52.712044 90901 sgd_solver.cpp:106] Iteration 15010, lr = 0.1
I0905 04:20:58.753551 90901 solver.cpp:228] Iteration 15020, loss = 0.293283
I0905 04:20:58.753600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293283 (* 1 = 0.293283 loss)
I0905 04:20:58.753612 90901 sgd_solver.cpp:106] Iteration 15020, lr = 0.1
I0905 04:21:04.855588 90901 solver.cpp:228] Iteration 15030, loss = 0.151367
I0905 04:21:04.855641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151367 (* 1 = 0.151367 loss)
I0905 04:21:04.855654 90901 sgd_solver.cpp:106] Iteration 15030, lr = 0.1
I0905 04:21:10.619117 90901 solver.cpp:228] Iteration 15040, loss = 0.492017
I0905 04:21:10.619175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492016 (* 1 = 0.492016 loss)
I0905 04:21:10.619189 90901 sgd_solver.cpp:106] Iteration 15040, lr = 0.1
I0905 04:21:16.696619 90901 solver.cpp:228] Iteration 15050, loss = 0.402178
I0905 04:21:16.696661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402178 (* 1 = 0.402178 loss)
I0905 04:21:16.696674 90901 sgd_solver.cpp:106] Iteration 15050, lr = 0.1
I0905 04:21:23.046084 90901 solver.cpp:228] Iteration 15060, loss = 0.508752
I0905 04:21:23.046298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.508752 (* 1 = 0.508752 loss)
I0905 04:21:23.046317 90901 sgd_solver.cpp:106] Iteration 15060, lr = 0.1
I0905 04:21:29.124502 90901 solver.cpp:228] Iteration 15070, loss = 0.774469
I0905 04:21:29.124562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.774468 (* 1 = 0.774468 loss)
I0905 04:21:29.124577 90901 sgd_solver.cpp:106] Iteration 15070, lr = 0.1
I0905 04:21:35.216364 90901 solver.cpp:228] Iteration 15080, loss = 0.300252
I0905 04:21:35.216413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300251 (* 1 = 0.300251 loss)
I0905 04:21:35.216425 90901 sgd_solver.cpp:106] Iteration 15080, lr = 0.1
I0905 04:21:41.598795 90901 solver.cpp:228] Iteration 15090, loss = 0.376305
I0905 04:21:41.598836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376305 (* 1 = 0.376305 loss)
I0905 04:21:41.598850 90901 sgd_solver.cpp:106] Iteration 15090, lr = 0.1
I0905 04:21:47.657393 90901 solver.cpp:228] Iteration 15100, loss = 0.298605
I0905 04:21:47.657430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298605 (* 1 = 0.298605 loss)
I0905 04:21:47.657449 90901 sgd_solver.cpp:106] Iteration 15100, lr = 0.1
I0905 04:21:53.754863 90901 solver.cpp:228] Iteration 15110, loss = 0.449612
I0905 04:21:53.755004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449612 (* 1 = 0.449612 loss)
I0905 04:21:53.755031 90901 sgd_solver.cpp:106] Iteration 15110, lr = 0.1
I0905 04:21:59.583780 90901 solver.cpp:228] Iteration 15120, loss = 0.362113
I0905 04:21:59.583837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362113 (* 1 = 0.362113 loss)
I0905 04:21:59.583849 90901 sgd_solver.cpp:106] Iteration 15120, lr = 0.1
I0905 04:22:05.132225 90901 solver.cpp:228] Iteration 15130, loss = 0.215152
I0905 04:22:05.132287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215152 (* 1 = 0.215152 loss)
I0905 04:22:05.132302 90901 sgd_solver.cpp:106] Iteration 15130, lr = 0.1
I0905 04:22:10.621304 90901 solver.cpp:228] Iteration 15140, loss = 0.286528
I0905 04:22:10.621359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286527 (* 1 = 0.286527 loss)
I0905 04:22:10.621372 90901 sgd_solver.cpp:106] Iteration 15140, lr = 0.1
I0905 04:22:16.938290 90901 solver.cpp:228] Iteration 15150, loss = 0.446782
I0905 04:22:16.938329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446781 (* 1 = 0.446781 loss)
I0905 04:22:16.938343 90901 sgd_solver.cpp:106] Iteration 15150, lr = 0.1
I0905 04:22:23.074813 90901 solver.cpp:228] Iteration 15160, loss = 0.379712
I0905 04:22:23.074865 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379712 (* 1 = 0.379712 loss)
I0905 04:22:23.074879 90901 sgd_solver.cpp:106] Iteration 15160, lr = 0.1
I0905 04:22:29.132169 90901 solver.cpp:228] Iteration 15170, loss = 0.502447
I0905 04:22:29.132328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502446 (* 1 = 0.502446 loss)
I0905 04:22:29.132378 90901 sgd_solver.cpp:106] Iteration 15170, lr = 0.1
I0905 04:22:35.181126 90901 solver.cpp:228] Iteration 15180, loss = 0.399068
I0905 04:22:35.181176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399068 (* 1 = 0.399068 loss)
I0905 04:22:35.181198 90901 sgd_solver.cpp:106] Iteration 15180, lr = 0.1
I0905 04:22:41.208143 90901 solver.cpp:228] Iteration 15190, loss = 0.314577
I0905 04:22:41.208194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314577 (* 1 = 0.314577 loss)
I0905 04:22:41.208207 90901 sgd_solver.cpp:106] Iteration 15190, lr = 0.1
I0905 04:22:47.047122 90901 solver.cpp:337] Iteration 15200, Testing net (#0)
I0905 04:23:29.286584 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.770625
I0905 04:23:29.286813 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.468856 (* 1 = 0.468856 loss)
I0905 04:23:29.798662 90901 solver.cpp:228] Iteration 15200, loss = 0.422737
I0905 04:23:29.798723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422736 (* 1 = 0.422736 loss)
I0905 04:23:29.798739 90901 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0905 04:23:35.881516 90901 solver.cpp:228] Iteration 15210, loss = 0.218443
I0905 04:23:35.881567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218442 (* 1 = 0.218442 loss)
I0905 04:23:35.881582 90901 sgd_solver.cpp:106] Iteration 15210, lr = 0.1
I0905 04:23:41.938985 90901 solver.cpp:228] Iteration 15220, loss = 0.382893
I0905 04:23:41.939054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382893 (* 1 = 0.382893 loss)
I0905 04:23:41.939070 90901 sgd_solver.cpp:106] Iteration 15220, lr = 0.1
I0905 04:23:47.817448 90901 solver.cpp:228] Iteration 15230, loss = 0.19216
I0905 04:23:47.817500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192159 (* 1 = 0.192159 loss)
I0905 04:23:47.817517 90901 sgd_solver.cpp:106] Iteration 15230, lr = 0.1
I0905 04:23:53.070297 90901 solver.cpp:228] Iteration 15240, loss = 0.58663
I0905 04:23:53.070343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.58663 (* 1 = 0.58663 loss)
I0905 04:23:53.070355 90901 sgd_solver.cpp:106] Iteration 15240, lr = 0.1
I0905 04:23:58.659068 90901 solver.cpp:228] Iteration 15250, loss = 0.370642
I0905 04:23:58.659122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370642 (* 1 = 0.370642 loss)
I0905 04:23:58.659135 90901 sgd_solver.cpp:106] Iteration 15250, lr = 0.1
I0905 04:24:05.012883 90901 solver.cpp:228] Iteration 15260, loss = 0.311077
I0905 04:24:05.013020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311076 (* 1 = 0.311076 loss)
I0905 04:24:05.013033 90901 sgd_solver.cpp:106] Iteration 15260, lr = 0.1
I0905 04:24:11.082105 90901 solver.cpp:228] Iteration 15270, loss = 0.396054
I0905 04:24:11.082147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396054 (* 1 = 0.396054 loss)
I0905 04:24:11.082162 90901 sgd_solver.cpp:106] Iteration 15270, lr = 0.1
I0905 04:24:17.127207 90901 solver.cpp:228] Iteration 15280, loss = 0.473938
I0905 04:24:17.127255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473938 (* 1 = 0.473938 loss)
I0905 04:24:17.127267 90901 sgd_solver.cpp:106] Iteration 15280, lr = 0.1
I0905 04:24:23.484402 90901 solver.cpp:228] Iteration 15290, loss = 0.460303
I0905 04:24:23.484474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460303 (* 1 = 0.460303 loss)
I0905 04:24:23.484488 90901 sgd_solver.cpp:106] Iteration 15290, lr = 0.1
I0905 04:24:29.483512 90901 solver.cpp:228] Iteration 15300, loss = 0.241092
I0905 04:24:29.483563 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241092 (* 1 = 0.241092 loss)
I0905 04:24:29.483579 90901 sgd_solver.cpp:106] Iteration 15300, lr = 0.1
I0905 04:24:35.576256 90901 solver.cpp:228] Iteration 15310, loss = 0.578169
I0905 04:24:35.576449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578169 (* 1 = 0.578169 loss)
I0905 04:24:35.576485 90901 sgd_solver.cpp:106] Iteration 15310, lr = 0.1
I0905 04:24:41.355527 90901 solver.cpp:228] Iteration 15320, loss = 0.427489
I0905 04:24:41.355576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427489 (* 1 = 0.427489 loss)
I0905 04:24:41.355589 90901 sgd_solver.cpp:106] Iteration 15320, lr = 0.1
I0905 04:24:47.771538 90901 solver.cpp:228] Iteration 15330, loss = 0.233648
I0905 04:24:47.771585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233648 (* 1 = 0.233648 loss)
I0905 04:24:47.771598 90901 sgd_solver.cpp:106] Iteration 15330, lr = 0.1
I0905 04:24:53.815136 90901 solver.cpp:228] Iteration 15340, loss = 0.529091
I0905 04:24:53.815189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529091 (* 1 = 0.529091 loss)
I0905 04:24:53.815202 90901 sgd_solver.cpp:106] Iteration 15340, lr = 0.1
I0905 04:24:59.886323 90901 solver.cpp:228] Iteration 15350, loss = 0.252799
I0905 04:24:59.886379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252799 (* 1 = 0.252799 loss)
I0905 04:24:59.886392 90901 sgd_solver.cpp:106] Iteration 15350, lr = 0.1
I0905 04:25:06.258826 90901 solver.cpp:228] Iteration 15360, loss = 0.523584
I0905 04:25:06.259042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523584 (* 1 = 0.523584 loss)
I0905 04:25:06.259078 90901 sgd_solver.cpp:106] Iteration 15360, lr = 0.1
I0905 04:25:12.339429 90901 solver.cpp:228] Iteration 15370, loss = 0.349736
I0905 04:25:12.339483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349735 (* 1 = 0.349735 loss)
I0905 04:25:12.339498 90901 sgd_solver.cpp:106] Iteration 15370, lr = 0.1
I0905 04:25:18.399651 90901 solver.cpp:228] Iteration 15380, loss = 0.335873
I0905 04:25:18.399704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335873 (* 1 = 0.335873 loss)
I0905 04:25:18.399720 90901 sgd_solver.cpp:106] Iteration 15380, lr = 0.1
I0905 04:25:24.460711 90901 solver.cpp:228] Iteration 15390, loss = 0.301461
I0905 04:25:24.460755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301461 (* 1 = 0.301461 loss)
I0905 04:25:24.460767 90901 sgd_solver.cpp:106] Iteration 15390, lr = 0.1
I0905 04:25:30.513573 90901 solver.cpp:228] Iteration 15400, loss = 0.334471
I0905 04:25:30.513633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334471 (* 1 = 0.334471 loss)
I0905 04:25:30.513653 90901 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0905 04:25:36.289484 90901 solver.cpp:228] Iteration 15410, loss = 0.218802
I0905 04:25:36.289635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218802 (* 1 = 0.218802 loss)
I0905 04:25:36.289679 90901 sgd_solver.cpp:106] Iteration 15410, lr = 0.1
I0905 04:25:41.613867 90901 solver.cpp:228] Iteration 15420, loss = 0.387356
I0905 04:25:41.613926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387356 (* 1 = 0.387356 loss)
I0905 04:25:41.613940 90901 sgd_solver.cpp:106] Iteration 15420, lr = 0.1
I0905 04:25:47.575901 90901 solver.cpp:228] Iteration 15430, loss = 0.382419
I0905 04:25:47.575948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382419 (* 1 = 0.382419 loss)
I0905 04:25:47.575963 90901 sgd_solver.cpp:106] Iteration 15430, lr = 0.1
I0905 04:25:53.457979 90901 solver.cpp:228] Iteration 15440, loss = 0.54289
I0905 04:25:53.458029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.54289 (* 1 = 0.54289 loss)
I0905 04:25:53.458042 90901 sgd_solver.cpp:106] Iteration 15440, lr = 0.1
I0905 04:25:59.805002 90901 solver.cpp:228] Iteration 15450, loss = 0.415602
I0905 04:25:59.805042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415602 (* 1 = 0.415602 loss)
I0905 04:25:59.805055 90901 sgd_solver.cpp:106] Iteration 15450, lr = 0.1
I0905 04:26:05.869278 90901 solver.cpp:228] Iteration 15460, loss = 0.387304
I0905 04:26:05.869329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387303 (* 1 = 0.387303 loss)
I0905 04:26:05.869344 90901 sgd_solver.cpp:106] Iteration 15460, lr = 0.1
I0905 04:26:11.938092 90901 solver.cpp:228] Iteration 15470, loss = 0.390745
I0905 04:26:11.938259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390745 (* 1 = 0.390745 loss)
I0905 04:26:11.938272 90901 sgd_solver.cpp:106] Iteration 15470, lr = 0.1
I0905 04:26:17.998755 90901 solver.cpp:228] Iteration 15480, loss = 0.565719
I0905 04:26:17.998805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565719 (* 1 = 0.565719 loss)
I0905 04:26:17.998819 90901 sgd_solver.cpp:106] Iteration 15480, lr = 0.1
I0905 04:26:24.046299 90901 solver.cpp:228] Iteration 15490, loss = 0.342224
I0905 04:26:24.046370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342223 (* 1 = 0.342223 loss)
I0905 04:26:24.046386 90901 sgd_solver.cpp:106] Iteration 15490, lr = 0.1
I0905 04:26:30.099273 90901 solver.cpp:228] Iteration 15500, loss = 0.316961
I0905 04:26:30.099329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316961 (* 1 = 0.316961 loss)
I0905 04:26:30.099344 90901 sgd_solver.cpp:106] Iteration 15500, lr = 0.1
I0905 04:26:36.485172 90901 solver.cpp:228] Iteration 15510, loss = 0.327002
I0905 04:26:36.485230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327001 (* 1 = 0.327001 loss)
I0905 04:26:36.485245 90901 sgd_solver.cpp:106] Iteration 15510, lr = 0.1
I0905 04:26:42.542904 90901 solver.cpp:228] Iteration 15520, loss = 0.172301
I0905 04:26:42.543189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172301 (* 1 = 0.172301 loss)
I0905 04:26:42.543206 90901 sgd_solver.cpp:106] Iteration 15520, lr = 0.1
I0905 04:26:48.608397 90901 solver.cpp:228] Iteration 15530, loss = 0.315751
I0905 04:26:48.608451 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315751 (* 1 = 0.315751 loss)
I0905 04:26:48.608465 90901 sgd_solver.cpp:106] Iteration 15530, lr = 0.1
I0905 04:26:54.670215 90901 solver.cpp:228] Iteration 15540, loss = 0.209965
I0905 04:26:54.670263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209965 (* 1 = 0.209965 loss)
I0905 04:26:54.670277 90901 sgd_solver.cpp:106] Iteration 15540, lr = 0.1
I0905 04:27:00.758371 90901 solver.cpp:228] Iteration 15550, loss = 0.319087
I0905 04:27:00.758430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319086 (* 1 = 0.319086 loss)
I0905 04:27:00.758443 90901 sgd_solver.cpp:106] Iteration 15550, lr = 0.1
I0905 04:27:07.188066 90901 solver.cpp:228] Iteration 15560, loss = 0.401038
I0905 04:27:07.188112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401038 (* 1 = 0.401038 loss)
I0905 04:27:07.188124 90901 sgd_solver.cpp:106] Iteration 15560, lr = 0.1
I0905 04:27:13.261373 90901 solver.cpp:228] Iteration 15570, loss = 0.367082
I0905 04:27:13.261548 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367082 (* 1 = 0.367082 loss)
I0905 04:27:13.261570 90901 sgd_solver.cpp:106] Iteration 15570, lr = 0.1
I0905 04:27:19.354887 90901 solver.cpp:228] Iteration 15580, loss = 0.326825
I0905 04:27:19.354938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326825 (* 1 = 0.326825 loss)
I0905 04:27:19.354953 90901 sgd_solver.cpp:106] Iteration 15580, lr = 0.1
I0905 04:27:25.112058 90901 solver.cpp:228] Iteration 15590, loss = 0.68828
I0905 04:27:25.112119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.68828 (* 1 = 0.68828 loss)
I0905 04:27:25.112139 90901 sgd_solver.cpp:106] Iteration 15590, lr = 0.1
I0905 04:27:30.678709 90901 solver.cpp:228] Iteration 15600, loss = 0.217968
I0905 04:27:30.678764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217968 (* 1 = 0.217968 loss)
I0905 04:27:30.678777 90901 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0905 04:27:36.300770 90901 solver.cpp:228] Iteration 15610, loss = 0.347071
I0905 04:27:36.300818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34707 (* 1 = 0.34707 loss)
I0905 04:27:36.300832 90901 sgd_solver.cpp:106] Iteration 15610, lr = 0.1
I0905 04:27:42.337560 90901 solver.cpp:228] Iteration 15620, loss = 0.206376
I0905 04:27:42.337610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206375 (* 1 = 0.206375 loss)
I0905 04:27:42.337625 90901 sgd_solver.cpp:106] Iteration 15620, lr = 0.1
I0905 04:27:48.675122 90901 solver.cpp:228] Iteration 15630, loss = 0.543039
I0905 04:27:48.675274 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543038 (* 1 = 0.543038 loss)
I0905 04:27:48.675313 90901 sgd_solver.cpp:106] Iteration 15630, lr = 0.1
I0905 04:27:54.775780 90901 solver.cpp:228] Iteration 15640, loss = 0.328924
I0905 04:27:54.775826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328923 (* 1 = 0.328923 loss)
I0905 04:27:54.775842 90901 sgd_solver.cpp:106] Iteration 15640, lr = 0.1
I0905 04:28:00.850409 90901 solver.cpp:228] Iteration 15650, loss = 0.453702
I0905 04:28:00.850456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453701 (* 1 = 0.453701 loss)
I0905 04:28:00.850469 90901 sgd_solver.cpp:106] Iteration 15650, lr = 0.1
I0905 04:28:06.957018 90901 solver.cpp:228] Iteration 15660, loss = 0.241739
I0905 04:28:06.957072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241739 (* 1 = 0.241739 loss)
I0905 04:28:06.957084 90901 sgd_solver.cpp:106] Iteration 15660, lr = 0.1
I0905 04:28:13.012012 90901 solver.cpp:228] Iteration 15670, loss = 0.155374
I0905 04:28:13.012061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155374 (* 1 = 0.155374 loss)
I0905 04:28:13.012076 90901 sgd_solver.cpp:106] Iteration 15670, lr = 0.1
I0905 04:28:19.049649 90901 solver.cpp:228] Iteration 15680, loss = 0.402796
I0905 04:28:19.049857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402796 (* 1 = 0.402796 loss)
I0905 04:28:19.049891 90901 sgd_solver.cpp:106] Iteration 15680, lr = 0.1
I0905 04:28:25.128619 90901 solver.cpp:228] Iteration 15690, loss = 0.611602
I0905 04:28:25.128672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.611602 (* 1 = 0.611602 loss)
I0905 04:28:25.128687 90901 sgd_solver.cpp:106] Iteration 15690, lr = 0.1
I0905 04:28:30.860591 90901 solver.cpp:228] Iteration 15700, loss = 0.277553
I0905 04:28:30.860635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277553 (* 1 = 0.277553 loss)
I0905 04:28:30.860652 90901 sgd_solver.cpp:106] Iteration 15700, lr = 0.1
I0905 04:28:36.947944 90901 solver.cpp:228] Iteration 15710, loss = 0.518042
I0905 04:28:36.947994 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.518041 (* 1 = 0.518041 loss)
I0905 04:28:36.948007 90901 sgd_solver.cpp:106] Iteration 15710, lr = 0.1
I0905 04:28:43.335458 90901 solver.cpp:228] Iteration 15720, loss = 0.618863
I0905 04:28:43.335510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.618862 (* 1 = 0.618862 loss)
I0905 04:28:43.335525 90901 sgd_solver.cpp:106] Iteration 15720, lr = 0.1
I0905 04:28:49.505301 90901 solver.cpp:228] Iteration 15730, loss = 0.476933
I0905 04:28:49.505471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476933 (* 1 = 0.476933 loss)
I0905 04:28:49.505512 90901 sgd_solver.cpp:106] Iteration 15730, lr = 0.1
I0905 04:28:55.492516 90901 solver.cpp:228] Iteration 15740, loss = 0.159523
I0905 04:28:55.492568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159523 (* 1 = 0.159523 loss)
I0905 04:28:55.492583 90901 sgd_solver.cpp:106] Iteration 15740, lr = 0.1
I0905 04:29:01.811385 90901 solver.cpp:228] Iteration 15750, loss = 0.311754
I0905 04:29:01.811436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311754 (* 1 = 0.311754 loss)
I0905 04:29:01.811451 90901 sgd_solver.cpp:106] Iteration 15750, lr = 0.1
I0905 04:29:07.685560 90901 solver.cpp:228] Iteration 15760, loss = 0.738179
I0905 04:29:07.685608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.738178 (* 1 = 0.738178 loss)
I0905 04:29:07.685621 90901 sgd_solver.cpp:106] Iteration 15760, lr = 0.1
I0905 04:29:13.346611 90901 solver.cpp:228] Iteration 15770, loss = 0.365407
I0905 04:29:13.346693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365407 (* 1 = 0.365407 loss)
I0905 04:29:13.346711 90901 sgd_solver.cpp:106] Iteration 15770, lr = 0.1
I0905 04:29:18.338136 90901 solver.cpp:228] Iteration 15780, loss = 0.325283
I0905 04:29:18.338181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325283 (* 1 = 0.325283 loss)
I0905 04:29:18.338194 90901 sgd_solver.cpp:106] Iteration 15780, lr = 0.1
I0905 04:29:24.707284 90901 solver.cpp:228] Iteration 15790, loss = 0.572552
I0905 04:29:24.707448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572552 (* 1 = 0.572552 loss)
I0905 04:29:24.707464 90901 sgd_solver.cpp:106] Iteration 15790, lr = 0.1
I0905 04:29:30.464800 90901 solver.cpp:228] Iteration 15800, loss = 0.323203
I0905 04:29:30.464848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323203 (* 1 = 0.323203 loss)
I0905 04:29:30.464862 90901 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0905 04:29:36.882179 90901 solver.cpp:228] Iteration 15810, loss = 0.322166
I0905 04:29:36.882241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322166 (* 1 = 0.322166 loss)
I0905 04:29:36.882252 90901 sgd_solver.cpp:106] Iteration 15810, lr = 0.1
I0905 04:29:42.936004 90901 solver.cpp:228] Iteration 15820, loss = 0.18756
I0905 04:29:42.936056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18756 (* 1 = 0.18756 loss)
I0905 04:29:42.936069 90901 sgd_solver.cpp:106] Iteration 15820, lr = 0.1
I0905 04:29:49.010143 90901 solver.cpp:228] Iteration 15830, loss = 0.189782
I0905 04:29:49.010205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189782 (* 1 = 0.189782 loss)
I0905 04:29:49.010221 90901 sgd_solver.cpp:106] Iteration 15830, lr = 0.1
I0905 04:29:55.421108 90901 solver.cpp:228] Iteration 15840, loss = 0.802213
I0905 04:29:55.421286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.802213 (* 1 = 0.802213 loss)
I0905 04:29:55.421304 90901 sgd_solver.cpp:106] Iteration 15840, lr = 0.1
I0905 04:30:01.488229 90901 solver.cpp:228] Iteration 15850, loss = 0.391633
I0905 04:30:01.488283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391632 (* 1 = 0.391632 loss)
I0905 04:30:01.488298 90901 sgd_solver.cpp:106] Iteration 15850, lr = 0.1
I0905 04:30:07.400799 90901 solver.cpp:228] Iteration 15860, loss = 0.552741
I0905 04:30:07.400849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552741 (* 1 = 0.552741 loss)
I0905 04:30:07.400867 90901 sgd_solver.cpp:106] Iteration 15860, lr = 0.1
I0905 04:30:13.598563 90901 solver.cpp:228] Iteration 15870, loss = 0.696825
I0905 04:30:13.598624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696825 (* 1 = 0.696825 loss)
I0905 04:30:13.598644 90901 sgd_solver.cpp:106] Iteration 15870, lr = 0.1
I0905 04:30:19.685658 90901 solver.cpp:228] Iteration 15880, loss = 0.392366
I0905 04:30:19.685705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392366 (* 1 = 0.392366 loss)
I0905 04:30:19.685719 90901 sgd_solver.cpp:106] Iteration 15880, lr = 0.1
I0905 04:30:25.782678 90901 solver.cpp:228] Iteration 15890, loss = 0.216577
I0905 04:30:25.782769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216576 (* 1 = 0.216576 loss)
I0905 04:30:25.782786 90901 sgd_solver.cpp:106] Iteration 15890, lr = 0.1
I0905 04:30:32.148780 90901 solver.cpp:228] Iteration 15900, loss = 0.199848
I0905 04:30:32.148818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199848 (* 1 = 0.199848 loss)
I0905 04:30:32.148831 90901 sgd_solver.cpp:106] Iteration 15900, lr = 0.1
I0905 04:30:38.183568 90901 solver.cpp:228] Iteration 15910, loss = 0.271292
I0905 04:30:38.183621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271292 (* 1 = 0.271292 loss)
I0905 04:30:38.183637 90901 sgd_solver.cpp:106] Iteration 15910, lr = 0.1
I0905 04:30:44.440654 90901 solver.cpp:228] Iteration 15920, loss = 0.573589
I0905 04:30:44.440711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.573588 (* 1 = 0.573588 loss)
I0905 04:30:44.440726 90901 sgd_solver.cpp:106] Iteration 15920, lr = 0.1
I0905 04:30:50.595073 90901 solver.cpp:228] Iteration 15930, loss = 0.696282
I0905 04:30:50.595124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696281 (* 1 = 0.696281 loss)
I0905 04:30:50.595139 90901 sgd_solver.cpp:106] Iteration 15930, lr = 0.1
I0905 04:30:56.327595 90901 solver.cpp:228] Iteration 15940, loss = 0.251376
I0905 04:30:56.327755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251375 (* 1 = 0.251375 loss)
I0905 04:30:56.327774 90901 sgd_solver.cpp:106] Iteration 15940, lr = 0.1
I0905 04:31:01.891433 90901 solver.cpp:228] Iteration 15950, loss = 0.4223
I0905 04:31:01.891508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4223 (* 1 = 0.4223 loss)
I0905 04:31:01.891526 90901 sgd_solver.cpp:106] Iteration 15950, lr = 0.1
I0905 04:31:07.357058 90901 solver.cpp:228] Iteration 15960, loss = 0.216678
I0905 04:31:07.357105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216678 (* 1 = 0.216678 loss)
I0905 04:31:07.357117 90901 sgd_solver.cpp:106] Iteration 15960, lr = 0.1
I0905 04:31:13.425084 90901 solver.cpp:228] Iteration 15970, loss = 0.52149
I0905 04:31:13.425146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.52149 (* 1 = 0.52149 loss)
I0905 04:31:13.425163 90901 sgd_solver.cpp:106] Iteration 15970, lr = 0.1
I0905 04:31:19.772121 90901 solver.cpp:228] Iteration 15980, loss = 0.304471
I0905 04:31:19.772174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304471 (* 1 = 0.304471 loss)
I0905 04:31:19.772189 90901 sgd_solver.cpp:106] Iteration 15980, lr = 0.1
I0905 04:31:25.870781 90901 solver.cpp:228] Iteration 15990, loss = 0.327428
I0905 04:31:25.870832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327428 (* 1 = 0.327428 loss)
I0905 04:31:25.870847 90901 sgd_solver.cpp:106] Iteration 15990, lr = 0.1
I0905 04:31:31.632491 90901 solver.cpp:337] Iteration 16000, Testing net (#0)
I0905 04:32:13.750208 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.83375
I0905 04:32:13.750363 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.377841 (* 1 = 0.377841 loss)
I0905 04:32:14.071491 90901 solver.cpp:228] Iteration 16000, loss = 0.356706
I0905 04:32:14.071542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356706 (* 1 = 0.356706 loss)
I0905 04:32:14.071563 90901 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0905 04:32:20.354269 90901 solver.cpp:228] Iteration 16010, loss = 0.709686
I0905 04:32:20.354333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.709685 (* 1 = 0.709685 loss)
I0905 04:32:20.354347 90901 sgd_solver.cpp:106] Iteration 16010, lr = 0.1
I0905 04:32:26.386081 90901 solver.cpp:228] Iteration 16020, loss = 0.583499
I0905 04:32:26.386148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.583499 (* 1 = 0.583499 loss)
I0905 04:32:26.386162 90901 sgd_solver.cpp:106] Iteration 16020, lr = 0.1
I0905 04:32:32.461123 90901 solver.cpp:228] Iteration 16030, loss = 0.652504
I0905 04:32:32.461170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.652504 (* 1 = 0.652504 loss)
I0905 04:32:32.461184 90901 sgd_solver.cpp:106] Iteration 16030, lr = 0.1
I0905 04:32:38.834518 90901 solver.cpp:228] Iteration 16040, loss = 0.321732
I0905 04:32:38.834568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321732 (* 1 = 0.321732 loss)
I0905 04:32:38.834580 90901 sgd_solver.cpp:106] Iteration 16040, lr = 0.1
I0905 04:32:44.958501 90901 solver.cpp:228] Iteration 16050, loss = 0.360868
I0905 04:32:44.958703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360867 (* 1 = 0.360867 loss)
I0905 04:32:44.958730 90901 sgd_solver.cpp:106] Iteration 16050, lr = 0.1
I0905 04:32:50.421033 90901 solver.cpp:228] Iteration 16060, loss = 0.488865
I0905 04:32:50.421095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488865 (* 1 = 0.488865 loss)
I0905 04:32:50.421115 90901 sgd_solver.cpp:106] Iteration 16060, lr = 0.1
I0905 04:32:55.772989 90901 solver.cpp:228] Iteration 16070, loss = 0.319646
I0905 04:32:55.773044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319646 (* 1 = 0.319646 loss)
I0905 04:32:55.773057 90901 sgd_solver.cpp:106] Iteration 16070, lr = 0.1
I0905 04:33:01.877403 90901 solver.cpp:228] Iteration 16080, loss = 0.168733
I0905 04:33:01.877475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168732 (* 1 = 0.168732 loss)
I0905 04:33:01.877491 90901 sgd_solver.cpp:106] Iteration 16080, lr = 0.1
I0905 04:33:07.908483 90901 solver.cpp:228] Iteration 16090, loss = 0.317652
I0905 04:33:07.908553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317652 (* 1 = 0.317652 loss)
I0905 04:33:07.908571 90901 sgd_solver.cpp:106] Iteration 16090, lr = 0.1
I0905 04:33:13.971992 90901 solver.cpp:228] Iteration 16100, loss = 0.424412
I0905 04:33:13.972059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424411 (* 1 = 0.424411 loss)
I0905 04:33:13.972074 90901 sgd_solver.cpp:106] Iteration 16100, lr = 0.1
I0905 04:33:20.344055 90901 solver.cpp:228] Iteration 16110, loss = 0.283737
I0905 04:33:20.344327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283736 (* 1 = 0.283736 loss)
I0905 04:33:20.344346 90901 sgd_solver.cpp:106] Iteration 16110, lr = 0.1
I0905 04:33:26.402199 90901 solver.cpp:228] Iteration 16120, loss = 0.319347
I0905 04:33:26.402263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319347 (* 1 = 0.319347 loss)
I0905 04:33:26.402278 90901 sgd_solver.cpp:106] Iteration 16120, lr = 0.1
I0905 04:33:32.746701 90901 solver.cpp:228] Iteration 16130, loss = 0.311835
I0905 04:33:32.746750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311835 (* 1 = 0.311835 loss)
I0905 04:33:32.746765 90901 sgd_solver.cpp:106] Iteration 16130, lr = 0.1
I0905 04:33:38.804764 90901 solver.cpp:228] Iteration 16140, loss = 0.21247
I0905 04:33:38.804838 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21247 (* 1 = 0.21247 loss)
I0905 04:33:38.804852 90901 sgd_solver.cpp:106] Iteration 16140, lr = 0.1
I0905 04:33:44.870424 90901 solver.cpp:228] Iteration 16150, loss = 0.498316
I0905 04:33:44.870484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498316 (* 1 = 0.498316 loss)
I0905 04:33:44.870498 90901 sgd_solver.cpp:106] Iteration 16150, lr = 0.1
I0905 04:33:50.943598 90901 solver.cpp:228] Iteration 16160, loss = 0.446333
I0905 04:33:50.943750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446332 (* 1 = 0.446332 loss)
I0905 04:33:50.943783 90901 sgd_solver.cpp:106] Iteration 16160, lr = 0.1
I0905 04:33:56.993187 90901 solver.cpp:228] Iteration 16170, loss = 0.363852
I0905 04:33:56.993242 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363852 (* 1 = 0.363852 loss)
I0905 04:33:56.993258 90901 sgd_solver.cpp:106] Iteration 16170, lr = 0.1
I0905 04:34:03.068785 90901 solver.cpp:228] Iteration 16180, loss = 0.388515
I0905 04:34:03.068858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388515 (* 1 = 0.388515 loss)
I0905 04:34:03.068874 90901 sgd_solver.cpp:106] Iteration 16180, lr = 0.1
I0905 04:34:09.337208 90901 solver.cpp:228] Iteration 16190, loss = 0.348326
I0905 04:34:09.337282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348326 (* 1 = 0.348326 loss)
I0905 04:34:09.337302 90901 sgd_solver.cpp:106] Iteration 16190, lr = 0.1
I0905 04:34:15.166682 90901 solver.cpp:228] Iteration 16200, loss = 0.135446
I0905 04:34:15.166749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135446 (* 1 = 0.135446 loss)
I0905 04:34:15.166777 90901 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0905 04:34:21.187392 90901 solver.cpp:228] Iteration 16210, loss = 0.375139
I0905 04:34:21.187562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375139 (* 1 = 0.375139 loss)
I0905 04:34:21.187578 90901 sgd_solver.cpp:106] Iteration 16210, lr = 0.1
I0905 04:34:27.380440 90901 solver.cpp:228] Iteration 16220, loss = 0.306422
I0905 04:34:27.380508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306422 (* 1 = 0.306422 loss)
I0905 04:34:27.380524 90901 sgd_solver.cpp:106] Iteration 16220, lr = 0.1
I0905 04:34:33.641576 90901 solver.cpp:228] Iteration 16230, loss = 0.451189
I0905 04:34:33.641649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451188 (* 1 = 0.451188 loss)
I0905 04:34:33.641683 90901 sgd_solver.cpp:106] Iteration 16230, lr = 0.1
I0905 04:34:39.280478 90901 solver.cpp:228] Iteration 16240, loss = 0.314597
I0905 04:34:39.280544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314596 (* 1 = 0.314596 loss)
I0905 04:34:39.280563 90901 sgd_solver.cpp:106] Iteration 16240, lr = 0.1
I0905 04:34:44.534229 90901 solver.cpp:228] Iteration 16250, loss = 0.36813
I0905 04:34:44.534277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368129 (* 1 = 0.368129 loss)
I0905 04:34:44.534289 90901 sgd_solver.cpp:106] Iteration 16250, lr = 0.1
I0905 04:34:50.552589 90901 solver.cpp:228] Iteration 16260, loss = 0.126052
I0905 04:34:50.552647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126051 (* 1 = 0.126051 loss)
I0905 04:34:50.552664 90901 sgd_solver.cpp:106] Iteration 16260, lr = 0.1
I0905 04:34:56.634897 90901 solver.cpp:228] Iteration 16270, loss = 0.292564
I0905 04:34:56.635141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292563 (* 1 = 0.292563 loss)
I0905 04:34:56.635174 90901 sgd_solver.cpp:106] Iteration 16270, lr = 0.1
I0905 04:35:02.677515 90901 solver.cpp:228] Iteration 16280, loss = 0.252662
I0905 04:35:02.677592 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252662 (* 1 = 0.252662 loss)
I0905 04:35:02.677606 90901 sgd_solver.cpp:106] Iteration 16280, lr = 0.1
I0905 04:35:08.785320 90901 solver.cpp:228] Iteration 16290, loss = 0.469352
I0905 04:35:08.785383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469351 (* 1 = 0.469351 loss)
I0905 04:35:08.785399 90901 sgd_solver.cpp:106] Iteration 16290, lr = 0.1
I0905 04:35:14.811549 90901 solver.cpp:228] Iteration 16300, loss = 0.355829
I0905 04:35:14.811599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355828 (* 1 = 0.355828 loss)
I0905 04:35:14.811612 90901 sgd_solver.cpp:106] Iteration 16300, lr = 0.1
I0905 04:35:21.159781 90901 solver.cpp:228] Iteration 16310, loss = 0.524983
I0905 04:35:21.159870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.524983 (* 1 = 0.524983 loss)
I0905 04:35:21.159888 90901 sgd_solver.cpp:106] Iteration 16310, lr = 0.1
I0905 04:35:26.902051 90901 solver.cpp:228] Iteration 16320, loss = 0.556084
I0905 04:35:26.902230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556084 (* 1 = 0.556084 loss)
I0905 04:35:26.902261 90901 sgd_solver.cpp:106] Iteration 16320, lr = 0.1
I0905 04:35:31.930352 90901 solver.cpp:228] Iteration 16330, loss = 0.419958
I0905 04:35:31.930413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419958 (* 1 = 0.419958 loss)
I0905 04:35:31.930429 90901 sgd_solver.cpp:106] Iteration 16330, lr = 0.1
I0905 04:35:36.978530 90901 solver.cpp:228] Iteration 16340, loss = 0.266066
I0905 04:35:36.978595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266065 (* 1 = 0.266065 loss)
I0905 04:35:36.978610 90901 sgd_solver.cpp:106] Iteration 16340, lr = 0.1
I0905 04:35:41.968386 90901 solver.cpp:228] Iteration 16350, loss = 0.338854
I0905 04:35:41.968442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338853 (* 1 = 0.338853 loss)
I0905 04:35:41.968458 90901 sgd_solver.cpp:106] Iteration 16350, lr = 0.1
I0905 04:35:46.983512 90901 solver.cpp:228] Iteration 16360, loss = 0.465662
I0905 04:35:46.983568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465662 (* 1 = 0.465662 loss)
I0905 04:35:46.983583 90901 sgd_solver.cpp:106] Iteration 16360, lr = 0.1
I0905 04:35:52.026458 90901 solver.cpp:228] Iteration 16370, loss = 0.224046
I0905 04:35:52.026520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224046 (* 1 = 0.224046 loss)
I0905 04:35:52.026536 90901 sgd_solver.cpp:106] Iteration 16370, lr = 0.1
I0905 04:35:57.071419 90901 solver.cpp:228] Iteration 16380, loss = 0.591819
I0905 04:35:57.071568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.591818 (* 1 = 0.591818 loss)
I0905 04:35:57.071605 90901 sgd_solver.cpp:106] Iteration 16380, lr = 0.1
I0905 04:36:02.078141 90901 solver.cpp:228] Iteration 16390, loss = 0.161349
I0905 04:36:02.078204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161349 (* 1 = 0.161349 loss)
I0905 04:36:02.078218 90901 sgd_solver.cpp:106] Iteration 16390, lr = 0.1
I0905 04:36:07.101115 90901 solver.cpp:228] Iteration 16400, loss = 0.199184
I0905 04:36:07.101186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199183 (* 1 = 0.199183 loss)
I0905 04:36:07.101200 90901 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0905 04:36:12.126166 90901 solver.cpp:228] Iteration 16410, loss = 0.274437
I0905 04:36:12.126230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274437 (* 1 = 0.274437 loss)
I0905 04:36:12.126248 90901 sgd_solver.cpp:106] Iteration 16410, lr = 0.1
I0905 04:36:17.159924 90901 solver.cpp:228] Iteration 16420, loss = 0.306397
I0905 04:36:17.159984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306396 (* 1 = 0.306396 loss)
I0905 04:36:17.159999 90901 sgd_solver.cpp:106] Iteration 16420, lr = 0.1
I0905 04:36:22.206993 90901 solver.cpp:228] Iteration 16430, loss = 0.138832
I0905 04:36:22.207047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138832 (* 1 = 0.138832 loss)
I0905 04:36:22.207067 90901 sgd_solver.cpp:106] Iteration 16430, lr = 0.1
I0905 04:36:27.249063 90901 solver.cpp:228] Iteration 16440, loss = 0.39534
I0905 04:36:27.249255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39534 (* 1 = 0.39534 loss)
I0905 04:36:27.249300 90901 sgd_solver.cpp:106] Iteration 16440, lr = 0.1
I0905 04:36:32.036664 90901 solver.cpp:228] Iteration 16450, loss = 0.302849
I0905 04:36:32.036706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302849 (* 1 = 0.302849 loss)
I0905 04:36:32.036720 90901 sgd_solver.cpp:106] Iteration 16450, lr = 0.1
I0905 04:36:36.678788 90901 solver.cpp:228] Iteration 16460, loss = 0.443838
I0905 04:36:36.678833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443838 (* 1 = 0.443838 loss)
I0905 04:36:36.678845 90901 sgd_solver.cpp:106] Iteration 16460, lr = 0.1
I0905 04:36:41.356204 90901 solver.cpp:228] Iteration 16470, loss = 0.378245
I0905 04:36:41.356256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378245 (* 1 = 0.378245 loss)
I0905 04:36:41.356267 90901 sgd_solver.cpp:106] Iteration 16470, lr = 0.1
I0905 04:36:46.381389 90901 solver.cpp:228] Iteration 16480, loss = 0.736108
I0905 04:36:46.381444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.736107 (* 1 = 0.736107 loss)
I0905 04:36:46.381459 90901 sgd_solver.cpp:106] Iteration 16480, lr = 0.1
I0905 04:36:52.451145 90901 solver.cpp:228] Iteration 16490, loss = 0.358207
I0905 04:36:52.451187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358207 (* 1 = 0.358207 loss)
I0905 04:36:52.451201 90901 sgd_solver.cpp:106] Iteration 16490, lr = 0.1
I0905 04:36:58.522785 90901 solver.cpp:228] Iteration 16500, loss = 0.350555
I0905 04:36:58.522936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350555 (* 1 = 0.350555 loss)
I0905 04:36:58.522981 90901 sgd_solver.cpp:106] Iteration 16500, lr = 0.1
I0905 04:37:04.930507 90901 solver.cpp:228] Iteration 16510, loss = 0.33353
I0905 04:37:04.930552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33353 (* 1 = 0.33353 loss)
I0905 04:37:04.930567 90901 sgd_solver.cpp:106] Iteration 16510, lr = 0.1
I0905 04:37:10.973811 90901 solver.cpp:228] Iteration 16520, loss = 0.262441
I0905 04:37:10.973857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262441 (* 1 = 0.262441 loss)
I0905 04:37:10.973870 90901 sgd_solver.cpp:106] Iteration 16520, lr = 0.1
I0905 04:37:17.059028 90901 solver.cpp:228] Iteration 16530, loss = 0.469012
I0905 04:37:17.059085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469012 (* 1 = 0.469012 loss)
I0905 04:37:17.059108 90901 sgd_solver.cpp:106] Iteration 16530, lr = 0.1
I0905 04:37:23.121418 90901 solver.cpp:228] Iteration 16540, loss = 0.44172
I0905 04:37:23.121471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.441719 (* 1 = 0.441719 loss)
I0905 04:37:23.121486 90901 sgd_solver.cpp:106] Iteration 16540, lr = 0.1
I0905 04:37:29.186282 90901 solver.cpp:228] Iteration 16550, loss = 0.17398
I0905 04:37:29.186432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17398 (* 1 = 0.17398 loss)
I0905 04:37:29.186461 90901 sgd_solver.cpp:106] Iteration 16550, lr = 0.1
I0905 04:37:35.238471 90901 solver.cpp:228] Iteration 16560, loss = 0.418489
I0905 04:37:35.238528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418489 (* 1 = 0.418489 loss)
I0905 04:37:35.238541 90901 sgd_solver.cpp:106] Iteration 16560, lr = 0.1
I0905 04:37:41.288338 90901 solver.cpp:228] Iteration 16570, loss = 0.190659
I0905 04:37:41.288401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190659 (* 1 = 0.190659 loss)
I0905 04:37:41.288416 90901 sgd_solver.cpp:106] Iteration 16570, lr = 0.1
I0905 04:37:47.341120 90901 solver.cpp:228] Iteration 16580, loss = 0.468371
I0905 04:37:47.341169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468371 (* 1 = 0.468371 loss)
I0905 04:37:47.341182 90901 sgd_solver.cpp:106] Iteration 16580, lr = 0.1
I0905 04:37:53.700587 90901 solver.cpp:228] Iteration 16590, loss = 0.539605
I0905 04:37:53.700644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.539605 (* 1 = 0.539605 loss)
I0905 04:37:53.700660 90901 sgd_solver.cpp:106] Iteration 16590, lr = 0.1
I0905 04:37:59.768296 90901 solver.cpp:228] Iteration 16600, loss = 0.341326
I0905 04:37:59.768476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341326 (* 1 = 0.341326 loss)
I0905 04:37:59.768527 90901 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0905 04:38:05.822573 90901 solver.cpp:228] Iteration 16610, loss = 0.437484
I0905 04:38:05.822634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437484 (* 1 = 0.437484 loss)
I0905 04:38:05.822657 90901 sgd_solver.cpp:106] Iteration 16610, lr = 0.1
I0905 04:38:11.874905 90901 solver.cpp:228] Iteration 16620, loss = 0.284027
I0905 04:38:11.874950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284026 (* 1 = 0.284026 loss)
I0905 04:38:11.874965 90901 sgd_solver.cpp:106] Iteration 16620, lr = 0.1
I0905 04:38:18.301098 90901 solver.cpp:228] Iteration 16630, loss = 0.274714
I0905 04:38:18.301152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274714 (* 1 = 0.274714 loss)
I0905 04:38:18.301165 90901 sgd_solver.cpp:106] Iteration 16630, lr = 0.1
I0905 04:38:23.647630 90901 solver.cpp:228] Iteration 16640, loss = 0.348526
I0905 04:38:23.647680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348526 (* 1 = 0.348526 loss)
I0905 04:38:23.647692 90901 sgd_solver.cpp:106] Iteration 16640, lr = 0.1
I0905 04:38:28.913879 90901 solver.cpp:228] Iteration 16650, loss = 0.842128
I0905 04:38:28.913931 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.842127 (* 1 = 0.842127 loss)
I0905 04:38:28.913944 90901 sgd_solver.cpp:106] Iteration 16650, lr = 0.1
I0905 04:38:35.002688 90901 solver.cpp:228] Iteration 16660, loss = 0.199951
I0905 04:38:35.002873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199951 (* 1 = 0.199951 loss)
I0905 04:38:35.002889 90901 sgd_solver.cpp:106] Iteration 16660, lr = 0.1
I0905 04:38:41.029669 90901 solver.cpp:228] Iteration 16670, loss = 0.352704
I0905 04:38:41.029719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352703 (* 1 = 0.352703 loss)
I0905 04:38:41.029736 90901 sgd_solver.cpp:106] Iteration 16670, lr = 0.1
I0905 04:38:47.150851 90901 solver.cpp:228] Iteration 16680, loss = 0.518431
I0905 04:38:47.150929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.51843 (* 1 = 0.51843 loss)
I0905 04:38:47.150957 90901 sgd_solver.cpp:106] Iteration 16680, lr = 0.1
I0905 04:38:53.211277 90901 solver.cpp:228] Iteration 16690, loss = 0.210629
I0905 04:38:53.211345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210629 (* 1 = 0.210629 loss)
I0905 04:38:53.211360 90901 sgd_solver.cpp:106] Iteration 16690, lr = 0.1
I0905 04:38:59.274932 90901 solver.cpp:228] Iteration 16700, loss = 0.850571
I0905 04:38:59.274986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.850571 (* 1 = 0.850571 loss)
I0905 04:38:59.275001 90901 sgd_solver.cpp:106] Iteration 16700, lr = 0.1
I0905 04:39:05.638273 90901 solver.cpp:228] Iteration 16710, loss = 0.328094
I0905 04:39:05.638469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328094 (* 1 = 0.328094 loss)
I0905 04:39:05.638504 90901 sgd_solver.cpp:106] Iteration 16710, lr = 0.1
I0905 04:39:11.721281 90901 solver.cpp:228] Iteration 16720, loss = 0.39041
I0905 04:39:11.721329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39041 (* 1 = 0.39041 loss)
I0905 04:39:11.721343 90901 sgd_solver.cpp:106] Iteration 16720, lr = 0.1
I0905 04:39:17.787842 90901 solver.cpp:228] Iteration 16730, loss = 0.222483
I0905 04:39:17.787900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222483 (* 1 = 0.222483 loss)
I0905 04:39:17.787915 90901 sgd_solver.cpp:106] Iteration 16730, lr = 0.1
I0905 04:39:24.148325 90901 solver.cpp:228] Iteration 16740, loss = 0.359059
I0905 04:39:24.148382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359059 (* 1 = 0.359059 loss)
I0905 04:39:24.148396 90901 sgd_solver.cpp:106] Iteration 16740, lr = 0.1
I0905 04:39:30.215318 90901 solver.cpp:228] Iteration 16750, loss = 0.366623
I0905 04:39:30.215380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366622 (* 1 = 0.366622 loss)
I0905 04:39:30.215395 90901 sgd_solver.cpp:106] Iteration 16750, lr = 0.1
I0905 04:39:36.279428 90901 solver.cpp:228] Iteration 16760, loss = 0.559979
I0905 04:39:36.279608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.559978 (* 1 = 0.559978 loss)
I0905 04:39:36.279635 90901 sgd_solver.cpp:106] Iteration 16760, lr = 0.1
I0905 04:39:42.330257 90901 solver.cpp:228] Iteration 16770, loss = 0.300084
I0905 04:39:42.330322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300084 (* 1 = 0.300084 loss)
I0905 04:39:42.330337 90901 sgd_solver.cpp:106] Iteration 16770, lr = 0.1
I0905 04:39:48.400367 90901 solver.cpp:228] Iteration 16780, loss = 0.196472
I0905 04:39:48.400450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196472 (* 1 = 0.196472 loss)
I0905 04:39:48.400470 90901 sgd_solver.cpp:106] Iteration 16780, lr = 0.1
I0905 04:39:54.796195 90901 solver.cpp:228] Iteration 16790, loss = 0.357664
I0905 04:39:54.796255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357664 (* 1 = 0.357664 loss)
I0905 04:39:54.796270 90901 sgd_solver.cpp:106] Iteration 16790, lr = 0.1
I0905 04:40:00.326086 90901 solver.cpp:337] Iteration 16800, Testing net (#0)
I0905 04:40:41.528429 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.844688
I0905 04:40:41.528585 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.344731 (* 1 = 0.344731 loss)
I0905 04:40:41.761699 90901 solver.cpp:228] Iteration 16800, loss = 0.408296
I0905 04:40:41.761741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408296 (* 1 = 0.408296 loss)
I0905 04:40:41.761756 90901 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0905 04:40:48.122478 90901 solver.cpp:228] Iteration 16810, loss = 0.631954
I0905 04:40:48.122530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.631953 (* 1 = 0.631953 loss)
I0905 04:40:48.122546 90901 sgd_solver.cpp:106] Iteration 16810, lr = 0.1
I0905 04:40:53.921588 90901 solver.cpp:228] Iteration 16820, loss = 0.239388
I0905 04:40:53.921622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239388 (* 1 = 0.239388 loss)
I0905 04:40:53.921634 90901 sgd_solver.cpp:106] Iteration 16820, lr = 0.1
I0905 04:41:00.316107 90901 solver.cpp:228] Iteration 16830, loss = 0.515632
I0905 04:41:00.316154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515631 (* 1 = 0.515631 loss)
I0905 04:41:00.316166 90901 sgd_solver.cpp:106] Iteration 16830, lr = 0.1
I0905 04:41:06.375941 90901 solver.cpp:228] Iteration 16840, loss = 0.294009
I0905 04:41:06.375982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294009 (* 1 = 0.294009 loss)
I0905 04:41:06.375996 90901 sgd_solver.cpp:106] Iteration 16840, lr = 0.1
I0905 04:41:12.749092 90901 solver.cpp:228] Iteration 16850, loss = 0.314299
I0905 04:41:12.749279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314298 (* 1 = 0.314298 loss)
I0905 04:41:12.749317 90901 sgd_solver.cpp:106] Iteration 16850, lr = 0.1
I0905 04:41:18.786146 90901 solver.cpp:228] Iteration 16860, loss = 0.256611
I0905 04:41:18.786195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256611 (* 1 = 0.256611 loss)
I0905 04:41:18.786209 90901 sgd_solver.cpp:106] Iteration 16860, lr = 0.1
I0905 04:41:24.858281 90901 solver.cpp:228] Iteration 16870, loss = 0.239091
I0905 04:41:24.858330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23909 (* 1 = 0.23909 loss)
I0905 04:41:24.858346 90901 sgd_solver.cpp:106] Iteration 16870, lr = 0.1
I0905 04:41:30.917353 90901 solver.cpp:228] Iteration 16880, loss = 0.388511
I0905 04:41:30.917413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388511 (* 1 = 0.388511 loss)
I0905 04:41:30.917428 90901 sgd_solver.cpp:106] Iteration 16880, lr = 0.1
I0905 04:41:36.960012 90901 solver.cpp:228] Iteration 16890, loss = 0.175807
I0905 04:41:36.960057 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175807 (* 1 = 0.175807 loss)
I0905 04:41:36.960069 90901 sgd_solver.cpp:106] Iteration 16890, lr = 0.1
I0905 04:41:43.055012 90901 solver.cpp:228] Iteration 16900, loss = 0.262458
I0905 04:41:43.055198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262458 (* 1 = 0.262458 loss)
I0905 04:41:43.055215 90901 sgd_solver.cpp:106] Iteration 16900, lr = 0.1
I0905 04:41:49.141695 90901 solver.cpp:228] Iteration 16910, loss = 0.745741
I0905 04:41:49.141731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.745741 (* 1 = 0.745741 loss)
I0905 04:41:49.141742 90901 sgd_solver.cpp:106] Iteration 16910, lr = 0.1
I0905 04:41:55.456758 90901 solver.cpp:228] Iteration 16920, loss = 0.413729
I0905 04:41:55.456830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413729 (* 1 = 0.413729 loss)
I0905 04:41:55.456845 90901 sgd_solver.cpp:106] Iteration 16920, lr = 0.1
I0905 04:42:00.719161 90901 solver.cpp:228] Iteration 16930, loss = 0.243903
I0905 04:42:00.719210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243902 (* 1 = 0.243902 loss)
I0905 04:42:00.719223 90901 sgd_solver.cpp:106] Iteration 16930, lr = 0.1
I0905 04:42:06.104560 90901 solver.cpp:228] Iteration 16940, loss = 0.27736
I0905 04:42:06.104604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27736 (* 1 = 0.27736 loss)
I0905 04:42:06.104616 90901 sgd_solver.cpp:106] Iteration 16940, lr = 0.1
I0905 04:42:12.230448 90901 solver.cpp:228] Iteration 16950, loss = 0.30805
I0905 04:42:12.230499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308049 (* 1 = 0.308049 loss)
I0905 04:42:12.230514 90901 sgd_solver.cpp:106] Iteration 16950, lr = 0.1
I0905 04:42:18.557392 90901 solver.cpp:228] Iteration 16960, loss = 0.0975237
I0905 04:42:18.557546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0975235 (* 1 = 0.0975235 loss)
I0905 04:42:18.557600 90901 sgd_solver.cpp:106] Iteration 16960, lr = 0.1
I0905 04:42:24.614581 90901 solver.cpp:228] Iteration 16970, loss = 0.190912
I0905 04:42:24.614639 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190912 (* 1 = 0.190912 loss)
I0905 04:42:24.614675 90901 sgd_solver.cpp:106] Iteration 16970, lr = 0.1
I0905 04:42:30.678409 90901 solver.cpp:228] Iteration 16980, loss = 0.555436
I0905 04:42:30.678449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555436 (* 1 = 0.555436 loss)
I0905 04:42:30.678462 90901 sgd_solver.cpp:106] Iteration 16980, lr = 0.1
I0905 04:42:36.730911 90901 solver.cpp:228] Iteration 16990, loss = 0.262233
I0905 04:42:36.730964 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262232 (* 1 = 0.262232 loss)
I0905 04:42:36.730978 90901 sgd_solver.cpp:106] Iteration 16990, lr = 0.1
I0905 04:42:43.119321 90901 solver.cpp:228] Iteration 17000, loss = 0.316915
I0905 04:42:43.119372 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316915 (* 1 = 0.316915 loss)
I0905 04:42:43.119386 90901 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0905 04:42:49.157786 90901 solver.cpp:228] Iteration 17010, loss = 0.374099
I0905 04:42:49.158102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374099 (* 1 = 0.374099 loss)
I0905 04:42:49.158121 90901 sgd_solver.cpp:106] Iteration 17010, lr = 0.1
I0905 04:42:55.217326 90901 solver.cpp:228] Iteration 17020, loss = 1.01712
I0905 04:42:55.217381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.01712 (* 1 = 1.01712 loss)
I0905 04:42:55.217393 90901 sgd_solver.cpp:106] Iteration 17020, lr = 0.1
I0905 04:43:01.595021 90901 solver.cpp:228] Iteration 17030, loss = 0.299217
I0905 04:43:01.595075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299217 (* 1 = 0.299217 loss)
I0905 04:43:01.595093 90901 sgd_solver.cpp:106] Iteration 17030, lr = 0.1
I0905 04:43:07.654270 90901 solver.cpp:228] Iteration 17040, loss = 0.581263
I0905 04:43:07.654320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.581263 (* 1 = 0.581263 loss)
I0905 04:43:07.654332 90901 sgd_solver.cpp:106] Iteration 17040, lr = 0.1
I0905 04:43:13.728430 90901 solver.cpp:228] Iteration 17050, loss = 0.143722
I0905 04:43:13.728478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143721 (* 1 = 0.143721 loss)
I0905 04:43:13.728493 90901 sgd_solver.cpp:106] Iteration 17050, lr = 0.1
I0905 04:43:19.828815 90901 solver.cpp:228] Iteration 17060, loss = 0.320999
I0905 04:43:19.828986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320998 (* 1 = 0.320998 loss)
I0905 04:43:19.829028 90901 sgd_solver.cpp:106] Iteration 17060, lr = 0.1
I0905 04:43:25.878343 90901 solver.cpp:228] Iteration 17070, loss = 0.490256
I0905 04:43:25.878388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490256 (* 1 = 0.490256 loss)
I0905 04:43:25.878401 90901 sgd_solver.cpp:106] Iteration 17070, lr = 0.1
I0905 04:43:32.295114 90901 solver.cpp:228] Iteration 17080, loss = 0.308564
I0905 04:43:32.295161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308564 (* 1 = 0.308564 loss)
I0905 04:43:32.295174 90901 sgd_solver.cpp:106] Iteration 17080, lr = 0.1
I0905 04:43:38.337236 90901 solver.cpp:228] Iteration 17090, loss = 0.577017
I0905 04:43:38.337290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.577017 (* 1 = 0.577017 loss)
I0905 04:43:38.337303 90901 sgd_solver.cpp:106] Iteration 17090, lr = 0.1
I0905 04:43:44.298697 90901 solver.cpp:228] Iteration 17100, loss = 0.12999
I0905 04:43:44.298743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12999 (* 1 = 0.12999 loss)
I0905 04:43:44.298756 90901 sgd_solver.cpp:106] Iteration 17100, lr = 0.1
I0905 04:43:49.861995 90901 solver.cpp:228] Iteration 17110, loss = 0.314528
I0905 04:43:49.862157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314527 (* 1 = 0.314527 loss)
I0905 04:43:49.862208 90901 sgd_solver.cpp:106] Iteration 17110, lr = 0.1
I0905 04:43:55.261874 90901 solver.cpp:228] Iteration 17120, loss = 0.314393
I0905 04:43:55.261924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314393 (* 1 = 0.314393 loss)
I0905 04:43:55.261939 90901 sgd_solver.cpp:106] Iteration 17120, lr = 0.1
I0905 04:44:01.312117 90901 solver.cpp:228] Iteration 17130, loss = 0.693498
I0905 04:44:01.312161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.693498 (* 1 = 0.693498 loss)
I0905 04:44:01.312173 90901 sgd_solver.cpp:106] Iteration 17130, lr = 0.1
I0905 04:44:07.727243 90901 solver.cpp:228] Iteration 17140, loss = 0.380128
I0905 04:44:07.727295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380128 (* 1 = 0.380128 loss)
I0905 04:44:07.727309 90901 sgd_solver.cpp:106] Iteration 17140, lr = 0.1
I0905 04:44:13.819363 90901 solver.cpp:228] Iteration 17150, loss = 0.163031
I0905 04:44:13.819413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163031 (* 1 = 0.163031 loss)
I0905 04:44:13.819428 90901 sgd_solver.cpp:106] Iteration 17150, lr = 0.1
I0905 04:44:19.892678 90901 solver.cpp:228] Iteration 17160, loss = 0.169133
I0905 04:44:19.892895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169133 (* 1 = 0.169133 loss)
I0905 04:44:19.892912 90901 sgd_solver.cpp:106] Iteration 17160, lr = 0.1
I0905 04:44:25.927918 90901 solver.cpp:228] Iteration 17170, loss = 0.341323
I0905 04:44:25.927966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341323 (* 1 = 0.341323 loss)
I0905 04:44:25.927980 90901 sgd_solver.cpp:106] Iteration 17170, lr = 0.1
I0905 04:44:32.275292 90901 solver.cpp:228] Iteration 17180, loss = 0.453665
I0905 04:44:32.275339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453665 (* 1 = 0.453665 loss)
I0905 04:44:32.275352 90901 sgd_solver.cpp:106] Iteration 17180, lr = 0.1
I0905 04:44:38.376294 90901 solver.cpp:228] Iteration 17190, loss = 0.272453
I0905 04:44:38.376344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272453 (* 1 = 0.272453 loss)
I0905 04:44:38.376359 90901 sgd_solver.cpp:106] Iteration 17190, lr = 0.1
I0905 04:44:44.459105 90901 solver.cpp:228] Iteration 17200, loss = 0.522927
I0905 04:44:44.459156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.522927 (* 1 = 0.522927 loss)
I0905 04:44:44.459172 90901 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0905 04:44:50.235556 90901 solver.cpp:228] Iteration 17210, loss = 0.0973943
I0905 04:44:50.235705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0973941 (* 1 = 0.0973941 loss)
I0905 04:44:50.235745 90901 sgd_solver.cpp:106] Iteration 17210, lr = 0.1
I0905 04:44:56.292131 90901 solver.cpp:228] Iteration 17220, loss = 0.541244
I0905 04:44:56.292172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541243 (* 1 = 0.541243 loss)
I0905 04:44:56.292184 90901 sgd_solver.cpp:106] Iteration 17220, lr = 0.1
I0905 04:45:02.457900 90901 solver.cpp:228] Iteration 17230, loss = 0.261425
I0905 04:45:02.457947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261424 (* 1 = 0.261424 loss)
I0905 04:45:02.457959 90901 sgd_solver.cpp:106] Iteration 17230, lr = 0.1
I0905 04:45:08.727722 90901 solver.cpp:228] Iteration 17240, loss = 0.528373
I0905 04:45:08.727798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528373 (* 1 = 0.528373 loss)
I0905 04:45:08.727820 90901 sgd_solver.cpp:106] Iteration 17240, lr = 0.1
I0905 04:45:14.834509 90901 solver.cpp:228] Iteration 17250, loss = 0.514557
I0905 04:45:14.834553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514557 (* 1 = 0.514557 loss)
I0905 04:45:14.834564 90901 sgd_solver.cpp:106] Iteration 17250, lr = 0.1
I0905 04:45:20.596238 90901 solver.cpp:228] Iteration 17260, loss = 0.707076
I0905 04:45:20.596392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.707075 (* 1 = 0.707075 loss)
I0905 04:45:20.596434 90901 sgd_solver.cpp:106] Iteration 17260, lr = 0.1
I0905 04:45:26.982218 90901 solver.cpp:228] Iteration 17270, loss = 0.276633
I0905 04:45:26.982264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276633 (* 1 = 0.276633 loss)
I0905 04:45:26.982276 90901 sgd_solver.cpp:106] Iteration 17270, lr = 0.1
I0905 04:45:32.807325 90901 solver.cpp:228] Iteration 17280, loss = 0.458882
I0905 04:45:32.807385 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458882 (* 1 = 0.458882 loss)
I0905 04:45:32.807399 90901 sgd_solver.cpp:106] Iteration 17280, lr = 0.1
I0905 04:45:38.052628 90901 solver.cpp:228] Iteration 17290, loss = 0.524809
I0905 04:45:38.052690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.524809 (* 1 = 0.524809 loss)
I0905 04:45:38.052703 90901 sgd_solver.cpp:106] Iteration 17290, lr = 0.1
I0905 04:45:43.970151 90901 solver.cpp:228] Iteration 17300, loss = 0.552329
I0905 04:45:43.970206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552329 (* 1 = 0.552329 loss)
I0905 04:45:43.970221 90901 sgd_solver.cpp:106] Iteration 17300, lr = 0.1
I0905 04:45:49.992630 90901 solver.cpp:228] Iteration 17310, loss = 0.484802
I0905 04:45:49.992682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484802 (* 1 = 0.484802 loss)
I0905 04:45:49.992697 90901 sgd_solver.cpp:106] Iteration 17310, lr = 0.1
I0905 04:45:56.048094 90901 solver.cpp:228] Iteration 17320, loss = 0.102806
I0905 04:45:56.048318 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102806 (* 1 = 0.102806 loss)
I0905 04:45:56.048332 90901 sgd_solver.cpp:106] Iteration 17320, lr = 0.1
I0905 04:46:02.113521 90901 solver.cpp:228] Iteration 17330, loss = 0.326412
I0905 04:46:02.113569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326411 (* 1 = 0.326411 loss)
I0905 04:46:02.113582 90901 sgd_solver.cpp:106] Iteration 17330, lr = 0.1
I0905 04:46:08.189187 90901 solver.cpp:228] Iteration 17340, loss = 0.327175
I0905 04:46:08.189234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327175 (* 1 = 0.327175 loss)
I0905 04:46:08.189245 90901 sgd_solver.cpp:106] Iteration 17340, lr = 0.1
I0905 04:46:14.255889 90901 solver.cpp:228] Iteration 17350, loss = 0.545215
I0905 04:46:14.255965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.545215 (* 1 = 0.545215 loss)
I0905 04:46:14.255986 90901 sgd_solver.cpp:106] Iteration 17350, lr = 0.1
I0905 04:46:20.003231 90901 solver.cpp:228] Iteration 17360, loss = 0.499836
I0905 04:46:20.003286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.499835 (* 1 = 0.499835 loss)
I0905 04:46:20.003300 90901 sgd_solver.cpp:106] Iteration 17360, lr = 0.1
I0905 04:46:26.371346 90901 solver.cpp:228] Iteration 17370, loss = 0.46961
I0905 04:46:26.371536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46961 (* 1 = 0.46961 loss)
I0905 04:46:26.371579 90901 sgd_solver.cpp:106] Iteration 17370, lr = 0.1
I0905 04:46:32.220697 90901 solver.cpp:228] Iteration 17380, loss = 0.371263
I0905 04:46:32.220752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371262 (* 1 = 0.371262 loss)
I0905 04:46:32.220765 90901 sgd_solver.cpp:106] Iteration 17380, lr = 0.1
I0905 04:46:38.617815 90901 solver.cpp:228] Iteration 17390, loss = 0.25714
I0905 04:46:38.617877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257139 (* 1 = 0.257139 loss)
I0905 04:46:38.617895 90901 sgd_solver.cpp:106] Iteration 17390, lr = 0.1
I0905 04:46:44.721392 90901 solver.cpp:228] Iteration 17400, loss = 0.402335
I0905 04:46:44.721437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402335 (* 1 = 0.402335 loss)
I0905 04:46:44.721451 90901 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0905 04:46:50.811352 90901 solver.cpp:228] Iteration 17410, loss = 0.253291
I0905 04:46:50.811394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253291 (* 1 = 0.253291 loss)
I0905 04:46:50.811406 90901 sgd_solver.cpp:106] Iteration 17410, lr = 0.1
I0905 04:46:56.872781 90901 solver.cpp:228] Iteration 17420, loss = 0.491239
I0905 04:46:56.872931 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491239 (* 1 = 0.491239 loss)
I0905 04:46:56.872977 90901 sgd_solver.cpp:106] Iteration 17420, lr = 0.1
I0905 04:47:03.253377 90901 solver.cpp:228] Iteration 17430, loss = 0.167355
I0905 04:47:03.253444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167355 (* 1 = 0.167355 loss)
I0905 04:47:03.253458 90901 sgd_solver.cpp:106] Iteration 17430, lr = 0.1
I0905 04:47:09.301213 90901 solver.cpp:228] Iteration 17440, loss = 0.598548
I0905 04:47:09.301261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.598548 (* 1 = 0.598548 loss)
I0905 04:47:09.301275 90901 sgd_solver.cpp:106] Iteration 17440, lr = 0.1
I0905 04:47:15.407254 90901 solver.cpp:228] Iteration 17450, loss = 0.520291
I0905 04:47:15.407307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520291 (* 1 = 0.520291 loss)
I0905 04:47:15.407327 90901 sgd_solver.cpp:106] Iteration 17450, lr = 0.1
I0905 04:47:21.031942 90901 solver.cpp:228] Iteration 17460, loss = 0.190597
I0905 04:47:21.031985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190597 (* 1 = 0.190597 loss)
I0905 04:47:21.031999 90901 sgd_solver.cpp:106] Iteration 17460, lr = 0.1
I0905 04:47:26.281800 90901 solver.cpp:228] Iteration 17470, loss = 0.462717
I0905 04:47:26.281844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462717 (* 1 = 0.462717 loss)
I0905 04:47:26.281858 90901 sgd_solver.cpp:106] Iteration 17470, lr = 0.1
I0905 04:47:32.345186 90901 solver.cpp:228] Iteration 17480, loss = 0.238749
I0905 04:47:32.345399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238749 (* 1 = 0.238749 loss)
I0905 04:47:32.345439 90901 sgd_solver.cpp:106] Iteration 17480, lr = 0.1
I0905 04:47:38.407579 90901 solver.cpp:228] Iteration 17490, loss = 0.327593
I0905 04:47:38.407621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327593 (* 1 = 0.327593 loss)
I0905 04:47:38.407635 90901 sgd_solver.cpp:106] Iteration 17490, lr = 0.1
I0905 04:47:44.459393 90901 solver.cpp:228] Iteration 17500, loss = 0.262603
I0905 04:47:44.459450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262602 (* 1 = 0.262602 loss)
I0905 04:47:44.459465 90901 sgd_solver.cpp:106] Iteration 17500, lr = 0.1
I0905 04:47:50.545739 90901 solver.cpp:228] Iteration 17510, loss = 0.409674
I0905 04:47:50.545809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409674 (* 1 = 0.409674 loss)
I0905 04:47:50.545825 90901 sgd_solver.cpp:106] Iteration 17510, lr = 0.1
I0905 04:47:56.859464 90901 solver.cpp:228] Iteration 17520, loss = 0.220482
I0905 04:47:56.859505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220482 (* 1 = 0.220482 loss)
I0905 04:47:56.859518 90901 sgd_solver.cpp:106] Iteration 17520, lr = 0.1
I0905 04:48:03.032594 90901 solver.cpp:228] Iteration 17530, loss = 0.27506
I0905 04:48:03.032752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275059 (* 1 = 0.275059 loss)
I0905 04:48:03.032793 90901 sgd_solver.cpp:106] Iteration 17530, lr = 0.1
I0905 04:48:09.088487 90901 solver.cpp:228] Iteration 17540, loss = 0.52497
I0905 04:48:09.088560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.52497 (* 1 = 0.52497 loss)
I0905 04:48:09.088577 90901 sgd_solver.cpp:106] Iteration 17540, lr = 0.1
I0905 04:48:15.146986 90901 solver.cpp:228] Iteration 17550, loss = 0.376091
I0905 04:48:15.147052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376091 (* 1 = 0.376091 loss)
I0905 04:48:15.147068 90901 sgd_solver.cpp:106] Iteration 17550, lr = 0.1
I0905 04:48:21.208482 90901 solver.cpp:228] Iteration 17560, loss = 0.404508
I0905 04:48:21.208539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404508 (* 1 = 0.404508 loss)
I0905 04:48:21.208552 90901 sgd_solver.cpp:106] Iteration 17560, lr = 0.1
I0905 04:48:27.612140 90901 solver.cpp:228] Iteration 17570, loss = 0.414074
I0905 04:48:27.612171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414074 (* 1 = 0.414074 loss)
I0905 04:48:27.612185 90901 sgd_solver.cpp:106] Iteration 17570, lr = 0.1
I0905 04:48:33.337899 90901 solver.cpp:228] Iteration 17580, loss = 0.383588
I0905 04:48:33.338552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383588 (* 1 = 0.383588 loss)
I0905 04:48:33.338570 90901 sgd_solver.cpp:106] Iteration 17580, lr = 0.1
I0905 04:48:39.395668 90901 solver.cpp:228] Iteration 17590, loss = 0.370648
I0905 04:48:39.395717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370648 (* 1 = 0.370648 loss)
I0905 04:48:39.395730 90901 sgd_solver.cpp:106] Iteration 17590, lr = 0.1
I0905 04:48:45.198185 90901 solver.cpp:337] Iteration 17600, Testing net (#0)
I0905 04:49:26.247539 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.705312
I0905 04:49:26.247778 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.581148 (* 1 = 0.581148 loss)
I0905 04:49:26.466809 90901 solver.cpp:228] Iteration 17600, loss = 0.303937
I0905 04:49:26.466857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303937 (* 1 = 0.303937 loss)
I0905 04:49:26.466876 90901 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0905 04:49:32.580482 90901 solver.cpp:228] Iteration 17610, loss = 0.101303
I0905 04:49:32.580543 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101302 (* 1 = 0.101302 loss)
I0905 04:49:32.580555 90901 sgd_solver.cpp:106] Iteration 17610, lr = 0.1
I0905 04:49:38.642748 90901 solver.cpp:228] Iteration 17620, loss = 0.369781
I0905 04:49:38.642797 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369781 (* 1 = 0.369781 loss)
I0905 04:49:38.642810 90901 sgd_solver.cpp:106] Iteration 17620, lr = 0.1
I0905 04:49:44.701838 90901 solver.cpp:228] Iteration 17630, loss = 0.242054
I0905 04:49:44.701880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242054 (* 1 = 0.242054 loss)
I0905 04:49:44.701894 90901 sgd_solver.cpp:106] Iteration 17630, lr = 0.1
I0905 04:49:50.463665 90901 solver.cpp:228] Iteration 17640, loss = 0.17837
I0905 04:49:50.463701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17837 (* 1 = 0.17837 loss)
I0905 04:49:50.463713 90901 sgd_solver.cpp:106] Iteration 17640, lr = 0.1
I0905 04:49:56.860141 90901 solver.cpp:228] Iteration 17650, loss = 0.578078
I0905 04:49:56.860321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578078 (* 1 = 0.578078 loss)
I0905 04:49:56.860373 90901 sgd_solver.cpp:106] Iteration 17650, lr = 0.1
I0905 04:50:03.240360 90901 solver.cpp:228] Iteration 17660, loss = 0.505996
I0905 04:50:03.240414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505996 (* 1 = 0.505996 loss)
I0905 04:50:03.240428 90901 sgd_solver.cpp:106] Iteration 17660, lr = 0.1
I0905 04:50:09.330579 90901 solver.cpp:228] Iteration 17670, loss = 0.583097
I0905 04:50:09.330634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.583097 (* 1 = 0.583097 loss)
I0905 04:50:09.330648 90901 sgd_solver.cpp:106] Iteration 17670, lr = 0.1
I0905 04:50:15.408339 90901 solver.cpp:228] Iteration 17680, loss = 0.244627
I0905 04:50:15.408390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244627 (* 1 = 0.244627 loss)
I0905 04:50:15.408403 90901 sgd_solver.cpp:106] Iteration 17680, lr = 0.1
I0905 04:50:21.355610 90901 solver.cpp:228] Iteration 17690, loss = 0.566099
I0905 04:50:21.355648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566099 (* 1 = 0.566099 loss)
I0905 04:50:21.355662 90901 sgd_solver.cpp:106] Iteration 17690, lr = 0.1
I0905 04:50:27.277928 90901 solver.cpp:228] Iteration 17700, loss = 0.583804
I0905 04:50:27.278156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.583804 (* 1 = 0.583804 loss)
I0905 04:50:27.278174 90901 sgd_solver.cpp:106] Iteration 17700, lr = 0.1
I0905 04:50:33.706245 90901 solver.cpp:228] Iteration 17710, loss = 0.288939
I0905 04:50:33.706302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288939 (* 1 = 0.288939 loss)
I0905 04:50:33.706318 90901 sgd_solver.cpp:106] Iteration 17710, lr = 0.1
I0905 04:50:39.727385 90901 solver.cpp:228] Iteration 17720, loss = 0.454444
I0905 04:50:39.727442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454444 (* 1 = 0.454444 loss)
I0905 04:50:39.727457 90901 sgd_solver.cpp:106] Iteration 17720, lr = 0.1
I0905 04:50:45.792150 90901 solver.cpp:228] Iteration 17730, loss = 0.424315
I0905 04:50:45.792197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424315 (* 1 = 0.424315 loss)
I0905 04:50:45.792212 90901 sgd_solver.cpp:106] Iteration 17730, lr = 0.1
I0905 04:50:52.192208 90901 solver.cpp:228] Iteration 17740, loss = 0.43228
I0905 04:50:52.192240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43228 (* 1 = 0.43228 loss)
I0905 04:50:52.192255 90901 sgd_solver.cpp:106] Iteration 17740, lr = 0.1
I0905 04:50:57.447809 90901 solver.cpp:228] Iteration 17750, loss = 0.274709
I0905 04:50:57.448017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274708 (* 1 = 0.274708 loss)
I0905 04:50:57.448031 90901 sgd_solver.cpp:106] Iteration 17750, lr = 0.1
I0905 04:51:03.036203 90901 solver.cpp:228] Iteration 17760, loss = 0.630791
I0905 04:51:03.036264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.630791 (* 1 = 0.630791 loss)
I0905 04:51:03.036278 90901 sgd_solver.cpp:106] Iteration 17760, lr = 0.1
I0905 04:51:08.794169 90901 solver.cpp:228] Iteration 17770, loss = 0.365324
I0905 04:51:08.794224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365324 (* 1 = 0.365324 loss)
I0905 04:51:08.794244 90901 sgd_solver.cpp:106] Iteration 17770, lr = 0.1
I0905 04:51:14.868486 90901 solver.cpp:228] Iteration 17780, loss = 0.201817
I0905 04:51:14.868531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201817 (* 1 = 0.201817 loss)
I0905 04:51:14.868546 90901 sgd_solver.cpp:106] Iteration 17780, lr = 0.1
I0905 04:51:21.230675 90901 solver.cpp:228] Iteration 17790, loss = 0.561391
I0905 04:51:21.230721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.561391 (* 1 = 0.561391 loss)
I0905 04:51:21.230736 90901 sgd_solver.cpp:106] Iteration 17790, lr = 0.1
I0905 04:51:27.085515 90901 solver.cpp:228] Iteration 17800, loss = 0.215211
I0905 04:51:27.085556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215211 (* 1 = 0.215211 loss)
I0905 04:51:27.085569 90901 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0905 04:51:33.419122 90901 solver.cpp:228] Iteration 17810, loss = 0.149522
I0905 04:51:33.419262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149522 (* 1 = 0.149522 loss)
I0905 04:51:33.419320 90901 sgd_solver.cpp:106] Iteration 17810, lr = 0.1
I0905 04:51:39.209347 90901 solver.cpp:228] Iteration 17820, loss = 0.680705
I0905 04:51:39.209398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.680705 (* 1 = 0.680705 loss)
I0905 04:51:39.209414 90901 sgd_solver.cpp:106] Iteration 17820, lr = 0.1
I0905 04:51:45.607193 90901 solver.cpp:228] Iteration 17830, loss = 0.298003
I0905 04:51:45.607235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298003 (* 1 = 0.298003 loss)
I0905 04:51:45.607249 90901 sgd_solver.cpp:106] Iteration 17830, lr = 0.1
I0905 04:51:51.682911 90901 solver.cpp:228] Iteration 17840, loss = 0.59684
I0905 04:51:51.682956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59684 (* 1 = 0.59684 loss)
I0905 04:51:51.682970 90901 sgd_solver.cpp:106] Iteration 17840, lr = 0.1
I0905 04:51:57.728572 90901 solver.cpp:228] Iteration 17850, loss = 0.158988
I0905 04:51:57.728621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158987 (* 1 = 0.158987 loss)
I0905 04:51:57.728634 90901 sgd_solver.cpp:106] Iteration 17850, lr = 0.1
I0905 04:52:04.107508 90901 solver.cpp:228] Iteration 17860, loss = 0.25941
I0905 04:52:04.107661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25941 (* 1 = 0.25941 loss)
I0905 04:52:04.107692 90901 sgd_solver.cpp:106] Iteration 17860, lr = 0.1
I0905 04:52:09.825752 90901 solver.cpp:228] Iteration 17870, loss = 0.57168
I0905 04:52:09.825794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.57168 (* 1 = 0.57168 loss)
I0905 04:52:09.825808 90901 sgd_solver.cpp:106] Iteration 17870, lr = 0.1
I0905 04:52:16.216223 90901 solver.cpp:228] Iteration 17880, loss = 0.236274
I0905 04:52:16.216262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236274 (* 1 = 0.236274 loss)
I0905 04:52:16.216274 90901 sgd_solver.cpp:106] Iteration 17880, lr = 0.1
I0905 04:52:22.299908 90901 solver.cpp:228] Iteration 17890, loss = 0.237992
I0905 04:52:22.299954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237992 (* 1 = 0.237992 loss)
I0905 04:52:22.299968 90901 sgd_solver.cpp:106] Iteration 17890, lr = 0.1
I0905 04:52:28.355377 90901 solver.cpp:228] Iteration 17900, loss = 0.186903
I0905 04:52:28.355423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186903 (* 1 = 0.186903 loss)
I0905 04:52:28.355437 90901 sgd_solver.cpp:106] Iteration 17900, lr = 0.1
I0905 04:52:34.449300 90901 solver.cpp:228] Iteration 17910, loss = 0.365718
I0905 04:52:34.449473 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365718 (* 1 = 0.365718 loss)
I0905 04:52:34.449496 90901 sgd_solver.cpp:106] Iteration 17910, lr = 0.1
I0905 04:52:40.390166 90901 solver.cpp:228] Iteration 17920, loss = 0.61541
I0905 04:52:40.390211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.615409 (* 1 = 0.615409 loss)
I0905 04:52:40.390223 90901 sgd_solver.cpp:106] Iteration 17920, lr = 0.1
I0905 04:52:45.636240 90901 solver.cpp:228] Iteration 17930, loss = 0.393797
I0905 04:52:45.636286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393797 (* 1 = 0.393797 loss)
I0905 04:52:45.636297 90901 sgd_solver.cpp:106] Iteration 17930, lr = 0.1
I0905 04:52:51.502801 90901 solver.cpp:228] Iteration 17940, loss = 0.285991
I0905 04:52:51.502847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28599 (* 1 = 0.28599 loss)
I0905 04:52:51.502862 90901 sgd_solver.cpp:106] Iteration 17940, lr = 0.1
I0905 04:52:57.374269 90901 solver.cpp:228] Iteration 17950, loss = 0.172023
I0905 04:52:57.374315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172023 (* 1 = 0.172023 loss)
I0905 04:52:57.374328 90901 sgd_solver.cpp:106] Iteration 17950, lr = 0.1
I0905 04:53:03.640015 90901 solver.cpp:228] Iteration 17960, loss = 0.376123
I0905 04:53:03.640060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376123 (* 1 = 0.376123 loss)
I0905 04:53:03.640074 90901 sgd_solver.cpp:106] Iteration 17960, lr = 0.1
I0905 04:53:09.653321 90901 solver.cpp:228] Iteration 17970, loss = 0.329406
I0905 04:53:09.653463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329406 (* 1 = 0.329406 loss)
I0905 04:53:09.653508 90901 sgd_solver.cpp:106] Iteration 17970, lr = 0.1
I0905 04:53:15.049357 90901 solver.cpp:228] Iteration 17980, loss = 0.444763
I0905 04:53:15.049401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444763 (* 1 = 0.444763 loss)
I0905 04:53:15.049413 90901 sgd_solver.cpp:106] Iteration 17980, lr = 0.1
I0905 04:53:20.099190 90901 solver.cpp:228] Iteration 17990, loss = 0.354451
I0905 04:53:20.099231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354451 (* 1 = 0.354451 loss)
I0905 04:53:20.099244 90901 sgd_solver.cpp:106] Iteration 17990, lr = 0.1
I0905 04:53:25.161247 90901 solver.cpp:228] Iteration 18000, loss = 0.27288
I0905 04:53:25.161291 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27288 (* 1 = 0.27288 loss)
I0905 04:53:25.161305 90901 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0905 04:53:30.199676 90901 solver.cpp:228] Iteration 18010, loss = 0.283702
I0905 04:53:30.199714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283701 (* 1 = 0.283701 loss)
I0905 04:53:30.199728 90901 sgd_solver.cpp:106] Iteration 18010, lr = 0.1
I0905 04:53:35.217744 90901 solver.cpp:228] Iteration 18020, loss = 0.201756
I0905 04:53:35.217808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201755 (* 1 = 0.201755 loss)
I0905 04:53:35.217821 90901 sgd_solver.cpp:106] Iteration 18020, lr = 0.1
I0905 04:53:40.242688 90901 solver.cpp:228] Iteration 18030, loss = 0.459695
I0905 04:53:40.242866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459695 (* 1 = 0.459695 loss)
I0905 04:53:40.242900 90901 sgd_solver.cpp:106] Iteration 18030, lr = 0.1
I0905 04:53:45.272043 90901 solver.cpp:228] Iteration 18040, loss = 0.833188
I0905 04:53:45.272089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.833188 (* 1 = 0.833188 loss)
I0905 04:53:45.272101 90901 sgd_solver.cpp:106] Iteration 18040, lr = 0.1
I0905 04:53:50.337180 90901 solver.cpp:228] Iteration 18050, loss = 0.179782
I0905 04:53:50.337225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179782 (* 1 = 0.179782 loss)
I0905 04:53:50.337239 90901 sgd_solver.cpp:106] Iteration 18050, lr = 0.1
I0905 04:53:55.392488 90901 solver.cpp:228] Iteration 18060, loss = 0.296525
I0905 04:53:55.392529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296525 (* 1 = 0.296525 loss)
I0905 04:53:55.392544 90901 sgd_solver.cpp:106] Iteration 18060, lr = 0.1
I0905 04:54:00.442360 90901 solver.cpp:228] Iteration 18070, loss = 0.53492
I0905 04:54:00.442420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.53492 (* 1 = 0.53492 loss)
I0905 04:54:00.442436 90901 sgd_solver.cpp:106] Iteration 18070, lr = 0.1
I0905 04:54:05.450907 90901 solver.cpp:228] Iteration 18080, loss = 0.208967
I0905 04:54:05.450956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208967 (* 1 = 0.208967 loss)
I0905 04:54:05.450969 90901 sgd_solver.cpp:106] Iteration 18080, lr = 0.1
I0905 04:54:10.475507 90901 solver.cpp:228] Iteration 18090, loss = 0.39654
I0905 04:54:10.475693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396539 (* 1 = 0.396539 loss)
I0905 04:54:10.475715 90901 sgd_solver.cpp:106] Iteration 18090, lr = 0.1
I0905 04:54:15.564097 90901 solver.cpp:228] Iteration 18100, loss = 0.295839
I0905 04:54:15.564146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295838 (* 1 = 0.295838 loss)
I0905 04:54:15.564159 90901 sgd_solver.cpp:106] Iteration 18100, lr = 0.1
I0905 04:54:20.589424 90901 solver.cpp:228] Iteration 18110, loss = 0.657461
I0905 04:54:20.589465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.65746 (* 1 = 0.65746 loss)
I0905 04:54:20.589484 90901 sgd_solver.cpp:106] Iteration 18110, lr = 0.1
I0905 04:54:25.627248 90901 solver.cpp:228] Iteration 18120, loss = 0.195665
I0905 04:54:25.627308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195664 (* 1 = 0.195664 loss)
I0905 04:54:25.627323 90901 sgd_solver.cpp:106] Iteration 18120, lr = 0.1
I0905 04:54:30.599237 90901 solver.cpp:228] Iteration 18130, loss = 0.477579
I0905 04:54:30.599282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477578 (* 1 = 0.477578 loss)
I0905 04:54:30.599295 90901 sgd_solver.cpp:106] Iteration 18130, lr = 0.1
I0905 04:54:35.548862 90901 solver.cpp:228] Iteration 18140, loss = 0.362652
I0905 04:54:35.548903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362651 (* 1 = 0.362651 loss)
I0905 04:54:35.548918 90901 sgd_solver.cpp:106] Iteration 18140, lr = 0.1
I0905 04:54:41.176108 90901 solver.cpp:228] Iteration 18150, loss = 0.710387
I0905 04:54:41.176246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.710387 (* 1 = 0.710387 loss)
I0905 04:54:41.176285 90901 sgd_solver.cpp:106] Iteration 18150, lr = 0.1
I0905 04:54:47.281690 90901 solver.cpp:228] Iteration 18160, loss = 0.198353
I0905 04:54:47.281738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198353 (* 1 = 0.198353 loss)
I0905 04:54:47.281750 90901 sgd_solver.cpp:106] Iteration 18160, lr = 0.1
I0905 04:54:53.315320 90901 solver.cpp:228] Iteration 18170, loss = 0.352621
I0905 04:54:53.315363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35262 (* 1 = 0.35262 loss)
I0905 04:54:53.315376 90901 sgd_solver.cpp:106] Iteration 18170, lr = 0.1
I0905 04:54:59.390787 90901 solver.cpp:228] Iteration 18180, loss = 0.55647
I0905 04:54:59.390839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55647 (* 1 = 0.55647 loss)
I0905 04:54:59.390852 90901 sgd_solver.cpp:106] Iteration 18180, lr = 0.1
I0905 04:55:05.154381 90901 solver.cpp:228] Iteration 18190, loss = 0.203115
I0905 04:55:05.154435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203115 (* 1 = 0.203115 loss)
I0905 04:55:05.154449 90901 sgd_solver.cpp:106] Iteration 18190, lr = 0.1
I0905 04:55:11.572464 90901 solver.cpp:228] Iteration 18200, loss = 0.30842
I0905 04:55:11.572656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308419 (* 1 = 0.308419 loss)
I0905 04:55:11.572674 90901 sgd_solver.cpp:106] Iteration 18200, lr = 0.1
I0905 04:55:17.632438 90901 solver.cpp:228] Iteration 18210, loss = 0.417865
I0905 04:55:17.632482 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417865 (* 1 = 0.417865 loss)
I0905 04:55:17.632494 90901 sgd_solver.cpp:106] Iteration 18210, lr = 0.1
I0905 04:55:23.657219 90901 solver.cpp:228] Iteration 18220, loss = 0.335562
I0905 04:55:23.657270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335562 (* 1 = 0.335562 loss)
I0905 04:55:23.657284 90901 sgd_solver.cpp:106] Iteration 18220, lr = 0.1
I0905 04:55:29.742053 90901 solver.cpp:228] Iteration 18230, loss = 0.442997
I0905 04:55:29.742099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442996 (* 1 = 0.442996 loss)
I0905 04:55:29.742110 90901 sgd_solver.cpp:106] Iteration 18230, lr = 0.1
I0905 04:55:35.819730 90901 solver.cpp:228] Iteration 18240, loss = 0.492136
I0905 04:55:35.819777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492135 (* 1 = 0.492135 loss)
I0905 04:55:35.819790 90901 sgd_solver.cpp:106] Iteration 18240, lr = 0.1
I0905 04:55:41.879916 90901 solver.cpp:228] Iteration 18250, loss = 0.697886
I0905 04:55:41.880092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.697886 (* 1 = 0.697886 loss)
I0905 04:55:41.880125 90901 sgd_solver.cpp:106] Iteration 18250, lr = 0.1
I0905 04:55:47.627959 90901 solver.cpp:228] Iteration 18260, loss = 0.362715
I0905 04:55:47.628003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362715 (* 1 = 0.362715 loss)
I0905 04:55:47.628016 90901 sgd_solver.cpp:106] Iteration 18260, lr = 0.1
I0905 04:55:53.977458 90901 solver.cpp:228] Iteration 18270, loss = 0.498189
I0905 04:55:53.977510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498189 (* 1 = 0.498189 loss)
I0905 04:55:53.977524 90901 sgd_solver.cpp:106] Iteration 18270, lr = 0.1
I0905 04:56:00.077201 90901 solver.cpp:228] Iteration 18280, loss = 0.344137
I0905 04:56:00.077249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344137 (* 1 = 0.344137 loss)
I0905 04:56:00.077262 90901 sgd_solver.cpp:106] Iteration 18280, lr = 0.1
I0905 04:56:06.510041 90901 solver.cpp:228] Iteration 18290, loss = 0.478907
I0905 04:56:06.510094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478906 (* 1 = 0.478906 loss)
I0905 04:56:06.510109 90901 sgd_solver.cpp:106] Iteration 18290, lr = 0.1
I0905 04:56:12.359681 90901 solver.cpp:228] Iteration 18300, loss = 0.398968
I0905 04:56:12.359841 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398968 (* 1 = 0.398968 loss)
I0905 04:56:12.359863 90901 sgd_solver.cpp:106] Iteration 18300, lr = 0.1
I0905 04:56:18.525434 90901 solver.cpp:228] Iteration 18310, loss = 0.328577
I0905 04:56:18.525480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328576 (* 1 = 0.328576 loss)
I0905 04:56:18.525492 90901 sgd_solver.cpp:106] Iteration 18310, lr = 0.1
I0905 04:56:23.789705 90901 solver.cpp:228] Iteration 18320, loss = 0.29643
I0905 04:56:23.789752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296429 (* 1 = 0.296429 loss)
I0905 04:56:23.789769 90901 sgd_solver.cpp:106] Iteration 18320, lr = 0.1
I0905 04:56:29.562830 90901 solver.cpp:228] Iteration 18330, loss = 0.394111
I0905 04:56:29.562919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394111 (* 1 = 0.394111 loss)
I0905 04:56:29.562958 90901 sgd_solver.cpp:106] Iteration 18330, lr = 0.1
I0905 04:56:35.605337 90901 solver.cpp:228] Iteration 18340, loss = 0.263092
I0905 04:56:35.605391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263092 (* 1 = 0.263092 loss)
I0905 04:56:35.605404 90901 sgd_solver.cpp:106] Iteration 18340, lr = 0.1
I0905 04:56:41.403230 90901 solver.cpp:228] Iteration 18350, loss = 0.188367
I0905 04:56:41.403277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188366 (* 1 = 0.188366 loss)
I0905 04:56:41.403291 90901 sgd_solver.cpp:106] Iteration 18350, lr = 0.1
I0905 04:56:47.453025 90901 solver.cpp:228] Iteration 18360, loss = 0.269033
I0905 04:56:47.453219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269033 (* 1 = 0.269033 loss)
I0905 04:56:47.453246 90901 sgd_solver.cpp:106] Iteration 18360, lr = 0.1
I0905 04:56:53.515475 90901 solver.cpp:228] Iteration 18370, loss = 0.224669
I0905 04:56:53.515519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224669 (* 1 = 0.224669 loss)
I0905 04:56:53.515532 90901 sgd_solver.cpp:106] Iteration 18370, lr = 0.1
I0905 04:56:59.251350 90901 solver.cpp:228] Iteration 18380, loss = 0.376726
I0905 04:56:59.251404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376726 (* 1 = 0.376726 loss)
I0905 04:56:59.251418 90901 sgd_solver.cpp:106] Iteration 18380, lr = 0.1
I0905 04:57:05.670868 90901 solver.cpp:228] Iteration 18390, loss = 0.505014
I0905 04:57:05.670912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505014 (* 1 = 0.505014 loss)
I0905 04:57:05.670924 90901 sgd_solver.cpp:106] Iteration 18390, lr = 0.1
I0905 04:57:11.522725 90901 solver.cpp:337] Iteration 18400, Testing net (#0)
I0905 04:57:53.963086 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.8325
I0905 04:57:53.963215 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.383399 (* 1 = 0.383399 loss)
I0905 04:57:54.179868 90901 solver.cpp:228] Iteration 18400, loss = 0.405635
I0905 04:57:54.179894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.405634 (* 1 = 0.405634 loss)
I0905 04:57:54.179909 90901 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0905 04:58:00.266054 90901 solver.cpp:228] Iteration 18410, loss = 0.51034
I0905 04:58:00.266103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.51034 (* 1 = 0.51034 loss)
I0905 04:58:00.266119 90901 sgd_solver.cpp:106] Iteration 18410, lr = 0.1
I0905 04:58:06.117254 90901 solver.cpp:228] Iteration 18420, loss = 0.151857
I0905 04:58:06.117300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151857 (* 1 = 0.151857 loss)
I0905 04:58:06.117312 90901 sgd_solver.cpp:106] Iteration 18420, lr = 0.1
I0905 04:58:11.668416 90901 solver.cpp:228] Iteration 18430, loss = 0.64255
I0905 04:58:11.668469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64255 (* 1 = 0.64255 loss)
I0905 04:58:11.668483 90901 sgd_solver.cpp:106] Iteration 18430, lr = 0.1
I0905 04:58:17.513458 90901 solver.cpp:228] Iteration 18440, loss = 0.369577
I0905 04:58:17.513504 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369577 (* 1 = 0.369577 loss)
I0905 04:58:17.513520 90901 sgd_solver.cpp:106] Iteration 18440, lr = 0.1
I0905 04:58:23.270807 90901 solver.cpp:228] Iteration 18450, loss = 0.194595
I0905 04:58:23.270858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194595 (* 1 = 0.194595 loss)
I0905 04:58:23.270870 90901 sgd_solver.cpp:106] Iteration 18450, lr = 0.1
I0905 04:58:29.349722 90901 solver.cpp:228] Iteration 18460, loss = 0.366206
I0905 04:58:29.349864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366206 (* 1 = 0.366206 loss)
I0905 04:58:29.349915 90901 sgd_solver.cpp:106] Iteration 18460, lr = 0.1
I0905 04:58:35.397929 90901 solver.cpp:228] Iteration 18470, loss = 0.316063
I0905 04:58:35.397976 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316063 (* 1 = 0.316063 loss)
I0905 04:58:35.397989 90901 sgd_solver.cpp:106] Iteration 18470, lr = 0.1
I0905 04:58:41.516396 90901 solver.cpp:228] Iteration 18480, loss = 0.213001
I0905 04:58:41.516453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213001 (* 1 = 0.213001 loss)
I0905 04:58:41.516469 90901 sgd_solver.cpp:106] Iteration 18480, lr = 0.1
I0905 04:58:47.602259 90901 solver.cpp:228] Iteration 18490, loss = 0.383625
I0905 04:58:47.602306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383625 (* 1 = 0.383625 loss)
I0905 04:58:47.602320 90901 sgd_solver.cpp:106] Iteration 18490, lr = 0.1
I0905 04:58:53.971735 90901 solver.cpp:228] Iteration 18500, loss = 0.173346
I0905 04:58:53.971786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173346 (* 1 = 0.173346 loss)
I0905 04:58:53.971804 90901 sgd_solver.cpp:106] Iteration 18500, lr = 0.1
I0905 04:59:00.064404 90901 solver.cpp:228] Iteration 18510, loss = 0.557677
I0905 04:59:00.064621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.557676 (* 1 = 0.557676 loss)
I0905 04:59:00.064640 90901 sgd_solver.cpp:106] Iteration 18510, lr = 0.1
I0905 04:59:06.140666 90901 solver.cpp:228] Iteration 18520, loss = 0.225219
I0905 04:59:06.140705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225219 (* 1 = 0.225219 loss)
I0905 04:59:06.140719 90901 sgd_solver.cpp:106] Iteration 18520, lr = 0.1
I0905 04:59:12.185029 90901 solver.cpp:228] Iteration 18530, loss = 0.692743
I0905 04:59:12.185075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.692743 (* 1 = 0.692743 loss)
I0905 04:59:12.185088 90901 sgd_solver.cpp:106] Iteration 18530, lr = 0.1
I0905 04:59:18.242875 90901 solver.cpp:228] Iteration 18540, loss = 0.365044
I0905 04:59:18.242919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365044 (* 1 = 0.365044 loss)
I0905 04:59:18.242933 90901 sgd_solver.cpp:106] Iteration 18540, lr = 0.1
I0905 04:59:24.320741 90901 solver.cpp:228] Iteration 18550, loss = 0.313447
I0905 04:59:24.320792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313447 (* 1 = 0.313447 loss)
I0905 04:59:24.320807 90901 sgd_solver.cpp:106] Iteration 18550, lr = 0.1
I0905 04:59:30.431516 90901 solver.cpp:228] Iteration 18560, loss = 0.142121
I0905 04:59:30.431687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142121 (* 1 = 0.142121 loss)
I0905 04:59:30.431727 90901 sgd_solver.cpp:106] Iteration 18560, lr = 0.1
I0905 04:59:36.393712 90901 solver.cpp:228] Iteration 18570, loss = 0.295452
I0905 04:59:36.393759 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295451 (* 1 = 0.295451 loss)
I0905 04:59:36.393772 90901 sgd_solver.cpp:106] Iteration 18570, lr = 0.1
I0905 04:59:42.465524 90901 solver.cpp:228] Iteration 18580, loss = 0.250867
I0905 04:59:42.465577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250867 (* 1 = 0.250867 loss)
I0905 04:59:42.465593 90901 sgd_solver.cpp:106] Iteration 18580, lr = 0.1
I0905 04:59:48.489137 90901 solver.cpp:228] Iteration 18590, loss = 0.224874
I0905 04:59:48.489195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224874 (* 1 = 0.224874 loss)
I0905 04:59:48.489210 90901 sgd_solver.cpp:106] Iteration 18590, lr = 0.1
I0905 04:59:54.328260 90901 solver.cpp:228] Iteration 18600, loss = 0.27263
I0905 04:59:54.328321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27263 (* 1 = 0.27263 loss)
I0905 04:59:54.328337 90901 sgd_solver.cpp:106] Iteration 18600, lr = 0.1
I0905 04:59:59.591629 90901 solver.cpp:228] Iteration 18610, loss = 0.220708
I0905 04:59:59.591692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220707 (* 1 = 0.220707 loss)
I0905 04:59:59.591711 90901 sgd_solver.cpp:106] Iteration 18610, lr = 0.1
I0905 05:00:05.539288 90901 solver.cpp:228] Iteration 18620, loss = 0.350539
I0905 05:00:05.539448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350538 (* 1 = 0.350538 loss)
I0905 05:00:05.539494 90901 sgd_solver.cpp:106] Iteration 18620, lr = 0.1
I0905 05:00:11.591620 90901 solver.cpp:228] Iteration 18630, loss = 0.241908
I0905 05:00:11.591677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241907 (* 1 = 0.241907 loss)
I0905 05:00:11.591693 90901 sgd_solver.cpp:106] Iteration 18630, lr = 0.1
I0905 05:00:17.970487 90901 solver.cpp:228] Iteration 18640, loss = 0.173448
I0905 05:00:17.970530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173448 (* 1 = 0.173448 loss)
I0905 05:00:17.970543 90901 sgd_solver.cpp:106] Iteration 18640, lr = 0.1
I0905 05:00:23.921802 90901 solver.cpp:228] Iteration 18650, loss = 0.435969
I0905 05:00:23.921854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435969 (* 1 = 0.435969 loss)
I0905 05:00:23.921867 90901 sgd_solver.cpp:106] Iteration 18650, lr = 0.1
I0905 05:00:30.126721 90901 solver.cpp:228] Iteration 18660, loss = 0.637175
I0905 05:00:30.126771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.637175 (* 1 = 0.637175 loss)
I0905 05:00:30.126783 90901 sgd_solver.cpp:106] Iteration 18660, lr = 0.1
I0905 05:00:36.197962 90901 solver.cpp:228] Iteration 18670, loss = 1.08835
I0905 05:00:36.198165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.08835 (* 1 = 1.08835 loss)
I0905 05:00:36.198180 90901 sgd_solver.cpp:106] Iteration 18670, lr = 0.1
I0905 05:00:42.623304 90901 solver.cpp:228] Iteration 18680, loss = 0.704341
I0905 05:00:42.623353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.70434 (* 1 = 0.70434 loss)
I0905 05:00:42.623368 90901 sgd_solver.cpp:106] Iteration 18680, lr = 0.1
I0905 05:00:48.674484 90901 solver.cpp:228] Iteration 18690, loss = 0.415586
I0905 05:00:48.674535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415585 (* 1 = 0.415585 loss)
I0905 05:00:48.674548 90901 sgd_solver.cpp:106] Iteration 18690, lr = 0.1
I0905 05:00:54.727231 90901 solver.cpp:228] Iteration 18700, loss = 0.348037
I0905 05:00:54.727298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348037 (* 1 = 0.348037 loss)
I0905 05:00:54.727314 90901 sgd_solver.cpp:106] Iteration 18700, lr = 0.1
I0905 05:01:00.770380 90901 solver.cpp:228] Iteration 18710, loss = 0.310771
I0905 05:01:00.770442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31077 (* 1 = 0.31077 loss)
I0905 05:01:00.770457 90901 sgd_solver.cpp:106] Iteration 18710, lr = 0.1
I0905 05:01:06.809084 90901 solver.cpp:228] Iteration 18720, loss = 0.348423
I0905 05:01:06.809272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348422 (* 1 = 0.348422 loss)
I0905 05:01:06.809298 90901 sgd_solver.cpp:106] Iteration 18720, lr = 0.1
I0905 05:01:13.175823 90901 solver.cpp:228] Iteration 18730, loss = 0.108601
I0905 05:01:13.175892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108601 (* 1 = 0.108601 loss)
I0905 05:01:13.175907 90901 sgd_solver.cpp:106] Iteration 18730, lr = 0.1
I0905 05:01:19.535763 90901 solver.cpp:228] Iteration 18740, loss = 0.412291
I0905 05:01:19.535809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412291 (* 1 = 0.412291 loss)
I0905 05:01:19.535823 90901 sgd_solver.cpp:106] Iteration 18740, lr = 0.1
I0905 05:01:25.622448 90901 solver.cpp:228] Iteration 18750, loss = 0.688865
I0905 05:01:25.622512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.688865 (* 1 = 0.688865 loss)
I0905 05:01:25.622526 90901 sgd_solver.cpp:106] Iteration 18750, lr = 0.1
I0905 05:01:31.709261 90901 solver.cpp:228] Iteration 18760, loss = 0.354458
I0905 05:01:31.709321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354457 (* 1 = 0.354457 loss)
I0905 05:01:31.709336 90901 sgd_solver.cpp:106] Iteration 18760, lr = 0.1
I0905 05:01:37.780493 90901 solver.cpp:228] Iteration 18770, loss = 0.397163
I0905 05:01:37.780656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397163 (* 1 = 0.397163 loss)
I0905 05:01:37.780680 90901 sgd_solver.cpp:106] Iteration 18770, lr = 0.1
I0905 05:01:43.237017 90901 solver.cpp:228] Iteration 18780, loss = 0.122628
I0905 05:01:43.237064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122628 (* 1 = 0.122628 loss)
I0905 05:01:43.237077 90901 sgd_solver.cpp:106] Iteration 18780, lr = 0.1
I0905 05:01:48.797087 90901 solver.cpp:228] Iteration 18790, loss = 0.239141
I0905 05:01:48.797149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23914 (* 1 = 0.23914 loss)
I0905 05:01:48.797163 90901 sgd_solver.cpp:106] Iteration 18790, lr = 0.1
I0905 05:01:54.717438 90901 solver.cpp:228] Iteration 18800, loss = 0.338973
I0905 05:01:54.717483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338972 (* 1 = 0.338972 loss)
I0905 05:01:54.717494 90901 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0905 05:02:00.815554 90901 solver.cpp:228] Iteration 18810, loss = 0.388897
I0905 05:02:00.815611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388897 (* 1 = 0.388897 loss)
I0905 05:02:00.815625 90901 sgd_solver.cpp:106] Iteration 18810, lr = 0.1
I0905 05:02:06.877336 90901 solver.cpp:228] Iteration 18820, loss = 0.303992
I0905 05:02:06.877396 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303992 (* 1 = 0.303992 loss)
I0905 05:02:06.877411 90901 sgd_solver.cpp:106] Iteration 18820, lr = 0.1
I0905 05:02:12.930888 90901 solver.cpp:228] Iteration 18830, loss = 0.194257
I0905 05:02:12.931162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194257 (* 1 = 0.194257 loss)
I0905 05:02:12.931177 90901 sgd_solver.cpp:106] Iteration 18830, lr = 0.1
I0905 05:02:19.323084 90901 solver.cpp:228] Iteration 18840, loss = 0.171076
I0905 05:02:19.323156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171076 (* 1 = 0.171076 loss)
I0905 05:02:19.323171 90901 sgd_solver.cpp:106] Iteration 18840, lr = 0.1
I0905 05:02:25.381603 90901 solver.cpp:228] Iteration 18850, loss = 0.316577
I0905 05:02:25.381675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316577 (* 1 = 0.316577 loss)
I0905 05:02:25.381697 90901 sgd_solver.cpp:106] Iteration 18850, lr = 0.1
I0905 05:02:31.473148 90901 solver.cpp:228] Iteration 18860, loss = 0.118312
I0905 05:02:31.473192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118312 (* 1 = 0.118312 loss)
I0905 05:02:31.473206 90901 sgd_solver.cpp:106] Iteration 18860, lr = 0.1
I0905 05:02:37.846992 90901 solver.cpp:228] Iteration 18870, loss = 0.184401
I0905 05:02:37.847034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184401 (* 1 = 0.184401 loss)
I0905 05:02:37.847048 90901 sgd_solver.cpp:106] Iteration 18870, lr = 0.1
I0905 05:02:43.938264 90901 solver.cpp:228] Iteration 18880, loss = 0.215899
I0905 05:02:43.938467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215898 (* 1 = 0.215898 loss)
I0905 05:02:43.938506 90901 sgd_solver.cpp:106] Iteration 18880, lr = 0.1
I0905 05:02:50.006389 90901 solver.cpp:228] Iteration 18890, loss = 0.273391
I0905 05:02:50.006446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273391 (* 1 = 0.273391 loss)
I0905 05:02:50.006460 90901 sgd_solver.cpp:106] Iteration 18890, lr = 0.1
I0905 05:02:56.062165 90901 solver.cpp:228] Iteration 18900, loss = 0.315887
I0905 05:02:56.062227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315887 (* 1 = 0.315887 loss)
I0905 05:02:56.062242 90901 sgd_solver.cpp:106] Iteration 18900, lr = 0.1
I0905 05:03:02.168622 90901 solver.cpp:228] Iteration 18910, loss = 0.299337
I0905 05:03:02.168692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299336 (* 1 = 0.299336 loss)
I0905 05:03:02.168709 90901 sgd_solver.cpp:106] Iteration 18910, lr = 0.1
I0905 05:03:08.211513 90901 solver.cpp:228] Iteration 18920, loss = 0.482685
I0905 05:03:08.211570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482685 (* 1 = 0.482685 loss)
I0905 05:03:08.211585 90901 sgd_solver.cpp:106] Iteration 18920, lr = 0.1
I0905 05:03:14.562082 90901 solver.cpp:228] Iteration 18930, loss = 0.246031
I0905 05:03:14.562247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246031 (* 1 = 0.246031 loss)
I0905 05:03:14.562283 90901 sgd_solver.cpp:106] Iteration 18930, lr = 0.1
I0905 05:03:20.657441 90901 solver.cpp:228] Iteration 18940, loss = 0.291521
I0905 05:03:20.657505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29152 (* 1 = 0.29152 loss)
I0905 05:03:20.657521 90901 sgd_solver.cpp:106] Iteration 18940, lr = 0.1
I0905 05:03:26.708462 90901 solver.cpp:228] Iteration 18950, loss = 0.592811
I0905 05:03:26.708506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.592811 (* 1 = 0.592811 loss)
I0905 05:03:26.708519 90901 sgd_solver.cpp:106] Iteration 18950, lr = 0.1
I0905 05:03:32.400876 90901 solver.cpp:228] Iteration 18960, loss = 0.384857
I0905 05:03:32.400925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384857 (* 1 = 0.384857 loss)
I0905 05:03:32.400938 90901 sgd_solver.cpp:106] Iteration 18960, lr = 0.1
I0905 05:03:37.378893 90901 solver.cpp:228] Iteration 18970, loss = 0.323182
I0905 05:03:37.378942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323181 (* 1 = 0.323181 loss)
I0905 05:03:37.378957 90901 sgd_solver.cpp:106] Iteration 18970, lr = 0.1
I0905 05:03:43.744601 90901 solver.cpp:228] Iteration 18980, loss = 0.362854
I0905 05:03:43.744665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362854 (* 1 = 0.362854 loss)
I0905 05:03:43.744683 90901 sgd_solver.cpp:106] Iteration 18980, lr = 0.1
I0905 05:03:49.527302 90901 solver.cpp:228] Iteration 18990, loss = 0.66579
I0905 05:03:49.527565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.66579 (* 1 = 0.66579 loss)
I0905 05:03:49.527601 90901 sgd_solver.cpp:106] Iteration 18990, lr = 0.1
I0905 05:03:55.935662 90901 solver.cpp:228] Iteration 19000, loss = 0.412587
I0905 05:03:55.935704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412586 (* 1 = 0.412586 loss)
I0905 05:03:55.935742 90901 sgd_solver.cpp:106] Iteration 19000, lr = 0.1
I0905 05:04:01.979310 90901 solver.cpp:228] Iteration 19010, loss = 0.216324
I0905 05:04:01.979380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216324 (* 1 = 0.216324 loss)
I0905 05:04:01.979396 90901 sgd_solver.cpp:106] Iteration 19010, lr = 0.1
I0905 05:04:07.982800 90901 solver.cpp:228] Iteration 19020, loss = 0.22925
I0905 05:04:07.982852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229249 (* 1 = 0.229249 loss)
I0905 05:04:07.982867 90901 sgd_solver.cpp:106] Iteration 19020, lr = 0.1
I0905 05:04:14.389387 90901 solver.cpp:228] Iteration 19030, loss = 0.409791
I0905 05:04:14.389431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409791 (* 1 = 0.409791 loss)
I0905 05:04:14.389443 90901 sgd_solver.cpp:106] Iteration 19030, lr = 0.1
I0905 05:04:20.421139 90901 solver.cpp:228] Iteration 19040, loss = 0.369095
I0905 05:04:20.423228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369095 (* 1 = 0.369095 loss)
I0905 05:04:20.423247 90901 sgd_solver.cpp:106] Iteration 19040, lr = 0.1
I0905 05:04:26.485712 90901 solver.cpp:228] Iteration 19050, loss = 0.381417
I0905 05:04:26.485755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381417 (* 1 = 0.381417 loss)
I0905 05:04:26.485767 90901 sgd_solver.cpp:106] Iteration 19050, lr = 0.1
I0905 05:04:32.556011 90901 solver.cpp:228] Iteration 19060, loss = 0.490578
I0905 05:04:32.556077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490578 (* 1 = 0.490578 loss)
I0905 05:04:32.556092 90901 sgd_solver.cpp:106] Iteration 19060, lr = 0.1
I0905 05:04:38.611297 90901 solver.cpp:228] Iteration 19070, loss = 0.24573
I0905 05:04:38.611356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245729 (* 1 = 0.245729 loss)
I0905 05:04:38.611371 90901 sgd_solver.cpp:106] Iteration 19070, lr = 0.1
I0905 05:04:44.930754 90901 solver.cpp:228] Iteration 19080, loss = 0.191646
I0905 05:04:44.930799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191646 (* 1 = 0.191646 loss)
I0905 05:04:44.930809 90901 sgd_solver.cpp:106] Iteration 19080, lr = 0.1
I0905 05:04:50.478813 90901 solver.cpp:228] Iteration 19090, loss = 0.140509
I0905 05:04:50.479002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140509 (* 1 = 0.140509 loss)
I0905 05:04:50.479048 90901 sgd_solver.cpp:106] Iteration 19090, lr = 0.1
I0905 05:04:56.875398 90901 solver.cpp:228] Iteration 19100, loss = 0.440982
I0905 05:04:56.875445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440982 (* 1 = 0.440982 loss)
I0905 05:04:56.875459 90901 sgd_solver.cpp:106] Iteration 19100, lr = 0.1
I0905 05:05:03.258563 90901 solver.cpp:228] Iteration 19110, loss = 0.227992
I0905 05:05:03.258617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227991 (* 1 = 0.227991 loss)
I0905 05:05:03.258635 90901 sgd_solver.cpp:106] Iteration 19110, lr = 0.1
I0905 05:05:09.294857 90901 solver.cpp:228] Iteration 19120, loss = 0.45203
I0905 05:05:09.294934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45203 (* 1 = 0.45203 loss)
I0905 05:05:09.294951 90901 sgd_solver.cpp:106] Iteration 19120, lr = 0.1
I0905 05:05:15.359624 90901 solver.cpp:228] Iteration 19130, loss = 0.386993
I0905 05:05:15.359670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386993 (* 1 = 0.386993 loss)
I0905 05:05:15.359683 90901 sgd_solver.cpp:106] Iteration 19130, lr = 0.1
I0905 05:05:20.925675 90901 solver.cpp:228] Iteration 19140, loss = 0.213958
I0905 05:05:20.925873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213958 (* 1 = 0.213958 loss)
I0905 05:05:20.925887 90901 sgd_solver.cpp:106] Iteration 19140, lr = 0.1
I0905 05:05:26.272974 90901 solver.cpp:228] Iteration 19150, loss = 0.194604
I0905 05:05:26.273020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194603 (* 1 = 0.194603 loss)
I0905 05:05:26.273031 90901 sgd_solver.cpp:106] Iteration 19150, lr = 0.1
I0905 05:05:32.031837 90901 solver.cpp:228] Iteration 19160, loss = 0.383969
I0905 05:05:32.031893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383969 (* 1 = 0.383969 loss)
I0905 05:05:32.031906 90901 sgd_solver.cpp:106] Iteration 19160, lr = 0.1
I0905 05:05:38.436033 90901 solver.cpp:228] Iteration 19170, loss = 0.562639
I0905 05:05:38.436086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.562639 (* 1 = 0.562639 loss)
I0905 05:05:38.436103 90901 sgd_solver.cpp:106] Iteration 19170, lr = 0.1
I0905 05:05:44.462581 90901 solver.cpp:228] Iteration 19180, loss = 0.148369
I0905 05:05:44.462666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148369 (* 1 = 0.148369 loss)
I0905 05:05:44.462690 90901 sgd_solver.cpp:106] Iteration 19180, lr = 0.1
I0905 05:05:50.523092 90901 solver.cpp:228] Iteration 19190, loss = 0.345263
I0905 05:05:50.523133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345263 (* 1 = 0.345263 loss)
I0905 05:05:50.523145 90901 sgd_solver.cpp:106] Iteration 19190, lr = 0.1
I0905 05:05:56.379967 90901 solver.cpp:337] Iteration 19200, Testing net (#0)
I0905 05:06:38.805377 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.616875
I0905 05:06:38.805563 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.959478 (* 1 = 0.959478 loss)
I0905 05:06:39.023340 90901 solver.cpp:228] Iteration 19200, loss = 0.0966364
I0905 05:06:39.023406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0966361 (* 1 = 0.0966361 loss)
I0905 05:06:39.023427 90901 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0905 05:06:45.414137 90901 solver.cpp:228] Iteration 19210, loss = 0.171345
I0905 05:06:45.414194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171345 (* 1 = 0.171345 loss)
I0905 05:06:45.414209 90901 sgd_solver.cpp:106] Iteration 19210, lr = 0.1
I0905 05:06:51.493623 90901 solver.cpp:228] Iteration 19220, loss = 0.903242
I0905 05:06:51.493665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.903242 (* 1 = 0.903242 loss)
I0905 05:06:51.493679 90901 sgd_solver.cpp:106] Iteration 19220, lr = 0.1
I0905 05:06:57.538969 90901 solver.cpp:228] Iteration 19230, loss = 0.284159
I0905 05:06:57.539036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284159 (* 1 = 0.284159 loss)
I0905 05:06:57.539050 90901 sgd_solver.cpp:106] Iteration 19230, lr = 0.1
I0905 05:07:03.603417 90901 solver.cpp:228] Iteration 19240, loss = 0.138553
I0905 05:07:03.603478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138553 (* 1 = 0.138553 loss)
I0905 05:07:03.603494 90901 sgd_solver.cpp:106] Iteration 19240, lr = 0.1
I0905 05:07:08.898811 90901 solver.cpp:228] Iteration 19250, loss = 0.284315
I0905 05:07:08.899008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284315 (* 1 = 0.284315 loss)
I0905 05:07:08.899040 90901 sgd_solver.cpp:106] Iteration 19250, lr = 0.1
I0905 05:07:14.326602 90901 solver.cpp:228] Iteration 19260, loss = 0.280833
I0905 05:07:14.326706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280833 (* 1 = 0.280833 loss)
I0905 05:07:14.326758 90901 sgd_solver.cpp:106] Iteration 19260, lr = 0.1
I0905 05:07:20.666807 90901 solver.cpp:228] Iteration 19270, loss = 0.143569
I0905 05:07:20.666859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143569 (* 1 = 0.143569 loss)
I0905 05:07:20.666873 90901 sgd_solver.cpp:106] Iteration 19270, lr = 0.1
I0905 05:07:26.435214 90901 solver.cpp:228] Iteration 19280, loss = 0.487633
I0905 05:07:26.435276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487632 (* 1 = 0.487632 loss)
I0905 05:07:26.435292 90901 sgd_solver.cpp:106] Iteration 19280, lr = 0.1
I0905 05:07:32.458178 90901 solver.cpp:228] Iteration 19290, loss = 0.3526
I0905 05:07:32.458223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3526 (* 1 = 0.3526 loss)
I0905 05:07:32.458237 90901 sgd_solver.cpp:106] Iteration 19290, lr = 0.1
I0905 05:07:38.794149 90901 solver.cpp:228] Iteration 19300, loss = 0.313492
I0905 05:07:38.794229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313492 (* 1 = 0.313492 loss)
I0905 05:07:38.794247 90901 sgd_solver.cpp:106] Iteration 19300, lr = 0.1
I0905 05:07:44.867678 90901 solver.cpp:228] Iteration 19310, loss = 0.167545
I0905 05:07:44.867877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167545 (* 1 = 0.167545 loss)
I0905 05:07:44.867904 90901 sgd_solver.cpp:106] Iteration 19310, lr = 0.1
I0905 05:07:50.675159 90901 solver.cpp:228] Iteration 19320, loss = 0.223209
I0905 05:07:50.675202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223209 (* 1 = 0.223209 loss)
I0905 05:07:50.675216 90901 sgd_solver.cpp:106] Iteration 19320, lr = 0.1
I0905 05:07:56.774636 90901 solver.cpp:228] Iteration 19330, loss = 0.440504
I0905 05:07:56.774718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440504 (* 1 = 0.440504 loss)
I0905 05:07:56.774734 90901 sgd_solver.cpp:106] Iteration 19330, lr = 0.1
I0905 05:08:02.867128 90901 solver.cpp:228] Iteration 19340, loss = 0.246297
I0905 05:08:02.867193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246296 (* 1 = 0.246296 loss)
I0905 05:08:02.867208 90901 sgd_solver.cpp:106] Iteration 19340, lr = 0.1
I0905 05:08:09.091358 90901 solver.cpp:228] Iteration 19350, loss = 0.410691
I0905 05:08:09.091418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410691 (* 1 = 0.410691 loss)
I0905 05:08:09.091431 90901 sgd_solver.cpp:106] Iteration 19350, lr = 0.1
I0905 05:08:15.331082 90901 solver.cpp:228] Iteration 19360, loss = 0.481255
I0905 05:08:15.331282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.481255 (* 1 = 0.481255 loss)
I0905 05:08:15.331300 90901 sgd_solver.cpp:106] Iteration 19360, lr = 0.1
I0905 05:08:21.373471 90901 solver.cpp:228] Iteration 19370, loss = 0.606234
I0905 05:08:21.373543 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.606234 (* 1 = 0.606234 loss)
I0905 05:08:21.373559 90901 sgd_solver.cpp:106] Iteration 19370, lr = 0.1
I0905 05:08:27.482599 90901 solver.cpp:228] Iteration 19380, loss = 0.220062
I0905 05:08:27.482709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220061 (* 1 = 0.220061 loss)
I0905 05:08:27.482728 90901 sgd_solver.cpp:106] Iteration 19380, lr = 0.1
I0905 05:08:33.601162 90901 solver.cpp:228] Iteration 19390, loss = 0.335992
I0905 05:08:33.601224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335991 (* 1 = 0.335991 loss)
I0905 05:08:33.601239 90901 sgd_solver.cpp:106] Iteration 19390, lr = 0.1
I0905 05:08:39.679368 90901 solver.cpp:228] Iteration 19400, loss = 0.486038
I0905 05:08:39.679425 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486038 (* 1 = 0.486038 loss)
I0905 05:08:39.679440 90901 sgd_solver.cpp:106] Iteration 19400, lr = 0.1
I0905 05:08:45.744565 90901 solver.cpp:228] Iteration 19410, loss = 0.133067
I0905 05:08:45.744808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133067 (* 1 = 0.133067 loss)
I0905 05:08:45.744827 90901 sgd_solver.cpp:106] Iteration 19410, lr = 0.1
I0905 05:08:51.612964 90901 solver.cpp:228] Iteration 19420, loss = 0.362519
I0905 05:08:51.613008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362519 (* 1 = 0.362519 loss)
I0905 05:08:51.613019 90901 sgd_solver.cpp:106] Iteration 19420, lr = 0.1
I0905 05:08:57.154382 90901 solver.cpp:228] Iteration 19430, loss = 0.297345
I0905 05:08:57.154464 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297344 (* 1 = 0.297344 loss)
I0905 05:08:57.154487 90901 sgd_solver.cpp:106] Iteration 19430, lr = 0.1
I0905 05:09:03.058559 90901 solver.cpp:228] Iteration 19440, loss = 0.302175
I0905 05:09:03.058614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302175 (* 1 = 0.302175 loss)
I0905 05:09:03.058632 90901 sgd_solver.cpp:106] Iteration 19440, lr = 0.1
I0905 05:09:09.134308 90901 solver.cpp:228] Iteration 19450, loss = 0.237119
I0905 05:09:09.134371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237118 (* 1 = 0.237118 loss)
I0905 05:09:09.134385 90901 sgd_solver.cpp:106] Iteration 19450, lr = 0.1
I0905 05:09:15.163048 90901 solver.cpp:228] Iteration 19460, loss = 0.285859
I0905 05:09:15.163108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285859 (* 1 = 0.285859 loss)
I0905 05:09:15.163122 90901 sgd_solver.cpp:106] Iteration 19460, lr = 0.1
I0905 05:09:21.256639 90901 solver.cpp:228] Iteration 19470, loss = 0.377541
I0905 05:09:21.256824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377541 (* 1 = 0.377541 loss)
I0905 05:09:21.256850 90901 sgd_solver.cpp:106] Iteration 19470, lr = 0.1
I0905 05:09:27.684737 90901 solver.cpp:228] Iteration 19480, loss = 0.357703
I0905 05:09:27.684792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357702 (* 1 = 0.357702 loss)
I0905 05:09:27.684811 90901 sgd_solver.cpp:106] Iteration 19480, lr = 0.1
I0905 05:09:33.731760 90901 solver.cpp:228] Iteration 19490, loss = 0.240429
I0905 05:09:33.731822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240429 (* 1 = 0.240429 loss)
I0905 05:09:33.731837 90901 sgd_solver.cpp:106] Iteration 19490, lr = 0.1
I0905 05:09:40.004508 90901 solver.cpp:228] Iteration 19500, loss = 0.439398
I0905 05:09:40.004577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439397 (* 1 = 0.439397 loss)
I0905 05:09:40.004593 90901 sgd_solver.cpp:106] Iteration 19500, lr = 0.1
I0905 05:09:46.132534 90901 solver.cpp:228] Iteration 19510, loss = 0.33178
I0905 05:09:46.132591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33178 (* 1 = 0.33178 loss)
I0905 05:09:46.132608 90901 sgd_solver.cpp:106] Iteration 19510, lr = 0.1
I0905 05:09:52.195719 90901 solver.cpp:228] Iteration 19520, loss = 0.341423
I0905 05:09:52.195993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341423 (* 1 = 0.341423 loss)
I0905 05:09:52.196012 90901 sgd_solver.cpp:106] Iteration 19520, lr = 0.1
I0905 05:09:58.266382 90901 solver.cpp:228] Iteration 19530, loss = 0.873935
I0905 05:09:58.266458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.873934 (* 1 = 0.873934 loss)
I0905 05:09:58.266476 90901 sgd_solver.cpp:106] Iteration 19530, lr = 0.1
I0905 05:10:04.451448 90901 solver.cpp:228] Iteration 19540, loss = 0.294399
I0905 05:10:04.451506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294399 (* 1 = 0.294399 loss)
I0905 05:10:04.451520 90901 sgd_solver.cpp:106] Iteration 19540, lr = 0.1
I0905 05:10:10.737547 90901 solver.cpp:228] Iteration 19550, loss = 0.298526
I0905 05:10:10.737612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298526 (* 1 = 0.298526 loss)
I0905 05:10:10.737627 90901 sgd_solver.cpp:106] Iteration 19550, lr = 0.1
I0905 05:10:16.816351 90901 solver.cpp:228] Iteration 19560, loss = 0.363357
I0905 05:10:16.816408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363357 (* 1 = 0.363357 loss)
I0905 05:10:16.816423 90901 sgd_solver.cpp:106] Iteration 19560, lr = 0.1
I0905 05:10:23.232509 90901 solver.cpp:228] Iteration 19570, loss = 0.348756
I0905 05:10:23.232763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348756 (* 1 = 0.348756 loss)
I0905 05:10:23.232794 90901 sgd_solver.cpp:106] Iteration 19570, lr = 0.1
I0905 05:10:29.320351 90901 solver.cpp:228] Iteration 19580, loss = 0.335399
I0905 05:10:29.320415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335399 (* 1 = 0.335399 loss)
I0905 05:10:29.320428 90901 sgd_solver.cpp:106] Iteration 19580, lr = 0.1
I0905 05:10:35.216940 90901 solver.cpp:228] Iteration 19590, loss = 0.274891
I0905 05:10:35.217005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27489 (* 1 = 0.27489 loss)
I0905 05:10:35.217020 90901 sgd_solver.cpp:106] Iteration 19590, lr = 0.1
I0905 05:10:41.217916 90901 solver.cpp:228] Iteration 19600, loss = 0.376998
I0905 05:10:41.217968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376998 (* 1 = 0.376998 loss)
I0905 05:10:41.217983 90901 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0905 05:10:46.475662 90901 solver.cpp:228] Iteration 19610, loss = 0.37924
I0905 05:10:46.475733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379239 (* 1 = 0.379239 loss)
I0905 05:10:46.475754 90901 sgd_solver.cpp:106] Iteration 19610, lr = 0.1
I0905 05:10:52.072434 90901 solver.cpp:228] Iteration 19620, loss = 0.367412
I0905 05:10:52.072494 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367411 (* 1 = 0.367411 loss)
I0905 05:10:52.072509 90901 sgd_solver.cpp:106] Iteration 19620, lr = 0.1
I0905 05:10:58.145813 90901 solver.cpp:228] Iteration 19630, loss = 0.586088
I0905 05:10:58.146044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.586087 (* 1 = 0.586087 loss)
I0905 05:10:58.146062 90901 sgd_solver.cpp:106] Iteration 19630, lr = 0.1
I0905 05:11:03.881012 90901 solver.cpp:228] Iteration 19640, loss = 0.194264
I0905 05:11:03.881078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194264 (* 1 = 0.194264 loss)
I0905 05:11:03.881093 90901 sgd_solver.cpp:106] Iteration 19640, lr = 0.1
I0905 05:11:08.922984 90901 solver.cpp:228] Iteration 19650, loss = 0.2066
I0905 05:11:08.923076 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206599 (* 1 = 0.206599 loss)
I0905 05:11:08.923104 90901 sgd_solver.cpp:106] Iteration 19650, lr = 0.1
I0905 05:11:13.920970 90901 solver.cpp:228] Iteration 19660, loss = 0.299139
I0905 05:11:13.921031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299139 (* 1 = 0.299139 loss)
I0905 05:11:13.921047 90901 sgd_solver.cpp:106] Iteration 19660, lr = 0.1
I0905 05:11:18.942008 90901 solver.cpp:228] Iteration 19670, loss = 0.37708
I0905 05:11:18.942066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37708 (* 1 = 0.37708 loss)
I0905 05:11:18.942081 90901 sgd_solver.cpp:106] Iteration 19670, lr = 0.1
I0905 05:11:23.960671 90901 solver.cpp:228] Iteration 19680, loss = 0.352867
I0905 05:11:23.960762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352867 (* 1 = 0.352867 loss)
I0905 05:11:23.960798 90901 sgd_solver.cpp:106] Iteration 19680, lr = 0.1
I0905 05:11:28.969581 90901 solver.cpp:228] Iteration 19690, loss = 0.656747
I0905 05:11:28.969751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.656746 (* 1 = 0.656746 loss)
I0905 05:11:28.969782 90901 sgd_solver.cpp:106] Iteration 19690, lr = 0.1
I0905 05:11:33.983153 90901 solver.cpp:228] Iteration 19700, loss = 0.515876
I0905 05:11:33.983206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515875 (* 1 = 0.515875 loss)
I0905 05:11:33.983228 90901 sgd_solver.cpp:106] Iteration 19700, lr = 0.1
I0905 05:11:38.980715 90901 solver.cpp:228] Iteration 19710, loss = 0.57394
I0905 05:11:38.980777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.57394 (* 1 = 0.57394 loss)
I0905 05:11:38.980793 90901 sgd_solver.cpp:106] Iteration 19710, lr = 0.1
I0905 05:11:43.972592 90901 solver.cpp:228] Iteration 19720, loss = 0.326065
I0905 05:11:43.972654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326064 (* 1 = 0.326064 loss)
I0905 05:11:43.972671 90901 sgd_solver.cpp:106] Iteration 19720, lr = 0.1
I0905 05:11:49.009263 90901 solver.cpp:228] Iteration 19730, loss = 0.350815
I0905 05:11:49.009325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350815 (* 1 = 0.350815 loss)
I0905 05:11:49.009341 90901 sgd_solver.cpp:106] Iteration 19730, lr = 0.1
I0905 05:11:54.051038 90901 solver.cpp:228] Iteration 19740, loss = 0.386972
I0905 05:11:54.051110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386972 (* 1 = 0.386972 loss)
I0905 05:11:54.051125 90901 sgd_solver.cpp:106] Iteration 19740, lr = 0.1
I0905 05:11:59.059759 90901 solver.cpp:228] Iteration 19750, loss = 0.253027
I0905 05:11:59.060070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253027 (* 1 = 0.253027 loss)
I0905 05:11:59.060089 90901 sgd_solver.cpp:106] Iteration 19750, lr = 0.1
I0905 05:12:04.073611 90901 solver.cpp:228] Iteration 19760, loss = 0.484651
I0905 05:12:04.073673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484651 (* 1 = 0.484651 loss)
I0905 05:12:04.073688 90901 sgd_solver.cpp:106] Iteration 19760, lr = 0.1
I0905 05:12:09.098634 90901 solver.cpp:228] Iteration 19770, loss = 0.125118
I0905 05:12:09.098690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125118 (* 1 = 0.125118 loss)
I0905 05:12:09.098704 90901 sgd_solver.cpp:106] Iteration 19770, lr = 0.1
I0905 05:12:14.131007 90901 solver.cpp:228] Iteration 19780, loss = 0.734774
I0905 05:12:14.131079 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.734774 (* 1 = 0.734774 loss)
I0905 05:12:14.131096 90901 sgd_solver.cpp:106] Iteration 19780, lr = 0.1
I0905 05:12:19.121023 90901 solver.cpp:228] Iteration 19790, loss = 0.496545
I0905 05:12:19.121084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496545 (* 1 = 0.496545 loss)
I0905 05:12:19.121100 90901 sgd_solver.cpp:106] Iteration 19790, lr = 0.1
I0905 05:12:25.197216 90901 solver.cpp:228] Iteration 19800, loss = 0.556489
I0905 05:12:25.197293 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556489 (* 1 = 0.556489 loss)
I0905 05:12:25.197310 90901 sgd_solver.cpp:106] Iteration 19800, lr = 0.1
I0905 05:12:31.278707 90901 solver.cpp:228] Iteration 19810, loss = 0.367297
I0905 05:12:31.278897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367297 (* 1 = 0.367297 loss)
I0905 05:12:31.278937 90901 sgd_solver.cpp:106] Iteration 19810, lr = 0.1
I0905 05:12:37.001461 90901 solver.cpp:228] Iteration 19820, loss = 0.592334
I0905 05:12:37.001518 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.592334 (* 1 = 0.592334 loss)
I0905 05:12:37.001530 90901 sgd_solver.cpp:106] Iteration 19820, lr = 0.1
I0905 05:12:42.264147 90901 solver.cpp:228] Iteration 19830, loss = 0.564171
I0905 05:12:42.264212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.564171 (* 1 = 0.564171 loss)
I0905 05:12:42.264226 90901 sgd_solver.cpp:106] Iteration 19830, lr = 0.1
I0905 05:12:48.263502 90901 solver.cpp:228] Iteration 19840, loss = 0.462188
I0905 05:12:48.263577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462188 (* 1 = 0.462188 loss)
I0905 05:12:48.263593 90901 sgd_solver.cpp:106] Iteration 19840, lr = 0.1
I0905 05:12:54.334880 90901 solver.cpp:228] Iteration 19850, loss = 0.740558
I0905 05:12:54.334923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.740558 (* 1 = 0.740558 loss)
I0905 05:12:54.334935 90901 sgd_solver.cpp:106] Iteration 19850, lr = 0.1
I0905 05:13:00.402411 90901 solver.cpp:228] Iteration 19860, loss = 0.6907
I0905 05:13:00.402467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.6907 (* 1 = 0.6907 loss)
I0905 05:13:00.402485 90901 sgd_solver.cpp:106] Iteration 19860, lr = 0.1
I0905 05:13:06.508312 90901 solver.cpp:228] Iteration 19870, loss = 0.278487
I0905 05:13:06.508538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278487 (* 1 = 0.278487 loss)
I0905 05:13:06.508576 90901 sgd_solver.cpp:106] Iteration 19870, lr = 0.1
I0905 05:13:12.542747 90901 solver.cpp:228] Iteration 19880, loss = 0.565139
I0905 05:13:12.542804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565139 (* 1 = 0.565139 loss)
I0905 05:13:12.542821 90901 sgd_solver.cpp:106] Iteration 19880, lr = 0.1
I0905 05:13:18.672194 90901 solver.cpp:228] Iteration 19890, loss = 0.37504
I0905 05:13:18.672251 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37504 (* 1 = 0.37504 loss)
I0905 05:13:18.672266 90901 sgd_solver.cpp:106] Iteration 19890, lr = 0.1
I0905 05:13:24.701870 90901 solver.cpp:228] Iteration 19900, loss = 0.476016
I0905 05:13:24.701932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476016 (* 1 = 0.476016 loss)
I0905 05:13:24.701957 90901 sgd_solver.cpp:106] Iteration 19900, lr = 0.1
I0905 05:13:31.126005 90901 solver.cpp:228] Iteration 19910, loss = 0.534666
I0905 05:13:31.126085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.534665 (* 1 = 0.534665 loss)
I0905 05:13:31.126107 90901 sgd_solver.cpp:106] Iteration 19910, lr = 0.1
I0905 05:13:37.187294 90901 solver.cpp:228] Iteration 19920, loss = 0.519602
I0905 05:13:37.187495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519601 (* 1 = 0.519601 loss)
I0905 05:13:37.187546 90901 sgd_solver.cpp:106] Iteration 19920, lr = 0.1
I0905 05:13:42.888665 90901 solver.cpp:228] Iteration 19930, loss = 0.329502
I0905 05:13:42.888731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329501 (* 1 = 0.329501 loss)
I0905 05:13:42.888746 90901 sgd_solver.cpp:106] Iteration 19930, lr = 0.1
I0905 05:13:49.345257 90901 solver.cpp:228] Iteration 19940, loss = 0.339952
I0905 05:13:49.345331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339951 (* 1 = 0.339951 loss)
I0905 05:13:49.345347 90901 sgd_solver.cpp:106] Iteration 19940, lr = 0.1
I0905 05:13:55.402665 90901 solver.cpp:228] Iteration 19950, loss = 0.208708
I0905 05:13:55.402755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208708 (* 1 = 0.208708 loss)
I0905 05:13:55.402801 90901 sgd_solver.cpp:106] Iteration 19950, lr = 0.1
I0905 05:14:01.445627 90901 solver.cpp:228] Iteration 19960, loss = 0.64641
I0905 05:14:01.445706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64641 (* 1 = 0.64641 loss)
I0905 05:14:01.445724 90901 sgd_solver.cpp:106] Iteration 19960, lr = 0.1
I0905 05:14:07.589094 90901 solver.cpp:228] Iteration 19970, loss = 0.515737
I0905 05:14:07.589244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515736 (* 1 = 0.515736 loss)
I0905 05:14:07.589284 90901 sgd_solver.cpp:106] Iteration 19970, lr = 0.1
I0905 05:14:13.768618 90901 solver.cpp:228] Iteration 19980, loss = 0.299126
I0905 05:14:13.768684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299126 (* 1 = 0.299126 loss)
I0905 05:14:13.768699 90901 sgd_solver.cpp:106] Iteration 19980, lr = 0.1
I0905 05:14:20.004863 90901 solver.cpp:228] Iteration 19990, loss = 0.386459
I0905 05:14:20.004917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386458 (* 1 = 0.386458 loss)
I0905 05:14:20.004931 90901 sgd_solver.cpp:106] Iteration 19990, lr = 0.1
I0905 05:14:25.093525 90901 solver.cpp:337] Iteration 20000, Testing net (#0)
I0905 05:15:06.818197 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.821563
I0905 05:15:06.818399 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.404316 (* 1 = 0.404316 loss)
I0905 05:15:07.034358 90901 solver.cpp:228] Iteration 20000, loss = 0.259792
I0905 05:15:07.034411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259791 (* 1 = 0.259791 loss)
I0905 05:15:07.034438 90901 sgd_solver.cpp:106] Iteration 20000, lr = 0.1
I0905 05:15:13.271554 90901 solver.cpp:228] Iteration 20010, loss = 0.516815
I0905 05:15:13.271623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.516814 (* 1 = 0.516814 loss)
I0905 05:15:13.271638 90901 sgd_solver.cpp:106] Iteration 20010, lr = 0.1
I0905 05:15:19.185528 90901 solver.cpp:228] Iteration 20020, loss = 0.363835
I0905 05:15:19.185580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363835 (* 1 = 0.363835 loss)
I0905 05:15:19.185593 90901 sgd_solver.cpp:106] Iteration 20020, lr = 0.1
I0905 05:15:25.579656 90901 solver.cpp:228] Iteration 20030, loss = 0.183849
I0905 05:15:25.579704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183849 (* 1 = 0.183849 loss)
I0905 05:15:25.579720 90901 sgd_solver.cpp:106] Iteration 20030, lr = 0.1
I0905 05:15:31.596038 90901 solver.cpp:228] Iteration 20040, loss = 0.329451
I0905 05:15:31.596109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329451 (* 1 = 0.329451 loss)
I0905 05:15:31.596124 90901 sgd_solver.cpp:106] Iteration 20040, lr = 0.1
I0905 05:15:37.664439 90901 solver.cpp:228] Iteration 20050, loss = 0.366647
I0905 05:15:37.664608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366647 (* 1 = 0.366647 loss)
I0905 05:15:37.664649 90901 sgd_solver.cpp:106] Iteration 20050, lr = 0.1
I0905 05:15:43.412128 90901 solver.cpp:228] Iteration 20060, loss = 0.360813
I0905 05:15:43.412176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360812 (* 1 = 0.360812 loss)
I0905 05:15:43.412191 90901 sgd_solver.cpp:106] Iteration 20060, lr = 0.1
I0905 05:15:49.816368 90901 solver.cpp:228] Iteration 20070, loss = 0.423327
I0905 05:15:49.816414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423327 (* 1 = 0.423327 loss)
I0905 05:15:49.816427 90901 sgd_solver.cpp:106] Iteration 20070, lr = 0.1
I0905 05:15:55.888326 90901 solver.cpp:228] Iteration 20080, loss = 0.377896
I0905 05:15:55.888373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377895 (* 1 = 0.377895 loss)
I0905 05:15:55.888391 90901 sgd_solver.cpp:106] Iteration 20080, lr = 0.1
I0905 05:16:01.942678 90901 solver.cpp:228] Iteration 20090, loss = 0.275039
I0905 05:16:01.942749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275038 (* 1 = 0.275038 loss)
I0905 05:16:01.942765 90901 sgd_solver.cpp:106] Iteration 20090, lr = 0.1
I0905 05:16:08.258452 90901 solver.cpp:228] Iteration 20100, loss = 0.286468
I0905 05:16:08.258626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286467 (* 1 = 0.286467 loss)
I0905 05:16:08.258687 90901 sgd_solver.cpp:106] Iteration 20100, lr = 0.1
I0905 05:16:13.511705 90901 solver.cpp:228] Iteration 20110, loss = 0.274471
I0905 05:16:13.511770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274471 (* 1 = 0.274471 loss)
I0905 05:16:13.511786 90901 sgd_solver.cpp:106] Iteration 20110, lr = 0.1
I0905 05:16:19.096024 90901 solver.cpp:228] Iteration 20120, loss = 0.213615
I0905 05:16:19.096071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213614 (* 1 = 0.213614 loss)
I0905 05:16:19.096084 90901 sgd_solver.cpp:106] Iteration 20120, lr = 0.1
I0905 05:16:25.043573 90901 solver.cpp:228] Iteration 20130, loss = 0.168941
I0905 05:16:25.043617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168941 (* 1 = 0.168941 loss)
I0905 05:16:25.043632 90901 sgd_solver.cpp:106] Iteration 20130, lr = 0.1
I0905 05:16:31.440723 90901 solver.cpp:228] Iteration 20140, loss = 0.362435
I0905 05:16:31.440778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362435 (* 1 = 0.362435 loss)
I0905 05:16:31.440791 90901 sgd_solver.cpp:106] Iteration 20140, lr = 0.1
I0905 05:16:37.481547 90901 solver.cpp:228] Iteration 20150, loss = 0.38947
I0905 05:16:37.481591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38947 (* 1 = 0.38947 loss)
I0905 05:16:37.481606 90901 sgd_solver.cpp:106] Iteration 20150, lr = 0.1
I0905 05:16:43.570719 90901 solver.cpp:228] Iteration 20160, loss = 0.236572
I0905 05:16:43.570977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236571 (* 1 = 0.236571 loss)
I0905 05:16:43.570994 90901 sgd_solver.cpp:106] Iteration 20160, lr = 0.1
I0905 05:16:49.340848 90901 solver.cpp:228] Iteration 20170, loss = 0.247062
I0905 05:16:49.340899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247062 (* 1 = 0.247062 loss)
I0905 05:16:49.340914 90901 sgd_solver.cpp:106] Iteration 20170, lr = 0.1
I0905 05:16:55.762380 90901 solver.cpp:228] Iteration 20180, loss = 0.244705
I0905 05:16:55.762424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244705 (* 1 = 0.244705 loss)
I0905 05:16:55.762439 90901 sgd_solver.cpp:106] Iteration 20180, lr = 0.1
I0905 05:17:01.835214 90901 solver.cpp:228] Iteration 20190, loss = 0.43332
I0905 05:17:01.835269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433319 (* 1 = 0.433319 loss)
I0905 05:17:01.835283 90901 sgd_solver.cpp:106] Iteration 20190, lr = 0.1
I0905 05:17:07.887501 90901 solver.cpp:228] Iteration 20200, loss = 0.415229
I0905 05:17:07.887557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415229 (* 1 = 0.415229 loss)
I0905 05:17:07.887572 90901 sgd_solver.cpp:106] Iteration 20200, lr = 0.1
I0905 05:17:13.891330 90901 solver.cpp:228] Iteration 20210, loss = 0.758198
I0905 05:17:13.891515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.758197 (* 1 = 0.758197 loss)
I0905 05:17:13.891531 90901 sgd_solver.cpp:106] Iteration 20210, lr = 0.1
I0905 05:17:20.265089 90901 solver.cpp:228] Iteration 20220, loss = 0.184226
I0905 05:17:20.265146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184225 (* 1 = 0.184225 loss)
I0905 05:17:20.265163 90901 sgd_solver.cpp:106] Iteration 20220, lr = 0.1
I0905 05:17:26.340255 90901 solver.cpp:228] Iteration 20230, loss = 0.619636
I0905 05:17:26.340301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.619636 (* 1 = 0.619636 loss)
I0905 05:17:26.340315 90901 sgd_solver.cpp:106] Iteration 20230, lr = 0.1
I0905 05:17:32.371904 90901 solver.cpp:228] Iteration 20240, loss = 0.197332
I0905 05:17:32.371953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197332 (* 1 = 0.197332 loss)
I0905 05:17:32.371968 90901 sgd_solver.cpp:106] Iteration 20240, lr = 0.1
I0905 05:17:38.731855 90901 solver.cpp:228] Iteration 20250, loss = 0.767284
I0905 05:17:38.731902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.767284 (* 1 = 0.767284 loss)
I0905 05:17:38.731916 90901 sgd_solver.cpp:106] Iteration 20250, lr = 0.1
I0905 05:17:44.810719 90901 solver.cpp:228] Iteration 20260, loss = 0.258404
I0905 05:17:44.810923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258404 (* 1 = 0.258404 loss)
I0905 05:17:44.810940 90901 sgd_solver.cpp:106] Iteration 20260, lr = 0.1
I0905 05:17:50.840358 90901 solver.cpp:228] Iteration 20270, loss = 0.592838
I0905 05:17:50.840421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.592838 (* 1 = 0.592838 loss)
I0905 05:17:50.840435 90901 sgd_solver.cpp:106] Iteration 20270, lr = 0.1
I0905 05:17:57.023802 90901 solver.cpp:228] Iteration 20280, loss = 0.353219
I0905 05:17:57.023857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353218 (* 1 = 0.353218 loss)
I0905 05:17:57.023870 90901 sgd_solver.cpp:106] Iteration 20280, lr = 0.1
I0905 05:18:02.320358 90901 solver.cpp:228] Iteration 20290, loss = 0.328253
I0905 05:18:02.320421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328253 (* 1 = 0.328253 loss)
I0905 05:18:02.320437 90901 sgd_solver.cpp:106] Iteration 20290, lr = 0.1
I0905 05:18:07.778756 90901 solver.cpp:228] Iteration 20300, loss = 0.145837
I0905 05:18:07.778811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145837 (* 1 = 0.145837 loss)
I0905 05:18:07.778827 90901 sgd_solver.cpp:106] Iteration 20300, lr = 0.1
I0905 05:18:14.191537 90901 solver.cpp:228] Iteration 20310, loss = 0.195424
I0905 05:18:14.191579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195424 (* 1 = 0.195424 loss)
I0905 05:18:14.191592 90901 sgd_solver.cpp:106] Iteration 20310, lr = 0.1
I0905 05:18:20.226116 90901 solver.cpp:228] Iteration 20320, loss = 0.434541
I0905 05:18:20.226361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43454 (* 1 = 0.43454 loss)
I0905 05:18:20.226375 90901 sgd_solver.cpp:106] Iteration 20320, lr = 0.1
I0905 05:18:26.445960 90901 solver.cpp:228] Iteration 20330, loss = 0.439302
I0905 05:18:26.446013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439302 (* 1 = 0.439302 loss)
I0905 05:18:26.446027 90901 sgd_solver.cpp:106] Iteration 20330, lr = 0.1
I0905 05:18:32.037050 90901 solver.cpp:228] Iteration 20340, loss = 0.405013
I0905 05:18:32.037107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.405013 (* 1 = 0.405013 loss)
I0905 05:18:32.037123 90901 sgd_solver.cpp:106] Iteration 20340, lr = 0.1
I0905 05:18:38.495303 90901 solver.cpp:228] Iteration 20350, loss = 0.462322
I0905 05:18:38.495347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462321 (* 1 = 0.462321 loss)
I0905 05:18:38.495362 90901 sgd_solver.cpp:106] Iteration 20350, lr = 0.1
I0905 05:18:44.903273 90901 solver.cpp:228] Iteration 20360, loss = 0.250499
I0905 05:18:44.903322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250499 (* 1 = 0.250499 loss)
I0905 05:18:44.903337 90901 sgd_solver.cpp:106] Iteration 20360, lr = 0.1
I0905 05:18:50.788519 90901 solver.cpp:228] Iteration 20370, loss = 0.21662
I0905 05:18:50.788669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21662 (* 1 = 0.21662 loss)
I0905 05:18:50.788700 90901 sgd_solver.cpp:106] Iteration 20370, lr = 0.1
I0905 05:18:57.024309 90901 solver.cpp:228] Iteration 20380, loss = 0.293612
I0905 05:18:57.024356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293612 (* 1 = 0.293612 loss)
I0905 05:18:57.024369 90901 sgd_solver.cpp:106] Iteration 20380, lr = 0.1
I0905 05:19:03.055165 90901 solver.cpp:228] Iteration 20390, loss = 0.490253
I0905 05:19:03.055229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490253 (* 1 = 0.490253 loss)
I0905 05:19:03.055246 90901 sgd_solver.cpp:106] Iteration 20390, lr = 0.1
I0905 05:19:09.173207 90901 solver.cpp:228] Iteration 20400, loss = 0.555781
I0905 05:19:09.173262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555781 (* 1 = 0.555781 loss)
I0905 05:19:09.173276 90901 sgd_solver.cpp:106] Iteration 20400, lr = 0.1
I0905 05:19:15.235330 90901 solver.cpp:228] Iteration 20410, loss = 0.320016
I0905 05:19:15.235379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320015 (* 1 = 0.320015 loss)
I0905 05:19:15.235394 90901 sgd_solver.cpp:106] Iteration 20410, lr = 0.1
I0905 05:19:21.609411 90901 solver.cpp:228] Iteration 20420, loss = 0.696385
I0905 05:19:21.609619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696385 (* 1 = 0.696385 loss)
I0905 05:19:21.609649 90901 sgd_solver.cpp:106] Iteration 20420, lr = 0.1
I0905 05:19:27.683053 90901 solver.cpp:228] Iteration 20430, loss = 0.885243
I0905 05:19:27.683094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.885243 (* 1 = 0.885243 loss)
I0905 05:19:27.683107 90901 sgd_solver.cpp:106] Iteration 20430, lr = 0.1
I0905 05:19:33.461704 90901 solver.cpp:228] Iteration 20440, loss = 0.451256
I0905 05:19:33.461748 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451256 (* 1 = 0.451256 loss)
I0905 05:19:33.461761 90901 sgd_solver.cpp:106] Iteration 20440, lr = 0.1
I0905 05:19:39.853263 90901 solver.cpp:228] Iteration 20450, loss = 0.293252
I0905 05:19:39.853314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293252 (* 1 = 0.293252 loss)
I0905 05:19:39.853329 90901 sgd_solver.cpp:106] Iteration 20450, lr = 0.1
I0905 05:19:45.633707 90901 solver.cpp:228] Iteration 20460, loss = 0.186434
I0905 05:19:45.633756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186433 (* 1 = 0.186433 loss)
I0905 05:19:45.633769 90901 sgd_solver.cpp:106] Iteration 20460, lr = 0.1
I0905 05:19:51.196782 90901 solver.cpp:228] Iteration 20470, loss = 0.398333
I0905 05:19:51.196846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398333 (* 1 = 0.398333 loss)
I0905 05:19:51.196864 90901 sgd_solver.cpp:106] Iteration 20470, lr = 0.1
I0905 05:19:56.779966 90901 solver.cpp:228] Iteration 20480, loss = 0.302971
I0905 05:19:56.780194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302971 (* 1 = 0.302971 loss)
I0905 05:19:56.780226 90901 sgd_solver.cpp:106] Iteration 20480, lr = 0.1
I0905 05:20:02.865192 90901 solver.cpp:228] Iteration 20490, loss = 0.730901
I0905 05:20:02.865237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.730901 (* 1 = 0.730901 loss)
I0905 05:20:02.865250 90901 sgd_solver.cpp:106] Iteration 20490, lr = 0.1
I0905 05:20:08.930873 90901 solver.cpp:228] Iteration 20500, loss = 0.280694
I0905 05:20:08.930917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280693 (* 1 = 0.280693 loss)
I0905 05:20:08.930932 90901 sgd_solver.cpp:106] Iteration 20500, lr = 0.1
I0905 05:20:15.020581 90901 solver.cpp:228] Iteration 20510, loss = 0.320731
I0905 05:20:15.020627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32073 (* 1 = 0.32073 loss)
I0905 05:20:15.020640 90901 sgd_solver.cpp:106] Iteration 20510, lr = 0.1
I0905 05:20:21.159343 90901 solver.cpp:228] Iteration 20520, loss = 1.05538
I0905 05:20:21.159392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.05538 (* 1 = 1.05538 loss)
I0905 05:20:21.159405 90901 sgd_solver.cpp:106] Iteration 20520, lr = 0.1
I0905 05:20:27.481169 90901 solver.cpp:228] Iteration 20530, loss = 0.623299
I0905 05:20:27.481375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.623299 (* 1 = 0.623299 loss)
I0905 05:20:27.481407 90901 sgd_solver.cpp:106] Iteration 20530, lr = 0.1
I0905 05:20:33.251327 90901 solver.cpp:228] Iteration 20540, loss = 0.498019
I0905 05:20:33.251387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498018 (* 1 = 0.498018 loss)
I0905 05:20:33.251402 90901 sgd_solver.cpp:106] Iteration 20540, lr = 0.1
I0905 05:20:39.314797 90901 solver.cpp:228] Iteration 20550, loss = 0.781473
I0905 05:20:39.314842 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.781473 (* 1 = 0.781473 loss)
I0905 05:20:39.314857 90901 sgd_solver.cpp:106] Iteration 20550, lr = 0.1
I0905 05:20:45.404269 90901 solver.cpp:228] Iteration 20560, loss = 0.34959
I0905 05:20:45.404309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34959 (* 1 = 0.34959 loss)
I0905 05:20:45.404325 90901 sgd_solver.cpp:106] Iteration 20560, lr = 0.1
I0905 05:20:51.489768 90901 solver.cpp:228] Iteration 20570, loss = 0.365749
I0905 05:20:51.489810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365749 (* 1 = 0.365749 loss)
I0905 05:20:51.489823 90901 sgd_solver.cpp:106] Iteration 20570, lr = 0.1
I0905 05:20:57.717389 90901 solver.cpp:228] Iteration 20580, loss = 0.299545
I0905 05:20:57.717548 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299544 (* 1 = 0.299544 loss)
I0905 05:20:57.717576 90901 sgd_solver.cpp:106] Iteration 20580, lr = 0.1
I0905 05:21:03.974552 90901 solver.cpp:228] Iteration 20590, loss = 0.214339
I0905 05:21:03.974607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214338 (* 1 = 0.214338 loss)
I0905 05:21:03.974620 90901 sgd_solver.cpp:106] Iteration 20590, lr = 0.1
I0905 05:21:10.049402 90901 solver.cpp:228] Iteration 20600, loss = 0.343297
I0905 05:21:10.049450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343297 (* 1 = 0.343297 loss)
I0905 05:21:10.049464 90901 sgd_solver.cpp:106] Iteration 20600, lr = 0.1
I0905 05:21:16.410645 90901 solver.cpp:228] Iteration 20610, loss = 0.366618
I0905 05:21:16.410694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366618 (* 1 = 0.366618 loss)
I0905 05:21:16.410712 90901 sgd_solver.cpp:106] Iteration 20610, lr = 0.1
I0905 05:21:22.499428 90901 solver.cpp:228] Iteration 20620, loss = 0.585329
I0905 05:21:22.499477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.585329 (* 1 = 0.585329 loss)
I0905 05:21:22.499492 90901 sgd_solver.cpp:106] Iteration 20620, lr = 0.1
I0905 05:21:28.231052 90901 solver.cpp:228] Iteration 20630, loss = 0.268273
I0905 05:21:28.231266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268272 (* 1 = 0.268272 loss)
I0905 05:21:28.231286 90901 sgd_solver.cpp:106] Iteration 20630, lr = 0.1
I0905 05:21:34.242226 90901 solver.cpp:228] Iteration 20640, loss = 0.504714
I0905 05:21:34.242276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504714 (* 1 = 0.504714 loss)
I0905 05:21:34.242291 90901 sgd_solver.cpp:106] Iteration 20640, lr = 0.1
I0905 05:21:39.492908 90901 solver.cpp:228] Iteration 20650, loss = 0.189517
I0905 05:21:39.492951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189517 (* 1 = 0.189517 loss)
I0905 05:21:39.492966 90901 sgd_solver.cpp:106] Iteration 20650, lr = 0.1
I0905 05:21:45.646392 90901 solver.cpp:228] Iteration 20660, loss = 0.389013
I0905 05:21:45.646451 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389012 (* 1 = 0.389012 loss)
I0905 05:21:45.646466 90901 sgd_solver.cpp:106] Iteration 20660, lr = 0.1
I0905 05:21:51.700897 90901 solver.cpp:228] Iteration 20670, loss = 0.379085
I0905 05:21:51.700942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379085 (* 1 = 0.379085 loss)
I0905 05:21:51.700954 90901 sgd_solver.cpp:106] Iteration 20670, lr = 0.1
I0905 05:21:57.766166 90901 solver.cpp:228] Iteration 20680, loss = 0.495049
I0905 05:21:57.766211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.495049 (* 1 = 0.495049 loss)
I0905 05:21:57.766224 90901 sgd_solver.cpp:106] Iteration 20680, lr = 0.1
I0905 05:22:03.827710 90901 solver.cpp:228] Iteration 20690, loss = 0.280185
I0905 05:22:03.828860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280185 (* 1 = 0.280185 loss)
I0905 05:22:03.828876 90901 sgd_solver.cpp:106] Iteration 20690, lr = 0.1
I0905 05:22:09.905284 90901 solver.cpp:228] Iteration 20700, loss = 0.62054
I0905 05:22:09.905333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.62054 (* 1 = 0.62054 loss)
I0905 05:22:09.905349 90901 sgd_solver.cpp:106] Iteration 20700, lr = 0.1
I0905 05:22:16.318568 90901 solver.cpp:228] Iteration 20710, loss = 0.270151
I0905 05:22:16.318617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270151 (* 1 = 0.270151 loss)
I0905 05:22:16.318640 90901 sgd_solver.cpp:106] Iteration 20710, lr = 0.1
I0905 05:22:22.388097 90901 solver.cpp:228] Iteration 20720, loss = 0.205701
I0905 05:22:22.388144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205701 (* 1 = 0.205701 loss)
I0905 05:22:22.388160 90901 sgd_solver.cpp:106] Iteration 20720, lr = 0.1
I0905 05:22:28.162948 90901 solver.cpp:228] Iteration 20730, loss = 0.366518
I0905 05:22:28.162992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366518 (* 1 = 0.366518 loss)
I0905 05:22:28.163004 90901 sgd_solver.cpp:106] Iteration 20730, lr = 0.1
I0905 05:22:34.589265 90901 solver.cpp:228] Iteration 20740, loss = 0.771071
I0905 05:22:34.589391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.771071 (* 1 = 0.771071 loss)
I0905 05:22:34.589423 90901 sgd_solver.cpp:106] Iteration 20740, lr = 0.1
I0905 05:22:40.648975 90901 solver.cpp:228] Iteration 20750, loss = 0.38198
I0905 05:22:40.649026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38198 (* 1 = 0.38198 loss)
I0905 05:22:40.649040 90901 sgd_solver.cpp:106] Iteration 20750, lr = 0.1
I0905 05:22:46.402600 90901 solver.cpp:228] Iteration 20760, loss = 0.726073
I0905 05:22:46.402649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.726072 (* 1 = 0.726072 loss)
I0905 05:22:46.402667 90901 sgd_solver.cpp:106] Iteration 20760, lr = 0.1
I0905 05:22:52.818383 90901 solver.cpp:228] Iteration 20770, loss = 0.287466
I0905 05:22:52.818424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287466 (* 1 = 0.287466 loss)
I0905 05:22:52.818439 90901 sgd_solver.cpp:106] Iteration 20770, lr = 0.1
I0905 05:22:59.222386 90901 solver.cpp:228] Iteration 20780, loss = 0.438684
I0905 05:22:59.222452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438683 (* 1 = 0.438683 loss)
I0905 05:22:59.222467 90901 sgd_solver.cpp:106] Iteration 20780, lr = 0.1
I0905 05:23:05.271889 90901 solver.cpp:228] Iteration 20790, loss = 0.461918
I0905 05:23:05.272091 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461917 (* 1 = 0.461917 loss)
I0905 05:23:05.272141 90901 sgd_solver.cpp:106] Iteration 20790, lr = 0.1
I0905 05:23:11.114245 90901 solver.cpp:337] Iteration 20800, Testing net (#0)
I0905 05:23:51.736266 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.57
I0905 05:23:51.736398 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.35113 (* 1 = 1.35113 loss)
I0905 05:23:52.066215 90901 solver.cpp:228] Iteration 20800, loss = 0.220422
I0905 05:23:52.066272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220422 (* 1 = 0.220422 loss)
I0905 05:23:52.066288 90901 sgd_solver.cpp:106] Iteration 20800, lr = 0.1
I0905 05:23:58.572521 90901 solver.cpp:228] Iteration 20810, loss = 0.813721
I0905 05:23:58.572567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.813721 (* 1 = 0.813721 loss)
I0905 05:23:58.572582 90901 sgd_solver.cpp:106] Iteration 20810, lr = 0.1
I0905 05:24:04.717514 90901 solver.cpp:228] Iteration 20820, loss = 0.369055
I0905 05:24:04.717572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369055 (* 1 = 0.369055 loss)
I0905 05:24:04.717588 90901 sgd_solver.cpp:106] Iteration 20820, lr = 0.1
I0905 05:24:11.005556 90901 solver.cpp:228] Iteration 20830, loss = 0.447444
I0905 05:24:11.005599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.447443 (* 1 = 0.447443 loss)
I0905 05:24:11.005611 90901 sgd_solver.cpp:106] Iteration 20830, lr = 0.1
I0905 05:24:17.128769 90901 solver.cpp:228] Iteration 20840, loss = 0.328529
I0905 05:24:17.128829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328529 (* 1 = 0.328529 loss)
I0905 05:24:17.128842 90901 sgd_solver.cpp:106] Iteration 20840, lr = 0.1
I0905 05:24:23.193110 90901 solver.cpp:228] Iteration 20850, loss = 0.219115
I0905 05:24:23.193311 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219115 (* 1 = 0.219115 loss)
I0905 05:24:23.193330 90901 sgd_solver.cpp:106] Iteration 20850, lr = 0.1
I0905 05:24:29.544438 90901 solver.cpp:228] Iteration 20860, loss = 0.138586
I0905 05:24:29.544488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138585 (* 1 = 0.138585 loss)
I0905 05:24:29.544502 90901 sgd_solver.cpp:106] Iteration 20860, lr = 0.1
I0905 05:24:35.333304 90901 solver.cpp:228] Iteration 20870, loss = 0.365451
I0905 05:24:35.333344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36545 (* 1 = 0.36545 loss)
I0905 05:24:35.333359 90901 sgd_solver.cpp:106] Iteration 20870, lr = 0.1
I0905 05:24:41.508266 90901 solver.cpp:228] Iteration 20880, loss = 0.241742
I0905 05:24:41.508318 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241741 (* 1 = 0.241741 loss)
I0905 05:24:41.508332 90901 sgd_solver.cpp:106] Iteration 20880, lr = 0.1
I0905 05:24:47.491389 90901 solver.cpp:228] Iteration 20890, loss = 0.673454
I0905 05:24:47.491435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.673453 (* 1 = 0.673453 loss)
I0905 05:24:47.491447 90901 sgd_solver.cpp:106] Iteration 20890, lr = 0.1
I0905 05:24:53.533764 90901 solver.cpp:228] Iteration 20900, loss = 0.136566
I0905 05:24:53.533992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136565 (* 1 = 0.136565 loss)
I0905 05:24:53.534010 90901 sgd_solver.cpp:106] Iteration 20900, lr = 0.1
I0905 05:24:59.995440 90901 solver.cpp:228] Iteration 20910, loss = 0.391227
I0905 05:24:59.995488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391226 (* 1 = 0.391226 loss)
I0905 05:24:59.995502 90901 sgd_solver.cpp:106] Iteration 20910, lr = 0.1
I0905 05:25:05.872220 90901 solver.cpp:228] Iteration 20920, loss = 0.665271
I0905 05:25:05.872270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.665271 (* 1 = 0.665271 loss)
I0905 05:25:05.872285 90901 sgd_solver.cpp:106] Iteration 20920, lr = 0.1
I0905 05:25:10.821910 90901 solver.cpp:228] Iteration 20930, loss = 0.540876
I0905 05:25:10.821959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.540876 (* 1 = 0.540876 loss)
I0905 05:25:10.821971 90901 sgd_solver.cpp:106] Iteration 20930, lr = 0.1
I0905 05:25:16.774615 90901 solver.cpp:228] Iteration 20940, loss = 0.276007
I0905 05:25:16.774667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276007 (* 1 = 0.276007 loss)
I0905 05:25:16.774682 90901 sgd_solver.cpp:106] Iteration 20940, lr = 0.1
I0905 05:25:23.170380 90901 solver.cpp:228] Iteration 20950, loss = 0.39697
I0905 05:25:23.170423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39697 (* 1 = 0.39697 loss)
I0905 05:25:23.170436 90901 sgd_solver.cpp:106] Iteration 20950, lr = 0.1
I0905 05:25:29.195689 90901 solver.cpp:228] Iteration 20960, loss = 0.211816
I0905 05:25:29.195930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211815 (* 1 = 0.211815 loss)
I0905 05:25:29.195947 90901 sgd_solver.cpp:106] Iteration 20960, lr = 0.1
I0905 05:25:35.288419 90901 solver.cpp:228] Iteration 20970, loss = 0.243712
I0905 05:25:35.288465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243711 (* 1 = 0.243711 loss)
I0905 05:25:35.288477 90901 sgd_solver.cpp:106] Iteration 20970, lr = 0.1
I0905 05:25:41.345288 90901 solver.cpp:228] Iteration 20980, loss = 0.1631
I0905 05:25:41.345360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1631 (* 1 = 0.1631 loss)
I0905 05:25:41.345374 90901 sgd_solver.cpp:106] Iteration 20980, lr = 0.1
I0905 05:25:47.510411 90901 solver.cpp:228] Iteration 20990, loss = 0.443759
I0905 05:25:47.510462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443758 (* 1 = 0.443758 loss)
I0905 05:25:47.510475 90901 sgd_solver.cpp:106] Iteration 20990, lr = 0.1
I0905 05:25:53.517648 90901 solver.cpp:228] Iteration 21000, loss = 0.189669
I0905 05:25:53.517694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189668 (* 1 = 0.189668 loss)
I0905 05:25:53.517707 90901 sgd_solver.cpp:106] Iteration 21000, lr = 0.1
I0905 05:25:59.905158 90901 solver.cpp:228] Iteration 21010, loss = 0.386553
I0905 05:25:59.905313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386552 (* 1 = 0.386552 loss)
I0905 05:25:59.905346 90901 sgd_solver.cpp:106] Iteration 21010, lr = 0.1
I0905 05:26:05.965751 90901 solver.cpp:228] Iteration 21020, loss = 0.194195
I0905 05:26:05.965807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194195 (* 1 = 0.194195 loss)
I0905 05:26:05.965821 90901 sgd_solver.cpp:106] Iteration 21020, lr = 0.1
I0905 05:26:12.047547 90901 solver.cpp:228] Iteration 21030, loss = 0.328714
I0905 05:26:12.047608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328714 (* 1 = 0.328714 loss)
I0905 05:26:12.047626 90901 sgd_solver.cpp:106] Iteration 21030, lr = 0.1
I0905 05:26:18.103353 90901 solver.cpp:228] Iteration 21040, loss = 0.319331
I0905 05:26:18.103400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319331 (* 1 = 0.319331 loss)
I0905 05:26:18.103415 90901 sgd_solver.cpp:106] Iteration 21040, lr = 0.1
I0905 05:26:24.187337 90901 solver.cpp:228] Iteration 21050, loss = 0.127411
I0905 05:26:24.187379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12741 (* 1 = 0.12741 loss)
I0905 05:26:24.187391 90901 sgd_solver.cpp:106] Iteration 21050, lr = 0.1
I0905 05:26:30.506784 90901 solver.cpp:228] Iteration 21060, loss = 0.563212
I0905 05:26:30.507052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.563212 (* 1 = 0.563212 loss)
I0905 05:26:30.507069 90901 sgd_solver.cpp:106] Iteration 21060, lr = 0.1
I0905 05:26:36.275152 90901 solver.cpp:228] Iteration 21070, loss = 0.388269
I0905 05:26:36.275200 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388269 (* 1 = 0.388269 loss)
I0905 05:26:36.275213 90901 sgd_solver.cpp:106] Iteration 21070, lr = 0.1
I0905 05:26:42.281350 90901 solver.cpp:228] Iteration 21080, loss = 0.435682
I0905 05:26:42.281411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435681 (* 1 = 0.435681 loss)
I0905 05:26:42.281425 90901 sgd_solver.cpp:106] Iteration 21080, lr = 0.1
I0905 05:26:48.781114 90901 solver.cpp:228] Iteration 21090, loss = 0.121742
I0905 05:26:48.781169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121742 (* 1 = 0.121742 loss)
I0905 05:26:48.781184 90901 sgd_solver.cpp:106] Iteration 21090, lr = 0.1
I0905 05:26:54.414611 90901 solver.cpp:228] Iteration 21100, loss = 0.221579
I0905 05:26:54.414686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221578 (* 1 = 0.221578 loss)
I0905 05:26:54.414717 90901 sgd_solver.cpp:106] Iteration 21100, lr = 0.1
I0905 05:26:59.850046 90901 solver.cpp:228] Iteration 21110, loss = 0.119526
I0905 05:26:59.850106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119526 (* 1 = 0.119526 loss)
I0905 05:26:59.850121 90901 sgd_solver.cpp:106] Iteration 21110, lr = 0.1
I0905 05:27:05.813678 90901 solver.cpp:228] Iteration 21120, loss = 0.591736
I0905 05:27:05.813843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.591735 (* 1 = 0.591735 loss)
I0905 05:27:05.813871 90901 sgd_solver.cpp:106] Iteration 21120, lr = 0.1
I0905 05:27:11.723840 90901 solver.cpp:228] Iteration 21130, loss = 0.38138
I0905 05:27:11.723886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38138 (* 1 = 0.38138 loss)
I0905 05:27:11.723899 90901 sgd_solver.cpp:106] Iteration 21130, lr = 0.1
I0905 05:27:18.125895 90901 solver.cpp:228] Iteration 21140, loss = 0.382602
I0905 05:27:18.125957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382602 (* 1 = 0.382602 loss)
I0905 05:27:18.125970 90901 sgd_solver.cpp:106] Iteration 21140, lr = 0.1
I0905 05:27:24.209058 90901 solver.cpp:228] Iteration 21150, loss = 0.538548
I0905 05:27:24.209121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.538547 (* 1 = 0.538547 loss)
I0905 05:27:24.209136 90901 sgd_solver.cpp:106] Iteration 21150, lr = 0.1
I0905 05:27:30.042059 90901 solver.cpp:228] Iteration 21160, loss = 0.105917
I0905 05:27:30.042103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105916 (* 1 = 0.105916 loss)
I0905 05:27:30.042115 90901 sgd_solver.cpp:106] Iteration 21160, lr = 0.1
I0905 05:27:36.045032 90901 solver.cpp:228] Iteration 21170, loss = 0.321657
I0905 05:27:36.045198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321657 (* 1 = 0.321657 loss)
I0905 05:27:36.045256 90901 sgd_solver.cpp:106] Iteration 21170, lr = 0.1
I0905 05:27:42.080516 90901 solver.cpp:228] Iteration 21180, loss = 0.424735
I0905 05:27:42.080565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424734 (* 1 = 0.424734 loss)
I0905 05:27:42.080579 90901 sgd_solver.cpp:106] Iteration 21180, lr = 0.1
I0905 05:27:48.145076 90901 solver.cpp:228] Iteration 21190, loss = 0.368865
I0905 05:27:48.145133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368864 (* 1 = 0.368864 loss)
I0905 05:27:48.145149 90901 sgd_solver.cpp:106] Iteration 21190, lr = 0.1
I0905 05:27:54.255981 90901 solver.cpp:228] Iteration 21200, loss = 0.6412
I0905 05:27:54.256028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.6412 (* 1 = 0.6412 loss)
I0905 05:27:54.256042 90901 sgd_solver.cpp:106] Iteration 21200, lr = 0.1
I0905 05:28:00.653020 90901 solver.cpp:228] Iteration 21210, loss = 0.436521
I0905 05:28:00.653084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436521 (* 1 = 0.436521 loss)
I0905 05:28:00.653098 90901 sgd_solver.cpp:106] Iteration 21210, lr = 0.1
I0905 05:28:06.416303 90901 solver.cpp:228] Iteration 21220, loss = 0.302914
I0905 05:28:06.416541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302914 (* 1 = 0.302914 loss)
I0905 05:28:06.416570 90901 sgd_solver.cpp:106] Iteration 21220, lr = 0.1
I0905 05:28:12.805969 90901 solver.cpp:228] Iteration 21230, loss = 0.203849
I0905 05:28:12.806030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203849 (* 1 = 0.203849 loss)
I0905 05:28:12.806044 90901 sgd_solver.cpp:106] Iteration 21230, lr = 0.1
I0905 05:28:18.887882 90901 solver.cpp:228] Iteration 21240, loss = 0.514334
I0905 05:28:18.887924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514334 (* 1 = 0.514334 loss)
I0905 05:28:18.887938 90901 sgd_solver.cpp:106] Iteration 21240, lr = 0.1
I0905 05:28:24.998189 90901 solver.cpp:228] Iteration 21250, loss = 0.188936
I0905 05:28:24.998240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188935 (* 1 = 0.188935 loss)
I0905 05:28:24.998255 90901 sgd_solver.cpp:106] Iteration 21250, lr = 0.1
I0905 05:28:30.723695 90901 solver.cpp:228] Iteration 21260, loss = 0.17638
I0905 05:28:30.723752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17638 (* 1 = 0.17638 loss)
I0905 05:28:30.723765 90901 sgd_solver.cpp:106] Iteration 21260, lr = 0.1
I0905 05:28:37.100719 90901 solver.cpp:228] Iteration 21270, loss = 0.200379
I0905 05:28:37.100850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200379 (* 1 = 0.200379 loss)
I0905 05:28:37.100878 90901 sgd_solver.cpp:106] Iteration 21270, lr = 0.1
I0905 05:28:42.422678 90901 solver.cpp:228] Iteration 21280, loss = 0.197246
I0905 05:28:42.422737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197246 (* 1 = 0.197246 loss)
I0905 05:28:42.422751 90901 sgd_solver.cpp:106] Iteration 21280, lr = 0.1
I0905 05:28:47.595250 90901 solver.cpp:228] Iteration 21290, loss = 0.457554
I0905 05:28:47.595309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457554 (* 1 = 0.457554 loss)
I0905 05:28:47.595322 90901 sgd_solver.cpp:106] Iteration 21290, lr = 0.1
I0905 05:28:52.622820 90901 solver.cpp:228] Iteration 21300, loss = 0.288278
I0905 05:28:52.622879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288278 (* 1 = 0.288278 loss)
I0905 05:28:52.622892 90901 sgd_solver.cpp:106] Iteration 21300, lr = 0.1
I0905 05:28:57.687429 90901 solver.cpp:228] Iteration 21310, loss = 0.35735
I0905 05:28:57.687484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357349 (* 1 = 0.357349 loss)
I0905 05:28:57.687497 90901 sgd_solver.cpp:106] Iteration 21310, lr = 0.1
I0905 05:29:02.739264 90901 solver.cpp:228] Iteration 21320, loss = 0.302622
I0905 05:29:02.739323 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302621 (* 1 = 0.302621 loss)
I0905 05:29:02.739339 90901 sgd_solver.cpp:106] Iteration 21320, lr = 0.1
I0905 05:29:07.792889 90901 solver.cpp:228] Iteration 21330, loss = 0.59884
I0905 05:29:07.793027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59884 (* 1 = 0.59884 loss)
I0905 05:29:07.793054 90901 sgd_solver.cpp:106] Iteration 21330, lr = 0.1
I0905 05:29:12.840152 90901 solver.cpp:228] Iteration 21340, loss = 0.440093
I0905 05:29:12.840204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440093 (* 1 = 0.440093 loss)
I0905 05:29:12.840216 90901 sgd_solver.cpp:106] Iteration 21340, lr = 0.1
I0905 05:29:17.901088 90901 solver.cpp:228] Iteration 21350, loss = 0.57659
I0905 05:29:17.901144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.576589 (* 1 = 0.576589 loss)
I0905 05:29:17.901156 90901 sgd_solver.cpp:106] Iteration 21350, lr = 0.1
I0905 05:29:22.983125 90901 solver.cpp:228] Iteration 21360, loss = 0.520797
I0905 05:29:22.983157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520797 (* 1 = 0.520797 loss)
I0905 05:29:22.983170 90901 sgd_solver.cpp:106] Iteration 21360, lr = 0.1
I0905 05:29:28.018944 90901 solver.cpp:228] Iteration 21370, loss = 0.488772
I0905 05:29:28.018990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488771 (* 1 = 0.488771 loss)
I0905 05:29:28.019006 90901 sgd_solver.cpp:106] Iteration 21370, lr = 0.1
I0905 05:29:33.083773 90901 solver.cpp:228] Iteration 21380, loss = 0.688749
I0905 05:29:33.083820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.688749 (* 1 = 0.688749 loss)
I0905 05:29:33.083832 90901 sgd_solver.cpp:106] Iteration 21380, lr = 0.1
I0905 05:29:38.123296 90901 solver.cpp:228] Iteration 21390, loss = 0.311275
I0905 05:29:38.123472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311274 (* 1 = 0.311274 loss)
I0905 05:29:38.123493 90901 sgd_solver.cpp:106] Iteration 21390, lr = 0.1
I0905 05:29:43.163111 90901 solver.cpp:228] Iteration 21400, loss = 0.582644
I0905 05:29:43.163153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.582644 (* 1 = 0.582644 loss)
I0905 05:29:43.163168 90901 sgd_solver.cpp:106] Iteration 21400, lr = 0.1
I0905 05:29:48.208521 90901 solver.cpp:228] Iteration 21410, loss = 0.577986
I0905 05:29:48.208556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.577985 (* 1 = 0.577985 loss)
I0905 05:29:48.208570 90901 sgd_solver.cpp:106] Iteration 21410, lr = 0.1
I0905 05:29:53.238493 90901 solver.cpp:228] Iteration 21420, loss = 0.441267
I0905 05:29:53.238536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.441267 (* 1 = 0.441267 loss)
I0905 05:29:53.238548 90901 sgd_solver.cpp:106] Iteration 21420, lr = 0.1
I0905 05:29:58.320582 90901 solver.cpp:228] Iteration 21430, loss = 0.323153
I0905 05:29:58.320629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323153 (* 1 = 0.323153 loss)
I0905 05:29:58.320643 90901 sgd_solver.cpp:106] Iteration 21430, lr = 0.1
I0905 05:30:03.390900 90901 solver.cpp:228] Iteration 21440, loss = 0.42376
I0905 05:30:03.390943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423759 (* 1 = 0.423759 loss)
I0905 05:30:03.390955 90901 sgd_solver.cpp:106] Iteration 21440, lr = 0.1
I0905 05:30:08.774453 90901 solver.cpp:228] Iteration 21450, loss = 0.689678
I0905 05:30:08.774585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.689678 (* 1 = 0.689678 loss)
I0905 05:30:08.774646 90901 sgd_solver.cpp:106] Iteration 21450, lr = 0.1
I0905 05:30:14.857744 90901 solver.cpp:228] Iteration 21460, loss = 0.50749
I0905 05:30:14.857796 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.50749 (* 1 = 0.50749 loss)
I0905 05:30:14.857810 90901 sgd_solver.cpp:106] Iteration 21460, lr = 0.1
I0905 05:30:20.940242 90901 solver.cpp:228] Iteration 21470, loss = 0.536662
I0905 05:30:20.940305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.536661 (* 1 = 0.536661 loss)
I0905 05:30:20.940320 90901 sgd_solver.cpp:106] Iteration 21470, lr = 0.1
I0905 05:30:27.016235 90901 solver.cpp:228] Iteration 21480, loss = 0.690756
I0905 05:30:27.016290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.690755 (* 1 = 0.690755 loss)
I0905 05:30:27.016304 90901 sgd_solver.cpp:106] Iteration 21480, lr = 0.1
I0905 05:30:32.741737 90901 solver.cpp:228] Iteration 21490, loss = 0.767056
I0905 05:30:32.741786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.767056 (* 1 = 0.767056 loss)
I0905 05:30:32.741798 90901 sgd_solver.cpp:106] Iteration 21490, lr = 0.1
I0905 05:30:37.993921 90901 solver.cpp:228] Iteration 21500, loss = 0.360477
I0905 05:30:37.993963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360477 (* 1 = 0.360477 loss)
I0905 05:30:37.993975 90901 sgd_solver.cpp:106] Iteration 21500, lr = 0.1
I0905 05:30:43.884001 90901 solver.cpp:228] Iteration 21510, loss = 0.219451
I0905 05:30:43.884191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219451 (* 1 = 0.219451 loss)
I0905 05:30:43.884222 90901 sgd_solver.cpp:106] Iteration 21510, lr = 0.1
I0905 05:30:50.053302 90901 solver.cpp:228] Iteration 21520, loss = 0.35965
I0905 05:30:50.053351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359649 (* 1 = 0.359649 loss)
I0905 05:30:50.053364 90901 sgd_solver.cpp:106] Iteration 21520, lr = 0.1
I0905 05:30:56.116051 90901 solver.cpp:228] Iteration 21530, loss = 0.269474
I0905 05:30:56.116099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269474 (* 1 = 0.269474 loss)
I0905 05:30:56.116112 90901 sgd_solver.cpp:106] Iteration 21530, lr = 0.1
I0905 05:31:02.190742 90901 solver.cpp:228] Iteration 21540, loss = 0.481432
I0905 05:31:02.190822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.481431 (* 1 = 0.481431 loss)
I0905 05:31:02.190840 90901 sgd_solver.cpp:106] Iteration 21540, lr = 0.1
I0905 05:31:08.241919 90901 solver.cpp:228] Iteration 21550, loss = 0.266852
I0905 05:31:08.241969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266851 (* 1 = 0.266851 loss)
I0905 05:31:08.241986 90901 sgd_solver.cpp:106] Iteration 21550, lr = 0.1
I0905 05:31:14.371475 90901 solver.cpp:228] Iteration 21560, loss = 0.221314
I0905 05:31:14.371630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221314 (* 1 = 0.221314 loss)
I0905 05:31:14.371685 90901 sgd_solver.cpp:106] Iteration 21560, lr = 0.1
I0905 05:31:20.462400 90901 solver.cpp:228] Iteration 21570, loss = 0.136794
I0905 05:31:20.462453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136793 (* 1 = 0.136793 loss)
I0905 05:31:20.462466 90901 sgd_solver.cpp:106] Iteration 21570, lr = 0.1
I0905 05:31:26.693856 90901 solver.cpp:228] Iteration 21580, loss = 0.33158
I0905 05:31:26.693910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33158 (* 1 = 0.33158 loss)
I0905 05:31:26.693923 90901 sgd_solver.cpp:106] Iteration 21580, lr = 0.1
I0905 05:31:32.892205 90901 solver.cpp:228] Iteration 21590, loss = 0.296268
I0905 05:31:32.892258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296268 (* 1 = 0.296268 loss)
I0905 05:31:32.892277 90901 sgd_solver.cpp:106] Iteration 21590, lr = 0.1
I0905 05:31:38.516907 90901 solver.cpp:337] Iteration 21600, Testing net (#0)
I0905 05:32:20.464853 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.7025
I0905 05:32:20.464999 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.657971 (* 1 = 0.657971 loss)
I0905 05:32:20.665860 90901 solver.cpp:228] Iteration 21600, loss = 0.3658
I0905 05:32:20.665897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3658 (* 1 = 0.3658 loss)
I0905 05:32:20.665915 90901 sgd_solver.cpp:106] Iteration 21600, lr = 0.1
I0905 05:32:26.030807 90901 solver.cpp:228] Iteration 21610, loss = 0.371879
I0905 05:32:26.030850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371879 (* 1 = 0.371879 loss)
I0905 05:32:26.030866 90901 sgd_solver.cpp:106] Iteration 21610, lr = 0.1
I0905 05:32:32.127712 90901 solver.cpp:228] Iteration 21620, loss = 0.425097
I0905 05:32:32.127763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425097 (* 1 = 0.425097 loss)
I0905 05:32:32.127777 90901 sgd_solver.cpp:106] Iteration 21620, lr = 0.1
I0905 05:32:38.193403 90901 solver.cpp:228] Iteration 21630, loss = 0.21165
I0905 05:32:38.193462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21165 (* 1 = 0.21165 loss)
I0905 05:32:38.193478 90901 sgd_solver.cpp:106] Iteration 21630, lr = 0.1
I0905 05:32:44.253471 90901 solver.cpp:228] Iteration 21640, loss = 0.202293
I0905 05:32:44.253510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202293 (* 1 = 0.202293 loss)
I0905 05:32:44.253525 90901 sgd_solver.cpp:106] Iteration 21640, lr = 0.1
I0905 05:32:50.302870 90901 solver.cpp:228] Iteration 21650, loss = 0.394061
I0905 05:32:50.302914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39406 (* 1 = 0.39406 loss)
I0905 05:32:50.302928 90901 sgd_solver.cpp:106] Iteration 21650, lr = 0.1
I0905 05:32:56.070924 90901 solver.cpp:228] Iteration 21660, loss = 0.159298
I0905 05:32:56.071161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159298 (* 1 = 0.159298 loss)
I0905 05:32:56.071178 90901 sgd_solver.cpp:106] Iteration 21660, lr = 0.1
I0905 05:33:02.480339 90901 solver.cpp:228] Iteration 21670, loss = 0.530544
I0905 05:33:02.480392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.530544 (* 1 = 0.530544 loss)
I0905 05:33:02.480406 90901 sgd_solver.cpp:106] Iteration 21670, lr = 0.1
I0905 05:33:08.564954 90901 solver.cpp:228] Iteration 21680, loss = 0.188318
I0905 05:33:08.565011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188317 (* 1 = 0.188317 loss)
I0905 05:33:08.565026 90901 sgd_solver.cpp:106] Iteration 21680, lr = 0.1
I0905 05:33:14.687775 90901 solver.cpp:228] Iteration 21690, loss = 0.898418
I0905 05:33:14.687826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.898418 (* 1 = 0.898418 loss)
I0905 05:33:14.687839 90901 sgd_solver.cpp:106] Iteration 21690, lr = 0.1
I0905 05:33:20.777309 90901 solver.cpp:228] Iteration 21700, loss = 0.439633
I0905 05:33:20.777359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439632 (* 1 = 0.439632 loss)
I0905 05:33:20.777379 90901 sgd_solver.cpp:106] Iteration 21700, lr = 0.1
I0905 05:33:27.163547 90901 solver.cpp:228] Iteration 21710, loss = 0.239898
I0905 05:33:27.163719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239897 (* 1 = 0.239897 loss)
I0905 05:33:27.163764 90901 sgd_solver.cpp:106] Iteration 21710, lr = 0.1
I0905 05:33:33.249944 90901 solver.cpp:228] Iteration 21720, loss = 0.489193
I0905 05:33:33.249995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489193 (* 1 = 0.489193 loss)
I0905 05:33:33.250010 90901 sgd_solver.cpp:106] Iteration 21720, lr = 0.1
I0905 05:33:39.546821 90901 solver.cpp:228] Iteration 21730, loss = 0.310022
I0905 05:33:39.546872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310022 (* 1 = 0.310022 loss)
I0905 05:33:39.546886 90901 sgd_solver.cpp:106] Iteration 21730, lr = 0.1
I0905 05:33:45.366282 90901 solver.cpp:228] Iteration 21740, loss = 0.659366
I0905 05:33:45.366336 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.659365 (* 1 = 0.659365 loss)
I0905 05:33:45.366349 90901 sgd_solver.cpp:106] Iteration 21740, lr = 0.1
I0905 05:33:51.431658 90901 solver.cpp:228] Iteration 21750, loss = 0.230225
I0905 05:33:51.431710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230225 (* 1 = 0.230225 loss)
I0905 05:33:51.431723 90901 sgd_solver.cpp:106] Iteration 21750, lr = 0.1
I0905 05:33:57.845176 90901 solver.cpp:228] Iteration 21760, loss = 0.10976
I0905 05:33:57.845376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10976 (* 1 = 0.10976 loss)
I0905 05:33:57.845412 90901 sgd_solver.cpp:106] Iteration 21760, lr = 0.1
I0905 05:34:03.650075 90901 solver.cpp:228] Iteration 21770, loss = 0.159463
I0905 05:34:03.650118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159463 (* 1 = 0.159463 loss)
I0905 05:34:03.650131 90901 sgd_solver.cpp:106] Iteration 21770, lr = 0.1
I0905 05:34:09.212822 90901 solver.cpp:228] Iteration 21780, loss = 0.336623
I0905 05:34:09.212888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336623 (* 1 = 0.336623 loss)
I0905 05:34:09.212904 90901 sgd_solver.cpp:106] Iteration 21780, lr = 0.1
I0905 05:34:14.860872 90901 solver.cpp:228] Iteration 21790, loss = 0.238715
I0905 05:34:14.860927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238714 (* 1 = 0.238714 loss)
I0905 05:34:14.860941 90901 sgd_solver.cpp:106] Iteration 21790, lr = 0.1
I0905 05:34:20.917829 90901 solver.cpp:228] Iteration 21800, loss = 0.273892
I0905 05:34:20.917896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273891 (* 1 = 0.273891 loss)
I0905 05:34:20.917912 90901 sgd_solver.cpp:106] Iteration 21800, lr = 0.1
I0905 05:34:27.188107 90901 solver.cpp:228] Iteration 21810, loss = 0.172832
I0905 05:34:27.188154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172831 (* 1 = 0.172831 loss)
I0905 05:34:27.188168 90901 sgd_solver.cpp:106] Iteration 21810, lr = 0.1
I0905 05:34:33.367461 90901 solver.cpp:228] Iteration 21820, loss = 0.558163
I0905 05:34:33.369858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.558163 (* 1 = 0.558163 loss)
I0905 05:34:33.369874 90901 sgd_solver.cpp:106] Iteration 21820, lr = 0.1
I0905 05:34:39.128579 90901 solver.cpp:228] Iteration 21830, loss = 0.352802
I0905 05:34:39.128630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352801 (* 1 = 0.352801 loss)
I0905 05:34:39.128643 90901 sgd_solver.cpp:106] Iteration 21830, lr = 0.1
I0905 05:34:45.534224 90901 solver.cpp:228] Iteration 21840, loss = 0.301363
I0905 05:34:45.534268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301363 (* 1 = 0.301363 loss)
I0905 05:34:45.534283 90901 sgd_solver.cpp:106] Iteration 21840, lr = 0.1
I0905 05:34:51.593291 90901 solver.cpp:228] Iteration 21850, loss = 0.219359
I0905 05:34:51.593329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219359 (* 1 = 0.219359 loss)
I0905 05:34:51.593343 90901 sgd_solver.cpp:106] Iteration 21850, lr = 0.1
I0905 05:34:57.673871 90901 solver.cpp:228] Iteration 21860, loss = 0.371335
I0905 05:34:57.673925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371334 (* 1 = 0.371334 loss)
I0905 05:34:57.673943 90901 sgd_solver.cpp:106] Iteration 21860, lr = 0.1
I0905 05:35:03.737538 90901 solver.cpp:228] Iteration 21870, loss = 0.589476
I0905 05:35:03.739188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.589475 (* 1 = 0.589475 loss)
I0905 05:35:03.739202 90901 sgd_solver.cpp:106] Iteration 21870, lr = 0.1
I0905 05:35:09.825760 90901 solver.cpp:228] Iteration 21880, loss = 0.271654
I0905 05:35:09.825804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271653 (* 1 = 0.271653 loss)
I0905 05:35:09.825816 90901 sgd_solver.cpp:106] Iteration 21880, lr = 0.1
I0905 05:35:16.217106 90901 solver.cpp:228] Iteration 21890, loss = 0.317806
I0905 05:35:16.217161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317806 (* 1 = 0.317806 loss)
I0905 05:35:16.217175 90901 sgd_solver.cpp:106] Iteration 21890, lr = 0.1
I0905 05:35:22.237628 90901 solver.cpp:228] Iteration 21900, loss = 0.188862
I0905 05:35:22.237681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188862 (* 1 = 0.188862 loss)
I0905 05:35:22.237696 90901 sgd_solver.cpp:106] Iteration 21900, lr = 0.1
I0905 05:35:28.372499 90901 solver.cpp:228] Iteration 21910, loss = 0.390212
I0905 05:35:28.372555 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390212 (* 1 = 0.390212 loss)
I0905 05:35:28.372571 90901 sgd_solver.cpp:106] Iteration 21910, lr = 0.1
I0905 05:35:34.650662 90901 solver.cpp:228] Iteration 21920, loss = 0.201009
I0905 05:35:34.650852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201009 (* 1 = 0.201009 loss)
I0905 05:35:34.650897 90901 sgd_solver.cpp:106] Iteration 21920, lr = 0.1
I0905 05:35:40.758216 90901 solver.cpp:228] Iteration 21930, loss = 0.11912
I0905 05:35:40.758260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11912 (* 1 = 0.11912 loss)
I0905 05:35:40.758272 90901 sgd_solver.cpp:106] Iteration 21930, lr = 0.1
I0905 05:35:46.790988 90901 solver.cpp:228] Iteration 21940, loss = 0.519444
I0905 05:35:46.791039 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519443 (* 1 = 0.519443 loss)
I0905 05:35:46.791054 90901 sgd_solver.cpp:106] Iteration 21940, lr = 0.1
I0905 05:35:52.487771 90901 solver.cpp:228] Iteration 21950, loss = 0.328789
I0905 05:35:52.487836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328789 (* 1 = 0.328789 loss)
I0905 05:35:52.487853 90901 sgd_solver.cpp:106] Iteration 21950, lr = 0.1
I0905 05:35:57.751238 90901 solver.cpp:228] Iteration 21960, loss = 0.103315
I0905 05:35:57.751297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103315 (* 1 = 0.103315 loss)
I0905 05:35:57.751312 90901 sgd_solver.cpp:106] Iteration 21960, lr = 0.1
I0905 05:36:03.657308 90901 solver.cpp:228] Iteration 21970, loss = 0.295019
I0905 05:36:03.657354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295019 (* 1 = 0.295019 loss)
I0905 05:36:03.657367 90901 sgd_solver.cpp:106] Iteration 21970, lr = 0.1
I0905 05:36:09.733523 90901 solver.cpp:228] Iteration 21980, loss = 0.515312
I0905 05:36:09.733750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515312 (* 1 = 0.515312 loss)
I0905 05:36:09.733778 90901 sgd_solver.cpp:106] Iteration 21980, lr = 0.1
I0905 05:36:16.137058 90901 solver.cpp:228] Iteration 21990, loss = 0.486381
I0905 05:36:16.137115 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486381 (* 1 = 0.486381 loss)
I0905 05:36:16.137130 90901 sgd_solver.cpp:106] Iteration 21990, lr = 0.1
I0905 05:36:22.211241 90901 solver.cpp:228] Iteration 22000, loss = 0.669003
I0905 05:36:22.211287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.669003 (* 1 = 0.669003 loss)
I0905 05:36:22.211300 90901 sgd_solver.cpp:106] Iteration 22000, lr = 0.1
I0905 05:36:27.942618 90901 solver.cpp:228] Iteration 22010, loss = 0.459982
I0905 05:36:27.942690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459981 (* 1 = 0.459981 loss)
I0905 05:36:27.942706 90901 sgd_solver.cpp:106] Iteration 22010, lr = 0.1
I0905 05:36:34.349112 90901 solver.cpp:228] Iteration 22020, loss = 0.574662
I0905 05:36:34.349170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.574661 (* 1 = 0.574661 loss)
I0905 05:36:34.349186 90901 sgd_solver.cpp:106] Iteration 22020, lr = 0.1
I0905 05:36:40.430613 90901 solver.cpp:228] Iteration 22030, loss = 0.268852
I0905 05:36:40.430788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268852 (* 1 = 0.268852 loss)
I0905 05:36:40.430819 90901 sgd_solver.cpp:106] Iteration 22030, lr = 0.1
I0905 05:36:46.483093 90901 solver.cpp:228] Iteration 22040, loss = 0.318362
I0905 05:36:46.483139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318361 (* 1 = 0.318361 loss)
I0905 05:36:46.483152 90901 sgd_solver.cpp:106] Iteration 22040, lr = 0.1
I0905 05:36:52.611063 90901 solver.cpp:228] Iteration 22050, loss = 0.803879
I0905 05:36:52.611106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.803879 (* 1 = 0.803879 loss)
I0905 05:36:52.611121 90901 sgd_solver.cpp:106] Iteration 22050, lr = 0.1
I0905 05:36:58.988317 90901 solver.cpp:228] Iteration 22060, loss = 0.441968
I0905 05:36:58.988358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.441968 (* 1 = 0.441968 loss)
I0905 05:36:58.988375 90901 sgd_solver.cpp:106] Iteration 22060, lr = 0.1
I0905 05:37:05.086832 90901 solver.cpp:228] Iteration 22070, loss = 0.502418
I0905 05:37:05.086876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502417 (* 1 = 0.502417 loss)
I0905 05:37:05.086889 90901 sgd_solver.cpp:106] Iteration 22070, lr = 0.1
I0905 05:37:11.138998 90901 solver.cpp:228] Iteration 22080, loss = 0.193068
I0905 05:37:11.139140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193068 (* 1 = 0.193068 loss)
I0905 05:37:11.139185 90901 sgd_solver.cpp:106] Iteration 22080, lr = 0.1
I0905 05:37:17.441164 90901 solver.cpp:228] Iteration 22090, loss = 0.134105
I0905 05:37:17.441216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134105 (* 1 = 0.134105 loss)
I0905 05:37:17.441231 90901 sgd_solver.cpp:106] Iteration 22090, lr = 0.1
I0905 05:37:23.283570 90901 solver.cpp:228] Iteration 22100, loss = 0.431611
I0905 05:37:23.283617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.431611 (* 1 = 0.431611 loss)
I0905 05:37:23.283632 90901 sgd_solver.cpp:106] Iteration 22100, lr = 0.1
I0905 05:37:29.519577 90901 solver.cpp:228] Iteration 22110, loss = 0.417077
I0905 05:37:29.519626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417077 (* 1 = 0.417077 loss)
I0905 05:37:29.519642 90901 sgd_solver.cpp:106] Iteration 22110, lr = 0.1
I0905 05:37:35.743553 90901 solver.cpp:228] Iteration 22120, loss = 0.166145
I0905 05:37:35.743600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166144 (* 1 = 0.166144 loss)
I0905 05:37:35.743615 90901 sgd_solver.cpp:106] Iteration 22120, lr = 0.1
I0905 05:37:41.133582 90901 solver.cpp:228] Iteration 22130, loss = 0.29871
I0905 05:37:41.133641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29871 (* 1 = 0.29871 loss)
I0905 05:37:41.133656 90901 sgd_solver.cpp:106] Iteration 22130, lr = 0.1
I0905 05:37:46.535742 90901 solver.cpp:228] Iteration 22140, loss = 0.90727
I0905 05:37:46.535923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.90727 (* 1 = 0.90727 loss)
I0905 05:37:46.535939 90901 sgd_solver.cpp:106] Iteration 22140, lr = 0.1
I0905 05:37:52.432757 90901 solver.cpp:228] Iteration 22150, loss = 0.167847
I0905 05:37:52.432811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167847 (* 1 = 0.167847 loss)
I0905 05:37:52.432824 90901 sgd_solver.cpp:106] Iteration 22150, lr = 0.1
I0905 05:37:58.480144 90901 solver.cpp:228] Iteration 22160, loss = 0.16471
I0905 05:37:58.480195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16471 (* 1 = 0.16471 loss)
I0905 05:37:58.480211 90901 sgd_solver.cpp:106] Iteration 22160, lr = 0.1
I0905 05:38:04.893731 90901 solver.cpp:228] Iteration 22170, loss = 0.363746
I0905 05:38:04.893792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363746 (* 1 = 0.363746 loss)
I0905 05:38:04.893812 90901 sgd_solver.cpp:106] Iteration 22170, lr = 0.1
I0905 05:38:10.908556 90901 solver.cpp:228] Iteration 22180, loss = 0.408323
I0905 05:38:10.908603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408323 (* 1 = 0.408323 loss)
I0905 05:38:10.908617 90901 sgd_solver.cpp:106] Iteration 22180, lr = 0.1
I0905 05:38:17.045038 90901 solver.cpp:228] Iteration 22190, loss = 0.363971
I0905 05:38:17.045193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36397 (* 1 = 0.36397 loss)
I0905 05:38:17.045222 90901 sgd_solver.cpp:106] Iteration 22190, lr = 0.1
I0905 05:38:23.367243 90901 solver.cpp:228] Iteration 22200, loss = 0.556877
I0905 05:38:23.367285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556877 (* 1 = 0.556877 loss)
I0905 05:38:23.367297 90901 sgd_solver.cpp:106] Iteration 22200, lr = 0.1
I0905 05:38:29.408324 90901 solver.cpp:228] Iteration 22210, loss = 0.828431
I0905 05:38:29.408370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.828431 (* 1 = 0.828431 loss)
I0905 05:38:29.408381 90901 sgd_solver.cpp:106] Iteration 22210, lr = 0.1
I0905 05:38:35.485824 90901 solver.cpp:228] Iteration 22220, loss = 0.166696
I0905 05:38:35.485872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166696 (* 1 = 0.166696 loss)
I0905 05:38:35.485885 90901 sgd_solver.cpp:106] Iteration 22220, lr = 0.1
I0905 05:38:41.549705 90901 solver.cpp:228] Iteration 22230, loss = 0.439582
I0905 05:38:41.549764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439581 (* 1 = 0.439581 loss)
I0905 05:38:41.549782 90901 sgd_solver.cpp:106] Iteration 22230, lr = 0.1
I0905 05:38:47.630081 90901 solver.cpp:228] Iteration 22240, loss = 0.391789
I0905 05:38:47.630278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391788 (* 1 = 0.391788 loss)
I0905 05:38:47.630311 90901 sgd_solver.cpp:106] Iteration 22240, lr = 0.1
I0905 05:38:54.030158 90901 solver.cpp:228] Iteration 22250, loss = 0.132343
I0905 05:38:54.030205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132343 (* 1 = 0.132343 loss)
I0905 05:38:54.030220 90901 sgd_solver.cpp:106] Iteration 22250, lr = 0.1
I0905 05:39:00.054961 90901 solver.cpp:228] Iteration 22260, loss = 0.121119
I0905 05:39:00.055021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121119 (* 1 = 0.121119 loss)
I0905 05:39:00.055037 90901 sgd_solver.cpp:106] Iteration 22260, lr = 0.1
I0905 05:39:05.891360 90901 solver.cpp:228] Iteration 22270, loss = 0.166957
I0905 05:39:05.891409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166957 (* 1 = 0.166957 loss)
I0905 05:39:05.891422 90901 sgd_solver.cpp:106] Iteration 22270, lr = 0.1
I0905 05:39:12.171365 90901 solver.cpp:228] Iteration 22280, loss = 0.902875
I0905 05:39:12.171411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.902875 (* 1 = 0.902875 loss)
I0905 05:39:12.171427 90901 sgd_solver.cpp:106] Iteration 22280, lr = 0.1
I0905 05:39:18.211182 90901 solver.cpp:228] Iteration 22290, loss = 0.285903
I0905 05:39:18.211392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285903 (* 1 = 0.285903 loss)
I0905 05:39:18.211422 90901 sgd_solver.cpp:106] Iteration 22290, lr = 0.1
I0905 05:39:24.298171 90901 solver.cpp:228] Iteration 22300, loss = 0.502237
I0905 05:39:24.298223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502236 (* 1 = 0.502236 loss)
I0905 05:39:24.298238 90901 sgd_solver.cpp:106] Iteration 22300, lr = 0.1
I0905 05:39:29.933135 90901 solver.cpp:228] Iteration 22310, loss = 0.295619
I0905 05:39:29.933176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295619 (* 1 = 0.295619 loss)
I0905 05:39:29.933188 90901 sgd_solver.cpp:106] Iteration 22310, lr = 0.1
I0905 05:39:35.491227 90901 solver.cpp:228] Iteration 22320, loss = 1.00897
I0905 05:39:35.491281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.00897 (* 1 = 1.00897 loss)
I0905 05:39:35.491294 90901 sgd_solver.cpp:106] Iteration 22320, lr = 0.1
I0905 05:39:41.544306 90901 solver.cpp:228] Iteration 22330, loss = 0.505516
I0905 05:39:41.544349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505516 (* 1 = 0.505516 loss)
I0905 05:39:41.544363 90901 sgd_solver.cpp:106] Iteration 22330, lr = 0.1
I0905 05:39:47.585269 90901 solver.cpp:228] Iteration 22340, loss = 0.435481
I0905 05:39:47.585325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435481 (* 1 = 0.435481 loss)
I0905 05:39:47.585343 90901 sgd_solver.cpp:106] Iteration 22340, lr = 0.1
I0905 05:39:53.629544 90901 solver.cpp:228] Iteration 22350, loss = 0.176752
I0905 05:39:53.629696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176752 (* 1 = 0.176752 loss)
I0905 05:39:53.629757 90901 sgd_solver.cpp:106] Iteration 22350, lr = 0.1
I0905 05:39:59.732974 90901 solver.cpp:228] Iteration 22360, loss = 0.286146
I0905 05:39:59.733021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286146 (* 1 = 0.286146 loss)
I0905 05:39:59.733033 90901 sgd_solver.cpp:106] Iteration 22360, lr = 0.1
I0905 05:40:05.787839 90901 solver.cpp:228] Iteration 22370, loss = 0.194151
I0905 05:40:05.787884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194151 (* 1 = 0.194151 loss)
I0905 05:40:05.787897 90901 sgd_solver.cpp:106] Iteration 22370, lr = 0.1
I0905 05:40:11.861248 90901 solver.cpp:228] Iteration 22380, loss = 0.299749
I0905 05:40:11.861294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299749 (* 1 = 0.299749 loss)
I0905 05:40:11.861310 90901 sgd_solver.cpp:106] Iteration 22380, lr = 0.1
I0905 05:40:17.983932 90901 solver.cpp:228] Iteration 22390, loss = 0.209985
I0905 05:40:17.983985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209985 (* 1 = 0.209985 loss)
I0905 05:40:17.983999 90901 sgd_solver.cpp:106] Iteration 22390, lr = 0.1
I0905 05:40:23.831558 90901 solver.cpp:337] Iteration 22400, Testing net (#0)
I0905 05:41:06.233536 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.815313
I0905 05:41:06.233687 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.399012 (* 1 = 0.399012 loss)
I0905 05:41:06.465205 90901 solver.cpp:228] Iteration 22400, loss = 0.231879
I0905 05:41:06.465232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231878 (* 1 = 0.231878 loss)
I0905 05:41:06.465248 90901 sgd_solver.cpp:106] Iteration 22400, lr = 0.1
I0905 05:41:12.479171 90901 solver.cpp:228] Iteration 22410, loss = 0.134971
I0905 05:41:12.479221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134971 (* 1 = 0.134971 loss)
I0905 05:41:12.479236 90901 sgd_solver.cpp:106] Iteration 22410, lr = 0.1
I0905 05:41:18.141706 90901 solver.cpp:228] Iteration 22420, loss = 0.453619
I0905 05:41:18.141751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453619 (* 1 = 0.453619 loss)
I0905 05:41:18.141765 90901 sgd_solver.cpp:106] Iteration 22420, lr = 0.1
I0905 05:41:23.396086 90901 solver.cpp:228] Iteration 22430, loss = 0.308562
I0905 05:41:23.396136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308562 (* 1 = 0.308562 loss)
I0905 05:41:23.396148 90901 sgd_solver.cpp:106] Iteration 22430, lr = 0.1
I0905 05:41:29.447434 90901 solver.cpp:228] Iteration 22440, loss = 0.572533
I0905 05:41:29.447484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572533 (* 1 = 0.572533 loss)
I0905 05:41:29.447497 90901 sgd_solver.cpp:106] Iteration 22440, lr = 0.1
I0905 05:41:35.866003 90901 solver.cpp:228] Iteration 22450, loss = 0.17543
I0905 05:41:35.866051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175429 (* 1 = 0.175429 loss)
I0905 05:41:35.866068 90901 sgd_solver.cpp:106] Iteration 22450, lr = 0.1
I0905 05:41:41.800113 90901 solver.cpp:228] Iteration 22460, loss = 0.216384
I0905 05:41:41.800273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216384 (* 1 = 0.216384 loss)
I0905 05:41:41.800302 90901 sgd_solver.cpp:106] Iteration 22460, lr = 0.1
I0905 05:41:47.717401 90901 solver.cpp:228] Iteration 22470, loss = 0.226259
I0905 05:41:47.717460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226258 (* 1 = 0.226258 loss)
I0905 05:41:47.717475 90901 sgd_solver.cpp:106] Iteration 22470, lr = 0.1
I0905 05:41:54.102035 90901 solver.cpp:228] Iteration 22480, loss = 0.605423
I0905 05:41:54.102090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.605423 (* 1 = 0.605423 loss)
I0905 05:41:54.102105 90901 sgd_solver.cpp:106] Iteration 22480, lr = 0.1
I0905 05:42:00.159396 90901 solver.cpp:228] Iteration 22490, loss = 0.205194
I0905 05:42:00.159456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205193 (* 1 = 0.205193 loss)
I0905 05:42:00.159471 90901 sgd_solver.cpp:106] Iteration 22490, lr = 0.1
I0905 05:42:06.230761 90901 solver.cpp:228] Iteration 22500, loss = 0.421648
I0905 05:42:06.230804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421648 (* 1 = 0.421648 loss)
I0905 05:42:06.230819 90901 sgd_solver.cpp:106] Iteration 22500, lr = 0.1
I0905 05:42:12.318025 90901 solver.cpp:228] Iteration 22510, loss = 0.206624
I0905 05:42:12.318174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206624 (* 1 = 0.206624 loss)
I0905 05:42:12.318214 90901 sgd_solver.cpp:106] Iteration 22510, lr = 0.1
I0905 05:42:18.412098 90901 solver.cpp:228] Iteration 22520, loss = 0.221228
I0905 05:42:18.412161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221228 (* 1 = 0.221228 loss)
I0905 05:42:18.412178 90901 sgd_solver.cpp:106] Iteration 22520, lr = 0.1
I0905 05:42:24.476892 90901 solver.cpp:228] Iteration 22530, loss = 0.340743
I0905 05:42:24.476938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340743 (* 1 = 0.340743 loss)
I0905 05:42:24.476950 90901 sgd_solver.cpp:106] Iteration 22530, lr = 0.1
I0905 05:42:30.866724 90901 solver.cpp:228] Iteration 22540, loss = 0.166535
I0905 05:42:30.866772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166535 (* 1 = 0.166535 loss)
I0905 05:42:30.866786 90901 sgd_solver.cpp:106] Iteration 22540, lr = 0.1
I0905 05:42:36.443740 90901 solver.cpp:228] Iteration 22550, loss = 0.49576
I0905 05:42:36.443785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.49576 (* 1 = 0.49576 loss)
I0905 05:42:36.443799 90901 sgd_solver.cpp:106] Iteration 22550, lr = 0.1
I0905 05:42:43.023366 90901 solver.cpp:228] Iteration 22560, loss = 0.211391
I0905 05:42:43.023574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211391 (* 1 = 0.211391 loss)
I0905 05:42:43.023603 90901 sgd_solver.cpp:106] Iteration 22560, lr = 0.1
I0905 05:42:49.058713 90901 solver.cpp:228] Iteration 22570, loss = 0.729449
I0905 05:42:49.058797 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.729449 (* 1 = 0.729449 loss)
I0905 05:42:49.058812 90901 sgd_solver.cpp:106] Iteration 22570, lr = 0.1
I0905 05:42:55.142608 90901 solver.cpp:228] Iteration 22580, loss = 0.127575
I0905 05:42:55.142680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127575 (* 1 = 0.127575 loss)
I0905 05:42:55.142696 90901 sgd_solver.cpp:106] Iteration 22580, lr = 0.1
I0905 05:43:01.122376 90901 solver.cpp:228] Iteration 22590, loss = 0.400243
I0905 05:43:01.122421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400242 (* 1 = 0.400242 loss)
I0905 05:43:01.122433 90901 sgd_solver.cpp:106] Iteration 22590, lr = 0.1
I0905 05:43:06.690340 90901 solver.cpp:228] Iteration 22600, loss = 0.288113
I0905 05:43:06.690381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288113 (* 1 = 0.288113 loss)
I0905 05:43:06.690393 90901 sgd_solver.cpp:106] Iteration 22600, lr = 0.1
I0905 05:43:12.052036 90901 solver.cpp:228] Iteration 22610, loss = 0.172737
I0905 05:43:12.052078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172737 (* 1 = 0.172737 loss)
I0905 05:43:12.052090 90901 sgd_solver.cpp:106] Iteration 22610, lr = 0.1
I0905 05:43:18.121490 90901 solver.cpp:228] Iteration 22620, loss = 0.174703
I0905 05:43:18.121636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174703 (* 1 = 0.174703 loss)
I0905 05:43:18.121681 90901 sgd_solver.cpp:106] Iteration 22620, lr = 0.1
I0905 05:43:24.190795 90901 solver.cpp:228] Iteration 22630, loss = 0.64165
I0905 05:43:24.190847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64165 (* 1 = 0.64165 loss)
I0905 05:43:24.190860 90901 sgd_solver.cpp:106] Iteration 22630, lr = 0.1
I0905 05:43:30.467964 90901 solver.cpp:228] Iteration 22640, loss = 0.178373
I0905 05:43:30.468008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178373 (* 1 = 0.178373 loss)
I0905 05:43:30.468021 90901 sgd_solver.cpp:106] Iteration 22640, lr = 0.1
I0905 05:43:36.411196 90901 solver.cpp:228] Iteration 22650, loss = 0.114893
I0905 05:43:36.411239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114893 (* 1 = 0.114893 loss)
I0905 05:43:36.411253 90901 sgd_solver.cpp:106] Iteration 22650, lr = 0.1
I0905 05:43:42.676120 90901 solver.cpp:228] Iteration 22660, loss = 1.29926
I0905 05:43:42.676158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.29926 (* 1 = 1.29926 loss)
I0905 05:43:42.676177 90901 sgd_solver.cpp:106] Iteration 22660, lr = 0.1
I0905 05:43:48.731350 90901 solver.cpp:228] Iteration 22670, loss = 0.312898
I0905 05:43:48.731488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312898 (* 1 = 0.312898 loss)
I0905 05:43:48.731546 90901 sgd_solver.cpp:106] Iteration 22670, lr = 0.1
I0905 05:43:54.807423 90901 solver.cpp:228] Iteration 22680, loss = 0.244845
I0905 05:43:54.807469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244844 (* 1 = 0.244844 loss)
I0905 05:43:54.807483 90901 sgd_solver.cpp:106] Iteration 22680, lr = 0.1
I0905 05:44:00.915027 90901 solver.cpp:228] Iteration 22690, loss = 0.390961
I0905 05:44:00.915071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390961 (* 1 = 0.390961 loss)
I0905 05:44:00.915084 90901 sgd_solver.cpp:106] Iteration 22690, lr = 0.1
I0905 05:44:07.148373 90901 solver.cpp:228] Iteration 22700, loss = 0.384088
I0905 05:44:07.148421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384087 (* 1 = 0.384087 loss)
I0905 05:44:07.148435 90901 sgd_solver.cpp:106] Iteration 22700, lr = 0.1
I0905 05:44:13.324024 90901 solver.cpp:228] Iteration 22710, loss = 0.416023
I0905 05:44:13.324074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416023 (* 1 = 0.416023 loss)
I0905 05:44:13.324086 90901 sgd_solver.cpp:106] Iteration 22710, lr = 0.1
I0905 05:44:19.405303 90901 solver.cpp:228] Iteration 22720, loss = 0.567058
I0905 05:44:19.405515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.567058 (* 1 = 0.567058 loss)
I0905 05:44:19.405555 90901 sgd_solver.cpp:106] Iteration 22720, lr = 0.1
I0905 05:44:25.483610 90901 solver.cpp:228] Iteration 22730, loss = 0.350678
I0905 05:44:25.483661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350678 (* 1 = 0.350678 loss)
I0905 05:44:25.483675 90901 sgd_solver.cpp:106] Iteration 22730, lr = 0.1
I0905 05:44:31.569149 90901 solver.cpp:228] Iteration 22740, loss = 0.227186
I0905 05:44:31.569195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227186 (* 1 = 0.227186 loss)
I0905 05:44:31.569208 90901 sgd_solver.cpp:106] Iteration 22740, lr = 0.1
I0905 05:44:37.636492 90901 solver.cpp:228] Iteration 22750, loss = 0.211852
I0905 05:44:37.636539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211851 (* 1 = 0.211851 loss)
I0905 05:44:37.636553 90901 sgd_solver.cpp:106] Iteration 22750, lr = 0.1
I0905 05:44:43.688079 90901 solver.cpp:228] Iteration 22760, loss = 0.190233
I0905 05:44:43.688128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190233 (* 1 = 0.190233 loss)
I0905 05:44:43.688143 90901 sgd_solver.cpp:106] Iteration 22760, lr = 0.1
I0905 05:44:49.671378 90901 solver.cpp:228] Iteration 22770, loss = 0.391163
I0905 05:44:49.671571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391163 (* 1 = 0.391163 loss)
I0905 05:44:49.671617 90901 sgd_solver.cpp:106] Iteration 22770, lr = 0.1
I0905 05:44:55.239642 90901 solver.cpp:228] Iteration 22780, loss = 0.39466
I0905 05:44:55.239714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39466 (* 1 = 0.39466 loss)
I0905 05:44:55.239730 90901 sgd_solver.cpp:106] Iteration 22780, lr = 0.1
I0905 05:45:00.711558 90901 solver.cpp:228] Iteration 22790, loss = 0.350021
I0905 05:45:00.711609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350021 (* 1 = 0.350021 loss)
I0905 05:45:00.711623 90901 sgd_solver.cpp:106] Iteration 22790, lr = 0.1
I0905 05:45:06.792313 90901 solver.cpp:228] Iteration 22800, loss = 0.401897
I0905 05:45:06.792371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401897 (* 1 = 0.401897 loss)
I0905 05:45:06.792387 90901 sgd_solver.cpp:106] Iteration 22800, lr = 0.1
I0905 05:45:12.837173 90901 solver.cpp:228] Iteration 22810, loss = 0.285569
I0905 05:45:12.837211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285569 (* 1 = 0.285569 loss)
I0905 05:45:12.837224 90901 sgd_solver.cpp:106] Iteration 22810, lr = 0.1
I0905 05:45:19.117432 90901 solver.cpp:228] Iteration 22820, loss = 0.245937
I0905 05:45:19.117475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245937 (* 1 = 0.245937 loss)
I0905 05:45:19.117487 90901 sgd_solver.cpp:106] Iteration 22820, lr = 0.1
I0905 05:45:25.314416 90901 solver.cpp:228] Iteration 22830, loss = 0.492695
I0905 05:45:25.314543 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492695 (* 1 = 0.492695 loss)
I0905 05:45:25.314570 90901 sgd_solver.cpp:106] Iteration 22830, lr = 0.1
I0905 05:45:31.417419 90901 solver.cpp:228] Iteration 22840, loss = 0.25624
I0905 05:45:31.417466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25624 (* 1 = 0.25624 loss)
I0905 05:45:31.417482 90901 sgd_solver.cpp:106] Iteration 22840, lr = 0.1
I0905 05:45:37.472417 90901 solver.cpp:228] Iteration 22850, loss = 0.334023
I0905 05:45:37.472476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334023 (* 1 = 0.334023 loss)
I0905 05:45:37.472491 90901 sgd_solver.cpp:106] Iteration 22850, lr = 0.1
I0905 05:45:43.538283 90901 solver.cpp:228] Iteration 22860, loss = 0.610704
I0905 05:45:43.538327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.610704 (* 1 = 0.610704 loss)
I0905 05:45:43.538341 90901 sgd_solver.cpp:106] Iteration 22860, lr = 0.1
I0905 05:45:49.925258 90901 solver.cpp:228] Iteration 22870, loss = 0.239667
I0905 05:45:49.925304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239666 (* 1 = 0.239666 loss)
I0905 05:45:49.925318 90901 sgd_solver.cpp:106] Iteration 22870, lr = 0.1
I0905 05:45:55.999017 90901 solver.cpp:228] Iteration 22880, loss = 0.568233
I0905 05:45:55.999203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.568233 (* 1 = 0.568233 loss)
I0905 05:45:55.999218 90901 sgd_solver.cpp:106] Iteration 22880, lr = 0.1
I0905 05:46:02.076424 90901 solver.cpp:228] Iteration 22890, loss = 0.344146
I0905 05:46:02.076483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344145 (* 1 = 0.344145 loss)
I0905 05:46:02.076495 90901 sgd_solver.cpp:106] Iteration 22890, lr = 0.1
I0905 05:46:08.413197 90901 solver.cpp:228] Iteration 22900, loss = 0.225363
I0905 05:46:08.413261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225363 (* 1 = 0.225363 loss)
I0905 05:46:08.413277 90901 sgd_solver.cpp:106] Iteration 22900, lr = 0.1
I0905 05:46:14.200789 90901 solver.cpp:228] Iteration 22910, loss = 0.067291
I0905 05:46:14.200845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0672908 (* 1 = 0.0672908 loss)
I0905 05:46:14.200860 90901 sgd_solver.cpp:106] Iteration 22910, lr = 0.1
I0905 05:46:20.267562 90901 solver.cpp:228] Iteration 22920, loss = 0.178719
I0905 05:46:20.267608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178719 (* 1 = 0.178719 loss)
I0905 05:46:20.267622 90901 sgd_solver.cpp:106] Iteration 22920, lr = 0.1
I0905 05:46:26.627332 90901 solver.cpp:228] Iteration 22930, loss = 0.394632
I0905 05:46:26.627583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394632 (* 1 = 0.394632 loss)
I0905 05:46:26.627600 90901 sgd_solver.cpp:106] Iteration 22930, lr = 0.1
I0905 05:46:32.379708 90901 solver.cpp:228] Iteration 22940, loss = 0.423788
I0905 05:46:32.379750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423788 (* 1 = 0.423788 loss)
I0905 05:46:32.379762 90901 sgd_solver.cpp:106] Iteration 22940, lr = 0.1
I0905 05:46:37.359365 90901 solver.cpp:228] Iteration 22950, loss = 0.300944
I0905 05:46:37.359408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300944 (* 1 = 0.300944 loss)
I0905 05:46:37.359423 90901 sgd_solver.cpp:106] Iteration 22950, lr = 0.1
I0905 05:46:42.004151 90901 solver.cpp:228] Iteration 22960, loss = 0.135687
I0905 05:46:42.004195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135687 (* 1 = 0.135687 loss)
I0905 05:46:42.004209 90901 sgd_solver.cpp:106] Iteration 22960, lr = 0.1
I0905 05:46:46.657078 90901 solver.cpp:228] Iteration 22970, loss = 0.274329
I0905 05:46:46.657146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274329 (* 1 = 0.274329 loss)
I0905 05:46:46.657162 90901 sgd_solver.cpp:106] Iteration 22970, lr = 0.1
I0905 05:46:51.609817 90901 solver.cpp:228] Iteration 22980, loss = 0.308692
I0905 05:46:51.609860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308692 (* 1 = 0.308692 loss)
I0905 05:46:51.609872 90901 sgd_solver.cpp:106] Iteration 22980, lr = 0.1
I0905 05:46:56.693300 90901 solver.cpp:228] Iteration 22990, loss = 0.799784
I0905 05:46:56.693442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.799784 (* 1 = 0.799784 loss)
I0905 05:46:56.693487 90901 sgd_solver.cpp:106] Iteration 22990, lr = 0.1
I0905 05:47:01.738625 90901 solver.cpp:228] Iteration 23000, loss = 0.457824
I0905 05:47:01.738672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457824 (* 1 = 0.457824 loss)
I0905 05:47:01.738687 90901 sgd_solver.cpp:106] Iteration 23000, lr = 0.1
I0905 05:47:06.790359 90901 solver.cpp:228] Iteration 23010, loss = 0.42593
I0905 05:47:06.790421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42593 (* 1 = 0.42593 loss)
I0905 05:47:06.790436 90901 sgd_solver.cpp:106] Iteration 23010, lr = 0.1
I0905 05:47:11.805702 90901 solver.cpp:228] Iteration 23020, loss = 0.178263
I0905 05:47:11.805755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178263 (* 1 = 0.178263 loss)
I0905 05:47:11.805769 90901 sgd_solver.cpp:106] Iteration 23020, lr = 0.1
I0905 05:47:16.856024 90901 solver.cpp:228] Iteration 23030, loss = 0.258622
I0905 05:47:16.856084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258622 (* 1 = 0.258622 loss)
I0905 05:47:16.856099 90901 sgd_solver.cpp:106] Iteration 23030, lr = 0.1
I0905 05:47:21.913126 90901 solver.cpp:228] Iteration 23040, loss = 0.155701
I0905 05:47:21.913169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155701 (* 1 = 0.155701 loss)
I0905 05:47:21.913182 90901 sgd_solver.cpp:106] Iteration 23040, lr = 0.1
I0905 05:47:26.961802 90901 solver.cpp:228] Iteration 23050, loss = 0.208438
I0905 05:47:26.961997 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208438 (* 1 = 0.208438 loss)
I0905 05:47:26.962024 90901 sgd_solver.cpp:106] Iteration 23050, lr = 0.1
I0905 05:47:32.025168 90901 solver.cpp:228] Iteration 23060, loss = 0.211046
I0905 05:47:32.025212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211045 (* 1 = 0.211045 loss)
I0905 05:47:32.025224 90901 sgd_solver.cpp:106] Iteration 23060, lr = 0.1
I0905 05:47:37.083894 90901 solver.cpp:228] Iteration 23070, loss = 0.164563
I0905 05:47:37.083988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164562 (* 1 = 0.164562 loss)
I0905 05:47:37.084003 90901 sgd_solver.cpp:106] Iteration 23070, lr = 0.1
I0905 05:47:42.148525 90901 solver.cpp:228] Iteration 23080, loss = 0.187603
I0905 05:47:42.148586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187603 (* 1 = 0.187603 loss)
I0905 05:47:42.148600 90901 sgd_solver.cpp:106] Iteration 23080, lr = 0.1
I0905 05:47:47.198909 90901 solver.cpp:228] Iteration 23090, loss = 0.57085
I0905 05:47:47.198956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.57085 (* 1 = 0.57085 loss)
I0905 05:47:47.198968 90901 sgd_solver.cpp:106] Iteration 23090, lr = 0.1
I0905 05:47:52.233495 90901 solver.cpp:228] Iteration 23100, loss = 0.249083
I0905 05:47:52.233551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249083 (* 1 = 0.249083 loss)
I0905 05:47:52.233566 90901 sgd_solver.cpp:106] Iteration 23100, lr = 0.1
I0905 05:47:57.973197 90901 solver.cpp:228] Iteration 23110, loss = 0.152875
I0905 05:47:57.973320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152875 (* 1 = 0.152875 loss)
I0905 05:47:57.973335 90901 sgd_solver.cpp:106] Iteration 23110, lr = 0.1
I0905 05:48:04.052196 90901 solver.cpp:228] Iteration 23120, loss = 0.159057
I0905 05:48:04.052240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159056 (* 1 = 0.159056 loss)
I0905 05:48:04.052253 90901 sgd_solver.cpp:106] Iteration 23120, lr = 0.1
I0905 05:48:10.145696 90901 solver.cpp:228] Iteration 23130, loss = 0.360137
I0905 05:48:10.145738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360136 (* 1 = 0.360136 loss)
I0905 05:48:10.145752 90901 sgd_solver.cpp:106] Iteration 23130, lr = 0.1
I0905 05:48:16.193902 90901 solver.cpp:228] Iteration 23140, loss = 0.188004
I0905 05:48:16.193958 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188004 (* 1 = 0.188004 loss)
I0905 05:48:16.193970 90901 sgd_solver.cpp:106] Iteration 23140, lr = 0.1
I0905 05:48:22.301941 90901 solver.cpp:228] Iteration 23150, loss = 0.223478
I0905 05:48:22.301986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223478 (* 1 = 0.223478 loss)
I0905 05:48:22.302000 90901 sgd_solver.cpp:106] Iteration 23150, lr = 0.1
I0905 05:48:28.684608 90901 solver.cpp:228] Iteration 23160, loss = 0.749474
I0905 05:48:28.684797 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.749474 (* 1 = 0.749474 loss)
I0905 05:48:28.684814 90901 sgd_solver.cpp:106] Iteration 23160, lr = 0.1
I0905 05:48:33.948117 90901 solver.cpp:228] Iteration 23170, loss = 0.389114
I0905 05:48:33.948160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389114 (* 1 = 0.389114 loss)
I0905 05:48:33.948173 90901 sgd_solver.cpp:106] Iteration 23170, lr = 0.1
I0905 05:48:39.324000 90901 solver.cpp:228] Iteration 23180, loss = 0.396809
I0905 05:48:39.324054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396808 (* 1 = 0.396808 loss)
I0905 05:48:39.324069 90901 sgd_solver.cpp:106] Iteration 23180, lr = 0.1
I0905 05:48:45.689992 90901 solver.cpp:228] Iteration 23190, loss = 0.23107
I0905 05:48:45.690035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23107 (* 1 = 0.23107 loss)
I0905 05:48:45.690048 90901 sgd_solver.cpp:106] Iteration 23190, lr = 0.1
I0905 05:48:51.199908 90901 solver.cpp:337] Iteration 23200, Testing net (#0)
I0905 05:49:33.650687 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.790937
I0905 05:49:33.650892 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.454995 (* 1 = 0.454995 loss)
I0905 05:49:33.867189 90901 solver.cpp:228] Iteration 23200, loss = 0.21695
I0905 05:49:33.867238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21695 (* 1 = 0.21695 loss)
I0905 05:49:33.867256 90901 sgd_solver.cpp:106] Iteration 23200, lr = 0.1
I0905 05:49:39.943840 90901 solver.cpp:228] Iteration 23210, loss = 0.501539
I0905 05:49:39.943892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501539 (* 1 = 0.501539 loss)
I0905 05:49:39.943904 90901 sgd_solver.cpp:106] Iteration 23210, lr = 0.1
I0905 05:49:46.338920 90901 solver.cpp:228] Iteration 23220, loss = 0.432022
I0905 05:49:46.338968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432022 (* 1 = 0.432022 loss)
I0905 05:49:46.338981 90901 sgd_solver.cpp:106] Iteration 23220, lr = 0.1
I0905 05:49:52.410444 90901 solver.cpp:228] Iteration 23230, loss = 0.207239
I0905 05:49:52.410493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207239 (* 1 = 0.207239 loss)
I0905 05:49:52.410506 90901 sgd_solver.cpp:106] Iteration 23230, lr = 0.1
I0905 05:49:58.483928 90901 solver.cpp:228] Iteration 23240, loss = 0.250822
I0905 05:49:58.483973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250822 (* 1 = 0.250822 loss)
I0905 05:49:58.483989 90901 sgd_solver.cpp:106] Iteration 23240, lr = 0.1
I0905 05:50:04.568155 90901 solver.cpp:228] Iteration 23250, loss = 0.332815
I0905 05:50:04.568285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332815 (* 1 = 0.332815 loss)
I0905 05:50:04.568317 90901 sgd_solver.cpp:106] Iteration 23250, lr = 0.1
I0905 05:50:10.931658 90901 solver.cpp:228] Iteration 23260, loss = 0.224071
I0905 05:50:10.931709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224071 (* 1 = 0.224071 loss)
I0905 05:50:10.931722 90901 sgd_solver.cpp:106] Iteration 23260, lr = 0.1
I0905 05:50:16.928524 90901 solver.cpp:228] Iteration 23270, loss = 0.357572
I0905 05:50:16.928588 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357572 (* 1 = 0.357572 loss)
I0905 05:50:16.928604 90901 sgd_solver.cpp:106] Iteration 23270, lr = 0.1
I0905 05:50:22.389041 90901 solver.cpp:228] Iteration 23280, loss = 0.298852
I0905 05:50:22.389101 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298852 (* 1 = 0.298852 loss)
I0905 05:50:22.389117 90901 sgd_solver.cpp:106] Iteration 23280, lr = 0.1
I0905 05:50:27.848222 90901 solver.cpp:228] Iteration 23290, loss = 0.261032
I0905 05:50:27.848263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261032 (* 1 = 0.261032 loss)
I0905 05:50:27.848276 90901 sgd_solver.cpp:106] Iteration 23290, lr = 0.1
I0905 05:50:33.595782 90901 solver.cpp:228] Iteration 23300, loss = 0.350655
I0905 05:50:33.595824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350654 (* 1 = 0.350654 loss)
I0905 05:50:33.595835 90901 sgd_solver.cpp:106] Iteration 23300, lr = 0.1
I0905 05:50:39.650156 90901 solver.cpp:228] Iteration 23310, loss = 0.478787
I0905 05:50:39.650363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478787 (* 1 = 0.478787 loss)
I0905 05:50:39.650393 90901 sgd_solver.cpp:106] Iteration 23310, lr = 0.1
I0905 05:50:45.758467 90901 solver.cpp:228] Iteration 23320, loss = 0.296756
I0905 05:50:45.758530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296756 (* 1 = 0.296756 loss)
I0905 05:50:45.758545 90901 sgd_solver.cpp:106] Iteration 23320, lr = 0.1
I0905 05:50:51.875696 90901 solver.cpp:228] Iteration 23330, loss = 0.397542
I0905 05:50:51.875753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397542 (* 1 = 0.397542 loss)
I0905 05:50:51.875766 90901 sgd_solver.cpp:106] Iteration 23330, lr = 0.1
I0905 05:50:58.182971 90901 solver.cpp:228] Iteration 23340, loss = 0.417241
I0905 05:50:58.183010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417241 (* 1 = 0.417241 loss)
I0905 05:50:58.183022 90901 sgd_solver.cpp:106] Iteration 23340, lr = 0.1
I0905 05:51:04.225397 90901 solver.cpp:228] Iteration 23350, loss = 0.503789
I0905 05:51:04.225437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.503789 (* 1 = 0.503789 loss)
I0905 05:51:04.225450 90901 sgd_solver.cpp:106] Iteration 23350, lr = 0.1
I0905 05:51:10.340965 90901 solver.cpp:228] Iteration 23360, loss = 0.330029
I0905 05:51:10.341136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330029 (* 1 = 0.330029 loss)
I0905 05:51:10.341164 90901 sgd_solver.cpp:106] Iteration 23360, lr = 0.1
I0905 05:51:16.404561 90901 solver.cpp:228] Iteration 23370, loss = 0.46698
I0905 05:51:16.404619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46698 (* 1 = 0.46698 loss)
I0905 05:51:16.404633 90901 sgd_solver.cpp:106] Iteration 23370, lr = 0.1
I0905 05:51:22.639384 90901 solver.cpp:228] Iteration 23380, loss = 0.217916
I0905 05:51:22.639454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217916 (* 1 = 0.217916 loss)
I0905 05:51:22.639470 90901 sgd_solver.cpp:106] Iteration 23380, lr = 0.1
I0905 05:51:28.870120 90901 solver.cpp:228] Iteration 23390, loss = 0.209507
I0905 05:51:28.870185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209506 (* 1 = 0.209506 loss)
I0905 05:51:28.870200 90901 sgd_solver.cpp:106] Iteration 23390, lr = 0.1
I0905 05:51:34.959681 90901 solver.cpp:228] Iteration 23400, loss = 0.37079
I0905 05:51:34.959733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37079 (* 1 = 0.37079 loss)
I0905 05:51:34.959746 90901 sgd_solver.cpp:106] Iteration 23400, lr = 0.1
I0905 05:51:41.048173 90901 solver.cpp:228] Iteration 23410, loss = 0.329588
I0905 05:51:41.048372 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329588 (* 1 = 0.329588 loss)
I0905 05:51:41.048419 90901 sgd_solver.cpp:106] Iteration 23410, lr = 0.1
I0905 05:51:46.826831 90901 solver.cpp:228] Iteration 23420, loss = 0.305936
I0905 05:51:46.826889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305935 (* 1 = 0.305935 loss)
I0905 05:51:46.826903 90901 sgd_solver.cpp:106] Iteration 23420, lr = 0.1
I0905 05:51:53.252383 90901 solver.cpp:228] Iteration 23430, loss = 0.244063
I0905 05:51:53.252434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244063 (* 1 = 0.244063 loss)
I0905 05:51:53.252447 90901 sgd_solver.cpp:106] Iteration 23430, lr = 0.1
I0905 05:51:59.299875 90901 solver.cpp:228] Iteration 23440, loss = 0.399675
I0905 05:51:59.299921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399674 (* 1 = 0.399674 loss)
I0905 05:51:59.299933 90901 sgd_solver.cpp:106] Iteration 23440, lr = 0.1
I0905 05:52:05.199064 90901 solver.cpp:228] Iteration 23450, loss = 0.480764
I0905 05:52:05.199108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480763 (* 1 = 0.480763 loss)
I0905 05:52:05.199121 90901 sgd_solver.cpp:106] Iteration 23450, lr = 0.1
I0905 05:52:10.479776 90901 solver.cpp:228] Iteration 23460, loss = 0.449125
I0905 05:52:10.479837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449125 (* 1 = 0.449125 loss)
I0905 05:52:10.479852 90901 sgd_solver.cpp:106] Iteration 23460, lr = 0.1
I0905 05:52:16.372514 90901 solver.cpp:228] Iteration 23470, loss = 0.106212
I0905 05:52:16.372668 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106212 (* 1 = 0.106212 loss)
I0905 05:52:16.372683 90901 sgd_solver.cpp:106] Iteration 23470, lr = 0.1
I0905 05:52:22.120174 90901 solver.cpp:228] Iteration 23480, loss = 0.259717
I0905 05:52:22.120224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259717 (* 1 = 0.259717 loss)
I0905 05:52:22.120239 90901 sgd_solver.cpp:106] Iteration 23480, lr = 0.1
I0905 05:52:28.388557 90901 solver.cpp:228] Iteration 23490, loss = 0.542062
I0905 05:52:28.388604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.542062 (* 1 = 0.542062 loss)
I0905 05:52:28.388619 90901 sgd_solver.cpp:106] Iteration 23490, lr = 0.1
I0905 05:52:34.325522 90901 solver.cpp:228] Iteration 23500, loss = 0.208415
I0905 05:52:34.325570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208415 (* 1 = 0.208415 loss)
I0905 05:52:34.325582 90901 sgd_solver.cpp:106] Iteration 23500, lr = 0.1
I0905 05:52:40.652632 90901 solver.cpp:228] Iteration 23510, loss = 0.328096
I0905 05:52:40.652673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328096 (* 1 = 0.328096 loss)
I0905 05:52:40.652686 90901 sgd_solver.cpp:106] Iteration 23510, lr = 0.1
I0905 05:52:46.745234 90901 solver.cpp:228] Iteration 23520, loss = 0.253334
I0905 05:52:46.745285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253334 (* 1 = 0.253334 loss)
I0905 05:52:46.745297 90901 sgd_solver.cpp:106] Iteration 23520, lr = 0.1
I0905 05:52:52.479367 90901 solver.cpp:228] Iteration 23530, loss = 0.625926
I0905 05:52:52.479419 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.625926 (* 1 = 0.625926 loss)
I0905 05:52:52.479434 90901 sgd_solver.cpp:106] Iteration 23530, lr = 0.1
I0905 05:52:58.864555 90901 solver.cpp:228] Iteration 23540, loss = 0.237811
I0905 05:52:58.864599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237811 (* 1 = 0.237811 loss)
I0905 05:52:58.864612 90901 sgd_solver.cpp:106] Iteration 23540, lr = 0.1
I0905 05:53:04.952793 90901 solver.cpp:228] Iteration 23550, loss = 0.259172
I0905 05:53:04.952832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259172 (* 1 = 0.259172 loss)
I0905 05:53:04.952846 90901 sgd_solver.cpp:106] Iteration 23550, lr = 0.1
I0905 05:53:11.313896 90901 solver.cpp:228] Iteration 23560, loss = 0.103798
I0905 05:53:11.313941 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103798 (* 1 = 0.103798 loss)
I0905 05:53:11.313954 90901 sgd_solver.cpp:106] Iteration 23560, lr = 0.1
I0905 05:53:17.423606 90901 solver.cpp:228] Iteration 23570, loss = 0.131614
I0905 05:53:17.423753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131613 (* 1 = 0.131613 loss)
I0905 05:53:17.423817 90901 sgd_solver.cpp:106] Iteration 23570, lr = 0.1
I0905 05:53:23.501562 90901 solver.cpp:228] Iteration 23580, loss = 0.113471
I0905 05:53:23.501607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11347 (* 1 = 0.11347 loss)
I0905 05:53:23.501621 90901 sgd_solver.cpp:106] Iteration 23580, lr = 0.1
I0905 05:53:29.246357 90901 solver.cpp:228] Iteration 23590, loss = 0.459947
I0905 05:53:29.246400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459947 (* 1 = 0.459947 loss)
I0905 05:53:29.246412 90901 sgd_solver.cpp:106] Iteration 23590, lr = 0.1
I0905 05:53:35.668969 90901 solver.cpp:228] Iteration 23600, loss = 0.158424
I0905 05:53:35.669010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158423 (* 1 = 0.158423 loss)
I0905 05:53:35.669023 90901 sgd_solver.cpp:106] Iteration 23600, lr = 0.1
I0905 05:53:41.419925 90901 solver.cpp:228] Iteration 23610, loss = 0.448852
I0905 05:53:41.419970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448852 (* 1 = 0.448852 loss)
I0905 05:53:41.419984 90901 sgd_solver.cpp:106] Iteration 23610, lr = 0.1
I0905 05:53:47.515771 90901 solver.cpp:228] Iteration 23620, loss = 0.236793
I0905 05:53:47.515939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236792 (* 1 = 0.236792 loss)
I0905 05:53:47.515954 90901 sgd_solver.cpp:106] Iteration 23620, lr = 0.1
I0905 05:53:53.418789 90901 solver.cpp:228] Iteration 23630, loss = 0.468835
I0905 05:53:53.418843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468835 (* 1 = 0.468835 loss)
I0905 05:53:53.418859 90901 sgd_solver.cpp:106] Iteration 23630, lr = 0.1
I0905 05:53:58.755748 90901 solver.cpp:228] Iteration 23640, loss = 0.385479
I0905 05:53:58.755792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385479 (* 1 = 0.385479 loss)
I0905 05:53:58.755806 90901 sgd_solver.cpp:106] Iteration 23640, lr = 0.1
I0905 05:54:04.482178 90901 solver.cpp:228] Iteration 23650, loss = 0.409738
I0905 05:54:04.482220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409738 (* 1 = 0.409738 loss)
I0905 05:54:04.482231 90901 sgd_solver.cpp:106] Iteration 23650, lr = 0.1
I0905 05:54:10.249939 90901 solver.cpp:228] Iteration 23660, loss = 0.572257
I0905 05:54:10.249984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572257 (* 1 = 0.572257 loss)
I0905 05:54:10.249997 90901 sgd_solver.cpp:106] Iteration 23660, lr = 0.1
I0905 05:54:16.734519 90901 solver.cpp:228] Iteration 23670, loss = 0.266355
I0905 05:54:16.734568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266355 (* 1 = 0.266355 loss)
I0905 05:54:16.734581 90901 sgd_solver.cpp:106] Iteration 23670, lr = 0.1
I0905 05:54:22.997583 90901 solver.cpp:228] Iteration 23680, loss = 0.189262
I0905 05:54:22.997771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189262 (* 1 = 0.189262 loss)
I0905 05:54:22.997825 90901 sgd_solver.cpp:106] Iteration 23680, lr = 0.1
I0905 05:54:29.021540 90901 solver.cpp:228] Iteration 23690, loss = 0.466307
I0905 05:54:29.021582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.466307 (* 1 = 0.466307 loss)
I0905 05:54:29.021595 90901 sgd_solver.cpp:106] Iteration 23690, lr = 0.1
I0905 05:54:35.102126 90901 solver.cpp:228] Iteration 23700, loss = 0.395587
I0905 05:54:35.102171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395587 (* 1 = 0.395587 loss)
I0905 05:54:35.102185 90901 sgd_solver.cpp:106] Iteration 23700, lr = 0.1
I0905 05:54:41.173254 90901 solver.cpp:228] Iteration 23710, loss = 0.221368
I0905 05:54:41.173306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221368 (* 1 = 0.221368 loss)
I0905 05:54:41.173319 90901 sgd_solver.cpp:106] Iteration 23710, lr = 0.1
I0905 05:54:47.248690 90901 solver.cpp:228] Iteration 23720, loss = 0.590862
I0905 05:54:47.248735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.590862 (* 1 = 0.590862 loss)
I0905 05:54:47.248750 90901 sgd_solver.cpp:106] Iteration 23720, lr = 0.1
I0905 05:54:53.462303 90901 solver.cpp:228] Iteration 23730, loss = 0.193101
I0905 05:54:53.462467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193101 (* 1 = 0.193101 loss)
I0905 05:54:53.462507 90901 sgd_solver.cpp:106] Iteration 23730, lr = 0.1
I0905 05:54:59.416589 90901 solver.cpp:228] Iteration 23740, loss = 0.259321
I0905 05:54:59.416622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259321 (* 1 = 0.259321 loss)
I0905 05:54:59.416635 90901 sgd_solver.cpp:106] Iteration 23740, lr = 0.1
I0905 05:55:05.552309 90901 solver.cpp:228] Iteration 23750, loss = 0.262268
I0905 05:55:05.552353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262268 (* 1 = 0.262268 loss)
I0905 05:55:05.552367 90901 sgd_solver.cpp:106] Iteration 23750, lr = 0.1
I0905 05:55:11.872259 90901 solver.cpp:228] Iteration 23760, loss = 0.254581
I0905 05:55:11.872304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254581 (* 1 = 0.254581 loss)
I0905 05:55:11.872318 90901 sgd_solver.cpp:106] Iteration 23760, lr = 0.1
I0905 05:55:17.930893 90901 solver.cpp:228] Iteration 23770, loss = 0.315272
I0905 05:55:17.930940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315272 (* 1 = 0.315272 loss)
I0905 05:55:17.930953 90901 sgd_solver.cpp:106] Iteration 23770, lr = 0.1
I0905 05:55:23.983716 90901 solver.cpp:228] Iteration 23780, loss = 0.247718
I0905 05:55:23.983911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247718 (* 1 = 0.247718 loss)
I0905 05:55:23.983950 90901 sgd_solver.cpp:106] Iteration 23780, lr = 0.1
I0905 05:55:30.068830 90901 solver.cpp:228] Iteration 23790, loss = 0.244948
I0905 05:55:30.068889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244948 (* 1 = 0.244948 loss)
I0905 05:55:30.068902 90901 sgd_solver.cpp:106] Iteration 23790, lr = 0.1
I0905 05:55:36.133225 90901 solver.cpp:228] Iteration 23800, loss = 0.180828
I0905 05:55:36.133272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180828 (* 1 = 0.180828 loss)
I0905 05:55:36.133285 90901 sgd_solver.cpp:106] Iteration 23800, lr = 0.1
I0905 05:55:41.725543 90901 solver.cpp:228] Iteration 23810, loss = 0.448823
I0905 05:55:41.725599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448823 (* 1 = 0.448823 loss)
I0905 05:55:41.725612 90901 sgd_solver.cpp:106] Iteration 23810, lr = 0.1
I0905 05:55:47.372689 90901 solver.cpp:228] Iteration 23820, loss = 0.242608
I0905 05:55:47.372733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242608 (* 1 = 0.242608 loss)
I0905 05:55:47.372747 90901 sgd_solver.cpp:106] Iteration 23820, lr = 0.1
I0905 05:55:53.467882 90901 solver.cpp:228] Iteration 23830, loss = 0.2532
I0905 05:55:53.467932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2532 (* 1 = 0.2532 loss)
I0905 05:55:53.467950 90901 sgd_solver.cpp:106] Iteration 23830, lr = 0.1
I0905 05:55:59.548905 90901 solver.cpp:228] Iteration 23840, loss = 0.354251
I0905 05:55:59.549062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354251 (* 1 = 0.354251 loss)
I0905 05:55:59.549085 90901 sgd_solver.cpp:106] Iteration 23840, lr = 0.1
I0905 05:56:05.836585 90901 solver.cpp:228] Iteration 23850, loss = 0.152424
I0905 05:56:05.836640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152424 (* 1 = 0.152424 loss)
I0905 05:56:05.836655 90901 sgd_solver.cpp:106] Iteration 23850, lr = 0.1
I0905 05:56:11.635680 90901 solver.cpp:228] Iteration 23860, loss = 0.295483
I0905 05:56:11.635735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295483 (* 1 = 0.295483 loss)
I0905 05:56:11.635749 90901 sgd_solver.cpp:106] Iteration 23860, lr = 0.1
I0905 05:56:17.706740 90901 solver.cpp:228] Iteration 23870, loss = 0.206252
I0905 05:56:17.706801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206252 (* 1 = 0.206252 loss)
I0905 05:56:17.706815 90901 sgd_solver.cpp:106] Iteration 23870, lr = 0.1
I0905 05:56:23.748991 90901 solver.cpp:228] Iteration 23880, loss = 0.222277
I0905 05:56:23.749037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222277 (* 1 = 0.222277 loss)
I0905 05:56:23.749050 90901 sgd_solver.cpp:106] Iteration 23880, lr = 0.1
I0905 05:56:30.042343 90901 solver.cpp:228] Iteration 23890, loss = 0.383065
I0905 05:56:30.042479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383065 (* 1 = 0.383065 loss)
I0905 05:56:30.042524 90901 sgd_solver.cpp:106] Iteration 23890, lr = 0.1
I0905 05:56:36.214663 90901 solver.cpp:228] Iteration 23900, loss = 0.436084
I0905 05:56:36.214715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436084 (* 1 = 0.436084 loss)
I0905 05:56:36.214730 90901 sgd_solver.cpp:106] Iteration 23900, lr = 0.1
I0905 05:56:41.989403 90901 solver.cpp:228] Iteration 23910, loss = 0.303346
I0905 05:56:41.989452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303346 (* 1 = 0.303346 loss)
I0905 05:56:41.989465 90901 sgd_solver.cpp:106] Iteration 23910, lr = 0.1
I0905 05:56:48.359248 90901 solver.cpp:228] Iteration 23920, loss = 0.845488
I0905 05:56:48.359292 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.845488 (* 1 = 0.845488 loss)
I0905 05:56:48.359304 90901 sgd_solver.cpp:106] Iteration 23920, lr = 0.1
I0905 05:56:54.430312 90901 solver.cpp:228] Iteration 23930, loss = 0.282034
I0905 05:56:54.430359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282034 (* 1 = 0.282034 loss)
I0905 05:56:54.430372 90901 sgd_solver.cpp:106] Iteration 23930, lr = 0.1
I0905 05:57:00.551537 90901 solver.cpp:228] Iteration 23940, loss = 0.517667
I0905 05:57:00.551748 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.517667 (* 1 = 0.517667 loss)
I0905 05:57:00.551784 90901 sgd_solver.cpp:106] Iteration 23940, lr = 0.1
I0905 05:57:06.623966 90901 solver.cpp:228] Iteration 23950, loss = 0.219311
I0905 05:57:06.624016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219311 (* 1 = 0.219311 loss)
I0905 05:57:06.624028 90901 sgd_solver.cpp:106] Iteration 23950, lr = 0.1
I0905 05:57:13.004731 90901 solver.cpp:228] Iteration 23960, loss = 0.206178
I0905 05:57:13.004802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206178 (* 1 = 0.206178 loss)
I0905 05:57:13.004819 90901 sgd_solver.cpp:106] Iteration 23960, lr = 0.1
I0905 05:57:19.076952 90901 solver.cpp:228] Iteration 23970, loss = 0.36294
I0905 05:57:19.077005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36294 (* 1 = 0.36294 loss)
I0905 05:57:19.077019 90901 sgd_solver.cpp:106] Iteration 23970, lr = 0.1
I0905 05:57:24.984153 90901 solver.cpp:228] Iteration 23980, loss = 0.113536
I0905 05:57:24.984213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113536 (* 1 = 0.113536 loss)
I0905 05:57:24.984226 90901 sgd_solver.cpp:106] Iteration 23980, lr = 0.1
I0905 05:57:30.236460 90901 solver.cpp:228] Iteration 23990, loss = 0.665211
I0905 05:57:30.236521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.665211 (* 1 = 0.665211 loss)
I0905 05:57:30.236549 90901 sgd_solver.cpp:106] Iteration 23990, lr = 0.1
I0905 05:57:35.792438 90901 solver.cpp:337] Iteration 24000, Testing net (#0)
I0905 05:58:18.240144 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.70625
I0905 05:58:18.240288 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.645082 (* 1 = 0.645082 loss)
I0905 05:58:18.771898 90901 solver.cpp:228] Iteration 24000, loss = 0.681155
I0905 05:58:18.771935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.681155 (* 1 = 0.681155 loss)
I0905 05:58:18.771952 90901 sgd_solver.cpp:106] Iteration 24000, lr = 0.1
I0905 05:58:24.409584 90901 solver.cpp:228] Iteration 24010, loss = 0.632319
I0905 05:58:24.409638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.632319 (* 1 = 0.632319 loss)
I0905 05:58:24.409652 90901 sgd_solver.cpp:106] Iteration 24010, lr = 0.1
I0905 05:58:30.584297 90901 solver.cpp:228] Iteration 24020, loss = 0.139129
I0905 05:58:30.584342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139129 (* 1 = 0.139129 loss)
I0905 05:58:30.584355 90901 sgd_solver.cpp:106] Iteration 24020, lr = 0.1
I0905 05:58:36.661120 90901 solver.cpp:228] Iteration 24030, loss = 0.387734
I0905 05:58:36.661170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387734 (* 1 = 0.387734 loss)
I0905 05:58:36.661185 90901 sgd_solver.cpp:106] Iteration 24030, lr = 0.1
I0905 05:58:43.047740 90901 solver.cpp:228] Iteration 24040, loss = 0.289126
I0905 05:58:43.047780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289126 (* 1 = 0.289126 loss)
I0905 05:58:43.047792 90901 sgd_solver.cpp:106] Iteration 24040, lr = 0.1
I0905 05:58:48.825397 90901 solver.cpp:228] Iteration 24050, loss = 0.290043
I0905 05:58:48.825598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290043 (* 1 = 0.290043 loss)
I0905 05:58:48.825624 90901 sgd_solver.cpp:106] Iteration 24050, lr = 0.1
I0905 05:58:54.928061 90901 solver.cpp:228] Iteration 24060, loss = 0.269662
I0905 05:58:54.928104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269662 (* 1 = 0.269662 loss)
I0905 05:58:54.928117 90901 sgd_solver.cpp:106] Iteration 24060, lr = 0.1
I0905 05:59:01.307999 90901 solver.cpp:228] Iteration 24070, loss = 0.217493
I0905 05:59:01.308044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217493 (* 1 = 0.217493 loss)
I0905 05:59:01.308060 90901 sgd_solver.cpp:106] Iteration 24070, lr = 0.1
I0905 05:59:07.390672 90901 solver.cpp:228] Iteration 24080, loss = 0.327613
I0905 05:59:07.390722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327613 (* 1 = 0.327613 loss)
I0905 05:59:07.390736 90901 sgd_solver.cpp:106] Iteration 24080, lr = 0.1
I0905 05:59:13.266536 90901 solver.cpp:228] Iteration 24090, loss = 0.503431
I0905 05:59:13.266585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.503431 (* 1 = 0.503431 loss)
I0905 05:59:13.266597 90901 sgd_solver.cpp:106] Iteration 24090, lr = 0.1
I0905 05:59:18.529202 90901 solver.cpp:228] Iteration 24100, loss = 0.104955
I0905 05:59:18.529247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104955 (* 1 = 0.104955 loss)
I0905 05:59:18.529261 90901 sgd_solver.cpp:106] Iteration 24100, lr = 0.1
I0905 05:59:24.371310 90901 solver.cpp:228] Iteration 24110, loss = 0.214597
I0905 05:59:24.371502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214597 (* 1 = 0.214597 loss)
I0905 05:59:24.371520 90901 sgd_solver.cpp:106] Iteration 24110, lr = 0.1
I0905 05:59:30.444509 90901 solver.cpp:228] Iteration 24120, loss = 0.18518
I0905 05:59:30.444557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185181 (* 1 = 0.185181 loss)
I0905 05:59:30.444569 90901 sgd_solver.cpp:106] Iteration 24120, lr = 0.1
I0905 05:59:36.203485 90901 solver.cpp:228] Iteration 24130, loss = 0.104166
I0905 05:59:36.203536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104166 (* 1 = 0.104166 loss)
I0905 05:59:36.203549 90901 sgd_solver.cpp:106] Iteration 24130, lr = 0.1
I0905 05:59:42.578150 90901 solver.cpp:228] Iteration 24140, loss = 0.151672
I0905 05:59:42.578188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151672 (* 1 = 0.151672 loss)
I0905 05:59:42.578205 90901 sgd_solver.cpp:106] Iteration 24140, lr = 0.1
I0905 05:59:48.538841 90901 solver.cpp:228] Iteration 24150, loss = 0.376131
I0905 05:59:48.538890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376131 (* 1 = 0.376131 loss)
I0905 05:59:48.538903 90901 sgd_solver.cpp:106] Iteration 24150, lr = 0.1
I0905 05:59:54.782511 90901 solver.cpp:228] Iteration 24160, loss = 0.412702
I0905 05:59:54.782678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412702 (* 1 = 0.412702 loss)
I0905 05:59:54.782737 90901 sgd_solver.cpp:106] Iteration 24160, lr = 0.1
I0905 06:00:00.844669 90901 solver.cpp:228] Iteration 24170, loss = 0.384829
I0905 06:00:00.844717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38483 (* 1 = 0.38483 loss)
I0905 06:00:00.844732 90901 sgd_solver.cpp:106] Iteration 24170, lr = 0.1
I0905 06:00:06.953656 90901 solver.cpp:228] Iteration 24180, loss = 0.294402
I0905 06:00:06.953708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294402 (* 1 = 0.294402 loss)
I0905 06:00:06.953724 90901 sgd_solver.cpp:106] Iteration 24180, lr = 0.1
I0905 06:00:13.046115 90901 solver.cpp:228] Iteration 24190, loss = 0.55187
I0905 06:00:13.046164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.551871 (* 1 = 0.551871 loss)
I0905 06:00:13.046176 90901 sgd_solver.cpp:106] Iteration 24190, lr = 0.1
I0905 06:00:19.197150 90901 solver.cpp:228] Iteration 24200, loss = 0.119583
I0905 06:00:19.197196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119583 (* 1 = 0.119583 loss)
I0905 06:00:19.197209 90901 sgd_solver.cpp:106] Iteration 24200, lr = 0.1
I0905 06:00:25.523473 90901 solver.cpp:228] Iteration 24210, loss = 0.240872
I0905 06:00:25.523694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240872 (* 1 = 0.240872 loss)
I0905 06:00:25.523710 90901 sgd_solver.cpp:106] Iteration 24210, lr = 0.1
I0905 06:00:31.604899 90901 solver.cpp:228] Iteration 24220, loss = 0.27701
I0905 06:00:31.604956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277011 (* 1 = 0.277011 loss)
I0905 06:00:31.604975 90901 sgd_solver.cpp:106] Iteration 24220, lr = 0.1
I0905 06:00:37.864673 90901 solver.cpp:228] Iteration 24230, loss = 0.219969
I0905 06:00:37.864718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219969 (* 1 = 0.219969 loss)
I0905 06:00:37.864732 90901 sgd_solver.cpp:106] Iteration 24230, lr = 0.1
I0905 06:00:43.695672 90901 solver.cpp:228] Iteration 24240, loss = 0.493244
I0905 06:00:43.695720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493244 (* 1 = 0.493244 loss)
I0905 06:00:43.695735 90901 sgd_solver.cpp:106] Iteration 24240, lr = 0.1
I0905 06:00:50.048324 90901 solver.cpp:228] Iteration 24250, loss = 0.245753
I0905 06:00:50.048375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245753 (* 1 = 0.245753 loss)
I0905 06:00:50.048388 90901 sgd_solver.cpp:106] Iteration 24250, lr = 0.1
I0905 06:00:56.117172 90901 solver.cpp:228] Iteration 24260, loss = 0.561399
I0905 06:00:56.117316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.561399 (* 1 = 0.561399 loss)
I0905 06:00:56.117354 90901 sgd_solver.cpp:106] Iteration 24260, lr = 0.1
I0905 06:01:01.846710 90901 solver.cpp:228] Iteration 24270, loss = 0.326181
I0905 06:01:01.846766 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326182 (* 1 = 0.326182 loss)
I0905 06:01:01.846778 90901 sgd_solver.cpp:106] Iteration 24270, lr = 0.1
I0905 06:01:07.109908 90901 solver.cpp:228] Iteration 24280, loss = 0.523163
I0905 06:01:07.109953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523163 (* 1 = 0.523163 loss)
I0905 06:01:07.109967 90901 sgd_solver.cpp:106] Iteration 24280, lr = 0.1
I0905 06:01:12.772099 90901 solver.cpp:228] Iteration 24290, loss = 0.168784
I0905 06:01:12.772158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168785 (* 1 = 0.168785 loss)
I0905 06:01:12.772172 90901 sgd_solver.cpp:106] Iteration 24290, lr = 0.1
I0905 06:01:19.141094 90901 solver.cpp:228] Iteration 24300, loss = 0.302541
I0905 06:01:19.141139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302542 (* 1 = 0.302542 loss)
I0905 06:01:19.141154 90901 sgd_solver.cpp:106] Iteration 24300, lr = 0.1
I0905 06:01:25.215257 90901 solver.cpp:228] Iteration 24310, loss = 0.26905
I0905 06:01:25.215317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26905 (* 1 = 0.26905 loss)
I0905 06:01:25.215332 90901 sgd_solver.cpp:106] Iteration 24310, lr = 0.1
I0905 06:01:31.639380 90901 solver.cpp:228] Iteration 24320, loss = 0.659596
I0905 06:01:31.639533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.659597 (* 1 = 0.659597 loss)
I0905 06:01:31.639569 90901 sgd_solver.cpp:106] Iteration 24320, lr = 0.1
I0905 06:01:37.722903 90901 solver.cpp:228] Iteration 24330, loss = 0.687868
I0905 06:01:37.722940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.687868 (* 1 = 0.687868 loss)
I0905 06:01:37.722952 90901 sgd_solver.cpp:106] Iteration 24330, lr = 0.1
I0905 06:01:43.534557 90901 solver.cpp:228] Iteration 24340, loss = 0.270459
I0905 06:01:43.534603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270459 (* 1 = 0.270459 loss)
I0905 06:01:43.534618 90901 sgd_solver.cpp:106] Iteration 24340, lr = 0.1
I0905 06:01:49.840162 90901 solver.cpp:228] Iteration 24350, loss = 0.434764
I0905 06:01:49.840214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434765 (* 1 = 0.434765 loss)
I0905 06:01:49.840227 90901 sgd_solver.cpp:106] Iteration 24350, lr = 0.1
I0905 06:01:56.224591 90901 solver.cpp:228] Iteration 24360, loss = 0.0562356
I0905 06:01:56.224638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0562358 (* 1 = 0.0562358 loss)
I0905 06:01:56.224653 90901 sgd_solver.cpp:106] Iteration 24360, lr = 0.1
I0905 06:02:02.294031 90901 solver.cpp:228] Iteration 24370, loss = 0.806504
I0905 06:02:02.294239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.806505 (* 1 = 0.806505 loss)
I0905 06:02:02.294292 90901 sgd_solver.cpp:106] Iteration 24370, lr = 0.1
I0905 06:02:08.334450 90901 solver.cpp:228] Iteration 24380, loss = 0.434455
I0905 06:02:08.334497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434456 (* 1 = 0.434456 loss)
I0905 06:02:08.334511 90901 sgd_solver.cpp:106] Iteration 24380, lr = 0.1
I0905 06:02:14.748560 90901 solver.cpp:228] Iteration 24390, loss = 0.41606
I0905 06:02:14.748615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41606 (* 1 = 0.41606 loss)
I0905 06:02:14.748628 90901 sgd_solver.cpp:106] Iteration 24390, lr = 0.1
I0905 06:02:20.821987 90901 solver.cpp:228] Iteration 24400, loss = 0.396044
I0905 06:02:20.822036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396044 (* 1 = 0.396044 loss)
I0905 06:02:20.822048 90901 sgd_solver.cpp:106] Iteration 24400, lr = 0.1
I0905 06:02:26.903470 90901 solver.cpp:228] Iteration 24410, loss = 0.763712
I0905 06:02:26.903512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.763713 (* 1 = 0.763713 loss)
I0905 06:02:26.903524 90901 sgd_solver.cpp:106] Iteration 24410, lr = 0.1
I0905 06:02:32.962461 90901 solver.cpp:228] Iteration 24420, loss = 0.271352
I0905 06:02:32.962590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271353 (* 1 = 0.271353 loss)
I0905 06:02:32.962616 90901 sgd_solver.cpp:106] Iteration 24420, lr = 0.1
I0905 06:02:39.364683 90901 solver.cpp:228] Iteration 24430, loss = 0.379076
I0905 06:02:39.364725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379076 (* 1 = 0.379076 loss)
I0905 06:02:39.364738 90901 sgd_solver.cpp:106] Iteration 24430, lr = 0.1
I0905 06:02:45.395254 90901 solver.cpp:228] Iteration 24440, loss = 0.144689
I0905 06:02:45.395298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14469 (* 1 = 0.14469 loss)
I0905 06:02:45.395311 90901 sgd_solver.cpp:106] Iteration 24440, lr = 0.1
I0905 06:02:51.072402 90901 solver.cpp:228] Iteration 24450, loss = 0.139328
I0905 06:02:51.072448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139329 (* 1 = 0.139329 loss)
I0905 06:02:51.072459 90901 sgd_solver.cpp:106] Iteration 24450, lr = 0.1
I0905 06:02:56.392864 90901 solver.cpp:228] Iteration 24460, loss = 0.131543
I0905 06:02:56.392902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131543 (* 1 = 0.131543 loss)
I0905 06:02:56.392916 90901 sgd_solver.cpp:106] Iteration 24460, lr = 0.1
I0905 06:03:02.427445 90901 solver.cpp:228] Iteration 24470, loss = 0.210641
I0905 06:03:02.427496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210642 (* 1 = 0.210642 loss)
I0905 06:03:02.427510 90901 sgd_solver.cpp:106] Iteration 24470, lr = 0.1
I0905 06:03:08.481096 90901 solver.cpp:228] Iteration 24480, loss = 0.231521
I0905 06:03:08.481256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231521 (* 1 = 0.231521 loss)
I0905 06:03:08.481297 90901 sgd_solver.cpp:106] Iteration 24480, lr = 0.1
I0905 06:03:14.574657 90901 solver.cpp:228] Iteration 24490, loss = 0.387123
I0905 06:03:14.574710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387123 (* 1 = 0.387123 loss)
I0905 06:03:14.574723 90901 sgd_solver.cpp:106] Iteration 24490, lr = 0.1
I0905 06:03:20.904760 90901 solver.cpp:228] Iteration 24500, loss = 0.166702
I0905 06:03:20.904813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166702 (* 1 = 0.166702 loss)
I0905 06:03:20.904825 90901 sgd_solver.cpp:106] Iteration 24500, lr = 0.1
I0905 06:03:26.991164 90901 solver.cpp:228] Iteration 24510, loss = 0.362203
I0905 06:03:26.991209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362204 (* 1 = 0.362204 loss)
I0905 06:03:26.991224 90901 sgd_solver.cpp:106] Iteration 24510, lr = 0.1
I0905 06:03:33.085635 90901 solver.cpp:228] Iteration 24520, loss = 0.136616
I0905 06:03:33.085681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136616 (* 1 = 0.136616 loss)
I0905 06:03:33.085696 90901 sgd_solver.cpp:106] Iteration 24520, lr = 0.1
I0905 06:03:39.480586 90901 solver.cpp:228] Iteration 24530, loss = 0.182269
I0905 06:03:39.480821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182269 (* 1 = 0.182269 loss)
I0905 06:03:39.480839 90901 sgd_solver.cpp:106] Iteration 24530, lr = 0.1
I0905 06:03:45.318312 90901 solver.cpp:228] Iteration 24540, loss = 0.589085
I0905 06:03:45.318361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.589085 (* 1 = 0.589085 loss)
I0905 06:03:45.318374 90901 sgd_solver.cpp:106] Iteration 24540, lr = 0.1
I0905 06:03:51.610792 90901 solver.cpp:228] Iteration 24550, loss = 0.118237
I0905 06:03:51.610836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118237 (* 1 = 0.118237 loss)
I0905 06:03:51.610847 90901 sgd_solver.cpp:106] Iteration 24550, lr = 0.1
I0905 06:03:57.665088 90901 solver.cpp:228] Iteration 24560, loss = 0.427171
I0905 06:03:57.665134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427171 (* 1 = 0.427171 loss)
I0905 06:03:57.665149 90901 sgd_solver.cpp:106] Iteration 24560, lr = 0.1
I0905 06:04:03.734390 90901 solver.cpp:228] Iteration 24570, loss = 0.166227
I0905 06:04:03.734443 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166227 (* 1 = 0.166227 loss)
I0905 06:04:03.734457 90901 sgd_solver.cpp:106] Iteration 24570, lr = 0.1
I0905 06:04:09.822492 90901 solver.cpp:228] Iteration 24580, loss = 0.25406
I0905 06:04:09.822660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254061 (* 1 = 0.254061 loss)
I0905 06:04:09.822677 90901 sgd_solver.cpp:106] Iteration 24580, lr = 0.1
I0905 06:04:16.197196 90901 solver.cpp:228] Iteration 24590, loss = 0.126767
I0905 06:04:16.197250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126768 (* 1 = 0.126768 loss)
I0905 06:04:16.197264 90901 sgd_solver.cpp:106] Iteration 24590, lr = 0.1
I0905 06:04:21.586984 90901 solver.cpp:228] Iteration 24600, loss = 0.212959
I0905 06:04:21.587028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212959 (* 1 = 0.212959 loss)
I0905 06:04:21.587040 90901 sgd_solver.cpp:106] Iteration 24600, lr = 0.1
I0905 06:04:26.652555 90901 solver.cpp:228] Iteration 24610, loss = 0.384318
I0905 06:04:26.652598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384319 (* 1 = 0.384319 loss)
I0905 06:04:26.652617 90901 sgd_solver.cpp:106] Iteration 24610, lr = 0.1
I0905 06:04:31.712694 90901 solver.cpp:228] Iteration 24620, loss = 0.365142
I0905 06:04:31.712740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365143 (* 1 = 0.365143 loss)
I0905 06:04:31.712754 90901 sgd_solver.cpp:106] Iteration 24620, lr = 0.1
I0905 06:04:36.590883 90901 solver.cpp:228] Iteration 24630, loss = 0.156106
I0905 06:04:36.590930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156106 (* 1 = 0.156106 loss)
I0905 06:04:36.590945 90901 sgd_solver.cpp:106] Iteration 24630, lr = 0.1
I0905 06:04:41.235373 90901 solver.cpp:228] Iteration 24640, loss = 0.171318
I0905 06:04:41.235584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171319 (* 1 = 0.171319 loss)
I0905 06:04:41.235601 90901 sgd_solver.cpp:106] Iteration 24640, lr = 0.1
I0905 06:04:45.884785 90901 solver.cpp:228] Iteration 24650, loss = 0.394409
I0905 06:04:45.884835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394409 (* 1 = 0.394409 loss)
I0905 06:04:45.884847 90901 sgd_solver.cpp:106] Iteration 24650, lr = 0.1
I0905 06:04:50.875767 90901 solver.cpp:228] Iteration 24660, loss = 0.110727
I0905 06:04:50.875814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110728 (* 1 = 0.110728 loss)
I0905 06:04:50.875833 90901 sgd_solver.cpp:106] Iteration 24660, lr = 0.1
I0905 06:04:55.910807 90901 solver.cpp:228] Iteration 24670, loss = 0.312626
I0905 06:04:55.910856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312626 (* 1 = 0.312626 loss)
I0905 06:04:55.910869 90901 sgd_solver.cpp:106] Iteration 24670, lr = 0.1
I0905 06:05:00.931452 90901 solver.cpp:228] Iteration 24680, loss = 0.197112
I0905 06:05:00.931502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197112 (* 1 = 0.197112 loss)
I0905 06:05:00.931519 90901 sgd_solver.cpp:106] Iteration 24680, lr = 0.1
I0905 06:05:05.965977 90901 solver.cpp:228] Iteration 24690, loss = 0.239579
I0905 06:05:05.966017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239579 (* 1 = 0.239579 loss)
I0905 06:05:05.966030 90901 sgd_solver.cpp:106] Iteration 24690, lr = 0.1
I0905 06:05:11.063817 90901 solver.cpp:228] Iteration 24700, loss = 0.205306
I0905 06:05:11.063864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205306 (* 1 = 0.205306 loss)
I0905 06:05:11.063879 90901 sgd_solver.cpp:106] Iteration 24700, lr = 0.1
I0905 06:05:16.164739 90901 solver.cpp:228] Iteration 24710, loss = 0.537499
I0905 06:05:16.164954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.537499 (* 1 = 0.537499 loss)
I0905 06:05:16.164988 90901 sgd_solver.cpp:106] Iteration 24710, lr = 0.1
I0905 06:05:21.225868 90901 solver.cpp:228] Iteration 24720, loss = 0.380122
I0905 06:05:21.225908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380123 (* 1 = 0.380123 loss)
I0905 06:05:21.225922 90901 sgd_solver.cpp:106] Iteration 24720, lr = 0.1
I0905 06:05:26.310304 90901 solver.cpp:228] Iteration 24730, loss = 0.15858
I0905 06:05:26.310351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158581 (* 1 = 0.158581 loss)
I0905 06:05:26.310366 90901 sgd_solver.cpp:106] Iteration 24730, lr = 0.1
I0905 06:05:31.343811 90901 solver.cpp:228] Iteration 24740, loss = 0.286674
I0905 06:05:31.343868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286675 (* 1 = 0.286675 loss)
I0905 06:05:31.343883 90901 sgd_solver.cpp:106] Iteration 24740, lr = 0.1
I0905 06:05:36.394465 90901 solver.cpp:228] Iteration 24750, loss = 0.271718
I0905 06:05:36.394532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271718 (* 1 = 0.271718 loss)
I0905 06:05:36.394548 90901 sgd_solver.cpp:106] Iteration 24750, lr = 0.1
I0905 06:05:41.466271 90901 solver.cpp:228] Iteration 24760, loss = 0.223697
I0905 06:05:41.466341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223697 (* 1 = 0.223697 loss)
I0905 06:05:41.466358 90901 sgd_solver.cpp:106] Iteration 24760, lr = 0.1
I0905 06:05:47.200544 90901 solver.cpp:228] Iteration 24770, loss = 0.0767276
I0905 06:05:47.200714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.076728 (* 1 = 0.076728 loss)
I0905 06:05:47.200748 90901 sgd_solver.cpp:106] Iteration 24770, lr = 0.1
I0905 06:05:53.288074 90901 solver.cpp:228] Iteration 24780, loss = 0.67885
I0905 06:05:53.288141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.67885 (* 1 = 0.67885 loss)
I0905 06:05:53.288156 90901 sgd_solver.cpp:106] Iteration 24780, lr = 0.1
I0905 06:05:59.325554 90901 solver.cpp:228] Iteration 24790, loss = 0.107928
I0905 06:05:59.325615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107929 (* 1 = 0.107929 loss)
I0905 06:05:59.325630 90901 sgd_solver.cpp:106] Iteration 24790, lr = 0.1
I0905 06:06:05.195660 90901 solver.cpp:337] Iteration 24800, Testing net (#0)
I0905 06:06:46.362329 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.81625
I0905 06:06:46.362526 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.411183 (* 1 = 0.411183 loss)
I0905 06:06:46.590279 90901 solver.cpp:228] Iteration 24800, loss = 0.696059
I0905 06:06:46.590322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.69606 (* 1 = 0.69606 loss)
I0905 06:06:46.590340 90901 sgd_solver.cpp:106] Iteration 24800, lr = 0.1
I0905 06:06:52.654480 90901 solver.cpp:228] Iteration 24810, loss = 0.317219
I0905 06:06:52.654554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317219 (* 1 = 0.317219 loss)
I0905 06:06:52.654573 90901 sgd_solver.cpp:106] Iteration 24810, lr = 0.1
I0905 06:06:58.764159 90901 solver.cpp:228] Iteration 24820, loss = 0.409696
I0905 06:06:58.764205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409697 (* 1 = 0.409697 loss)
I0905 06:06:58.764219 90901 sgd_solver.cpp:106] Iteration 24820, lr = 0.1
I0905 06:07:04.831629 90901 solver.cpp:228] Iteration 24830, loss = 0.251696
I0905 06:07:04.831688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251696 (* 1 = 0.251696 loss)
I0905 06:07:04.831702 90901 sgd_solver.cpp:106] Iteration 24830, lr = 0.1
I0905 06:07:11.236791 90901 solver.cpp:228] Iteration 24840, loss = 0.0961581
I0905 06:07:11.236852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0961586 (* 1 = 0.0961586 loss)
I0905 06:07:11.236868 90901 sgd_solver.cpp:106] Iteration 24840, lr = 0.1
I0905 06:07:17.315109 90901 solver.cpp:228] Iteration 24850, loss = 0.154415
I0905 06:07:17.315348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154415 (* 1 = 0.154415 loss)
I0905 06:07:17.315372 90901 sgd_solver.cpp:106] Iteration 24850, lr = 0.1
I0905 06:07:23.422443 90901 solver.cpp:228] Iteration 24860, loss = 0.410581
I0905 06:07:23.422485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410582 (* 1 = 0.410582 loss)
I0905 06:07:23.422498 90901 sgd_solver.cpp:106] Iteration 24860, lr = 0.1
I0905 06:07:29.653882 90901 solver.cpp:228] Iteration 24870, loss = 0.515172
I0905 06:07:29.653928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515172 (* 1 = 0.515172 loss)
I0905 06:07:29.653940 90901 sgd_solver.cpp:106] Iteration 24870, lr = 0.1
I0905 06:07:35.595161 90901 solver.cpp:228] Iteration 24880, loss = 0.166194
I0905 06:07:35.595208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166194 (* 1 = 0.166194 loss)
I0905 06:07:35.595221 90901 sgd_solver.cpp:106] Iteration 24880, lr = 0.1
I0905 06:07:41.839835 90901 solver.cpp:228] Iteration 24890, loss = 0.290192
I0905 06:07:41.839876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290192 (* 1 = 0.290192 loss)
I0905 06:07:41.839890 90901 sgd_solver.cpp:106] Iteration 24890, lr = 0.1
I0905 06:07:48.033781 90901 solver.cpp:228] Iteration 24900, loss = 0.866004
I0905 06:07:48.033926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.866004 (* 1 = 0.866004 loss)
I0905 06:07:48.033969 90901 sgd_solver.cpp:106] Iteration 24900, lr = 0.1
I0905 06:07:53.819269 90901 solver.cpp:228] Iteration 24910, loss = 0.379073
I0905 06:07:53.819309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379073 (* 1 = 0.379073 loss)
I0905 06:07:53.819324 90901 sgd_solver.cpp:106] Iteration 24910, lr = 0.1
I0905 06:08:00.057216 90901 solver.cpp:228] Iteration 24920, loss = 0.333744
I0905 06:08:00.057271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333745 (* 1 = 0.333745 loss)
I0905 06:08:00.057286 90901 sgd_solver.cpp:106] Iteration 24920, lr = 0.1
I0905 06:08:05.992621 90901 solver.cpp:228] Iteration 24930, loss = 0.362822
I0905 06:08:05.992665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362822 (* 1 = 0.362822 loss)
I0905 06:08:05.992676 90901 sgd_solver.cpp:106] Iteration 24930, lr = 0.1
I0905 06:08:12.106897 90901 solver.cpp:228] Iteration 24940, loss = 0.447855
I0905 06:08:12.106952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.447856 (* 1 = 0.447856 loss)
I0905 06:08:12.106968 90901 sgd_solver.cpp:106] Iteration 24940, lr = 0.1
I0905 06:08:17.717141 90901 solver.cpp:228] Iteration 24950, loss = 0.152421
I0905 06:08:17.717191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152422 (* 1 = 0.152422 loss)
I0905 06:08:17.717203 90901 sgd_solver.cpp:106] Iteration 24950, lr = 0.1
I0905 06:08:23.011458 90901 solver.cpp:228] Iteration 24960, loss = 0.21853
I0905 06:08:23.011660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218531 (* 1 = 0.218531 loss)
I0905 06:08:23.011678 90901 sgd_solver.cpp:106] Iteration 24960, lr = 0.1
I0905 06:08:29.053230 90901 solver.cpp:228] Iteration 24970, loss = 0.322227
I0905 06:08:29.053284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322228 (* 1 = 0.322228 loss)
I0905 06:08:29.053299 90901 sgd_solver.cpp:106] Iteration 24970, lr = 0.1
I0905 06:08:35.171382 90901 solver.cpp:228] Iteration 24980, loss = 0.364846
I0905 06:08:35.171437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364847 (* 1 = 0.364847 loss)
I0905 06:08:35.171448 90901 sgd_solver.cpp:106] Iteration 24980, lr = 0.1
I0905 06:08:41.249888 90901 solver.cpp:228] Iteration 24990, loss = 0.3131
I0905 06:08:41.249945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3131 (* 1 = 0.3131 loss)
I0905 06:08:41.249960 90901 sgd_solver.cpp:106] Iteration 24990, lr = 0.1
I0905 06:08:47.316943 90901 solver.cpp:228] Iteration 25000, loss = 0.605912
I0905 06:08:47.317009 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.605912 (* 1 = 0.605912 loss)
I0905 06:08:47.317026 90901 sgd_solver.cpp:106] Iteration 25000, lr = 0.1
I0905 06:08:53.706665 90901 solver.cpp:228] Iteration 25010, loss = 0.172262
I0905 06:08:53.706806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172263 (* 1 = 0.172263 loss)
I0905 06:08:53.706833 90901 sgd_solver.cpp:106] Iteration 25010, lr = 0.1
I0905 06:08:59.781373 90901 solver.cpp:228] Iteration 25020, loss = 0.296049
I0905 06:08:59.781425 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29605 (* 1 = 0.29605 loss)
I0905 06:08:59.781441 90901 sgd_solver.cpp:106] Iteration 25020, lr = 0.1
I0905 06:09:05.538271 90901 solver.cpp:228] Iteration 25030, loss = 0.751273
I0905 06:09:05.538312 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.751274 (* 1 = 0.751274 loss)
I0905 06:09:05.538326 90901 sgd_solver.cpp:106] Iteration 25030, lr = 0.1
I0905 06:09:11.935256 90901 solver.cpp:228] Iteration 25040, loss = 0.438729
I0905 06:09:11.935303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438729 (* 1 = 0.438729 loss)
I0905 06:09:11.935322 90901 sgd_solver.cpp:106] Iteration 25040, lr = 0.1
I0905 06:09:17.988924 90901 solver.cpp:228] Iteration 25050, loss = 0.646722
I0905 06:09:17.988970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.646722 (* 1 = 0.646722 loss)
I0905 06:09:17.988983 90901 sgd_solver.cpp:106] Iteration 25050, lr = 0.1
I0905 06:09:24.081166 90901 solver.cpp:228] Iteration 25060, loss = 0.378617
I0905 06:09:24.081324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378617 (* 1 = 0.378617 loss)
I0905 06:09:24.081347 90901 sgd_solver.cpp:106] Iteration 25060, lr = 0.1
I0905 06:09:30.475687 90901 solver.cpp:228] Iteration 25070, loss = 0.21138
I0905 06:09:30.475730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21138 (* 1 = 0.21138 loss)
I0905 06:09:30.475745 90901 sgd_solver.cpp:106] Iteration 25070, lr = 0.1
I0905 06:09:36.513967 90901 solver.cpp:228] Iteration 25080, loss = 0.332328
I0905 06:09:36.514008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332329 (* 1 = 0.332329 loss)
I0905 06:09:36.514024 90901 sgd_solver.cpp:106] Iteration 25080, lr = 0.1
I0905 06:09:42.555994 90901 solver.cpp:228] Iteration 25090, loss = 0.239449
I0905 06:09:42.556035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239449 (* 1 = 0.239449 loss)
I0905 06:09:42.556048 90901 sgd_solver.cpp:106] Iteration 25090, lr = 0.1
I0905 06:09:48.660293 90901 solver.cpp:228] Iteration 25100, loss = 0.53846
I0905 06:09:48.660341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.53846 (* 1 = 0.53846 loss)
I0905 06:09:48.660353 90901 sgd_solver.cpp:106] Iteration 25100, lr = 0.1
I0905 06:09:54.745652 90901 solver.cpp:228] Iteration 25110, loss = 0.254685
I0905 06:09:54.745867 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254685 (* 1 = 0.254685 loss)
I0905 06:09:54.745882 90901 sgd_solver.cpp:106] Iteration 25110, lr = 0.1
I0905 06:10:00.715505 90901 solver.cpp:228] Iteration 25120, loss = 0.106048
I0905 06:10:00.715567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106049 (* 1 = 0.106049 loss)
I0905 06:10:00.715584 90901 sgd_solver.cpp:106] Iteration 25120, lr = 0.1
I0905 06:10:05.960971 90901 solver.cpp:228] Iteration 25130, loss = 0.301708
I0905 06:10:05.961030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301708 (* 1 = 0.301708 loss)
I0905 06:10:05.961043 90901 sgd_solver.cpp:106] Iteration 25130, lr = 0.1
I0905 06:10:11.662071 90901 solver.cpp:228] Iteration 25140, loss = 0.412396
I0905 06:10:11.662122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412396 (* 1 = 0.412396 loss)
I0905 06:10:11.662137 90901 sgd_solver.cpp:106] Iteration 25140, lr = 0.1
I0905 06:10:17.805126 90901 solver.cpp:228] Iteration 25150, loss = 0.308335
I0905 06:10:17.805189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308335 (* 1 = 0.308335 loss)
I0905 06:10:17.805227 90901 sgd_solver.cpp:106] Iteration 25150, lr = 0.1
I0905 06:10:23.893774 90901 solver.cpp:228] Iteration 25160, loss = 0.322746
I0905 06:10:23.893815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322746 (* 1 = 0.322746 loss)
I0905 06:10:23.893828 90901 sgd_solver.cpp:106] Iteration 25160, lr = 0.1
I0905 06:10:29.972827 90901 solver.cpp:228] Iteration 25170, loss = 0.281716
I0905 06:10:29.972982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281716 (* 1 = 0.281716 loss)
I0905 06:10:29.972996 90901 sgd_solver.cpp:106] Iteration 25170, lr = 0.1
I0905 06:10:36.359457 90901 solver.cpp:228] Iteration 25180, loss = 0.460217
I0905 06:10:36.359503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460217 (* 1 = 0.460217 loss)
I0905 06:10:36.359514 90901 sgd_solver.cpp:106] Iteration 25180, lr = 0.1
I0905 06:10:42.394127 90901 solver.cpp:228] Iteration 25190, loss = 0.256977
I0905 06:10:42.394170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256978 (* 1 = 0.256978 loss)
I0905 06:10:42.394183 90901 sgd_solver.cpp:106] Iteration 25190, lr = 0.1
I0905 06:10:48.570502 90901 solver.cpp:228] Iteration 25200, loss = 0.152053
I0905 06:10:48.570545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152054 (* 1 = 0.152054 loss)
I0905 06:10:48.570560 90901 sgd_solver.cpp:106] Iteration 25200, lr = 0.1
I0905 06:10:54.844552 90901 solver.cpp:228] Iteration 25210, loss = 0.166008
I0905 06:10:54.844602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166008 (* 1 = 0.166008 loss)
I0905 06:10:54.844615 90901 sgd_solver.cpp:106] Iteration 25210, lr = 0.1
I0905 06:11:00.928498 90901 solver.cpp:228] Iteration 25220, loss = 0.138065
I0905 06:11:00.928623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138066 (* 1 = 0.138066 loss)
I0905 06:11:00.928638 90901 sgd_solver.cpp:106] Iteration 25220, lr = 0.1
I0905 06:11:06.687108 90901 solver.cpp:228] Iteration 25230, loss = 0.473173
I0905 06:11:06.687156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473174 (* 1 = 0.473174 loss)
I0905 06:11:06.687170 90901 sgd_solver.cpp:106] Iteration 25230, lr = 0.1
I0905 06:11:12.774281 90901 solver.cpp:228] Iteration 25240, loss = 0.464475
I0905 06:11:12.774329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464475 (* 1 = 0.464475 loss)
I0905 06:11:12.774344 90901 sgd_solver.cpp:106] Iteration 25240, lr = 0.1
I0905 06:11:18.973745 90901 solver.cpp:228] Iteration 25250, loss = 0.292563
I0905 06:11:18.973793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292564 (* 1 = 0.292564 loss)
I0905 06:11:18.973806 90901 sgd_solver.cpp:106] Iteration 25250, lr = 0.1
I0905 06:11:25.251621 90901 solver.cpp:228] Iteration 25260, loss = 0.0633789
I0905 06:11:25.251665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0633794 (* 1 = 0.0633794 loss)
I0905 06:11:25.251678 90901 sgd_solver.cpp:106] Iteration 25260, lr = 0.1
I0905 06:11:30.952697 90901 solver.cpp:228] Iteration 25270, loss = 0.954579
I0905 06:11:30.952899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.95458 (* 1 = 0.95458 loss)
I0905 06:11:30.952920 90901 sgd_solver.cpp:106] Iteration 25270, lr = 0.1
I0905 06:11:37.381157 90901 solver.cpp:228] Iteration 25280, loss = 0.15959
I0905 06:11:37.381198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159591 (* 1 = 0.159591 loss)
I0905 06:11:37.381211 90901 sgd_solver.cpp:106] Iteration 25280, lr = 0.1
I0905 06:11:43.721881 90901 solver.cpp:228] Iteration 25290, loss = 0.24986
I0905 06:11:43.721951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249861 (* 1 = 0.249861 loss)
I0905 06:11:43.721966 90901 sgd_solver.cpp:106] Iteration 25290, lr = 0.1
I0905 06:11:49.618662 90901 solver.cpp:228] Iteration 25300, loss = 0.133492
I0905 06:11:49.618721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133492 (* 1 = 0.133492 loss)
I0905 06:11:49.618746 90901 sgd_solver.cpp:106] Iteration 25300, lr = 0.1
I0905 06:11:54.873108 90901 solver.cpp:228] Iteration 25310, loss = 0.152417
I0905 06:11:54.873159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152417 (* 1 = 0.152417 loss)
I0905 06:11:54.873173 90901 sgd_solver.cpp:106] Iteration 25310, lr = 0.1
I0905 06:12:00.665730 90901 solver.cpp:228] Iteration 25320, loss = 0.319789
I0905 06:12:00.665788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319789 (* 1 = 0.319789 loss)
I0905 06:12:00.665803 90901 sgd_solver.cpp:106] Iteration 25320, lr = 0.1
I0905 06:12:06.719183 90901 solver.cpp:228] Iteration 25330, loss = 0.08714
I0905 06:12:06.719408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0871404 (* 1 = 0.0871404 loss)
I0905 06:12:06.719425 90901 sgd_solver.cpp:106] Iteration 25330, lr = 0.1
I0905 06:12:12.810818 90901 solver.cpp:228] Iteration 25340, loss = 0.322948
I0905 06:12:12.810886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322949 (* 1 = 0.322949 loss)
I0905 06:12:12.810902 90901 sgd_solver.cpp:106] Iteration 25340, lr = 0.1
I0905 06:12:18.970590 90901 solver.cpp:228] Iteration 25350, loss = 0.241986
I0905 06:12:18.970680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241986 (* 1 = 0.241986 loss)
I0905 06:12:18.970697 90901 sgd_solver.cpp:106] Iteration 25350, lr = 0.1
I0905 06:12:25.283164 90901 solver.cpp:228] Iteration 25360, loss = 0.796647
I0905 06:12:25.283218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.796647 (* 1 = 0.796647 loss)
I0905 06:12:25.283231 90901 sgd_solver.cpp:106] Iteration 25360, lr = 0.1
I0905 06:12:31.068475 90901 solver.cpp:228] Iteration 25370, loss = 0.278784
I0905 06:12:31.068514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278784 (* 1 = 0.278784 loss)
I0905 06:12:31.068527 90901 sgd_solver.cpp:106] Iteration 25370, lr = 0.1
I0905 06:12:37.474066 90901 solver.cpp:228] Iteration 25380, loss = 0.284183
I0905 06:12:37.474203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284183 (* 1 = 0.284183 loss)
I0905 06:12:37.474231 90901 sgd_solver.cpp:106] Iteration 25380, lr = 0.1
I0905 06:12:43.548122 90901 solver.cpp:228] Iteration 25390, loss = 0.319175
I0905 06:12:43.548185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319175 (* 1 = 0.319175 loss)
I0905 06:12:43.548199 90901 sgd_solver.cpp:106] Iteration 25390, lr = 0.1
I0905 06:12:49.943231 90901 solver.cpp:228] Iteration 25400, loss = 0.17457
I0905 06:12:49.943285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17457 (* 1 = 0.17457 loss)
I0905 06:12:49.943300 90901 sgd_solver.cpp:106] Iteration 25400, lr = 0.1
I0905 06:12:55.974483 90901 solver.cpp:228] Iteration 25410, loss = 0.091989
I0905 06:12:55.974529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0919893 (* 1 = 0.0919893 loss)
I0905 06:12:55.974540 90901 sgd_solver.cpp:106] Iteration 25410, lr = 0.1
I0905 06:13:02.096685 90901 solver.cpp:228] Iteration 25420, loss = 0.386768
I0905 06:13:02.096722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386769 (* 1 = 0.386769 loss)
I0905 06:13:02.096736 90901 sgd_solver.cpp:106] Iteration 25420, lr = 0.1
I0905 06:13:08.160670 90901 solver.cpp:228] Iteration 25430, loss = 0.327239
I0905 06:13:08.160923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327239 (* 1 = 0.327239 loss)
I0905 06:13:08.160940 90901 sgd_solver.cpp:106] Iteration 25430, lr = 0.1
I0905 06:13:14.557060 90901 solver.cpp:228] Iteration 25440, loss = 0.382814
I0905 06:13:14.557119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382814 (* 1 = 0.382814 loss)
I0905 06:13:14.557134 90901 sgd_solver.cpp:106] Iteration 25440, lr = 0.1
I0905 06:13:20.608096 90901 solver.cpp:228] Iteration 25450, loss = 0.276392
I0905 06:13:20.608140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276392 (* 1 = 0.276392 loss)
I0905 06:13:20.608153 90901 sgd_solver.cpp:106] Iteration 25450, lr = 0.1
I0905 06:13:26.731081 90901 solver.cpp:228] Iteration 25460, loss = 0.21494
I0905 06:13:26.731123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214941 (* 1 = 0.214941 loss)
I0905 06:13:26.731137 90901 sgd_solver.cpp:106] Iteration 25460, lr = 0.1
I0905 06:13:32.480708 90901 solver.cpp:228] Iteration 25470, loss = 0.256999
I0905 06:13:32.480770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257 (* 1 = 0.257 loss)
I0905 06:13:32.480785 90901 sgd_solver.cpp:106] Iteration 25470, lr = 0.1
I0905 06:13:38.557742 90901 solver.cpp:228] Iteration 25480, loss = 0.177503
I0905 06:13:38.557839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177503 (* 1 = 0.177503 loss)
I0905 06:13:38.557857 90901 sgd_solver.cpp:106] Iteration 25480, lr = 0.1
I0905 06:13:43.818529 90901 solver.cpp:228] Iteration 25490, loss = 0.223516
I0905 06:13:43.818591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223516 (* 1 = 0.223516 loss)
I0905 06:13:43.818606 90901 sgd_solver.cpp:106] Iteration 25490, lr = 0.1
I0905 06:13:49.417114 90901 solver.cpp:228] Iteration 25500, loss = 0.193551
I0905 06:13:49.417151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193551 (* 1 = 0.193551 loss)
I0905 06:13:49.417163 90901 sgd_solver.cpp:106] Iteration 25500, lr = 0.1
I0905 06:13:55.787585 90901 solver.cpp:228] Iteration 25510, loss = 0.225072
I0905 06:13:55.787633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225072 (* 1 = 0.225072 loss)
I0905 06:13:55.787647 90901 sgd_solver.cpp:106] Iteration 25510, lr = 0.1
I0905 06:14:01.896952 90901 solver.cpp:228] Iteration 25520, loss = 0.257252
I0905 06:14:01.897007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257252 (* 1 = 0.257252 loss)
I0905 06:14:01.897022 90901 sgd_solver.cpp:106] Iteration 25520, lr = 0.1
I0905 06:14:07.983019 90901 solver.cpp:228] Iteration 25530, loss = 0.26384
I0905 06:14:07.983067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26384 (* 1 = 0.26384 loss)
I0905 06:14:07.983083 90901 sgd_solver.cpp:106] Iteration 25530, lr = 0.1
I0905 06:14:14.075515 90901 solver.cpp:228] Iteration 25540, loss = 0.446097
I0905 06:14:14.075700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446097 (* 1 = 0.446097 loss)
I0905 06:14:14.075726 90901 sgd_solver.cpp:106] Iteration 25540, lr = 0.1
I0905 06:14:20.170827 90901 solver.cpp:228] Iteration 25550, loss = 0.542235
I0905 06:14:20.170884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.542235 (* 1 = 0.542235 loss)
I0905 06:14:20.170897 90901 sgd_solver.cpp:106] Iteration 25550, lr = 0.1
I0905 06:14:26.205166 90901 solver.cpp:228] Iteration 25560, loss = 0.220378
I0905 06:14:26.205222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220378 (* 1 = 0.220378 loss)
I0905 06:14:26.205237 90901 sgd_solver.cpp:106] Iteration 25560, lr = 0.1
I0905 06:14:32.304970 90901 solver.cpp:228] Iteration 25570, loss = 0.205347
I0905 06:14:32.305016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205347 (* 1 = 0.205347 loss)
I0905 06:14:32.305028 90901 sgd_solver.cpp:106] Iteration 25570, lr = 0.1
I0905 06:14:38.371151 90901 solver.cpp:228] Iteration 25580, loss = 0.258171
I0905 06:14:38.371207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258172 (* 1 = 0.258172 loss)
I0905 06:14:38.371220 90901 sgd_solver.cpp:106] Iteration 25580, lr = 0.1
I0905 06:14:44.427690 90901 solver.cpp:228] Iteration 25590, loss = 0.757174
I0905 06:14:44.427914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.757175 (* 1 = 0.757175 loss)
I0905 06:14:44.427932 90901 sgd_solver.cpp:106] Iteration 25590, lr = 0.1
I0905 06:14:50.312047 90901 solver.cpp:337] Iteration 25600, Testing net (#0)
I0905 06:15:31.298564 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.828125
I0905 06:15:31.298758 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.384231 (* 1 = 0.384231 loss)
I0905 06:15:31.499325 90901 solver.cpp:228] Iteration 25600, loss = 0.241808
I0905 06:15:31.499397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241808 (* 1 = 0.241808 loss)
I0905 06:15:31.499420 90901 sgd_solver.cpp:106] Iteration 25600, lr = 0.1
I0905 06:15:37.535187 90901 solver.cpp:228] Iteration 25610, loss = 0.213087
I0905 06:15:37.535234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213087 (* 1 = 0.213087 loss)
I0905 06:15:37.535248 90901 sgd_solver.cpp:106] Iteration 25610, lr = 0.1
I0905 06:15:43.618748 90901 solver.cpp:228] Iteration 25620, loss = 0.359364
I0905 06:15:43.618834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359364 (* 1 = 0.359364 loss)
I0905 06:15:43.618860 90901 sgd_solver.cpp:106] Iteration 25620, lr = 0.1
I0905 06:15:49.691128 90901 solver.cpp:228] Iteration 25630, loss = 0.442053
I0905 06:15:49.691172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442053 (* 1 = 0.442053 loss)
I0905 06:15:49.691186 90901 sgd_solver.cpp:106] Iteration 25630, lr = 0.1
I0905 06:15:56.067214 90901 solver.cpp:228] Iteration 25640, loss = 0.358586
I0905 06:15:56.067255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358586 (* 1 = 0.358586 loss)
I0905 06:15:56.067270 90901 sgd_solver.cpp:106] Iteration 25640, lr = 0.1
I0905 06:16:01.847184 90901 solver.cpp:228] Iteration 25650, loss = 0.244545
I0905 06:16:01.847337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244545 (* 1 = 0.244545 loss)
I0905 06:16:01.847379 90901 sgd_solver.cpp:106] Iteration 25650, lr = 0.1
I0905 06:16:07.962298 90901 solver.cpp:228] Iteration 25660, loss = 0.14426
I0905 06:16:07.962339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14426 (* 1 = 0.14426 loss)
I0905 06:16:07.962352 90901 sgd_solver.cpp:106] Iteration 25660, lr = 0.1
I0905 06:16:14.054642 90901 solver.cpp:228] Iteration 25670, loss = 0.406852
I0905 06:16:14.054693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406852 (* 1 = 0.406852 loss)
I0905 06:16:14.054707 90901 sgd_solver.cpp:106] Iteration 25670, lr = 0.1
I0905 06:16:20.145123 90901 solver.cpp:228] Iteration 25680, loss = 0.198009
I0905 06:16:20.145159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19801 (* 1 = 0.19801 loss)
I0905 06:16:20.145174 90901 sgd_solver.cpp:106] Iteration 25680, lr = 0.1
I0905 06:16:26.214694 90901 solver.cpp:228] Iteration 25690, loss = 0.522087
I0905 06:16:26.214738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.522087 (* 1 = 0.522087 loss)
I0905 06:16:26.214751 90901 sgd_solver.cpp:106] Iteration 25690, lr = 0.1
I0905 06:16:32.523680 90901 solver.cpp:228] Iteration 25700, loss = 0.236327
I0905 06:16:32.523874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236327 (* 1 = 0.236327 loss)
I0905 06:16:32.523919 90901 sgd_solver.cpp:106] Iteration 25700, lr = 0.1
I0905 06:16:38.446766 90901 solver.cpp:228] Iteration 25710, loss = 0.383644
I0905 06:16:38.446810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383645 (* 1 = 0.383645 loss)
I0905 06:16:38.446826 90901 sgd_solver.cpp:106] Iteration 25710, lr = 0.1
I0905 06:16:44.699535 90901 solver.cpp:228] Iteration 25720, loss = 0.331038
I0905 06:16:44.699602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331039 (* 1 = 0.331039 loss)
I0905 06:16:44.699617 90901 sgd_solver.cpp:106] Iteration 25720, lr = 0.1
I0905 06:16:50.694363 90901 solver.cpp:228] Iteration 25730, loss = 0.266775
I0905 06:16:50.694418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266775 (* 1 = 0.266775 loss)
I0905 06:16:50.694432 90901 sgd_solver.cpp:106] Iteration 25730, lr = 0.1
I0905 06:16:56.854984 90901 solver.cpp:228] Iteration 25740, loss = 0.171507
I0905 06:16:56.855034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171507 (* 1 = 0.171507 loss)
I0905 06:16:56.855049 90901 sgd_solver.cpp:106] Iteration 25740, lr = 0.1
I0905 06:17:02.919777 90901 solver.cpp:228] Iteration 25750, loss = 0.324582
I0905 06:17:02.919917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324582 (* 1 = 0.324582 loss)
I0905 06:17:02.919932 90901 sgd_solver.cpp:106] Iteration 25750, lr = 0.1
I0905 06:17:08.953979 90901 solver.cpp:228] Iteration 25760, loss = 0.187491
I0905 06:17:08.954026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187491 (* 1 = 0.187491 loss)
I0905 06:17:08.954041 90901 sgd_solver.cpp:106] Iteration 25760, lr = 0.1
I0905 06:17:14.201341 90901 solver.cpp:228] Iteration 25770, loss = 0.450603
I0905 06:17:14.201393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450603 (* 1 = 0.450603 loss)
I0905 06:17:14.201407 90901 sgd_solver.cpp:106] Iteration 25770, lr = 0.1
I0905 06:17:19.656947 90901 solver.cpp:228] Iteration 25780, loss = 0.697028
I0905 06:17:19.656990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.697028 (* 1 = 0.697028 loss)
I0905 06:17:19.657003 90901 sgd_solver.cpp:106] Iteration 25780, lr = 0.1
I0905 06:17:26.086257 90901 solver.cpp:228] Iteration 25790, loss = 0.217953
I0905 06:17:26.086302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217953 (* 1 = 0.217953 loss)
I0905 06:17:26.086314 90901 sgd_solver.cpp:106] Iteration 25790, lr = 0.1
I0905 06:17:32.177294 90901 solver.cpp:228] Iteration 25800, loss = 0.415405
I0905 06:17:32.177335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415405 (* 1 = 0.415405 loss)
I0905 06:17:32.177347 90901 sgd_solver.cpp:106] Iteration 25800, lr = 0.1
I0905 06:17:38.268990 90901 solver.cpp:228] Iteration 25810, loss = 0.270251
I0905 06:17:38.269078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270251 (* 1 = 0.270251 loss)
I0905 06:17:38.269093 90901 sgd_solver.cpp:106] Iteration 25810, lr = 0.1
I0905 06:17:44.609813 90901 solver.cpp:228] Iteration 25820, loss = 0.251888
I0905 06:17:44.609869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251888 (* 1 = 0.251888 loss)
I0905 06:17:44.609881 90901 sgd_solver.cpp:106] Iteration 25820, lr = 0.1
I0905 06:17:50.425338 90901 solver.cpp:228] Iteration 25830, loss = 0.162881
I0905 06:17:50.425386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162881 (* 1 = 0.162881 loss)
I0905 06:17:50.425400 90901 sgd_solver.cpp:106] Iteration 25830, lr = 0.1
I0905 06:17:56.468523 90901 solver.cpp:228] Iteration 25840, loss = 0.552952
I0905 06:17:56.468571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552952 (* 1 = 0.552952 loss)
I0905 06:17:56.468585 90901 sgd_solver.cpp:106] Iteration 25840, lr = 0.1
I0905 06:18:02.845762 90901 solver.cpp:228] Iteration 25850, loss = 0.0801421
I0905 06:18:02.845805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0801423 (* 1 = 0.0801423 loss)
I0905 06:18:02.845820 90901 sgd_solver.cpp:106] Iteration 25850, lr = 0.1
I0905 06:18:08.916661 90901 solver.cpp:228] Iteration 25860, loss = 0.172909
I0905 06:18:08.916894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172909 (* 1 = 0.172909 loss)
I0905 06:18:08.916926 90901 sgd_solver.cpp:106] Iteration 25860, lr = 0.1
I0905 06:18:15.010802 90901 solver.cpp:228] Iteration 25870, loss = 0.352096
I0905 06:18:15.010869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352096 (* 1 = 0.352096 loss)
I0905 06:18:15.010885 90901 sgd_solver.cpp:106] Iteration 25870, lr = 0.1
I0905 06:18:21.226573 90901 solver.cpp:228] Iteration 25880, loss = 0.309535
I0905 06:18:21.226614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309535 (* 1 = 0.309535 loss)
I0905 06:18:21.226626 90901 sgd_solver.cpp:106] Iteration 25880, lr = 0.1
I0905 06:18:27.483687 90901 solver.cpp:228] Iteration 25890, loss = 0.545586
I0905 06:18:27.483729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.545586 (* 1 = 0.545586 loss)
I0905 06:18:27.483743 90901 sgd_solver.cpp:106] Iteration 25890, lr = 0.1
I0905 06:18:33.556326 90901 solver.cpp:228] Iteration 25900, loss = 0.263301
I0905 06:18:33.556370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263301 (* 1 = 0.263301 loss)
I0905 06:18:33.556387 90901 sgd_solver.cpp:106] Iteration 25900, lr = 0.1
I0905 06:18:39.626176 90901 solver.cpp:228] Iteration 25910, loss = 0.194335
I0905 06:18:39.626397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194336 (* 1 = 0.194336 loss)
I0905 06:18:39.626415 90901 sgd_solver.cpp:106] Iteration 25910, lr = 0.1
I0905 06:18:45.656195 90901 solver.cpp:228] Iteration 25920, loss = 0.103956
I0905 06:18:45.656265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103956 (* 1 = 0.103956 loss)
I0905 06:18:45.656285 90901 sgd_solver.cpp:106] Iteration 25920, lr = 0.1
I0905 06:18:52.019786 90901 solver.cpp:228] Iteration 25930, loss = 0.172925
I0905 06:18:52.019830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172925 (* 1 = 0.172925 loss)
I0905 06:18:52.019842 90901 sgd_solver.cpp:106] Iteration 25930, lr = 0.1
I0905 06:18:57.787305 90901 solver.cpp:228] Iteration 25940, loss = 0.212871
I0905 06:18:57.787363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212872 (* 1 = 0.212872 loss)
I0905 06:18:57.787376 90901 sgd_solver.cpp:106] Iteration 25940, lr = 0.1
I0905 06:19:03.039258 90901 solver.cpp:228] Iteration 25950, loss = 0.304951
I0905 06:19:03.039314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304951 (* 1 = 0.304951 loss)
I0905 06:19:03.039329 90901 sgd_solver.cpp:106] Iteration 25950, lr = 0.1
I0905 06:19:08.703029 90901 solver.cpp:228] Iteration 25960, loss = 0.299788
I0905 06:19:08.703081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299789 (* 1 = 0.299789 loss)
I0905 06:19:08.703094 90901 sgd_solver.cpp:106] Iteration 25960, lr = 0.1
I0905 06:19:14.747606 90901 solver.cpp:228] Iteration 25970, loss = 0.593793
I0905 06:19:14.747766 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.593793 (* 1 = 0.593793 loss)
I0905 06:19:14.747797 90901 sgd_solver.cpp:106] Iteration 25970, lr = 0.1
I0905 06:19:21.109017 90901 solver.cpp:228] Iteration 25980, loss = 0.102439
I0905 06:19:21.109066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10244 (* 1 = 0.10244 loss)
I0905 06:19:21.109081 90901 sgd_solver.cpp:106] Iteration 25980, lr = 0.1
I0905 06:19:27.142207 90901 solver.cpp:228] Iteration 25990, loss = 0.184308
I0905 06:19:27.142253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184308 (* 1 = 0.184308 loss)
I0905 06:19:27.142266 90901 sgd_solver.cpp:106] Iteration 25990, lr = 0.1
I0905 06:19:33.208020 90901 solver.cpp:228] Iteration 26000, loss = 0.206276
I0905 06:19:33.208065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206276 (* 1 = 0.206276 loss)
I0905 06:19:33.208078 90901 sgd_solver.cpp:106] Iteration 26000, lr = 0.1
I0905 06:19:39.264967 90901 solver.cpp:228] Iteration 26010, loss = 0.0688409
I0905 06:19:39.265027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0688411 (* 1 = 0.0688411 loss)
I0905 06:19:39.265043 90901 sgd_solver.cpp:106] Iteration 26010, lr = 0.1
I0905 06:19:45.359266 90901 solver.cpp:228] Iteration 26020, loss = 0.221311
I0905 06:19:45.359513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221311 (* 1 = 0.221311 loss)
I0905 06:19:45.359532 90901 sgd_solver.cpp:106] Iteration 26020, lr = 0.1
I0905 06:19:51.427605 90901 solver.cpp:228] Iteration 26030, loss = 0.231818
I0905 06:19:51.427645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231818 (* 1 = 0.231818 loss)
I0905 06:19:51.427659 90901 sgd_solver.cpp:106] Iteration 26030, lr = 0.1
I0905 06:19:57.494503 90901 solver.cpp:228] Iteration 26040, loss = 0.491137
I0905 06:19:57.494561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491137 (* 1 = 0.491137 loss)
I0905 06:19:57.494576 90901 sgd_solver.cpp:106] Iteration 26040, lr = 0.1
I0905 06:20:03.574421 90901 solver.cpp:228] Iteration 26050, loss = 0.507872
I0905 06:20:03.574483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507872 (* 1 = 0.507872 loss)
I0905 06:20:03.574497 90901 sgd_solver.cpp:106] Iteration 26050, lr = 0.1
I0905 06:20:09.663022 90901 solver.cpp:228] Iteration 26060, loss = 0.340148
I0905 06:20:09.663075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340148 (* 1 = 0.340148 loss)
I0905 06:20:09.663089 90901 sgd_solver.cpp:106] Iteration 26060, lr = 0.1
I0905 06:20:16.044054 90901 solver.cpp:228] Iteration 26070, loss = 0.335635
I0905 06:20:16.044150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335635 (* 1 = 0.335635 loss)
I0905 06:20:16.044163 90901 sgd_solver.cpp:106] Iteration 26070, lr = 0.1
I0905 06:20:21.873175 90901 solver.cpp:228] Iteration 26080, loss = 0.205803
I0905 06:20:21.873234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205803 (* 1 = 0.205803 loss)
I0905 06:20:21.873250 90901 sgd_solver.cpp:106] Iteration 26080, lr = 0.1
I0905 06:20:28.181382 90901 solver.cpp:228] Iteration 26090, loss = 1.36911
I0905 06:20:28.181447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.36911 (* 1 = 1.36911 loss)
I0905 06:20:28.181463 90901 sgd_solver.cpp:106] Iteration 26090, lr = 0.1
I0905 06:20:34.209512 90901 solver.cpp:228] Iteration 26100, loss = 0.346846
I0905 06:20:34.209554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346846 (* 1 = 0.346846 loss)
I0905 06:20:34.209571 90901 sgd_solver.cpp:106] Iteration 26100, lr = 0.1
I0905 06:20:40.245676 90901 solver.cpp:228] Iteration 26110, loss = 0.271151
I0905 06:20:40.245724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271151 (* 1 = 0.271151 loss)
I0905 06:20:40.245738 90901 sgd_solver.cpp:106] Iteration 26110, lr = 0.1
I0905 06:20:45.988848 90901 solver.cpp:228] Iteration 26120, loss = 0.18873
I0905 06:20:45.988934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18873 (* 1 = 0.18873 loss)
I0905 06:20:45.988950 90901 sgd_solver.cpp:106] Iteration 26120, lr = 0.1
I0905 06:20:51.259392 90901 solver.cpp:228] Iteration 26130, loss = 0.258826
I0905 06:20:51.259579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258826 (* 1 = 0.258826 loss)
I0905 06:20:51.259596 90901 sgd_solver.cpp:106] Iteration 26130, lr = 0.1
I0905 06:20:56.942132 90901 solver.cpp:228] Iteration 26140, loss = 0.217959
I0905 06:20:56.942178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217959 (* 1 = 0.217959 loss)
I0905 06:20:56.942193 90901 sgd_solver.cpp:106] Iteration 26140, lr = 0.1
I0905 06:21:03.322651 90901 solver.cpp:228] Iteration 26150, loss = 0.16467
I0905 06:21:03.322741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16467 (* 1 = 0.16467 loss)
I0905 06:21:03.322772 90901 sgd_solver.cpp:106] Iteration 26150, lr = 0.1
I0905 06:21:09.390027 90901 solver.cpp:228] Iteration 26160, loss = 0.24176
I0905 06:21:09.390074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24176 (* 1 = 0.24176 loss)
I0905 06:21:09.390086 90901 sgd_solver.cpp:106] Iteration 26160, lr = 0.1
I0905 06:21:15.165040 90901 solver.cpp:228] Iteration 26170, loss = 0.180735
I0905 06:21:15.165094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180736 (* 1 = 0.180736 loss)
I0905 06:21:15.165108 90901 sgd_solver.cpp:106] Iteration 26170, lr = 0.1
I0905 06:21:21.542904 90901 solver.cpp:228] Iteration 26180, loss = 0.17821
I0905 06:21:21.543193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17821 (* 1 = 0.17821 loss)
I0905 06:21:21.543210 90901 sgd_solver.cpp:106] Iteration 26180, lr = 0.1
I0905 06:21:27.910586 90901 solver.cpp:228] Iteration 26190, loss = 0.0693268
I0905 06:21:27.910655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0693269 (* 1 = 0.0693269 loss)
I0905 06:21:27.910670 90901 sgd_solver.cpp:106] Iteration 26190, lr = 0.1
I0905 06:21:33.980437 90901 solver.cpp:228] Iteration 26200, loss = 0.17028
I0905 06:21:33.980496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17028 (* 1 = 0.17028 loss)
I0905 06:21:33.980511 90901 sgd_solver.cpp:106] Iteration 26200, lr = 0.1
I0905 06:21:40.037572 90901 solver.cpp:228] Iteration 26210, loss = 0.368216
I0905 06:21:40.037641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368216 (* 1 = 0.368216 loss)
I0905 06:21:40.037654 90901 sgd_solver.cpp:106] Iteration 26210, lr = 0.1
I0905 06:21:45.778815 90901 solver.cpp:228] Iteration 26220, loss = 0.313145
I0905 06:21:45.778872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313145 (* 1 = 0.313145 loss)
I0905 06:21:45.778888 90901 sgd_solver.cpp:106] Iteration 26220, lr = 0.1
I0905 06:21:52.148588 90901 solver.cpp:228] Iteration 26230, loss = 0.225999
I0905 06:21:52.148746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225999 (* 1 = 0.225999 loss)
I0905 06:21:52.148787 90901 sgd_solver.cpp:106] Iteration 26230, lr = 0.1
I0905 06:21:58.239876 90901 solver.cpp:228] Iteration 26240, loss = 0.199189
I0905 06:21:58.239945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199189 (* 1 = 0.199189 loss)
I0905 06:21:58.239961 90901 sgd_solver.cpp:106] Iteration 26240, lr = 0.1
I0905 06:22:04.286409 90901 solver.cpp:228] Iteration 26250, loss = 0.733194
I0905 06:22:04.286470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.733194 (* 1 = 0.733194 loss)
I0905 06:22:04.286484 90901 sgd_solver.cpp:106] Iteration 26250, lr = 0.1
I0905 06:22:10.371438 90901 solver.cpp:228] Iteration 26260, loss = 0.607407
I0905 06:22:10.371515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607407 (* 1 = 0.607407 loss)
I0905 06:22:10.371531 90901 sgd_solver.cpp:106] Iteration 26260, lr = 0.1
I0905 06:22:16.080916 90901 solver.cpp:228] Iteration 26270, loss = 0.519383
I0905 06:22:16.080978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519383 (* 1 = 0.519383 loss)
I0905 06:22:16.080994 90901 sgd_solver.cpp:106] Iteration 26270, lr = 0.1
I0905 06:22:21.112968 90901 solver.cpp:228] Iteration 26280, loss = 0.222081
I0905 06:22:21.113023 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222081 (* 1 = 0.222081 loss)
I0905 06:22:21.113039 90901 sgd_solver.cpp:106] Iteration 26280, lr = 0.1
I0905 06:22:26.093068 90901 solver.cpp:228] Iteration 26290, loss = 0.427445
I0905 06:22:26.093194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427445 (* 1 = 0.427445 loss)
I0905 06:22:26.093209 90901 sgd_solver.cpp:106] Iteration 26290, lr = 0.1
I0905 06:22:31.113752 90901 solver.cpp:228] Iteration 26300, loss = 0.362308
I0905 06:22:31.113803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362308 (* 1 = 0.362308 loss)
I0905 06:22:31.113816 90901 sgd_solver.cpp:106] Iteration 26300, lr = 0.1
I0905 06:22:35.872539 90901 solver.cpp:228] Iteration 26310, loss = 0.261712
I0905 06:22:35.872599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261712 (* 1 = 0.261712 loss)
I0905 06:22:35.872613 90901 sgd_solver.cpp:106] Iteration 26310, lr = 0.1
I0905 06:22:40.525449 90901 solver.cpp:228] Iteration 26320, loss = 0.281775
I0905 06:22:40.525501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281775 (* 1 = 0.281775 loss)
I0905 06:22:40.525513 90901 sgd_solver.cpp:106] Iteration 26320, lr = 0.1
I0905 06:22:45.241753 90901 solver.cpp:228] Iteration 26330, loss = 0.101106
I0905 06:22:45.241801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101106 (* 1 = 0.101106 loss)
I0905 06:22:45.241814 90901 sgd_solver.cpp:106] Iteration 26330, lr = 0.1
I0905 06:22:50.309034 90901 solver.cpp:228] Iteration 26340, loss = 0.411543
I0905 06:22:50.309082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.411543 (* 1 = 0.411543 loss)
I0905 06:22:50.309094 90901 sgd_solver.cpp:106] Iteration 26340, lr = 0.1
I0905 06:22:55.358176 90901 solver.cpp:228] Iteration 26350, loss = 0.418476
I0905 06:22:55.358228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418476 (* 1 = 0.418476 loss)
I0905 06:22:55.358256 90901 sgd_solver.cpp:106] Iteration 26350, lr = 0.1
I0905 06:23:00.412045 90901 solver.cpp:228] Iteration 26360, loss = 0.884555
I0905 06:23:00.412247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.884555 (* 1 = 0.884555 loss)
I0905 06:23:00.412266 90901 sgd_solver.cpp:106] Iteration 26360, lr = 0.1
I0905 06:23:05.455997 90901 solver.cpp:228] Iteration 26370, loss = 0.45643
I0905 06:23:05.456045 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45643 (* 1 = 0.45643 loss)
I0905 06:23:05.456059 90901 sgd_solver.cpp:106] Iteration 26370, lr = 0.1
I0905 06:23:10.472165 90901 solver.cpp:228] Iteration 26380, loss = 0.206081
I0905 06:23:10.472214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20608 (* 1 = 0.20608 loss)
I0905 06:23:10.472230 90901 sgd_solver.cpp:106] Iteration 26380, lr = 0.1
I0905 06:23:15.521423 90901 solver.cpp:228] Iteration 26390, loss = 0.319279
I0905 06:23:15.521493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319279 (* 1 = 0.319279 loss)
I0905 06:23:15.521509 90901 sgd_solver.cpp:106] Iteration 26390, lr = 0.1
I0905 06:23:20.314648 90901 solver.cpp:337] Iteration 26400, Testing net (#0)
I0905 06:23:59.797371 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.578438
I0905 06:23:59.797547 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.60595 (* 1 = 1.60595 loss)
I0905 06:24:00.014483 90901 solver.cpp:228] Iteration 26400, loss = 0.32444
I0905 06:24:00.014546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32444 (* 1 = 0.32444 loss)
I0905 06:24:00.014565 90901 sgd_solver.cpp:106] Iteration 26400, lr = 0.1
I0905 06:24:06.093737 90901 solver.cpp:228] Iteration 26410, loss = 0.315619
I0905 06:24:06.093780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315619 (* 1 = 0.315619 loss)
I0905 06:24:06.093793 90901 sgd_solver.cpp:106] Iteration 26410, lr = 0.1
I0905 06:24:12.163940 90901 solver.cpp:228] Iteration 26420, loss = 0.20562
I0905 06:24:12.163980 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20562 (* 1 = 0.20562 loss)
I0905 06:24:12.163995 90901 sgd_solver.cpp:106] Iteration 26420, lr = 0.1
I0905 06:24:18.556321 90901 solver.cpp:228] Iteration 26430, loss = 0.249622
I0905 06:24:18.556378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249621 (* 1 = 0.249621 loss)
I0905 06:24:18.556392 90901 sgd_solver.cpp:106] Iteration 26430, lr = 0.1
I0905 06:24:24.625099 90901 solver.cpp:228] Iteration 26440, loss = 0.457235
I0905 06:24:24.625144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457235 (* 1 = 0.457235 loss)
I0905 06:24:24.625156 90901 sgd_solver.cpp:106] Iteration 26440, lr = 0.1
I0905 06:24:30.278322 90901 solver.cpp:228] Iteration 26450, loss = 0.249808
I0905 06:24:30.278542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249807 (* 1 = 0.249807 loss)
I0905 06:24:30.278573 90901 sgd_solver.cpp:106] Iteration 26450, lr = 0.1
I0905 06:24:35.520627 90901 solver.cpp:228] Iteration 26460, loss = 0.139296
I0905 06:24:35.520696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139295 (* 1 = 0.139295 loss)
I0905 06:24:35.520711 90901 sgd_solver.cpp:106] Iteration 26460, lr = 0.1
I0905 06:24:41.515211 90901 solver.cpp:228] Iteration 26470, loss = 0.4372
I0905 06:24:41.515256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4372 (* 1 = 0.4372 loss)
I0905 06:24:41.515270 90901 sgd_solver.cpp:106] Iteration 26470, lr = 0.1
I0905 06:24:47.306911 90901 solver.cpp:228] Iteration 26480, loss = 0.359471
I0905 06:24:47.306967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35947 (* 1 = 0.35947 loss)
I0905 06:24:47.306980 90901 sgd_solver.cpp:106] Iteration 26480, lr = 0.1
I0905 06:24:53.699914 90901 solver.cpp:228] Iteration 26490, loss = 0.496842
I0905 06:24:53.699971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496842 (* 1 = 0.496842 loss)
I0905 06:24:53.699987 90901 sgd_solver.cpp:106] Iteration 26490, lr = 0.1
I0905 06:24:59.740725 90901 solver.cpp:228] Iteration 26500, loss = 0.258798
I0905 06:24:59.740772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258798 (* 1 = 0.258798 loss)
I0905 06:24:59.740784 90901 sgd_solver.cpp:106] Iteration 26500, lr = 0.1
I0905 06:25:05.819430 90901 solver.cpp:228] Iteration 26510, loss = 0.242897
I0905 06:25:05.819623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242897 (* 1 = 0.242897 loss)
I0905 06:25:05.819640 90901 sgd_solver.cpp:106] Iteration 26510, lr = 0.1
I0905 06:25:11.984967 90901 solver.cpp:228] Iteration 26520, loss = 0.22975
I0905 06:25:11.985015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229749 (* 1 = 0.229749 loss)
I0905 06:25:11.985029 90901 sgd_solver.cpp:106] Iteration 26520, lr = 0.1
I0905 06:25:18.246752 90901 solver.cpp:228] Iteration 26530, loss = 0.432291
I0905 06:25:18.246803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432291 (* 1 = 0.432291 loss)
I0905 06:25:18.246819 90901 sgd_solver.cpp:106] Iteration 26530, lr = 0.1
I0905 06:25:24.313541 90901 solver.cpp:228] Iteration 26540, loss = 0.209588
I0905 06:25:24.313585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209588 (* 1 = 0.209588 loss)
I0905 06:25:24.313597 90901 sgd_solver.cpp:106] Iteration 26540, lr = 0.1
I0905 06:25:30.392738 90901 solver.cpp:228] Iteration 26550, loss = 0.230205
I0905 06:25:30.392792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230204 (* 1 = 0.230204 loss)
I0905 06:25:30.392805 90901 sgd_solver.cpp:106] Iteration 26550, lr = 0.1
I0905 06:25:36.453920 90901 solver.cpp:228] Iteration 26560, loss = 0.209211
I0905 06:25:36.454071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209211 (* 1 = 0.209211 loss)
I0905 06:25:36.454118 90901 sgd_solver.cpp:106] Iteration 26560, lr = 0.1
I0905 06:25:42.813254 90901 solver.cpp:228] Iteration 26570, loss = 0.420338
I0905 06:25:42.813300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.420338 (* 1 = 0.420338 loss)
I0905 06:25:42.813313 90901 sgd_solver.cpp:106] Iteration 26570, lr = 0.1
I0905 06:25:48.892948 90901 solver.cpp:228] Iteration 26580, loss = 0.743065
I0905 06:25:48.893002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.743064 (* 1 = 0.743064 loss)
I0905 06:25:48.893014 90901 sgd_solver.cpp:106] Iteration 26580, lr = 0.1
I0905 06:25:55.253669 90901 solver.cpp:228] Iteration 26590, loss = 0.295484
I0905 06:25:55.253721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295483 (* 1 = 0.295483 loss)
I0905 06:25:55.253734 90901 sgd_solver.cpp:106] Iteration 26590, lr = 0.1
I0905 06:26:01.320438 90901 solver.cpp:228] Iteration 26600, loss = 0.942855
I0905 06:26:01.320485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.942854 (* 1 = 0.942854 loss)
I0905 06:26:01.320499 90901 sgd_solver.cpp:106] Iteration 26600, lr = 0.1
I0905 06:26:07.383704 90901 solver.cpp:228] Iteration 26610, loss = 0.403373
I0905 06:26:07.383891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403373 (* 1 = 0.403373 loss)
I0905 06:26:07.383913 90901 sgd_solver.cpp:106] Iteration 26610, lr = 0.1
I0905 06:26:13.433099 90901 solver.cpp:228] Iteration 26620, loss = 0.562945
I0905 06:26:13.433166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.562945 (* 1 = 0.562945 loss)
I0905 06:26:13.433179 90901 sgd_solver.cpp:106] Iteration 26620, lr = 0.1
I0905 06:26:18.842277 90901 solver.cpp:228] Iteration 26630, loss = 0.25287
I0905 06:26:18.842324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25287 (* 1 = 0.25287 loss)
I0905 06:26:18.842339 90901 sgd_solver.cpp:106] Iteration 26630, lr = 0.1
I0905 06:26:24.163396 90901 solver.cpp:228] Iteration 26640, loss = 0.386819
I0905 06:26:24.163439 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386819 (* 1 = 0.386819 loss)
I0905 06:26:24.163452 90901 sgd_solver.cpp:106] Iteration 26640, lr = 0.1
I0905 06:26:30.258888 90901 solver.cpp:228] Iteration 26650, loss = 0.174893
I0905 06:26:30.258934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174893 (* 1 = 0.174893 loss)
I0905 06:26:30.258947 90901 sgd_solver.cpp:106] Iteration 26650, lr = 0.1
I0905 06:26:36.327215 90901 solver.cpp:228] Iteration 26660, loss = 0.207162
I0905 06:26:36.327258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207161 (* 1 = 0.207161 loss)
I0905 06:26:36.327275 90901 sgd_solver.cpp:106] Iteration 26660, lr = 0.1
I0905 06:26:42.561266 90901 solver.cpp:228] Iteration 26670, loss = 0.225367
I0905 06:26:42.561384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225367 (* 1 = 0.225367 loss)
I0905 06:26:42.561399 90901 sgd_solver.cpp:106] Iteration 26670, lr = 0.1
I0905 06:26:48.806849 90901 solver.cpp:228] Iteration 26680, loss = 0.275678
I0905 06:26:48.806895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275678 (* 1 = 0.275678 loss)
I0905 06:26:48.806910 90901 sgd_solver.cpp:106] Iteration 26680, lr = 0.1
I0905 06:26:54.858111 90901 solver.cpp:228] Iteration 26690, loss = 0.287445
I0905 06:26:54.858166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287445 (* 1 = 0.287445 loss)
I0905 06:26:54.858178 90901 sgd_solver.cpp:106] Iteration 26690, lr = 0.1
I0905 06:27:00.985826 90901 solver.cpp:228] Iteration 26700, loss = 0.118931
I0905 06:27:00.985867 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118931 (* 1 = 0.118931 loss)
I0905 06:27:00.985879 90901 sgd_solver.cpp:106] Iteration 26700, lr = 0.1
I0905 06:27:07.105182 90901 solver.cpp:228] Iteration 26710, loss = 0.425912
I0905 06:27:07.105240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425912 (* 1 = 0.425912 loss)
I0905 06:27:07.105257 90901 sgd_solver.cpp:106] Iteration 26710, lr = 0.1
I0905 06:27:13.137018 90901 solver.cpp:228] Iteration 26720, loss = 0.161293
I0905 06:27:13.137192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161293 (* 1 = 0.161293 loss)
I0905 06:27:13.137238 90901 sgd_solver.cpp:106] Iteration 26720, lr = 0.1
I0905 06:27:19.563408 90901 solver.cpp:228] Iteration 26730, loss = 0.398589
I0905 06:27:19.563457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398589 (* 1 = 0.398589 loss)
I0905 06:27:19.563473 90901 sgd_solver.cpp:106] Iteration 26730, lr = 0.1
I0905 06:27:25.633745 90901 solver.cpp:228] Iteration 26740, loss = 0.203668
I0905 06:27:25.633795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203668 (* 1 = 0.203668 loss)
I0905 06:27:25.633807 90901 sgd_solver.cpp:106] Iteration 26740, lr = 0.1
I0905 06:27:31.416339 90901 solver.cpp:228] Iteration 26750, loss = 0.177597
I0905 06:27:31.416388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177597 (* 1 = 0.177597 loss)
I0905 06:27:31.416401 90901 sgd_solver.cpp:106] Iteration 26750, lr = 0.1
I0905 06:27:38.024754 90901 solver.cpp:228] Iteration 26760, loss = 0.21434
I0905 06:27:38.024799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21434 (* 1 = 0.21434 loss)
I0905 06:27:38.024814 90901 sgd_solver.cpp:106] Iteration 26760, lr = 0.1
I0905 06:27:43.854075 90901 solver.cpp:228] Iteration 26770, loss = 0.313751
I0905 06:27:43.854305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313751 (* 1 = 0.313751 loss)
I0905 06:27:43.854321 90901 sgd_solver.cpp:106] Iteration 26770, lr = 0.1
I0905 06:27:50.108697 90901 solver.cpp:228] Iteration 26780, loss = 0.313471
I0905 06:27:50.108747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313471 (* 1 = 0.313471 loss)
I0905 06:27:50.108760 90901 sgd_solver.cpp:106] Iteration 26780, lr = 0.1
I0905 06:27:56.373909 90901 solver.cpp:228] Iteration 26790, loss = 0.643488
I0905 06:27:56.373957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.643488 (* 1 = 0.643488 loss)
I0905 06:27:56.373971 90901 sgd_solver.cpp:106] Iteration 26790, lr = 0.1
I0905 06:28:02.191828 90901 solver.cpp:228] Iteration 26800, loss = 0.262087
I0905 06:28:02.191874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262087 (* 1 = 0.262087 loss)
I0905 06:28:02.191887 90901 sgd_solver.cpp:106] Iteration 26800, lr = 0.1
I0905 06:28:07.703827 90901 solver.cpp:228] Iteration 26810, loss = 0.632168
I0905 06:28:07.703876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.632168 (* 1 = 0.632168 loss)
I0905 06:28:07.703889 90901 sgd_solver.cpp:106] Iteration 26810, lr = 0.1
I0905 06:28:13.417160 90901 solver.cpp:228] Iteration 26820, loss = 0.675109
I0905 06:28:13.417230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.675108 (* 1 = 0.675108 loss)
I0905 06:28:13.417245 90901 sgd_solver.cpp:106] Iteration 26820, lr = 0.1
I0905 06:28:19.700302 90901 solver.cpp:228] Iteration 26830, loss = 0.174206
I0905 06:28:19.700450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174206 (* 1 = 0.174206 loss)
I0905 06:28:19.700495 90901 sgd_solver.cpp:106] Iteration 26830, lr = 0.1
I0905 06:28:25.773216 90901 solver.cpp:228] Iteration 26840, loss = 0.42142
I0905 06:28:25.773262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421419 (* 1 = 0.421419 loss)
I0905 06:28:25.773277 90901 sgd_solver.cpp:106] Iteration 26840, lr = 0.1
I0905 06:28:31.855931 90901 solver.cpp:228] Iteration 26850, loss = 0.410438
I0905 06:28:31.855975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410438 (* 1 = 0.410438 loss)
I0905 06:28:31.855988 90901 sgd_solver.cpp:106] Iteration 26850, lr = 0.1
I0905 06:28:37.934507 90901 solver.cpp:228] Iteration 26860, loss = 0.456478
I0905 06:28:37.934561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456478 (* 1 = 0.456478 loss)
I0905 06:28:37.934576 90901 sgd_solver.cpp:106] Iteration 26860, lr = 0.1
I0905 06:28:43.887421 90901 solver.cpp:228] Iteration 26870, loss = 0.378659
I0905 06:28:43.887506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378659 (* 1 = 0.378659 loss)
I0905 06:28:43.887522 90901 sgd_solver.cpp:106] Iteration 26870, lr = 0.1
I0905 06:28:50.130266 90901 solver.cpp:228] Iteration 26880, loss = 0.464961
I0905 06:28:50.130404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464961 (* 1 = 0.464961 loss)
I0905 06:28:50.130432 90901 sgd_solver.cpp:106] Iteration 26880, lr = 0.1
I0905 06:28:56.233726 90901 solver.cpp:228] Iteration 26890, loss = 0.168198
I0905 06:28:56.233775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168198 (* 1 = 0.168198 loss)
I0905 06:28:56.233788 90901 sgd_solver.cpp:106] Iteration 26890, lr = 0.1
I0905 06:29:02.366818 90901 solver.cpp:228] Iteration 26900, loss = 0.305201
I0905 06:29:02.366863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305201 (* 1 = 0.305201 loss)
I0905 06:29:02.366876 90901 sgd_solver.cpp:106] Iteration 26900, lr = 0.1
I0905 06:29:08.774291 90901 solver.cpp:228] Iteration 26910, loss = 0.397737
I0905 06:29:08.774340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397737 (* 1 = 0.397737 loss)
I0905 06:29:08.774354 90901 sgd_solver.cpp:106] Iteration 26910, lr = 0.1
I0905 06:29:14.849604 90901 solver.cpp:228] Iteration 26920, loss = 0.265582
I0905 06:29:14.849648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265581 (* 1 = 0.265581 loss)
I0905 06:29:14.849664 90901 sgd_solver.cpp:106] Iteration 26920, lr = 0.1
I0905 06:29:20.911548 90901 solver.cpp:228] Iteration 26930, loss = 0.208994
I0905 06:29:20.911819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208994 (* 1 = 0.208994 loss)
I0905 06:29:20.911834 90901 sgd_solver.cpp:106] Iteration 26930, lr = 0.1
I0905 06:29:26.985996 90901 solver.cpp:228] Iteration 26940, loss = 0.504555
I0905 06:29:26.986057 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504554 (* 1 = 0.504554 loss)
I0905 06:29:26.986073 90901 sgd_solver.cpp:106] Iteration 26940, lr = 0.1
I0905 06:29:33.127972 90901 solver.cpp:228] Iteration 26950, loss = 0.357302
I0905 06:29:33.128038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357301 (* 1 = 0.357301 loss)
I0905 06:29:33.128053 90901 sgd_solver.cpp:106] Iteration 26950, lr = 0.1
I0905 06:29:39.384807 90901 solver.cpp:228] Iteration 26960, loss = 0.98359
I0905 06:29:39.384868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.983589 (* 1 = 0.983589 loss)
I0905 06:29:39.384883 90901 sgd_solver.cpp:106] Iteration 26960, lr = 0.1
I0905 06:29:45.464328 90901 solver.cpp:228] Iteration 26970, loss = 0.143312
I0905 06:29:45.464386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143312 (* 1 = 0.143312 loss)
I0905 06:29:45.464401 90901 sgd_solver.cpp:106] Iteration 26970, lr = 0.1
I0905 06:29:51.121240 90901 solver.cpp:228] Iteration 26980, loss = 0.218354
I0905 06:29:51.121407 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218354 (* 1 = 0.218354 loss)
I0905 06:29:51.121423 90901 sgd_solver.cpp:106] Iteration 26980, lr = 0.1
I0905 06:29:56.473521 90901 solver.cpp:228] Iteration 26990, loss = 0.209032
I0905 06:29:56.473593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209032 (* 1 = 0.209032 loss)
I0905 06:29:56.473608 90901 sgd_solver.cpp:106] Iteration 26990, lr = 0.1
I0905 06:30:02.532724 90901 solver.cpp:228] Iteration 27000, loss = 0.300822
I0905 06:30:02.532783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300822 (* 1 = 0.300822 loss)
I0905 06:30:02.532799 90901 sgd_solver.cpp:106] Iteration 27000, lr = 0.1
I0905 06:30:08.615260 90901 solver.cpp:228] Iteration 27010, loss = 0.26548
I0905 06:30:08.615331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26548 (* 1 = 0.26548 loss)
I0905 06:30:08.615345 90901 sgd_solver.cpp:106] Iteration 27010, lr = 0.1
I0905 06:30:14.884771 90901 solver.cpp:228] Iteration 27020, loss = 0.446507
I0905 06:30:14.884850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446507 (* 1 = 0.446507 loss)
I0905 06:30:14.884866 90901 sgd_solver.cpp:106] Iteration 27020, lr = 0.1
I0905 06:30:21.067252 90901 solver.cpp:228] Iteration 27030, loss = 0.277065
I0905 06:30:21.067294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277065 (* 1 = 0.277065 loss)
I0905 06:30:21.067312 90901 sgd_solver.cpp:106] Iteration 27030, lr = 0.1
I0905 06:30:27.149904 90901 solver.cpp:228] Iteration 27040, loss = 0.187505
I0905 06:30:27.150017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187505 (* 1 = 0.187505 loss)
I0905 06:30:27.150046 90901 sgd_solver.cpp:106] Iteration 27040, lr = 0.1
I0905 06:30:32.905903 90901 solver.cpp:228] Iteration 27050, loss = 0.315742
I0905 06:30:32.905947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315742 (* 1 = 0.315742 loss)
I0905 06:30:32.905961 90901 sgd_solver.cpp:106] Iteration 27050, lr = 0.1
I0905 06:30:39.291782 90901 solver.cpp:228] Iteration 27060, loss = 0.570782
I0905 06:30:39.291846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.570781 (* 1 = 0.570781 loss)
I0905 06:30:39.291862 90901 sgd_solver.cpp:106] Iteration 27060, lr = 0.1
I0905 06:30:45.395577 90901 solver.cpp:228] Iteration 27070, loss = 0.321667
I0905 06:30:45.395632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321667 (* 1 = 0.321667 loss)
I0905 06:30:45.395648 90901 sgd_solver.cpp:106] Iteration 27070, lr = 0.1
I0905 06:30:51.488096 90901 solver.cpp:228] Iteration 27080, loss = 0.144367
I0905 06:30:51.488155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144367 (* 1 = 0.144367 loss)
I0905 06:30:51.488169 90901 sgd_solver.cpp:106] Iteration 27080, lr = 0.1
I0905 06:30:57.566156 90901 solver.cpp:228] Iteration 27090, loss = 0.517408
I0905 06:30:57.566287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.517407 (* 1 = 0.517407 loss)
I0905 06:30:57.566315 90901 sgd_solver.cpp:106] Iteration 27090, lr = 0.1
I0905 06:31:03.782207 90901 solver.cpp:228] Iteration 27100, loss = 0.17852
I0905 06:31:03.782250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17852 (* 1 = 0.17852 loss)
I0905 06:31:03.782264 90901 sgd_solver.cpp:106] Iteration 27100, lr = 0.1
I0905 06:31:09.730582 90901 solver.cpp:228] Iteration 27110, loss = 0.096017
I0905 06:31:09.730669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0960168 (* 1 = 0.0960168 loss)
I0905 06:31:09.730686 90901 sgd_solver.cpp:106] Iteration 27110, lr = 0.1
I0905 06:31:16.159008 90901 solver.cpp:228] Iteration 27120, loss = 0.31659
I0905 06:31:16.159070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31659 (* 1 = 0.31659 loss)
I0905 06:31:16.159086 90901 sgd_solver.cpp:106] Iteration 27120, lr = 0.1
I0905 06:31:22.227581 90901 solver.cpp:228] Iteration 27130, loss = 0.186444
I0905 06:31:22.227653 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186444 (* 1 = 0.186444 loss)
I0905 06:31:22.227669 90901 sgd_solver.cpp:106] Iteration 27130, lr = 0.1
I0905 06:31:28.268784 90901 solver.cpp:228] Iteration 27140, loss = 0.168959
I0905 06:31:28.268945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168958 (* 1 = 0.168958 loss)
I0905 06:31:28.268985 90901 sgd_solver.cpp:106] Iteration 27140, lr = 0.1
I0905 06:31:34.293385 90901 solver.cpp:228] Iteration 27150, loss = 0.404624
I0905 06:31:34.293473 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404624 (* 1 = 0.404624 loss)
I0905 06:31:34.293490 90901 sgd_solver.cpp:106] Iteration 27150, lr = 0.1
I0905 06:31:39.785209 90901 solver.cpp:228] Iteration 27160, loss = 0.84172
I0905 06:31:39.785269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.841719 (* 1 = 0.841719 loss)
I0905 06:31:39.785282 90901 sgd_solver.cpp:106] Iteration 27160, lr = 0.1
I0905 06:31:45.592310 90901 solver.cpp:228] Iteration 27170, loss = 0.165233
I0905 06:31:45.592384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165233 (* 1 = 0.165233 loss)
I0905 06:31:45.592401 90901 sgd_solver.cpp:106] Iteration 27170, lr = 0.1
I0905 06:31:51.666343 90901 solver.cpp:228] Iteration 27180, loss = 0.677696
I0905 06:31:51.666411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.677696 (* 1 = 0.677696 loss)
I0905 06:31:51.666427 90901 sgd_solver.cpp:106] Iteration 27180, lr = 0.1
I0905 06:31:57.405544 90901 solver.cpp:228] Iteration 27190, loss = 0.699479
I0905 06:31:57.405619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.699479 (* 1 = 0.699479 loss)
I0905 06:31:57.405635 90901 sgd_solver.cpp:106] Iteration 27190, lr = 0.1
I0905 06:32:03.272260 90901 solver.cpp:337] Iteration 27200, Testing net (#0)
I0905 06:32:45.835449 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.71375
I0905 06:32:45.835678 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.808755 (* 1 = 0.808755 loss)
I0905 06:32:46.051764 90901 solver.cpp:228] Iteration 27200, loss = 0.526498
I0905 06:32:46.051813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.526497 (* 1 = 0.526497 loss)
I0905 06:32:46.051831 90901 sgd_solver.cpp:106] Iteration 27200, lr = 0.1
I0905 06:32:52.440330 90901 solver.cpp:228] Iteration 27210, loss = 0.484379
I0905 06:32:52.440389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484379 (* 1 = 0.484379 loss)
I0905 06:32:52.440404 90901 sgd_solver.cpp:106] Iteration 27210, lr = 0.1
I0905 06:32:58.212456 90901 solver.cpp:228] Iteration 27220, loss = 0.229952
I0905 06:32:58.212525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229951 (* 1 = 0.229951 loss)
I0905 06:32:58.212541 90901 sgd_solver.cpp:106] Iteration 27220, lr = 0.1
I0905 06:33:04.357141 90901 solver.cpp:228] Iteration 27230, loss = 0.209509
I0905 06:33:04.357208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209508 (* 1 = 0.209508 loss)
I0905 06:33:04.357223 90901 sgd_solver.cpp:106] Iteration 27230, lr = 0.1
I0905 06:33:10.097692 90901 solver.cpp:228] Iteration 27240, loss = 0.103871
I0905 06:33:10.097762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10387 (* 1 = 0.10387 loss)
I0905 06:33:10.097779 90901 sgd_solver.cpp:106] Iteration 27240, lr = 0.1
I0905 06:33:16.203990 90901 solver.cpp:228] Iteration 27250, loss = 0.404985
I0905 06:33:16.204226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404985 (* 1 = 0.404985 loss)
I0905 06:33:16.204247 90901 sgd_solver.cpp:106] Iteration 27250, lr = 0.1
I0905 06:33:21.989264 90901 solver.cpp:228] Iteration 27260, loss = 0.265378
I0905 06:33:21.989323 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265377 (* 1 = 0.265377 loss)
I0905 06:33:21.989341 90901 sgd_solver.cpp:106] Iteration 27260, lr = 0.1
I0905 06:33:27.572068 90901 solver.cpp:228] Iteration 27270, loss = 0.29119
I0905 06:33:27.572129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29119 (* 1 = 0.29119 loss)
I0905 06:33:27.572149 90901 sgd_solver.cpp:106] Iteration 27270, lr = 0.1
I0905 06:33:33.477934 90901 solver.cpp:228] Iteration 27280, loss = 0.0815032
I0905 06:33:33.477985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0815028 (* 1 = 0.0815028 loss)
I0905 06:33:33.478003 90901 sgd_solver.cpp:106] Iteration 27280, lr = 0.1
I0905 06:33:39.538007 90901 solver.cpp:228] Iteration 27290, loss = 0.458534
I0905 06:33:39.538043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458533 (* 1 = 0.458533 loss)
I0905 06:33:39.538055 90901 sgd_solver.cpp:106] Iteration 27290, lr = 0.1
I0905 06:33:45.585156 90901 solver.cpp:228] Iteration 27300, loss = 0.0970757
I0905 06:33:45.585208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0970753 (* 1 = 0.0970753 loss)
I0905 06:33:45.585224 90901 sgd_solver.cpp:106] Iteration 27300, lr = 0.1
I0905 06:33:51.664912 90901 solver.cpp:228] Iteration 27310, loss = 0.440934
I0905 06:33:51.665114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440934 (* 1 = 0.440934 loss)
I0905 06:33:51.665151 90901 sgd_solver.cpp:106] Iteration 27310, lr = 0.1
I0905 06:33:58.068897 90901 solver.cpp:228] Iteration 27320, loss = 0.478643
I0905 06:33:58.068939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478642 (* 1 = 0.478642 loss)
I0905 06:33:58.068953 90901 sgd_solver.cpp:106] Iteration 27320, lr = 0.1
I0905 06:34:04.133968 90901 solver.cpp:228] Iteration 27330, loss = 0.380443
I0905 06:34:04.134021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380442 (* 1 = 0.380442 loss)
I0905 06:34:04.134034 90901 sgd_solver.cpp:106] Iteration 27330, lr = 0.1
I0905 06:34:10.222767 90901 solver.cpp:228] Iteration 27340, loss = 0.165593
I0905 06:34:10.222815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165592 (* 1 = 0.165592 loss)
I0905 06:34:10.222831 90901 sgd_solver.cpp:106] Iteration 27340, lr = 0.1
I0905 06:34:16.291553 90901 solver.cpp:228] Iteration 27350, loss = 0.929007
I0905 06:34:16.291610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.929006 (* 1 = 0.929006 loss)
I0905 06:34:16.291623 90901 sgd_solver.cpp:106] Iteration 27350, lr = 0.1
I0905 06:34:22.364902 90901 solver.cpp:228] Iteration 27360, loss = 0.284028
I0905 06:34:22.365114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284028 (* 1 = 0.284028 loss)
I0905 06:34:22.365130 90901 sgd_solver.cpp:106] Iteration 27360, lr = 0.1
I0905 06:34:28.727660 90901 solver.cpp:228] Iteration 27370, loss = 0.192687
I0905 06:34:28.727711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192687 (* 1 = 0.192687 loss)
I0905 06:34:28.727725 90901 sgd_solver.cpp:106] Iteration 27370, lr = 0.1
I0905 06:34:34.795393 90901 solver.cpp:228] Iteration 27380, loss = 0.293725
I0905 06:34:34.795440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293725 (* 1 = 0.293725 loss)
I0905 06:34:34.795454 90901 sgd_solver.cpp:106] Iteration 27380, lr = 0.1
I0905 06:34:40.864711 90901 solver.cpp:228] Iteration 27390, loss = 0.457266
I0905 06:34:40.864758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457265 (* 1 = 0.457265 loss)
I0905 06:34:40.864775 90901 sgd_solver.cpp:106] Iteration 27390, lr = 0.1
I0905 06:34:46.956696 90901 solver.cpp:228] Iteration 27400, loss = 0.181939
I0905 06:34:46.956744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181939 (* 1 = 0.181939 loss)
I0905 06:34:46.956758 90901 sgd_solver.cpp:106] Iteration 27400, lr = 0.1
I0905 06:34:53.032668 90901 solver.cpp:228] Iteration 27410, loss = 0.212817
I0905 06:34:53.032814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212817 (* 1 = 0.212817 loss)
I0905 06:34:53.032829 90901 sgd_solver.cpp:106] Iteration 27410, lr = 0.1
I0905 06:34:59.109727 90901 solver.cpp:228] Iteration 27420, loss = 0.267004
I0905 06:34:59.109778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267003 (* 1 = 0.267003 loss)
I0905 06:34:59.109793 90901 sgd_solver.cpp:106] Iteration 27420, lr = 0.1
I0905 06:35:05.188995 90901 solver.cpp:228] Iteration 27430, loss = 0.267285
I0905 06:35:05.189038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267285 (* 1 = 0.267285 loss)
I0905 06:35:05.189050 90901 sgd_solver.cpp:106] Iteration 27430, lr = 0.1
I0905 06:35:11.194784 90901 solver.cpp:228] Iteration 27440, loss = 0.125058
I0905 06:35:11.194825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125058 (* 1 = 0.125058 loss)
I0905 06:35:11.194840 90901 sgd_solver.cpp:106] Iteration 27440, lr = 0.1
I0905 06:35:16.453227 90901 solver.cpp:228] Iteration 27450, loss = 0.696785
I0905 06:35:16.453277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696785 (* 1 = 0.696785 loss)
I0905 06:35:16.453290 90901 sgd_solver.cpp:106] Iteration 27450, lr = 0.1
I0905 06:35:22.430987 90901 solver.cpp:228] Iteration 27460, loss = 0.491578
I0905 06:35:22.431056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491578 (* 1 = 0.491578 loss)
I0905 06:35:22.431071 90901 sgd_solver.cpp:106] Iteration 27460, lr = 0.1
I0905 06:35:28.491984 90901 solver.cpp:228] Iteration 27470, loss = 0.19976
I0905 06:35:28.492151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19976 (* 1 = 0.19976 loss)
I0905 06:35:28.492194 90901 sgd_solver.cpp:106] Iteration 27470, lr = 0.1
I0905 06:35:34.612131 90901 solver.cpp:228] Iteration 27480, loss = 0.417473
I0905 06:35:34.612171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417472 (* 1 = 0.417472 loss)
I0905 06:35:34.612188 90901 sgd_solver.cpp:106] Iteration 27480, lr = 0.1
I0905 06:35:40.668532 90901 solver.cpp:228] Iteration 27490, loss = 0.309771
I0905 06:35:40.668572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309771 (* 1 = 0.309771 loss)
I0905 06:35:40.668586 90901 sgd_solver.cpp:106] Iteration 27490, lr = 0.1
I0905 06:35:46.723242 90901 solver.cpp:228] Iteration 27500, loss = 0.346232
I0905 06:35:46.723284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346232 (* 1 = 0.346232 loss)
I0905 06:35:46.723301 90901 sgd_solver.cpp:106] Iteration 27500, lr = 0.1
I0905 06:35:53.137869 90901 solver.cpp:228] Iteration 27510, loss = 0.301148
I0905 06:35:53.137938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301147 (* 1 = 0.301147 loss)
I0905 06:35:53.137953 90901 sgd_solver.cpp:106] Iteration 27510, lr = 0.1
I0905 06:35:59.249316 90901 solver.cpp:228] Iteration 27520, loss = 0.145814
I0905 06:35:59.249557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145814 (* 1 = 0.145814 loss)
I0905 06:35:59.249572 90901 sgd_solver.cpp:106] Iteration 27520, lr = 0.1
I0905 06:36:05.325812 90901 solver.cpp:228] Iteration 27530, loss = 0.359126
I0905 06:36:05.325856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359126 (* 1 = 0.359126 loss)
I0905 06:36:05.325870 90901 sgd_solver.cpp:106] Iteration 27530, lr = 0.1
I0905 06:36:11.396764 90901 solver.cpp:228] Iteration 27540, loss = 0.326814
I0905 06:36:11.396811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326813 (* 1 = 0.326813 loss)
I0905 06:36:11.396826 90901 sgd_solver.cpp:106] Iteration 27540, lr = 0.1
I0905 06:36:17.464607 90901 solver.cpp:228] Iteration 27550, loss = 0.171087
I0905 06:36:17.464649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171086 (* 1 = 0.171086 loss)
I0905 06:36:17.464661 90901 sgd_solver.cpp:106] Iteration 27550, lr = 0.1
I0905 06:36:23.733371 90901 solver.cpp:228] Iteration 27560, loss = 0.339713
I0905 06:36:23.733417 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339713 (* 1 = 0.339713 loss)
I0905 06:36:23.733430 90901 sgd_solver.cpp:106] Iteration 27560, lr = 0.1
I0905 06:36:29.769165 90901 solver.cpp:228] Iteration 27570, loss = 0.364228
I0905 06:36:29.769356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364228 (* 1 = 0.364228 loss)
I0905 06:36:29.769392 90901 sgd_solver.cpp:106] Iteration 27570, lr = 0.1
I0905 06:36:35.680647 90901 solver.cpp:228] Iteration 27580, loss = 0.187442
I0905 06:36:35.680694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187442 (* 1 = 0.187442 loss)
I0905 06:36:35.680711 90901 sgd_solver.cpp:106] Iteration 27580, lr = 0.1
I0905 06:36:42.076720 90901 solver.cpp:228] Iteration 27590, loss = 0.247326
I0905 06:36:42.076772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247325 (* 1 = 0.247325 loss)
I0905 06:36:42.076786 90901 sgd_solver.cpp:106] Iteration 27590, lr = 0.1
I0905 06:36:48.123843 90901 solver.cpp:228] Iteration 27600, loss = 0.204326
I0905 06:36:48.123893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204326 (* 1 = 0.204326 loss)
I0905 06:36:48.123908 90901 sgd_solver.cpp:106] Iteration 27600, lr = 0.1
I0905 06:36:54.206801 90901 solver.cpp:228] Iteration 27610, loss = 0.234148
I0905 06:36:54.206852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234147 (* 1 = 0.234147 loss)
I0905 06:36:54.206866 90901 sgd_solver.cpp:106] Iteration 27610, lr = 0.1
I0905 06:36:59.761499 90901 solver.cpp:228] Iteration 27620, loss = 0.0908209
I0905 06:36:59.761544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0908207 (* 1 = 0.0908207 loss)
I0905 06:36:59.761559 90901 sgd_solver.cpp:106] Iteration 27620, lr = 0.1
I0905 06:37:05.104583 90901 solver.cpp:228] Iteration 27630, loss = 0.387617
I0905 06:37:05.104744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387617 (* 1 = 0.387617 loss)
I0905 06:37:05.104786 90901 sgd_solver.cpp:106] Iteration 27630, lr = 0.1
I0905 06:37:10.896760 90901 solver.cpp:228] Iteration 27640, loss = 0.221456
I0905 06:37:10.896803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221456 (* 1 = 0.221456 loss)
I0905 06:37:10.896814 90901 sgd_solver.cpp:106] Iteration 27640, lr = 0.1
I0905 06:37:17.209064 90901 solver.cpp:228] Iteration 27650, loss = 0.137426
I0905 06:37:17.209110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137426 (* 1 = 0.137426 loss)
I0905 06:37:17.209123 90901 sgd_solver.cpp:106] Iteration 27650, lr = 0.1
I0905 06:37:23.287416 90901 solver.cpp:228] Iteration 27660, loss = 0.546474
I0905 06:37:23.287479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546474 (* 1 = 0.546474 loss)
I0905 06:37:23.287494 90901 sgd_solver.cpp:106] Iteration 27660, lr = 0.1
I0905 06:37:29.349700 90901 solver.cpp:228] Iteration 27670, loss = 0.312264
I0905 06:37:29.349750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312263 (* 1 = 0.312263 loss)
I0905 06:37:29.349763 90901 sgd_solver.cpp:106] Iteration 27670, lr = 0.1
I0905 06:37:35.740558 90901 solver.cpp:228] Iteration 27680, loss = 0.567155
I0905 06:37:35.740782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.567154 (* 1 = 0.567154 loss)
I0905 06:37:35.740805 90901 sgd_solver.cpp:106] Iteration 27680, lr = 0.1
I0905 06:37:41.819716 90901 solver.cpp:228] Iteration 27690, loss = 0.310854
I0905 06:37:41.819759 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310854 (* 1 = 0.310854 loss)
I0905 06:37:41.819777 90901 sgd_solver.cpp:106] Iteration 27690, lr = 0.1
I0905 06:37:47.921543 90901 solver.cpp:228] Iteration 27700, loss = 0.331108
I0905 06:37:47.921584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331108 (* 1 = 0.331108 loss)
I0905 06:37:47.921602 90901 sgd_solver.cpp:106] Iteration 27700, lr = 0.1
I0905 06:37:54.003633 90901 solver.cpp:228] Iteration 27710, loss = 0.251805
I0905 06:37:54.003679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251805 (* 1 = 0.251805 loss)
I0905 06:37:54.003695 90901 sgd_solver.cpp:106] Iteration 27710, lr = 0.1
I0905 06:37:59.766568 90901 solver.cpp:228] Iteration 27720, loss = 0.276986
I0905 06:37:59.766611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276986 (* 1 = 0.276986 loss)
I0905 06:37:59.766623 90901 sgd_solver.cpp:106] Iteration 27720, lr = 0.1
I0905 06:38:06.161800 90901 solver.cpp:228] Iteration 27730, loss = 0.22487
I0905 06:38:06.161945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22487 (* 1 = 0.22487 loss)
I0905 06:38:06.161972 90901 sgd_solver.cpp:106] Iteration 27730, lr = 0.1
I0905 06:38:11.935807 90901 solver.cpp:228] Iteration 27740, loss = 0.382714
I0905 06:38:11.935854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382714 (* 1 = 0.382714 loss)
I0905 06:38:11.935868 90901 sgd_solver.cpp:106] Iteration 27740, lr = 0.1
I0905 06:38:18.300097 90901 solver.cpp:228] Iteration 27750, loss = 0.487715
I0905 06:38:18.300153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487714 (* 1 = 0.487714 loss)
I0905 06:38:18.300166 90901 sgd_solver.cpp:106] Iteration 27750, lr = 0.1
I0905 06:38:24.424206 90901 solver.cpp:228] Iteration 27760, loss = 0.238558
I0905 06:38:24.424247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238558 (* 1 = 0.238558 loss)
I0905 06:38:24.424259 90901 sgd_solver.cpp:106] Iteration 27760, lr = 0.1
I0905 06:38:30.483163 90901 solver.cpp:228] Iteration 27770, loss = 0.240653
I0905 06:38:30.483213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240653 (* 1 = 0.240653 loss)
I0905 06:38:30.483228 90901 sgd_solver.cpp:106] Iteration 27770, lr = 0.1
I0905 06:38:36.850819 90901 solver.cpp:228] Iteration 27780, loss = 0.132225
I0905 06:38:36.850947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132225 (* 1 = 0.132225 loss)
I0905 06:38:36.850999 90901 sgd_solver.cpp:106] Iteration 27780, lr = 0.1
I0905 06:38:42.440992 90901 solver.cpp:228] Iteration 27790, loss = 0.142799
I0905 06:38:42.441041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142799 (* 1 = 0.142799 loss)
I0905 06:38:42.441053 90901 sgd_solver.cpp:106] Iteration 27790, lr = 0.1
I0905 06:38:48.013617 90901 solver.cpp:228] Iteration 27800, loss = 0.347274
I0905 06:38:48.013669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347274 (* 1 = 0.347274 loss)
I0905 06:38:48.013682 90901 sgd_solver.cpp:106] Iteration 27800, lr = 0.1
I0905 06:38:53.847268 90901 solver.cpp:228] Iteration 27810, loss = 0.165026
I0905 06:38:53.847321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165026 (* 1 = 0.165026 loss)
I0905 06:38:53.847335 90901 sgd_solver.cpp:106] Iteration 27810, lr = 0.1
I0905 06:38:59.941315 90901 solver.cpp:228] Iteration 27820, loss = 0.225084
I0905 06:38:59.941364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225084 (* 1 = 0.225084 loss)
I0905 06:38:59.941377 90901 sgd_solver.cpp:106] Iteration 27820, lr = 0.1
I0905 06:39:06.287894 90901 solver.cpp:228] Iteration 27830, loss = 0.195329
I0905 06:39:06.287956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195329 (* 1 = 0.195329 loss)
I0905 06:39:06.287971 90901 sgd_solver.cpp:106] Iteration 27830, lr = 0.1
I0905 06:39:12.326830 90901 solver.cpp:228] Iteration 27840, loss = 0.119858
I0905 06:39:12.327059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119858 (* 1 = 0.119858 loss)
I0905 06:39:12.327086 90901 sgd_solver.cpp:106] Iteration 27840, lr = 0.1
I0905 06:39:18.055584 90901 solver.cpp:228] Iteration 27850, loss = 1.17273
I0905 06:39:18.055635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.17273 (* 1 = 1.17273 loss)
I0905 06:39:18.055647 90901 sgd_solver.cpp:106] Iteration 27850, lr = 0.1
I0905 06:39:24.458459 90901 solver.cpp:228] Iteration 27860, loss = 0.28061
I0905 06:39:24.458510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28061 (* 1 = 0.28061 loss)
I0905 06:39:24.458524 90901 sgd_solver.cpp:106] Iteration 27860, lr = 0.1
I0905 06:39:30.516211 90901 solver.cpp:228] Iteration 27870, loss = 0.130781
I0905 06:39:30.516254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130781 (* 1 = 0.130781 loss)
I0905 06:39:30.516266 90901 sgd_solver.cpp:106] Iteration 27870, lr = 0.1
I0905 06:39:36.671519 90901 solver.cpp:228] Iteration 27880, loss = 0.142561
I0905 06:39:36.671582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142561 (* 1 = 0.142561 loss)
I0905 06:39:36.671597 90901 sgd_solver.cpp:106] Iteration 27880, lr = 0.1
I0905 06:39:42.952196 90901 solver.cpp:228] Iteration 27890, loss = 0.366257
I0905 06:39:42.952342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366257 (* 1 = 0.366257 loss)
I0905 06:39:42.952380 90901 sgd_solver.cpp:106] Iteration 27890, lr = 0.1
I0905 06:39:48.414242 90901 solver.cpp:228] Iteration 27900, loss = 0.408475
I0905 06:39:48.414286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408475 (* 1 = 0.408475 loss)
I0905 06:39:48.414302 90901 sgd_solver.cpp:106] Iteration 27900, lr = 0.1
I0905 06:39:55.096124 90901 solver.cpp:228] Iteration 27910, loss = 0.263122
I0905 06:39:55.096177 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263122 (* 1 = 0.263122 loss)
I0905 06:39:55.096190 90901 sgd_solver.cpp:106] Iteration 27910, lr = 0.1
I0905 06:40:00.518127 90901 solver.cpp:228] Iteration 27920, loss = 0.659568
I0905 06:40:00.518172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.659568 (* 1 = 0.659568 loss)
I0905 06:40:00.518185 90901 sgd_solver.cpp:106] Iteration 27920, lr = 0.1
I0905 06:40:05.598395 90901 solver.cpp:228] Iteration 27930, loss = 0.425737
I0905 06:40:05.598459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425737 (* 1 = 0.425737 loss)
I0905 06:40:05.598474 90901 sgd_solver.cpp:106] Iteration 27930, lr = 0.1
I0905 06:40:10.720836 90901 solver.cpp:228] Iteration 27940, loss = 0.208059
I0905 06:40:10.720880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208059 (* 1 = 0.208059 loss)
I0905 06:40:10.720893 90901 sgd_solver.cpp:106] Iteration 27940, lr = 0.1
I0905 06:40:15.749841 90901 solver.cpp:228] Iteration 27950, loss = 0.476956
I0905 06:40:15.750083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476956 (* 1 = 0.476956 loss)
I0905 06:40:15.750107 90901 sgd_solver.cpp:106] Iteration 27950, lr = 0.1
I0905 06:40:20.775975 90901 solver.cpp:228] Iteration 27960, loss = 0.376507
I0905 06:40:20.776022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376507 (* 1 = 0.376507 loss)
I0905 06:40:20.776036 90901 sgd_solver.cpp:106] Iteration 27960, lr = 0.1
I0905 06:40:25.847976 90901 solver.cpp:228] Iteration 27970, loss = 0.297896
I0905 06:40:25.848016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297896 (* 1 = 0.297896 loss)
I0905 06:40:25.848032 90901 sgd_solver.cpp:106] Iteration 27970, lr = 0.1
I0905 06:40:30.797204 90901 solver.cpp:228] Iteration 27980, loss = 0.57728
I0905 06:40:30.797250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.57728 (* 1 = 0.57728 loss)
I0905 06:40:30.797264 90901 sgd_solver.cpp:106] Iteration 27980, lr = 0.1
I0905 06:40:35.446988 90901 solver.cpp:228] Iteration 27990, loss = 0.199121
I0905 06:40:35.447033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199121 (* 1 = 0.199121 loss)
I0905 06:40:35.447046 90901 sgd_solver.cpp:106] Iteration 27990, lr = 0.1
I0905 06:40:39.884753 90901 solver.cpp:337] Iteration 28000, Testing net (#0)
I0905 06:41:14.986013 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.67375
I0905 06:41:14.986153 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.74739 (* 1 = 0.74739 loss)
I0905 06:41:15.202237 90901 solver.cpp:228] Iteration 28000, loss = 0.513017
I0905 06:41:15.202262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513017 (* 1 = 0.513017 loss)
I0905 06:41:15.202278 90901 sgd_solver.cpp:106] Iteration 28000, lr = 0.1
I0905 06:41:20.338316 90901 solver.cpp:228] Iteration 28010, loss = 0.274276
I0905 06:41:20.338361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274275 (* 1 = 0.274275 loss)
I0905 06:41:20.338372 90901 sgd_solver.cpp:106] Iteration 28010, lr = 0.1
I0905 06:41:25.790264 90901 solver.cpp:228] Iteration 28020, loss = 0.186672
I0905 06:41:25.790319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186672 (* 1 = 0.186672 loss)
I0905 06:41:25.790333 90901 sgd_solver.cpp:106] Iteration 28020, lr = 0.1
I0905 06:41:31.887675 90901 solver.cpp:228] Iteration 28030, loss = 0.191093
I0905 06:41:31.887722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191093 (* 1 = 0.191093 loss)
I0905 06:41:31.887734 90901 sgd_solver.cpp:106] Iteration 28030, lr = 0.1
I0905 06:41:38.297757 90901 solver.cpp:228] Iteration 28040, loss = 0.799605
I0905 06:41:38.297802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.799604 (* 1 = 0.799604 loss)
I0905 06:41:38.297816 90901 sgd_solver.cpp:106] Iteration 28040, lr = 0.1
I0905 06:41:44.366488 90901 solver.cpp:228] Iteration 28050, loss = 0.256382
I0905 06:41:44.366538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256382 (* 1 = 0.256382 loss)
I0905 06:41:44.366554 90901 sgd_solver.cpp:106] Iteration 28050, lr = 0.1
I0905 06:41:50.451604 90901 solver.cpp:228] Iteration 28060, loss = 0.327864
I0905 06:41:50.451804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327864 (* 1 = 0.327864 loss)
I0905 06:41:50.451841 90901 sgd_solver.cpp:106] Iteration 28060, lr = 0.1
I0905 06:41:56.419092 90901 solver.cpp:228] Iteration 28070, loss = 0.212672
I0905 06:41:56.419134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212672 (* 1 = 0.212672 loss)
I0905 06:41:56.419152 90901 sgd_solver.cpp:106] Iteration 28070, lr = 0.1
I0905 06:42:02.586927 90901 solver.cpp:228] Iteration 28080, loss = 0.520607
I0905 06:42:02.586969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520607 (* 1 = 0.520607 loss)
I0905 06:42:02.586982 90901 sgd_solver.cpp:106] Iteration 28080, lr = 0.1
I0905 06:42:08.657743 90901 solver.cpp:228] Iteration 28090, loss = 0.47104
I0905 06:42:08.657794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.47104 (* 1 = 0.47104 loss)
I0905 06:42:08.657807 90901 sgd_solver.cpp:106] Iteration 28090, lr = 0.1
I0905 06:42:14.760253 90901 solver.cpp:228] Iteration 28100, loss = 0.669674
I0905 06:42:14.760304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.669674 (* 1 = 0.669674 loss)
I0905 06:42:14.760318 90901 sgd_solver.cpp:106] Iteration 28100, lr = 0.1
I0905 06:42:20.480072 90901 solver.cpp:228] Iteration 28110, loss = 0.410953
I0905 06:42:20.480260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410953 (* 1 = 0.410953 loss)
I0905 06:42:20.480301 90901 sgd_solver.cpp:106] Iteration 28110, lr = 0.1
I0905 06:42:26.040699 90901 solver.cpp:228] Iteration 28120, loss = 0.205243
I0905 06:42:26.040747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205243 (* 1 = 0.205243 loss)
I0905 06:42:26.040762 90901 sgd_solver.cpp:106] Iteration 28120, lr = 0.1
I0905 06:42:31.735322 90901 solver.cpp:228] Iteration 28130, loss = 0.398521
I0905 06:42:31.735383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398521 (* 1 = 0.398521 loss)
I0905 06:42:31.735396 90901 sgd_solver.cpp:106] Iteration 28130, lr = 0.1
I0905 06:42:37.803362 90901 solver.cpp:228] Iteration 28140, loss = 0.329061
I0905 06:42:37.803412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329061 (* 1 = 0.329061 loss)
I0905 06:42:37.803426 90901 sgd_solver.cpp:106] Iteration 28140, lr = 0.1
I0905 06:42:43.888756 90901 solver.cpp:228] Iteration 28150, loss = 0.274893
I0905 06:42:43.888805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274893 (* 1 = 0.274893 loss)
I0905 06:42:43.888823 90901 sgd_solver.cpp:106] Iteration 28150, lr = 0.1
I0905 06:42:50.252210 90901 solver.cpp:228] Iteration 28160, loss = 0.218426
I0905 06:42:50.252269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218426 (* 1 = 0.218426 loss)
I0905 06:42:50.252285 90901 sgd_solver.cpp:106] Iteration 28160, lr = 0.1
I0905 06:42:56.366890 90901 solver.cpp:228] Iteration 28170, loss = 0.410383
I0905 06:42:56.367036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410382 (* 1 = 0.410382 loss)
I0905 06:42:56.367084 90901 sgd_solver.cpp:106] Iteration 28170, lr = 0.1
I0905 06:43:02.420496 90901 solver.cpp:228] Iteration 28180, loss = 0.235976
I0905 06:43:02.420547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235976 (* 1 = 0.235976 loss)
I0905 06:43:02.420558 90901 sgd_solver.cpp:106] Iteration 28180, lr = 0.1
I0905 06:43:08.525229 90901 solver.cpp:228] Iteration 28190, loss = 0.546271
I0905 06:43:08.525285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546271 (* 1 = 0.546271 loss)
I0905 06:43:08.525300 90901 sgd_solver.cpp:106] Iteration 28190, lr = 0.1
I0905 06:43:14.604130 90901 solver.cpp:228] Iteration 28200, loss = 0.287623
I0905 06:43:14.604179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287623 (* 1 = 0.287623 loss)
I0905 06:43:14.604193 90901 sgd_solver.cpp:106] Iteration 28200, lr = 0.1
I0905 06:43:20.359603 90901 solver.cpp:228] Iteration 28210, loss = 0.469992
I0905 06:43:20.359645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469992 (* 1 = 0.469992 loss)
I0905 06:43:20.359658 90901 sgd_solver.cpp:106] Iteration 28210, lr = 0.1
I0905 06:43:26.744900 90901 solver.cpp:228] Iteration 28220, loss = 0.226987
I0905 06:43:26.745033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226987 (* 1 = 0.226987 loss)
I0905 06:43:26.745069 90901 sgd_solver.cpp:106] Iteration 28220, lr = 0.1
I0905 06:43:32.809933 90901 solver.cpp:228] Iteration 28230, loss = 0.216229
I0905 06:43:32.809986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216229 (* 1 = 0.216229 loss)
I0905 06:43:32.810001 90901 sgd_solver.cpp:106] Iteration 28230, lr = 0.1
I0905 06:43:39.103713 90901 solver.cpp:228] Iteration 28240, loss = 0.355394
I0905 06:43:39.103752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355394 (* 1 = 0.355394 loss)
I0905 06:43:39.103766 90901 sgd_solver.cpp:106] Iteration 28240, lr = 0.1
I0905 06:43:45.280900 90901 solver.cpp:228] Iteration 28250, loss = 0.189536
I0905 06:43:45.280951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189535 (* 1 = 0.189535 loss)
I0905 06:43:45.280963 90901 sgd_solver.cpp:106] Iteration 28250, lr = 0.1
I0905 06:43:51.037655 90901 solver.cpp:228] Iteration 28260, loss = 0.173843
I0905 06:43:51.037701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173843 (* 1 = 0.173843 loss)
I0905 06:43:51.037716 90901 sgd_solver.cpp:106] Iteration 28260, lr = 0.1
I0905 06:43:57.156843 90901 solver.cpp:228] Iteration 28270, loss = 0.554393
I0905 06:43:57.157088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.554393 (* 1 = 0.554393 loss)
I0905 06:43:57.157130 90901 sgd_solver.cpp:106] Iteration 28270, lr = 0.1
I0905 06:44:03.215967 90901 solver.cpp:228] Iteration 28280, loss = 0.437372
I0905 06:44:03.216022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437372 (* 1 = 0.437372 loss)
I0905 06:44:03.216037 90901 sgd_solver.cpp:106] Iteration 28280, lr = 0.1
I0905 06:44:08.790328 90901 solver.cpp:228] Iteration 28290, loss = 0.240235
I0905 06:44:08.790376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240235 (* 1 = 0.240235 loss)
I0905 06:44:08.790390 90901 sgd_solver.cpp:106] Iteration 28290, lr = 0.1
I0905 06:44:14.512099 90901 solver.cpp:228] Iteration 28300, loss = 0.499348
I0905 06:44:14.512151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.499348 (* 1 = 0.499348 loss)
I0905 06:44:14.512166 90901 sgd_solver.cpp:106] Iteration 28300, lr = 0.1
I0905 06:44:20.598887 90901 solver.cpp:228] Iteration 28310, loss = 0.333879
I0905 06:44:20.598937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333879 (* 1 = 0.333879 loss)
I0905 06:44:20.598951 90901 sgd_solver.cpp:106] Iteration 28310, lr = 0.1
I0905 06:44:26.642788 90901 solver.cpp:228] Iteration 28320, loss = 0.542821
I0905 06:44:26.642848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.542821 (* 1 = 0.542821 loss)
I0905 06:44:26.642861 90901 sgd_solver.cpp:106] Iteration 28320, lr = 0.1
I0905 06:44:32.684248 90901 solver.cpp:228] Iteration 28330, loss = 0.183639
I0905 06:44:32.684376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183639 (* 1 = 0.183639 loss)
I0905 06:44:32.684418 90901 sgd_solver.cpp:106] Iteration 28330, lr = 0.1
I0905 06:44:39.073042 90901 solver.cpp:228] Iteration 28340, loss = 0.307519
I0905 06:44:39.073089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307519 (* 1 = 0.307519 loss)
I0905 06:44:39.073102 90901 sgd_solver.cpp:106] Iteration 28340, lr = 0.1
I0905 06:44:45.145033 90901 solver.cpp:228] Iteration 28350, loss = 0.276164
I0905 06:44:45.145088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276164 (* 1 = 0.276164 loss)
I0905 06:44:45.145103 90901 sgd_solver.cpp:106] Iteration 28350, lr = 0.1
I0905 06:44:51.191387 90901 solver.cpp:228] Iteration 28360, loss = 0.326074
I0905 06:44:51.191426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326074 (* 1 = 0.326074 loss)
I0905 06:44:51.191442 90901 sgd_solver.cpp:106] Iteration 28360, lr = 0.1
I0905 06:44:57.329460 90901 solver.cpp:228] Iteration 28370, loss = 0.335273
I0905 06:44:57.329509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335273 (* 1 = 0.335273 loss)
I0905 06:44:57.329522 90901 sgd_solver.cpp:106] Iteration 28370, lr = 0.1
I0905 06:45:03.636541 90901 solver.cpp:228] Iteration 28380, loss = 0.300717
I0905 06:45:03.636696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300717 (* 1 = 0.300717 loss)
I0905 06:45:03.636752 90901 sgd_solver.cpp:106] Iteration 28380, lr = 0.1
I0905 06:45:09.679553 90901 solver.cpp:228] Iteration 28390, loss = 0.201429
I0905 06:45:09.679605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201428 (* 1 = 0.201428 loss)
I0905 06:45:09.679620 90901 sgd_solver.cpp:106] Iteration 28390, lr = 0.1
I0905 06:45:15.813693 90901 solver.cpp:228] Iteration 28400, loss = 0.216925
I0905 06:45:15.813731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216924 (* 1 = 0.216924 loss)
I0905 06:45:15.813745 90901 sgd_solver.cpp:106] Iteration 28400, lr = 0.1
I0905 06:45:21.881145 90901 solver.cpp:228] Iteration 28410, loss = 0.0958744
I0905 06:45:21.881187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0958742 (* 1 = 0.0958742 loss)
I0905 06:45:21.881201 90901 sgd_solver.cpp:106] Iteration 28410, lr = 0.1
I0905 06:45:27.944381 90901 solver.cpp:228] Iteration 28420, loss = 0.268711
I0905 06:45:27.944429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26871 (* 1 = 0.26871 loss)
I0905 06:45:27.944444 90901 sgd_solver.cpp:106] Iteration 28420, lr = 0.1
I0905 06:45:34.031853 90901 solver.cpp:228] Iteration 28430, loss = 0.317552
I0905 06:45:34.032050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317552 (* 1 = 0.317552 loss)
I0905 06:45:34.032079 90901 sgd_solver.cpp:106] Iteration 28430, lr = 0.1
I0905 06:45:40.170862 90901 solver.cpp:228] Iteration 28440, loss = 0.109984
I0905 06:45:40.170902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109983 (* 1 = 0.109983 loss)
I0905 06:45:40.170918 90901 sgd_solver.cpp:106] Iteration 28440, lr = 0.1
I0905 06:45:46.483296 90901 solver.cpp:228] Iteration 28450, loss = 0.362746
I0905 06:45:46.483340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362745 (* 1 = 0.362745 loss)
I0905 06:45:46.483355 90901 sgd_solver.cpp:106] Iteration 28450, lr = 0.1
I0905 06:45:52.400691 90901 solver.cpp:228] Iteration 28460, loss = 0.432159
I0905 06:45:52.400735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432158 (* 1 = 0.432158 loss)
I0905 06:45:52.400748 90901 sgd_solver.cpp:106] Iteration 28460, lr = 0.1
I0905 06:45:57.668414 90901 solver.cpp:228] Iteration 28470, loss = 0.601187
I0905 06:45:57.668468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.601187 (* 1 = 0.601187 loss)
I0905 06:45:57.668484 90901 sgd_solver.cpp:106] Iteration 28470, lr = 0.1
I0905 06:46:03.482332 90901 solver.cpp:228] Iteration 28480, loss = 0.421418
I0905 06:46:03.482379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421418 (* 1 = 0.421418 loss)
I0905 06:46:03.482393 90901 sgd_solver.cpp:106] Iteration 28480, lr = 0.1
I0905 06:46:09.529036 90901 solver.cpp:228] Iteration 28490, loss = 0.202814
I0905 06:46:09.529233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202813 (* 1 = 0.202813 loss)
I0905 06:46:09.529261 90901 sgd_solver.cpp:106] Iteration 28490, lr = 0.1
I0905 06:46:15.605664 90901 solver.cpp:228] Iteration 28500, loss = 0.310711
I0905 06:46:15.605733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310711 (* 1 = 0.310711 loss)
I0905 06:46:15.605749 90901 sgd_solver.cpp:106] Iteration 28500, lr = 0.1
I0905 06:46:21.691198 90901 solver.cpp:228] Iteration 28510, loss = 0.538395
I0905 06:46:21.691244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.538395 (* 1 = 0.538395 loss)
I0905 06:46:21.691257 90901 sgd_solver.cpp:106] Iteration 28510, lr = 0.1
I0905 06:46:28.068954 90901 solver.cpp:228] Iteration 28520, loss = 0.11211
I0905 06:46:28.069005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11211 (* 1 = 0.11211 loss)
I0905 06:46:28.069020 90901 sgd_solver.cpp:106] Iteration 28520, lr = 0.1
I0905 06:46:34.167268 90901 solver.cpp:228] Iteration 28530, loss = 0.708469
I0905 06:46:34.167336 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.708469 (* 1 = 0.708469 loss)
I0905 06:46:34.167353 90901 sgd_solver.cpp:106] Iteration 28530, lr = 0.1
I0905 06:46:40.204279 90901 solver.cpp:228] Iteration 28540, loss = 0.430445
I0905 06:46:40.204435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430445 (* 1 = 0.430445 loss)
I0905 06:46:40.204485 90901 sgd_solver.cpp:106] Iteration 28540, lr = 0.1
I0905 06:46:46.290236 90901 solver.cpp:228] Iteration 28550, loss = 0.366101
I0905 06:46:46.290282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366101 (* 1 = 0.366101 loss)
I0905 06:46:46.290299 90901 sgd_solver.cpp:106] Iteration 28550, lr = 0.1
I0905 06:46:52.572492 90901 solver.cpp:228] Iteration 28560, loss = 0.30227
I0905 06:46:52.572573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30227 (* 1 = 0.30227 loss)
I0905 06:46:52.572590 90901 sgd_solver.cpp:106] Iteration 28560, lr = 0.1
I0905 06:46:58.735549 90901 solver.cpp:228] Iteration 28570, loss = 0.780014
I0905 06:46:58.735613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.780014 (* 1 = 0.780014 loss)
I0905 06:46:58.735628 90901 sgd_solver.cpp:106] Iteration 28570, lr = 0.1
I0905 06:47:04.817423 90901 solver.cpp:228] Iteration 28580, loss = 0.299901
I0905 06:47:04.817472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299901 (* 1 = 0.299901 loss)
I0905 06:47:04.817486 90901 sgd_solver.cpp:106] Iteration 28580, lr = 0.1
I0905 06:47:10.908104 90901 solver.cpp:228] Iteration 28590, loss = 0.191509
I0905 06:47:10.908327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191509 (* 1 = 0.191509 loss)
I0905 06:47:10.908345 90901 sgd_solver.cpp:106] Iteration 28590, lr = 0.1
I0905 06:47:16.973052 90901 solver.cpp:228] Iteration 28600, loss = 0.318058
I0905 06:47:16.973103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318058 (* 1 = 0.318058 loss)
I0905 06:47:16.973119 90901 sgd_solver.cpp:106] Iteration 28600, lr = 0.1
I0905 06:47:23.003134 90901 solver.cpp:228] Iteration 28610, loss = 0.219703
I0905 06:47:23.003188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219703 (* 1 = 0.219703 loss)
I0905 06:47:23.003202 90901 sgd_solver.cpp:106] Iteration 28610, lr = 0.1
I0905 06:47:29.081477 90901 solver.cpp:228] Iteration 28620, loss = 0.407665
I0905 06:47:29.081537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407665 (* 1 = 0.407665 loss)
I0905 06:47:29.081552 90901 sgd_solver.cpp:106] Iteration 28620, lr = 0.1
I0905 06:47:35.172634 90901 solver.cpp:228] Iteration 28630, loss = 0.255839
I0905 06:47:35.172690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255839 (* 1 = 0.255839 loss)
I0905 06:47:35.172705 90901 sgd_solver.cpp:106] Iteration 28630, lr = 0.1
I0905 06:47:40.989837 90901 solver.cpp:228] Iteration 28640, loss = 0.294538
I0905 06:47:40.989979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294538 (* 1 = 0.294538 loss)
I0905 06:47:40.990006 90901 sgd_solver.cpp:106] Iteration 28640, lr = 0.1
I0905 06:47:46.258635 90901 solver.cpp:228] Iteration 28650, loss = 0.488887
I0905 06:47:46.258708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488887 (* 1 = 0.488887 loss)
I0905 06:47:46.258721 90901 sgd_solver.cpp:106] Iteration 28650, lr = 0.1
I0905 06:47:51.910367 90901 solver.cpp:228] Iteration 28660, loss = 0.94305
I0905 06:47:51.910439 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.94305 (* 1 = 0.94305 loss)
I0905 06:47:51.910454 90901 sgd_solver.cpp:106] Iteration 28660, lr = 0.1
I0905 06:47:58.314384 90901 solver.cpp:228] Iteration 28670, loss = 0.166358
I0905 06:47:58.314429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166358 (* 1 = 0.166358 loss)
I0905 06:47:58.314445 90901 sgd_solver.cpp:106] Iteration 28670, lr = 0.1
I0905 06:48:04.349459 90901 solver.cpp:228] Iteration 28680, loss = 0.187266
I0905 06:48:04.349514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187266 (* 1 = 0.187266 loss)
I0905 06:48:04.349529 90901 sgd_solver.cpp:106] Iteration 28680, lr = 0.1
I0905 06:48:10.477429 90901 solver.cpp:228] Iteration 28690, loss = 0.332457
I0905 06:48:10.477491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332457 (* 1 = 0.332457 loss)
I0905 06:48:10.477507 90901 sgd_solver.cpp:106] Iteration 28690, lr = 0.1
I0905 06:48:16.268081 90901 solver.cpp:228] Iteration 28700, loss = 0.109521
I0905 06:48:16.268316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109521 (* 1 = 0.109521 loss)
I0905 06:48:16.268347 90901 sgd_solver.cpp:106] Iteration 28700, lr = 0.1
I0905 06:48:22.712126 90901 solver.cpp:228] Iteration 28710, loss = 0.217274
I0905 06:48:22.712221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217274 (* 1 = 0.217274 loss)
I0905 06:48:22.712239 90901 sgd_solver.cpp:106] Iteration 28710, lr = 0.1
I0905 06:48:28.754415 90901 solver.cpp:228] Iteration 28720, loss = 0.778623
I0905 06:48:28.754474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.778623 (* 1 = 0.778623 loss)
I0905 06:48:28.754489 90901 sgd_solver.cpp:106] Iteration 28720, lr = 0.1
I0905 06:48:35.162117 90901 solver.cpp:228] Iteration 28730, loss = 0.218807
I0905 06:48:35.162163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218808 (* 1 = 0.218808 loss)
I0905 06:48:35.162178 90901 sgd_solver.cpp:106] Iteration 28730, lr = 0.1
I0905 06:48:41.237749 90901 solver.cpp:228] Iteration 28740, loss = 0.157088
I0905 06:48:41.237807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157088 (* 1 = 0.157088 loss)
I0905 06:48:41.237821 90901 sgd_solver.cpp:106] Iteration 28740, lr = 0.1
I0905 06:48:47.312095 90901 solver.cpp:228] Iteration 28750, loss = 0.297022
I0905 06:48:47.312793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297022 (* 1 = 0.297022 loss)
I0905 06:48:47.312824 90901 sgd_solver.cpp:106] Iteration 28750, lr = 0.1
I0905 06:48:53.419682 90901 solver.cpp:228] Iteration 28760, loss = 0.362991
I0905 06:48:53.419734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362991 (* 1 = 0.362991 loss)
I0905 06:48:53.419747 90901 sgd_solver.cpp:106] Iteration 28760, lr = 0.1
I0905 06:48:59.530210 90901 solver.cpp:228] Iteration 28770, loss = 0.375815
I0905 06:48:59.530256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375815 (* 1 = 0.375815 loss)
I0905 06:48:59.530269 90901 sgd_solver.cpp:106] Iteration 28770, lr = 0.1
I0905 06:49:05.620928 90901 solver.cpp:228] Iteration 28780, loss = 0.148711
I0905 06:49:05.620986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148711 (* 1 = 0.148711 loss)
I0905 06:49:05.621002 90901 sgd_solver.cpp:106] Iteration 28780, lr = 0.1
I0905 06:49:11.673965 90901 solver.cpp:228] Iteration 28790, loss = 0.261421
I0905 06:49:11.674021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261421 (* 1 = 0.261421 loss)
I0905 06:49:11.674034 90901 sgd_solver.cpp:106] Iteration 28790, lr = 0.1
I0905 06:49:17.833274 90901 solver.cpp:337] Iteration 28800, Testing net (#0)
I0905 06:49:58.690943 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.795313
I0905 06:49:58.691079 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.507405 (* 1 = 0.507405 loss)
I0905 06:49:58.893512 90901 solver.cpp:228] Iteration 28800, loss = 0.210169
I0905 06:49:58.893540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210169 (* 1 = 0.210169 loss)
I0905 06:49:58.893556 90901 sgd_solver.cpp:106] Iteration 28800, lr = 0.1
I0905 06:50:04.970654 90901 solver.cpp:228] Iteration 28810, loss = 0.0511998
I0905 06:50:04.970707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0511998 (* 1 = 0.0511998 loss)
I0905 06:50:04.970723 90901 sgd_solver.cpp:106] Iteration 28810, lr = 0.1
I0905 06:50:11.034735 90901 solver.cpp:228] Iteration 28820, loss = 0.152589
I0905 06:50:11.034782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152589 (* 1 = 0.152589 loss)
I0905 06:50:11.034796 90901 sgd_solver.cpp:106] Iteration 28820, lr = 0.1
I0905 06:50:17.115658 90901 solver.cpp:228] Iteration 28830, loss = 0.61539
I0905 06:50:17.115711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.61539 (* 1 = 0.61539 loss)
I0905 06:50:17.115725 90901 sgd_solver.cpp:106] Iteration 28830, lr = 0.1
I0905 06:50:23.219758 90901 solver.cpp:228] Iteration 28840, loss = 0.546378
I0905 06:50:23.219807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546378 (* 1 = 0.546378 loss)
I0905 06:50:23.219821 90901 sgd_solver.cpp:106] Iteration 28840, lr = 0.1
I0905 06:50:29.304313 90901 solver.cpp:228] Iteration 28850, loss = 0.232239
I0905 06:50:29.304536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232239 (* 1 = 0.232239 loss)
I0905 06:50:29.304550 90901 sgd_solver.cpp:106] Iteration 28850, lr = 0.1
I0905 06:50:35.385650 90901 solver.cpp:228] Iteration 28860, loss = 0.270747
I0905 06:50:35.385692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270747 (* 1 = 0.270747 loss)
I0905 06:50:35.385705 90901 sgd_solver.cpp:106] Iteration 28860, lr = 0.1
I0905 06:50:41.458681 90901 solver.cpp:228] Iteration 28870, loss = 0.274585
I0905 06:50:41.458724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274585 (* 1 = 0.274585 loss)
I0905 06:50:41.458737 90901 sgd_solver.cpp:106] Iteration 28870, lr = 0.1
I0905 06:50:47.517065 90901 solver.cpp:228] Iteration 28880, loss = 0.173108
I0905 06:50:47.517107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173108 (* 1 = 0.173108 loss)
I0905 06:50:47.517119 90901 sgd_solver.cpp:106] Iteration 28880, lr = 0.1
I0905 06:50:53.583531 90901 solver.cpp:228] Iteration 28890, loss = 0.18184
I0905 06:50:53.583580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18184 (* 1 = 0.18184 loss)
I0905 06:50:53.583592 90901 sgd_solver.cpp:106] Iteration 28890, lr = 0.1
I0905 06:50:59.987210 90901 solver.cpp:228] Iteration 28900, loss = 0.259325
I0905 06:50:59.987432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259325 (* 1 = 0.259325 loss)
I0905 06:50:59.987448 90901 sgd_solver.cpp:106] Iteration 28900, lr = 0.1
I0905 06:51:05.903977 90901 solver.cpp:228] Iteration 28910, loss = 0.144193
I0905 06:51:05.904031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144193 (* 1 = 0.144193 loss)
I0905 06:51:05.904045 90901 sgd_solver.cpp:106] Iteration 28910, lr = 0.1
I0905 06:51:11.800381 90901 solver.cpp:228] Iteration 28920, loss = 0.423669
I0905 06:51:11.800423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423669 (* 1 = 0.423669 loss)
I0905 06:51:11.800436 90901 sgd_solver.cpp:106] Iteration 28920, lr = 0.1
I0905 06:51:17.666160 90901 solver.cpp:228] Iteration 28930, loss = 0.24321
I0905 06:51:17.666209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24321 (* 1 = 0.24321 loss)
I0905 06:51:17.666223 90901 sgd_solver.cpp:106] Iteration 28930, lr = 0.1
I0905 06:51:22.987853 90901 solver.cpp:228] Iteration 28940, loss = 0.0565649
I0905 06:51:22.987910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0565649 (* 1 = 0.0565649 loss)
I0905 06:51:22.987923 90901 sgd_solver.cpp:106] Iteration 28940, lr = 0.1
I0905 06:51:29.077142 90901 solver.cpp:228] Iteration 28950, loss = 0.180268
I0905 06:51:29.077193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180268 (* 1 = 0.180268 loss)
I0905 06:51:29.077205 90901 sgd_solver.cpp:106] Iteration 28950, lr = 0.1
I0905 06:51:35.127579 90901 solver.cpp:228] Iteration 28960, loss = 0.109952
I0905 06:51:35.127786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109952 (* 1 = 0.109952 loss)
I0905 06:51:35.127815 90901 sgd_solver.cpp:106] Iteration 28960, lr = 0.1
I0905 06:51:41.198014 90901 solver.cpp:228] Iteration 28970, loss = 0.497378
I0905 06:51:41.198068 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.497378 (* 1 = 0.497378 loss)
I0905 06:51:41.198082 90901 sgd_solver.cpp:106] Iteration 28970, lr = 0.1
I0905 06:51:47.402559 90901 solver.cpp:228] Iteration 28980, loss = 0.224188
I0905 06:51:47.402614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224188 (* 1 = 0.224188 loss)
I0905 06:51:47.402642 90901 sgd_solver.cpp:106] Iteration 28980, lr = 0.1
I0905 06:51:53.655670 90901 solver.cpp:228] Iteration 28990, loss = 0.355527
I0905 06:51:53.655719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355527 (* 1 = 0.355527 loss)
I0905 06:51:53.655742 90901 sgd_solver.cpp:106] Iteration 28990, lr = 0.1
I0905 06:51:59.712985 90901 solver.cpp:228] Iteration 29000, loss = 0.448142
I0905 06:51:59.713027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448142 (* 1 = 0.448142 loss)
I0905 06:51:59.713039 90901 sgd_solver.cpp:106] Iteration 29000, lr = 0.1
I0905 06:52:05.807799 90901 solver.cpp:228] Iteration 29010, loss = 0.167686
I0905 06:52:05.808008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167686 (* 1 = 0.167686 loss)
I0905 06:52:05.808023 90901 sgd_solver.cpp:106] Iteration 29010, lr = 0.1
I0905 06:52:11.858281 90901 solver.cpp:228] Iteration 29020, loss = 0.146641
I0905 06:52:11.858338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146641 (* 1 = 0.146641 loss)
I0905 06:52:11.858352 90901 sgd_solver.cpp:106] Iteration 29020, lr = 0.1
I0905 06:52:17.932113 90901 solver.cpp:228] Iteration 29030, loss = 0.286657
I0905 06:52:17.932163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286657 (* 1 = 0.286657 loss)
I0905 06:52:17.932174 90901 sgd_solver.cpp:106] Iteration 29030, lr = 0.1
I0905 06:52:23.981680 90901 solver.cpp:228] Iteration 29040, loss = 0.156908
I0905 06:52:23.981724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156908 (* 1 = 0.156908 loss)
I0905 06:52:23.981737 90901 sgd_solver.cpp:106] Iteration 29040, lr = 0.1
I0905 06:52:30.071169 90901 solver.cpp:228] Iteration 29050, loss = 0.236825
I0905 06:52:30.071219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236825 (* 1 = 0.236825 loss)
I0905 06:52:30.071233 90901 sgd_solver.cpp:106] Iteration 29050, lr = 0.1
I0905 06:52:36.160794 90901 solver.cpp:228] Iteration 29060, loss = 0.419457
I0905 06:52:36.160971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419457 (* 1 = 0.419457 loss)
I0905 06:52:36.161005 90901 sgd_solver.cpp:106] Iteration 29060, lr = 0.1
I0905 06:52:42.259913 90901 solver.cpp:228] Iteration 29070, loss = 0.351919
I0905 06:52:42.259963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351919 (* 1 = 0.351919 loss)
I0905 06:52:42.259974 90901 sgd_solver.cpp:106] Iteration 29070, lr = 0.1
I0905 06:52:48.353530 90901 solver.cpp:228] Iteration 29080, loss = 0.250313
I0905 06:52:48.353576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250313 (* 1 = 0.250313 loss)
I0905 06:52:48.353591 90901 sgd_solver.cpp:106] Iteration 29080, lr = 0.1
I0905 06:52:54.729440 90901 solver.cpp:228] Iteration 29090, loss = 0.604736
I0905 06:52:54.729491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.604736 (* 1 = 0.604736 loss)
I0905 06:52:54.729504 90901 sgd_solver.cpp:106] Iteration 29090, lr = 0.1
I0905 06:53:00.352829 90901 solver.cpp:228] Iteration 29100, loss = 0.348514
I0905 06:53:00.352885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348514 (* 1 = 0.348514 loss)
I0905 06:53:00.352900 90901 sgd_solver.cpp:106] Iteration 29100, lr = 0.1
I0905 06:53:05.917935 90901 solver.cpp:228] Iteration 29110, loss = 0.594489
I0905 06:53:05.917982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.594489 (* 1 = 0.594489 loss)
I0905 06:53:05.917994 90901 sgd_solver.cpp:106] Iteration 29110, lr = 0.1
I0905 06:53:11.683640 90901 solver.cpp:228] Iteration 29120, loss = 0.316746
I0905 06:53:11.683809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316746 (* 1 = 0.316746 loss)
I0905 06:53:11.683843 90901 sgd_solver.cpp:106] Iteration 29120, lr = 0.1
I0905 06:53:17.739900 90901 solver.cpp:228] Iteration 29130, loss = 0.278389
I0905 06:53:17.739959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278389 (* 1 = 0.278389 loss)
I0905 06:53:17.739974 90901 sgd_solver.cpp:106] Iteration 29130, lr = 0.1
I0905 06:53:23.854043 90901 solver.cpp:228] Iteration 29140, loss = 0.510776
I0905 06:53:23.854096 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.510776 (* 1 = 0.510776 loss)
I0905 06:53:23.854110 90901 sgd_solver.cpp:106] Iteration 29140, lr = 0.1
I0905 06:53:30.258373 90901 solver.cpp:228] Iteration 29150, loss = 0.109047
I0905 06:53:30.258416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109047 (* 1 = 0.109047 loss)
I0905 06:53:30.258431 90901 sgd_solver.cpp:106] Iteration 29150, lr = 0.1
I0905 06:53:36.291923 90901 solver.cpp:228] Iteration 29160, loss = 0.243645
I0905 06:53:36.291966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243645 (* 1 = 0.243645 loss)
I0905 06:53:36.291980 90901 sgd_solver.cpp:106] Iteration 29160, lr = 0.1
I0905 06:53:42.349292 90901 solver.cpp:228] Iteration 29170, loss = 0.444844
I0905 06:53:42.349544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444844 (* 1 = 0.444844 loss)
I0905 06:53:42.349573 90901 sgd_solver.cpp:106] Iteration 29170, lr = 0.1
I0905 06:53:48.426194 90901 solver.cpp:228] Iteration 29180, loss = 0.158933
I0905 06:53:48.426241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158933 (* 1 = 0.158933 loss)
I0905 06:53:48.426255 90901 sgd_solver.cpp:106] Iteration 29180, lr = 0.1
I0905 06:53:54.484313 90901 solver.cpp:228] Iteration 29190, loss = 0.385106
I0905 06:53:54.484354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385106 (* 1 = 0.385106 loss)
I0905 06:53:54.484369 90901 sgd_solver.cpp:106] Iteration 29190, lr = 0.1
I0905 06:54:00.906816 90901 solver.cpp:228] Iteration 29200, loss = 0.194718
I0905 06:54:00.906862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194718 (* 1 = 0.194718 loss)
I0905 06:54:00.906875 90901 sgd_solver.cpp:106] Iteration 29200, lr = 0.1
I0905 06:54:06.759519 90901 solver.cpp:228] Iteration 29210, loss = 0.489974
I0905 06:54:06.759577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489974 (* 1 = 0.489974 loss)
I0905 06:54:06.759591 90901 sgd_solver.cpp:106] Iteration 29210, lr = 0.1
I0905 06:54:12.658895 90901 solver.cpp:228] Iteration 29220, loss = 0.714271
I0905 06:54:12.659109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.714271 (* 1 = 0.714271 loss)
I0905 06:54:12.659157 90901 sgd_solver.cpp:106] Iteration 29220, lr = 0.1
I0905 06:54:18.732969 90901 solver.cpp:228] Iteration 29230, loss = 0.519866
I0905 06:54:18.733006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519866 (* 1 = 0.519866 loss)
I0905 06:54:18.733021 90901 sgd_solver.cpp:106] Iteration 29230, lr = 0.1
I0905 06:54:24.557726 90901 solver.cpp:228] Iteration 29240, loss = 0.471465
I0905 06:54:24.557768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.471465 (* 1 = 0.471465 loss)
I0905 06:54:24.557780 90901 sgd_solver.cpp:106] Iteration 29240, lr = 0.1
I0905 06:54:30.800863 90901 solver.cpp:228] Iteration 29250, loss = 0.304577
I0905 06:54:30.800915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304577 (* 1 = 0.304577 loss)
I0905 06:54:30.800927 90901 sgd_solver.cpp:106] Iteration 29250, lr = 0.1
I0905 06:54:36.957990 90901 solver.cpp:228] Iteration 29260, loss = 0.356612
I0905 06:54:36.958050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356612 (* 1 = 0.356612 loss)
I0905 06:54:36.958073 90901 sgd_solver.cpp:106] Iteration 29260, lr = 0.1
I0905 06:54:43.048424 90901 solver.cpp:228] Iteration 29270, loss = 0.372501
I0905 06:54:43.048600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372501 (* 1 = 0.372501 loss)
I0905 06:54:43.048655 90901 sgd_solver.cpp:106] Iteration 29270, lr = 0.1
I0905 06:54:49.049691 90901 solver.cpp:228] Iteration 29280, loss = 0.461227
I0905 06:54:49.049743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461227 (* 1 = 0.461227 loss)
I0905 06:54:49.049758 90901 sgd_solver.cpp:106] Iteration 29280, lr = 0.1
I0905 06:54:54.552711 90901 solver.cpp:228] Iteration 29290, loss = 0.133132
I0905 06:54:54.552762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133132 (* 1 = 0.133132 loss)
I0905 06:54:54.552777 90901 sgd_solver.cpp:106] Iteration 29290, lr = 0.1
I0905 06:55:00.228080 90901 solver.cpp:228] Iteration 29300, loss = 0.493312
I0905 06:55:00.228135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493312 (* 1 = 0.493312 loss)
I0905 06:55:00.228150 90901 sgd_solver.cpp:106] Iteration 29300, lr = 0.1
I0905 06:55:06.283712 90901 solver.cpp:228] Iteration 29310, loss = 0.326587
I0905 06:55:06.283756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326587 (* 1 = 0.326587 loss)
I0905 06:55:06.283769 90901 sgd_solver.cpp:106] Iteration 29310, lr = 0.1
I0905 06:55:12.429811 90901 solver.cpp:228] Iteration 29320, loss = 0.424591
I0905 06:55:12.429855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424591 (* 1 = 0.424591 loss)
I0905 06:55:12.429872 90901 sgd_solver.cpp:106] Iteration 29320, lr = 0.1
I0905 06:55:18.401645 90901 solver.cpp:228] Iteration 29330, loss = 0.585929
I0905 06:55:18.401898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.585929 (* 1 = 0.585929 loss)
I0905 06:55:18.401927 90901 sgd_solver.cpp:106] Iteration 29330, lr = 0.1
I0905 06:55:24.532604 90901 solver.cpp:228] Iteration 29340, loss = 0.125767
I0905 06:55:24.532656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125767 (* 1 = 0.125767 loss)
I0905 06:55:24.532671 90901 sgd_solver.cpp:106] Iteration 29340, lr = 0.1
I0905 06:55:30.901317 90901 solver.cpp:228] Iteration 29350, loss = 0.361611
I0905 06:55:30.901365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361611 (* 1 = 0.361611 loss)
I0905 06:55:30.901377 90901 sgd_solver.cpp:106] Iteration 29350, lr = 0.1
I0905 06:55:36.678810 90901 solver.cpp:228] Iteration 29360, loss = 0.17288
I0905 06:55:36.678854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17288 (* 1 = 0.17288 loss)
I0905 06:55:36.678869 90901 sgd_solver.cpp:106] Iteration 29360, lr = 0.1
I0905 06:55:43.112690 90901 solver.cpp:228] Iteration 29370, loss = 0.195659
I0905 06:55:43.112742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195659 (* 1 = 0.195659 loss)
I0905 06:55:43.112756 90901 sgd_solver.cpp:106] Iteration 29370, lr = 0.1
I0905 06:55:49.178380 90901 solver.cpp:228] Iteration 29380, loss = 0.138228
I0905 06:55:49.178529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138228 (* 1 = 0.138228 loss)
I0905 06:55:49.178588 90901 sgd_solver.cpp:106] Iteration 29380, lr = 0.1
I0905 06:55:55.267377 90901 solver.cpp:228] Iteration 29390, loss = 0.109795
I0905 06:55:55.267426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109795 (* 1 = 0.109795 loss)
I0905 06:55:55.267439 90901 sgd_solver.cpp:106] Iteration 29390, lr = 0.1
I0905 06:56:01.437938 90901 solver.cpp:228] Iteration 29400, loss = 0.486846
I0905 06:56:01.437979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486846 (* 1 = 0.486846 loss)
I0905 06:56:01.437994 90901 sgd_solver.cpp:106] Iteration 29400, lr = 0.1
I0905 06:56:07.369575 90901 solver.cpp:228] Iteration 29410, loss = 0.359568
I0905 06:56:07.369632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359568 (* 1 = 0.359568 loss)
I0905 06:56:07.369645 90901 sgd_solver.cpp:106] Iteration 29410, lr = 0.1
I0905 06:56:13.572814 90901 solver.cpp:228] Iteration 29420, loss = 0.221106
I0905 06:56:13.572870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221106 (* 1 = 0.221106 loss)
I0905 06:56:13.572885 90901 sgd_solver.cpp:106] Iteration 29420, lr = 0.1
I0905 06:56:19.880913 90901 solver.cpp:228] Iteration 29430, loss = 0.383355
I0905 06:56:19.881052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383355 (* 1 = 0.383355 loss)
I0905 06:56:19.881090 90901 sgd_solver.cpp:106] Iteration 29430, lr = 0.1
I0905 06:56:25.888685 90901 solver.cpp:228] Iteration 29440, loss = 0.313606
I0905 06:56:25.888739 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313606 (* 1 = 0.313606 loss)
I0905 06:56:25.888753 90901 sgd_solver.cpp:106] Iteration 29440, lr = 0.1
I0905 06:56:31.962296 90901 solver.cpp:228] Iteration 29450, loss = 0.27454
I0905 06:56:31.962339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27454 (* 1 = 0.27454 loss)
I0905 06:56:31.962352 90901 sgd_solver.cpp:106] Iteration 29450, lr = 0.1
I0905 06:56:37.908313 90901 solver.cpp:228] Iteration 29460, loss = 0.130461
I0905 06:56:37.908362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130461 (* 1 = 0.130461 loss)
I0905 06:56:37.908375 90901 sgd_solver.cpp:106] Iteration 29460, lr = 0.1
I0905 06:56:43.466814 90901 solver.cpp:228] Iteration 29470, loss = 0.102191
I0905 06:56:43.466856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102191 (* 1 = 0.102191 loss)
I0905 06:56:43.466868 90901 sgd_solver.cpp:106] Iteration 29470, lr = 0.1
I0905 06:56:48.845345 90901 solver.cpp:228] Iteration 29480, loss = 0.398718
I0905 06:56:48.845402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398718 (* 1 = 0.398718 loss)
I0905 06:56:48.845417 90901 sgd_solver.cpp:106] Iteration 29480, lr = 0.1
I0905 06:56:55.224421 90901 solver.cpp:228] Iteration 29490, loss = 0.421933
I0905 06:56:55.224670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421933 (* 1 = 0.421933 loss)
I0905 06:56:55.224714 90901 sgd_solver.cpp:106] Iteration 29490, lr = 0.1
I0905 06:57:01.334208 90901 solver.cpp:228] Iteration 29500, loss = 0.476671
I0905 06:57:01.334259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476671 (* 1 = 0.476671 loss)
I0905 06:57:01.334272 90901 sgd_solver.cpp:106] Iteration 29500, lr = 0.1
I0905 06:57:07.088951 90901 solver.cpp:228] Iteration 29510, loss = 0.570248
I0905 06:57:07.088999 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.570248 (* 1 = 0.570248 loss)
I0905 06:57:07.089012 90901 sgd_solver.cpp:106] Iteration 29510, lr = 0.1
I0905 06:57:13.199456 90901 solver.cpp:228] Iteration 29520, loss = 0.15206
I0905 06:57:13.199513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15206 (* 1 = 0.15206 loss)
I0905 06:57:13.199527 90901 sgd_solver.cpp:106] Iteration 29520, lr = 0.1
I0905 06:57:19.619019 90901 solver.cpp:228] Iteration 29530, loss = 0.158454
I0905 06:57:19.619061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158454 (* 1 = 0.158454 loss)
I0905 06:57:19.619081 90901 sgd_solver.cpp:106] Iteration 29530, lr = 0.1
I0905 06:57:25.674967 90901 solver.cpp:228] Iteration 29540, loss = 0.847102
I0905 06:57:25.675158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.847102 (* 1 = 0.847102 loss)
I0905 06:57:25.675186 90901 sgd_solver.cpp:106] Iteration 29540, lr = 0.1
I0905 06:57:31.760355 90901 solver.cpp:228] Iteration 29550, loss = 0.196812
I0905 06:57:31.760412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196812 (* 1 = 0.196812 loss)
I0905 06:57:31.760426 90901 sgd_solver.cpp:106] Iteration 29550, lr = 0.1
I0905 06:57:37.515647 90901 solver.cpp:228] Iteration 29560, loss = 0.499757
I0905 06:57:37.515707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.499757 (* 1 = 0.499757 loss)
I0905 06:57:37.515722 90901 sgd_solver.cpp:106] Iteration 29560, lr = 0.1
I0905 06:57:43.624842 90901 solver.cpp:228] Iteration 29570, loss = 0.320517
I0905 06:57:43.624888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320517 (* 1 = 0.320517 loss)
I0905 06:57:43.624902 90901 sgd_solver.cpp:106] Iteration 29570, lr = 0.1
I0905 06:57:49.710357 90901 solver.cpp:228] Iteration 29580, loss = 0.288001
I0905 06:57:49.710412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288001 (* 1 = 0.288001 loss)
I0905 06:57:49.710425 90901 sgd_solver.cpp:106] Iteration 29580, lr = 0.1
I0905 06:57:55.462947 90901 solver.cpp:228] Iteration 29590, loss = 0.132528
I0905 06:57:55.462996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132528 (* 1 = 0.132528 loss)
I0905 06:57:55.463009 90901 sgd_solver.cpp:106] Iteration 29590, lr = 0.1
I0905 06:58:00.352664 90901 solver.cpp:337] Iteration 29600, Testing net (#0)
I0905 06:58:34.520472 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.778125
I0905 06:58:34.520598 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.620684 (* 1 = 0.620684 loss)
I0905 06:58:34.721245 90901 solver.cpp:228] Iteration 29600, loss = 0.262914
I0905 06:58:34.721276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262914 (* 1 = 0.262914 loss)
I0905 06:58:34.721292 90901 sgd_solver.cpp:106] Iteration 29600, lr = 0.1
I0905 06:58:39.643157 90901 solver.cpp:228] Iteration 29610, loss = 0.314829
I0905 06:58:39.643224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314829 (* 1 = 0.314829 loss)
I0905 06:58:39.643239 90901 sgd_solver.cpp:106] Iteration 29610, lr = 0.1
I0905 06:58:44.680886 90901 solver.cpp:228] Iteration 29620, loss = 0.480909
I0905 06:58:44.680932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480909 (* 1 = 0.480909 loss)
I0905 06:58:44.680944 90901 sgd_solver.cpp:106] Iteration 29620, lr = 0.1
I0905 06:58:49.721135 90901 solver.cpp:228] Iteration 29630, loss = 0.351296
I0905 06:58:49.721187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351296 (* 1 = 0.351296 loss)
I0905 06:58:49.721201 90901 sgd_solver.cpp:106] Iteration 29630, lr = 0.1
I0905 06:58:54.807842 90901 solver.cpp:228] Iteration 29640, loss = 0.502858
I0905 06:58:54.807898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.502858 (* 1 = 0.502858 loss)
I0905 06:58:54.807912 90901 sgd_solver.cpp:106] Iteration 29640, lr = 0.1
I0905 06:58:59.851138 90901 solver.cpp:228] Iteration 29650, loss = 0.0741974
I0905 06:58:59.851184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0741974 (* 1 = 0.0741974 loss)
I0905 06:58:59.851197 90901 sgd_solver.cpp:106] Iteration 29650, lr = 0.1
I0905 06:59:04.905966 90901 solver.cpp:228] Iteration 29660, loss = 0.27976
I0905 06:59:04.906111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27976 (* 1 = 0.27976 loss)
I0905 06:59:04.906137 90901 sgd_solver.cpp:106] Iteration 29660, lr = 0.1
I0905 06:59:09.987506 90901 solver.cpp:228] Iteration 29670, loss = 0.138242
I0905 06:59:09.987553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138242 (* 1 = 0.138242 loss)
I0905 06:59:09.987566 90901 sgd_solver.cpp:106] Iteration 29670, lr = 0.1
I0905 06:59:15.077240 90901 solver.cpp:228] Iteration 29680, loss = 0.293393
I0905 06:59:15.077286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293393 (* 1 = 0.293393 loss)
I0905 06:59:15.077302 90901 sgd_solver.cpp:106] Iteration 29680, lr = 0.1
I0905 06:59:20.775964 90901 solver.cpp:228] Iteration 29690, loss = 0.424282
I0905 06:59:20.776006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424282 (* 1 = 0.424282 loss)
I0905 06:59:20.776018 90901 sgd_solver.cpp:106] Iteration 29690, lr = 0.1
I0905 06:59:26.895686 90901 solver.cpp:228] Iteration 29700, loss = 0.163363
I0905 06:59:26.895735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163363 (* 1 = 0.163363 loss)
I0905 06:59:26.895750 90901 sgd_solver.cpp:106] Iteration 29700, lr = 0.1
I0905 06:59:33.083957 90901 solver.cpp:228] Iteration 29710, loss = 0.121616
I0905 06:59:33.084002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121616 (* 1 = 0.121616 loss)
I0905 06:59:33.084017 90901 sgd_solver.cpp:106] Iteration 29710, lr = 0.1
I0905 06:59:39.195606 90901 solver.cpp:228] Iteration 29720, loss = 0.119092
I0905 06:59:39.195791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119092 (* 1 = 0.119092 loss)
I0905 06:59:39.195830 90901 sgd_solver.cpp:106] Iteration 29720, lr = 0.1
I0905 06:59:45.415949 90901 solver.cpp:228] Iteration 29730, loss = 0.168312
I0905 06:59:45.416005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168312 (* 1 = 0.168312 loss)
I0905 06:59:45.416019 90901 sgd_solver.cpp:106] Iteration 29730, lr = 0.1
I0905 06:59:51.483535 90901 solver.cpp:228] Iteration 29740, loss = 0.345524
I0905 06:59:51.483587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345524 (* 1 = 0.345524 loss)
I0905 06:59:51.483602 90901 sgd_solver.cpp:106] Iteration 29740, lr = 0.1
I0905 06:59:57.535866 90901 solver.cpp:228] Iteration 29750, loss = 0.649917
I0905 06:59:57.535920 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.649917 (* 1 = 0.649917 loss)
I0905 06:59:57.535935 90901 sgd_solver.cpp:106] Iteration 29750, lr = 0.1
I0905 07:00:03.598647 90901 solver.cpp:228] Iteration 29760, loss = 0.180983
I0905 07:00:03.598693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180984 (* 1 = 0.180984 loss)
I0905 07:00:03.598707 90901 sgd_solver.cpp:106] Iteration 29760, lr = 0.1
I0905 07:00:09.701673 90901 solver.cpp:228] Iteration 29770, loss = 0.629699
I0905 07:00:09.701882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.6297 (* 1 = 0.6297 loss)
I0905 07:00:09.701902 90901 sgd_solver.cpp:106] Iteration 29770, lr = 0.1
I0905 07:00:15.952338 90901 solver.cpp:228] Iteration 29780, loss = 0.698746
I0905 07:00:15.952391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.698746 (* 1 = 0.698746 loss)
I0905 07:00:15.952405 90901 sgd_solver.cpp:106] Iteration 29780, lr = 0.1
I0905 07:00:21.223752 90901 solver.cpp:228] Iteration 29790, loss = 0.459123
I0905 07:00:21.223795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459124 (* 1 = 0.459124 loss)
I0905 07:00:21.223808 90901 sgd_solver.cpp:106] Iteration 29790, lr = 0.1
I0905 07:00:26.659507 90901 solver.cpp:228] Iteration 29800, loss = 0.195044
I0905 07:00:26.659553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195044 (* 1 = 0.195044 loss)
I0905 07:00:26.659565 90901 sgd_solver.cpp:106] Iteration 29800, lr = 0.1
I0905 07:00:32.733384 90901 solver.cpp:228] Iteration 29810, loss = 0.547525
I0905 07:00:32.733433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547525 (* 1 = 0.547525 loss)
I0905 07:00:32.733448 90901 sgd_solver.cpp:106] Iteration 29810, lr = 0.1
I0905 07:00:39.125280 90901 solver.cpp:228] Iteration 29820, loss = 0.282877
I0905 07:00:39.125334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282877 (* 1 = 0.282877 loss)
I0905 07:00:39.125351 90901 sgd_solver.cpp:106] Iteration 29820, lr = 0.1
I0905 07:00:45.183440 90901 solver.cpp:228] Iteration 29830, loss = 0.302842
I0905 07:00:45.183598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302843 (* 1 = 0.302843 loss)
I0905 07:00:45.183640 90901 sgd_solver.cpp:106] Iteration 29830, lr = 0.1
I0905 07:00:50.946780 90901 solver.cpp:228] Iteration 29840, loss = 0.213327
I0905 07:00:50.946830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213327 (* 1 = 0.213327 loss)
I0905 07:00:50.946844 90901 sgd_solver.cpp:106] Iteration 29840, lr = 0.1
I0905 07:00:57.196007 90901 solver.cpp:228] Iteration 29850, loss = 0.401094
I0905 07:00:57.196053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401094 (* 1 = 0.401094 loss)
I0905 07:00:57.196066 90901 sgd_solver.cpp:106] Iteration 29850, lr = 0.1
I0905 07:01:03.447546 90901 solver.cpp:228] Iteration 29860, loss = 0.473128
I0905 07:01:03.447590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473128 (* 1 = 0.473128 loss)
I0905 07:01:03.447604 90901 sgd_solver.cpp:106] Iteration 29860, lr = 0.1
I0905 07:01:09.514771 90901 solver.cpp:228] Iteration 29870, loss = 0.30691
I0905 07:01:09.514816 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30691 (* 1 = 0.30691 loss)
I0905 07:01:09.514829 90901 sgd_solver.cpp:106] Iteration 29870, lr = 0.1
I0905 07:01:15.625377 90901 solver.cpp:228] Iteration 29880, loss = 0.420769
I0905 07:01:15.625509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42077 (* 1 = 0.42077 loss)
I0905 07:01:15.625524 90901 sgd_solver.cpp:106] Iteration 29880, lr = 0.1
I0905 07:01:21.707419 90901 solver.cpp:228] Iteration 29890, loss = 0.641708
I0905 07:01:21.707463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.641709 (* 1 = 0.641709 loss)
I0905 07:01:21.707476 90901 sgd_solver.cpp:106] Iteration 29890, lr = 0.1
I0905 07:01:28.140657 90901 solver.cpp:228] Iteration 29900, loss = 0.346838
I0905 07:01:28.140703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346838 (* 1 = 0.346838 loss)
I0905 07:01:28.140718 90901 sgd_solver.cpp:106] Iteration 29900, lr = 0.1
I0905 07:01:33.923815 90901 solver.cpp:228] Iteration 29910, loss = 0.160876
I0905 07:01:33.923869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160877 (* 1 = 0.160877 loss)
I0905 07:01:33.923882 90901 sgd_solver.cpp:106] Iteration 29910, lr = 0.1
I0905 07:01:39.968451 90901 solver.cpp:228] Iteration 29920, loss = 0.412277
I0905 07:01:39.968497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412277 (* 1 = 0.412277 loss)
I0905 07:01:39.968510 90901 sgd_solver.cpp:106] Iteration 29920, lr = 0.1
I0905 07:01:46.084825 90901 solver.cpp:228] Iteration 29930, loss = 0.173467
I0905 07:01:46.085029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173467 (* 1 = 0.173467 loss)
I0905 07:01:46.085083 90901 sgd_solver.cpp:106] Iteration 29930, lr = 0.1
I0905 07:01:52.151250 90901 solver.cpp:228] Iteration 29940, loss = 0.512467
I0905 07:01:52.151298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.512468 (* 1 = 0.512468 loss)
I0905 07:01:52.151311 90901 sgd_solver.cpp:106] Iteration 29940, lr = 0.1
I0905 07:01:58.255668 90901 solver.cpp:228] Iteration 29950, loss = 0.1716
I0905 07:01:58.255723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1716 (* 1 = 0.1716 loss)
I0905 07:01:58.255738 90901 sgd_solver.cpp:106] Iteration 29950, lr = 0.1
I0905 07:02:04.257863 90901 solver.cpp:228] Iteration 29960, loss = 0.35415
I0905 07:02:04.257908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354151 (* 1 = 0.354151 loss)
I0905 07:02:04.257921 90901 sgd_solver.cpp:106] Iteration 29960, lr = 0.1
I0905 07:02:09.527555 90901 solver.cpp:228] Iteration 29970, loss = 0.176332
I0905 07:02:09.527613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176332 (* 1 = 0.176332 loss)
I0905 07:02:09.527628 90901 sgd_solver.cpp:106] Iteration 29970, lr = 0.1
I0905 07:02:15.168921 90901 solver.cpp:228] Iteration 29980, loss = 0.290302
I0905 07:02:15.168972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290303 (* 1 = 0.290303 loss)
I0905 07:02:15.168985 90901 sgd_solver.cpp:106] Iteration 29980, lr = 0.1
I0905 07:02:21.496963 90901 solver.cpp:228] Iteration 29990, loss = 0.293356
I0905 07:02:21.497159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293356 (* 1 = 0.293356 loss)
I0905 07:02:21.497174 90901 sgd_solver.cpp:106] Iteration 29990, lr = 0.1
I0905 07:02:27.544574 90901 solver.cpp:228] Iteration 30000, loss = 0.442339
I0905 07:02:27.544620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442339 (* 1 = 0.442339 loss)
I0905 07:02:27.544634 90901 sgd_solver.cpp:106] Iteration 30000, lr = 0.1
I0905 07:02:33.623195 90901 solver.cpp:228] Iteration 30010, loss = 0.216769
I0905 07:02:33.623240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216769 (* 1 = 0.216769 loss)
I0905 07:02:33.623252 90901 sgd_solver.cpp:106] Iteration 30010, lr = 0.1
I0905 07:02:40.007032 90901 solver.cpp:228] Iteration 30020, loss = 0.3656
I0905 07:02:40.007088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3656 (* 1 = 0.3656 loss)
I0905 07:02:40.007102 90901 sgd_solver.cpp:106] Iteration 30020, lr = 0.1
I0905 07:02:46.086562 90901 solver.cpp:228] Iteration 30030, loss = 0.117735
I0905 07:02:46.086607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117736 (* 1 = 0.117736 loss)
I0905 07:02:46.086621 90901 sgd_solver.cpp:106] Iteration 30030, lr = 0.1
I0905 07:02:52.166880 90901 solver.cpp:228] Iteration 30040, loss = 0.124995
I0905 07:02:52.167104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124995 (* 1 = 0.124995 loss)
I0905 07:02:52.167132 90901 sgd_solver.cpp:106] Iteration 30040, lr = 0.1
I0905 07:02:58.241842 90901 solver.cpp:228] Iteration 30050, loss = 0.239355
I0905 07:02:58.241894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239355 (* 1 = 0.239355 loss)
I0905 07:02:58.241907 90901 sgd_solver.cpp:106] Iteration 30050, lr = 0.1
I0905 07:03:04.652650 90901 solver.cpp:228] Iteration 30060, loss = 0.366312
I0905 07:03:04.652714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366312 (* 1 = 0.366312 loss)
I0905 07:03:04.652729 90901 sgd_solver.cpp:106] Iteration 30060, lr = 0.1
I0905 07:03:10.395503 90901 solver.cpp:228] Iteration 30070, loss = 0.120308
I0905 07:03:10.395545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120308 (* 1 = 0.120308 loss)
I0905 07:03:10.395558 90901 sgd_solver.cpp:106] Iteration 30070, lr = 0.1
I0905 07:03:16.454736 90901 solver.cpp:228] Iteration 30080, loss = 0.137423
I0905 07:03:16.454789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137424 (* 1 = 0.137424 loss)
I0905 07:03:16.454802 90901 sgd_solver.cpp:106] Iteration 30080, lr = 0.1
I0905 07:03:22.908094 90901 solver.cpp:228] Iteration 30090, loss = 0.401554
I0905 07:03:22.908259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401554 (* 1 = 0.401554 loss)
I0905 07:03:22.908282 90901 sgd_solver.cpp:106] Iteration 30090, lr = 0.1
I0905 07:03:28.998349 90901 solver.cpp:228] Iteration 30100, loss = 0.482397
I0905 07:03:28.998389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482398 (* 1 = 0.482398 loss)
I0905 07:03:28.998402 90901 sgd_solver.cpp:106] Iteration 30100, lr = 0.1
I0905 07:03:35.177842 90901 solver.cpp:228] Iteration 30110, loss = 0.628764
I0905 07:03:35.177892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.628765 (* 1 = 0.628765 loss)
I0905 07:03:35.177907 90901 sgd_solver.cpp:106] Iteration 30110, lr = 0.1
I0905 07:03:41.473389 90901 solver.cpp:228] Iteration 30120, loss = 0.496227
I0905 07:03:41.473445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496227 (* 1 = 0.496227 loss)
I0905 07:03:41.473459 90901 sgd_solver.cpp:106] Iteration 30120, lr = 0.1
I0905 07:03:47.536253 90901 solver.cpp:228] Iteration 30130, loss = 0.244562
I0905 07:03:47.536305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244563 (* 1 = 0.244563 loss)
I0905 07:03:47.536319 90901 sgd_solver.cpp:106] Iteration 30130, lr = 0.1
I0905 07:03:53.194615 90901 solver.cpp:228] Iteration 30140, loss = 0.210328
I0905 07:03:53.194813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210328 (* 1 = 0.210328 loss)
I0905 07:03:53.194859 90901 sgd_solver.cpp:106] Iteration 30140, lr = 0.1
I0905 07:03:58.509029 90901 solver.cpp:228] Iteration 30150, loss = 0.226135
I0905 07:03:58.509091 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226135 (* 1 = 0.226135 loss)
I0905 07:03:58.509106 90901 sgd_solver.cpp:106] Iteration 30150, lr = 0.1
I0905 07:04:04.570106 90901 solver.cpp:228] Iteration 30160, loss = 0.167167
I0905 07:04:04.570148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167167 (* 1 = 0.167167 loss)
I0905 07:04:04.570161 90901 sgd_solver.cpp:106] Iteration 30160, lr = 0.1
I0905 07:04:10.343307 90901 solver.cpp:228] Iteration 30170, loss = 0.166545
I0905 07:04:10.343358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166545 (* 1 = 0.166545 loss)
I0905 07:04:10.343374 90901 sgd_solver.cpp:106] Iteration 30170, lr = 0.1
I0905 07:04:16.735179 90901 solver.cpp:228] Iteration 30180, loss = 0.357262
I0905 07:04:16.735230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357263 (* 1 = 0.357263 loss)
I0905 07:04:16.735245 90901 sgd_solver.cpp:106] Iteration 30180, lr = 0.1
I0905 07:04:22.867679 90901 solver.cpp:228] Iteration 30190, loss = 0.340235
I0905 07:04:22.867728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340235 (* 1 = 0.340235 loss)
I0905 07:04:22.867743 90901 sgd_solver.cpp:106] Iteration 30190, lr = 0.1
I0905 07:04:29.183501 90901 solver.cpp:228] Iteration 30200, loss = 0.3484
I0905 07:04:29.183711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3484 (* 1 = 0.3484 loss)
I0905 07:04:29.183727 90901 sgd_solver.cpp:106] Iteration 30200, lr = 0.1
I0905 07:04:35.258622 90901 solver.cpp:228] Iteration 30210, loss = 0.295711
I0905 07:04:35.258689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295712 (* 1 = 0.295712 loss)
I0905 07:04:35.258704 90901 sgd_solver.cpp:106] Iteration 30210, lr = 0.1
I0905 07:04:41.375409 90901 solver.cpp:228] Iteration 30220, loss = 0.0953248
I0905 07:04:41.375453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0953251 (* 1 = 0.0953251 loss)
I0905 07:04:41.375468 90901 sgd_solver.cpp:106] Iteration 30220, lr = 0.1
I0905 07:04:47.195531 90901 solver.cpp:228] Iteration 30230, loss = 0.16149
I0905 07:04:47.195580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161491 (* 1 = 0.161491 loss)
I0905 07:04:47.195593 90901 sgd_solver.cpp:106] Iteration 30230, lr = 0.1
I0905 07:04:53.526062 90901 solver.cpp:228] Iteration 30240, loss = 0.246368
I0905 07:04:53.526124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246369 (* 1 = 0.246369 loss)
I0905 07:04:53.526139 90901 sgd_solver.cpp:106] Iteration 30240, lr = 0.1
I0905 07:04:59.626328 90901 solver.cpp:228] Iteration 30250, loss = 0.179311
I0905 07:04:59.626433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179312 (* 1 = 0.179312 loss)
I0905 07:04:59.626446 90901 sgd_solver.cpp:106] Iteration 30250, lr = 0.1
I0905 07:05:05.733130 90901 solver.cpp:228] Iteration 30260, loss = 0.588461
I0905 07:05:05.733175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.588461 (* 1 = 0.588461 loss)
I0905 07:05:05.733187 90901 sgd_solver.cpp:106] Iteration 30260, lr = 0.1
I0905 07:05:11.886567 90901 solver.cpp:228] Iteration 30270, loss = 0.386302
I0905 07:05:11.886615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386302 (* 1 = 0.386302 loss)
I0905 07:05:11.886631 90901 sgd_solver.cpp:106] Iteration 30270, lr = 0.1
I0905 07:05:17.915555 90901 solver.cpp:228] Iteration 30280, loss = 0.37085
I0905 07:05:17.915606 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370851 (* 1 = 0.370851 loss)
I0905 07:05:17.915623 90901 sgd_solver.cpp:106] Iteration 30280, lr = 0.1
I0905 07:05:24.211751 90901 solver.cpp:228] Iteration 30290, loss = 0.30813
I0905 07:05:24.211793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30813 (* 1 = 0.30813 loss)
I0905 07:05:24.211807 90901 sgd_solver.cpp:106] Iteration 30290, lr = 0.1
I0905 07:05:30.402853 90901 solver.cpp:228] Iteration 30300, loss = 0.273567
I0905 07:05:30.403082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273567 (* 1 = 0.273567 loss)
I0905 07:05:30.403100 90901 sgd_solver.cpp:106] Iteration 30300, lr = 0.1
I0905 07:05:36.287915 90901 solver.cpp:228] Iteration 30310, loss = 0.330388
I0905 07:05:36.287963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330389 (* 1 = 0.330389 loss)
I0905 07:05:36.287976 90901 sgd_solver.cpp:106] Iteration 30310, lr = 0.1
I0905 07:05:41.539762 90901 solver.cpp:228] Iteration 30320, loss = 0.426321
I0905 07:05:41.539813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426321 (* 1 = 0.426321 loss)
I0905 07:05:41.539827 90901 sgd_solver.cpp:106] Iteration 30320, lr = 0.1
I0905 07:05:47.144106 90901 solver.cpp:228] Iteration 30330, loss = 0.117702
I0905 07:05:47.144160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117703 (* 1 = 0.117703 loss)
I0905 07:05:47.144174 90901 sgd_solver.cpp:106] Iteration 30330, lr = 0.1
I0905 07:05:53.374699 90901 solver.cpp:228] Iteration 30340, loss = 0.421445
I0905 07:05:53.374748 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421446 (* 1 = 0.421446 loss)
I0905 07:05:53.374763 90901 sgd_solver.cpp:106] Iteration 30340, lr = 0.1
I0905 07:05:59.468736 90901 solver.cpp:228] Iteration 30350, loss = 0.27038
I0905 07:05:59.468780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27038 (* 1 = 0.27038 loss)
I0905 07:05:59.468792 90901 sgd_solver.cpp:106] Iteration 30350, lr = 0.1
I0905 07:06:05.522919 90901 solver.cpp:228] Iteration 30360, loss = 0.193996
I0905 07:06:05.523107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193997 (* 1 = 0.193997 loss)
I0905 07:06:05.523145 90901 sgd_solver.cpp:106] Iteration 30360, lr = 0.1
I0905 07:06:11.557281 90901 solver.cpp:228] Iteration 30370, loss = 0.282223
I0905 07:06:11.557325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282223 (* 1 = 0.282223 loss)
I0905 07:06:11.557339 90901 sgd_solver.cpp:106] Iteration 30370, lr = 0.1
I0905 07:06:17.964293 90901 solver.cpp:228] Iteration 30380, loss = 0.18478
I0905 07:06:17.964340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18478 (* 1 = 0.18478 loss)
I0905 07:06:17.964355 90901 sgd_solver.cpp:106] Iteration 30380, lr = 0.1
I0905 07:06:24.025130 90901 solver.cpp:228] Iteration 30390, loss = 0.312677
I0905 07:06:24.025168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312678 (* 1 = 0.312678 loss)
I0905 07:06:24.025182 90901 sgd_solver.cpp:106] Iteration 30390, lr = 0.1
I0905 07:06:30.199496 90901 solver.cpp:337] Iteration 30400, Testing net (#0)
I0905 07:07:12.449827 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.707187
I0905 07:07:12.449992 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.74044 (* 1 = 0.74044 loss)
I0905 07:07:12.852119 90901 solver.cpp:228] Iteration 30400, loss = 0.202553
I0905 07:07:12.852151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202554 (* 1 = 0.202554 loss)
I0905 07:07:12.852167 90901 sgd_solver.cpp:106] Iteration 30400, lr = 0.1
I0905 07:07:18.894302 90901 solver.cpp:228] Iteration 30410, loss = 0.746806
I0905 07:07:18.894347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.746807 (* 1 = 0.746807 loss)
I0905 07:07:18.894361 90901 sgd_solver.cpp:106] Iteration 30410, lr = 0.1
I0905 07:07:24.819195 90901 solver.cpp:228] Iteration 30420, loss = 0.279788
I0905 07:07:24.819254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279788 (* 1 = 0.279788 loss)
I0905 07:07:24.819270 90901 sgd_solver.cpp:106] Iteration 30420, lr = 0.1
I0905 07:07:30.389356 90901 solver.cpp:228] Iteration 30430, loss = 0.342987
I0905 07:07:30.389405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342987 (* 1 = 0.342987 loss)
I0905 07:07:30.389420 90901 sgd_solver.cpp:106] Iteration 30430, lr = 0.1
I0905 07:07:35.852561 90901 solver.cpp:228] Iteration 30440, loss = 0.175403
I0905 07:07:35.852610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175404 (* 1 = 0.175404 loss)
I0905 07:07:35.852624 90901 sgd_solver.cpp:106] Iteration 30440, lr = 0.1
I0905 07:07:41.946521 90901 solver.cpp:228] Iteration 30450, loss = 0.255281
I0905 07:07:41.946569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255282 (* 1 = 0.255282 loss)
I0905 07:07:41.946583 90901 sgd_solver.cpp:106] Iteration 30450, lr = 0.1
I0905 07:07:48.008754 90901 solver.cpp:228] Iteration 30460, loss = 0.226585
I0905 07:07:48.008896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226585 (* 1 = 0.226585 loss)
I0905 07:07:48.008929 90901 sgd_solver.cpp:106] Iteration 30460, lr = 0.1
I0905 07:07:54.343551 90901 solver.cpp:228] Iteration 30470, loss = 0.639233
I0905 07:07:54.343602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.639233 (* 1 = 0.639233 loss)
I0905 07:07:54.343616 90901 sgd_solver.cpp:106] Iteration 30470, lr = 0.1
I0905 07:08:00.395850 90901 solver.cpp:228] Iteration 30480, loss = 0.563145
I0905 07:08:00.395895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.563145 (* 1 = 0.563145 loss)
I0905 07:08:00.395910 90901 sgd_solver.cpp:106] Iteration 30480, lr = 0.1
I0905 07:08:06.525718 90901 solver.cpp:228] Iteration 30490, loss = 0.226033
I0905 07:08:06.525773 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226033 (* 1 = 0.226033 loss)
I0905 07:08:06.525787 90901 sgd_solver.cpp:106] Iteration 30490, lr = 0.1
I0905 07:08:12.456070 90901 solver.cpp:228] Iteration 30500, loss = 0.220201
I0905 07:08:12.456116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220202 (* 1 = 0.220202 loss)
I0905 07:08:12.456131 90901 sgd_solver.cpp:106] Iteration 30500, lr = 0.1
I0905 07:08:18.544742 90901 solver.cpp:228] Iteration 30510, loss = 0.346074
I0905 07:08:18.544966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346074 (* 1 = 0.346074 loss)
I0905 07:08:18.544996 90901 sgd_solver.cpp:106] Iteration 30510, lr = 0.1
I0905 07:08:24.930665 90901 solver.cpp:228] Iteration 30520, loss = 0.246992
I0905 07:08:24.930717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246992 (* 1 = 0.246992 loss)
I0905 07:08:24.930732 90901 sgd_solver.cpp:106] Iteration 30520, lr = 0.1
I0905 07:08:30.698480 90901 solver.cpp:228] Iteration 30530, loss = 0.334224
I0905 07:08:30.698528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334224 (* 1 = 0.334224 loss)
I0905 07:08:30.698540 90901 sgd_solver.cpp:106] Iteration 30530, lr = 0.1
I0905 07:08:36.957396 90901 solver.cpp:228] Iteration 30540, loss = 0.218841
I0905 07:08:36.957458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218841 (* 1 = 0.218841 loss)
I0905 07:08:36.957474 90901 sgd_solver.cpp:106] Iteration 30540, lr = 0.1
I0905 07:08:43.169412 90901 solver.cpp:228] Iteration 30550, loss = 0.413571
I0905 07:08:43.169461 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413571 (* 1 = 0.413571 loss)
I0905 07:08:43.169476 90901 sgd_solver.cpp:106] Iteration 30550, lr = 0.1
I0905 07:08:49.239853 90901 solver.cpp:228] Iteration 30560, loss = 0.229733
I0905 07:08:49.240075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229734 (* 1 = 0.229734 loss)
I0905 07:08:49.240093 90901 sgd_solver.cpp:106] Iteration 30560, lr = 0.1
I0905 07:08:55.298698 90901 solver.cpp:228] Iteration 30570, loss = 0.281754
I0905 07:08:55.298753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281755 (* 1 = 0.281755 loss)
I0905 07:08:55.298766 90901 sgd_solver.cpp:106] Iteration 30570, lr = 0.1
I0905 07:09:01.604106 90901 solver.cpp:228] Iteration 30580, loss = 0.317912
I0905 07:09:01.604153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317913 (* 1 = 0.317913 loss)
I0905 07:09:01.604167 90901 sgd_solver.cpp:106] Iteration 30580, lr = 0.1
I0905 07:09:07.703907 90901 solver.cpp:228] Iteration 30590, loss = 0.474052
I0905 07:09:07.703963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.474053 (* 1 = 0.474053 loss)
I0905 07:09:07.703976 90901 sgd_solver.cpp:106] Iteration 30590, lr = 0.1
I0905 07:09:13.674232 90901 solver.cpp:228] Iteration 30600, loss = 0.225947
I0905 07:09:13.674283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225947 (* 1 = 0.225947 loss)
I0905 07:09:13.674295 90901 sgd_solver.cpp:106] Iteration 30600, lr = 0.1
I0905 07:09:19.234978 90901 solver.cpp:228] Iteration 30610, loss = 0.193475
I0905 07:09:19.235023 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193475 (* 1 = 0.193475 loss)
I0905 07:09:19.235038 90901 sgd_solver.cpp:106] Iteration 30610, lr = 0.1
I0905 07:09:24.636404 90901 solver.cpp:228] Iteration 30620, loss = 0.50373
I0905 07:09:24.636541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.50373 (* 1 = 0.50373 loss)
I0905 07:09:24.636586 90901 sgd_solver.cpp:106] Iteration 30620, lr = 0.1
I0905 07:09:30.725595 90901 solver.cpp:228] Iteration 30630, loss = 0.126783
I0905 07:09:30.725641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126784 (* 1 = 0.126784 loss)
I0905 07:09:30.725652 90901 sgd_solver.cpp:106] Iteration 30630, lr = 0.1
I0905 07:09:36.780586 90901 solver.cpp:228] Iteration 30640, loss = 0.397644
I0905 07:09:36.780632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397645 (* 1 = 0.397645 loss)
I0905 07:09:36.780645 90901 sgd_solver.cpp:106] Iteration 30640, lr = 0.1
I0905 07:09:42.834947 90901 solver.cpp:228] Iteration 30650, loss = 0.383804
I0905 07:09:42.834992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383804 (* 1 = 0.383804 loss)
I0905 07:09:42.835006 90901 sgd_solver.cpp:106] Iteration 30650, lr = 0.1
I0905 07:09:49.250969 90901 solver.cpp:228] Iteration 30660, loss = 0.506959
I0905 07:09:49.251016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.506959 (* 1 = 0.506959 loss)
I0905 07:09:49.251031 90901 sgd_solver.cpp:106] Iteration 30660, lr = 0.1
I0905 07:09:55.303591 90901 solver.cpp:228] Iteration 30670, loss = 0.672634
I0905 07:09:55.303828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.672635 (* 1 = 0.672635 loss)
I0905 07:09:55.303865 90901 sgd_solver.cpp:106] Iteration 30670, lr = 0.1
I0905 07:10:01.392802 90901 solver.cpp:228] Iteration 30680, loss = 0.339587
I0905 07:10:01.392850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339588 (* 1 = 0.339588 loss)
I0905 07:10:01.392865 90901 sgd_solver.cpp:106] Iteration 30680, lr = 0.1
I0905 07:10:07.453994 90901 solver.cpp:228] Iteration 30690, loss = 0.189118
I0905 07:10:07.454040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189118 (* 1 = 0.189118 loss)
I0905 07:10:07.454053 90901 sgd_solver.cpp:106] Iteration 30690, lr = 0.1
I0905 07:10:13.888938 90901 solver.cpp:228] Iteration 30700, loss = 0.633641
I0905 07:10:13.888990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633641 (* 1 = 0.633641 loss)
I0905 07:10:13.889005 90901 sgd_solver.cpp:106] Iteration 30700, lr = 0.1
I0905 07:10:19.925554 90901 solver.cpp:228] Iteration 30710, loss = 0.381807
I0905 07:10:19.925611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381807 (* 1 = 0.381807 loss)
I0905 07:10:19.925624 90901 sgd_solver.cpp:106] Iteration 30710, lr = 0.1
I0905 07:10:26.099653 90901 solver.cpp:228] Iteration 30720, loss = 0.467996
I0905 07:10:26.099845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467996 (* 1 = 0.467996 loss)
I0905 07:10:26.099900 90901 sgd_solver.cpp:106] Iteration 30720, lr = 0.1
I0905 07:10:32.376811 90901 solver.cpp:228] Iteration 30730, loss = 0.638053
I0905 07:10:32.376868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.638053 (* 1 = 0.638053 loss)
I0905 07:10:32.376883 90901 sgd_solver.cpp:106] Iteration 30730, lr = 0.1
I0905 07:10:38.460819 90901 solver.cpp:228] Iteration 30740, loss = 0.231531
I0905 07:10:38.460860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231532 (* 1 = 0.231532 loss)
I0905 07:10:38.460873 90901 sgd_solver.cpp:106] Iteration 30740, lr = 0.1
I0905 07:10:44.515950 90901 solver.cpp:228] Iteration 30750, loss = 0.315969
I0905 07:10:44.516019 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315969 (* 1 = 0.315969 loss)
I0905 07:10:44.516036 90901 sgd_solver.cpp:106] Iteration 30750, lr = 0.1
I0905 07:10:50.622768 90901 solver.cpp:228] Iteration 30760, loss = 0.203762
I0905 07:10:50.622829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203762 (* 1 = 0.203762 loss)
I0905 07:10:50.622849 90901 sgd_solver.cpp:106] Iteration 30760, lr = 0.1
I0905 07:10:56.672273 90901 solver.cpp:228] Iteration 30770, loss = 0.272188
I0905 07:10:56.672489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272188 (* 1 = 0.272188 loss)
I0905 07:10:56.672533 90901 sgd_solver.cpp:106] Iteration 30770, lr = 0.1
I0905 07:11:02.547312 90901 solver.cpp:228] Iteration 30780, loss = 0.393442
I0905 07:11:02.547361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393443 (* 1 = 0.393443 loss)
I0905 07:11:02.547380 90901 sgd_solver.cpp:106] Iteration 30780, lr = 0.1
I0905 07:11:07.906076 90901 solver.cpp:228] Iteration 30790, loss = 0.283081
I0905 07:11:07.906121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283082 (* 1 = 0.283082 loss)
I0905 07:11:07.906133 90901 sgd_solver.cpp:106] Iteration 30790, lr = 0.1
I0905 07:11:13.599583 90901 solver.cpp:228] Iteration 30800, loss = 0.367577
I0905 07:11:13.599630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367577 (* 1 = 0.367577 loss)
I0905 07:11:13.599645 90901 sgd_solver.cpp:106] Iteration 30800, lr = 0.1
I0905 07:11:19.704370 90901 solver.cpp:228] Iteration 30810, loss = 0.331266
I0905 07:11:19.704423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331266 (* 1 = 0.331266 loss)
I0905 07:11:19.704437 90901 sgd_solver.cpp:106] Iteration 30810, lr = 0.1
I0905 07:11:25.800160 90901 solver.cpp:228] Iteration 30820, loss = 0.0516521
I0905 07:11:25.800209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0516525 (* 1 = 0.0516525 loss)
I0905 07:11:25.800223 90901 sgd_solver.cpp:106] Iteration 30820, lr = 0.1
I0905 07:11:32.156460 90901 solver.cpp:228] Iteration 30830, loss = 0.511455
I0905 07:11:32.156677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.511455 (* 1 = 0.511455 loss)
I0905 07:11:32.156697 90901 sgd_solver.cpp:106] Iteration 30830, lr = 0.1
I0905 07:11:38.264567 90901 solver.cpp:228] Iteration 30840, loss = 0.410997
I0905 07:11:38.264614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410997 (* 1 = 0.410997 loss)
I0905 07:11:38.264627 90901 sgd_solver.cpp:106] Iteration 30840, lr = 0.1
I0905 07:11:44.282325 90901 solver.cpp:228] Iteration 30850, loss = 0.458262
I0905 07:11:44.282377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458262 (* 1 = 0.458262 loss)
I0905 07:11:44.282389 90901 sgd_solver.cpp:106] Iteration 30850, lr = 0.1
I0905 07:11:50.303544 90901 solver.cpp:228] Iteration 30860, loss = 0.28895
I0905 07:11:50.303601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288951 (* 1 = 0.288951 loss)
I0905 07:11:50.303617 90901 sgd_solver.cpp:106] Iteration 30860, lr = 0.1
I0905 07:11:56.431891 90901 solver.cpp:228] Iteration 30870, loss = 0.102856
I0905 07:11:56.431962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102857 (* 1 = 0.102857 loss)
I0905 07:11:56.431977 90901 sgd_solver.cpp:106] Iteration 30870, lr = 0.1
I0905 07:12:02.728394 90901 solver.cpp:228] Iteration 30880, loss = 0.173106
I0905 07:12:02.728525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173107 (* 1 = 0.173107 loss)
I0905 07:12:02.728569 90901 sgd_solver.cpp:106] Iteration 30880, lr = 0.1
I0905 07:12:08.797260 90901 solver.cpp:228] Iteration 30890, loss = 0.212111
I0905 07:12:08.797319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212111 (* 1 = 0.212111 loss)
I0905 07:12:08.797333 90901 sgd_solver.cpp:106] Iteration 30890, lr = 0.1
I0905 07:12:14.841748 90901 solver.cpp:228] Iteration 30900, loss = 0.286336
I0905 07:12:14.841805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286336 (* 1 = 0.286336 loss)
I0905 07:12:14.841820 90901 sgd_solver.cpp:106] Iteration 30900, lr = 0.1
I0905 07:12:20.944314 90901 solver.cpp:228] Iteration 30910, loss = 0.143757
I0905 07:12:20.944356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143758 (* 1 = 0.143758 loss)
I0905 07:12:20.944370 90901 sgd_solver.cpp:106] Iteration 30910, lr = 0.1
I0905 07:12:26.996054 90901 solver.cpp:228] Iteration 30920, loss = 0.1426
I0905 07:12:26.996129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1426 (* 1 = 0.1426 loss)
I0905 07:12:26.996146 90901 sgd_solver.cpp:106] Iteration 30920, lr = 0.1
I0905 07:12:33.063596 90901 solver.cpp:228] Iteration 30930, loss = 0.4003
I0905 07:12:33.063781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400301 (* 1 = 0.400301 loss)
I0905 07:12:33.063809 90901 sgd_solver.cpp:106] Iteration 30930, lr = 0.1
I0905 07:12:39.132161 90901 solver.cpp:228] Iteration 30940, loss = 0.352468
I0905 07:12:39.132202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352468 (* 1 = 0.352468 loss)
I0905 07:12:39.132215 90901 sgd_solver.cpp:106] Iteration 30940, lr = 0.1
I0905 07:12:45.211549 90901 solver.cpp:228] Iteration 30950, loss = 0.300969
I0905 07:12:45.211609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30097 (* 1 = 0.30097 loss)
I0905 07:12:45.211625 90901 sgd_solver.cpp:106] Iteration 30950, lr = 0.1
I0905 07:12:51.072103 90901 solver.cpp:228] Iteration 30960, loss = 0.253732
I0905 07:12:51.072171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253733 (* 1 = 0.253733 loss)
I0905 07:12:51.072187 90901 sgd_solver.cpp:106] Iteration 30960, lr = 0.1
I0905 07:12:56.324694 90901 solver.cpp:228] Iteration 30970, loss = 0.333361
I0905 07:12:56.324774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333362 (* 1 = 0.333362 loss)
I0905 07:12:56.324790 90901 sgd_solver.cpp:106] Iteration 30970, lr = 0.1
I0905 07:13:01.944836 90901 solver.cpp:228] Iteration 30980, loss = 0.136389
I0905 07:13:01.944892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13639 (* 1 = 0.13639 loss)
I0905 07:13:01.944914 90901 sgd_solver.cpp:106] Iteration 30980, lr = 0.1
I0905 07:13:08.354833 90901 solver.cpp:228] Iteration 30990, loss = 0.257359
I0905 07:13:08.355063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25736 (* 1 = 0.25736 loss)
I0905 07:13:08.355093 90901 sgd_solver.cpp:106] Iteration 30990, lr = 0.1
I0905 07:13:14.416266 90901 solver.cpp:228] Iteration 31000, loss = 0.154632
I0905 07:13:14.416326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154633 (* 1 = 0.154633 loss)
I0905 07:13:14.416339 90901 sgd_solver.cpp:106] Iteration 31000, lr = 0.1
I0905 07:13:20.473091 90901 solver.cpp:228] Iteration 31010, loss = 0.238481
I0905 07:13:20.473147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238481 (* 1 = 0.238481 loss)
I0905 07:13:20.473163 90901 sgd_solver.cpp:106] Iteration 31010, lr = 0.1
I0905 07:13:26.541811 90901 solver.cpp:228] Iteration 31020, loss = 0.385843
I0905 07:13:26.541854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385844 (* 1 = 0.385844 loss)
I0905 07:13:26.541867 90901 sgd_solver.cpp:106] Iteration 31020, lr = 0.1
I0905 07:13:32.604070 90901 solver.cpp:228] Iteration 31030, loss = 0.176929
I0905 07:13:32.604112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17693 (* 1 = 0.17693 loss)
I0905 07:13:32.604125 90901 sgd_solver.cpp:106] Iteration 31030, lr = 0.1
I0905 07:13:38.664144 90901 solver.cpp:228] Iteration 31040, loss = 0.241277
I0905 07:13:38.664294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241277 (* 1 = 0.241277 loss)
I0905 07:13:38.664335 90901 sgd_solver.cpp:106] Iteration 31040, lr = 0.1
I0905 07:13:45.026926 90901 solver.cpp:228] Iteration 31050, loss = 0.301005
I0905 07:13:45.026962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301005 (* 1 = 0.301005 loss)
I0905 07:13:45.026976 90901 sgd_solver.cpp:106] Iteration 31050, lr = 0.1
I0905 07:13:50.768383 90901 solver.cpp:228] Iteration 31060, loss = 0.297913
I0905 07:13:50.768436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297913 (* 1 = 0.297913 loss)
I0905 07:13:50.768450 90901 sgd_solver.cpp:106] Iteration 31060, lr = 0.1
I0905 07:13:57.162159 90901 solver.cpp:228] Iteration 31070, loss = 0.439715
I0905 07:13:57.162214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439715 (* 1 = 0.439715 loss)
I0905 07:13:57.162226 90901 sgd_solver.cpp:106] Iteration 31070, lr = 0.1
I0905 07:14:03.239881 90901 solver.cpp:228] Iteration 31080, loss = 0.308771
I0905 07:14:03.239933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308772 (* 1 = 0.308772 loss)
I0905 07:14:03.239946 90901 sgd_solver.cpp:106] Iteration 31080, lr = 0.1
I0905 07:14:09.309269 90901 solver.cpp:228] Iteration 31090, loss = 0.273669
I0905 07:14:09.309442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273669 (* 1 = 0.273669 loss)
I0905 07:14:09.309470 90901 sgd_solver.cpp:106] Iteration 31090, lr = 0.1
I0905 07:14:15.392915 90901 solver.cpp:228] Iteration 31100, loss = 0.186845
I0905 07:14:15.392977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186845 (* 1 = 0.186845 loss)
I0905 07:14:15.392992 90901 sgd_solver.cpp:106] Iteration 31100, lr = 0.1
I0905 07:14:21.550918 90901 solver.cpp:228] Iteration 31110, loss = 0.924288
I0905 07:14:21.550971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.924288 (* 1 = 0.924288 loss)
I0905 07:14:21.550986 90901 sgd_solver.cpp:106] Iteration 31110, lr = 0.1
I0905 07:14:27.503355 90901 solver.cpp:228] Iteration 31120, loss = 0.344725
I0905 07:14:27.503408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344726 (* 1 = 0.344726 loss)
I0905 07:14:27.503423 90901 sgd_solver.cpp:106] Iteration 31120, lr = 0.1
I0905 07:14:33.633651 90901 solver.cpp:228] Iteration 31130, loss = 0.327036
I0905 07:14:33.633699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327037 (* 1 = 0.327037 loss)
I0905 07:14:33.633713 90901 sgd_solver.cpp:106] Iteration 31130, lr = 0.1
I0905 07:14:39.299583 90901 solver.cpp:228] Iteration 31140, loss = 0.472919
I0905 07:14:39.299626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.47292 (* 1 = 0.47292 loss)
I0905 07:14:39.299639 90901 sgd_solver.cpp:106] Iteration 31140, lr = 0.1
I0905 07:14:44.258576 90901 solver.cpp:228] Iteration 31150, loss = 0.393896
I0905 07:14:44.258903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393896 (* 1 = 0.393896 loss)
I0905 07:14:44.258929 90901 sgd_solver.cpp:106] Iteration 31150, lr = 0.1
I0905 07:14:50.549772 90901 solver.cpp:228] Iteration 31160, loss = 0.580051
I0905 07:14:50.549819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.580052 (* 1 = 0.580052 loss)
I0905 07:14:50.549834 90901 sgd_solver.cpp:106] Iteration 31160, lr = 0.1
I0905 07:14:56.631456 90901 solver.cpp:228] Iteration 31170, loss = 0.431595
I0905 07:14:56.631501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.431596 (* 1 = 0.431596 loss)
I0905 07:14:56.631515 90901 sgd_solver.cpp:106] Iteration 31170, lr = 0.1
I0905 07:15:02.889786 90901 solver.cpp:228] Iteration 31180, loss = 0.237774
I0905 07:15:02.889839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237775 (* 1 = 0.237775 loss)
I0905 07:15:02.889853 90901 sgd_solver.cpp:106] Iteration 31180, lr = 0.1
I0905 07:15:08.766499 90901 solver.cpp:228] Iteration 31190, loss = 0.0942733
I0905 07:15:08.766589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0942736 (* 1 = 0.0942736 loss)
I0905 07:15:08.766638 90901 sgd_solver.cpp:106] Iteration 31190, lr = 0.1
I0905 07:15:14.953392 90901 solver.cpp:337] Iteration 31200, Testing net (#0)
I0905 07:15:54.116181 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.62625
I0905 07:15:54.116330 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.36398 (* 1 = 1.36398 loss)
I0905 07:15:54.332188 90901 solver.cpp:228] Iteration 31200, loss = 0.558295
I0905 07:15:54.332216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.558295 (* 1 = 0.558295 loss)
I0905 07:15:54.332231 90901 sgd_solver.cpp:106] Iteration 31200, lr = 0.1
I0905 07:15:59.434177 90901 solver.cpp:228] Iteration 31210, loss = 0.103204
I0905 07:15:59.434224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103205 (* 1 = 0.103205 loss)
I0905 07:15:59.434237 90901 sgd_solver.cpp:106] Iteration 31210, lr = 0.1
I0905 07:16:04.498142 90901 solver.cpp:228] Iteration 31220, loss = 0.374481
I0905 07:16:04.498191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374481 (* 1 = 0.374481 loss)
I0905 07:16:04.498204 90901 sgd_solver.cpp:106] Iteration 31220, lr = 0.1
I0905 07:16:09.572440 90901 solver.cpp:228] Iteration 31230, loss = 0.333929
I0905 07:16:09.572492 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333929 (* 1 = 0.333929 loss)
I0905 07:16:09.572506 90901 sgd_solver.cpp:106] Iteration 31230, lr = 0.1
I0905 07:16:14.636255 90901 solver.cpp:228] Iteration 31240, loss = 0.372536
I0905 07:16:14.636302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372536 (* 1 = 0.372536 loss)
I0905 07:16:14.636317 90901 sgd_solver.cpp:106] Iteration 31240, lr = 0.1
I0905 07:16:19.700951 90901 solver.cpp:228] Iteration 31250, loss = 0.391176
I0905 07:16:19.701014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391176 (* 1 = 0.391176 loss)
I0905 07:16:19.701028 90901 sgd_solver.cpp:106] Iteration 31250, lr = 0.1
I0905 07:16:24.607702 90901 solver.cpp:228] Iteration 31260, loss = 0.0658636
I0905 07:16:24.607882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0658639 (* 1 = 0.0658639 loss)
I0905 07:16:24.607904 90901 sgd_solver.cpp:106] Iteration 31260, lr = 0.1
I0905 07:16:29.256577 90901 solver.cpp:228] Iteration 31270, loss = 0.446976
I0905 07:16:29.256623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446976 (* 1 = 0.446976 loss)
I0905 07:16:29.256634 90901 sgd_solver.cpp:106] Iteration 31270, lr = 0.1
I0905 07:16:33.906780 90901 solver.cpp:228] Iteration 31280, loss = 0.440369
I0905 07:16:33.906836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44037 (* 1 = 0.44037 loss)
I0905 07:16:33.906850 90901 sgd_solver.cpp:106] Iteration 31280, lr = 0.1
I0905 07:16:38.930312 90901 solver.cpp:228] Iteration 31290, loss = 0.365492
I0905 07:16:38.930347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365492 (* 1 = 0.365492 loss)
I0905 07:16:38.930361 90901 sgd_solver.cpp:106] Iteration 31290, lr = 0.1
I0905 07:16:43.977812 90901 solver.cpp:228] Iteration 31300, loss = 0.208508
I0905 07:16:43.977854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208508 (* 1 = 0.208508 loss)
I0905 07:16:43.977870 90901 sgd_solver.cpp:106] Iteration 31300, lr = 0.1
I0905 07:16:49.071898 90901 solver.cpp:228] Iteration 31310, loss = 0.441531
I0905 07:16:49.071938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.441531 (* 1 = 0.441531 loss)
I0905 07:16:49.071949 90901 sgd_solver.cpp:106] Iteration 31310, lr = 0.1
I0905 07:16:54.104738 90901 solver.cpp:228] Iteration 31320, loss = 0.802524
I0905 07:16:54.104787 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.802525 (* 1 = 0.802525 loss)
I0905 07:16:54.104799 90901 sgd_solver.cpp:106] Iteration 31320, lr = 0.1
I0905 07:16:59.149679 90901 solver.cpp:228] Iteration 31330, loss = 0.170189
I0905 07:16:59.149830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170189 (* 1 = 0.170189 loss)
I0905 07:16:59.149871 90901 sgd_solver.cpp:106] Iteration 31330, lr = 0.1
I0905 07:17:04.245261 90901 solver.cpp:228] Iteration 31340, loss = 0.595633
I0905 07:17:04.245298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.595633 (* 1 = 0.595633 loss)
I0905 07:17:04.245311 90901 sgd_solver.cpp:106] Iteration 31340, lr = 0.1
I0905 07:17:10.300210 90901 solver.cpp:228] Iteration 31350, loss = 0.318032
I0905 07:17:10.300254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318032 (* 1 = 0.318032 loss)
I0905 07:17:10.300268 90901 sgd_solver.cpp:106] Iteration 31350, lr = 0.1
I0905 07:17:16.671895 90901 solver.cpp:228] Iteration 31360, loss = 0.22618
I0905 07:17:16.671947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226181 (* 1 = 0.226181 loss)
I0905 07:17:16.671960 90901 sgd_solver.cpp:106] Iteration 31360, lr = 0.1
I0905 07:17:22.429124 90901 solver.cpp:228] Iteration 31370, loss = 0.271967
I0905 07:17:22.429169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271968 (* 1 = 0.271968 loss)
I0905 07:17:22.429183 90901 sgd_solver.cpp:106] Iteration 31370, lr = 0.1
I0905 07:17:28.509680 90901 solver.cpp:228] Iteration 31380, loss = 0.301229
I0905 07:17:28.509729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301229 (* 1 = 0.301229 loss)
I0905 07:17:28.509743 90901 sgd_solver.cpp:106] Iteration 31380, lr = 0.1
I0905 07:17:34.602936 90901 solver.cpp:228] Iteration 31390, loss = 0.192204
I0905 07:17:34.603212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192204 (* 1 = 0.192204 loss)
I0905 07:17:34.603225 90901 sgd_solver.cpp:106] Iteration 31390, lr = 0.1
I0905 07:17:40.669431 90901 solver.cpp:228] Iteration 31400, loss = 0.187645
I0905 07:17:40.669472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187646 (* 1 = 0.187646 loss)
I0905 07:17:40.669487 90901 sgd_solver.cpp:106] Iteration 31400, lr = 0.1
I0905 07:17:46.721272 90901 solver.cpp:228] Iteration 31410, loss = 0.168421
I0905 07:17:46.721324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168421 (* 1 = 0.168421 loss)
I0905 07:17:46.721338 90901 sgd_solver.cpp:106] Iteration 31410, lr = 0.1
I0905 07:17:52.817181 90901 solver.cpp:228] Iteration 31420, loss = 0.148068
I0905 07:17:52.817230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148068 (* 1 = 0.148068 loss)
I0905 07:17:52.817245 90901 sgd_solver.cpp:106] Iteration 31420, lr = 0.1
I0905 07:17:58.875474 90901 solver.cpp:228] Iteration 31430, loss = 0.415616
I0905 07:17:58.875519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415617 (* 1 = 0.415617 loss)
I0905 07:17:58.875531 90901 sgd_solver.cpp:106] Iteration 31430, lr = 0.1
I0905 07:18:04.952636 90901 solver.cpp:228] Iteration 31440, loss = 0.314276
I0905 07:18:04.952831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314276 (* 1 = 0.314276 loss)
I0905 07:18:04.952848 90901 sgd_solver.cpp:106] Iteration 31440, lr = 0.1
I0905 07:18:11.016600 90901 solver.cpp:228] Iteration 31450, loss = 0.277698
I0905 07:18:11.016650 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277699 (* 1 = 0.277699 loss)
I0905 07:18:11.016664 90901 sgd_solver.cpp:106] Iteration 31450, lr = 0.1
I0905 07:18:16.592555 90901 solver.cpp:228] Iteration 31460, loss = 0.144891
I0905 07:18:16.592627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144891 (* 1 = 0.144891 loss)
I0905 07:18:16.592640 90901 sgd_solver.cpp:106] Iteration 31460, lr = 0.1
I0905 07:18:21.944038 90901 solver.cpp:228] Iteration 31470, loss = 0.0844941
I0905 07:18:21.944092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0844944 (* 1 = 0.0844944 loss)
I0905 07:18:21.944108 90901 sgd_solver.cpp:106] Iteration 31470, lr = 0.1
I0905 07:18:28.017717 90901 solver.cpp:228] Iteration 31480, loss = 0.292647
I0905 07:18:28.017760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292647 (* 1 = 0.292647 loss)
I0905 07:18:28.017773 90901 sgd_solver.cpp:106] Iteration 31480, lr = 0.1
I0905 07:18:34.390485 90901 solver.cpp:228] Iteration 31490, loss = 0.251732
I0905 07:18:34.390532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251732 (* 1 = 0.251732 loss)
I0905 07:18:34.390547 90901 sgd_solver.cpp:106] Iteration 31490, lr = 0.1
I0905 07:18:40.390897 90901 solver.cpp:228] Iteration 31500, loss = 0.254401
I0905 07:18:40.391113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254401 (* 1 = 0.254401 loss)
I0905 07:18:40.391130 90901 sgd_solver.cpp:106] Iteration 31500, lr = 0.1
I0905 07:18:46.157888 90901 solver.cpp:228] Iteration 31510, loss = 0.311803
I0905 07:18:46.157933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311803 (* 1 = 0.311803 loss)
I0905 07:18:46.157946 90901 sgd_solver.cpp:106] Iteration 31510, lr = 0.1
I0905 07:18:52.179407 90901 solver.cpp:228] Iteration 31520, loss = 0.243416
I0905 07:18:52.179455 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243416 (* 1 = 0.243416 loss)
I0905 07:18:52.179466 90901 sgd_solver.cpp:106] Iteration 31520, lr = 0.1
I0905 07:18:58.207793 90901 solver.cpp:228] Iteration 31530, loss = 0.554774
I0905 07:18:58.207839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.554775 (* 1 = 0.554775 loss)
I0905 07:18:58.207852 90901 sgd_solver.cpp:106] Iteration 31530, lr = 0.1
I0905 07:19:04.344008 90901 solver.cpp:228] Iteration 31540, loss = 0.664748
I0905 07:19:04.344063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.664749 (* 1 = 0.664749 loss)
I0905 07:19:04.344076 90901 sgd_solver.cpp:106] Iteration 31540, lr = 0.1
I0905 07:19:10.454607 90901 solver.cpp:228] Iteration 31550, loss = 0.103726
I0905 07:19:10.454805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103726 (* 1 = 0.103726 loss)
I0905 07:19:10.454819 90901 sgd_solver.cpp:106] Iteration 31550, lr = 0.1
I0905 07:19:16.815997 90901 solver.cpp:228] Iteration 31560, loss = 0.5211
I0905 07:19:16.816047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.5211 (* 1 = 0.5211 loss)
I0905 07:19:16.816063 90901 sgd_solver.cpp:106] Iteration 31560, lr = 0.1
I0905 07:19:23.213212 90901 solver.cpp:228] Iteration 31570, loss = 0.29806
I0905 07:19:23.213253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29806 (* 1 = 0.29806 loss)
I0905 07:19:23.213268 90901 sgd_solver.cpp:106] Iteration 31570, lr = 0.1
I0905 07:19:29.283181 90901 solver.cpp:228] Iteration 31580, loss = 0.396199
I0905 07:19:29.283224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396199 (* 1 = 0.396199 loss)
I0905 07:19:29.283237 90901 sgd_solver.cpp:106] Iteration 31580, lr = 0.1
I0905 07:19:35.399490 90901 solver.cpp:228] Iteration 31590, loss = 0.462378
I0905 07:19:35.399536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462379 (* 1 = 0.462379 loss)
I0905 07:19:35.399550 90901 sgd_solver.cpp:106] Iteration 31590, lr = 0.1
I0905 07:19:41.253976 90901 solver.cpp:228] Iteration 31600, loss = 0.642491
I0905 07:19:41.254055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.642491 (* 1 = 0.642491 loss)
I0905 07:19:41.254068 90901 sgd_solver.cpp:106] Iteration 31600, lr = 0.1
I0905 07:19:47.519815 90901 solver.cpp:228] Iteration 31610, loss = 0.624191
I0905 07:19:47.519860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.624191 (* 1 = 0.624191 loss)
I0905 07:19:47.519873 90901 sgd_solver.cpp:106] Iteration 31610, lr = 0.1
I0905 07:19:53.575130 90901 solver.cpp:228] Iteration 31620, loss = 0.262172
I0905 07:19:53.575181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262173 (* 1 = 0.262173 loss)
I0905 07:19:53.575196 90901 sgd_solver.cpp:106] Iteration 31620, lr = 0.1
I0905 07:19:59.849212 90901 solver.cpp:228] Iteration 31630, loss = 0.346849
I0905 07:19:59.849267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346849 (* 1 = 0.346849 loss)
I0905 07:19:59.849282 90901 sgd_solver.cpp:106] Iteration 31630, lr = 0.1
I0905 07:20:05.108584 90901 solver.cpp:228] Iteration 31640, loss = 0.386953
I0905 07:20:05.108629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386953 (* 1 = 0.386953 loss)
I0905 07:20:05.108644 90901 sgd_solver.cpp:106] Iteration 31640, lr = 0.1
I0905 07:20:10.761409 90901 solver.cpp:228] Iteration 31650, loss = 0.15592
I0905 07:20:10.761457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15592 (* 1 = 0.15592 loss)
I0905 07:20:10.761472 90901 sgd_solver.cpp:106] Iteration 31650, lr = 0.1
I0905 07:20:16.824405 90901 solver.cpp:228] Iteration 31660, loss = 0.202411
I0905 07:20:16.824540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202412 (* 1 = 0.202412 loss)
I0905 07:20:16.824568 90901 sgd_solver.cpp:106] Iteration 31660, lr = 0.1
I0905 07:20:22.927856 90901 solver.cpp:228] Iteration 31670, loss = 0.164798
I0905 07:20:22.927898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164798 (* 1 = 0.164798 loss)
I0905 07:20:22.927911 90901 sgd_solver.cpp:106] Iteration 31670, lr = 0.1
I0905 07:20:28.699726 90901 solver.cpp:228] Iteration 31680, loss = 0.413917
I0905 07:20:28.699772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413917 (* 1 = 0.413917 loss)
I0905 07:20:28.699786 90901 sgd_solver.cpp:106] Iteration 31680, lr = 0.1
I0905 07:20:35.089509 90901 solver.cpp:228] Iteration 31690, loss = 0.145783
I0905 07:20:35.089556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145783 (* 1 = 0.145783 loss)
I0905 07:20:35.089570 90901 sgd_solver.cpp:106] Iteration 31690, lr = 0.1
I0905 07:20:40.804781 90901 solver.cpp:228] Iteration 31700, loss = 0.274224
I0905 07:20:40.804823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274224 (* 1 = 0.274224 loss)
I0905 07:20:40.804836 90901 sgd_solver.cpp:106] Iteration 31700, lr = 0.1
I0905 07:20:46.917677 90901 solver.cpp:228] Iteration 31710, loss = 0.226616
I0905 07:20:46.917846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226616 (* 1 = 0.226616 loss)
I0905 07:20:46.917899 90901 sgd_solver.cpp:106] Iteration 31710, lr = 0.1
I0905 07:20:52.957947 90901 solver.cpp:228] Iteration 31720, loss = 0.42821
I0905 07:20:52.958001 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42821 (* 1 = 0.42821 loss)
I0905 07:20:52.958016 90901 sgd_solver.cpp:106] Iteration 31720, lr = 0.1
I0905 07:20:59.027369 90901 solver.cpp:228] Iteration 31730, loss = 0.212929
I0905 07:20:59.027415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212929 (* 1 = 0.212929 loss)
I0905 07:20:59.027426 90901 sgd_solver.cpp:106] Iteration 31730, lr = 0.1
I0905 07:21:05.464648 90901 solver.cpp:228] Iteration 31740, loss = 0.286743
I0905 07:21:05.464700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286744 (* 1 = 0.286744 loss)
I0905 07:21:05.464715 90901 sgd_solver.cpp:106] Iteration 31740, lr = 0.1
I0905 07:21:11.558598 90901 solver.cpp:228] Iteration 31750, loss = 0.460389
I0905 07:21:11.558652 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460389 (* 1 = 0.460389 loss)
I0905 07:21:11.558672 90901 sgd_solver.cpp:106] Iteration 31750, lr = 0.1
I0905 07:21:17.289628 90901 solver.cpp:228] Iteration 31760, loss = 0.477787
I0905 07:21:17.289829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477787 (* 1 = 0.477787 loss)
I0905 07:21:17.289857 90901 sgd_solver.cpp:106] Iteration 31760, lr = 0.1
I0905 07:21:23.715148 90901 solver.cpp:228] Iteration 31770, loss = 0.0544264
I0905 07:21:23.715198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0544267 (* 1 = 0.0544267 loss)
I0905 07:21:23.715210 90901 sgd_solver.cpp:106] Iteration 31770, lr = 0.1
I0905 07:21:29.784793 90901 solver.cpp:228] Iteration 31780, loss = 0.383021
I0905 07:21:29.784862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383021 (* 1 = 0.383021 loss)
I0905 07:21:29.784878 90901 sgd_solver.cpp:106] Iteration 31780, lr = 0.1
I0905 07:21:35.864706 90901 solver.cpp:228] Iteration 31790, loss = 0.0599502
I0905 07:21:35.864783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0599505 (* 1 = 0.0599505 loss)
I0905 07:21:35.864802 90901 sgd_solver.cpp:106] Iteration 31790, lr = 0.1
I0905 07:21:41.936775 90901 solver.cpp:228] Iteration 31800, loss = 0.298727
I0905 07:21:41.936837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298727 (* 1 = 0.298727 loss)
I0905 07:21:41.936854 90901 sgd_solver.cpp:106] Iteration 31800, lr = 0.1
I0905 07:21:47.849323 90901 solver.cpp:228] Iteration 31810, loss = 0.461808
I0905 07:21:47.849483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461809 (* 1 = 0.461809 loss)
I0905 07:21:47.849498 90901 sgd_solver.cpp:106] Iteration 31810, lr = 0.1
I0905 07:21:53.628959 90901 solver.cpp:228] Iteration 31820, loss = 0.608655
I0905 07:21:53.629032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.608656 (* 1 = 0.608656 loss)
I0905 07:21:53.629048 90901 sgd_solver.cpp:106] Iteration 31820, lr = 0.1
I0905 07:21:59.151199 90901 solver.cpp:228] Iteration 31830, loss = 0.589303
I0905 07:21:59.151248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.589303 (* 1 = 0.589303 loss)
I0905 07:21:59.151263 90901 sgd_solver.cpp:106] Iteration 31830, lr = 0.1
I0905 07:22:05.208788 90901 solver.cpp:228] Iteration 31840, loss = 0.147828
I0905 07:22:05.208854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147829 (* 1 = 0.147829 loss)
I0905 07:22:05.208869 90901 sgd_solver.cpp:106] Iteration 31840, lr = 0.1
I0905 07:22:10.972793 90901 solver.cpp:228] Iteration 31850, loss = 0.0825051
I0905 07:22:10.972844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0825053 (* 1 = 0.0825053 loss)
I0905 07:22:10.972859 90901 sgd_solver.cpp:106] Iteration 31850, lr = 0.1
I0905 07:22:17.029150 90901 solver.cpp:228] Iteration 31860, loss = 0.119886
I0905 07:22:17.029199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119886 (* 1 = 0.119886 loss)
I0905 07:22:17.029212 90901 sgd_solver.cpp:106] Iteration 31860, lr = 0.1
I0905 07:22:23.118994 90901 solver.cpp:228] Iteration 31870, loss = 0.291013
I0905 07:22:23.119216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291013 (* 1 = 0.291013 loss)
I0905 07:22:23.119231 90901 sgd_solver.cpp:106] Iteration 31870, lr = 0.1
I0905 07:22:29.207036 90901 solver.cpp:228] Iteration 31880, loss = 0.313743
I0905 07:22:29.207098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313743 (* 1 = 0.313743 loss)
I0905 07:22:29.207113 90901 sgd_solver.cpp:106] Iteration 31880, lr = 0.1
I0905 07:22:35.271641 90901 solver.cpp:228] Iteration 31890, loss = 0.365127
I0905 07:22:35.271702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365128 (* 1 = 0.365128 loss)
I0905 07:22:35.271716 90901 sgd_solver.cpp:106] Iteration 31890, lr = 0.1
I0905 07:22:41.329900 90901 solver.cpp:228] Iteration 31900, loss = 0.268148
I0905 07:22:41.329946 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268148 (* 1 = 0.268148 loss)
I0905 07:22:41.329957 90901 sgd_solver.cpp:106] Iteration 31900, lr = 0.1
I0905 07:22:47.707412 90901 solver.cpp:228] Iteration 31910, loss = 0.228538
I0905 07:22:47.707465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228538 (* 1 = 0.228538 loss)
I0905 07:22:47.707481 90901 sgd_solver.cpp:106] Iteration 31910, lr = 0.1
I0905 07:22:53.817741 90901 solver.cpp:228] Iteration 31920, loss = 0.716205
I0905 07:22:53.817924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.716205 (* 1 = 0.716205 loss)
I0905 07:22:53.817955 90901 sgd_solver.cpp:106] Iteration 31920, lr = 0.1
I0905 07:22:59.926597 90901 solver.cpp:228] Iteration 31930, loss = 0.503738
I0905 07:22:59.926671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.503738 (* 1 = 0.503738 loss)
I0905 07:22:59.926692 90901 sgd_solver.cpp:106] Iteration 31930, lr = 0.1
I0905 07:23:06.016208 90901 solver.cpp:228] Iteration 31940, loss = 0.724395
I0905 07:23:06.016252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.724396 (* 1 = 0.724396 loss)
I0905 07:23:06.016263 90901 sgd_solver.cpp:106] Iteration 31940, lr = 0.1
I0905 07:23:12.111323 90901 solver.cpp:228] Iteration 31950, loss = 0.246401
I0905 07:23:12.111363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246401 (* 1 = 0.246401 loss)
I0905 07:23:12.111382 90901 sgd_solver.cpp:106] Iteration 31950, lr = 0.1
I0905 07:23:18.205869 90901 solver.cpp:228] Iteration 31960, loss = 0.575311
I0905 07:23:18.205921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.575311 (* 1 = 0.575311 loss)
I0905 07:23:18.205937 90901 sgd_solver.cpp:106] Iteration 31960, lr = 0.1
I0905 07:23:24.274655 90901 solver.cpp:228] Iteration 31970, loss = 0.307737
I0905 07:23:24.274844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307737 (* 1 = 0.307737 loss)
I0905 07:23:24.274871 90901 sgd_solver.cpp:106] Iteration 31970, lr = 0.1
I0905 07:23:30.354813 90901 solver.cpp:228] Iteration 31980, loss = 0.179993
I0905 07:23:30.354863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179994 (* 1 = 0.179994 loss)
I0905 07:23:30.354877 90901 sgd_solver.cpp:106] Iteration 31980, lr = 0.1
I0905 07:23:36.386862 90901 solver.cpp:228] Iteration 31990, loss = 0.394418
I0905 07:23:36.386915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394418 (* 1 = 0.394418 loss)
I0905 07:23:36.386929 90901 sgd_solver.cpp:106] Iteration 31990, lr = 0.1
I0905 07:23:41.442914 90901 solver.cpp:337] Iteration 32000, Testing net (#0)
I0905 07:24:23.131687 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.617813
I0905 07:24:23.131973 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.40476 (* 1 = 1.40476 loss)
I0905 07:24:23.359674 90901 solver.cpp:228] Iteration 32000, loss = 0.323583
I0905 07:24:23.359706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323583 (* 1 = 0.323583 loss)
I0905 07:24:23.359721 90901 sgd_solver.cpp:106] Iteration 32000, lr = 0.1
I0905 07:24:29.782671 90901 solver.cpp:228] Iteration 32010, loss = 0.17737
I0905 07:24:29.782716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17737 (* 1 = 0.17737 loss)
I0905 07:24:29.782734 90901 sgd_solver.cpp:106] Iteration 32010, lr = 0.1
I0905 07:24:35.797386 90901 solver.cpp:228] Iteration 32020, loss = 0.607131
I0905 07:24:35.797435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607132 (* 1 = 0.607132 loss)
I0905 07:24:35.797449 90901 sgd_solver.cpp:106] Iteration 32020, lr = 0.1
I0905 07:24:41.882757 90901 solver.cpp:228] Iteration 32030, loss = 0.258499
I0905 07:24:41.882812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258499 (* 1 = 0.258499 loss)
I0905 07:24:41.882824 90901 sgd_solver.cpp:106] Iteration 32030, lr = 0.1
I0905 07:24:47.898031 90901 solver.cpp:228] Iteration 32040, loss = 0.623486
I0905 07:24:47.898087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.623486 (* 1 = 0.623486 loss)
I0905 07:24:47.898102 90901 sgd_solver.cpp:106] Iteration 32040, lr = 0.1
I0905 07:24:54.309797 90901 solver.cpp:228] Iteration 32050, loss = 0.39182
I0905 07:24:54.309969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39182 (* 1 = 0.39182 loss)
I0905 07:24:54.309991 90901 sgd_solver.cpp:106] Iteration 32050, lr = 0.1
I0905 07:25:00.143990 90901 solver.cpp:228] Iteration 32060, loss = 0.348995
I0905 07:25:00.144035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348995 (* 1 = 0.348995 loss)
I0905 07:25:00.144050 90901 sgd_solver.cpp:106] Iteration 32060, lr = 0.1
I0905 07:25:06.477221 90901 solver.cpp:228] Iteration 32070, loss = 0.373
I0905 07:25:06.477272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373 (* 1 = 0.373 loss)
I0905 07:25:06.477286 90901 sgd_solver.cpp:106] Iteration 32070, lr = 0.1
I0905 07:25:12.522876 90901 solver.cpp:228] Iteration 32080, loss = 0.532894
I0905 07:25:12.522922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.532895 (* 1 = 0.532895 loss)
I0905 07:25:12.522934 90901 sgd_solver.cpp:106] Iteration 32080, lr = 0.1
I0905 07:25:18.580665 90901 solver.cpp:228] Iteration 32090, loss = 0.33887
I0905 07:25:18.580725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33887 (* 1 = 0.33887 loss)
I0905 07:25:18.580740 90901 sgd_solver.cpp:106] Iteration 32090, lr = 0.1
I0905 07:25:24.359366 90901 solver.cpp:228] Iteration 32100, loss = 0.189794
I0905 07:25:24.359478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189794 (* 1 = 0.189794 loss)
I0905 07:25:24.359493 90901 sgd_solver.cpp:106] Iteration 32100, lr = 0.1
I0905 07:25:29.926961 90901 solver.cpp:228] Iteration 32110, loss = 0.28428
I0905 07:25:29.927004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284281 (* 1 = 0.284281 loss)
I0905 07:25:29.927018 90901 sgd_solver.cpp:106] Iteration 32110, lr = 0.1
I0905 07:25:35.458344 90901 solver.cpp:228] Iteration 32120, loss = 0.456008
I0905 07:25:35.458389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456008 (* 1 = 0.456008 loss)
I0905 07:25:35.458403 90901 sgd_solver.cpp:106] Iteration 32120, lr = 0.1
I0905 07:25:41.831410 90901 solver.cpp:228] Iteration 32130, loss = 0.662395
I0905 07:25:41.831454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.662395 (* 1 = 0.662395 loss)
I0905 07:25:41.831467 90901 sgd_solver.cpp:106] Iteration 32130, lr = 0.1
I0905 07:25:47.565522 90901 solver.cpp:228] Iteration 32140, loss = 0.191825
I0905 07:25:47.565577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191825 (* 1 = 0.191825 loss)
I0905 07:25:47.565592 90901 sgd_solver.cpp:106] Iteration 32140, lr = 0.1
I0905 07:25:53.691463 90901 solver.cpp:228] Iteration 32150, loss = 0.288831
I0905 07:25:53.691510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288831 (* 1 = 0.288831 loss)
I0905 07:25:53.691525 90901 sgd_solver.cpp:106] Iteration 32150, lr = 0.1
I0905 07:26:00.130398 90901 solver.cpp:228] Iteration 32160, loss = 0.21635
I0905 07:26:00.130589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216351 (* 1 = 0.216351 loss)
I0905 07:26:00.130605 90901 sgd_solver.cpp:106] Iteration 32160, lr = 0.1
I0905 07:26:06.234118 90901 solver.cpp:228] Iteration 32170, loss = 0.288025
I0905 07:26:06.234164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288026 (* 1 = 0.288026 loss)
I0905 07:26:06.234181 90901 sgd_solver.cpp:106] Iteration 32170, lr = 0.1
I0905 07:26:12.315799 90901 solver.cpp:228] Iteration 32180, loss = 0.410686
I0905 07:26:12.315845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410686 (* 1 = 0.410686 loss)
I0905 07:26:12.315860 90901 sgd_solver.cpp:106] Iteration 32180, lr = 0.1
I0905 07:26:18.720190 90901 solver.cpp:228] Iteration 32190, loss = 0.295573
I0905 07:26:18.720232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295573 (* 1 = 0.295573 loss)
I0905 07:26:18.720253 90901 sgd_solver.cpp:106] Iteration 32190, lr = 0.1
I0905 07:26:24.791862 90901 solver.cpp:228] Iteration 32200, loss = 0.552654
I0905 07:26:24.791911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552654 (* 1 = 0.552654 loss)
I0905 07:26:24.791924 90901 sgd_solver.cpp:106] Iteration 32200, lr = 0.1
I0905 07:26:30.824177 90901 solver.cpp:228] Iteration 32210, loss = 0.352877
I0905 07:26:30.824395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352877 (* 1 = 0.352877 loss)
I0905 07:26:30.824436 90901 sgd_solver.cpp:106] Iteration 32210, lr = 0.1
I0905 07:26:36.886178 90901 solver.cpp:228] Iteration 32220, loss = 0.218968
I0905 07:26:36.886221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218968 (* 1 = 0.218968 loss)
I0905 07:26:36.886236 90901 sgd_solver.cpp:106] Iteration 32220, lr = 0.1
I0905 07:26:42.987637 90901 solver.cpp:228] Iteration 32230, loss = 0.130931
I0905 07:26:42.987680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130931 (* 1 = 0.130931 loss)
I0905 07:26:42.987696 90901 sgd_solver.cpp:106] Iteration 32230, lr = 0.1
I0905 07:26:49.171911 90901 solver.cpp:228] Iteration 32240, loss = 0.339706
I0905 07:26:49.171950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339707 (* 1 = 0.339707 loss)
I0905 07:26:49.171965 90901 sgd_solver.cpp:106] Iteration 32240, lr = 0.1
I0905 07:26:55.456585 90901 solver.cpp:228] Iteration 32250, loss = 0.208194
I0905 07:26:55.456630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208195 (* 1 = 0.208195 loss)
I0905 07:26:55.456643 90901 sgd_solver.cpp:106] Iteration 32250, lr = 0.1
I0905 07:27:01.543087 90901 solver.cpp:228] Iteration 32260, loss = 0.302273
I0905 07:27:01.543239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302274 (* 1 = 0.302274 loss)
I0905 07:27:01.543264 90901 sgd_solver.cpp:106] Iteration 32260, lr = 0.1
I0905 07:27:07.343873 90901 solver.cpp:228] Iteration 32270, loss = 0.185488
I0905 07:27:07.343907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185488 (* 1 = 0.185488 loss)
I0905 07:27:07.343919 90901 sgd_solver.cpp:106] Iteration 32270, lr = 0.1
I0905 07:27:13.294072 90901 solver.cpp:228] Iteration 32280, loss = 0.224374
I0905 07:27:13.294123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224375 (* 1 = 0.224375 loss)
I0905 07:27:13.294137 90901 sgd_solver.cpp:106] Iteration 32280, lr = 0.1
I0905 07:27:18.855738 90901 solver.cpp:228] Iteration 32290, loss = 0.957394
I0905 07:27:18.855794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.957394 (* 1 = 0.957394 loss)
I0905 07:27:18.855808 90901 sgd_solver.cpp:106] Iteration 32290, lr = 0.1
I0905 07:27:24.507800 90901 solver.cpp:228] Iteration 32300, loss = 0.228362
I0905 07:27:24.507841 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228363 (* 1 = 0.228363 loss)
I0905 07:27:24.507855 90901 sgd_solver.cpp:106] Iteration 32300, lr = 0.1
I0905 07:27:30.584780 90901 solver.cpp:228] Iteration 32310, loss = 0.187232
I0905 07:27:30.584828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187233 (* 1 = 0.187233 loss)
I0905 07:27:30.584843 90901 sgd_solver.cpp:106] Iteration 32310, lr = 0.1
I0905 07:27:36.980864 90901 solver.cpp:228] Iteration 32320, loss = 0.31643
I0905 07:27:36.981075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316431 (* 1 = 0.316431 loss)
I0905 07:27:36.981091 90901 sgd_solver.cpp:106] Iteration 32320, lr = 0.1
I0905 07:27:43.047024 90901 solver.cpp:228] Iteration 32330, loss = 0.179467
I0905 07:27:43.047070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179468 (* 1 = 0.179468 loss)
I0905 07:27:43.047082 90901 sgd_solver.cpp:106] Iteration 32330, lr = 0.1
I0905 07:27:49.102444 90901 solver.cpp:228] Iteration 32340, loss = 0.100612
I0905 07:27:49.102499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100612 (* 1 = 0.100612 loss)
I0905 07:27:49.102514 90901 sgd_solver.cpp:106] Iteration 32340, lr = 0.1
I0905 07:27:55.119734 90901 solver.cpp:228] Iteration 32350, loss = 0.301714
I0905 07:27:55.119777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301714 (* 1 = 0.301714 loss)
I0905 07:27:55.119791 90901 sgd_solver.cpp:106] Iteration 32350, lr = 0.1
I0905 07:28:01.242756 90901 solver.cpp:228] Iteration 32360, loss = 0.36541
I0905 07:28:01.242799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36541 (* 1 = 0.36541 loss)
I0905 07:28:01.242815 90901 sgd_solver.cpp:106] Iteration 32360, lr = 0.1
I0905 07:28:07.621000 90901 solver.cpp:228] Iteration 32370, loss = 0.0680967
I0905 07:28:07.621223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0680972 (* 1 = 0.0680972 loss)
I0905 07:28:07.621254 90901 sgd_solver.cpp:106] Iteration 32370, lr = 0.1
I0905 07:28:13.672269 90901 solver.cpp:228] Iteration 32380, loss = 0.11371
I0905 07:28:13.672314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11371 (* 1 = 0.11371 loss)
I0905 07:28:13.672330 90901 sgd_solver.cpp:106] Iteration 32380, lr = 0.1
I0905 07:28:19.752439 90901 solver.cpp:228] Iteration 32390, loss = 0.244337
I0905 07:28:19.752481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244338 (* 1 = 0.244338 loss)
I0905 07:28:19.752496 90901 sgd_solver.cpp:106] Iteration 32390, lr = 0.1
I0905 07:28:25.849020 90901 solver.cpp:228] Iteration 32400, loss = 0.163982
I0905 07:28:25.849092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163982 (* 1 = 0.163982 loss)
I0905 07:28:25.849108 90901 sgd_solver.cpp:106] Iteration 32400, lr = 0.1
I0905 07:28:32.219130 90901 solver.cpp:228] Iteration 32410, loss = 0.144956
I0905 07:28:32.219188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144956 (* 1 = 0.144956 loss)
I0905 07:28:32.219203 90901 sgd_solver.cpp:106] Iteration 32410, lr = 0.1
I0905 07:28:38.303308 90901 solver.cpp:228] Iteration 32420, loss = 0.238544
I0905 07:28:38.303452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238544 (* 1 = 0.238544 loss)
I0905 07:28:38.303503 90901 sgd_solver.cpp:106] Iteration 32420, lr = 0.1
I0905 07:28:44.348201 90901 solver.cpp:228] Iteration 32430, loss = 0.0728394
I0905 07:28:44.348244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0728399 (* 1 = 0.0728399 loss)
I0905 07:28:44.348258 90901 sgd_solver.cpp:106] Iteration 32430, lr = 0.1
I0905 07:28:50.469271 90901 solver.cpp:228] Iteration 32440, loss = 0.677383
I0905 07:28:50.469316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.677383 (* 1 = 0.677383 loss)
I0905 07:28:50.469333 90901 sgd_solver.cpp:106] Iteration 32440, lr = 0.1
I0905 07:28:56.558214 90901 solver.cpp:228] Iteration 32450, loss = 0.434296
I0905 07:28:56.558264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434297 (* 1 = 0.434297 loss)
I0905 07:28:56.558279 90901 sgd_solver.cpp:106] Iteration 32450, lr = 0.1
I0905 07:29:02.205080 90901 solver.cpp:228] Iteration 32460, loss = 0.365523
I0905 07:29:02.205133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365524 (* 1 = 0.365524 loss)
I0905 07:29:02.205148 90901 sgd_solver.cpp:106] Iteration 32460, lr = 0.1
I0905 07:29:07.464712 90901 solver.cpp:228] Iteration 32470, loss = 0.146782
I0905 07:29:07.464762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146782 (* 1 = 0.146782 loss)
I0905 07:29:07.464776 90901 sgd_solver.cpp:106] Iteration 32470, lr = 0.1
I0905 07:29:13.570336 90901 solver.cpp:228] Iteration 32480, loss = 0.228593
I0905 07:29:13.570659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228594 (* 1 = 0.228594 loss)
I0905 07:29:13.570677 90901 sgd_solver.cpp:106] Iteration 32480, lr = 0.1
I0905 07:29:19.567208 90901 solver.cpp:228] Iteration 32490, loss = 0.235731
I0905 07:29:19.567256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235731 (* 1 = 0.235731 loss)
I0905 07:29:19.567270 90901 sgd_solver.cpp:106] Iteration 32490, lr = 0.1
I0905 07:29:25.923413 90901 solver.cpp:228] Iteration 32500, loss = 0.426116
I0905 07:29:25.923460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426116 (* 1 = 0.426116 loss)
I0905 07:29:25.923472 90901 sgd_solver.cpp:106] Iteration 32500, lr = 0.1
I0905 07:29:31.999919 90901 solver.cpp:228] Iteration 32510, loss = 0.145151
I0905 07:29:31.999963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145152 (* 1 = 0.145152 loss)
I0905 07:29:31.999974 90901 sgd_solver.cpp:106] Iteration 32510, lr = 0.1
I0905 07:29:38.077647 90901 solver.cpp:228] Iteration 32520, loss = 0.301185
I0905 07:29:38.077694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301185 (* 1 = 0.301185 loss)
I0905 07:29:38.077708 90901 sgd_solver.cpp:106] Iteration 32520, lr = 0.1
I0905 07:29:44.106580 90901 solver.cpp:228] Iteration 32530, loss = 0.232152
I0905 07:29:44.106763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232153 (* 1 = 0.232153 loss)
I0905 07:29:44.106827 90901 sgd_solver.cpp:106] Iteration 32530, lr = 0.1
I0905 07:29:50.222951 90901 solver.cpp:228] Iteration 32540, loss = 0.197182
I0905 07:29:50.222993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197182 (* 1 = 0.197182 loss)
I0905 07:29:50.223009 90901 sgd_solver.cpp:106] Iteration 32540, lr = 0.1
I0905 07:29:56.603590 90901 solver.cpp:228] Iteration 32550, loss = 0.286265
I0905 07:29:56.603646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286265 (* 1 = 0.286265 loss)
I0905 07:29:56.603662 90901 sgd_solver.cpp:106] Iteration 32550, lr = 0.1
I0905 07:30:02.698988 90901 solver.cpp:228] Iteration 32560, loss = 0.127587
I0905 07:30:02.699043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127588 (* 1 = 0.127588 loss)
I0905 07:30:02.699056 90901 sgd_solver.cpp:106] Iteration 32560, lr = 0.1
I0905 07:30:08.557725 90901 solver.cpp:228] Iteration 32570, loss = 0.465191
I0905 07:30:08.557775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465191 (* 1 = 0.465191 loss)
I0905 07:30:08.557790 90901 sgd_solver.cpp:106] Iteration 32570, lr = 0.1
I0905 07:30:14.836944 90901 solver.cpp:228] Iteration 32580, loss = 0.822185
I0905 07:30:14.837110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.822186 (* 1 = 0.822186 loss)
I0905 07:30:14.837139 90901 sgd_solver.cpp:106] Iteration 32580, lr = 0.1
I0905 07:30:20.893213 90901 solver.cpp:228] Iteration 32590, loss = 0.133546
I0905 07:30:20.893265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133546 (* 1 = 0.133546 loss)
I0905 07:30:20.893280 90901 sgd_solver.cpp:106] Iteration 32590, lr = 0.1
I0905 07:30:26.978216 90901 solver.cpp:228] Iteration 32600, loss = 0.202913
I0905 07:30:26.978262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202914 (* 1 = 0.202914 loss)
I0905 07:30:26.978276 90901 sgd_solver.cpp:106] Iteration 32600, lr = 0.1
I0905 07:30:33.128448 90901 solver.cpp:228] Iteration 32610, loss = 0.341929
I0905 07:30:33.128489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34193 (* 1 = 0.34193 loss)
I0905 07:30:33.128499 90901 sgd_solver.cpp:106] Iteration 32610, lr = 0.1
I0905 07:30:39.123692 90901 solver.cpp:228] Iteration 32620, loss = 0.613617
I0905 07:30:39.123740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.613618 (* 1 = 0.613618 loss)
I0905 07:30:39.123754 90901 sgd_solver.cpp:106] Iteration 32620, lr = 0.1
I0905 07:30:45.196205 90901 solver.cpp:228] Iteration 32630, loss = 0.351166
I0905 07:30:45.196408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351167 (* 1 = 0.351167 loss)
I0905 07:30:45.196460 90901 sgd_solver.cpp:106] Iteration 32630, lr = 0.1
I0905 07:30:50.516121 90901 solver.cpp:228] Iteration 32640, loss = 0.162387
I0905 07:30:50.516170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162387 (* 1 = 0.162387 loss)
I0905 07:30:50.516185 90901 sgd_solver.cpp:106] Iteration 32640, lr = 0.1
I0905 07:30:56.189584 90901 solver.cpp:228] Iteration 32650, loss = 0.224902
I0905 07:30:56.189631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224903 (* 1 = 0.224903 loss)
I0905 07:30:56.189645 90901 sgd_solver.cpp:106] Iteration 32650, lr = 0.1
I0905 07:31:02.291065 90901 solver.cpp:228] Iteration 32660, loss = 0.449425
I0905 07:31:02.291121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449426 (* 1 = 0.449426 loss)
I0905 07:31:02.291136 90901 sgd_solver.cpp:106] Iteration 32660, lr = 0.1
I0905 07:31:08.350502 90901 solver.cpp:228] Iteration 32670, loss = 0.217321
I0905 07:31:08.350533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217322 (* 1 = 0.217322 loss)
I0905 07:31:08.350549 90901 sgd_solver.cpp:106] Iteration 32670, lr = 0.1
I0905 07:31:14.408607 90901 solver.cpp:228] Iteration 32680, loss = 0.40935
I0905 07:31:14.408655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40935 (* 1 = 0.40935 loss)
I0905 07:31:14.408669 90901 sgd_solver.cpp:106] Iteration 32680, lr = 0.1
I0905 07:31:20.491058 90901 solver.cpp:228] Iteration 32690, loss = 0.329629
I0905 07:31:20.491279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32963 (* 1 = 0.32963 loss)
I0905 07:31:20.491295 90901 sgd_solver.cpp:106] Iteration 32690, lr = 0.1
I0905 07:31:26.739006 90901 solver.cpp:228] Iteration 32700, loss = 0.245359
I0905 07:31:26.739064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24536 (* 1 = 0.24536 loss)
I0905 07:31:26.739084 90901 sgd_solver.cpp:106] Iteration 32700, lr = 0.1
I0905 07:31:32.590319 90901 solver.cpp:228] Iteration 32710, loss = 0.546037
I0905 07:31:32.590363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546037 (* 1 = 0.546037 loss)
I0905 07:31:32.590375 90901 sgd_solver.cpp:106] Iteration 32710, lr = 0.1
I0905 07:31:38.937393 90901 solver.cpp:228] Iteration 32720, loss = 0.319279
I0905 07:31:38.937435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319279 (* 1 = 0.319279 loss)
I0905 07:31:38.937449 90901 sgd_solver.cpp:106] Iteration 32720, lr = 0.1
I0905 07:31:45.064748 90901 solver.cpp:228] Iteration 32730, loss = 0.282046
I0905 07:31:45.064786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282047 (* 1 = 0.282047 loss)
I0905 07:31:45.064801 90901 sgd_solver.cpp:106] Iteration 32730, lr = 0.1
I0905 07:31:50.801156 90901 solver.cpp:228] Iteration 32740, loss = 0.360216
I0905 07:31:50.801354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360217 (* 1 = 0.360217 loss)
I0905 07:31:50.801383 90901 sgd_solver.cpp:106] Iteration 32740, lr = 0.1
I0905 07:31:57.213435 90901 solver.cpp:228] Iteration 32750, loss = 0.489086
I0905 07:31:57.213488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489086 (* 1 = 0.489086 loss)
I0905 07:31:57.213502 90901 sgd_solver.cpp:106] Iteration 32750, lr = 0.1
I0905 07:32:03.285737 90901 solver.cpp:228] Iteration 32760, loss = 0.358499
I0905 07:32:03.285780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3585 (* 1 = 0.3585 loss)
I0905 07:32:03.285794 90901 sgd_solver.cpp:106] Iteration 32760, lr = 0.1
I0905 07:32:09.649732 90901 solver.cpp:228] Iteration 32770, loss = 0.548262
I0905 07:32:09.649791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.548262 (* 1 = 0.548262 loss)
I0905 07:32:09.649804 90901 sgd_solver.cpp:106] Iteration 32770, lr = 0.1
I0905 07:32:15.751798 90901 solver.cpp:228] Iteration 32780, loss = 0.455488
I0905 07:32:15.751843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455488 (* 1 = 0.455488 loss)
I0905 07:32:15.751857 90901 sgd_solver.cpp:106] Iteration 32780, lr = 0.1
I0905 07:32:21.786926 90901 solver.cpp:228] Iteration 32790, loss = 0.344362
I0905 07:32:21.787142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344363 (* 1 = 0.344363 loss)
I0905 07:32:21.787158 90901 sgd_solver.cpp:106] Iteration 32790, lr = 0.1
I0905 07:32:27.889737 90901 solver.cpp:337] Iteration 32800, Testing net (#0)
I0905 07:33:09.005614 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.571875
I0905 07:33:09.005753 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.80879 (* 1 = 1.80879 loss)
I0905 07:33:09.383568 90901 solver.cpp:228] Iteration 32800, loss = 0.368246
I0905 07:33:09.383625 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368247 (* 1 = 0.368247 loss)
I0905 07:33:09.383641 90901 sgd_solver.cpp:106] Iteration 32800, lr = 0.1
I0905 07:33:15.284811 90901 solver.cpp:228] Iteration 32810, loss = 0.294022
I0905 07:33:15.284868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294022 (* 1 = 0.294022 loss)
I0905 07:33:15.284880 90901 sgd_solver.cpp:106] Iteration 32810, lr = 0.1
I0905 07:33:21.356971 90901 solver.cpp:228] Iteration 32820, loss = 0.507359
I0905 07:33:21.357038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507359 (* 1 = 0.507359 loss)
I0905 07:33:21.357053 90901 sgd_solver.cpp:106] Iteration 32820, lr = 0.1
I0905 07:33:27.750927 90901 solver.cpp:228] Iteration 32830, loss = 0.229066
I0905 07:33:27.750973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229067 (* 1 = 0.229067 loss)
I0905 07:33:27.750986 90901 sgd_solver.cpp:106] Iteration 32830, lr = 0.1
I0905 07:33:33.184294 90901 solver.cpp:228] Iteration 32840, loss = 0.537194
I0905 07:33:33.184337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.537194 (* 1 = 0.537194 loss)
I0905 07:33:33.184350 90901 sgd_solver.cpp:106] Iteration 32840, lr = 0.1
I0905 07:33:38.226249 90901 solver.cpp:228] Iteration 32850, loss = 0.151485
I0905 07:33:38.226320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151485 (* 1 = 0.151485 loss)
I0905 07:33:38.226335 90901 sgd_solver.cpp:106] Iteration 32850, lr = 0.1
I0905 07:33:43.268476 90901 solver.cpp:228] Iteration 32860, loss = 0.280087
I0905 07:33:43.268656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280088 (* 1 = 0.280088 loss)
I0905 07:33:43.268718 90901 sgd_solver.cpp:106] Iteration 32860, lr = 0.1
I0905 07:33:48.327631 90901 solver.cpp:228] Iteration 32870, loss = 0.253909
I0905 07:33:48.327679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25391 (* 1 = 0.25391 loss)
I0905 07:33:48.327692 90901 sgd_solver.cpp:106] Iteration 32870, lr = 0.1
I0905 07:33:53.382128 90901 solver.cpp:228] Iteration 32880, loss = 0.28042
I0905 07:33:53.382179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28042 (* 1 = 0.28042 loss)
I0905 07:33:53.382194 90901 sgd_solver.cpp:106] Iteration 32880, lr = 0.1
I0905 07:33:58.439414 90901 solver.cpp:228] Iteration 32890, loss = 0.134455
I0905 07:33:58.439457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134455 (* 1 = 0.134455 loss)
I0905 07:33:58.439471 90901 sgd_solver.cpp:106] Iteration 32890, lr = 0.1
I0905 07:34:03.502159 90901 solver.cpp:228] Iteration 32900, loss = 0.12053
I0905 07:34:03.502214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120531 (* 1 = 0.120531 loss)
I0905 07:34:03.502228 90901 sgd_solver.cpp:106] Iteration 32900, lr = 0.1
I0905 07:34:08.583017 90901 solver.cpp:228] Iteration 32910, loss = 0.0747728
I0905 07:34:08.583070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0747734 (* 1 = 0.0747734 loss)
I0905 07:34:08.583082 90901 sgd_solver.cpp:106] Iteration 32910, lr = 0.1
I0905 07:34:13.614529 90901 solver.cpp:228] Iteration 32920, loss = 0.789162
I0905 07:34:13.614749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.789163 (* 1 = 0.789163 loss)
I0905 07:34:13.614784 90901 sgd_solver.cpp:106] Iteration 32920, lr = 0.1
I0905 07:34:18.687979 90901 solver.cpp:228] Iteration 32930, loss = 0.492354
I0905 07:34:18.688027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492354 (* 1 = 0.492354 loss)
I0905 07:34:18.688040 90901 sgd_solver.cpp:106] Iteration 32930, lr = 0.1
I0905 07:34:23.701474 90901 solver.cpp:228] Iteration 32940, loss = 0.448118
I0905 07:34:23.701520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448119 (* 1 = 0.448119 loss)
I0905 07:34:23.701534 90901 sgd_solver.cpp:106] Iteration 32940, lr = 0.1
I0905 07:34:28.350713 90901 solver.cpp:228] Iteration 32950, loss = 0.218254
I0905 07:34:28.350754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218254 (* 1 = 0.218254 loss)
I0905 07:34:28.350765 90901 sgd_solver.cpp:106] Iteration 32950, lr = 0.1
I0905 07:34:32.999727 90901 solver.cpp:228] Iteration 32960, loss = 0.46392
I0905 07:34:32.999770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463921 (* 1 = 0.463921 loss)
I0905 07:34:32.999783 90901 sgd_solver.cpp:106] Iteration 32960, lr = 0.1
I0905 07:34:37.895965 90901 solver.cpp:228] Iteration 32970, loss = 0.167309
I0905 07:34:37.896021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16731 (* 1 = 0.16731 loss)
I0905 07:34:37.896034 90901 sgd_solver.cpp:106] Iteration 32970, lr = 0.1
I0905 07:34:42.948644 90901 solver.cpp:228] Iteration 32980, loss = 0.0827135
I0905 07:34:42.948685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0827142 (* 1 = 0.0827142 loss)
I0905 07:34:42.948699 90901 sgd_solver.cpp:106] Iteration 32980, lr = 0.1
I0905 07:34:48.008131 90901 solver.cpp:228] Iteration 32990, loss = 0.364491
I0905 07:34:48.008286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364491 (* 1 = 0.364491 loss)
I0905 07:34:48.008327 90901 sgd_solver.cpp:106] Iteration 32990, lr = 0.1
I0905 07:34:53.068981 90901 solver.cpp:228] Iteration 33000, loss = 0.105511
I0905 07:34:53.069025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105512 (* 1 = 0.105512 loss)
I0905 07:34:53.069036 90901 sgd_solver.cpp:106] Iteration 33000, lr = 0.1
I0905 07:34:59.111872 90901 solver.cpp:228] Iteration 33010, loss = 0.110369
I0905 07:34:59.111917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11037 (* 1 = 0.11037 loss)
I0905 07:34:59.111932 90901 sgd_solver.cpp:106] Iteration 33010, lr = 0.1
I0905 07:35:05.252692 90901 solver.cpp:228] Iteration 33020, loss = 0.392092
I0905 07:35:05.252737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392093 (* 1 = 0.392093 loss)
I0905 07:35:05.252754 90901 sgd_solver.cpp:106] Iteration 33020, lr = 0.1
I0905 07:35:11.316064 90901 solver.cpp:228] Iteration 33030, loss = 0.652173
I0905 07:35:11.316109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.652174 (* 1 = 0.652174 loss)
I0905 07:35:11.316123 90901 sgd_solver.cpp:106] Iteration 33030, lr = 0.1
I0905 07:35:17.408128 90901 solver.cpp:228] Iteration 33040, loss = 0.0958034
I0905 07:35:17.408179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.095804 (* 1 = 0.095804 loss)
I0905 07:35:17.408193 90901 sgd_solver.cpp:106] Iteration 33040, lr = 0.1
I0905 07:35:23.421159 90901 solver.cpp:228] Iteration 33050, loss = 0.224219
I0905 07:35:23.421414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22422 (* 1 = 0.22422 loss)
I0905 07:35:23.421429 90901 sgd_solver.cpp:106] Iteration 33050, lr = 0.1
I0905 07:35:29.560171 90901 solver.cpp:228] Iteration 33060, loss = 0.196979
I0905 07:35:29.560211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196979 (* 1 = 0.196979 loss)
I0905 07:35:29.560223 90901 sgd_solver.cpp:106] Iteration 33060, lr = 0.1
I0905 07:35:35.877104 90901 solver.cpp:228] Iteration 33070, loss = 0.161132
I0905 07:35:35.877156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161133 (* 1 = 0.161133 loss)
I0905 07:35:35.877169 90901 sgd_solver.cpp:106] Iteration 33070, lr = 0.1
I0905 07:35:41.950562 90901 solver.cpp:228] Iteration 33080, loss = 0.159139
I0905 07:35:41.950626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15914 (* 1 = 0.15914 loss)
I0905 07:35:41.950654 90901 sgd_solver.cpp:106] Iteration 33080, lr = 0.1
I0905 07:35:48.035876 90901 solver.cpp:228] Iteration 33090, loss = 0.540691
I0905 07:35:48.035923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.540692 (* 1 = 0.540692 loss)
I0905 07:35:48.035940 90901 sgd_solver.cpp:106] Iteration 33090, lr = 0.1
I0905 07:35:54.118036 90901 solver.cpp:228] Iteration 33100, loss = 0.359417
I0905 07:35:54.118204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359417 (* 1 = 0.359417 loss)
I0905 07:35:54.118218 90901 sgd_solver.cpp:106] Iteration 33100, lr = 0.1
I0905 07:36:00.177995 90901 solver.cpp:228] Iteration 33110, loss = 0.360177
I0905 07:36:00.178036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360177 (* 1 = 0.360177 loss)
I0905 07:36:00.178048 90901 sgd_solver.cpp:106] Iteration 33110, lr = 0.1
I0905 07:36:05.929718 90901 solver.cpp:228] Iteration 33120, loss = 0.271076
I0905 07:36:05.929777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271077 (* 1 = 0.271077 loss)
I0905 07:36:05.929793 90901 sgd_solver.cpp:106] Iteration 33120, lr = 0.1
I0905 07:36:12.325407 90901 solver.cpp:228] Iteration 33130, loss = 0.15991
I0905 07:36:12.325456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159911 (* 1 = 0.159911 loss)
I0905 07:36:12.325469 90901 sgd_solver.cpp:106] Iteration 33130, lr = 0.1
I0905 07:36:17.896661 90901 solver.cpp:228] Iteration 33140, loss = 0.594439
I0905 07:36:17.896706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59444 (* 1 = 0.59444 loss)
I0905 07:36:17.896720 90901 sgd_solver.cpp:106] Iteration 33140, lr = 0.1
I0905 07:36:23.220309 90901 solver.cpp:228] Iteration 33150, loss = 0.301645
I0905 07:36:23.220358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301645 (* 1 = 0.301645 loss)
I0905 07:36:23.220376 90901 sgd_solver.cpp:106] Iteration 33150, lr = 0.1
I0905 07:36:29.299985 90901 solver.cpp:228] Iteration 33160, loss = 0.287938
I0905 07:36:29.300176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287939 (* 1 = 0.287939 loss)
I0905 07:36:29.300191 90901 sgd_solver.cpp:106] Iteration 33160, lr = 0.1
I0905 07:36:35.688745 90901 solver.cpp:228] Iteration 33170, loss = 0.269753
I0905 07:36:35.688798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269753 (* 1 = 0.269753 loss)
I0905 07:36:35.688810 90901 sgd_solver.cpp:106] Iteration 33170, lr = 0.1
I0905 07:36:41.449744 90901 solver.cpp:228] Iteration 33180, loss = 0.261531
I0905 07:36:41.449790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261531 (* 1 = 0.261531 loss)
I0905 07:36:41.449805 90901 sgd_solver.cpp:106] Iteration 33180, lr = 0.1
I0905 07:36:47.907995 90901 solver.cpp:228] Iteration 33190, loss = 0.244531
I0905 07:36:47.908033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244532 (* 1 = 0.244532 loss)
I0905 07:36:47.908048 90901 sgd_solver.cpp:106] Iteration 33190, lr = 0.1
I0905 07:36:54.000614 90901 solver.cpp:228] Iteration 33200, loss = 0.266915
I0905 07:36:54.000669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266916 (* 1 = 0.266916 loss)
I0905 07:36:54.000684 90901 sgd_solver.cpp:106] Iteration 33200, lr = 0.1
I0905 07:36:59.782946 90901 solver.cpp:228] Iteration 33210, loss = 0.229609
I0905 07:36:59.783164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22961 (* 1 = 0.22961 loss)
I0905 07:36:59.783185 90901 sgd_solver.cpp:106] Iteration 33210, lr = 0.1
I0905 07:37:05.844764 90901 solver.cpp:228] Iteration 33220, loss = 0.146396
I0905 07:37:05.844812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146397 (* 1 = 0.146397 loss)
I0905 07:37:05.844825 90901 sgd_solver.cpp:106] Iteration 33220, lr = 0.1
I0905 07:37:12.254458 90901 solver.cpp:228] Iteration 33230, loss = 0.126195
I0905 07:37:12.254495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126196 (* 1 = 0.126196 loss)
I0905 07:37:12.254508 90901 sgd_solver.cpp:106] Iteration 33230, lr = 0.1
I0905 07:37:18.345574 90901 solver.cpp:228] Iteration 33240, loss = 0.29259
I0905 07:37:18.345623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29259 (* 1 = 0.29259 loss)
I0905 07:37:18.345635 90901 sgd_solver.cpp:106] Iteration 33240, lr = 0.1
I0905 07:37:24.429057 90901 solver.cpp:228] Iteration 33250, loss = 0.428925
I0905 07:37:24.429114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428925 (* 1 = 0.428925 loss)
I0905 07:37:24.429128 90901 sgd_solver.cpp:106] Iteration 33250, lr = 0.1
I0905 07:37:30.586491 90901 solver.cpp:228] Iteration 33260, loss = 0.186846
I0905 07:37:30.586673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186847 (* 1 = 0.186847 loss)
I0905 07:37:30.586700 90901 sgd_solver.cpp:106] Iteration 33260, lr = 0.1
I0905 07:37:36.614384 90901 solver.cpp:228] Iteration 33270, loss = 0.124313
I0905 07:37:36.614433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124313 (* 1 = 0.124313 loss)
I0905 07:37:36.614449 90901 sgd_solver.cpp:106] Iteration 33270, lr = 0.1
I0905 07:37:42.680341 90901 solver.cpp:228] Iteration 33280, loss = 0.519962
I0905 07:37:42.680388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519963 (* 1 = 0.519963 loss)
I0905 07:37:42.680402 90901 sgd_solver.cpp:106] Iteration 33280, lr = 0.1
I0905 07:37:48.757670 90901 solver.cpp:228] Iteration 33290, loss = 0.30966
I0905 07:37:48.757717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309661 (* 1 = 0.309661 loss)
I0905 07:37:48.757731 90901 sgd_solver.cpp:106] Iteration 33290, lr = 0.1
I0905 07:37:55.132994 90901 solver.cpp:228] Iteration 33300, loss = 0.443165
I0905 07:37:55.133043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443166 (* 1 = 0.443166 loss)
I0905 07:37:55.133056 90901 sgd_solver.cpp:106] Iteration 33300, lr = 0.1
I0905 07:38:00.966225 90901 solver.cpp:228] Iteration 33310, loss = 0.367321
I0905 07:38:00.966382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367322 (* 1 = 0.367322 loss)
I0905 07:38:00.966413 90901 sgd_solver.cpp:106] Iteration 33310, lr = 0.1
I0905 07:38:06.224398 90901 solver.cpp:228] Iteration 33320, loss = 0.16867
I0905 07:38:06.224447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168671 (* 1 = 0.168671 loss)
I0905 07:38:06.224460 90901 sgd_solver.cpp:106] Iteration 33320, lr = 0.1
I0905 07:38:12.049877 90901 solver.cpp:228] Iteration 33330, loss = 0.253549
I0905 07:38:12.049923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25355 (* 1 = 0.25355 loss)
I0905 07:38:12.049937 90901 sgd_solver.cpp:106] Iteration 33330, lr = 0.1
I0905 07:38:18.098562 90901 solver.cpp:228] Iteration 33340, loss = 0.198017
I0905 07:38:18.098608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198017 (* 1 = 0.198017 loss)
I0905 07:38:18.098621 90901 sgd_solver.cpp:106] Iteration 33340, lr = 0.1
I0905 07:38:24.458185 90901 solver.cpp:228] Iteration 33350, loss = 0.280709
I0905 07:38:24.458231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28071 (* 1 = 0.28071 loss)
I0905 07:38:24.458243 90901 sgd_solver.cpp:106] Iteration 33350, lr = 0.1
I0905 07:38:30.527189 90901 solver.cpp:228] Iteration 33360, loss = 0.326881
I0905 07:38:30.527233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326881 (* 1 = 0.326881 loss)
I0905 07:38:30.527247 90901 sgd_solver.cpp:106] Iteration 33360, lr = 0.1
I0905 07:38:36.554525 90901 solver.cpp:228] Iteration 33370, loss = 0.0790653
I0905 07:38:36.554821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0790661 (* 1 = 0.0790661 loss)
I0905 07:38:36.554846 90901 sgd_solver.cpp:106] Iteration 33370, lr = 0.1
I0905 07:38:42.947718 90901 solver.cpp:228] Iteration 33380, loss = 0.262544
I0905 07:38:42.947782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262545 (* 1 = 0.262545 loss)
I0905 07:38:42.947798 90901 sgd_solver.cpp:106] Iteration 33380, lr = 0.1
I0905 07:38:49.013105 90901 solver.cpp:228] Iteration 33390, loss = 0.206228
I0905 07:38:49.013166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206229 (* 1 = 0.206229 loss)
I0905 07:38:49.013180 90901 sgd_solver.cpp:106] Iteration 33390, lr = 0.1
I0905 07:38:55.414213 90901 solver.cpp:228] Iteration 33400, loss = 0.156648
I0905 07:38:55.414258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156648 (* 1 = 0.156648 loss)
I0905 07:38:55.414273 90901 sgd_solver.cpp:106] Iteration 33400, lr = 0.1
I0905 07:39:01.452025 90901 solver.cpp:228] Iteration 33410, loss = 0.226178
I0905 07:39:01.452072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226179 (* 1 = 0.226179 loss)
I0905 07:39:01.452086 90901 sgd_solver.cpp:106] Iteration 33410, lr = 0.1
I0905 07:39:07.574470 90901 solver.cpp:228] Iteration 33420, loss = 0.0506752
I0905 07:39:07.574622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0506759 (* 1 = 0.0506759 loss)
I0905 07:39:07.574684 90901 sgd_solver.cpp:106] Iteration 33420, lr = 0.1
I0905 07:39:13.687597 90901 solver.cpp:228] Iteration 33430, loss = 0.29857
I0905 07:39:13.687649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298571 (* 1 = 0.298571 loss)
I0905 07:39:13.687664 90901 sgd_solver.cpp:106] Iteration 33430, lr = 0.1
I0905 07:39:19.781662 90901 solver.cpp:228] Iteration 33440, loss = 0.156593
I0905 07:39:19.781709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156593 (* 1 = 0.156593 loss)
I0905 07:39:19.781723 90901 sgd_solver.cpp:106] Iteration 33440, lr = 0.1
I0905 07:39:26.202725 90901 solver.cpp:228] Iteration 33450, loss = 0.421378
I0905 07:39:26.202776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421379 (* 1 = 0.421379 loss)
I0905 07:39:26.202790 90901 sgd_solver.cpp:106] Iteration 33450, lr = 0.1
I0905 07:39:32.120513 90901 solver.cpp:228] Iteration 33460, loss = 0.26742
I0905 07:39:32.120550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267421 (* 1 = 0.267421 loss)
I0905 07:39:32.120573 90901 sgd_solver.cpp:106] Iteration 33460, lr = 0.1
I0905 07:39:38.014462 90901 solver.cpp:228] Iteration 33470, loss = 0.454512
I0905 07:39:38.014665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454512 (* 1 = 0.454512 loss)
I0905 07:39:38.014695 90901 sgd_solver.cpp:106] Iteration 33470, lr = 0.1
I0905 07:39:44.410010 90901 solver.cpp:228] Iteration 33480, loss = 0.462563
I0905 07:39:44.410053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462563 (* 1 = 0.462563 loss)
I0905 07:39:44.410068 90901 sgd_solver.cpp:106] Iteration 33480, lr = 0.1
I0905 07:39:50.267177 90901 solver.cpp:228] Iteration 33490, loss = 0.369777
I0905 07:39:50.267226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369778 (* 1 = 0.369778 loss)
I0905 07:39:50.267241 90901 sgd_solver.cpp:106] Iteration 33490, lr = 0.1
I0905 07:39:55.532058 90901 solver.cpp:228] Iteration 33500, loss = 0.548834
I0905 07:39:55.532120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.548835 (* 1 = 0.548835 loss)
I0905 07:39:55.532136 90901 sgd_solver.cpp:106] Iteration 33500, lr = 0.1
I0905 07:40:01.454339 90901 solver.cpp:228] Iteration 33510, loss = 0.109702
I0905 07:40:01.454411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109703 (* 1 = 0.109703 loss)
I0905 07:40:01.454427 90901 sgd_solver.cpp:106] Iteration 33510, lr = 0.1
I0905 07:40:07.542567 90901 solver.cpp:228] Iteration 33520, loss = 0.282546
I0905 07:40:07.542609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282546 (* 1 = 0.282546 loss)
I0905 07:40:07.542631 90901 sgd_solver.cpp:106] Iteration 33520, lr = 0.1
I0905 07:40:13.588737 90901 solver.cpp:228] Iteration 33530, loss = 0.138172
I0905 07:40:13.588963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138172 (* 1 = 0.138172 loss)
I0905 07:40:13.588994 90901 sgd_solver.cpp:106] Iteration 33530, lr = 0.1
I0905 07:40:19.665478 90901 solver.cpp:228] Iteration 33540, loss = 0.0875809
I0905 07:40:19.665547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0875815 (* 1 = 0.0875815 loss)
I0905 07:40:19.665563 90901 sgd_solver.cpp:106] Iteration 33540, lr = 0.1
I0905 07:40:25.932564 90901 solver.cpp:228] Iteration 33550, loss = 0.129593
I0905 07:40:25.932617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129593 (* 1 = 0.129593 loss)
I0905 07:40:25.932631 90901 sgd_solver.cpp:106] Iteration 33550, lr = 0.1
I0905 07:40:31.782027 90901 solver.cpp:228] Iteration 33560, loss = 0.185672
I0905 07:40:31.782073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185673 (* 1 = 0.185673 loss)
I0905 07:40:31.782085 90901 sgd_solver.cpp:106] Iteration 33560, lr = 0.1
I0905 07:40:38.081434 90901 solver.cpp:228] Iteration 33570, loss = 0.238624
I0905 07:40:38.081482 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238625 (* 1 = 0.238625 loss)
I0905 07:40:38.081496 90901 sgd_solver.cpp:106] Iteration 33570, lr = 0.1
I0905 07:40:43.941810 90901 solver.cpp:228] Iteration 33580, loss = 0.375713
I0905 07:40:43.941942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375713 (* 1 = 0.375713 loss)
I0905 07:40:43.941968 90901 sgd_solver.cpp:106] Iteration 33580, lr = 0.1
I0905 07:40:50.389664 90901 solver.cpp:228] Iteration 33590, loss = 0.280396
I0905 07:40:50.389729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280397 (* 1 = 0.280397 loss)
I0905 07:40:50.389744 90901 sgd_solver.cpp:106] Iteration 33590, lr = 0.1
I0905 07:40:56.213708 90901 solver.cpp:337] Iteration 33600, Testing net (#0)
I0905 07:41:37.705579 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.814375
I0905 07:41:37.705724 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.464334 (* 1 = 0.464334 loss)
I0905 07:41:37.906164 90901 solver.cpp:228] Iteration 33600, loss = 0.123538
I0905 07:41:37.906194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123538 (* 1 = 0.123538 loss)
I0905 07:41:37.906211 90901 sgd_solver.cpp:106] Iteration 33600, lr = 0.1
I0905 07:41:43.169409 90901 solver.cpp:228] Iteration 33610, loss = 0.159403
I0905 07:41:43.169464 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159404 (* 1 = 0.159404 loss)
I0905 07:41:43.169478 90901 sgd_solver.cpp:106] Iteration 33610, lr = 0.1
I0905 07:41:49.441098 90901 solver.cpp:228] Iteration 33620, loss = 0.289334
I0905 07:41:49.441150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289335 (* 1 = 0.289335 loss)
I0905 07:41:49.441164 90901 sgd_solver.cpp:106] Iteration 33620, lr = 0.1
I0905 07:41:55.495340 90901 solver.cpp:228] Iteration 33630, loss = 0.450616
I0905 07:41:55.495399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450617 (* 1 = 0.450617 loss)
I0905 07:41:55.495414 90901 sgd_solver.cpp:106] Iteration 33630, lr = 0.1
I0905 07:42:01.598723 90901 solver.cpp:228] Iteration 33640, loss = 0.209063
I0905 07:42:01.598783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209064 (* 1 = 0.209064 loss)
I0905 07:42:01.598798 90901 sgd_solver.cpp:106] Iteration 33640, lr = 0.1
I0905 07:42:07.642921 90901 solver.cpp:228] Iteration 33650, loss = 0.065415
I0905 07:42:07.642962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0654155 (* 1 = 0.0654155 loss)
I0905 07:42:07.642976 90901 sgd_solver.cpp:106] Iteration 33650, lr = 0.1
I0905 07:42:14.002990 90901 solver.cpp:228] Iteration 33660, loss = 0.116402
I0905 07:42:14.003190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116403 (* 1 = 0.116403 loss)
I0905 07:42:14.003213 90901 sgd_solver.cpp:106] Iteration 33660, lr = 0.1
I0905 07:42:20.111299 90901 solver.cpp:228] Iteration 33670, loss = 0.362881
I0905 07:42:20.111356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362882 (* 1 = 0.362882 loss)
I0905 07:42:20.111369 90901 sgd_solver.cpp:106] Iteration 33670, lr = 0.1
I0905 07:42:26.444931 90901 solver.cpp:228] Iteration 33680, loss = 0.239611
I0905 07:42:26.444975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239611 (* 1 = 0.239611 loss)
I0905 07:42:26.444989 90901 sgd_solver.cpp:106] Iteration 33680, lr = 0.1
I0905 07:42:32.509697 90901 solver.cpp:228] Iteration 33690, loss = 0.133367
I0905 07:42:32.509757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133367 (* 1 = 0.133367 loss)
I0905 07:42:32.509771 90901 sgd_solver.cpp:106] Iteration 33690, lr = 0.1
I0905 07:42:38.904887 90901 solver.cpp:228] Iteration 33700, loss = 0.151592
I0905 07:42:38.904942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151593 (* 1 = 0.151593 loss)
I0905 07:42:38.904956 90901 sgd_solver.cpp:106] Iteration 33700, lr = 0.1
I0905 07:42:44.971232 90901 solver.cpp:228] Iteration 33710, loss = 0.366873
I0905 07:42:44.971410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366874 (* 1 = 0.366874 loss)
I0905 07:42:44.971438 90901 sgd_solver.cpp:106] Iteration 33710, lr = 0.1
I0905 07:42:51.044894 90901 solver.cpp:228] Iteration 33720, loss = 0.0852159
I0905 07:42:51.044950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0852165 (* 1 = 0.0852165 loss)
I0905 07:42:51.044980 90901 sgd_solver.cpp:106] Iteration 33720, lr = 0.1
I0905 07:42:57.092952 90901 solver.cpp:228] Iteration 33730, loss = 0.210647
I0905 07:42:57.093005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210648 (* 1 = 0.210648 loss)
I0905 07:42:57.093019 90901 sgd_solver.cpp:106] Iteration 33730, lr = 0.1
I0905 07:43:03.156891 90901 solver.cpp:228] Iteration 33740, loss = 0.614425
I0905 07:43:03.156934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.614426 (* 1 = 0.614426 loss)
I0905 07:43:03.156947 90901 sgd_solver.cpp:106] Iteration 33740, lr = 0.1
I0905 07:43:09.574139 90901 solver.cpp:228] Iteration 33750, loss = 0.299005
I0905 07:43:09.574201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299006 (* 1 = 0.299006 loss)
I0905 07:43:09.574218 90901 sgd_solver.cpp:106] Iteration 33750, lr = 0.1
I0905 07:43:15.672168 90901 solver.cpp:228] Iteration 33760, loss = 0.202974
I0905 07:43:15.672305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202974 (* 1 = 0.202974 loss)
I0905 07:43:15.672349 90901 sgd_solver.cpp:106] Iteration 33760, lr = 0.1
I0905 07:43:21.736651 90901 solver.cpp:228] Iteration 33770, loss = 0.256758
I0905 07:43:21.736701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256759 (* 1 = 0.256759 loss)
I0905 07:43:21.736714 90901 sgd_solver.cpp:106] Iteration 33770, lr = 0.1
I0905 07:43:27.430606 90901 solver.cpp:228] Iteration 33780, loss = 0.220947
I0905 07:43:27.430663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220948 (* 1 = 0.220948 loss)
I0905 07:43:27.430677 90901 sgd_solver.cpp:106] Iteration 33780, lr = 0.1
I0905 07:43:32.810051 90901 solver.cpp:228] Iteration 33790, loss = 0.192828
I0905 07:43:32.810099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192829 (* 1 = 0.192829 loss)
I0905 07:43:32.810114 90901 sgd_solver.cpp:106] Iteration 33790, lr = 0.1
I0905 07:43:38.629894 90901 solver.cpp:228] Iteration 33800, loss = 0.277391
I0905 07:43:38.629950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277391 (* 1 = 0.277391 loss)
I0905 07:43:38.629961 90901 sgd_solver.cpp:106] Iteration 33800, lr = 0.1
I0905 07:43:44.726562 90901 solver.cpp:228] Iteration 33810, loss = 0.261904
I0905 07:43:44.726618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261905 (* 1 = 0.261905 loss)
I0905 07:43:44.726640 90901 sgd_solver.cpp:106] Iteration 33810, lr = 0.1
I0905 07:43:51.096420 90901 solver.cpp:228] Iteration 33820, loss = 0.566614
I0905 07:43:51.096658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566615 (* 1 = 0.566615 loss)
I0905 07:43:51.096688 90901 sgd_solver.cpp:106] Iteration 33820, lr = 0.1
I0905 07:43:57.134078 90901 solver.cpp:228] Iteration 33830, loss = 0.338347
I0905 07:43:57.134132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338347 (* 1 = 0.338347 loss)
I0905 07:43:57.134146 90901 sgd_solver.cpp:106] Iteration 33830, lr = 0.1
I0905 07:44:03.448261 90901 solver.cpp:228] Iteration 33840, loss = 0.208646
I0905 07:44:03.448310 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208647 (* 1 = 0.208647 loss)
I0905 07:44:03.448328 90901 sgd_solver.cpp:106] Iteration 33840, lr = 0.1
I0905 07:44:09.304220 90901 solver.cpp:228] Iteration 33850, loss = 0.259378
I0905 07:44:09.304268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259379 (* 1 = 0.259379 loss)
I0905 07:44:09.304280 90901 sgd_solver.cpp:106] Iteration 33850, lr = 0.1
I0905 07:44:15.393585 90901 solver.cpp:228] Iteration 33860, loss = 0.574393
I0905 07:44:15.393638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.574393 (* 1 = 0.574393 loss)
I0905 07:44:15.393651 90901 sgd_solver.cpp:106] Iteration 33860, lr = 0.1
I0905 07:44:21.472493 90901 solver.cpp:228] Iteration 33870, loss = 0.454824
I0905 07:44:21.479480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454825 (* 1 = 0.454825 loss)
I0905 07:44:21.479496 90901 sgd_solver.cpp:106] Iteration 33870, lr = 0.1
I0905 07:44:27.527732 90901 solver.cpp:228] Iteration 33880, loss = 0.186865
I0905 07:44:27.527792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186866 (* 1 = 0.186866 loss)
I0905 07:44:27.527807 90901 sgd_solver.cpp:106] Iteration 33880, lr = 0.1
I0905 07:44:33.411818 90901 solver.cpp:228] Iteration 33890, loss = 0.315894
I0905 07:44:33.411870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315894 (* 1 = 0.315894 loss)
I0905 07:44:33.411882 90901 sgd_solver.cpp:106] Iteration 33890, lr = 0.1
I0905 07:44:39.692319 90901 solver.cpp:228] Iteration 33900, loss = 0.457043
I0905 07:44:39.692375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457043 (* 1 = 0.457043 loss)
I0905 07:44:39.692390 90901 sgd_solver.cpp:106] Iteration 33900, lr = 0.1
I0905 07:44:45.769305 90901 solver.cpp:228] Iteration 33910, loss = 0.292999
I0905 07:44:45.769361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293 (* 1 = 0.293 loss)
I0905 07:44:45.769376 90901 sgd_solver.cpp:106] Iteration 33910, lr = 0.1
I0905 07:44:51.866078 90901 solver.cpp:228] Iteration 33920, loss = 0.261075
I0905 07:44:51.866300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261076 (* 1 = 0.261076 loss)
I0905 07:44:51.866315 90901 sgd_solver.cpp:106] Iteration 33920, lr = 0.1
I0905 07:44:58.235326 90901 solver.cpp:228] Iteration 33930, loss = 0.209062
I0905 07:44:58.235388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209062 (* 1 = 0.209062 loss)
I0905 07:44:58.235404 90901 sgd_solver.cpp:106] Iteration 33930, lr = 0.1
I0905 07:45:04.314568 90901 solver.cpp:228] Iteration 33940, loss = 0.238614
I0905 07:45:04.314615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238615 (* 1 = 0.238615 loss)
I0905 07:45:04.314635 90901 sgd_solver.cpp:106] Iteration 33940, lr = 0.1
I0905 07:45:10.680491 90901 solver.cpp:228] Iteration 33950, loss = 0.239647
I0905 07:45:10.680539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239648 (* 1 = 0.239648 loss)
I0905 07:45:10.680553 90901 sgd_solver.cpp:106] Iteration 33950, lr = 0.1
I0905 07:45:16.344993 90901 solver.cpp:228] Iteration 33960, loss = 0.29349
I0905 07:45:16.345041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293491 (* 1 = 0.293491 loss)
I0905 07:45:16.345057 90901 sgd_solver.cpp:106] Iteration 33960, lr = 0.1
I0905 07:45:21.629108 90901 solver.cpp:228] Iteration 33970, loss = 0.163228
I0905 07:45:21.629148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163229 (* 1 = 0.163229 loss)
I0905 07:45:21.629161 90901 sgd_solver.cpp:106] Iteration 33970, lr = 0.1
I0905 07:45:27.560287 90901 solver.cpp:228] Iteration 33980, loss = 0.194791
I0905 07:45:27.560475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194791 (* 1 = 0.194791 loss)
I0905 07:45:27.560521 90901 sgd_solver.cpp:106] Iteration 33980, lr = 0.1
I0905 07:45:33.877079 90901 solver.cpp:228] Iteration 33990, loss = 0.291821
I0905 07:45:33.877142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291822 (* 1 = 0.291822 loss)
I0905 07:45:33.877157 90901 sgd_solver.cpp:106] Iteration 33990, lr = 0.1
I0905 07:45:40.043458 90901 solver.cpp:228] Iteration 34000, loss = 0.284213
I0905 07:45:40.043500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284213 (* 1 = 0.284213 loss)
I0905 07:45:40.043514 90901 sgd_solver.cpp:106] Iteration 34000, lr = 0.1
I0905 07:45:46.102130 90901 solver.cpp:228] Iteration 34010, loss = 0.268374
I0905 07:45:46.102187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268374 (* 1 = 0.268374 loss)
I0905 07:45:46.102202 90901 sgd_solver.cpp:106] Iteration 34010, lr = 0.1
I0905 07:45:52.178355 90901 solver.cpp:228] Iteration 34020, loss = 0.296573
I0905 07:45:52.178411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296573 (* 1 = 0.296573 loss)
I0905 07:45:52.178426 90901 sgd_solver.cpp:106] Iteration 34020, lr = 0.1
I0905 07:45:58.218453 90901 solver.cpp:228] Iteration 34030, loss = 0.224245
I0905 07:45:58.218614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224245 (* 1 = 0.224245 loss)
I0905 07:45:58.218652 90901 sgd_solver.cpp:106] Iteration 34030, lr = 0.1
I0905 07:46:04.300894 90901 solver.cpp:228] Iteration 34040, loss = 0.0569533
I0905 07:46:04.300953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0569537 (* 1 = 0.0569537 loss)
I0905 07:46:04.300968 90901 sgd_solver.cpp:106] Iteration 34040, lr = 0.1
I0905 07:46:10.468416 90901 solver.cpp:228] Iteration 34050, loss = 0.731268
I0905 07:46:10.468456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.731269 (* 1 = 0.731269 loss)
I0905 07:46:10.468468 90901 sgd_solver.cpp:106] Iteration 34050, lr = 0.1
I0905 07:46:16.437726 90901 solver.cpp:228] Iteration 34060, loss = 0.479478
I0905 07:46:16.437782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.479478 (* 1 = 0.479478 loss)
I0905 07:46:16.437795 90901 sgd_solver.cpp:106] Iteration 34060, lr = 0.1
I0905 07:46:22.519536 90901 solver.cpp:228] Iteration 34070, loss = 0.407141
I0905 07:46:22.519595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407142 (* 1 = 0.407142 loss)
I0905 07:46:22.519610 90901 sgd_solver.cpp:106] Iteration 34070, lr = 0.1
I0905 07:46:28.573369 90901 solver.cpp:228] Iteration 34080, loss = 0.286359
I0905 07:46:28.573568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28636 (* 1 = 0.28636 loss)
I0905 07:46:28.573588 90901 sgd_solver.cpp:106] Iteration 34080, lr = 0.1
I0905 07:46:34.680992 90901 solver.cpp:228] Iteration 34090, loss = 0.565845
I0905 07:46:34.681041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565845 (* 1 = 0.565845 loss)
I0905 07:46:34.681054 90901 sgd_solver.cpp:106] Iteration 34090, lr = 0.1
I0905 07:46:40.781368 90901 solver.cpp:228] Iteration 34100, loss = 0.76209
I0905 07:46:40.781416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.762091 (* 1 = 0.762091 loss)
I0905 07:46:40.781430 90901 sgd_solver.cpp:106] Iteration 34100, lr = 0.1
I0905 07:46:46.880923 90901 solver.cpp:228] Iteration 34110, loss = 0.607868
I0905 07:46:46.880977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607869 (* 1 = 0.607869 loss)
I0905 07:46:46.880992 90901 sgd_solver.cpp:106] Iteration 34110, lr = 0.1
I0905 07:46:53.289595 90901 solver.cpp:228] Iteration 34120, loss = 0.351001
I0905 07:46:53.289664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351001 (* 1 = 0.351001 loss)
I0905 07:46:53.289680 90901 sgd_solver.cpp:106] Iteration 34120, lr = 0.1
I0905 07:46:59.363579 90901 solver.cpp:228] Iteration 34130, loss = 0.165064
I0905 07:46:59.363787 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165064 (* 1 = 0.165064 loss)
I0905 07:46:59.363822 90901 sgd_solver.cpp:106] Iteration 34130, lr = 0.1
I0905 07:47:04.662770 90901 solver.cpp:228] Iteration 34140, loss = 0.172104
I0905 07:47:04.662827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172105 (* 1 = 0.172105 loss)
I0905 07:47:04.662840 90901 sgd_solver.cpp:106] Iteration 34140, lr = 0.1
I0905 07:47:10.064493 90901 solver.cpp:228] Iteration 34150, loss = 0.191796
I0905 07:47:10.064564 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191797 (* 1 = 0.191797 loss)
I0905 07:47:10.064580 90901 sgd_solver.cpp:106] Iteration 34150, lr = 0.1
I0905 07:47:16.427460 90901 solver.cpp:228] Iteration 34160, loss = 0.247634
I0905 07:47:16.427508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247635 (* 1 = 0.247635 loss)
I0905 07:47:16.427521 90901 sgd_solver.cpp:106] Iteration 34160, lr = 0.1
I0905 07:47:22.534104 90901 solver.cpp:228] Iteration 34170, loss = 0.195156
I0905 07:47:22.534162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195156 (* 1 = 0.195156 loss)
I0905 07:47:22.534176 90901 sgd_solver.cpp:106] Iteration 34170, lr = 0.1
I0905 07:47:28.584354 90901 solver.cpp:228] Iteration 34180, loss = 0.0904413
I0905 07:47:28.584390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0904417 (* 1 = 0.0904417 loss)
I0905 07:47:28.584408 90901 sgd_solver.cpp:106] Iteration 34180, lr = 0.1
I0905 07:47:34.976196 90901 solver.cpp:228] Iteration 34190, loss = 0.182313
I0905 07:47:34.976366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182314 (* 1 = 0.182314 loss)
I0905 07:47:34.976415 90901 sgd_solver.cpp:106] Iteration 34190, lr = 0.1
I0905 07:47:40.973086 90901 solver.cpp:228] Iteration 34200, loss = 0.855504
I0905 07:47:40.973126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.855504 (* 1 = 0.855504 loss)
I0905 07:47:40.973140 90901 sgd_solver.cpp:106] Iteration 34200, lr = 0.1
I0905 07:47:47.089748 90901 solver.cpp:228] Iteration 34210, loss = 0.28242
I0905 07:47:47.089802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282421 (* 1 = 0.282421 loss)
I0905 07:47:47.089814 90901 sgd_solver.cpp:106] Iteration 34210, lr = 0.1
I0905 07:47:53.411083 90901 solver.cpp:228] Iteration 34220, loss = 0.17151
I0905 07:47:53.411133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171511 (* 1 = 0.171511 loss)
I0905 07:47:53.411145 90901 sgd_solver.cpp:106] Iteration 34220, lr = 0.1
I0905 07:47:59.243595 90901 solver.cpp:228] Iteration 34230, loss = 0.336684
I0905 07:47:59.243640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336685 (* 1 = 0.336685 loss)
I0905 07:47:59.243654 90901 sgd_solver.cpp:106] Iteration 34230, lr = 0.1
I0905 07:48:05.325538 90901 solver.cpp:228] Iteration 34240, loss = 0.0435707
I0905 07:48:05.325781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0435712 (* 1 = 0.0435712 loss)
I0905 07:48:05.325819 90901 sgd_solver.cpp:106] Iteration 34240, lr = 0.1
I0905 07:48:11.666914 90901 solver.cpp:228] Iteration 34250, loss = 0.282158
I0905 07:48:11.666965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282158 (* 1 = 0.282158 loss)
I0905 07:48:11.666977 90901 sgd_solver.cpp:106] Iteration 34250, lr = 0.1
I0905 07:48:17.744488 90901 solver.cpp:228] Iteration 34260, loss = 0.235204
I0905 07:48:17.744539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235205 (* 1 = 0.235205 loss)
I0905 07:48:17.744554 90901 sgd_solver.cpp:106] Iteration 34260, lr = 0.1
I0905 07:48:23.814780 90901 solver.cpp:228] Iteration 34270, loss = 0.195009
I0905 07:48:23.814831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19501 (* 1 = 0.19501 loss)
I0905 07:48:23.814846 90901 sgd_solver.cpp:106] Iteration 34270, lr = 0.1
I0905 07:48:29.917783 90901 solver.cpp:228] Iteration 34280, loss = 0.253339
I0905 07:48:29.917830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253339 (* 1 = 0.253339 loss)
I0905 07:48:29.917843 90901 sgd_solver.cpp:106] Iteration 34280, lr = 0.1
I0905 07:48:36.321106 90901 solver.cpp:228] Iteration 34290, loss = 0.444429
I0905 07:48:36.321250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444429 (* 1 = 0.444429 loss)
I0905 07:48:36.321305 90901 sgd_solver.cpp:106] Iteration 34290, lr = 0.1
I0905 07:48:42.377583 90901 solver.cpp:228] Iteration 34300, loss = 0.222065
I0905 07:48:42.377646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222066 (* 1 = 0.222066 loss)
I0905 07:48:42.377661 90901 sgd_solver.cpp:106] Iteration 34300, lr = 0.1
I0905 07:48:48.367991 90901 solver.cpp:228] Iteration 34310, loss = 0.23425
I0905 07:48:48.368037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23425 (* 1 = 0.23425 loss)
I0905 07:48:48.368051 90901 sgd_solver.cpp:106] Iteration 34310, lr = 0.1
I0905 07:48:53.831845 90901 solver.cpp:228] Iteration 34320, loss = 0.110659
I0905 07:48:53.831892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110659 (* 1 = 0.110659 loss)
I0905 07:48:53.831905 90901 sgd_solver.cpp:106] Iteration 34320, lr = 0.1
I0905 07:48:59.362799 90901 solver.cpp:228] Iteration 34330, loss = 0.33899
I0905 07:48:59.362859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338991 (* 1 = 0.338991 loss)
I0905 07:48:59.362872 90901 sgd_solver.cpp:106] Iteration 34330, lr = 0.1
I0905 07:49:05.737603 90901 solver.cpp:228] Iteration 34340, loss = 0.349103
I0905 07:49:05.737645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349103 (* 1 = 0.349103 loss)
I0905 07:49:05.737658 90901 sgd_solver.cpp:106] Iteration 34340, lr = 0.1
I0905 07:49:11.853082 90901 solver.cpp:228] Iteration 34350, loss = 0.353157
I0905 07:49:11.853305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353157 (* 1 = 0.353157 loss)
I0905 07:49:11.853334 90901 sgd_solver.cpp:106] Iteration 34350, lr = 0.1
I0905 07:49:17.898936 90901 solver.cpp:228] Iteration 34360, loss = 0.276702
I0905 07:49:17.898993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276702 (* 1 = 0.276702 loss)
I0905 07:49:17.899006 90901 sgd_solver.cpp:106] Iteration 34360, lr = 0.1
I0905 07:49:23.966102 90901 solver.cpp:228] Iteration 34370, loss = 0.190736
I0905 07:49:23.966152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190736 (* 1 = 0.190736 loss)
I0905 07:49:23.966166 90901 sgd_solver.cpp:106] Iteration 34370, lr = 0.1
I0905 07:49:30.064550 90901 solver.cpp:228] Iteration 34380, loss = 0.137704
I0905 07:49:30.064609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137705 (* 1 = 0.137705 loss)
I0905 07:49:30.064623 90901 sgd_solver.cpp:106] Iteration 34380, lr = 0.1
I0905 07:49:36.142854 90901 solver.cpp:228] Iteration 34390, loss = 0.150811
I0905 07:49:36.142918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150811 (* 1 = 0.150811 loss)
I0905 07:49:36.142933 90901 sgd_solver.cpp:106] Iteration 34390, lr = 0.1
I0905 07:49:42.161272 90901 solver.cpp:337] Iteration 34400, Testing net (#0)
I0905 07:50:24.626611 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.868438
I0905 07:50:24.626801 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.324713 (* 1 = 0.324713 loss)
I0905 07:50:24.844359 90901 solver.cpp:228] Iteration 34400, loss = 0.141064
I0905 07:50:24.844391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141065 (* 1 = 0.141065 loss)
I0905 07:50:24.844410 90901 sgd_solver.cpp:106] Iteration 34400, lr = 0.1
I0905 07:50:30.973647 90901 solver.cpp:228] Iteration 34410, loss = 0.290634
I0905 07:50:30.973695 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290634 (* 1 = 0.290634 loss)
I0905 07:50:30.973707 90901 sgd_solver.cpp:106] Iteration 34410, lr = 0.1
I0905 07:50:36.364405 90901 solver.cpp:228] Iteration 34420, loss = 0.308293
I0905 07:50:36.364456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308293 (* 1 = 0.308293 loss)
I0905 07:50:36.364470 90901 sgd_solver.cpp:106] Iteration 34420, lr = 0.1
I0905 07:50:42.233005 90901 solver.cpp:228] Iteration 34430, loss = 0.309367
I0905 07:50:42.233043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309367 (* 1 = 0.309367 loss)
I0905 07:50:42.233053 90901 sgd_solver.cpp:106] Iteration 34430, lr = 0.1
I0905 07:50:47.978900 90901 solver.cpp:228] Iteration 34440, loss = 0.406612
I0905 07:50:47.978942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406613 (* 1 = 0.406613 loss)
I0905 07:50:47.978957 90901 sgd_solver.cpp:106] Iteration 34440, lr = 0.1
I0905 07:50:54.080840 90901 solver.cpp:228] Iteration 34450, loss = 0.153222
I0905 07:50:54.080881 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153223 (* 1 = 0.153223 loss)
I0905 07:50:54.080893 90901 sgd_solver.cpp:106] Iteration 34450, lr = 0.1
I0905 07:51:00.115646 90901 solver.cpp:228] Iteration 34460, loss = 0.324251
I0905 07:51:00.115885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324252 (* 1 = 0.324252 loss)
I0905 07:51:00.115916 90901 sgd_solver.cpp:106] Iteration 34460, lr = 0.1
I0905 07:51:06.225942 90901 solver.cpp:228] Iteration 34470, loss = 0.377045
I0905 07:51:06.226003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377045 (* 1 = 0.377045 loss)
I0905 07:51:06.226021 90901 sgd_solver.cpp:106] Iteration 34470, lr = 0.1
I0905 07:51:12.638840 90901 solver.cpp:228] Iteration 34480, loss = 0.387488
I0905 07:51:12.638901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387489 (* 1 = 0.387489 loss)
I0905 07:51:12.638916 90901 sgd_solver.cpp:106] Iteration 34480, lr = 0.1
I0905 07:51:17.669814 90901 solver.cpp:228] Iteration 34490, loss = 0.373969
I0905 07:51:17.669865 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37397 (* 1 = 0.37397 loss)
I0905 07:51:17.669878 90901 sgd_solver.cpp:106] Iteration 34490, lr = 0.1
I0905 07:51:22.748126 90901 solver.cpp:228] Iteration 34500, loss = 0.174357
I0905 07:51:22.748178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174358 (* 1 = 0.174358 loss)
I0905 07:51:22.748193 90901 sgd_solver.cpp:106] Iteration 34500, lr = 0.1
I0905 07:51:27.785951 90901 solver.cpp:228] Iteration 34510, loss = 0.389311
I0905 07:51:27.785995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389311 (* 1 = 0.389311 loss)
I0905 07:51:27.786007 90901 sgd_solver.cpp:106] Iteration 34510, lr = 0.1
I0905 07:51:32.832319 90901 solver.cpp:228] Iteration 34520, loss = 0.374084
I0905 07:51:32.832525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374084 (* 1 = 0.374084 loss)
I0905 07:51:32.832545 90901 sgd_solver.cpp:106] Iteration 34520, lr = 0.1
I0905 07:51:37.846801 90901 solver.cpp:228] Iteration 34530, loss = 0.320515
I0905 07:51:37.846873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320515 (* 1 = 0.320515 loss)
I0905 07:51:37.846887 90901 sgd_solver.cpp:106] Iteration 34530, lr = 0.1
I0905 07:51:42.901160 90901 solver.cpp:228] Iteration 34540, loss = 0.190949
I0905 07:51:42.901209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19095 (* 1 = 0.19095 loss)
I0905 07:51:42.901228 90901 sgd_solver.cpp:106] Iteration 34540, lr = 0.1
I0905 07:51:47.891592 90901 solver.cpp:228] Iteration 34550, loss = 0.0968565
I0905 07:51:47.891659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0968569 (* 1 = 0.0968569 loss)
I0905 07:51:47.891674 90901 sgd_solver.cpp:106] Iteration 34550, lr = 0.1
I0905 07:51:52.913301 90901 solver.cpp:228] Iteration 34560, loss = 0.273719
I0905 07:51:52.913357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273719 (* 1 = 0.273719 loss)
I0905 07:51:52.913373 90901 sgd_solver.cpp:106] Iteration 34560, lr = 0.1
I0905 07:51:57.937569 90901 solver.cpp:228] Iteration 34570, loss = 0.699463
I0905 07:51:57.937618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.699464 (* 1 = 0.699464 loss)
I0905 07:51:57.937633 90901 sgd_solver.cpp:106] Iteration 34570, lr = 0.1
I0905 07:52:03.014956 90901 solver.cpp:228] Iteration 34580, loss = 0.436054
I0905 07:52:03.015146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436054 (* 1 = 0.436054 loss)
I0905 07:52:03.015187 90901 sgd_solver.cpp:106] Iteration 34580, lr = 0.1
I0905 07:52:08.042001 90901 solver.cpp:228] Iteration 34590, loss = 0.244857
I0905 07:52:08.042055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244857 (* 1 = 0.244857 loss)
I0905 07:52:08.042068 90901 sgd_solver.cpp:106] Iteration 34590, lr = 0.1
I0905 07:52:13.110296 90901 solver.cpp:228] Iteration 34600, loss = 0.176923
I0905 07:52:13.110342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176923 (* 1 = 0.176923 loss)
I0905 07:52:13.110354 90901 sgd_solver.cpp:106] Iteration 34600, lr = 0.1
I0905 07:52:18.161547 90901 solver.cpp:228] Iteration 34610, loss = 0.140232
I0905 07:52:18.161605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140233 (* 1 = 0.140233 loss)
I0905 07:52:18.161620 90901 sgd_solver.cpp:106] Iteration 34610, lr = 0.1
I0905 07:52:23.209599 90901 solver.cpp:228] Iteration 34620, loss = 0.280929
I0905 07:52:23.209661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280929 (* 1 = 0.280929 loss)
I0905 07:52:23.209677 90901 sgd_solver.cpp:106] Iteration 34620, lr = 0.1
I0905 07:52:28.025570 90901 solver.cpp:228] Iteration 34630, loss = 0.181252
I0905 07:52:28.025612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181252 (* 1 = 0.181252 loss)
I0905 07:52:28.025625 90901 sgd_solver.cpp:106] Iteration 34630, lr = 0.1
I0905 07:52:32.685798 90901 solver.cpp:228] Iteration 34640, loss = 0.683405
I0905 07:52:32.685847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.683405 (* 1 = 0.683405 loss)
I0905 07:52:32.685859 90901 sgd_solver.cpp:106] Iteration 34640, lr = 0.1
I0905 07:52:38.081076 90901 solver.cpp:228] Iteration 34650, loss = 0.125838
I0905 07:52:38.081226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125839 (* 1 = 0.125839 loss)
I0905 07:52:38.081269 90901 sgd_solver.cpp:106] Iteration 34650, lr = 0.1
I0905 07:52:44.174284 90901 solver.cpp:228] Iteration 34660, loss = 0.291095
I0905 07:52:44.174320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291095 (* 1 = 0.291095 loss)
I0905 07:52:44.174334 90901 sgd_solver.cpp:106] Iteration 34660, lr = 0.1
I0905 07:52:50.559994 90901 solver.cpp:228] Iteration 34670, loss = 0.377613
I0905 07:52:50.560034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377614 (* 1 = 0.377614 loss)
I0905 07:52:50.560047 90901 sgd_solver.cpp:106] Iteration 34670, lr = 0.1
I0905 07:52:56.618682 90901 solver.cpp:228] Iteration 34680, loss = 0.645004
I0905 07:52:56.618727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.645004 (* 1 = 0.645004 loss)
I0905 07:52:56.618749 90901 sgd_solver.cpp:106] Iteration 34680, lr = 0.1
I0905 07:53:02.683825 90901 solver.cpp:228] Iteration 34690, loss = 0.296221
I0905 07:53:02.683877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296222 (* 1 = 0.296222 loss)
I0905 07:53:02.683890 90901 sgd_solver.cpp:106] Iteration 34690, lr = 0.1
I0905 07:53:09.050302 90901 solver.cpp:228] Iteration 34700, loss = 0.150129
I0905 07:53:09.050591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15013 (* 1 = 0.15013 loss)
I0905 07:53:09.050612 90901 sgd_solver.cpp:106] Iteration 34700, lr = 0.1
I0905 07:53:15.174593 90901 solver.cpp:228] Iteration 34710, loss = 0.0997907
I0905 07:53:15.174657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0997913 (* 1 = 0.0997913 loss)
I0905 07:53:15.174671 90901 sgd_solver.cpp:106] Iteration 34710, lr = 0.1
I0905 07:53:21.348350 90901 solver.cpp:228] Iteration 34720, loss = 0.301751
I0905 07:53:21.348394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301751 (* 1 = 0.301751 loss)
I0905 07:53:21.348408 90901 sgd_solver.cpp:106] Iteration 34720, lr = 0.1
I0905 07:53:27.661938 90901 solver.cpp:228] Iteration 34730, loss = 0.279952
I0905 07:53:27.661998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279953 (* 1 = 0.279953 loss)
I0905 07:53:27.662014 90901 sgd_solver.cpp:106] Iteration 34730, lr = 0.1
I0905 07:53:33.747771 90901 solver.cpp:228] Iteration 34740, loss = 0.100453
I0905 07:53:33.747822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100454 (* 1 = 0.100454 loss)
I0905 07:53:33.747838 90901 sgd_solver.cpp:106] Iteration 34740, lr = 0.1
I0905 07:53:39.830734 90901 solver.cpp:228] Iteration 34750, loss = 0.587826
I0905 07:53:39.830945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.587827 (* 1 = 0.587827 loss)
I0905 07:53:39.830960 90901 sgd_solver.cpp:106] Iteration 34750, lr = 0.1
I0905 07:53:45.930780 90901 solver.cpp:228] Iteration 34760, loss = 0.276965
I0905 07:53:45.930819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276966 (* 1 = 0.276966 loss)
I0905 07:53:45.930831 90901 sgd_solver.cpp:106] Iteration 34760, lr = 0.1
I0905 07:53:52.013525 90901 solver.cpp:228] Iteration 34770, loss = 0.34888
I0905 07:53:52.013578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348881 (* 1 = 0.348881 loss)
I0905 07:53:52.013593 90901 sgd_solver.cpp:106] Iteration 34770, lr = 0.1
I0905 07:53:58.060292 90901 solver.cpp:228] Iteration 34780, loss = 0.216285
I0905 07:53:58.060356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216286 (* 1 = 0.216286 loss)
I0905 07:53:58.060370 90901 sgd_solver.cpp:106] Iteration 34780, lr = 0.1
I0905 07:54:04.157826 90901 solver.cpp:228] Iteration 34790, loss = 0.164599
I0905 07:54:04.157877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1646 (* 1 = 0.1646 loss)
I0905 07:54:04.157889 90901 sgd_solver.cpp:106] Iteration 34790, lr = 0.1
I0905 07:54:10.224954 90901 solver.cpp:228] Iteration 34800, loss = 0.349611
I0905 07:54:10.225087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349612 (* 1 = 0.349612 loss)
I0905 07:54:10.225121 90901 sgd_solver.cpp:106] Iteration 34800, lr = 0.1
I0905 07:54:16.062858 90901 solver.cpp:228] Iteration 34810, loss = 0.412458
I0905 07:54:16.062906 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412459 (* 1 = 0.412459 loss)
I0905 07:54:16.062918 90901 sgd_solver.cpp:106] Iteration 34810, lr = 0.1
I0905 07:54:21.449270 90901 solver.cpp:228] Iteration 34820, loss = 0.245857
I0905 07:54:21.449316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245858 (* 1 = 0.245858 loss)
I0905 07:54:21.449328 90901 sgd_solver.cpp:106] Iteration 34820, lr = 0.1
I0905 07:54:27.212821 90901 solver.cpp:228] Iteration 34830, loss = 0.388133
I0905 07:54:27.212880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388134 (* 1 = 0.388134 loss)
I0905 07:54:27.212901 90901 sgd_solver.cpp:106] Iteration 34830, lr = 0.1
I0905 07:54:33.291720 90901 solver.cpp:228] Iteration 34840, loss = 0.571161
I0905 07:54:33.291769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.571162 (* 1 = 0.571162 loss)
I0905 07:54:33.291782 90901 sgd_solver.cpp:106] Iteration 34840, lr = 0.1
I0905 07:54:39.003468 90901 solver.cpp:228] Iteration 34850, loss = 0.640256
I0905 07:54:39.003510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.640256 (* 1 = 0.640256 loss)
I0905 07:54:39.003523 90901 sgd_solver.cpp:106] Iteration 34850, lr = 0.1
I0905 07:54:45.392377 90901 solver.cpp:228] Iteration 34860, loss = 0.190444
I0905 07:54:45.392585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190445 (* 1 = 0.190445 loss)
I0905 07:54:45.392604 90901 sgd_solver.cpp:106] Iteration 34860, lr = 0.1
I0905 07:54:51.459475 90901 solver.cpp:228] Iteration 34870, loss = 0.121995
I0905 07:54:51.459527 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121996 (* 1 = 0.121996 loss)
I0905 07:54:51.459542 90901 sgd_solver.cpp:106] Iteration 34870, lr = 0.1
I0905 07:54:57.655637 90901 solver.cpp:228] Iteration 34880, loss = 0.178218
I0905 07:54:57.655681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178219 (* 1 = 0.178219 loss)
I0905 07:54:57.655694 90901 sgd_solver.cpp:106] Iteration 34880, lr = 0.1
I0905 07:55:03.700440 90901 solver.cpp:228] Iteration 34890, loss = 0.205272
I0905 07:55:03.700497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205273 (* 1 = 0.205273 loss)
I0905 07:55:03.700511 90901 sgd_solver.cpp:106] Iteration 34890, lr = 0.1
I0905 07:55:09.799051 90901 solver.cpp:228] Iteration 34900, loss = 0.382288
I0905 07:55:09.799091 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382289 (* 1 = 0.382289 loss)
I0905 07:55:09.799104 90901 sgd_solver.cpp:106] Iteration 34900, lr = 0.1
I0905 07:55:15.883257 90901 solver.cpp:228] Iteration 34910, loss = 0.403421
I0905 07:55:15.883406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403422 (* 1 = 0.403422 loss)
I0905 07:55:15.883432 90901 sgd_solver.cpp:106] Iteration 34910, lr = 0.1
I0905 07:55:21.951757 90901 solver.cpp:228] Iteration 34920, loss = 0.297131
I0905 07:55:21.951822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297131 (* 1 = 0.297131 loss)
I0905 07:55:21.951838 90901 sgd_solver.cpp:106] Iteration 34920, lr = 0.1
I0905 07:55:28.033584 90901 solver.cpp:228] Iteration 34930, loss = 0.289802
I0905 07:55:28.033632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289803 (* 1 = 0.289803 loss)
I0905 07:55:28.033645 90901 sgd_solver.cpp:106] Iteration 34930, lr = 0.1
I0905 07:55:34.447309 90901 solver.cpp:228] Iteration 34940, loss = 0.521344
I0905 07:55:34.447376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.521345 (* 1 = 0.521345 loss)
I0905 07:55:34.447392 90901 sgd_solver.cpp:106] Iteration 34940, lr = 0.1
I0905 07:55:40.455059 90901 solver.cpp:228] Iteration 34950, loss = 0.186523
I0905 07:55:40.455106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186524 (* 1 = 0.186524 loss)
I0905 07:55:40.455118 90901 sgd_solver.cpp:106] Iteration 34950, lr = 0.1
I0905 07:55:46.606225 90901 solver.cpp:228] Iteration 34960, loss = 0.183763
I0905 07:55:46.606350 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183764 (* 1 = 0.183764 loss)
I0905 07:55:46.606382 90901 sgd_solver.cpp:106] Iteration 34960, lr = 0.1
I0905 07:55:52.710520 90901 solver.cpp:228] Iteration 34970, loss = 0.243388
I0905 07:55:52.710573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243389 (* 1 = 0.243389 loss)
I0905 07:55:52.710588 90901 sgd_solver.cpp:106] Iteration 34970, lr = 0.1
I0905 07:55:58.793314 90901 solver.cpp:228] Iteration 34980, loss = 0.601805
I0905 07:55:58.793354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.601806 (* 1 = 0.601806 loss)
I0905 07:55:58.793367 90901 sgd_solver.cpp:106] Iteration 34980, lr = 0.1
I0905 07:56:04.628609 90901 solver.cpp:228] Iteration 34990, loss = 0.279332
I0905 07:56:04.628657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279333 (* 1 = 0.279333 loss)
I0905 07:56:04.628670 90901 sgd_solver.cpp:106] Iteration 34990, lr = 0.1
I0905 07:56:09.885563 90901 solver.cpp:228] Iteration 35000, loss = 0.187773
I0905 07:56:09.885610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187774 (* 1 = 0.187774 loss)
I0905 07:56:09.885624 90901 sgd_solver.cpp:106] Iteration 35000, lr = 0.1
I0905 07:56:15.408308 90901 solver.cpp:228] Iteration 35010, loss = 0.0961224
I0905 07:56:15.408356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0961231 (* 1 = 0.0961231 loss)
I0905 07:56:15.408368 90901 sgd_solver.cpp:106] Iteration 35010, lr = 0.1
I0905 07:56:21.492709 90901 solver.cpp:228] Iteration 35020, loss = 0.25953
I0905 07:56:21.492914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25953 (* 1 = 0.25953 loss)
I0905 07:56:21.492952 90901 sgd_solver.cpp:106] Iteration 35020, lr = 0.1
I0905 07:56:27.907346 90901 solver.cpp:228] Iteration 35030, loss = 0.388395
I0905 07:56:27.907392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388396 (* 1 = 0.388396 loss)
I0905 07:56:27.907405 90901 sgd_solver.cpp:106] Iteration 35030, lr = 0.1
I0905 07:56:33.995975 90901 solver.cpp:228] Iteration 35040, loss = 0.227213
I0905 07:56:33.996019 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227214 (* 1 = 0.227214 loss)
I0905 07:56:33.996033 90901 sgd_solver.cpp:106] Iteration 35040, lr = 0.1
I0905 07:56:40.237031 90901 solver.cpp:228] Iteration 35050, loss = 0.165956
I0905 07:56:40.237088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165957 (* 1 = 0.165957 loss)
I0905 07:56:40.237103 90901 sgd_solver.cpp:106] Iteration 35050, lr = 0.1
I0905 07:56:46.463271 90901 solver.cpp:228] Iteration 35060, loss = 0.386018
I0905 07:56:46.463315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386019 (* 1 = 0.386019 loss)
I0905 07:56:46.463328 90901 sgd_solver.cpp:106] Iteration 35060, lr = 0.1
I0905 07:56:52.539616 90901 solver.cpp:228] Iteration 35070, loss = 0.278974
I0905 07:56:52.539762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278974 (* 1 = 0.278974 loss)
I0905 07:56:52.539789 90901 sgd_solver.cpp:106] Iteration 35070, lr = 0.1
I0905 07:56:58.676625 90901 solver.cpp:228] Iteration 35080, loss = 0.135835
I0905 07:56:58.676682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135836 (* 1 = 0.135836 loss)
I0905 07:56:58.676700 90901 sgd_solver.cpp:106] Iteration 35080, lr = 0.1
I0905 07:57:04.758673 90901 solver.cpp:228] Iteration 35090, loss = 0.0930799
I0905 07:57:04.758733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0930806 (* 1 = 0.0930806 loss)
I0905 07:57:04.758747 90901 sgd_solver.cpp:106] Iteration 35090, lr = 0.1
I0905 07:57:10.885874 90901 solver.cpp:228] Iteration 35100, loss = 0.086314
I0905 07:57:10.885912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0863147 (* 1 = 0.0863147 loss)
I0905 07:57:10.885926 90901 sgd_solver.cpp:106] Iteration 35100, lr = 0.1
I0905 07:57:17.256083 90901 solver.cpp:228] Iteration 35110, loss = 0.254143
I0905 07:57:17.256141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254144 (* 1 = 0.254144 loss)
I0905 07:57:17.256155 90901 sgd_solver.cpp:106] Iteration 35110, lr = 0.1
I0905 07:57:23.327154 90901 solver.cpp:228] Iteration 35120, loss = 0.836166
I0905 07:57:23.327301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.836167 (* 1 = 0.836167 loss)
I0905 07:57:23.327344 90901 sgd_solver.cpp:106] Iteration 35120, lr = 0.1
I0905 07:57:29.425966 90901 solver.cpp:228] Iteration 35130, loss = 0.453675
I0905 07:57:29.426013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453676 (* 1 = 0.453676 loss)
I0905 07:57:29.426026 90901 sgd_solver.cpp:106] Iteration 35130, lr = 0.1
I0905 07:57:35.856591 90901 solver.cpp:228] Iteration 35140, loss = 0.425486
I0905 07:57:35.856643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425486 (* 1 = 0.425486 loss)
I0905 07:57:35.856657 90901 sgd_solver.cpp:106] Iteration 35140, lr = 0.1
I0905 07:57:41.961861 90901 solver.cpp:228] Iteration 35150, loss = 0.260012
I0905 07:57:41.961923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260013 (* 1 = 0.260013 loss)
I0905 07:57:41.961940 90901 sgd_solver.cpp:106] Iteration 35150, lr = 0.1
I0905 07:57:47.751485 90901 solver.cpp:228] Iteration 35160, loss = 0.219267
I0905 07:57:47.751528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219268 (* 1 = 0.219268 loss)
I0905 07:57:47.751541 90901 sgd_solver.cpp:106] Iteration 35160, lr = 0.1
I0905 07:57:53.397544 90901 solver.cpp:228] Iteration 35170, loss = 0.529166
I0905 07:57:53.397716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529166 (* 1 = 0.529166 loss)
I0905 07:57:53.397754 90901 sgd_solver.cpp:106] Iteration 35170, lr = 0.1
I0905 07:57:58.985323 90901 solver.cpp:228] Iteration 35180, loss = 0.108284
I0905 07:57:58.985355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108285 (* 1 = 0.108285 loss)
I0905 07:57:58.985369 90901 sgd_solver.cpp:106] Iteration 35180, lr = 0.1
I0905 07:58:04.712863 90901 solver.cpp:228] Iteration 35190, loss = 0.678746
I0905 07:58:04.712925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.678747 (* 1 = 0.678747 loss)
I0905 07:58:04.712940 90901 sgd_solver.cpp:106] Iteration 35190, lr = 0.1
I0905 07:58:10.577741 90901 solver.cpp:337] Iteration 35200, Testing net (#0)
I0905 07:58:52.895964 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.737188
I0905 07:58:52.896116 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.666303 (* 1 = 0.666303 loss)
I0905 07:58:53.122938 90901 solver.cpp:228] Iteration 35200, loss = 0.375511
I0905 07:58:53.122975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375512 (* 1 = 0.375512 loss)
I0905 07:58:53.122992 90901 sgd_solver.cpp:106] Iteration 35200, lr = 0.1
I0905 07:58:59.211935 90901 solver.cpp:228] Iteration 35210, loss = 0.367091
I0905 07:58:59.211995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367092 (* 1 = 0.367092 loss)
I0905 07:58:59.212010 90901 sgd_solver.cpp:106] Iteration 35210, lr = 0.1
I0905 07:59:05.572859 90901 solver.cpp:228] Iteration 35220, loss = 0.225314
I0905 07:59:05.572914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225315 (* 1 = 0.225315 loss)
I0905 07:59:05.572928 90901 sgd_solver.cpp:106] Iteration 35220, lr = 0.1
I0905 07:59:11.664523 90901 solver.cpp:228] Iteration 35230, loss = 0.110194
I0905 07:59:11.664566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110195 (* 1 = 0.110195 loss)
I0905 07:59:11.664579 90901 sgd_solver.cpp:106] Iteration 35230, lr = 0.1
I0905 07:59:17.729203 90901 solver.cpp:228] Iteration 35240, loss = 0.299267
I0905 07:59:17.729256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299268 (* 1 = 0.299268 loss)
I0905 07:59:17.729270 90901 sgd_solver.cpp:106] Iteration 35240, lr = 0.1
I0905 07:59:23.797057 90901 solver.cpp:228] Iteration 35250, loss = 0.245106
I0905 07:59:23.799252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245107 (* 1 = 0.245107 loss)
I0905 07:59:23.799268 90901 sgd_solver.cpp:106] Iteration 35250, lr = 0.1
I0905 07:59:29.857156 90901 solver.cpp:228] Iteration 35260, loss = 0.339476
I0905 07:59:29.857201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339477 (* 1 = 0.339477 loss)
I0905 07:59:29.857214 90901 sgd_solver.cpp:106] Iteration 35260, lr = 0.1
I0905 07:59:36.220280 90901 solver.cpp:228] Iteration 35270, loss = 0.420375
I0905 07:59:36.220338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.420376 (* 1 = 0.420376 loss)
I0905 07:59:36.220352 90901 sgd_solver.cpp:106] Iteration 35270, lr = 0.1
I0905 07:59:41.176038 90901 solver.cpp:228] Iteration 35280, loss = 0.299187
I0905 07:59:41.176081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299188 (* 1 = 0.299188 loss)
I0905 07:59:41.176093 90901 sgd_solver.cpp:106] Iteration 35280, lr = 0.1
I0905 07:59:46.683936 90901 solver.cpp:228] Iteration 35290, loss = 0.865908
I0905 07:59:46.684013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.865909 (* 1 = 0.865909 loss)
I0905 07:59:46.684036 90901 sgd_solver.cpp:106] Iteration 35290, lr = 0.1
I0905 07:59:53.033282 90901 solver.cpp:228] Iteration 35300, loss = 0.293201
I0905 07:59:53.033325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293202 (* 1 = 0.293202 loss)
I0905 07:59:53.033340 90901 sgd_solver.cpp:106] Iteration 35300, lr = 0.1
I0905 07:59:59.118332 90901 solver.cpp:228] Iteration 35310, loss = 0.50529
I0905 07:59:59.118568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505291 (* 1 = 0.505291 loss)
I0905 07:59:59.118590 90901 sgd_solver.cpp:106] Iteration 35310, lr = 0.1
I0905 08:00:05.203878 90901 solver.cpp:228] Iteration 35320, loss = 0.374006
I0905 08:00:05.203924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374007 (* 1 = 0.374007 loss)
I0905 08:00:05.203940 90901 sgd_solver.cpp:106] Iteration 35320, lr = 0.1
I0905 08:00:11.597276 90901 solver.cpp:228] Iteration 35330, loss = 0.193295
I0905 08:00:11.597326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193296 (* 1 = 0.193296 loss)
I0905 08:00:11.597339 90901 sgd_solver.cpp:106] Iteration 35330, lr = 0.1
I0905 08:00:17.691503 90901 solver.cpp:228] Iteration 35340, loss = 0.46204
I0905 08:00:17.691540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462041 (* 1 = 0.462041 loss)
I0905 08:00:17.691551 90901 sgd_solver.cpp:106] Iteration 35340, lr = 0.1
I0905 08:00:23.793123 90901 solver.cpp:228] Iteration 35350, loss = 0.456405
I0905 08:00:23.793167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456406 (* 1 = 0.456406 loss)
I0905 08:00:23.793181 90901 sgd_solver.cpp:106] Iteration 35350, lr = 0.1
I0905 08:00:29.841614 90901 solver.cpp:228] Iteration 35360, loss = 0.201567
I0905 08:00:29.841759 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201568 (* 1 = 0.201568 loss)
I0905 08:00:29.841812 90901 sgd_solver.cpp:106] Iteration 35360, lr = 0.1
I0905 08:00:35.932237 90901 solver.cpp:228] Iteration 35370, loss = 0.163489
I0905 08:00:35.932301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16349 (* 1 = 0.16349 loss)
I0905 08:00:35.932317 90901 sgd_solver.cpp:106] Iteration 35370, lr = 0.1
I0905 08:00:42.019127 90901 solver.cpp:228] Iteration 35380, loss = 0.410354
I0905 08:00:42.019177 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410355 (* 1 = 0.410355 loss)
I0905 08:00:42.019191 90901 sgd_solver.cpp:106] Iteration 35380, lr = 0.1
I0905 08:00:48.132926 90901 solver.cpp:228] Iteration 35390, loss = 0.222884
I0905 08:00:48.132966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222885 (* 1 = 0.222885 loss)
I0905 08:00:48.132982 90901 sgd_solver.cpp:106] Iteration 35390, lr = 0.1
I0905 08:00:54.241621 90901 solver.cpp:228] Iteration 35400, loss = 0.197872
I0905 08:00:54.241665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197873 (* 1 = 0.197873 loss)
I0905 08:00:54.241679 90901 sgd_solver.cpp:106] Iteration 35400, lr = 0.1
I0905 08:01:00.303361 90901 solver.cpp:228] Iteration 35410, loss = 0.285489
I0905 08:01:00.303534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28549 (* 1 = 0.28549 loss)
I0905 08:01:00.303575 90901 sgd_solver.cpp:106] Iteration 35410, lr = 0.1
I0905 08:01:06.385042 90901 solver.cpp:228] Iteration 35420, loss = 0.384539
I0905 08:01:06.385085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38454 (* 1 = 0.38454 loss)
I0905 08:01:06.385097 90901 sgd_solver.cpp:106] Iteration 35420, lr = 0.1
I0905 08:01:12.462327 90901 solver.cpp:228] Iteration 35430, loss = 0.29775
I0905 08:01:12.462396 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29775 (* 1 = 0.29775 loss)
I0905 08:01:12.462411 90901 sgd_solver.cpp:106] Iteration 35430, lr = 0.1
I0905 08:01:18.564368 90901 solver.cpp:228] Iteration 35440, loss = 0.61769
I0905 08:01:18.564421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.617691 (* 1 = 0.617691 loss)
I0905 08:01:18.564436 90901 sgd_solver.cpp:106] Iteration 35440, lr = 0.1
I0905 08:01:24.283790 90901 solver.cpp:228] Iteration 35450, loss = 0.381554
I0905 08:01:24.283849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381555 (* 1 = 0.381555 loss)
I0905 08:01:24.283861 90901 sgd_solver.cpp:106] Iteration 35450, lr = 0.1
I0905 08:01:29.534755 90901 solver.cpp:228] Iteration 35460, loss = 0.214572
I0905 08:01:29.534814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214573 (* 1 = 0.214573 loss)
I0905 08:01:29.534827 90901 sgd_solver.cpp:106] Iteration 35460, lr = 0.1
I0905 08:01:35.575037 90901 solver.cpp:228] Iteration 35470, loss = 0.377278
I0905 08:01:35.575273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377279 (* 1 = 0.377279 loss)
I0905 08:01:35.575290 90901 sgd_solver.cpp:106] Iteration 35470, lr = 0.1
I0905 08:01:41.642392 90901 solver.cpp:228] Iteration 35480, loss = 0.291312
I0905 08:01:41.642449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291313 (* 1 = 0.291313 loss)
I0905 08:01:41.642463 90901 sgd_solver.cpp:106] Iteration 35480, lr = 0.1
I0905 08:01:47.713989 90901 solver.cpp:228] Iteration 35490, loss = 0.450859
I0905 08:01:47.714035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45086 (* 1 = 0.45086 loss)
I0905 08:01:47.714049 90901 sgd_solver.cpp:106] Iteration 35490, lr = 0.1
I0905 08:01:53.805402 90901 solver.cpp:228] Iteration 35500, loss = 0.271263
I0905 08:01:53.805451 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271264 (* 1 = 0.271264 loss)
I0905 08:01:53.805466 90901 sgd_solver.cpp:106] Iteration 35500, lr = 0.1
I0905 08:01:59.954735 90901 solver.cpp:228] Iteration 35510, loss = 0.268114
I0905 08:01:59.954784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268115 (* 1 = 0.268115 loss)
I0905 08:01:59.954797 90901 sgd_solver.cpp:106] Iteration 35510, lr = 0.1
I0905 08:02:06.282531 90901 solver.cpp:228] Iteration 35520, loss = 0.246154
I0905 08:02:06.282719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246154 (* 1 = 0.246154 loss)
I0905 08:02:06.282757 90901 sgd_solver.cpp:106] Iteration 35520, lr = 0.1
I0905 08:02:12.355212 90901 solver.cpp:228] Iteration 35530, loss = 0.216323
I0905 08:02:12.355259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216323 (* 1 = 0.216323 loss)
I0905 08:02:12.355273 90901 sgd_solver.cpp:106] Iteration 35530, lr = 0.1
I0905 08:02:18.649873 90901 solver.cpp:228] Iteration 35540, loss = 0.696076
I0905 08:02:18.649922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.696077 (* 1 = 0.696077 loss)
I0905 08:02:18.649936 90901 sgd_solver.cpp:106] Iteration 35540, lr = 0.1
I0905 08:02:24.820780 90901 solver.cpp:228] Iteration 35550, loss = 0.234696
I0905 08:02:24.820828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234697 (* 1 = 0.234697 loss)
I0905 08:02:24.820842 90901 sgd_solver.cpp:106] Iteration 35550, lr = 0.1
I0905 08:02:30.887147 90901 solver.cpp:228] Iteration 35560, loss = 0.17814
I0905 08:02:30.887199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178141 (* 1 = 0.178141 loss)
I0905 08:02:30.887214 90901 sgd_solver.cpp:106] Iteration 35560, lr = 0.1
I0905 08:02:37.228699 90901 solver.cpp:228] Iteration 35570, loss = 0.224564
I0905 08:02:37.228904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224564 (* 1 = 0.224564 loss)
I0905 08:02:37.228936 90901 sgd_solver.cpp:106] Iteration 35570, lr = 0.1
I0905 08:02:43.343178 90901 solver.cpp:228] Iteration 35580, loss = 0.193263
I0905 08:02:43.343221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193264 (* 1 = 0.193264 loss)
I0905 08:02:43.343235 90901 sgd_solver.cpp:106] Iteration 35580, lr = 0.1
I0905 08:02:49.123800 90901 solver.cpp:228] Iteration 35590, loss = 0.165919
I0905 08:02:49.123847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16592 (* 1 = 0.16592 loss)
I0905 08:02:49.123862 90901 sgd_solver.cpp:106] Iteration 35590, lr = 0.1
I0905 08:02:55.559017 90901 solver.cpp:228] Iteration 35600, loss = 0.213282
I0905 08:02:55.559065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213283 (* 1 = 0.213283 loss)
I0905 08:02:55.559080 90901 sgd_solver.cpp:106] Iteration 35600, lr = 0.1
I0905 08:03:01.310302 90901 solver.cpp:228] Iteration 35610, loss = 0.145265
I0905 08:03:01.310348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145266 (* 1 = 0.145266 loss)
I0905 08:03:01.310361 90901 sgd_solver.cpp:106] Iteration 35610, lr = 0.1
I0905 08:03:07.480242 90901 solver.cpp:228] Iteration 35620, loss = 0.091908
I0905 08:03:07.480500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0919089 (* 1 = 0.0919089 loss)
I0905 08:03:07.480518 90901 sgd_solver.cpp:106] Iteration 35620, lr = 0.1
I0905 08:03:12.821315 90901 solver.cpp:228] Iteration 35630, loss = 0.533118
I0905 08:03:12.821358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.533119 (* 1 = 0.533119 loss)
I0905 08:03:12.821372 90901 sgd_solver.cpp:106] Iteration 35630, lr = 0.1
I0905 08:03:18.510536 90901 solver.cpp:228] Iteration 35640, loss = 0.228484
I0905 08:03:18.510591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228485 (* 1 = 0.228485 loss)
I0905 08:03:18.510603 90901 sgd_solver.cpp:106] Iteration 35640, lr = 0.1
I0905 08:03:24.567214 90901 solver.cpp:228] Iteration 35650, loss = 0.248844
I0905 08:03:24.567273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248845 (* 1 = 0.248845 loss)
I0905 08:03:24.567288 90901 sgd_solver.cpp:106] Iteration 35650, lr = 0.1
I0905 08:03:30.790470 90901 solver.cpp:228] Iteration 35660, loss = 0.46658
I0905 08:03:30.790518 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.466581 (* 1 = 0.466581 loss)
I0905 08:03:30.790531 90901 sgd_solver.cpp:106] Iteration 35660, lr = 0.1
I0905 08:03:37.081843 90901 solver.cpp:228] Iteration 35670, loss = 0.328165
I0905 08:03:37.081898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328166 (* 1 = 0.328166 loss)
I0905 08:03:37.081912 90901 sgd_solver.cpp:106] Iteration 35670, lr = 0.1
I0905 08:03:43.175024 90901 solver.cpp:228] Iteration 35680, loss = 0.210296
I0905 08:03:43.175179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210297 (* 1 = 0.210297 loss)
I0905 08:03:43.175225 90901 sgd_solver.cpp:106] Iteration 35680, lr = 0.1
I0905 08:03:49.063844 90901 solver.cpp:228] Iteration 35690, loss = 0.24503
I0905 08:03:49.063889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245031 (* 1 = 0.245031 loss)
I0905 08:03:49.063902 90901 sgd_solver.cpp:106] Iteration 35690, lr = 0.1
I0905 08:03:55.293597 90901 solver.cpp:228] Iteration 35700, loss = 0.401855
I0905 08:03:55.293644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401856 (* 1 = 0.401856 loss)
I0905 08:03:55.293658 90901 sgd_solver.cpp:106] Iteration 35700, lr = 0.1
I0905 08:04:01.365381 90901 solver.cpp:228] Iteration 35710, loss = 0.26228
I0905 08:04:01.365442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262281 (* 1 = 0.262281 loss)
I0905 08:04:01.365456 90901 sgd_solver.cpp:106] Iteration 35710, lr = 0.1
I0905 08:04:07.428891 90901 solver.cpp:228] Iteration 35720, loss = 0.106342
I0905 08:04:07.428939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106343 (* 1 = 0.106343 loss)
I0905 08:04:07.428952 90901 sgd_solver.cpp:106] Iteration 35720, lr = 0.1
I0905 08:04:13.486335 90901 solver.cpp:228] Iteration 35730, loss = 0.413508
I0905 08:04:13.486472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413509 (* 1 = 0.413509 loss)
I0905 08:04:13.486495 90901 sgd_solver.cpp:106] Iteration 35730, lr = 0.1
I0905 08:04:19.885572 90901 solver.cpp:228] Iteration 35740, loss = 0.161285
I0905 08:04:19.885617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161286 (* 1 = 0.161286 loss)
I0905 08:04:19.885630 90901 sgd_solver.cpp:106] Iteration 35740, lr = 0.1
I0905 08:04:26.002787 90901 solver.cpp:228] Iteration 35750, loss = 0.21085
I0905 08:04:26.002851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210851 (* 1 = 0.210851 loss)
I0905 08:04:26.002866 90901 sgd_solver.cpp:106] Iteration 35750, lr = 0.1
I0905 08:04:32.095541 90901 solver.cpp:228] Iteration 35760, loss = 0.140146
I0905 08:04:32.095584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140147 (* 1 = 0.140147 loss)
I0905 08:04:32.095597 90901 sgd_solver.cpp:106] Iteration 35760, lr = 0.1
I0905 08:04:37.850561 90901 solver.cpp:228] Iteration 35770, loss = 0.103879
I0905 08:04:37.850611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10388 (* 1 = 0.10388 loss)
I0905 08:04:37.850625 90901 sgd_solver.cpp:106] Iteration 35770, lr = 0.1
I0905 08:04:43.952953 90901 solver.cpp:228] Iteration 35780, loss = 0.219748
I0905 08:04:43.953213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219749 (* 1 = 0.219749 loss)
I0905 08:04:43.953243 90901 sgd_solver.cpp:106] Iteration 35780, lr = 0.1
I0905 08:04:50.349524 90901 solver.cpp:228] Iteration 35790, loss = 0.0826366
I0905 08:04:50.349570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0826377 (* 1 = 0.0826377 loss)
I0905 08:04:50.349583 90901 sgd_solver.cpp:106] Iteration 35790, lr = 0.1
I0905 08:04:56.157764 90901 solver.cpp:228] Iteration 35800, loss = 0.296835
I0905 08:04:56.157806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296836 (* 1 = 0.296836 loss)
I0905 08:04:56.157820 90901 sgd_solver.cpp:106] Iteration 35800, lr = 0.1
I0905 08:05:01.465509 90901 solver.cpp:228] Iteration 35810, loss = 0.222684
I0905 08:05:01.465554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222685 (* 1 = 0.222685 loss)
I0905 08:05:01.465569 90901 sgd_solver.cpp:106] Iteration 35810, lr = 0.1
I0905 08:05:07.334215 90901 solver.cpp:228] Iteration 35820, loss = 0.168792
I0905 08:05:07.334266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168794 (* 1 = 0.168794 loss)
I0905 08:05:07.334280 90901 sgd_solver.cpp:106] Iteration 35820, lr = 0.1
I0905 08:05:13.416707 90901 solver.cpp:228] Iteration 35830, loss = 0.195915
I0905 08:05:13.416755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195916 (* 1 = 0.195916 loss)
I0905 08:05:13.416767 90901 sgd_solver.cpp:106] Iteration 35830, lr = 0.1
I0905 08:05:19.852987 90901 solver.cpp:228] Iteration 35840, loss = 0.334237
I0905 08:05:19.853119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334239 (* 1 = 0.334239 loss)
I0905 08:05:19.853147 90901 sgd_solver.cpp:106] Iteration 35840, lr = 0.1
I0905 08:05:25.914535 90901 solver.cpp:228] Iteration 35850, loss = 0.337405
I0905 08:05:25.914605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337406 (* 1 = 0.337406 loss)
I0905 08:05:25.914621 90901 sgd_solver.cpp:106] Iteration 35850, lr = 0.1
I0905 08:05:31.963707 90901 solver.cpp:228] Iteration 35860, loss = 0.326195
I0905 08:05:31.963791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326196 (* 1 = 0.326196 loss)
I0905 08:05:31.963824 90901 sgd_solver.cpp:106] Iteration 35860, lr = 0.1
I0905 08:05:38.027075 90901 solver.cpp:228] Iteration 35870, loss = 0.26889
I0905 08:05:38.027149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268891 (* 1 = 0.268891 loss)
I0905 08:05:38.027163 90901 sgd_solver.cpp:106] Iteration 35870, lr = 0.1
I0905 08:05:44.116875 90901 solver.cpp:228] Iteration 35880, loss = 0.16875
I0905 08:05:44.116946 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168751 (* 1 = 0.168751 loss)
I0905 08:05:44.116962 90901 sgd_solver.cpp:106] Iteration 35880, lr = 0.1
I0905 08:05:50.207080 90901 solver.cpp:228] Iteration 35890, loss = 0.277346
I0905 08:05:50.207376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277347 (* 1 = 0.277347 loss)
I0905 08:05:50.207393 90901 sgd_solver.cpp:106] Iteration 35890, lr = 0.1
I0905 08:05:56.570107 90901 solver.cpp:228] Iteration 35900, loss = 0.322538
I0905 08:05:56.570169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322539 (* 1 = 0.322539 loss)
I0905 08:05:56.570185 90901 sgd_solver.cpp:106] Iteration 35900, lr = 0.1
I0905 08:06:02.644619 90901 solver.cpp:228] Iteration 35910, loss = 0.210007
I0905 08:06:02.644672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210008 (* 1 = 0.210008 loss)
I0905 08:06:02.644687 90901 sgd_solver.cpp:106] Iteration 35910, lr = 0.1
I0905 08:06:08.674345 90901 solver.cpp:228] Iteration 35920, loss = 0.244211
I0905 08:06:08.674407 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244212 (* 1 = 0.244212 loss)
I0905 08:06:08.674422 90901 sgd_solver.cpp:106] Iteration 35920, lr = 0.1
I0905 08:06:14.774868 90901 solver.cpp:228] Iteration 35930, loss = 0.207322
I0905 08:06:14.774924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207323 (* 1 = 0.207323 loss)
I0905 08:06:14.774946 90901 sgd_solver.cpp:106] Iteration 35930, lr = 0.1
I0905 08:06:20.806660 90901 solver.cpp:228] Iteration 35940, loss = 0.0879389
I0905 08:06:20.806758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.08794 (* 1 = 0.08794 loss)
I0905 08:06:20.806776 90901 sgd_solver.cpp:106] Iteration 35940, lr = 0.1
I0905 08:06:26.874867 90901 solver.cpp:228] Iteration 35950, loss = 0.145547
I0905 08:06:26.874922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145548 (* 1 = 0.145548 loss)
I0905 08:06:26.874936 90901 sgd_solver.cpp:106] Iteration 35950, lr = 0.1
I0905 08:06:33.130215 90901 solver.cpp:228] Iteration 35960, loss = 0.32504
I0905 08:06:33.130272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325041 (* 1 = 0.325041 loss)
I0905 08:06:33.130287 90901 sgd_solver.cpp:106] Iteration 35960, lr = 0.1
I0905 08:06:38.993222 90901 solver.cpp:228] Iteration 35970, loss = 0.0747086
I0905 08:06:38.993284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0747096 (* 1 = 0.0747096 loss)
I0905 08:06:38.993300 90901 sgd_solver.cpp:106] Iteration 35970, lr = 0.1
I0905 08:06:45.172467 90901 solver.cpp:228] Iteration 35980, loss = 0.192227
I0905 08:06:45.172515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192228 (* 1 = 0.192228 loss)
I0905 08:06:45.172528 90901 sgd_solver.cpp:106] Iteration 35980, lr = 0.1
I0905 08:06:50.425343 90901 solver.cpp:228] Iteration 35990, loss = 0.280588
I0905 08:06:50.425385 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280589 (* 1 = 0.280589 loss)
I0905 08:06:50.425398 90901 sgd_solver.cpp:106] Iteration 35990, lr = 0.1
I0905 08:06:55.571022 90901 solver.cpp:337] Iteration 36000, Testing net (#0)
I0905 08:07:38.300853 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.843125
I0905 08:07:38.301044 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.383078 (* 1 = 0.383078 loss)
I0905 08:07:38.521497 90901 solver.cpp:228] Iteration 36000, loss = 0.461492
I0905 08:07:38.521530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461493 (* 1 = 0.461493 loss)
I0905 08:07:38.521548 90901 sgd_solver.cpp:106] Iteration 36000, lr = 0.1
I0905 08:07:44.640328 90901 solver.cpp:228] Iteration 36010, loss = 0.491803
I0905 08:07:44.640393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491804 (* 1 = 0.491804 loss)
I0905 08:07:44.640408 90901 sgd_solver.cpp:106] Iteration 36010, lr = 0.1
I0905 08:07:50.710564 90901 solver.cpp:228] Iteration 36020, loss = 0.190105
I0905 08:07:50.710683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190106 (* 1 = 0.190106 loss)
I0905 08:07:50.710726 90901 sgd_solver.cpp:106] Iteration 36020, lr = 0.1
I0905 08:07:56.805218 90901 solver.cpp:228] Iteration 36030, loss = 0.238786
I0905 08:07:56.805253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238787 (* 1 = 0.238787 loss)
I0905 08:07:56.805265 90901 sgd_solver.cpp:106] Iteration 36030, lr = 0.1
I0905 08:08:02.847949 90901 solver.cpp:228] Iteration 36040, loss = 0.223399
I0905 08:08:02.848003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2234 (* 1 = 0.2234 loss)
I0905 08:08:02.848018 90901 sgd_solver.cpp:106] Iteration 36040, lr = 0.1
I0905 08:08:08.913820 90901 solver.cpp:228] Iteration 36050, loss = 0.317245
I0905 08:08:08.914033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317246 (* 1 = 0.317246 loss)
I0905 08:08:08.914064 90901 sgd_solver.cpp:106] Iteration 36050, lr = 0.1
I0905 08:08:14.683722 90901 solver.cpp:228] Iteration 36060, loss = 0.167317
I0905 08:08:14.683781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167317 (* 1 = 0.167317 loss)
I0905 08:08:14.683809 90901 sgd_solver.cpp:106] Iteration 36060, lr = 0.1
I0905 08:08:21.102800 90901 solver.cpp:228] Iteration 36070, loss = 0.467431
I0905 08:08:21.102869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467432 (* 1 = 0.467432 loss)
I0905 08:08:21.102885 90901 sgd_solver.cpp:106] Iteration 36070, lr = 0.1
I0905 08:08:27.175066 90901 solver.cpp:228] Iteration 36080, loss = 0.2721
I0905 08:08:27.175108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272101 (* 1 = 0.272101 loss)
I0905 08:08:27.175122 90901 sgd_solver.cpp:106] Iteration 36080, lr = 0.1
I0905 08:08:32.944672 90901 solver.cpp:228] Iteration 36090, loss = 0.118767
I0905 08:08:32.944733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118768 (* 1 = 0.118768 loss)
I0905 08:08:32.944746 90901 sgd_solver.cpp:106] Iteration 36090, lr = 0.1
I0905 08:08:38.335296 90901 solver.cpp:228] Iteration 36100, loss = 0.498565
I0905 08:08:38.335347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498566 (* 1 = 0.498566 loss)
I0905 08:08:38.335361 90901 sgd_solver.cpp:106] Iteration 36100, lr = 0.1
I0905 08:08:44.114663 90901 solver.cpp:228] Iteration 36110, loss = 0.482495
I0905 08:08:44.114811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482495 (* 1 = 0.482495 loss)
I0905 08:08:44.114857 90901 sgd_solver.cpp:106] Iteration 36110, lr = 0.1
I0905 08:08:50.157081 90901 solver.cpp:228] Iteration 36120, loss = 0.255914
I0905 08:08:50.157121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255915 (* 1 = 0.255915 loss)
I0905 08:08:50.157135 90901 sgd_solver.cpp:106] Iteration 36120, lr = 0.1
I0905 08:08:56.217473 90901 solver.cpp:228] Iteration 36130, loss = 0.264054
I0905 08:08:56.217515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264055 (* 1 = 0.264055 loss)
I0905 08:08:56.217528 90901 sgd_solver.cpp:106] Iteration 36130, lr = 0.1
I0905 08:09:02.281741 90901 solver.cpp:228] Iteration 36140, loss = 0.201674
I0905 08:09:02.281791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201675 (* 1 = 0.201675 loss)
I0905 08:09:02.281810 90901 sgd_solver.cpp:106] Iteration 36140, lr = 0.1
I0905 08:09:08.046437 90901 solver.cpp:228] Iteration 36150, loss = 0.280737
I0905 08:09:08.046481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280738 (* 1 = 0.280738 loss)
I0905 08:09:08.046494 90901 sgd_solver.cpp:106] Iteration 36150, lr = 0.1
I0905 08:09:13.089174 90901 solver.cpp:228] Iteration 36160, loss = 0.572033
I0905 08:09:13.089215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572034 (* 1 = 0.572034 loss)
I0905 08:09:13.089231 90901 sgd_solver.cpp:106] Iteration 36160, lr = 0.1
I0905 08:09:18.167362 90901 solver.cpp:228] Iteration 36170, loss = 0.46137
I0905 08:09:18.167572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461371 (* 1 = 0.461371 loss)
I0905 08:09:18.167618 90901 sgd_solver.cpp:106] Iteration 36170, lr = 0.1
I0905 08:09:23.224386 90901 solver.cpp:228] Iteration 36180, loss = 0.209147
I0905 08:09:23.224434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209147 (* 1 = 0.209147 loss)
I0905 08:09:23.224447 90901 sgd_solver.cpp:106] Iteration 36180, lr = 0.1
I0905 08:09:28.247174 90901 solver.cpp:228] Iteration 36190, loss = 0.491487
I0905 08:09:28.247215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491488 (* 1 = 0.491488 loss)
I0905 08:09:28.247227 90901 sgd_solver.cpp:106] Iteration 36190, lr = 0.1
I0905 08:09:33.275832 90901 solver.cpp:228] Iteration 36200, loss = 0.383833
I0905 08:09:33.275882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383833 (* 1 = 0.383833 loss)
I0905 08:09:33.275895 90901 sgd_solver.cpp:106] Iteration 36200, lr = 0.1
I0905 08:09:38.332777 90901 solver.cpp:228] Iteration 36210, loss = 0.207246
I0905 08:09:38.332836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207247 (* 1 = 0.207247 loss)
I0905 08:09:38.332850 90901 sgd_solver.cpp:106] Iteration 36210, lr = 0.1
I0905 08:09:43.416388 90901 solver.cpp:228] Iteration 36220, loss = 0.308597
I0905 08:09:43.416436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308598 (* 1 = 0.308598 loss)
I0905 08:09:43.416448 90901 sgd_solver.cpp:106] Iteration 36220, lr = 0.1
I0905 08:09:48.471398 90901 solver.cpp:228] Iteration 36230, loss = 0.193745
I0905 08:09:48.471645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193746 (* 1 = 0.193746 loss)
I0905 08:09:48.471662 90901 sgd_solver.cpp:106] Iteration 36230, lr = 0.1
I0905 08:09:53.542193 90901 solver.cpp:228] Iteration 36240, loss = 0.3877
I0905 08:09:53.542232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387701 (* 1 = 0.387701 loss)
I0905 08:09:53.542245 90901 sgd_solver.cpp:106] Iteration 36240, lr = 0.1
I0905 08:09:58.580137 90901 solver.cpp:228] Iteration 36250, loss = 0.224846
I0905 08:09:58.580183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224847 (* 1 = 0.224847 loss)
I0905 08:09:58.580196 90901 sgd_solver.cpp:106] Iteration 36250, lr = 0.1
I0905 08:10:03.649073 90901 solver.cpp:228] Iteration 36260, loss = 0.343191
I0905 08:10:03.649121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343192 (* 1 = 0.343192 loss)
I0905 08:10:03.649132 90901 sgd_solver.cpp:106] Iteration 36260, lr = 0.1
I0905 08:10:08.731395 90901 solver.cpp:228] Iteration 36270, loss = 0.199655
I0905 08:10:08.731449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199656 (* 1 = 0.199656 loss)
I0905 08:10:08.731464 90901 sgd_solver.cpp:106] Iteration 36270, lr = 0.1
I0905 08:10:13.824825 90901 solver.cpp:228] Iteration 36280, loss = 0.198829
I0905 08:10:13.824873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19883 (* 1 = 0.19883 loss)
I0905 08:10:13.824888 90901 sgd_solver.cpp:106] Iteration 36280, lr = 0.1
I0905 08:10:18.881760 90901 solver.cpp:228] Iteration 36290, loss = 0.278176
I0905 08:10:18.881948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278177 (* 1 = 0.278177 loss)
I0905 08:10:18.881973 90901 sgd_solver.cpp:106] Iteration 36290, lr = 0.1
I0905 08:10:23.521842 90901 solver.cpp:228] Iteration 36300, loss = 0.116661
I0905 08:10:23.521890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116661 (* 1 = 0.116661 loss)
I0905 08:10:23.521903 90901 sgd_solver.cpp:106] Iteration 36300, lr = 0.1
I0905 08:10:28.168575 90901 solver.cpp:228] Iteration 36310, loss = 0.39008
I0905 08:10:28.168620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39008 (* 1 = 0.39008 loss)
I0905 08:10:28.168633 90901 sgd_solver.cpp:106] Iteration 36310, lr = 0.1
I0905 08:10:33.672972 90901 solver.cpp:228] Iteration 36320, loss = 0.177012
I0905 08:10:33.673029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177013 (* 1 = 0.177013 loss)
I0905 08:10:33.673045 90901 sgd_solver.cpp:106] Iteration 36320, lr = 0.1
I0905 08:10:39.936653 90901 solver.cpp:228] Iteration 36330, loss = 0.147565
I0905 08:10:39.936697 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147565 (* 1 = 0.147565 loss)
I0905 08:10:39.936710 90901 sgd_solver.cpp:106] Iteration 36330, lr = 0.1
I0905 08:10:45.818444 90901 solver.cpp:228] Iteration 36340, loss = 0.471832
I0905 08:10:45.818497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.471833 (* 1 = 0.471833 loss)
I0905 08:10:45.818511 90901 sgd_solver.cpp:106] Iteration 36340, lr = 0.1
I0905 08:10:51.921579 90901 solver.cpp:228] Iteration 36350, loss = 0.245015
I0905 08:10:51.921785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245016 (* 1 = 0.245016 loss)
I0905 08:10:51.921849 90901 sgd_solver.cpp:106] Iteration 36350, lr = 0.1
I0905 08:10:57.989601 90901 solver.cpp:228] Iteration 36360, loss = 0.387683
I0905 08:10:57.989640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387684 (* 1 = 0.387684 loss)
I0905 08:10:57.989653 90901 sgd_solver.cpp:106] Iteration 36360, lr = 0.1
I0905 08:11:04.324653 90901 solver.cpp:228] Iteration 36370, loss = 0.247424
I0905 08:11:04.324694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247425 (* 1 = 0.247425 loss)
I0905 08:11:04.324707 90901 sgd_solver.cpp:106] Iteration 36370, lr = 0.1
I0905 08:11:10.358858 90901 solver.cpp:228] Iteration 36380, loss = 0.453348
I0905 08:11:10.358894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453348 (* 1 = 0.453348 loss)
I0905 08:11:10.358908 90901 sgd_solver.cpp:106] Iteration 36380, lr = 0.1
I0905 08:11:16.763545 90901 solver.cpp:228] Iteration 36390, loss = 0.32865
I0905 08:11:16.763602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328651 (* 1 = 0.328651 loss)
I0905 08:11:16.763615 90901 sgd_solver.cpp:106] Iteration 36390, lr = 0.1
I0905 08:11:22.792174 90901 solver.cpp:228] Iteration 36400, loss = 0.132402
I0905 08:11:22.792398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132402 (* 1 = 0.132402 loss)
I0905 08:11:22.792438 90901 sgd_solver.cpp:106] Iteration 36400, lr = 0.1
I0905 08:11:28.880188 90901 solver.cpp:228] Iteration 36410, loss = 0.126376
I0905 08:11:28.880230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126377 (* 1 = 0.126377 loss)
I0905 08:11:28.880241 90901 sgd_solver.cpp:106] Iteration 36410, lr = 0.1
I0905 08:11:34.952683 90901 solver.cpp:228] Iteration 36420, loss = 0.252242
I0905 08:11:34.952729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252243 (* 1 = 0.252243 loss)
I0905 08:11:34.952742 90901 sgd_solver.cpp:106] Iteration 36420, lr = 0.1
I0905 08:11:41.035003 90901 solver.cpp:228] Iteration 36430, loss = 0.407172
I0905 08:11:41.035051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407172 (* 1 = 0.407172 loss)
I0905 08:11:41.035069 90901 sgd_solver.cpp:106] Iteration 36430, lr = 0.1
I0905 08:11:47.127012 90901 solver.cpp:228] Iteration 36440, loss = 0.241661
I0905 08:11:47.127056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241662 (* 1 = 0.241662 loss)
I0905 08:11:47.127069 90901 sgd_solver.cpp:106] Iteration 36440, lr = 0.1
I0905 08:11:53.395977 90901 solver.cpp:228] Iteration 36450, loss = 0.164053
I0905 08:11:53.396188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164054 (* 1 = 0.164054 loss)
I0905 08:11:53.396205 90901 sgd_solver.cpp:106] Iteration 36450, lr = 0.1
I0905 08:11:59.271034 90901 solver.cpp:228] Iteration 36460, loss = 0.294685
I0905 08:11:59.271080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294685 (* 1 = 0.294685 loss)
I0905 08:11:59.271095 90901 sgd_solver.cpp:106] Iteration 36460, lr = 0.1
I0905 08:12:05.490236 90901 solver.cpp:228] Iteration 36470, loss = 0.287956
I0905 08:12:05.490278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287956 (* 1 = 0.287956 loss)
I0905 08:12:05.490293 90901 sgd_solver.cpp:106] Iteration 36470, lr = 0.1
I0905 08:12:11.481930 90901 solver.cpp:228] Iteration 36480, loss = 0.241764
I0905 08:12:11.481978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241765 (* 1 = 0.241765 loss)
I0905 08:12:11.481992 90901 sgd_solver.cpp:106] Iteration 36480, lr = 0.1
I0905 08:12:16.736876 90901 solver.cpp:228] Iteration 36490, loss = 0.311317
I0905 08:12:16.736939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311318 (* 1 = 0.311318 loss)
I0905 08:12:16.736953 90901 sgd_solver.cpp:106] Iteration 36490, lr = 0.1
I0905 08:12:22.564175 90901 solver.cpp:228] Iteration 36500, loss = 0.154995
I0905 08:12:22.564225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154995 (* 1 = 0.154995 loss)
I0905 08:12:22.564241 90901 sgd_solver.cpp:106] Iteration 36500, lr = 0.1
I0905 08:12:28.497272 90901 solver.cpp:228] Iteration 36510, loss = 0.158101
I0905 08:12:28.497416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158102 (* 1 = 0.158102 loss)
I0905 08:12:28.497434 90901 sgd_solver.cpp:106] Iteration 36510, lr = 0.1
I0905 08:12:34.743597 90901 solver.cpp:228] Iteration 36520, loss = 0.552241
I0905 08:12:34.743650 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552242 (* 1 = 0.552242 loss)
I0905 08:12:34.743664 90901 sgd_solver.cpp:106] Iteration 36520, lr = 0.1
I0905 08:12:40.854341 90901 solver.cpp:228] Iteration 36530, loss = 0.448429
I0905 08:12:40.854384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44843 (* 1 = 0.44843 loss)
I0905 08:12:40.854396 90901 sgd_solver.cpp:106] Iteration 36530, lr = 0.1
I0905 08:12:46.932258 90901 solver.cpp:228] Iteration 36540, loss = 0.389585
I0905 08:12:46.932304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389585 (* 1 = 0.389585 loss)
I0905 08:12:46.932317 90901 sgd_solver.cpp:106] Iteration 36540, lr = 0.1
I0905 08:12:52.995170 90901 solver.cpp:228] Iteration 36550, loss = 0.237665
I0905 08:12:52.995218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237665 (* 1 = 0.237665 loss)
I0905 08:12:52.995231 90901 sgd_solver.cpp:106] Iteration 36550, lr = 0.1
I0905 08:12:59.103294 90901 solver.cpp:228] Iteration 36560, loss = 0.146735
I0905 08:12:59.103446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146736 (* 1 = 0.146736 loss)
I0905 08:12:59.103490 90901 sgd_solver.cpp:106] Iteration 36560, lr = 0.1
I0905 08:13:05.274576 90901 solver.cpp:228] Iteration 36570, loss = 0.237157
I0905 08:13:05.274624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237158 (* 1 = 0.237158 loss)
I0905 08:13:05.274648 90901 sgd_solver.cpp:106] Iteration 36570, lr = 0.1
I0905 08:13:11.292775 90901 solver.cpp:228] Iteration 36580, loss = 0.321289
I0905 08:13:11.292815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321289 (* 1 = 0.321289 loss)
I0905 08:13:11.292829 90901 sgd_solver.cpp:106] Iteration 36580, lr = 0.1
I0905 08:13:17.610002 90901 solver.cpp:228] Iteration 36590, loss = 0.209988
I0905 08:13:17.610059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209988 (* 1 = 0.209988 loss)
I0905 08:13:17.610072 90901 sgd_solver.cpp:106] Iteration 36590, lr = 0.1
I0905 08:13:23.705050 90901 solver.cpp:228] Iteration 36600, loss = 0.356445
I0905 08:13:23.705104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356445 (* 1 = 0.356445 loss)
I0905 08:13:23.705118 90901 sgd_solver.cpp:106] Iteration 36600, lr = 0.1
I0905 08:13:29.769510 90901 solver.cpp:228] Iteration 36610, loss = 0.887008
I0905 08:13:29.769654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.887009 (* 1 = 0.887009 loss)
I0905 08:13:29.769681 90901 sgd_solver.cpp:106] Iteration 36610, lr = 0.1
I0905 08:13:35.860671 90901 solver.cpp:228] Iteration 36620, loss = 0.10995
I0905 08:13:35.860725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109951 (* 1 = 0.109951 loss)
I0905 08:13:35.860739 90901 sgd_solver.cpp:106] Iteration 36620, lr = 0.1
I0905 08:13:41.947409 90901 solver.cpp:228] Iteration 36630, loss = 0.161489
I0905 08:13:41.947455 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16149 (* 1 = 0.16149 loss)
I0905 08:13:41.947468 90901 sgd_solver.cpp:106] Iteration 36630, lr = 0.1
I0905 08:13:47.684962 90901 solver.cpp:228] Iteration 36640, loss = 0.266955
I0905 08:13:47.685009 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266955 (* 1 = 0.266955 loss)
I0905 08:13:47.685021 90901 sgd_solver.cpp:106] Iteration 36640, lr = 0.1
I0905 08:13:54.128857 90901 solver.cpp:228] Iteration 36650, loss = 0.131783
I0905 08:13:54.128940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131784 (* 1 = 0.131784 loss)
I0905 08:13:54.128991 90901 sgd_solver.cpp:106] Iteration 36650, lr = 0.1
I0905 08:13:59.729408 90901 solver.cpp:228] Iteration 36660, loss = 0.411335
I0905 08:13:59.729454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.411336 (* 1 = 0.411336 loss)
I0905 08:13:59.729466 90901 sgd_solver.cpp:106] Iteration 36660, lr = 0.1
I0905 08:14:05.029701 90901 solver.cpp:228] Iteration 36670, loss = 0.577408
I0905 08:14:05.029953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.577408 (* 1 = 0.577408 loss)
I0905 08:14:05.029978 90901 sgd_solver.cpp:106] Iteration 36670, lr = 0.1
I0905 08:14:11.317169 90901 solver.cpp:228] Iteration 36680, loss = 0.410396
I0905 08:14:11.317225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410396 (* 1 = 0.410396 loss)
I0905 08:14:11.317245 90901 sgd_solver.cpp:106] Iteration 36680, lr = 0.1
I0905 08:14:17.190383 90901 solver.cpp:228] Iteration 36690, loss = 0.637147
I0905 08:14:17.190438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.637147 (* 1 = 0.637147 loss)
I0905 08:14:17.190451 90901 sgd_solver.cpp:106] Iteration 36690, lr = 0.1
I0905 08:14:23.276427 90901 solver.cpp:228] Iteration 36700, loss = 0.169489
I0905 08:14:23.276466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169489 (* 1 = 0.169489 loss)
I0905 08:14:23.276479 90901 sgd_solver.cpp:106] Iteration 36700, lr = 0.1
I0905 08:14:29.621251 90901 solver.cpp:228] Iteration 36710, loss = 0.0980874
I0905 08:14:29.621299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0980879 (* 1 = 0.0980879 loss)
I0905 08:14:29.621311 90901 sgd_solver.cpp:106] Iteration 36710, lr = 0.1
I0905 08:14:35.765844 90901 solver.cpp:228] Iteration 36720, loss = 0.451733
I0905 08:14:35.766011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451733 (* 1 = 0.451733 loss)
I0905 08:14:35.766050 90901 sgd_solver.cpp:106] Iteration 36720, lr = 0.1
I0905 08:14:41.848073 90901 solver.cpp:228] Iteration 36730, loss = 0.158914
I0905 08:14:41.848132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158915 (* 1 = 0.158915 loss)
I0905 08:14:41.848147 90901 sgd_solver.cpp:106] Iteration 36730, lr = 0.1
I0905 08:14:47.911077 90901 solver.cpp:228] Iteration 36740, loss = 0.509372
I0905 08:14:47.911118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.509373 (* 1 = 0.509373 loss)
I0905 08:14:47.911139 90901 sgd_solver.cpp:106] Iteration 36740, lr = 0.1
I0905 08:14:54.260471 90901 solver.cpp:228] Iteration 36750, loss = 0.789128
I0905 08:14:54.260531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.789128 (* 1 = 0.789128 loss)
I0905 08:14:54.260546 90901 sgd_solver.cpp:106] Iteration 36750, lr = 0.1
I0905 08:15:00.045469 90901 solver.cpp:228] Iteration 36760, loss = 0.0852925
I0905 08:15:00.045516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.085293 (* 1 = 0.085293 loss)
I0905 08:15:00.045542 90901 sgd_solver.cpp:106] Iteration 36760, lr = 0.1
I0905 08:15:06.328423 90901 solver.cpp:228] Iteration 36770, loss = 0.613049
I0905 08:15:06.328531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.613049 (* 1 = 0.613049 loss)
I0905 08:15:06.328543 90901 sgd_solver.cpp:106] Iteration 36770, lr = 0.1
I0905 08:15:12.201288 90901 solver.cpp:228] Iteration 36780, loss = 0.251961
I0905 08:15:12.201337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251961 (* 1 = 0.251961 loss)
I0905 08:15:12.201352 90901 sgd_solver.cpp:106] Iteration 36780, lr = 0.1
I0905 08:15:18.445567 90901 solver.cpp:228] Iteration 36790, loss = 0.105426
I0905 08:15:18.445622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105427 (* 1 = 0.105427 loss)
I0905 08:15:18.445636 90901 sgd_solver.cpp:106] Iteration 36790, lr = 0.1
I0905 08:15:24.119702 90901 solver.cpp:337] Iteration 36800, Testing net (#0)
I0905 08:16:05.533231 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.74125
I0905 08:16:05.533460 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.537304 (* 1 = 0.537304 loss)
I0905 08:16:05.750784 90901 solver.cpp:228] Iteration 36800, loss = 0.109698
I0905 08:16:05.750814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109699 (* 1 = 0.109699 loss)
I0905 08:16:05.750829 90901 sgd_solver.cpp:106] Iteration 36800, lr = 0.1
I0905 08:16:11.798502 90901 solver.cpp:228] Iteration 36810, loss = 0.118809
I0905 08:16:11.798557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11881 (* 1 = 0.11881 loss)
I0905 08:16:11.798570 90901 sgd_solver.cpp:106] Iteration 36810, lr = 0.1
I0905 08:16:18.174161 90901 solver.cpp:228] Iteration 36820, loss = 0.157852
I0905 08:16:18.174221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157852 (* 1 = 0.157852 loss)
I0905 08:16:18.174235 90901 sgd_solver.cpp:106] Iteration 36820, lr = 0.1
I0905 08:16:24.223512 90901 solver.cpp:228] Iteration 36830, loss = 0.105976
I0905 08:16:24.223559 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105977 (* 1 = 0.105977 loss)
I0905 08:16:24.223572 90901 sgd_solver.cpp:106] Iteration 36830, lr = 0.1
I0905 08:16:30.303977 90901 solver.cpp:228] Iteration 36840, loss = 0.177339
I0905 08:16:30.304039 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177339 (* 1 = 0.177339 loss)
I0905 08:16:30.304054 90901 sgd_solver.cpp:106] Iteration 36840, lr = 0.1
I0905 08:16:36.382839 90901 solver.cpp:228] Iteration 36850, loss = 0.286481
I0905 08:16:36.383035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286482 (* 1 = 0.286482 loss)
I0905 08:16:36.383064 90901 sgd_solver.cpp:106] Iteration 36850, lr = 0.1
I0905 08:16:42.419741 90901 solver.cpp:228] Iteration 36860, loss = 0.516836
I0905 08:16:42.419785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.516837 (* 1 = 0.516837 loss)
I0905 08:16:42.419798 90901 sgd_solver.cpp:106] Iteration 36860, lr = 0.1
I0905 08:16:48.544657 90901 solver.cpp:228] Iteration 36870, loss = 0.184947
I0905 08:16:48.544728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184948 (* 1 = 0.184948 loss)
I0905 08:16:48.544744 90901 sgd_solver.cpp:106] Iteration 36870, lr = 0.1
I0905 08:16:54.292287 90901 solver.cpp:228] Iteration 36880, loss = 0.370595
I0905 08:16:54.292335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370595 (* 1 = 0.370595 loss)
I0905 08:16:54.292348 90901 sgd_solver.cpp:106] Iteration 36880, lr = 0.1
I0905 08:17:00.662027 90901 solver.cpp:228] Iteration 36890, loss = 0.265891
I0905 08:17:00.662086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265892 (* 1 = 0.265892 loss)
I0905 08:17:00.662101 90901 sgd_solver.cpp:106] Iteration 36890, lr = 0.1
I0905 08:17:06.733775 90901 solver.cpp:228] Iteration 36900, loss = 0.42505
I0905 08:17:06.733916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42505 (* 1 = 0.42505 loss)
I0905 08:17:06.733932 90901 sgd_solver.cpp:106] Iteration 36900, lr = 0.1
I0905 08:17:12.833747 90901 solver.cpp:228] Iteration 36910, loss = 0.157765
I0905 08:17:12.833820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157766 (* 1 = 0.157766 loss)
I0905 08:17:12.833834 90901 sgd_solver.cpp:106] Iteration 36910, lr = 0.1
I0905 08:17:18.585624 90901 solver.cpp:228] Iteration 36920, loss = 0.555777
I0905 08:17:18.585671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555778 (* 1 = 0.555778 loss)
I0905 08:17:18.585685 90901 sgd_solver.cpp:106] Iteration 36920, lr = 0.1
I0905 08:17:24.984349 90901 solver.cpp:228] Iteration 36930, loss = 0.14538
I0905 08:17:24.984426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14538 (* 1 = 0.14538 loss)
I0905 08:17:24.984442 90901 sgd_solver.cpp:106] Iteration 36930, lr = 0.1
I0905 08:17:31.055182 90901 solver.cpp:228] Iteration 36940, loss = 0.332779
I0905 08:17:31.055255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33278 (* 1 = 0.33278 loss)
I0905 08:17:31.055271 90901 sgd_solver.cpp:106] Iteration 36940, lr = 0.1
I0905 08:17:36.372586 90901 solver.cpp:228] Iteration 36950, loss = 0.310623
I0905 08:17:36.372650 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310624 (* 1 = 0.310624 loss)
I0905 08:17:36.372664 90901 sgd_solver.cpp:106] Iteration 36950, lr = 0.1
I0905 08:17:42.038689 90901 solver.cpp:228] Iteration 36960, loss = 0.412605
I0905 08:17:42.039011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412605 (* 1 = 0.412605 loss)
I0905 08:17:42.039028 90901 sgd_solver.cpp:106] Iteration 36960, lr = 0.1
I0905 08:17:48.120299 90901 solver.cpp:228] Iteration 36970, loss = 0.161528
I0905 08:17:48.120357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161529 (* 1 = 0.161529 loss)
I0905 08:17:48.120373 90901 sgd_solver.cpp:106] Iteration 36970, lr = 0.1
I0905 08:17:54.168706 90901 solver.cpp:228] Iteration 36980, loss = 0.518804
I0905 08:17:54.168767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.518804 (* 1 = 0.518804 loss)
I0905 08:17:54.168783 90901 sgd_solver.cpp:106] Iteration 36980, lr = 0.1
I0905 08:18:00.293062 90901 solver.cpp:228] Iteration 36990, loss = 0.294353
I0905 08:18:00.293125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294353 (* 1 = 0.294353 loss)
I0905 08:18:00.293143 90901 sgd_solver.cpp:106] Iteration 36990, lr = 0.1
I0905 08:18:06.342236 90901 solver.cpp:228] Iteration 37000, loss = 0.266979
I0905 08:18:06.342296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26698 (* 1 = 0.26698 loss)
I0905 08:18:06.342310 90901 sgd_solver.cpp:106] Iteration 37000, lr = 0.1
I0905 08:18:12.414624 90901 solver.cpp:228] Iteration 37010, loss = 0.387565
I0905 08:18:12.414834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387565 (* 1 = 0.387565 loss)
I0905 08:18:12.414876 90901 sgd_solver.cpp:106] Iteration 37010, lr = 0.1
I0905 08:18:18.481596 90901 solver.cpp:228] Iteration 37020, loss = 0.170986
I0905 08:18:18.481667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170986 (* 1 = 0.170986 loss)
I0905 08:18:18.481683 90901 sgd_solver.cpp:106] Iteration 37020, lr = 0.1
I0905 08:18:24.548773 90901 solver.cpp:228] Iteration 37030, loss = 0.30107
I0905 08:18:24.548821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30107 (* 1 = 0.30107 loss)
I0905 08:18:24.548833 90901 sgd_solver.cpp:106] Iteration 37030, lr = 0.1
I0905 08:18:30.616727 90901 solver.cpp:228] Iteration 37040, loss = 0.311464
I0905 08:18:30.616797 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311465 (* 1 = 0.311465 loss)
I0905 08:18:30.616812 90901 sgd_solver.cpp:106] Iteration 37040, lr = 0.1
I0905 08:18:36.686287 90901 solver.cpp:228] Iteration 37050, loss = 0.189637
I0905 08:18:36.686342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189638 (* 1 = 0.189638 loss)
I0905 08:18:36.686355 90901 sgd_solver.cpp:106] Iteration 37050, lr = 0.1
I0905 08:18:43.091069 90901 solver.cpp:228] Iteration 37060, loss = 0.156434
I0905 08:18:43.091197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156435 (* 1 = 0.156435 loss)
I0905 08:18:43.091225 90901 sgd_solver.cpp:106] Iteration 37060, lr = 0.1
I0905 08:18:48.850767 90901 solver.cpp:228] Iteration 37070, loss = 0.26541
I0905 08:18:48.850807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265411 (* 1 = 0.265411 loss)
I0905 08:18:48.850819 90901 sgd_solver.cpp:106] Iteration 37070, lr = 0.1
I0905 08:18:54.944437 90901 solver.cpp:228] Iteration 37080, loss = 0.27757
I0905 08:18:54.944496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277571 (* 1 = 0.277571 loss)
I0905 08:18:54.944510 90901 sgd_solver.cpp:106] Iteration 37080, lr = 0.1
I0905 08:19:01.383282 90901 solver.cpp:228] Iteration 37090, loss = 0.725275
I0905 08:19:01.383324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.725276 (* 1 = 0.725276 loss)
I0905 08:19:01.383337 90901 sgd_solver.cpp:106] Iteration 37090, lr = 0.1
I0905 08:19:07.442864 90901 solver.cpp:228] Iteration 37100, loss = 0.254745
I0905 08:19:07.442939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254745 (* 1 = 0.254745 loss)
I0905 08:19:07.442975 90901 sgd_solver.cpp:106] Iteration 37100, lr = 0.1
I0905 08:19:13.496166 90901 solver.cpp:228] Iteration 37110, loss = 0.443269
I0905 08:19:13.496422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443269 (* 1 = 0.443269 loss)
I0905 08:19:13.496438 90901 sgd_solver.cpp:106] Iteration 37110, lr = 0.1
I0905 08:19:19.455484 90901 solver.cpp:228] Iteration 37120, loss = 0.358679
I0905 08:19:19.455534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35868 (* 1 = 0.35868 loss)
I0905 08:19:19.455549 90901 sgd_solver.cpp:106] Iteration 37120, lr = 0.1
I0905 08:19:25.021052 90901 solver.cpp:228] Iteration 37130, loss = 0.158798
I0905 08:19:25.021108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158799 (* 1 = 0.158799 loss)
I0905 08:19:25.021123 90901 sgd_solver.cpp:106] Iteration 37130, lr = 0.1
I0905 08:19:30.452383 90901 solver.cpp:228] Iteration 37140, loss = 0.332179
I0905 08:19:30.452431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332179 (* 1 = 0.332179 loss)
I0905 08:19:30.452445 90901 sgd_solver.cpp:106] Iteration 37140, lr = 0.1
I0905 08:19:36.831616 90901 solver.cpp:228] Iteration 37150, loss = 0.423942
I0905 08:19:36.831687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423943 (* 1 = 0.423943 loss)
I0905 08:19:36.831702 90901 sgd_solver.cpp:106] Iteration 37150, lr = 0.1
I0905 08:19:42.907358 90901 solver.cpp:228] Iteration 37160, loss = 0.345627
I0905 08:19:42.907418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345628 (* 1 = 0.345628 loss)
I0905 08:19:42.907433 90901 sgd_solver.cpp:106] Iteration 37160, lr = 0.1
I0905 08:19:49.104369 90901 solver.cpp:228] Iteration 37170, loss = 0.13315
I0905 08:19:49.104815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13315 (* 1 = 0.13315 loss)
I0905 08:19:49.104830 90901 sgd_solver.cpp:106] Iteration 37170, lr = 0.1
I0905 08:19:55.360772 90901 solver.cpp:228] Iteration 37180, loss = 0.22232
I0905 08:19:55.360817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22232 (* 1 = 0.22232 loss)
I0905 08:19:55.360831 90901 sgd_solver.cpp:106] Iteration 37180, lr = 0.1
I0905 08:20:01.260622 90901 solver.cpp:228] Iteration 37190, loss = 0.822615
I0905 08:20:01.260668 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.822616 (* 1 = 0.822616 loss)
I0905 08:20:01.260681 90901 sgd_solver.cpp:106] Iteration 37190, lr = 0.1
I0905 08:20:07.502096 90901 solver.cpp:228] Iteration 37200, loss = 0.187871
I0905 08:20:07.502142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187871 (* 1 = 0.187871 loss)
I0905 08:20:07.502159 90901 sgd_solver.cpp:106] Iteration 37200, lr = 0.1
I0905 08:20:13.553076 90901 solver.cpp:228] Iteration 37210, loss = 0.409765
I0905 08:20:13.553123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409765 (* 1 = 0.409765 loss)
I0905 08:20:13.553136 90901 sgd_solver.cpp:106] Iteration 37210, lr = 0.1
I0905 08:20:19.326091 90901 solver.cpp:228] Iteration 37220, loss = 0.437368
I0905 08:20:19.326230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437368 (* 1 = 0.437368 loss)
I0905 08:20:19.326279 90901 sgd_solver.cpp:106] Iteration 37220, lr = 0.1
I0905 08:20:25.729737 90901 solver.cpp:228] Iteration 37230, loss = 0.139129
I0905 08:20:25.729795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13913 (* 1 = 0.13913 loss)
I0905 08:20:25.729809 90901 sgd_solver.cpp:106] Iteration 37230, lr = 0.1
I0905 08:20:32.083956 90901 solver.cpp:228] Iteration 37240, loss = 0.0954527
I0905 08:20:32.084020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0954532 (* 1 = 0.0954532 loss)
I0905 08:20:32.084036 90901 sgd_solver.cpp:106] Iteration 37240, lr = 0.1
I0905 08:20:38.148668 90901 solver.cpp:228] Iteration 37250, loss = 0.287828
I0905 08:20:38.148718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287828 (* 1 = 0.287828 loss)
I0905 08:20:38.148732 90901 sgd_solver.cpp:106] Iteration 37250, lr = 0.1
I0905 08:20:44.310791 90901 solver.cpp:228] Iteration 37260, loss = 0.164953
I0905 08:20:44.310844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164954 (* 1 = 0.164954 loss)
I0905 08:20:44.310858 90901 sgd_solver.cpp:106] Iteration 37260, lr = 0.1
I0905 08:20:50.294880 90901 solver.cpp:228] Iteration 37270, loss = 0.417284
I0905 08:20:50.295112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417284 (* 1 = 0.417284 loss)
I0905 08:20:50.295136 90901 sgd_solver.cpp:106] Iteration 37270, lr = 0.1
I0905 08:20:56.371219 90901 solver.cpp:228] Iteration 37280, loss = 0.202168
I0905 08:20:56.371266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202168 (* 1 = 0.202168 loss)
I0905 08:20:56.371282 90901 sgd_solver.cpp:106] Iteration 37280, lr = 0.1
I0905 08:21:02.431290 90901 solver.cpp:228] Iteration 37290, loss = 0.114759
I0905 08:21:02.431346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114759 (* 1 = 0.114759 loss)
I0905 08:21:02.431360 90901 sgd_solver.cpp:106] Iteration 37290, lr = 0.1
I0905 08:21:08.652436 90901 solver.cpp:228] Iteration 37300, loss = 0.836116
I0905 08:21:08.652499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.836117 (* 1 = 0.836117 loss)
I0905 08:21:08.652520 90901 sgd_solver.cpp:106] Iteration 37300, lr = 0.1
I0905 08:21:13.843526 90901 solver.cpp:228] Iteration 37310, loss = 0.341122
I0905 08:21:13.843577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341122 (* 1 = 0.341122 loss)
I0905 08:21:13.843592 90901 sgd_solver.cpp:106] Iteration 37310, lr = 0.1
I0905 08:21:19.754935 90901 solver.cpp:228] Iteration 37320, loss = 0.329191
I0905 08:21:19.755002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329191 (* 1 = 0.329191 loss)
I0905 08:21:19.755017 90901 sgd_solver.cpp:106] Iteration 37320, lr = 0.1
I0905 08:21:25.805871 90901 solver.cpp:228] Iteration 37330, loss = 0.347884
I0905 08:21:25.806028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347884 (* 1 = 0.347884 loss)
I0905 08:21:25.806066 90901 sgd_solver.cpp:106] Iteration 37330, lr = 0.1
I0905 08:21:31.857254 90901 solver.cpp:228] Iteration 37340, loss = 0.537437
I0905 08:21:31.857316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.537437 (* 1 = 0.537437 loss)
I0905 08:21:31.857331 90901 sgd_solver.cpp:106] Iteration 37340, lr = 0.1
I0905 08:21:37.949404 90901 solver.cpp:228] Iteration 37350, loss = 0.523416
I0905 08:21:37.949460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.523416 (* 1 = 0.523416 loss)
I0905 08:21:37.949476 90901 sgd_solver.cpp:106] Iteration 37350, lr = 0.1
I0905 08:21:44.185730 90901 solver.cpp:228] Iteration 37360, loss = 0.283063
I0905 08:21:44.185791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283063 (* 1 = 0.283063 loss)
I0905 08:21:44.185806 90901 sgd_solver.cpp:106] Iteration 37360, lr = 0.1
I0905 08:21:50.402562 90901 solver.cpp:228] Iteration 37370, loss = 0.193046
I0905 08:21:50.402613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193046 (* 1 = 0.193046 loss)
I0905 08:21:50.402631 90901 sgd_solver.cpp:106] Iteration 37370, lr = 0.1
I0905 08:21:56.499599 90901 solver.cpp:228] Iteration 37380, loss = 0.188472
I0905 08:21:56.499790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188473 (* 1 = 0.188473 loss)
I0905 08:21:56.499819 90901 sgd_solver.cpp:106] Iteration 37380, lr = 0.1
I0905 08:22:02.559936 90901 solver.cpp:228] Iteration 37390, loss = 0.102971
I0905 08:22:02.559988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102972 (* 1 = 0.102972 loss)
I0905 08:22:02.560003 90901 sgd_solver.cpp:106] Iteration 37390, lr = 0.1
I0905 08:22:08.598100 90901 solver.cpp:228] Iteration 37400, loss = 0.370191
I0905 08:22:08.598160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370191 (* 1 = 0.370191 loss)
I0905 08:22:08.598176 90901 sgd_solver.cpp:106] Iteration 37400, lr = 0.1
I0905 08:22:14.780280 90901 solver.cpp:228] Iteration 37410, loss = 0.426323
I0905 08:22:14.780354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426324 (* 1 = 0.426324 loss)
I0905 08:22:14.780369 90901 sgd_solver.cpp:106] Iteration 37410, lr = 0.1
I0905 08:22:21.047636 90901 solver.cpp:228] Iteration 37420, loss = 0.265574
I0905 08:22:21.047708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265575 (* 1 = 0.265575 loss)
I0905 08:22:21.047724 90901 sgd_solver.cpp:106] Iteration 37420, lr = 0.1
I0905 08:22:27.096802 90901 solver.cpp:228] Iteration 37430, loss = 0.453241
I0905 08:22:27.097053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453241 (* 1 = 0.453241 loss)
I0905 08:22:27.097080 90901 sgd_solver.cpp:106] Iteration 37430, lr = 0.1
I0905 08:22:33.144260 90901 solver.cpp:228] Iteration 37440, loss = 0.264993
I0905 08:22:33.144330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264994 (* 1 = 0.264994 loss)
I0905 08:22:33.144346 90901 sgd_solver.cpp:106] Iteration 37440, lr = 0.1
I0905 08:22:39.479756 90901 solver.cpp:228] Iteration 37450, loss = 0.237883
I0905 08:22:39.479820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237883 (* 1 = 0.237883 loss)
I0905 08:22:39.479833 90901 sgd_solver.cpp:106] Iteration 37450, lr = 0.1
I0905 08:22:45.588212 90901 solver.cpp:228] Iteration 37460, loss = 0.4898
I0905 08:22:45.588279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4898 (* 1 = 0.4898 loss)
I0905 08:22:45.588306 90901 sgd_solver.cpp:106] Iteration 37460, lr = 0.1
I0905 08:22:51.677785 90901 solver.cpp:228] Iteration 37470, loss = 0.292289
I0905 08:22:51.677855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292289 (* 1 = 0.292289 loss)
I0905 08:22:51.677870 90901 sgd_solver.cpp:106] Iteration 37470, lr = 0.1
I0905 08:22:57.528615 90901 solver.cpp:228] Iteration 37480, loss = 0.347273
I0905 08:22:57.528726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347274 (* 1 = 0.347274 loss)
I0905 08:22:57.528741 90901 sgd_solver.cpp:106] Iteration 37480, lr = 0.1
I0905 08:23:02.879426 90901 solver.cpp:228] Iteration 37490, loss = 0.250342
I0905 08:23:02.879468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250342 (* 1 = 0.250342 loss)
I0905 08:23:02.879480 90901 sgd_solver.cpp:106] Iteration 37490, lr = 0.1
I0905 08:23:08.486153 90901 solver.cpp:228] Iteration 37500, loss = 0.227724
I0905 08:23:08.486196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227725 (* 1 = 0.227725 loss)
I0905 08:23:08.486210 90901 sgd_solver.cpp:106] Iteration 37500, lr = 0.1
I0905 08:23:14.686626 90901 solver.cpp:228] Iteration 37510, loss = 0.733504
I0905 08:23:14.686703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.733504 (* 1 = 0.733504 loss)
I0905 08:23:14.686719 90901 sgd_solver.cpp:106] Iteration 37510, lr = 0.1
I0905 08:23:20.776525 90901 solver.cpp:228] Iteration 37520, loss = 0.159744
I0905 08:23:20.776584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159744 (* 1 = 0.159744 loss)
I0905 08:23:20.776599 90901 sgd_solver.cpp:106] Iteration 37520, lr = 0.1
I0905 08:23:26.801216 90901 solver.cpp:228] Iteration 37530, loss = 0.267054
I0905 08:23:26.801268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267054 (* 1 = 0.267054 loss)
I0905 08:23:26.801291 90901 sgd_solver.cpp:106] Iteration 37530, lr = 0.1
I0905 08:23:32.863100 90901 solver.cpp:228] Iteration 37540, loss = 0.43361
I0905 08:23:32.863343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433611 (* 1 = 0.433611 loss)
I0905 08:23:32.863361 90901 sgd_solver.cpp:106] Iteration 37540, lr = 0.1
I0905 08:23:38.927058 90901 solver.cpp:228] Iteration 37550, loss = 0.233605
I0905 08:23:38.927146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233606 (* 1 = 0.233606 loss)
I0905 08:23:38.927163 90901 sgd_solver.cpp:106] Iteration 37550, lr = 0.1
I0905 08:23:44.682029 90901 solver.cpp:228] Iteration 37560, loss = 0.264125
I0905 08:23:44.682087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264125 (* 1 = 0.264125 loss)
I0905 08:23:44.682101 90901 sgd_solver.cpp:106] Iteration 37560, lr = 0.1
I0905 08:23:51.085486 90901 solver.cpp:228] Iteration 37570, loss = 0.30539
I0905 08:23:51.085536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305391 (* 1 = 0.305391 loss)
I0905 08:23:51.085549 90901 sgd_solver.cpp:106] Iteration 37570, lr = 0.1
I0905 08:23:57.138764 90901 solver.cpp:228] Iteration 37580, loss = 0.352527
I0905 08:23:57.138855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352528 (* 1 = 0.352528 loss)
I0905 08:23:57.138872 90901 sgd_solver.cpp:106] Iteration 37580, lr = 0.1
I0905 08:24:03.507922 90901 solver.cpp:228] Iteration 37590, loss = 0.136375
I0905 08:24:03.508065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136375 (* 1 = 0.136375 loss)
I0905 08:24:03.508110 90901 sgd_solver.cpp:106] Iteration 37590, lr = 0.1
I0905 08:24:09.361728 90901 solver.cpp:337] Iteration 37600, Testing net (#0)
I0905 08:24:50.989670 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.564375
I0905 08:24:50.989836 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 3.04213 (* 1 = 3.04213 loss)
I0905 08:24:51.415295 90901 solver.cpp:228] Iteration 37600, loss = 0.524472
I0905 08:24:51.415326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.524472 (* 1 = 0.524472 loss)
I0905 08:24:51.415343 90901 sgd_solver.cpp:106] Iteration 37600, lr = 0.1
I0905 08:24:56.779314 90901 solver.cpp:228] Iteration 37610, loss = 0.290936
I0905 08:24:56.779376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290937 (* 1 = 0.290937 loss)
I0905 08:24:56.779391 90901 sgd_solver.cpp:106] Iteration 37610, lr = 0.1
I0905 08:25:03.163378 90901 solver.cpp:228] Iteration 37620, loss = 0.289511
I0905 08:25:03.163434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289511 (* 1 = 0.289511 loss)
I0905 08:25:03.163450 90901 sgd_solver.cpp:106] Iteration 37620, lr = 0.1
I0905 08:25:09.280341 90901 solver.cpp:228] Iteration 37630, loss = 0.0529675
I0905 08:25:09.280402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0529679 (* 1 = 0.0529679 loss)
I0905 08:25:09.280417 90901 sgd_solver.cpp:106] Iteration 37630, lr = 0.1
I0905 08:25:15.508077 90901 solver.cpp:228] Iteration 37640, loss = 0.223357
I0905 08:25:15.508126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223357 (* 1 = 0.223357 loss)
I0905 08:25:15.508141 90901 sgd_solver.cpp:106] Iteration 37640, lr = 0.1
I0905 08:25:21.554103 90901 solver.cpp:228] Iteration 37650, loss = 0.215683
I0905 08:25:21.554266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215684 (* 1 = 0.215684 loss)
I0905 08:25:21.554306 90901 sgd_solver.cpp:106] Iteration 37650, lr = 0.1
I0905 08:25:27.927206 90901 solver.cpp:228] Iteration 37660, loss = 0.41625
I0905 08:25:27.927266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41625 (* 1 = 0.41625 loss)
I0905 08:25:27.927283 90901 sgd_solver.cpp:106] Iteration 37660, lr = 0.1
I0905 08:25:33.648773 90901 solver.cpp:228] Iteration 37670, loss = 0.242268
I0905 08:25:33.648833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242269 (* 1 = 0.242269 loss)
I0905 08:25:33.648849 90901 sgd_solver.cpp:106] Iteration 37670, lr = 0.1
I0905 08:25:40.062875 90901 solver.cpp:228] Iteration 37680, loss = 0.0822964
I0905 08:25:40.062925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0822968 (* 1 = 0.0822968 loss)
I0905 08:25:40.062939 90901 sgd_solver.cpp:106] Iteration 37680, lr = 0.1
I0905 08:25:46.164216 90901 solver.cpp:228] Iteration 37690, loss = 0.273735
I0905 08:25:46.164269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273736 (* 1 = 0.273736 loss)
I0905 08:25:46.164284 90901 sgd_solver.cpp:106] Iteration 37690, lr = 0.1
I0905 08:25:52.206217 90901 solver.cpp:228] Iteration 37700, loss = 0.081305
I0905 08:25:52.206459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0813055 (* 1 = 0.0813055 loss)
I0905 08:25:52.206475 90901 sgd_solver.cpp:106] Iteration 37700, lr = 0.1
I0905 08:25:58.273972 90901 solver.cpp:228] Iteration 37710, loss = 0.449647
I0905 08:25:58.274024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449648 (* 1 = 0.449648 loss)
I0905 08:25:58.274039 90901 sgd_solver.cpp:106] Iteration 37710, lr = 0.1
I0905 08:26:04.338099 90901 solver.cpp:228] Iteration 37720, loss = 0.263941
I0905 08:26:04.338156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263942 (* 1 = 0.263942 loss)
I0905 08:26:04.338171 90901 sgd_solver.cpp:106] Iteration 37720, lr = 0.1
I0905 08:26:10.415204 90901 solver.cpp:228] Iteration 37730, loss = 0.108118
I0905 08:26:10.415268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108119 (* 1 = 0.108119 loss)
I0905 08:26:10.415283 90901 sgd_solver.cpp:106] Iteration 37730, lr = 0.1
I0905 08:26:16.502463 90901 solver.cpp:228] Iteration 37740, loss = 0.642678
I0905 08:26:16.502534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.642678 (* 1 = 0.642678 loss)
I0905 08:26:16.502550 90901 sgd_solver.cpp:106] Iteration 37740, lr = 0.1
I0905 08:26:22.556905 90901 solver.cpp:228] Iteration 37750, loss = 0.24202
I0905 08:26:22.557106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242021 (* 1 = 0.242021 loss)
I0905 08:26:22.557129 90901 sgd_solver.cpp:106] Iteration 37750, lr = 0.1
I0905 08:26:28.830536 90901 solver.cpp:228] Iteration 37760, loss = 0.225966
I0905 08:26:28.830605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225966 (* 1 = 0.225966 loss)
I0905 08:26:28.830620 90901 sgd_solver.cpp:106] Iteration 37760, lr = 0.1
I0905 08:26:34.650902 90901 solver.cpp:228] Iteration 37770, loss = 0.556371
I0905 08:26:34.650974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556372 (* 1 = 0.556372 loss)
I0905 08:26:34.650990 90901 sgd_solver.cpp:106] Iteration 37770, lr = 0.1
I0905 08:26:40.634373 90901 solver.cpp:228] Iteration 37780, loss = 0.153318
I0905 08:26:40.634419 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153318 (* 1 = 0.153318 loss)
I0905 08:26:40.634433 90901 sgd_solver.cpp:106] Iteration 37780, lr = 0.1
I0905 08:26:45.907578 90901 solver.cpp:228] Iteration 37790, loss = 0.429465
I0905 08:26:45.907636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429466 (* 1 = 0.429466 loss)
I0905 08:26:45.907652 90901 sgd_solver.cpp:106] Iteration 37790, lr = 0.1
I0905 08:26:51.636057 90901 solver.cpp:228] Iteration 37800, loss = 0.131135
I0905 08:26:51.636106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131136 (* 1 = 0.131136 loss)
I0905 08:26:51.636122 90901 sgd_solver.cpp:106] Iteration 37800, lr = 0.1
I0905 08:26:56.694236 90901 solver.cpp:228] Iteration 37810, loss = 0.357462
I0905 08:26:56.694414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357462 (* 1 = 0.357462 loss)
I0905 08:26:56.694449 90901 sgd_solver.cpp:106] Iteration 37810, lr = 0.1
I0905 08:27:01.735991 90901 solver.cpp:228] Iteration 37820, loss = 0.235308
I0905 08:27:01.736050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235309 (* 1 = 0.235309 loss)
I0905 08:27:01.736063 90901 sgd_solver.cpp:106] Iteration 37820, lr = 0.1
I0905 08:27:06.777158 90901 solver.cpp:228] Iteration 37830, loss = 0.171485
I0905 08:27:06.777211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171486 (* 1 = 0.171486 loss)
I0905 08:27:06.777221 90901 sgd_solver.cpp:106] Iteration 37830, lr = 0.1
I0905 08:27:11.840045 90901 solver.cpp:228] Iteration 37840, loss = 0.42763
I0905 08:27:11.840112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42763 (* 1 = 0.42763 loss)
I0905 08:27:11.840128 90901 sgd_solver.cpp:106] Iteration 37840, lr = 0.1
I0905 08:27:16.866605 90901 solver.cpp:228] Iteration 37850, loss = 0.380233
I0905 08:27:16.866685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380234 (* 1 = 0.380234 loss)
I0905 08:27:16.866703 90901 sgd_solver.cpp:106] Iteration 37850, lr = 0.1
I0905 08:27:21.889621 90901 solver.cpp:228] Iteration 37860, loss = 0.264937
I0905 08:27:21.889684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264937 (* 1 = 0.264937 loss)
I0905 08:27:21.889698 90901 sgd_solver.cpp:106] Iteration 37860, lr = 0.1
I0905 08:27:26.907464 90901 solver.cpp:228] Iteration 37870, loss = 0.440013
I0905 08:27:26.907781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440014 (* 1 = 0.440014 loss)
I0905 08:27:26.907798 90901 sgd_solver.cpp:106] Iteration 37870, lr = 0.1
I0905 08:27:31.961524 90901 solver.cpp:228] Iteration 37880, loss = 0.216466
I0905 08:27:31.961577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216467 (* 1 = 0.216467 loss)
I0905 08:27:31.961593 90901 sgd_solver.cpp:106] Iteration 37880, lr = 0.1
I0905 08:27:36.978595 90901 solver.cpp:228] Iteration 37890, loss = 0.199525
I0905 08:27:36.978688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199526 (* 1 = 0.199526 loss)
I0905 08:27:36.978704 90901 sgd_solver.cpp:106] Iteration 37890, lr = 0.1
I0905 08:27:41.999002 90901 solver.cpp:228] Iteration 37900, loss = 0.437049
I0905 08:27:41.999071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43705 (* 1 = 0.43705 loss)
I0905 08:27:41.999088 90901 sgd_solver.cpp:106] Iteration 37900, lr = 0.1
I0905 08:27:47.035854 90901 solver.cpp:228] Iteration 37910, loss = 0.337424
I0905 08:27:47.035923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337425 (* 1 = 0.337425 loss)
I0905 08:27:47.035939 90901 sgd_solver.cpp:106] Iteration 37910, lr = 0.1
I0905 08:27:52.087976 90901 solver.cpp:228] Iteration 37920, loss = 0.359431
I0905 08:27:52.088035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359432 (* 1 = 0.359432 loss)
I0905 08:27:52.088049 90901 sgd_solver.cpp:106] Iteration 37920, lr = 0.1
I0905 08:27:57.107166 90901 solver.cpp:228] Iteration 37930, loss = 0.138861
I0905 08:27:57.107362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138862 (* 1 = 0.138862 loss)
I0905 08:27:57.107377 90901 sgd_solver.cpp:106] Iteration 37930, lr = 0.1
I0905 08:28:02.123258 90901 solver.cpp:228] Iteration 37940, loss = 0.28183
I0905 08:28:02.123309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281831 (* 1 = 0.281831 loss)
I0905 08:28:02.123324 90901 sgd_solver.cpp:106] Iteration 37940, lr = 0.1
I0905 08:28:07.179024 90901 solver.cpp:228] Iteration 37950, loss = 0.259476
I0905 08:28:07.179090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259477 (* 1 = 0.259477 loss)
I0905 08:28:07.179108 90901 sgd_solver.cpp:106] Iteration 37950, lr = 0.1
I0905 08:28:12.889421 90901 solver.cpp:228] Iteration 37960, loss = 0.330039
I0905 08:28:12.889483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33004 (* 1 = 0.33004 loss)
I0905 08:28:12.889498 90901 sgd_solver.cpp:106] Iteration 37960, lr = 0.1
I0905 08:28:18.914768 90901 solver.cpp:228] Iteration 37970, loss = 0.33657
I0905 08:28:18.914839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336571 (* 1 = 0.336571 loss)
I0905 08:28:18.914855 90901 sgd_solver.cpp:106] Iteration 37970, lr = 0.1
I0905 08:28:24.982785 90901 solver.cpp:228] Iteration 37980, loss = 0.557742
I0905 08:28:24.982826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.557743 (* 1 = 0.557743 loss)
I0905 08:28:24.982841 90901 sgd_solver.cpp:106] Iteration 37980, lr = 0.1
I0905 08:28:31.037374 90901 solver.cpp:228] Iteration 37990, loss = 0.138844
I0905 08:28:31.037534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138845 (* 1 = 0.138845 loss)
I0905 08:28:31.037572 90901 sgd_solver.cpp:106] Iteration 37990, lr = 0.1
I0905 08:28:36.606508 90901 solver.cpp:228] Iteration 38000, loss = 0.107058
I0905 08:28:36.606572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107059 (* 1 = 0.107059 loss)
I0905 08:28:36.606586 90901 sgd_solver.cpp:106] Iteration 38000, lr = 0.1
I0905 08:28:41.995669 90901 solver.cpp:228] Iteration 38010, loss = 0.464152
I0905 08:28:41.995733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464153 (* 1 = 0.464153 loss)
I0905 08:28:41.995746 90901 sgd_solver.cpp:106] Iteration 38010, lr = 0.1
I0905 08:28:48.091495 90901 solver.cpp:228] Iteration 38020, loss = 0.324396
I0905 08:28:48.091548 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324396 (* 1 = 0.324396 loss)
I0905 08:28:48.091562 90901 sgd_solver.cpp:106] Iteration 38020, lr = 0.1
I0905 08:28:54.159818 90901 solver.cpp:228] Iteration 38030, loss = 0.281203
I0905 08:28:54.159888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281204 (* 1 = 0.281204 loss)
I0905 08:28:54.159910 90901 sgd_solver.cpp:106] Iteration 38030, lr = 0.1
I0905 08:29:00.560185 90901 solver.cpp:228] Iteration 38040, loss = 0.556135
I0905 08:29:00.560248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556136 (* 1 = 0.556136 loss)
I0905 08:29:00.560264 90901 sgd_solver.cpp:106] Iteration 38040, lr = 0.1
I0905 08:29:06.639130 90901 solver.cpp:228] Iteration 38050, loss = 0.248044
I0905 08:29:06.639384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248045 (* 1 = 0.248045 loss)
I0905 08:29:06.639401 90901 sgd_solver.cpp:106] Iteration 38050, lr = 0.1
I0905 08:29:12.564060 90901 solver.cpp:228] Iteration 38060, loss = 0.376328
I0905 08:29:12.564121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376328 (* 1 = 0.376328 loss)
I0905 08:29:12.564136 90901 sgd_solver.cpp:106] Iteration 38060, lr = 0.1
I0905 08:29:18.522303 90901 solver.cpp:228] Iteration 38070, loss = 0.07924
I0905 08:29:18.522367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0792406 (* 1 = 0.0792406 loss)
I0905 08:29:18.522382 90901 sgd_solver.cpp:106] Iteration 38070, lr = 0.1
I0905 08:29:24.963055 90901 solver.cpp:228] Iteration 38080, loss = 0.0708025
I0905 08:29:24.963129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0708031 (* 1 = 0.0708031 loss)
I0905 08:29:24.963143 90901 sgd_solver.cpp:106] Iteration 38080, lr = 0.1
I0905 08:29:30.731036 90901 solver.cpp:228] Iteration 38090, loss = 0.301971
I0905 08:29:30.731117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301971 (* 1 = 0.301971 loss)
I0905 08:29:30.731132 90901 sgd_solver.cpp:106] Iteration 38090, lr = 0.1
I0905 08:29:36.816747 90901 solver.cpp:228] Iteration 38100, loss = 0.169647
I0905 08:29:36.816982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169648 (* 1 = 0.169648 loss)
I0905 08:29:36.817003 90901 sgd_solver.cpp:106] Iteration 38100, lr = 0.1
I0905 08:29:43.210829 90901 solver.cpp:228] Iteration 38110, loss = 0.494556
I0905 08:29:43.210887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.494557 (* 1 = 0.494557 loss)
I0905 08:29:43.210901 90901 sgd_solver.cpp:106] Iteration 38110, lr = 0.1
I0905 08:29:49.555809 90901 solver.cpp:228] Iteration 38120, loss = 0.339641
I0905 08:29:49.555872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339642 (* 1 = 0.339642 loss)
I0905 08:29:49.555888 90901 sgd_solver.cpp:106] Iteration 38120, lr = 0.1
I0905 08:29:55.603430 90901 solver.cpp:228] Iteration 38130, loss = 0.205723
I0905 08:29:55.603485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205723 (* 1 = 0.205723 loss)
I0905 08:29:55.603498 90901 sgd_solver.cpp:106] Iteration 38130, lr = 0.1
I0905 08:30:01.743613 90901 solver.cpp:228] Iteration 38140, loss = 0.262517
I0905 08:30:01.743671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262518 (* 1 = 0.262518 loss)
I0905 08:30:01.743687 90901 sgd_solver.cpp:106] Iteration 38140, lr = 0.1
I0905 08:30:07.852190 90901 solver.cpp:228] Iteration 38150, loss = 0.199624
I0905 08:30:07.852413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199624 (* 1 = 0.199624 loss)
I0905 08:30:07.852460 90901 sgd_solver.cpp:106] Iteration 38150, lr = 0.1
I0905 08:30:13.916466 90901 solver.cpp:228] Iteration 38160, loss = 0.136084
I0905 08:30:13.916539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136084 (* 1 = 0.136084 loss)
I0905 08:30:13.916561 90901 sgd_solver.cpp:106] Iteration 38160, lr = 0.1
I0905 08:30:19.678814 90901 solver.cpp:228] Iteration 38170, loss = 0.169116
I0905 08:30:19.678859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169117 (* 1 = 0.169117 loss)
I0905 08:30:19.678875 90901 sgd_solver.cpp:106] Iteration 38170, lr = 0.1
I0905 08:30:25.249891 90901 solver.cpp:228] Iteration 38180, loss = 0.206115
I0905 08:30:25.249936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206115 (* 1 = 0.206115 loss)
I0905 08:30:25.249949 90901 sgd_solver.cpp:106] Iteration 38180, lr = 0.1
I0905 08:30:30.959060 90901 solver.cpp:228] Iteration 38190, loss = 0.259822
I0905 08:30:30.959123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259822 (* 1 = 0.259822 loss)
I0905 08:30:30.959139 90901 sgd_solver.cpp:106] Iteration 38190, lr = 0.1
I0905 08:30:37.057289 90901 solver.cpp:228] Iteration 38200, loss = 0.539451
I0905 08:30:37.057353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.539452 (* 1 = 0.539452 loss)
I0905 08:30:37.057368 90901 sgd_solver.cpp:106] Iteration 38200, lr = 0.1
I0905 08:30:42.808010 90901 solver.cpp:228] Iteration 38210, loss = 0.210596
I0905 08:30:42.808179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210597 (* 1 = 0.210597 loss)
I0905 08:30:42.808220 90901 sgd_solver.cpp:106] Iteration 38210, lr = 0.1
I0905 08:30:48.880650 90901 solver.cpp:228] Iteration 38220, loss = 0.144917
I0905 08:30:48.880704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144918 (* 1 = 0.144918 loss)
I0905 08:30:48.880722 90901 sgd_solver.cpp:106] Iteration 38220, lr = 0.1
I0905 08:30:55.241729 90901 solver.cpp:228] Iteration 38230, loss = 0.468883
I0905 08:30:55.241794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468884 (* 1 = 0.468884 loss)
I0905 08:30:55.241808 90901 sgd_solver.cpp:106] Iteration 38230, lr = 0.1
I0905 08:31:01.348989 90901 solver.cpp:228] Iteration 38240, loss = 0.178425
I0905 08:31:01.349048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178426 (* 1 = 0.178426 loss)
I0905 08:31:01.349063 90901 sgd_solver.cpp:106] Iteration 38240, lr = 0.1
I0905 08:31:07.451171 90901 solver.cpp:228] Iteration 38250, loss = 0.283052
I0905 08:31:07.451220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283053 (* 1 = 0.283053 loss)
I0905 08:31:07.451233 90901 sgd_solver.cpp:106] Iteration 38250, lr = 0.1
I0905 08:31:13.683094 90901 solver.cpp:228] Iteration 38260, loss = 0.366907
I0905 08:31:13.683321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366907 (* 1 = 0.366907 loss)
I0905 08:31:13.683343 90901 sgd_solver.cpp:106] Iteration 38260, lr = 0.1
I0905 08:31:19.602334 90901 solver.cpp:228] Iteration 38270, loss = 0.276449
I0905 08:31:19.602391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276449 (* 1 = 0.276449 loss)
I0905 08:31:19.602416 90901 sgd_solver.cpp:106] Iteration 38270, lr = 0.1
I0905 08:31:26.002921 90901 solver.cpp:228] Iteration 38280, loss = 0.312092
I0905 08:31:26.002990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312093 (* 1 = 0.312093 loss)
I0905 08:31:26.003005 90901 sgd_solver.cpp:106] Iteration 38280, lr = 0.1
I0905 08:31:32.104195 90901 solver.cpp:228] Iteration 38290, loss = 0.114171
I0905 08:31:32.104249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114172 (* 1 = 0.114172 loss)
I0905 08:31:32.104264 90901 sgd_solver.cpp:106] Iteration 38290, lr = 0.1
I0905 08:31:38.166736 90901 solver.cpp:228] Iteration 38300, loss = 0.107894
I0905 08:31:38.166790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107895 (* 1 = 0.107895 loss)
I0905 08:31:38.166803 90901 sgd_solver.cpp:106] Iteration 38300, lr = 0.1
I0905 08:31:44.233590 90901 solver.cpp:228] Iteration 38310, loss = 0.401807
I0905 08:31:44.233849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401807 (* 1 = 0.401807 loss)
I0905 08:31:44.233863 90901 sgd_solver.cpp:106] Iteration 38310, lr = 0.1
I0905 08:31:50.351972 90901 solver.cpp:228] Iteration 38320, loss = 0.24673
I0905 08:31:50.352015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24673 (* 1 = 0.24673 loss)
I0905 08:31:50.352030 90901 sgd_solver.cpp:106] Iteration 38320, lr = 0.1
I0905 08:31:56.465891 90901 solver.cpp:228] Iteration 38330, loss = 0.281788
I0905 08:31:56.465940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281788 (* 1 = 0.281788 loss)
I0905 08:31:56.465955 90901 sgd_solver.cpp:106] Iteration 38330, lr = 0.1
I0905 08:32:02.473500 90901 solver.cpp:228] Iteration 38340, loss = 0.373538
I0905 08:32:02.473562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373538 (* 1 = 0.373538 loss)
I0905 08:32:02.473582 90901 sgd_solver.cpp:106] Iteration 38340, lr = 0.1
I0905 08:32:07.725862 90901 solver.cpp:228] Iteration 38350, loss = 0.143798
I0905 08:32:07.725909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143799 (* 1 = 0.143799 loss)
I0905 08:32:07.725921 90901 sgd_solver.cpp:106] Iteration 38350, lr = 0.1
I0905 08:32:13.473568 90901 solver.cpp:228] Iteration 38360, loss = 0.258581
I0905 08:32:13.473620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258581 (* 1 = 0.258581 loss)
I0905 08:32:13.473636 90901 sgd_solver.cpp:106] Iteration 38360, lr = 0.1
I0905 08:32:19.536620 90901 solver.cpp:228] Iteration 38370, loss = 0.22216
I0905 08:32:19.536804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22216 (* 1 = 0.22216 loss)
I0905 08:32:19.536841 90901 sgd_solver.cpp:106] Iteration 38370, lr = 0.1
I0905 08:32:25.604871 90901 solver.cpp:228] Iteration 38380, loss = 0.414171
I0905 08:32:25.604926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414171 (* 1 = 0.414171 loss)
I0905 08:32:25.604941 90901 sgd_solver.cpp:106] Iteration 38380, lr = 0.1
I0905 08:32:31.692221 90901 solver.cpp:228] Iteration 38390, loss = 0.391102
I0905 08:32:31.692275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391102 (* 1 = 0.391102 loss)
I0905 08:32:31.692289 90901 sgd_solver.cpp:106] Iteration 38390, lr = 0.1
I0905 08:32:37.854351 90901 solver.cpp:337] Iteration 38400, Testing net (#0)
I0905 08:33:20.052317 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.843125
I0905 08:33:20.052513 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.365617 (* 1 = 0.365617 loss)
I0905 08:33:20.270395 90901 solver.cpp:228] Iteration 38400, loss = 0.213953
I0905 08:33:20.270452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213954 (* 1 = 0.213954 loss)
I0905 08:33:20.270469 90901 sgd_solver.cpp:106] Iteration 38400, lr = 0.1
I0905 08:33:26.546094 90901 solver.cpp:228] Iteration 38410, loss = 0.322919
I0905 08:33:26.546154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322919 (* 1 = 0.322919 loss)
I0905 08:33:26.546167 90901 sgd_solver.cpp:106] Iteration 38410, lr = 0.1
I0905 08:33:32.784404 90901 solver.cpp:228] Iteration 38420, loss = 0.231979
I0905 08:33:32.784458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23198 (* 1 = 0.23198 loss)
I0905 08:33:32.784473 90901 sgd_solver.cpp:106] Iteration 38420, lr = 0.1
I0905 08:33:38.539129 90901 solver.cpp:228] Iteration 38430, loss = 0.235649
I0905 08:33:38.539180 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235649 (* 1 = 0.235649 loss)
I0905 08:33:38.539193 90901 sgd_solver.cpp:106] Iteration 38430, lr = 0.1
I0905 08:33:44.648627 90901 solver.cpp:228] Iteration 38440, loss = 0.228842
I0905 08:33:44.648666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228842 (* 1 = 0.228842 loss)
I0905 08:33:44.648679 90901 sgd_solver.cpp:106] Iteration 38440, lr = 0.1
I0905 08:33:50.499697 90901 solver.cpp:228] Iteration 38450, loss = 0.80793
I0905 08:33:50.499968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.80793 (* 1 = 0.80793 loss)
I0905 08:33:50.499989 90901 sgd_solver.cpp:106] Iteration 38450, lr = 0.1
I0905 08:33:56.074945 90901 solver.cpp:228] Iteration 38460, loss = 0.353761
I0905 08:33:56.074990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353761 (* 1 = 0.353761 loss)
I0905 08:33:56.075006 90901 sgd_solver.cpp:106] Iteration 38460, lr = 0.1
I0905 08:34:01.566848 90901 solver.cpp:228] Iteration 38470, loss = 0.429018
I0905 08:34:01.566890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429018 (* 1 = 0.429018 loss)
I0905 08:34:01.566905 90901 sgd_solver.cpp:106] Iteration 38470, lr = 0.1
I0905 08:34:07.641952 90901 solver.cpp:228] Iteration 38480, loss = 0.483182
I0905 08:34:07.642009 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.483182 (* 1 = 0.483182 loss)
I0905 08:34:07.642024 90901 sgd_solver.cpp:106] Iteration 38480, lr = 0.1
I0905 08:34:13.390915 90901 solver.cpp:228] Iteration 38490, loss = 0.330088
I0905 08:34:13.390974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330088 (* 1 = 0.330088 loss)
I0905 08:34:13.390988 90901 sgd_solver.cpp:106] Iteration 38490, lr = 0.1
I0905 08:34:19.770177 90901 solver.cpp:228] Iteration 38500, loss = 0.392658
I0905 08:34:19.770246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392658 (* 1 = 0.392658 loss)
I0905 08:34:19.770261 90901 sgd_solver.cpp:106] Iteration 38500, lr = 0.1
I0905 08:34:25.861407 90901 solver.cpp:228] Iteration 38510, loss = 0.318985
I0905 08:34:25.861618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318985 (* 1 = 0.318985 loss)
I0905 08:34:25.861634 90901 sgd_solver.cpp:106] Iteration 38510, lr = 0.1
I0905 08:34:31.969589 90901 solver.cpp:228] Iteration 38520, loss = 0.743479
I0905 08:34:31.969637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.74348 (* 1 = 0.74348 loss)
I0905 08:34:31.969652 90901 sgd_solver.cpp:106] Iteration 38520, lr = 0.1
I0905 08:34:37.730352 90901 solver.cpp:228] Iteration 38530, loss = 0.100857
I0905 08:34:37.730403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100858 (* 1 = 0.100858 loss)
I0905 08:34:37.730417 90901 sgd_solver.cpp:106] Iteration 38530, lr = 0.1
I0905 08:34:44.152359 90901 solver.cpp:228] Iteration 38540, loss = 0.163562
I0905 08:34:44.152400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163562 (* 1 = 0.163562 loss)
I0905 08:34:44.152411 90901 sgd_solver.cpp:106] Iteration 38540, lr = 0.1
I0905 08:34:50.306342 90901 solver.cpp:228] Iteration 38550, loss = 0.234546
I0905 08:34:50.306391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234546 (* 1 = 0.234546 loss)
I0905 08:34:50.306406 90901 sgd_solver.cpp:106] Iteration 38550, lr = 0.1
I0905 08:34:56.002882 90901 solver.cpp:228] Iteration 38560, loss = 0.358033
I0905 08:34:56.003041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358033 (* 1 = 0.358033 loss)
I0905 08:34:56.003099 90901 sgd_solver.cpp:106] Iteration 38560, lr = 0.1
I0905 08:35:02.704226 90901 solver.cpp:228] Iteration 38570, loss = 0.206083
I0905 08:35:02.704274 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206083 (* 1 = 0.206083 loss)
I0905 08:35:02.704289 90901 sgd_solver.cpp:106] Iteration 38570, lr = 0.1
I0905 08:35:08.814514 90901 solver.cpp:228] Iteration 38580, loss = 0.27796
I0905 08:35:08.814586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277961 (* 1 = 0.277961 loss)
I0905 08:35:08.814602 90901 sgd_solver.cpp:106] Iteration 38580, lr = 0.1
I0905 08:35:14.923331 90901 solver.cpp:228] Iteration 38590, loss = 0.234068
I0905 08:35:14.923404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234068 (* 1 = 0.234068 loss)
I0905 08:35:14.923420 90901 sgd_solver.cpp:106] Iteration 38590, lr = 0.1
I0905 08:35:20.975416 90901 solver.cpp:228] Iteration 38600, loss = 0.241943
I0905 08:35:20.975472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241944 (* 1 = 0.241944 loss)
I0905 08:35:20.975486 90901 sgd_solver.cpp:106] Iteration 38600, lr = 0.1
I0905 08:35:27.044363 90901 solver.cpp:228] Iteration 38610, loss = 0.23735
I0905 08:35:27.044606 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23735 (* 1 = 0.23735 loss)
I0905 08:35:27.044625 90901 sgd_solver.cpp:106] Iteration 38610, lr = 0.1
I0905 08:35:33.097807 90901 solver.cpp:228] Iteration 38620, loss = 0.308095
I0905 08:35:33.097852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308096 (* 1 = 0.308096 loss)
I0905 08:35:33.097867 90901 sgd_solver.cpp:106] Iteration 38620, lr = 0.1
I0905 08:35:38.905766 90901 solver.cpp:228] Iteration 38630, loss = 0.181277
I0905 08:35:38.905817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181277 (* 1 = 0.181277 loss)
I0905 08:35:38.905829 90901 sgd_solver.cpp:106] Iteration 38630, lr = 0.1
I0905 08:35:44.208892 90901 solver.cpp:228] Iteration 38640, loss = 0.179464
I0905 08:35:44.208942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179464 (* 1 = 0.179464 loss)
I0905 08:35:44.208957 90901 sgd_solver.cpp:106] Iteration 38640, lr = 0.1
I0905 08:35:50.120268 90901 solver.cpp:228] Iteration 38650, loss = 0.137489
I0905 08:35:50.120333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13749 (* 1 = 0.13749 loss)
I0905 08:35:50.120350 90901 sgd_solver.cpp:106] Iteration 38650, lr = 0.1
I0905 08:35:56.500855 90901 solver.cpp:228] Iteration 38660, loss = 0.252053
I0905 08:35:56.500921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252053 (* 1 = 0.252053 loss)
I0905 08:35:56.500936 90901 sgd_solver.cpp:106] Iteration 38660, lr = 0.1
I0905 08:36:02.370812 90901 solver.cpp:228] Iteration 38670, loss = 0.271319
I0905 08:36:02.371055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271319 (* 1 = 0.271319 loss)
I0905 08:36:02.371073 90901 sgd_solver.cpp:106] Iteration 38670, lr = 0.1
I0905 08:36:08.613832 90901 solver.cpp:228] Iteration 38680, loss = 0.211628
I0905 08:36:08.613878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211628 (* 1 = 0.211628 loss)
I0905 08:36:08.613893 90901 sgd_solver.cpp:106] Iteration 38680, lr = 0.1
I0905 08:36:14.656262 90901 solver.cpp:228] Iteration 38690, loss = 0.227194
I0905 08:36:14.656328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227194 (* 1 = 0.227194 loss)
I0905 08:36:14.656343 90901 sgd_solver.cpp:106] Iteration 38690, lr = 0.1
I0905 08:36:20.754762 90901 solver.cpp:228] Iteration 38700, loss = 0.167309
I0905 08:36:20.754825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16731 (* 1 = 0.16731 loss)
I0905 08:36:20.754840 90901 sgd_solver.cpp:106] Iteration 38700, lr = 0.1
I0905 08:36:26.787729 90901 solver.cpp:228] Iteration 38710, loss = 0.85064
I0905 08:36:26.787780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.85064 (* 1 = 0.85064 loss)
I0905 08:36:26.787792 90901 sgd_solver.cpp:106] Iteration 38710, lr = 0.1
I0905 08:36:32.878686 90901 solver.cpp:228] Iteration 38720, loss = 0.120831
I0905 08:36:32.878859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120832 (* 1 = 0.120832 loss)
I0905 08:36:32.878909 90901 sgd_solver.cpp:106] Iteration 38720, lr = 0.1
I0905 08:36:38.617312 90901 solver.cpp:228] Iteration 38730, loss = 0.114287
I0905 08:36:38.617394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114287 (* 1 = 0.114287 loss)
I0905 08:36:38.617414 90901 sgd_solver.cpp:106] Iteration 38730, lr = 0.1
I0905 08:36:45.176476 90901 solver.cpp:228] Iteration 38740, loss = 0.188601
I0905 08:36:45.176522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188602 (* 1 = 0.188602 loss)
I0905 08:36:45.176533 90901 sgd_solver.cpp:106] Iteration 38740, lr = 0.1
I0905 08:36:51.343418 90901 solver.cpp:228] Iteration 38750, loss = 0.346532
I0905 08:36:51.343461 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346532 (* 1 = 0.346532 loss)
I0905 08:36:51.343475 90901 sgd_solver.cpp:106] Iteration 38750, lr = 0.1
I0905 08:36:57.465423 90901 solver.cpp:228] Iteration 38760, loss = 0.196897
I0905 08:36:57.465484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196898 (* 1 = 0.196898 loss)
I0905 08:36:57.465502 90901 sgd_solver.cpp:106] Iteration 38760, lr = 0.1
I0905 08:37:03.475611 90901 solver.cpp:228] Iteration 38770, loss = 0.378938
I0905 08:37:03.475930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378938 (* 1 = 0.378938 loss)
I0905 08:37:03.475945 90901 sgd_solver.cpp:106] Iteration 38770, lr = 0.1
I0905 08:37:09.870241 90901 solver.cpp:228] Iteration 38780, loss = 0.238454
I0905 08:37:09.870298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238454 (* 1 = 0.238454 loss)
I0905 08:37:09.870314 90901 sgd_solver.cpp:106] Iteration 38780, lr = 0.1
I0905 08:37:15.908838 90901 solver.cpp:228] Iteration 38790, loss = 0.465893
I0905 08:37:15.908902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465893 (* 1 = 0.465893 loss)
I0905 08:37:15.908917 90901 sgd_solver.cpp:106] Iteration 38790, lr = 0.1
I0905 08:37:22.030452 90901 solver.cpp:228] Iteration 38800, loss = 0.321278
I0905 08:37:22.030510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321279 (* 1 = 0.321279 loss)
I0905 08:37:22.030529 90901 sgd_solver.cpp:106] Iteration 38800, lr = 0.1
I0905 08:37:27.820669 90901 solver.cpp:228] Iteration 38810, loss = 0.276823
I0905 08:37:27.820711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276824 (* 1 = 0.276824 loss)
I0905 08:37:27.820724 90901 sgd_solver.cpp:106] Iteration 38810, lr = 0.1
I0905 08:37:33.066664 90901 solver.cpp:228] Iteration 38820, loss = 0.486489
I0905 08:37:33.066715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.48649 (* 1 = 0.48649 loss)
I0905 08:37:33.066732 90901 sgd_solver.cpp:106] Iteration 38820, lr = 0.1
I0905 08:37:38.731492 90901 solver.cpp:228] Iteration 38830, loss = 0.217915
I0905 08:37:38.731729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217915 (* 1 = 0.217915 loss)
I0905 08:37:38.731757 90901 sgd_solver.cpp:106] Iteration 38830, lr = 0.1
I0905 08:37:44.859148 90901 solver.cpp:228] Iteration 38840, loss = 0.209989
I0905 08:37:44.859212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209989 (* 1 = 0.209989 loss)
I0905 08:37:44.859227 90901 sgd_solver.cpp:106] Iteration 38840, lr = 0.1
I0905 08:37:51.004739 90901 solver.cpp:228] Iteration 38850, loss = 0.353817
I0905 08:37:51.004809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353817 (* 1 = 0.353817 loss)
I0905 08:37:51.004823 90901 sgd_solver.cpp:106] Iteration 38850, lr = 0.1
I0905 08:37:57.065572 90901 solver.cpp:228] Iteration 38860, loss = 0.145455
I0905 08:37:57.065629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145455 (* 1 = 0.145455 loss)
I0905 08:37:57.065644 90901 sgd_solver.cpp:106] Iteration 38860, lr = 0.1
I0905 08:38:03.227529 90901 solver.cpp:228] Iteration 38870, loss = 0.143281
I0905 08:38:03.227581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143281 (* 1 = 0.143281 loss)
I0905 08:38:03.227596 90901 sgd_solver.cpp:106] Iteration 38870, lr = 0.1
I0905 08:38:09.537288 90901 solver.cpp:228] Iteration 38880, loss = 0.0819793
I0905 08:38:09.537529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0819796 (* 1 = 0.0819796 loss)
I0905 08:38:09.537549 90901 sgd_solver.cpp:106] Iteration 38880, lr = 0.1
I0905 08:38:15.818770 90901 solver.cpp:228] Iteration 38890, loss = 0.514814
I0905 08:38:15.818832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514814 (* 1 = 0.514814 loss)
I0905 08:38:15.818850 90901 sgd_solver.cpp:106] Iteration 38890, lr = 0.1
I0905 08:38:21.610790 90901 solver.cpp:228] Iteration 38900, loss = 0.191233
I0905 08:38:21.610872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191233 (* 1 = 0.191233 loss)
I0905 08:38:21.610888 90901 sgd_solver.cpp:106] Iteration 38900, lr = 0.1
I0905 08:38:28.037509 90901 solver.cpp:228] Iteration 38910, loss = 0.280973
I0905 08:38:28.037559 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280973 (* 1 = 0.280973 loss)
I0905 08:38:28.037575 90901 sgd_solver.cpp:106] Iteration 38910, lr = 0.1
I0905 08:38:34.114377 90901 solver.cpp:228] Iteration 38920, loss = 0.205487
I0905 08:38:34.114444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205488 (* 1 = 0.205488 loss)
I0905 08:38:34.114461 90901 sgd_solver.cpp:106] Iteration 38920, lr = 0.1
I0905 08:38:40.201052 90901 solver.cpp:228] Iteration 38930, loss = 0.210278
I0905 08:38:40.201263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210278 (* 1 = 0.210278 loss)
I0905 08:38:40.201293 90901 sgd_solver.cpp:106] Iteration 38930, lr = 0.1
I0905 08:38:46.280572 90901 solver.cpp:228] Iteration 38940, loss = 0.203521
I0905 08:38:46.280643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203521 (* 1 = 0.203521 loss)
I0905 08:38:46.280658 90901 sgd_solver.cpp:106] Iteration 38940, lr = 0.1
I0905 08:38:52.351063 90901 solver.cpp:228] Iteration 38950, loss = 0.388464
I0905 08:38:52.351135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388465 (* 1 = 0.388465 loss)
I0905 08:38:52.351150 90901 sgd_solver.cpp:106] Iteration 38950, lr = 0.1
I0905 08:38:58.500778 90901 solver.cpp:228] Iteration 38960, loss = 0.32769
I0905 08:38:58.500835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327691 (* 1 = 0.327691 loss)
I0905 08:38:58.500852 90901 sgd_solver.cpp:106] Iteration 38960, lr = 0.1
I0905 08:39:04.586447 90901 solver.cpp:228] Iteration 38970, loss = 0.449906
I0905 08:39:04.586520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449907 (* 1 = 0.449907 loss)
I0905 08:39:04.586536 90901 sgd_solver.cpp:106] Iteration 38970, lr = 0.1
I0905 08:39:10.597849 90901 solver.cpp:228] Iteration 38980, loss = 0.0758351
I0905 08:39:10.598031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0758356 (* 1 = 0.0758356 loss)
I0905 08:39:10.598050 90901 sgd_solver.cpp:106] Iteration 38980, lr = 0.1
I0905 08:39:15.858638 90901 solver.cpp:228] Iteration 38990, loss = 0.690923
I0905 08:39:15.858696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.690924 (* 1 = 0.690924 loss)
I0905 08:39:15.858711 90901 sgd_solver.cpp:106] Iteration 38990, lr = 0.1
I0905 08:39:21.367327 90901 solver.cpp:228] Iteration 39000, loss = 0.425131
I0905 08:39:21.367383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425131 (* 1 = 0.425131 loss)
I0905 08:39:21.367398 90901 sgd_solver.cpp:106] Iteration 39000, lr = 0.1
I0905 08:39:27.779857 90901 solver.cpp:228] Iteration 39010, loss = 0.20394
I0905 08:39:27.779912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203941 (* 1 = 0.203941 loss)
I0905 08:39:27.779927 90901 sgd_solver.cpp:106] Iteration 39010, lr = 0.1
I0905 08:39:33.878775 90901 solver.cpp:228] Iteration 39020, loss = 0.316172
I0905 08:39:33.878834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316173 (* 1 = 0.316173 loss)
I0905 08:39:33.878850 90901 sgd_solver.cpp:106] Iteration 39020, lr = 0.1
I0905 08:39:39.931514 90901 solver.cpp:228] Iteration 39030, loss = 0.180295
I0905 08:39:39.931560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180296 (* 1 = 0.180296 loss)
I0905 08:39:39.931573 90901 sgd_solver.cpp:106] Iteration 39030, lr = 0.1
I0905 08:39:46.372323 90901 solver.cpp:228] Iteration 39040, loss = 0.345307
I0905 08:39:46.372573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345308 (* 1 = 0.345308 loss)
I0905 08:39:46.372588 90901 sgd_solver.cpp:106] Iteration 39040, lr = 0.1
I0905 08:39:52.423388 90901 solver.cpp:228] Iteration 39050, loss = 0.228083
I0905 08:39:52.423424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228084 (* 1 = 0.228084 loss)
I0905 08:39:52.423435 90901 sgd_solver.cpp:106] Iteration 39050, lr = 0.1
I0905 08:39:58.497692 90901 solver.cpp:228] Iteration 39060, loss = 0.477587
I0905 08:39:58.497761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477588 (* 1 = 0.477588 loss)
I0905 08:39:58.497777 90901 sgd_solver.cpp:106] Iteration 39060, lr = 0.1
I0905 08:40:04.622299 90901 solver.cpp:228] Iteration 39070, loss = 0.412299
I0905 08:40:04.622364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4123 (* 1 = 0.4123 loss)
I0905 08:40:04.622380 90901 sgd_solver.cpp:106] Iteration 39070, lr = 0.1
I0905 08:40:10.732800 90901 solver.cpp:228] Iteration 39080, loss = 0.400813
I0905 08:40:10.732849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400814 (* 1 = 0.400814 loss)
I0905 08:40:10.732863 90901 sgd_solver.cpp:106] Iteration 39080, lr = 0.1
I0905 08:40:16.488873 90901 solver.cpp:228] Iteration 39090, loss = 0.159114
I0905 08:40:16.489049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159114 (* 1 = 0.159114 loss)
I0905 08:40:16.489094 90901 sgd_solver.cpp:106] Iteration 39090, lr = 0.1
I0905 08:40:22.889605 90901 solver.cpp:228] Iteration 39100, loss = 0.297082
I0905 08:40:22.889667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297083 (* 1 = 0.297083 loss)
I0905 08:40:22.889683 90901 sgd_solver.cpp:106] Iteration 39100, lr = 0.1
I0905 08:40:28.988021 90901 solver.cpp:228] Iteration 39110, loss = 0.302132
I0905 08:40:28.988068 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302132 (* 1 = 0.302132 loss)
I0905 08:40:28.988081 90901 sgd_solver.cpp:106] Iteration 39110, lr = 0.1
I0905 08:40:35.067665 90901 solver.cpp:228] Iteration 39120, loss = 0.331568
I0905 08:40:35.067716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331569 (* 1 = 0.331569 loss)
I0905 08:40:35.067731 90901 sgd_solver.cpp:106] Iteration 39120, lr = 0.1
I0905 08:40:41.444295 90901 solver.cpp:228] Iteration 39130, loss = 0.21802
I0905 08:40:41.444334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21802 (* 1 = 0.21802 loss)
I0905 08:40:41.444347 90901 sgd_solver.cpp:106] Iteration 39130, lr = 0.1
I0905 08:40:47.507524 90901 solver.cpp:228] Iteration 39140, loss = 0.567859
I0905 08:40:47.507688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.567859 (* 1 = 0.567859 loss)
I0905 08:40:47.507733 90901 sgd_solver.cpp:106] Iteration 39140, lr = 0.1
I0905 08:40:53.584174 90901 solver.cpp:228] Iteration 39150, loss = 0.231214
I0905 08:40:53.584239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231215 (* 1 = 0.231215 loss)
I0905 08:40:53.584254 90901 sgd_solver.cpp:106] Iteration 39150, lr = 0.1
I0905 08:40:59.280846 90901 solver.cpp:228] Iteration 39160, loss = 0.125922
I0905 08:40:59.280903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125923 (* 1 = 0.125923 loss)
I0905 08:40:59.280921 90901 sgd_solver.cpp:106] Iteration 39160, lr = 0.1
I0905 08:41:04.455430 90901 solver.cpp:228] Iteration 39170, loss = 0.181045
I0905 08:41:04.455505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181045 (* 1 = 0.181045 loss)
I0905 08:41:04.455536 90901 sgd_solver.cpp:106] Iteration 39170, lr = 0.1
I0905 08:41:10.408435 90901 solver.cpp:228] Iteration 39180, loss = 0.156177
I0905 08:41:10.408478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156177 (* 1 = 0.156177 loss)
I0905 08:41:10.408501 90901 sgd_solver.cpp:106] Iteration 39180, lr = 0.1
I0905 08:41:16.719446 90901 solver.cpp:228] Iteration 39190, loss = 0.117501
I0905 08:41:16.719494 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117501 (* 1 = 0.117501 loss)
I0905 08:41:16.719509 90901 sgd_solver.cpp:106] Iteration 39190, lr = 0.1
I0905 08:41:22.644839 90901 solver.cpp:337] Iteration 39200, Testing net (#0)
I0905 08:42:05.068248 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.752813
I0905 08:42:05.068413 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.523655 (* 1 = 0.523655 loss)
I0905 08:42:05.285408 90901 solver.cpp:228] Iteration 39200, loss = 0.155796
I0905 08:42:05.285447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155797 (* 1 = 0.155797 loss)
I0905 08:42:05.285464 90901 sgd_solver.cpp:106] Iteration 39200, lr = 0.1
I0905 08:42:11.038465 90901 solver.cpp:228] Iteration 39210, loss = 0.227121
I0905 08:42:11.038522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227122 (* 1 = 0.227122 loss)
I0905 08:42:11.038537 90901 sgd_solver.cpp:106] Iteration 39210, lr = 0.1
I0905 08:42:17.445205 90901 solver.cpp:228] Iteration 39220, loss = 0.26059
I0905 08:42:17.445267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260591 (* 1 = 0.260591 loss)
I0905 08:42:17.445283 90901 sgd_solver.cpp:106] Iteration 39220, lr = 0.1
I0905 08:42:23.531361 90901 solver.cpp:228] Iteration 39230, loss = 0.326468
I0905 08:42:23.531424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326469 (* 1 = 0.326469 loss)
I0905 08:42:23.531440 90901 sgd_solver.cpp:106] Iteration 39230, lr = 0.1
I0905 08:42:29.598064 90901 solver.cpp:228] Iteration 39240, loss = 0.147071
I0905 08:42:29.598125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147071 (* 1 = 0.147071 loss)
I0905 08:42:29.598141 90901 sgd_solver.cpp:106] Iteration 39240, lr = 0.1
I0905 08:42:35.673904 90901 solver.cpp:228] Iteration 39250, loss = 0.198087
I0905 08:42:35.674059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198088 (* 1 = 0.198088 loss)
I0905 08:42:35.674098 90901 sgd_solver.cpp:106] Iteration 39250, lr = 0.1
I0905 08:42:41.679086 90901 solver.cpp:228] Iteration 39260, loss = 0.274431
I0905 08:42:41.679148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274432 (* 1 = 0.274432 loss)
I0905 08:42:41.679164 90901 sgd_solver.cpp:106] Iteration 39260, lr = 0.1
I0905 08:42:47.256116 90901 solver.cpp:228] Iteration 39270, loss = 0.402554
I0905 08:42:47.256170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402554 (* 1 = 0.402554 loss)
I0905 08:42:47.256183 90901 sgd_solver.cpp:106] Iteration 39270, lr = 0.1
I0905 08:42:52.677409 90901 solver.cpp:228] Iteration 39280, loss = 0.151428
I0905 08:42:52.677459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151429 (* 1 = 0.151429 loss)
I0905 08:42:52.677470 90901 sgd_solver.cpp:106] Iteration 39280, lr = 0.1
I0905 08:42:58.997298 90901 solver.cpp:228] Iteration 39290, loss = 0.654251
I0905 08:42:58.997334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.654251 (* 1 = 0.654251 loss)
I0905 08:42:58.997349 90901 sgd_solver.cpp:106] Iteration 39290, lr = 0.1
I0905 08:43:04.825268 90901 solver.cpp:228] Iteration 39300, loss = 0.269644
I0905 08:43:04.825328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269644 (* 1 = 0.269644 loss)
I0905 08:43:04.825350 90901 sgd_solver.cpp:106] Iteration 39300, lr = 0.1
I0905 08:43:10.872288 90901 solver.cpp:228] Iteration 39310, loss = 0.176799
I0905 08:43:10.872427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176799 (* 1 = 0.176799 loss)
I0905 08:43:10.872486 90901 sgd_solver.cpp:106] Iteration 39310, lr = 0.1
I0905 08:43:16.923610 90901 solver.cpp:228] Iteration 39320, loss = 0.209235
I0905 08:43:16.923648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209236 (* 1 = 0.209236 loss)
I0905 08:43:16.923661 90901 sgd_solver.cpp:106] Iteration 39320, lr = 0.1
I0905 08:43:23.352319 90901 solver.cpp:228] Iteration 39330, loss = 0.330903
I0905 08:43:23.352366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330904 (* 1 = 0.330904 loss)
I0905 08:43:23.352382 90901 sgd_solver.cpp:106] Iteration 39330, lr = 0.1
I0905 08:43:29.420120 90901 solver.cpp:228] Iteration 39340, loss = 0.111592
I0905 08:43:29.420168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111593 (* 1 = 0.111593 loss)
I0905 08:43:29.420186 90901 sgd_solver.cpp:106] Iteration 39340, lr = 0.1
I0905 08:43:35.474958 90901 solver.cpp:228] Iteration 39350, loss = 0.136127
I0905 08:43:35.475013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136127 (* 1 = 0.136127 loss)
I0905 08:43:35.475028 90901 sgd_solver.cpp:106] Iteration 39350, lr = 0.1
I0905 08:43:41.555595 90901 solver.cpp:228] Iteration 39360, loss = 0.4268
I0905 08:43:41.555812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426801 (* 1 = 0.426801 loss)
I0905 08:43:41.555831 90901 sgd_solver.cpp:106] Iteration 39360, lr = 0.1
I0905 08:43:47.280777 90901 solver.cpp:228] Iteration 39370, loss = 1.25566
I0905 08:43:47.280823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.25566 (* 1 = 1.25566 loss)
I0905 08:43:47.280835 90901 sgd_solver.cpp:106] Iteration 39370, lr = 0.1
I0905 08:43:53.691473 90901 solver.cpp:228] Iteration 39380, loss = 0.248526
I0905 08:43:53.691509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248526 (* 1 = 0.248526 loss)
I0905 08:43:53.691524 90901 sgd_solver.cpp:106] Iteration 39380, lr = 0.1
I0905 08:43:59.463165 90901 solver.cpp:228] Iteration 39390, loss = 0.149836
I0905 08:43:59.463204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149836 (* 1 = 0.149836 loss)
I0905 08:43:59.463217 90901 sgd_solver.cpp:106] Iteration 39390, lr = 0.1
I0905 08:44:05.870820 90901 solver.cpp:228] Iteration 39400, loss = 0.436486
I0905 08:44:05.870868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436487 (* 1 = 0.436487 loss)
I0905 08:44:05.870885 90901 sgd_solver.cpp:106] Iteration 39400, lr = 0.1
I0905 08:44:11.945612 90901 solver.cpp:228] Iteration 39410, loss = 0.179319
I0905 08:44:11.945857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179319 (* 1 = 0.179319 loss)
I0905 08:44:11.945871 90901 sgd_solver.cpp:106] Iteration 39410, lr = 0.1
I0905 08:44:18.347331 90901 solver.cpp:228] Iteration 39420, loss = 0.247974
I0905 08:44:18.347381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247974 (* 1 = 0.247974 loss)
I0905 08:44:18.347395 90901 sgd_solver.cpp:106] Iteration 39420, lr = 0.1
I0905 08:44:24.416160 90901 solver.cpp:228] Iteration 39430, loss = 0.119084
I0905 08:44:24.416224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119085 (* 1 = 0.119085 loss)
I0905 08:44:24.416239 90901 sgd_solver.cpp:106] Iteration 39430, lr = 0.1
I0905 08:44:29.988435 90901 solver.cpp:228] Iteration 39440, loss = 0.158402
I0905 08:44:29.988476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158403 (* 1 = 0.158403 loss)
I0905 08:44:29.988487 90901 sgd_solver.cpp:106] Iteration 39440, lr = 0.1
I0905 08:44:35.258342 90901 solver.cpp:228] Iteration 39450, loss = 0.224611
I0905 08:44:35.258422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224612 (* 1 = 0.224612 loss)
I0905 08:44:35.258437 90901 sgd_solver.cpp:106] Iteration 39450, lr = 0.1
I0905 08:44:41.126046 90901 solver.cpp:228] Iteration 39460, loss = 0.154743
I0905 08:44:41.126090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154743 (* 1 = 0.154743 loss)
I0905 08:44:41.126102 90901 sgd_solver.cpp:106] Iteration 39460, lr = 0.1
I0905 08:44:47.219238 90901 solver.cpp:228] Iteration 39470, loss = 0.205254
I0905 08:44:47.219485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205254 (* 1 = 0.205254 loss)
I0905 08:44:47.219501 90901 sgd_solver.cpp:106] Iteration 39470, lr = 0.1
I0905 08:44:52.299963 90901 solver.cpp:228] Iteration 39480, loss = 0.324855
I0905 08:44:52.300017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324856 (* 1 = 0.324856 loss)
I0905 08:44:52.300034 90901 sgd_solver.cpp:106] Iteration 39480, lr = 0.1
I0905 08:44:57.338176 90901 solver.cpp:228] Iteration 39490, loss = 0.349192
I0905 08:44:57.338232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349193 (* 1 = 0.349193 loss)
I0905 08:44:57.338246 90901 sgd_solver.cpp:106] Iteration 39490, lr = 0.1
I0905 08:45:02.391310 90901 solver.cpp:228] Iteration 39500, loss = 0.13271
I0905 08:45:02.391366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132711 (* 1 = 0.132711 loss)
I0905 08:45:02.391379 90901 sgd_solver.cpp:106] Iteration 39500, lr = 0.1
I0905 08:45:07.425597 90901 solver.cpp:228] Iteration 39510, loss = 0.0983668
I0905 08:45:07.425644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0983674 (* 1 = 0.0983674 loss)
I0905 08:45:07.425663 90901 sgd_solver.cpp:106] Iteration 39510, lr = 0.1
I0905 08:45:12.438200 90901 solver.cpp:228] Iteration 39520, loss = 0.226777
I0905 08:45:12.438259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226777 (* 1 = 0.226777 loss)
I0905 08:45:12.438272 90901 sgd_solver.cpp:106] Iteration 39520, lr = 0.1
I0905 08:45:17.508213 90901 solver.cpp:228] Iteration 39530, loss = 0.501663
I0905 08:45:17.508458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501663 (* 1 = 0.501663 loss)
I0905 08:45:17.508476 90901 sgd_solver.cpp:106] Iteration 39530, lr = 0.1
I0905 08:45:22.533745 90901 solver.cpp:228] Iteration 39540, loss = 0.137313
I0905 08:45:22.533794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137314 (* 1 = 0.137314 loss)
I0905 08:45:22.533809 90901 sgd_solver.cpp:106] Iteration 39540, lr = 0.1
I0905 08:45:27.555455 90901 solver.cpp:228] Iteration 39550, loss = 0.705335
I0905 08:45:27.555500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.705335 (* 1 = 0.705335 loss)
I0905 08:45:27.555513 90901 sgd_solver.cpp:106] Iteration 39550, lr = 0.1
I0905 08:45:32.550097 90901 solver.cpp:228] Iteration 39560, loss = 0.451037
I0905 08:45:32.550129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451038 (* 1 = 0.451038 loss)
I0905 08:45:32.550143 90901 sgd_solver.cpp:106] Iteration 39560, lr = 0.1
I0905 08:45:37.598176 90901 solver.cpp:228] Iteration 39570, loss = 0.383261
I0905 08:45:37.598237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383262 (* 1 = 0.383262 loss)
I0905 08:45:37.598251 90901 sgd_solver.cpp:106] Iteration 39570, lr = 0.1
I0905 08:45:42.641991 90901 solver.cpp:228] Iteration 39580, loss = 0.0861026
I0905 08:45:42.642060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0861032 (* 1 = 0.0861032 loss)
I0905 08:45:42.642073 90901 sgd_solver.cpp:106] Iteration 39580, lr = 0.1
I0905 08:45:47.659513 90901 solver.cpp:228] Iteration 39590, loss = 0.318081
I0905 08:45:47.659687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318082 (* 1 = 0.318082 loss)
I0905 08:45:47.659716 90901 sgd_solver.cpp:106] Iteration 39590, lr = 0.1
I0905 08:45:52.695231 90901 solver.cpp:228] Iteration 39600, loss = 0.137034
I0905 08:45:52.695303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137035 (* 1 = 0.137035 loss)
I0905 08:45:52.695318 90901 sgd_solver.cpp:106] Iteration 39600, lr = 0.1
I0905 08:45:57.762454 90901 solver.cpp:228] Iteration 39610, loss = 0.148336
I0905 08:45:57.762501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148337 (* 1 = 0.148337 loss)
I0905 08:45:57.762516 90901 sgd_solver.cpp:106] Iteration 39610, lr = 0.1
I0905 08:46:02.820046 90901 solver.cpp:228] Iteration 39620, loss = 0.481016
I0905 08:46:02.820155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.481016 (* 1 = 0.481016 loss)
I0905 08:46:02.820190 90901 sgd_solver.cpp:106] Iteration 39620, lr = 0.1
I0905 08:46:07.876878 90901 solver.cpp:228] Iteration 39630, loss = 0.430057
I0905 08:46:07.876927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430057 (* 1 = 0.430057 loss)
I0905 08:46:07.876942 90901 sgd_solver.cpp:106] Iteration 39630, lr = 0.1
I0905 08:46:13.932348 90901 solver.cpp:228] Iteration 39640, loss = 0.139351
I0905 08:46:13.932417 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139352 (* 1 = 0.139352 loss)
I0905 08:46:13.932435 90901 sgd_solver.cpp:106] Iteration 39640, lr = 0.1
I0905 08:46:19.966835 90901 solver.cpp:228] Iteration 39650, loss = 0.488621
I0905 08:46:19.967146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488622 (* 1 = 0.488622 loss)
I0905 08:46:19.967164 90901 sgd_solver.cpp:106] Iteration 39650, lr = 0.1
I0905 08:46:25.536911 90901 solver.cpp:228] Iteration 39660, loss = 0.146108
I0905 08:46:25.536984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146109 (* 1 = 0.146109 loss)
I0905 08:46:25.537001 90901 sgd_solver.cpp:106] Iteration 39660, lr = 0.1
I0905 08:46:30.917232 90901 solver.cpp:228] Iteration 39670, loss = 0.303673
I0905 08:46:30.917299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303673 (* 1 = 0.303673 loss)
I0905 08:46:30.917315 90901 sgd_solver.cpp:106] Iteration 39670, lr = 0.1
I0905 08:46:36.968395 90901 solver.cpp:228] Iteration 39680, loss = 0.246098
I0905 08:46:36.968466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246099 (* 1 = 0.246099 loss)
I0905 08:46:36.968482 90901 sgd_solver.cpp:106] Iteration 39680, lr = 0.1
I0905 08:46:43.034504 90901 solver.cpp:228] Iteration 39690, loss = 0.248981
I0905 08:46:43.034575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248982 (* 1 = 0.248982 loss)
I0905 08:46:43.034590 90901 sgd_solver.cpp:106] Iteration 39690, lr = 0.1
I0905 08:46:49.087474 90901 solver.cpp:228] Iteration 39700, loss = 0.371442
I0905 08:46:49.087543 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371443 (* 1 = 0.371443 loss)
I0905 08:46:49.087556 90901 sgd_solver.cpp:106] Iteration 39700, lr = 0.1
I0905 08:46:55.498788 90901 solver.cpp:228] Iteration 39710, loss = 0.255385
I0905 08:46:55.498996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255385 (* 1 = 0.255385 loss)
I0905 08:46:55.499012 90901 sgd_solver.cpp:106] Iteration 39710, lr = 0.1
I0905 08:47:01.577930 90901 solver.cpp:228] Iteration 39720, loss = 0.165621
I0905 08:47:01.577976 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165622 (* 1 = 0.165622 loss)
I0905 08:47:01.577991 90901 sgd_solver.cpp:106] Iteration 39720, lr = 0.1
I0905 08:47:07.683265 90901 solver.cpp:228] Iteration 39730, loss = 0.475543
I0905 08:47:07.683322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475544 (* 1 = 0.475544 loss)
I0905 08:47:07.683337 90901 sgd_solver.cpp:106] Iteration 39730, lr = 0.1
I0905 08:47:13.745437 90901 solver.cpp:228] Iteration 39740, loss = 0.235041
I0905 08:47:13.745489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235041 (* 1 = 0.235041 loss)
I0905 08:47:13.745504 90901 sgd_solver.cpp:106] Iteration 39740, lr = 0.1
I0905 08:47:19.833575 90901 solver.cpp:228] Iteration 39750, loss = 0.494497
I0905 08:47:19.833619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.494498 (* 1 = 0.494498 loss)
I0905 08:47:19.833632 90901 sgd_solver.cpp:106] Iteration 39750, lr = 0.1
I0905 08:47:25.887394 90901 solver.cpp:228] Iteration 39760, loss = 0.333713
I0905 08:47:25.887682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333714 (* 1 = 0.333714 loss)
I0905 08:47:25.887706 90901 sgd_solver.cpp:106] Iteration 39760, lr = 0.1
I0905 08:47:32.300895 90901 solver.cpp:228] Iteration 39770, loss = 0.105435
I0905 08:47:32.300945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105436 (* 1 = 0.105436 loss)
I0905 08:47:32.300957 90901 sgd_solver.cpp:106] Iteration 39770, lr = 0.1
I0905 08:47:38.293233 90901 solver.cpp:228] Iteration 39780, loss = 0.0802858
I0905 08:47:38.293282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0802865 (* 1 = 0.0802865 loss)
I0905 08:47:38.293293 90901 sgd_solver.cpp:106] Iteration 39780, lr = 0.1
I0905 08:47:44.245452 90901 solver.cpp:228] Iteration 39790, loss = 0.137403
I0905 08:47:44.245507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137404 (* 1 = 0.137404 loss)
I0905 08:47:44.245523 90901 sgd_solver.cpp:106] Iteration 39790, lr = 0.1
I0905 08:47:50.523707 90901 solver.cpp:228] Iteration 39800, loss = 0.194684
I0905 08:47:50.523752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194685 (* 1 = 0.194685 loss)
I0905 08:47:50.523767 90901 sgd_solver.cpp:106] Iteration 39800, lr = 0.1
I0905 08:47:56.618772 90901 solver.cpp:228] Iteration 39810, loss = 0.200005
I0905 08:47:56.619002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200006 (* 1 = 0.200006 loss)
I0905 08:47:56.619019 90901 sgd_solver.cpp:106] Iteration 39810, lr = 0.1
I0905 08:48:02.678952 90901 solver.cpp:228] Iteration 39820, loss = 0.463516
I0905 08:48:02.679015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463517 (* 1 = 0.463517 loss)
I0905 08:48:02.679029 90901 sgd_solver.cpp:106] Iteration 39820, lr = 0.1
I0905 08:48:08.576944 90901 solver.cpp:228] Iteration 39830, loss = 0.231822
I0905 08:48:08.576987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231823 (* 1 = 0.231823 loss)
I0905 08:48:08.577000 90901 sgd_solver.cpp:106] Iteration 39830, lr = 0.1
I0905 08:48:13.841116 90901 solver.cpp:228] Iteration 39840, loss = 0.588246
I0905 08:48:13.841163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.588247 (* 1 = 0.588247 loss)
I0905 08:48:13.841177 90901 sgd_solver.cpp:106] Iteration 39840, lr = 0.1
I0905 08:48:19.600306 90901 solver.cpp:228] Iteration 39850, loss = 0.143229
I0905 08:48:19.600342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14323 (* 1 = 0.14323 loss)
I0905 08:48:19.600355 90901 sgd_solver.cpp:106] Iteration 39850, lr = 0.1
I0905 08:48:26.016472 90901 solver.cpp:228] Iteration 39860, loss = 0.352541
I0905 08:48:26.016520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352542 (* 1 = 0.352542 loss)
I0905 08:48:26.016535 90901 sgd_solver.cpp:106] Iteration 39860, lr = 0.1
I0905 08:48:32.061358 90901 solver.cpp:228] Iteration 39870, loss = 0.150748
I0905 08:48:32.061576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150749 (* 1 = 0.150749 loss)
I0905 08:48:32.061604 90901 sgd_solver.cpp:106] Iteration 39870, lr = 0.1
I0905 08:48:38.135136 90901 solver.cpp:228] Iteration 39880, loss = 0.163374
I0905 08:48:38.135186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163375 (* 1 = 0.163375 loss)
I0905 08:48:38.135200 90901 sgd_solver.cpp:106] Iteration 39880, lr = 0.1
I0905 08:48:44.191674 90901 solver.cpp:228] Iteration 39890, loss = 0.319038
I0905 08:48:44.191716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319039 (* 1 = 0.319039 loss)
I0905 08:48:44.191730 90901 sgd_solver.cpp:106] Iteration 39890, lr = 0.1
I0905 08:48:50.268810 90901 solver.cpp:228] Iteration 39900, loss = 0.399582
I0905 08:48:50.268852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399583 (* 1 = 0.399583 loss)
I0905 08:48:50.268867 90901 sgd_solver.cpp:106] Iteration 39900, lr = 0.1
I0905 08:48:56.341652 90901 solver.cpp:228] Iteration 39910, loss = 0.137955
I0905 08:48:56.341702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137956 (* 1 = 0.137956 loss)
I0905 08:48:56.341714 90901 sgd_solver.cpp:106] Iteration 39910, lr = 0.1
I0905 08:49:02.739290 90901 solver.cpp:228] Iteration 39920, loss = 0.13904
I0905 08:49:02.739437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139041 (* 1 = 0.139041 loss)
I0905 08:49:02.739478 90901 sgd_solver.cpp:106] Iteration 39920, lr = 0.1
I0905 08:49:08.782275 90901 solver.cpp:228] Iteration 39930, loss = 0.185784
I0905 08:49:08.782313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185785 (* 1 = 0.185785 loss)
I0905 08:49:08.782326 90901 sgd_solver.cpp:106] Iteration 39930, lr = 0.1
I0905 08:49:14.847791 90901 solver.cpp:228] Iteration 39940, loss = 0.106462
I0905 08:49:14.847851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106463 (* 1 = 0.106463 loss)
I0905 08:49:14.847867 90901 sgd_solver.cpp:106] Iteration 39940, lr = 0.1
I0905 08:49:20.949414 90901 solver.cpp:228] Iteration 39950, loss = 0.0553256
I0905 08:49:20.949461 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0553265 (* 1 = 0.0553265 loss)
I0905 08:49:20.949475 90901 sgd_solver.cpp:106] Iteration 39950, lr = 0.1
I0905 08:49:26.707598 90901 solver.cpp:228] Iteration 39960, loss = 0.338732
I0905 08:49:26.707643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338733 (* 1 = 0.338733 loss)
I0905 08:49:26.707656 90901 sgd_solver.cpp:106] Iteration 39960, lr = 0.1
I0905 08:49:33.043269 90901 solver.cpp:228] Iteration 39970, loss = 0.544765
I0905 08:49:33.043478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.544766 (* 1 = 0.544766 loss)
I0905 08:49:33.043505 90901 sgd_solver.cpp:106] Iteration 39970, lr = 0.1
I0905 08:49:39.218267 90901 solver.cpp:228] Iteration 39980, loss = 0.129584
I0905 08:49:39.218312 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129585 (* 1 = 0.129585 loss)
I0905 08:49:39.218327 90901 sgd_solver.cpp:106] Iteration 39980, lr = 0.1
I0905 08:49:45.306144 90901 solver.cpp:228] Iteration 39990, loss = 0.0834746
I0905 08:49:45.306190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0834755 (* 1 = 0.0834755 loss)
I0905 08:49:45.306202 90901 sgd_solver.cpp:106] Iteration 39990, lr = 0.1
I0905 08:49:51.164362 90901 solver.cpp:337] Iteration 40000, Testing net (#0)
I0905 08:50:32.287672 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.750625
I0905 08:50:32.287859 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.897847 (* 1 = 0.897847 loss)
I0905 08:50:32.523087 90901 solver.cpp:228] Iteration 40000, loss = 0.285766
I0905 08:50:32.523138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285766 (* 1 = 0.285766 loss)
I0905 08:50:32.523155 90901 sgd_solver.cpp:106] Iteration 40000, lr = 0.1
I0905 08:50:38.688937 90901 solver.cpp:228] Iteration 40010, loss = 0.199086
I0905 08:50:38.688987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199087 (* 1 = 0.199087 loss)
I0905 08:50:38.689000 90901 sgd_solver.cpp:106] Iteration 40010, lr = 0.1
I0905 08:50:44.902351 90901 solver.cpp:228] Iteration 40020, loss = 0.611931
I0905 08:50:44.902390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.611932 (* 1 = 0.611932 loss)
I0905 08:50:44.902402 90901 sgd_solver.cpp:106] Iteration 40020, lr = 0.1
I0905 08:50:50.696166 90901 solver.cpp:228] Iteration 40030, loss = 0.0946042
I0905 08:50:50.696215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0946049 (* 1 = 0.0946049 loss)
I0905 08:50:50.696229 90901 sgd_solver.cpp:106] Iteration 40030, lr = 0.1
I0905 08:50:57.129895 90901 solver.cpp:228] Iteration 40040, loss = 0.411973
I0905 08:50:57.129941 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.411973 (* 1 = 0.411973 loss)
I0905 08:50:57.129956 90901 sgd_solver.cpp:106] Iteration 40040, lr = 0.1
I0905 08:51:02.852237 90901 solver.cpp:228] Iteration 40050, loss = 0.392387
I0905 08:51:02.852380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392388 (* 1 = 0.392388 loss)
I0905 08:51:02.852411 90901 sgd_solver.cpp:106] Iteration 40050, lr = 0.1
I0905 08:51:09.602897 90901 solver.cpp:228] Iteration 40060, loss = 0.365149
I0905 08:51:09.602943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365149 (* 1 = 0.365149 loss)
I0905 08:51:09.602957 90901 sgd_solver.cpp:106] Iteration 40060, lr = 0.1
I0905 08:51:15.387342 90901 solver.cpp:228] Iteration 40070, loss = 0.460736
I0905 08:51:15.387378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460736 (* 1 = 0.460736 loss)
I0905 08:51:15.387390 90901 sgd_solver.cpp:106] Iteration 40070, lr = 0.1
I0905 08:51:21.748265 90901 solver.cpp:228] Iteration 40080, loss = 0.29869
I0905 08:51:21.748317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298691 (* 1 = 0.298691 loss)
I0905 08:51:21.748330 90901 sgd_solver.cpp:106] Iteration 40080, lr = 0.1
I0905 08:51:27.780398 90901 solver.cpp:228] Iteration 40090, loss = 0.138855
I0905 08:51:27.780447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138856 (* 1 = 0.138856 loss)
I0905 08:51:27.780460 90901 sgd_solver.cpp:106] Iteration 40090, lr = 0.1
I0905 08:51:33.855662 90901 solver.cpp:228] Iteration 40100, loss = 0.778234
I0905 08:51:33.855859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.778235 (* 1 = 0.778235 loss)
I0905 08:51:33.855909 90901 sgd_solver.cpp:106] Iteration 40100, lr = 0.1
I0905 08:51:39.899811 90901 solver.cpp:228] Iteration 40110, loss = 0.114147
I0905 08:51:39.899855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114148 (* 1 = 0.114148 loss)
I0905 08:51:39.899868 90901 sgd_solver.cpp:106] Iteration 40110, lr = 0.1
I0905 08:51:45.528720 90901 solver.cpp:228] Iteration 40120, loss = 0.463274
I0905 08:51:45.528792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463274 (* 1 = 0.463274 loss)
I0905 08:51:45.528810 90901 sgd_solver.cpp:106] Iteration 40120, lr = 0.1
I0905 08:51:50.990954 90901 solver.cpp:228] Iteration 40130, loss = 0.275891
I0905 08:51:50.991022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275892 (* 1 = 0.275892 loss)
I0905 08:51:50.991039 90901 sgd_solver.cpp:106] Iteration 40130, lr = 0.1
I0905 08:51:56.920351 90901 solver.cpp:228] Iteration 40140, loss = 0.432849
I0905 08:51:56.920397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43285 (* 1 = 0.43285 loss)
I0905 08:51:56.920411 90901 sgd_solver.cpp:106] Iteration 40140, lr = 0.1
I0905 08:52:02.991646 90901 solver.cpp:228] Iteration 40150, loss = 0.226432
I0905 08:52:02.991696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226433 (* 1 = 0.226433 loss)
I0905 08:52:02.991709 90901 sgd_solver.cpp:106] Iteration 40150, lr = 0.1
I0905 08:52:09.087380 90901 solver.cpp:228] Iteration 40160, loss = 0.0896315
I0905 08:52:09.087579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0896323 (* 1 = 0.0896323 loss)
I0905 08:52:09.087600 90901 sgd_solver.cpp:106] Iteration 40160, lr = 0.1
I0905 08:52:15.451618 90901 solver.cpp:228] Iteration 40170, loss = 0.271961
I0905 08:52:15.451674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271962 (* 1 = 0.271962 loss)
I0905 08:52:15.451690 90901 sgd_solver.cpp:106] Iteration 40170, lr = 0.1
I0905 08:52:21.071580 90901 solver.cpp:228] Iteration 40180, loss = 0.196191
I0905 08:52:21.071631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196192 (* 1 = 0.196192 loss)
I0905 08:52:21.071645 90901 sgd_solver.cpp:106] Iteration 40180, lr = 0.1
I0905 08:52:27.631960 90901 solver.cpp:228] Iteration 40190, loss = 0.241936
I0905 08:52:27.632002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241936 (* 1 = 0.241936 loss)
I0905 08:52:27.632015 90901 sgd_solver.cpp:106] Iteration 40190, lr = 0.1
I0905 08:52:33.709162 90901 solver.cpp:228] Iteration 40200, loss = 0.210485
I0905 08:52:33.709211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210485 (* 1 = 0.210485 loss)
I0905 08:52:33.709226 90901 sgd_solver.cpp:106] Iteration 40200, lr = 0.1
I0905 08:52:39.813560 90901 solver.cpp:228] Iteration 40210, loss = 0.823647
I0905 08:52:39.813696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.823648 (* 1 = 0.823648 loss)
I0905 08:52:39.813721 90901 sgd_solver.cpp:106] Iteration 40210, lr = 0.1
I0905 08:52:45.490397 90901 solver.cpp:228] Iteration 40220, loss = 0.282481
I0905 08:52:45.490444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282481 (* 1 = 0.282481 loss)
I0905 08:52:45.490456 90901 sgd_solver.cpp:106] Iteration 40220, lr = 0.1
I0905 08:52:51.871729 90901 solver.cpp:228] Iteration 40230, loss = 0.491759
I0905 08:52:51.871776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.49176 (* 1 = 0.49176 loss)
I0905 08:52:51.871788 90901 sgd_solver.cpp:106] Iteration 40230, lr = 0.1
I0905 08:52:57.957654 90901 solver.cpp:228] Iteration 40240, loss = 0.144906
I0905 08:52:57.957700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144907 (* 1 = 0.144907 loss)
I0905 08:52:57.957713 90901 sgd_solver.cpp:106] Iteration 40240, lr = 0.1
I0905 08:53:04.062481 90901 solver.cpp:228] Iteration 40250, loss = 0.172908
I0905 08:53:04.062537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172908 (* 1 = 0.172908 loss)
I0905 08:53:04.062551 90901 sgd_solver.cpp:106] Iteration 40250, lr = 0.1
I0905 08:53:10.167742 90901 solver.cpp:228] Iteration 40260, loss = 0.437675
I0905 08:53:10.167944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437675 (* 1 = 0.437675 loss)
I0905 08:53:10.167971 90901 sgd_solver.cpp:106] Iteration 40260, lr = 0.1
I0905 08:53:16.542201 90901 solver.cpp:228] Iteration 40270, loss = 0.243979
I0905 08:53:16.542249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24398 (* 1 = 0.24398 loss)
I0905 08:53:16.542263 90901 sgd_solver.cpp:106] Iteration 40270, lr = 0.1
I0905 08:53:22.656894 90901 solver.cpp:228] Iteration 40280, loss = 0.282445
I0905 08:53:22.656936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282446 (* 1 = 0.282446 loss)
I0905 08:53:22.656949 90901 sgd_solver.cpp:106] Iteration 40280, lr = 0.1
I0905 08:53:29.029757 90901 solver.cpp:228] Iteration 40290, loss = 0.419821
I0905 08:53:29.029794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419822 (* 1 = 0.419822 loss)
I0905 08:53:29.029808 90901 sgd_solver.cpp:106] Iteration 40290, lr = 0.1
I0905 08:53:34.299300 90901 solver.cpp:228] Iteration 40300, loss = 0.248677
I0905 08:53:34.299351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248678 (* 1 = 0.248678 loss)
I0905 08:53:34.299365 90901 sgd_solver.cpp:106] Iteration 40300, lr = 0.1
I0905 08:53:39.906095 90901 solver.cpp:228] Iteration 40310, loss = 0.635808
I0905 08:53:39.906142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.635808 (* 1 = 0.635808 loss)
I0905 08:53:39.906157 90901 sgd_solver.cpp:106] Iteration 40310, lr = 0.1
I0905 08:53:45.991582 90901 solver.cpp:228] Iteration 40320, loss = 0.285049
I0905 08:53:45.991734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28505 (* 1 = 0.28505 loss)
I0905 08:53:45.991775 90901 sgd_solver.cpp:106] Iteration 40320, lr = 0.1
I0905 08:53:52.051409 90901 solver.cpp:228] Iteration 40330, loss = 0.254347
I0905 08:53:52.051460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254348 (* 1 = 0.254348 loss)
I0905 08:53:52.051473 90901 sgd_solver.cpp:106] Iteration 40330, lr = 0.1
I0905 08:53:58.127725 90901 solver.cpp:228] Iteration 40340, loss = 0.0971712
I0905 08:53:58.127769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0971718 (* 1 = 0.0971718 loss)
I0905 08:53:58.127784 90901 sgd_solver.cpp:106] Iteration 40340, lr = 0.1
I0905 08:54:04.218333 90901 solver.cpp:228] Iteration 40350, loss = 0.441519
I0905 08:54:04.218379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44152 (* 1 = 0.44152 loss)
I0905 08:54:04.218394 90901 sgd_solver.cpp:106] Iteration 40350, lr = 0.1
I0905 08:54:10.009708 90901 solver.cpp:228] Iteration 40360, loss = 0.306081
I0905 08:54:10.009760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306081 (* 1 = 0.306081 loss)
I0905 08:54:10.009774 90901 sgd_solver.cpp:106] Iteration 40360, lr = 0.1
I0905 08:54:16.118649 90901 solver.cpp:228] Iteration 40370, loss = 0.585513
I0905 08:54:16.120414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.585514 (* 1 = 0.585514 loss)
I0905 08:54:16.120434 90901 sgd_solver.cpp:106] Iteration 40370, lr = 0.1
I0905 08:54:22.525285 90901 solver.cpp:228] Iteration 40380, loss = 0.181344
I0905 08:54:22.525341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181344 (* 1 = 0.181344 loss)
I0905 08:54:22.525357 90901 sgd_solver.cpp:106] Iteration 40380, lr = 0.1
I0905 08:54:28.586484 90901 solver.cpp:228] Iteration 40390, loss = 0.134431
I0905 08:54:28.586534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134431 (* 1 = 0.134431 loss)
I0905 08:54:28.586546 90901 sgd_solver.cpp:106] Iteration 40390, lr = 0.1
I0905 08:54:34.673818 90901 solver.cpp:228] Iteration 40400, loss = 0.120208
I0905 08:54:34.673877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120209 (* 1 = 0.120209 loss)
I0905 08:54:34.673890 90901 sgd_solver.cpp:106] Iteration 40400, lr = 0.1
I0905 08:54:41.052306 90901 solver.cpp:228] Iteration 40410, loss = 0.434214
I0905 08:54:41.052345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434215 (* 1 = 0.434215 loss)
I0905 08:54:41.052362 90901 sgd_solver.cpp:106] Iteration 40410, lr = 0.1
I0905 08:54:47.147126 90901 solver.cpp:228] Iteration 40420, loss = 0.0821071
I0905 08:54:47.147336 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0821078 (* 1 = 0.0821078 loss)
I0905 08:54:47.147379 90901 sgd_solver.cpp:106] Iteration 40420, lr = 0.1
I0905 08:54:53.219691 90901 solver.cpp:228] Iteration 40430, loss = 0.338076
I0905 08:54:53.219743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338077 (* 1 = 0.338077 loss)
I0905 08:54:53.219758 90901 sgd_solver.cpp:106] Iteration 40430, lr = 0.1
I0905 08:54:59.445569 90901 solver.cpp:228] Iteration 40440, loss = 0.101215
I0905 08:54:59.445634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101216 (* 1 = 0.101216 loss)
I0905 08:54:59.445649 90901 sgd_solver.cpp:106] Iteration 40440, lr = 0.1
I0905 08:55:05.700731 90901 solver.cpp:228] Iteration 40450, loss = 0.0541722
I0905 08:55:05.700781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0541729 (* 1 = 0.0541729 loss)
I0905 08:55:05.700796 90901 sgd_solver.cpp:106] Iteration 40450, lr = 0.1
I0905 08:55:11.755646 90901 solver.cpp:228] Iteration 40460, loss = 0.336303
I0905 08:55:11.755695 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336304 (* 1 = 0.336304 loss)
I0905 08:55:11.755710 90901 sgd_solver.cpp:106] Iteration 40460, lr = 0.1
I0905 08:55:17.684454 90901 solver.cpp:228] Iteration 40470, loss = 0.202007
I0905 08:55:17.684655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202008 (* 1 = 0.202008 loss)
I0905 08:55:17.684702 90901 sgd_solver.cpp:106] Iteration 40470, lr = 0.1
I0905 08:55:22.944036 90901 solver.cpp:228] Iteration 40480, loss = 0.364795
I0905 08:55:22.944082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364795 (* 1 = 0.364795 loss)
I0905 08:55:22.944094 90901 sgd_solver.cpp:106] Iteration 40480, lr = 0.1
I0905 08:55:28.663296 90901 solver.cpp:228] Iteration 40490, loss = 0.594522
I0905 08:55:28.663341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.594523 (* 1 = 0.594523 loss)
I0905 08:55:28.663354 90901 sgd_solver.cpp:106] Iteration 40490, lr = 0.1
I0905 08:55:34.726009 90901 solver.cpp:228] Iteration 40500, loss = 0.104369
I0905 08:55:34.726070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104369 (* 1 = 0.104369 loss)
I0905 08:55:34.726085 90901 sgd_solver.cpp:106] Iteration 40500, lr = 0.1
I0905 08:55:40.752282 90901 solver.cpp:228] Iteration 40510, loss = 0.126155
I0905 08:55:40.752331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126156 (* 1 = 0.126156 loss)
I0905 08:55:40.752344 90901 sgd_solver.cpp:106] Iteration 40510, lr = 0.1
I0905 08:55:47.158664 90901 solver.cpp:228] Iteration 40520, loss = 0.116498
I0905 08:55:47.158720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116499 (* 1 = 0.116499 loss)
I0905 08:55:47.158742 90901 sgd_solver.cpp:106] Iteration 40520, lr = 0.1
I0905 08:55:53.228489 90901 solver.cpp:228] Iteration 40530, loss = 0.0715412
I0905 08:55:53.228725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0715421 (* 1 = 0.0715421 loss)
I0905 08:55:53.228761 90901 sgd_solver.cpp:106] Iteration 40530, lr = 0.1
I0905 08:55:59.307574 90901 solver.cpp:228] Iteration 40540, loss = 0.383827
I0905 08:55:59.307624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383828 (* 1 = 0.383828 loss)
I0905 08:55:59.307637 90901 sgd_solver.cpp:106] Iteration 40540, lr = 0.1
I0905 08:56:05.421663 90901 solver.cpp:228] Iteration 40550, loss = 0.60872
I0905 08:56:05.421715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.608721 (* 1 = 0.608721 loss)
I0905 08:56:05.421726 90901 sgd_solver.cpp:106] Iteration 40550, lr = 0.1
I0905 08:56:11.506661 90901 solver.cpp:228] Iteration 40560, loss = 0.340296
I0905 08:56:11.506703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340297 (* 1 = 0.340297 loss)
I0905 08:56:11.506716 90901 sgd_solver.cpp:106] Iteration 40560, lr = 0.1
I0905 08:56:17.564102 90901 solver.cpp:228] Iteration 40570, loss = 0.368642
I0905 08:56:17.564158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368643 (* 1 = 0.368643 loss)
I0905 08:56:17.564172 90901 sgd_solver.cpp:106] Iteration 40570, lr = 0.1
I0905 08:56:23.990227 90901 solver.cpp:228] Iteration 40580, loss = 0.391172
I0905 08:56:23.990401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391173 (* 1 = 0.391173 loss)
I0905 08:56:23.990433 90901 sgd_solver.cpp:106] Iteration 40580, lr = 0.1
I0905 08:56:30.035507 90901 solver.cpp:228] Iteration 40590, loss = 0.327185
I0905 08:56:30.035548 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327186 (* 1 = 0.327186 loss)
I0905 08:56:30.035562 90901 sgd_solver.cpp:106] Iteration 40590, lr = 0.1
I0905 08:56:36.116588 90901 solver.cpp:228] Iteration 40600, loss = 0.278795
I0905 08:56:36.116641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278796 (* 1 = 0.278796 loss)
I0905 08:56:36.116655 90901 sgd_solver.cpp:106] Iteration 40600, lr = 0.1
I0905 08:56:41.891916 90901 solver.cpp:228] Iteration 40610, loss = 0.239
I0905 08:56:41.891958 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239001 (* 1 = 0.239001 loss)
I0905 08:56:41.891970 90901 sgd_solver.cpp:106] Iteration 40610, lr = 0.1
I0905 08:56:48.288322 90901 solver.cpp:228] Iteration 40620, loss = 0.129407
I0905 08:56:48.288367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129408 (* 1 = 0.129408 loss)
I0905 08:56:48.288381 90901 sgd_solver.cpp:106] Iteration 40620, lr = 0.1
I0905 08:56:54.038126 90901 solver.cpp:228] Iteration 40630, loss = 0.516652
I0905 08:56:54.038281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.516653 (* 1 = 0.516653 loss)
I0905 08:56:54.038326 90901 sgd_solver.cpp:106] Iteration 40630, lr = 0.1
I0905 08:57:00.459210 90901 solver.cpp:228] Iteration 40640, loss = 0.277216
I0905 08:57:00.459259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277217 (* 1 = 0.277217 loss)
I0905 08:57:00.459273 90901 sgd_solver.cpp:106] Iteration 40640, lr = 0.1
I0905 08:57:06.340032 90901 solver.cpp:228] Iteration 40650, loss = 0.334857
I0905 08:57:06.340076 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334857 (* 1 = 0.334857 loss)
I0905 08:57:06.340090 90901 sgd_solver.cpp:106] Iteration 40650, lr = 0.1
I0905 08:57:11.918498 90901 solver.cpp:228] Iteration 40660, loss = 0.300443
I0905 08:57:11.918555 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300444 (* 1 = 0.300444 loss)
I0905 08:57:11.918570 90901 sgd_solver.cpp:106] Iteration 40660, lr = 0.1
I0905 08:57:17.442818 90901 solver.cpp:228] Iteration 40670, loss = 0.146755
I0905 08:57:17.442869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146756 (* 1 = 0.146756 loss)
I0905 08:57:17.442883 90901 sgd_solver.cpp:106] Iteration 40670, lr = 0.1
I0905 08:57:23.492738 90901 solver.cpp:228] Iteration 40680, loss = 0.407697
I0905 08:57:23.492789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407698 (* 1 = 0.407698 loss)
I0905 08:57:23.492801 90901 sgd_solver.cpp:106] Iteration 40680, lr = 0.1
I0905 08:57:29.869298 90901 solver.cpp:228] Iteration 40690, loss = 0.46694
I0905 08:57:29.869498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46694 (* 1 = 0.46694 loss)
I0905 08:57:29.869526 90901 sgd_solver.cpp:106] Iteration 40690, lr = 0.1
I0905 08:57:35.940150 90901 solver.cpp:228] Iteration 40700, loss = 0.608071
I0905 08:57:35.940199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.608071 (* 1 = 0.608071 loss)
I0905 08:57:35.940213 90901 sgd_solver.cpp:106] Iteration 40700, lr = 0.1
I0905 08:57:42.012404 90901 solver.cpp:228] Iteration 40710, loss = 0.290618
I0905 08:57:42.012447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290619 (* 1 = 0.290619 loss)
I0905 08:57:42.012461 90901 sgd_solver.cpp:106] Iteration 40710, lr = 0.1
I0905 08:57:48.095693 90901 solver.cpp:228] Iteration 40720, loss = 0.657907
I0905 08:57:48.095741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.657908 (* 1 = 0.657908 loss)
I0905 08:57:48.095753 90901 sgd_solver.cpp:106] Iteration 40720, lr = 0.1
I0905 08:57:54.147713 90901 solver.cpp:228] Iteration 40730, loss = 0.208343
I0905 08:57:54.147756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208343 (* 1 = 0.208343 loss)
I0905 08:57:54.147769 90901 sgd_solver.cpp:106] Iteration 40730, lr = 0.1
I0905 08:57:59.964470 90901 solver.cpp:228] Iteration 40740, loss = 0.144358
I0905 08:57:59.964638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144359 (* 1 = 0.144359 loss)
I0905 08:57:59.964685 90901 sgd_solver.cpp:106] Iteration 40740, lr = 0.1
I0905 08:58:06.312039 90901 solver.cpp:228] Iteration 40750, loss = 0.345486
I0905 08:58:06.312093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345487 (* 1 = 0.345487 loss)
I0905 08:58:06.312111 90901 sgd_solver.cpp:106] Iteration 40750, lr = 0.1
I0905 08:58:12.373803 90901 solver.cpp:228] Iteration 40760, loss = 0.200648
I0905 08:58:12.373848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200649 (* 1 = 0.200649 loss)
I0905 08:58:12.373860 90901 sgd_solver.cpp:106] Iteration 40760, lr = 0.1
I0905 08:58:18.763365 90901 solver.cpp:228] Iteration 40770, loss = 0.370084
I0905 08:58:18.763424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370085 (* 1 = 0.370085 loss)
I0905 08:58:18.763438 90901 sgd_solver.cpp:106] Iteration 40770, lr = 0.1
I0905 08:58:24.875792 90901 solver.cpp:228] Iteration 40780, loss = 0.473499
I0905 08:58:24.875839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473499 (* 1 = 0.473499 loss)
I0905 08:58:24.875852 90901 sgd_solver.cpp:106] Iteration 40780, lr = 0.1
I0905 08:58:30.945596 90901 solver.cpp:228] Iteration 40790, loss = 0.256805
I0905 08:58:30.945771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256806 (* 1 = 0.256806 loss)
I0905 08:58:30.945819 90901 sgd_solver.cpp:106] Iteration 40790, lr = 0.1
I0905 08:58:36.453579 90901 solver.cpp:337] Iteration 40800, Testing net (#0)
I0905 08:59:18.104573 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.819062
I0905 08:59:18.104720 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.388248 (* 1 = 0.388248 loss)
I0905 08:59:18.321662 90901 solver.cpp:228] Iteration 40800, loss = 0.288468
I0905 08:59:18.321704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288468 (* 1 = 0.288468 loss)
I0905 08:59:18.321722 90901 sgd_solver.cpp:106] Iteration 40800, lr = 0.1
I0905 08:59:24.366729 90901 solver.cpp:228] Iteration 40810, loss = 0.142138
I0905 08:59:24.366798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142139 (* 1 = 0.142139 loss)
I0905 08:59:24.366813 90901 sgd_solver.cpp:106] Iteration 40810, lr = 0.1
I0905 08:59:30.741472 90901 solver.cpp:228] Iteration 40820, loss = 0.401982
I0905 08:59:30.741518 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401982 (* 1 = 0.401982 loss)
I0905 08:59:30.741531 90901 sgd_solver.cpp:106] Iteration 40820, lr = 0.1
I0905 08:59:36.800124 90901 solver.cpp:228] Iteration 40830, loss = 0.124624
I0905 08:59:36.800202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124625 (* 1 = 0.124625 loss)
I0905 08:59:36.800217 90901 sgd_solver.cpp:106] Iteration 40830, lr = 0.1
I0905 08:59:42.870007 90901 solver.cpp:228] Iteration 40840, loss = 0.346574
I0905 08:59:42.870049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346575 (* 1 = 0.346575 loss)
I0905 08:59:42.870061 90901 sgd_solver.cpp:106] Iteration 40840, lr = 0.1
I0905 08:59:49.309293 90901 solver.cpp:228] Iteration 40850, loss = 0.438783
I0905 08:59:49.309516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438784 (* 1 = 0.438784 loss)
I0905 08:59:49.309533 90901 sgd_solver.cpp:106] Iteration 40850, lr = 0.1
I0905 08:59:55.371621 90901 solver.cpp:228] Iteration 40860, loss = 0.262443
I0905 08:59:55.371665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262444 (* 1 = 0.262444 loss)
I0905 08:59:55.371677 90901 sgd_solver.cpp:106] Iteration 40860, lr = 0.1
I0905 09:00:01.423792 90901 solver.cpp:228] Iteration 40870, loss = 0.437581
I0905 09:00:01.423864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437581 (* 1 = 0.437581 loss)
I0905 09:00:01.423880 90901 sgd_solver.cpp:106] Iteration 40870, lr = 0.1
I0905 09:00:07.520128 90901 solver.cpp:228] Iteration 40880, loss = 0.278689
I0905 09:00:07.520169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27869 (* 1 = 0.27869 loss)
I0905 09:00:07.520180 90901 sgd_solver.cpp:106] Iteration 40880, lr = 0.1
I0905 09:00:13.562727 90901 solver.cpp:228] Iteration 40890, loss = 0.285388
I0905 09:00:13.562778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285389 (* 1 = 0.285389 loss)
I0905 09:00:13.562791 90901 sgd_solver.cpp:106] Iteration 40890, lr = 0.1
I0905 09:00:19.838352 90901 solver.cpp:228] Iteration 40900, loss = 0.435248
I0905 09:00:19.838505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435249 (* 1 = 0.435249 loss)
I0905 09:00:19.838554 90901 sgd_solver.cpp:106] Iteration 40900, lr = 0.1
I0905 09:00:26.070386 90901 solver.cpp:228] Iteration 40910, loss = 0.296807
I0905 09:00:26.070441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296808 (* 1 = 0.296808 loss)
I0905 09:00:26.070453 90901 sgd_solver.cpp:106] Iteration 40910, lr = 0.1
I0905 09:00:32.119993 90901 solver.cpp:228] Iteration 40920, loss = 0.56615
I0905 09:00:32.120035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566151 (* 1 = 0.566151 loss)
I0905 09:00:32.120048 90901 sgd_solver.cpp:106] Iteration 40920, lr = 0.1
I0905 09:00:38.538187 90901 solver.cpp:228] Iteration 40930, loss = 0.128465
I0905 09:00:38.538250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128466 (* 1 = 0.128466 loss)
I0905 09:00:38.538265 90901 sgd_solver.cpp:106] Iteration 40930, lr = 0.1
I0905 09:00:43.959645 90901 solver.cpp:228] Iteration 40940, loss = 0.384735
I0905 09:00:43.959692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384736 (* 1 = 0.384736 loss)
I0905 09:00:43.959704 90901 sgd_solver.cpp:106] Iteration 40940, lr = 0.1
I0905 09:00:49.521584 90901 solver.cpp:228] Iteration 40950, loss = 0.18363
I0905 09:00:49.521636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183631 (* 1 = 0.183631 loss)
I0905 09:00:49.521651 90901 sgd_solver.cpp:106] Iteration 40950, lr = 0.1
I0905 09:00:55.408179 90901 solver.cpp:228] Iteration 40960, loss = 0.414444
I0905 09:00:55.408418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414445 (* 1 = 0.414445 loss)
I0905 09:00:55.408433 90901 sgd_solver.cpp:106] Iteration 40960, lr = 0.1
I0905 09:01:01.475944 90901 solver.cpp:228] Iteration 40970, loss = 0.195547
I0905 09:01:01.475989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195548 (* 1 = 0.195548 loss)
I0905 09:01:01.476003 90901 sgd_solver.cpp:106] Iteration 40970, lr = 0.1
I0905 09:01:07.545785 90901 solver.cpp:228] Iteration 40980, loss = 0.221495
I0905 09:01:07.545833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221495 (* 1 = 0.221495 loss)
I0905 09:01:07.545846 90901 sgd_solver.cpp:106] Iteration 40980, lr = 0.1
I0905 09:01:13.601052 90901 solver.cpp:228] Iteration 40990, loss = 0.342736
I0905 09:01:13.601094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342737 (* 1 = 0.342737 loss)
I0905 09:01:13.601105 90901 sgd_solver.cpp:106] Iteration 40990, lr = 0.1
I0905 09:01:20.015203 90901 solver.cpp:228] Iteration 41000, loss = 0.218482
I0905 09:01:20.015249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218482 (* 1 = 0.218482 loss)
I0905 09:01:20.015262 90901 sgd_solver.cpp:106] Iteration 41000, lr = 0.1
I0905 09:01:25.972278 90901 solver.cpp:228] Iteration 41010, loss = 0.145887
I0905 09:01:25.972506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145888 (* 1 = 0.145888 loss)
I0905 09:01:25.972538 90901 sgd_solver.cpp:106] Iteration 41010, lr = 0.1
I0905 09:01:32.190333 90901 solver.cpp:228] Iteration 41020, loss = 0.208348
I0905 09:01:32.190371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208349 (* 1 = 0.208349 loss)
I0905 09:01:32.190383 90901 sgd_solver.cpp:106] Iteration 41020, lr = 0.1
I0905 09:01:38.244808 90901 solver.cpp:228] Iteration 41030, loss = 0.66932
I0905 09:01:38.244874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.669321 (* 1 = 0.669321 loss)
I0905 09:01:38.244889 90901 sgd_solver.cpp:106] Iteration 41030, lr = 0.1
I0905 09:01:44.319926 90901 solver.cpp:228] Iteration 41040, loss = 0.133733
I0905 09:01:44.319968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133733 (* 1 = 0.133733 loss)
I0905 09:01:44.319982 90901 sgd_solver.cpp:106] Iteration 41040, lr = 0.1
I0905 09:01:50.391048 90901 solver.cpp:228] Iteration 41050, loss = 0.110482
I0905 09:01:50.391094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110483 (* 1 = 0.110483 loss)
I0905 09:01:50.391109 90901 sgd_solver.cpp:106] Iteration 41050, lr = 0.1
I0905 09:01:56.465291 90901 solver.cpp:228] Iteration 41060, loss = 0.111068
I0905 09:01:56.465476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111069 (* 1 = 0.111069 loss)
I0905 09:01:56.465517 90901 sgd_solver.cpp:106] Iteration 41060, lr = 0.1
I0905 09:02:02.708621 90901 solver.cpp:228] Iteration 41070, loss = 0.517879
I0905 09:02:02.708670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.517879 (* 1 = 0.517879 loss)
I0905 09:02:02.708683 90901 sgd_solver.cpp:106] Iteration 41070, lr = 0.1
I0905 09:02:08.887675 90901 solver.cpp:228] Iteration 41080, loss = 0.235117
I0905 09:02:08.887732 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235117 (* 1 = 0.235117 loss)
I0905 09:02:08.887744 90901 sgd_solver.cpp:106] Iteration 41080, lr = 0.1
I0905 09:02:14.959674 90901 solver.cpp:228] Iteration 41090, loss = 0.143754
I0905 09:02:14.959724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143755 (* 1 = 0.143755 loss)
I0905 09:02:14.959738 90901 sgd_solver.cpp:106] Iteration 41090, lr = 0.1
I0905 09:02:21.046483 90901 solver.cpp:228] Iteration 41100, loss = 0.0977043
I0905 09:02:21.046547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0977051 (* 1 = 0.0977051 loss)
I0905 09:02:21.046561 90901 sgd_solver.cpp:106] Iteration 41100, lr = 0.1
I0905 09:02:27.158205 90901 solver.cpp:228] Iteration 41110, loss = 0.52922
I0905 09:02:27.158313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.529221 (* 1 = 0.529221 loss)
I0905 09:02:27.158329 90901 sgd_solver.cpp:106] Iteration 41110, lr = 0.1
I0905 09:02:31.986333 90901 solver.cpp:228] Iteration 41120, loss = 0.27472
I0905 09:02:31.986397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274721 (* 1 = 0.274721 loss)
I0905 09:02:31.986413 90901 sgd_solver.cpp:106] Iteration 41120, lr = 0.1
I0905 09:02:36.636929 90901 solver.cpp:228] Iteration 41130, loss = 0.195933
I0905 09:02:36.637006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195933 (* 1 = 0.195933 loss)
I0905 09:02:36.637022 90901 sgd_solver.cpp:106] Iteration 41130, lr = 0.1
I0905 09:02:41.286455 90901 solver.cpp:228] Iteration 41140, loss = 0.223765
I0905 09:02:41.286530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223766 (* 1 = 0.223766 loss)
I0905 09:02:41.286545 90901 sgd_solver.cpp:106] Iteration 41140, lr = 0.1
I0905 09:02:46.304601 90901 solver.cpp:228] Iteration 41150, loss = 0.231802
I0905 09:02:46.304672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231803 (* 1 = 0.231803 loss)
I0905 09:02:46.304687 90901 sgd_solver.cpp:106] Iteration 41150, lr = 0.1
I0905 09:02:51.382800 90901 solver.cpp:228] Iteration 41160, loss = 0.20642
I0905 09:02:51.382859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20642 (* 1 = 0.20642 loss)
I0905 09:02:51.382875 90901 sgd_solver.cpp:106] Iteration 41160, lr = 0.1
I0905 09:02:56.436871 90901 solver.cpp:228] Iteration 41170, loss = 0.437329
I0905 09:02:56.436939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43733 (* 1 = 0.43733 loss)
I0905 09:02:56.436954 90901 sgd_solver.cpp:106] Iteration 41170, lr = 0.1
I0905 09:03:01.497987 90901 solver.cpp:228] Iteration 41180, loss = 0.418723
I0905 09:03:01.498253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418724 (* 1 = 0.418724 loss)
I0905 09:03:01.498271 90901 sgd_solver.cpp:106] Iteration 41180, lr = 0.1
I0905 09:03:06.548200 90901 solver.cpp:228] Iteration 41190, loss = 0.222965
I0905 09:03:06.548272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222966 (* 1 = 0.222966 loss)
I0905 09:03:06.548288 90901 sgd_solver.cpp:106] Iteration 41190, lr = 0.1
I0905 09:03:11.581758 90901 solver.cpp:228] Iteration 41200, loss = 0.290221
I0905 09:03:11.581832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290222 (* 1 = 0.290222 loss)
I0905 09:03:11.581848 90901 sgd_solver.cpp:106] Iteration 41200, lr = 0.1
I0905 09:03:16.640583 90901 solver.cpp:228] Iteration 41210, loss = 0.132885
I0905 09:03:16.640655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132886 (* 1 = 0.132886 loss)
I0905 09:03:16.640669 90901 sgd_solver.cpp:106] Iteration 41210, lr = 0.1
I0905 09:03:21.674350 90901 solver.cpp:228] Iteration 41220, loss = 0.315298
I0905 09:03:21.674427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315299 (* 1 = 0.315299 loss)
I0905 09:03:21.674443 90901 sgd_solver.cpp:106] Iteration 41220, lr = 0.1
I0905 09:03:26.739382 90901 solver.cpp:228] Iteration 41230, loss = 0.217732
I0905 09:03:26.739433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217733 (* 1 = 0.217733 loss)
I0905 09:03:26.739447 90901 sgd_solver.cpp:106] Iteration 41230, lr = 0.1
I0905 09:03:31.789366 90901 solver.cpp:228] Iteration 41240, loss = 0.40443
I0905 09:03:31.789564 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404431 (* 1 = 0.404431 loss)
I0905 09:03:31.789580 90901 sgd_solver.cpp:106] Iteration 41240, lr = 0.1
I0905 09:03:36.838709 90901 solver.cpp:228] Iteration 41250, loss = 0.264601
I0905 09:03:36.838788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264602 (* 1 = 0.264602 loss)
I0905 09:03:36.838805 90901 sgd_solver.cpp:106] Iteration 41250, lr = 0.1
I0905 09:03:41.847918 90901 solver.cpp:228] Iteration 41260, loss = 0.781492
I0905 09:03:41.847992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.781493 (* 1 = 0.781493 loss)
I0905 09:03:41.848017 90901 sgd_solver.cpp:106] Iteration 41260, lr = 0.1
I0905 09:03:46.904937 90901 solver.cpp:228] Iteration 41270, loss = 0.258875
I0905 09:03:46.905010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258876 (* 1 = 0.258876 loss)
I0905 09:03:46.905027 90901 sgd_solver.cpp:106] Iteration 41270, lr = 0.1
I0905 09:03:52.637835 90901 solver.cpp:228] Iteration 41280, loss = 0.265695
I0905 09:03:52.637908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265696 (* 1 = 0.265696 loss)
I0905 09:03:52.637923 90901 sgd_solver.cpp:106] Iteration 41280, lr = 0.1
I0905 09:03:58.756160 90901 solver.cpp:228] Iteration 41290, loss = 0.309194
I0905 09:03:58.756224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309195 (* 1 = 0.309195 loss)
I0905 09:03:58.756239 90901 sgd_solver.cpp:106] Iteration 41290, lr = 0.1
I0905 09:04:04.870779 90901 solver.cpp:228] Iteration 41300, loss = 0.417937
I0905 09:04:04.871050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417938 (* 1 = 0.417938 loss)
I0905 09:04:04.871067 90901 sgd_solver.cpp:106] Iteration 41300, lr = 0.1
I0905 09:04:11.278086 90901 solver.cpp:228] Iteration 41310, loss = 0.433559
I0905 09:04:11.278147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433559 (* 1 = 0.433559 loss)
I0905 09:04:11.278163 90901 sgd_solver.cpp:106] Iteration 41310, lr = 0.1
I0905 09:04:17.051904 90901 solver.cpp:228] Iteration 41320, loss = 0.249007
I0905 09:04:17.051970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249008 (* 1 = 0.249008 loss)
I0905 09:04:17.051985 90901 sgd_solver.cpp:106] Iteration 41320, lr = 0.1
I0905 09:04:22.956704 90901 solver.cpp:228] Iteration 41330, loss = 0.110272
I0905 09:04:22.956776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110273 (* 1 = 0.110273 loss)
I0905 09:04:22.956791 90901 sgd_solver.cpp:106] Iteration 41330, lr = 0.1
I0905 09:04:28.148058 90901 solver.cpp:228] Iteration 41340, loss = 0.59655
I0905 09:04:28.148119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.596551 (* 1 = 0.596551 loss)
I0905 09:04:28.148134 90901 sgd_solver.cpp:106] Iteration 41340, lr = 0.1
I0905 09:04:34.072270 90901 solver.cpp:228] Iteration 41350, loss = 0.161911
I0905 09:04:34.072336 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161912 (* 1 = 0.161912 loss)
I0905 09:04:34.072352 90901 sgd_solver.cpp:106] Iteration 41350, lr = 0.1
I0905 09:04:40.149129 90901 solver.cpp:228] Iteration 41360, loss = 0.267849
I0905 09:04:40.149307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267849 (* 1 = 0.267849 loss)
I0905 09:04:40.149348 90901 sgd_solver.cpp:106] Iteration 41360, lr = 0.1
I0905 09:04:46.177134 90901 solver.cpp:228] Iteration 41370, loss = 0.348571
I0905 09:04:46.177182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348571 (* 1 = 0.348571 loss)
I0905 09:04:46.177197 90901 sgd_solver.cpp:106] Iteration 41370, lr = 0.1
I0905 09:04:52.571089 90901 solver.cpp:228] Iteration 41380, loss = 0.291609
I0905 09:04:52.571149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29161 (* 1 = 0.29161 loss)
I0905 09:04:52.571164 90901 sgd_solver.cpp:106] Iteration 41380, lr = 0.1
I0905 09:04:58.310803 90901 solver.cpp:228] Iteration 41390, loss = 0.329403
I0905 09:04:58.310870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329403 (* 1 = 0.329403 loss)
I0905 09:04:58.310884 90901 sgd_solver.cpp:106] Iteration 41390, lr = 0.1
I0905 09:05:04.748955 90901 solver.cpp:228] Iteration 41400, loss = 0.188907
I0905 09:05:04.749018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188908 (* 1 = 0.188908 loss)
I0905 09:05:04.749044 90901 sgd_solver.cpp:106] Iteration 41400, lr = 0.1
I0905 09:05:10.822640 90901 solver.cpp:228] Iteration 41410, loss = 0.206904
I0905 09:05:10.822777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206904 (* 1 = 0.206904 loss)
I0905 09:05:10.822809 90901 sgd_solver.cpp:106] Iteration 41410, lr = 0.1
I0905 09:05:17.216547 90901 solver.cpp:228] Iteration 41420, loss = 0.0954438
I0905 09:05:17.216606 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0954446 (* 1 = 0.0954446 loss)
I0905 09:05:17.216624 90901 sgd_solver.cpp:106] Iteration 41420, lr = 0.1
I0905 09:05:23.277752 90901 solver.cpp:228] Iteration 41430, loss = 0.56561
I0905 09:05:23.277806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565611 (* 1 = 0.565611 loss)
I0905 09:05:23.277822 90901 sgd_solver.cpp:106] Iteration 41430, lr = 0.1
I0905 09:05:29.354358 90901 solver.cpp:228] Iteration 41440, loss = 0.299879
I0905 09:05:29.354423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29988 (* 1 = 0.29988 loss)
I0905 09:05:29.354435 90901 sgd_solver.cpp:106] Iteration 41440, lr = 0.1
I0905 09:05:35.730733 90901 solver.cpp:228] Iteration 41450, loss = 0.342721
I0905 09:05:35.730772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342722 (* 1 = 0.342722 loss)
I0905 09:05:35.730784 90901 sgd_solver.cpp:106] Iteration 41450, lr = 0.1
I0905 09:05:41.867903 90901 solver.cpp:228] Iteration 41460, loss = 0.610795
I0905 09:05:41.868080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.610796 (* 1 = 0.610796 loss)
I0905 09:05:41.868124 90901 sgd_solver.cpp:106] Iteration 41460, lr = 0.1
I0905 09:05:47.922314 90901 solver.cpp:228] Iteration 41470, loss = 0.359651
I0905 09:05:47.922392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359652 (* 1 = 0.359652 loss)
I0905 09:05:47.922407 90901 sgd_solver.cpp:106] Iteration 41470, lr = 0.1
I0905 09:05:53.970369 90901 solver.cpp:228] Iteration 41480, loss = 0.255502
I0905 09:05:53.970427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255503 (* 1 = 0.255503 loss)
I0905 09:05:53.970441 90901 sgd_solver.cpp:106] Iteration 41480, lr = 0.1
I0905 09:06:00.127274 90901 solver.cpp:228] Iteration 41490, loss = 0.48669
I0905 09:06:00.127317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486691 (* 1 = 0.486691 loss)
I0905 09:06:00.127331 90901 sgd_solver.cpp:106] Iteration 41490, lr = 0.1
I0905 09:06:06.149273 90901 solver.cpp:228] Iteration 41500, loss = 0.47525
I0905 09:06:06.149341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475251 (* 1 = 0.475251 loss)
I0905 09:06:06.149356 90901 sgd_solver.cpp:106] Iteration 41500, lr = 0.1
I0905 09:06:11.920527 90901 solver.cpp:228] Iteration 41510, loss = 0.376437
I0905 09:06:11.920694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376438 (* 1 = 0.376438 loss)
I0905 09:06:11.920730 90901 sgd_solver.cpp:106] Iteration 41510, lr = 0.1
I0905 09:06:17.174068 90901 solver.cpp:228] Iteration 41520, loss = 0.134332
I0905 09:06:17.174154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134333 (* 1 = 0.134333 loss)
I0905 09:06:17.174171 90901 sgd_solver.cpp:106] Iteration 41520, lr = 0.1
I0905 09:06:23.140499 90901 solver.cpp:228] Iteration 41530, loss = 0.514998
I0905 09:06:23.140555 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514998 (* 1 = 0.514998 loss)
I0905 09:06:23.140569 90901 sgd_solver.cpp:106] Iteration 41530, lr = 0.1
I0905 09:06:29.205768 90901 solver.cpp:228] Iteration 41540, loss = 0.339351
I0905 09:06:29.205824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339352 (* 1 = 0.339352 loss)
I0905 09:06:29.205837 90901 sgd_solver.cpp:106] Iteration 41540, lr = 0.1
I0905 09:06:35.320797 90901 solver.cpp:228] Iteration 41550, loss = 0.0539325
I0905 09:06:35.320857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0539333 (* 1 = 0.0539333 loss)
I0905 09:06:35.320873 90901 sgd_solver.cpp:106] Iteration 41550, lr = 0.1
I0905 09:06:41.428450 90901 solver.cpp:228] Iteration 41560, loss = 0.493495
I0905 09:06:41.428503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493496 (* 1 = 0.493496 loss)
I0905 09:06:41.428517 90901 sgd_solver.cpp:106] Iteration 41560, lr = 0.1
I0905 09:06:47.531801 90901 solver.cpp:228] Iteration 41570, loss = 0.23838
I0905 09:06:47.532011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23838 (* 1 = 0.23838 loss)
I0905 09:06:47.532042 90901 sgd_solver.cpp:106] Iteration 41570, lr = 0.1
I0905 09:06:53.897940 90901 solver.cpp:228] Iteration 41580, loss = 0.130007
I0905 09:06:53.897995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130007 (* 1 = 0.130007 loss)
I0905 09:06:53.898010 90901 sgd_solver.cpp:106] Iteration 41580, lr = 0.1
I0905 09:06:59.686401 90901 solver.cpp:228] Iteration 41590, loss = 0.235808
I0905 09:06:59.686460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235809 (* 1 = 0.235809 loss)
I0905 09:06:59.686473 90901 sgd_solver.cpp:106] Iteration 41590, lr = 0.1
I0905 09:07:05.903264 90901 solver.cpp:337] Iteration 41600, Testing net (#0)
I0905 09:07:48.116665 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.510312
I0905 09:07:48.116890 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.58618 (* 1 = 2.58618 loss)
I0905 09:07:48.407366 90901 solver.cpp:228] Iteration 41600, loss = 0.366278
I0905 09:07:48.407433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366279 (* 1 = 0.366279 loss)
I0905 09:07:48.407459 90901 sgd_solver.cpp:106] Iteration 41600, lr = 0.1
I0905 09:07:54.543275 90901 solver.cpp:228] Iteration 41610, loss = 0.131191
I0905 09:07:54.543335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131192 (* 1 = 0.131192 loss)
I0905 09:07:54.543351 90901 sgd_solver.cpp:106] Iteration 41610, lr = 0.1
I0905 09:07:59.989461 90901 solver.cpp:228] Iteration 41620, loss = 0.353532
I0905 09:07:59.989507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353533 (* 1 = 0.353533 loss)
I0905 09:07:59.989521 90901 sgd_solver.cpp:106] Iteration 41620, lr = 0.1
I0905 09:08:05.132396 90901 solver.cpp:228] Iteration 41630, loss = 0.777102
I0905 09:08:05.132438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.777102 (* 1 = 0.777102 loss)
I0905 09:08:05.132453 90901 sgd_solver.cpp:106] Iteration 41630, lr = 0.1
I0905 09:08:11.203649 90901 solver.cpp:228] Iteration 41640, loss = 0.2134
I0905 09:08:11.203706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213401 (* 1 = 0.213401 loss)
I0905 09:08:11.203722 90901 sgd_solver.cpp:106] Iteration 41640, lr = 0.1
I0905 09:08:17.276110 90901 solver.cpp:228] Iteration 41650, loss = 0.490831
I0905 09:08:17.276170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490832 (* 1 = 0.490832 loss)
I0905 09:08:17.276185 90901 sgd_solver.cpp:106] Iteration 41650, lr = 0.1
I0905 09:08:23.686553 90901 solver.cpp:228] Iteration 41660, loss = 0.375667
I0905 09:08:23.686764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375667 (* 1 = 0.375667 loss)
I0905 09:08:23.686782 90901 sgd_solver.cpp:106] Iteration 41660, lr = 0.1
I0905 09:08:29.726891 90901 solver.cpp:228] Iteration 41670, loss = 0.493319
I0905 09:08:29.726951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493319 (* 1 = 0.493319 loss)
I0905 09:08:29.726969 90901 sgd_solver.cpp:106] Iteration 41670, lr = 0.1
I0905 09:08:35.525589 90901 solver.cpp:228] Iteration 41680, loss = 0.362128
I0905 09:08:35.525647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362128 (* 1 = 0.362128 loss)
I0905 09:08:35.525665 90901 sgd_solver.cpp:106] Iteration 41680, lr = 0.1
I0905 09:08:41.922209 90901 solver.cpp:228] Iteration 41690, loss = 0.324389
I0905 09:08:41.922257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32439 (* 1 = 0.32439 loss)
I0905 09:08:41.922281 90901 sgd_solver.cpp:106] Iteration 41690, lr = 0.1
I0905 09:08:47.985139 90901 solver.cpp:228] Iteration 41700, loss = 0.350965
I0905 09:08:47.985174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350966 (* 1 = 0.350966 loss)
I0905 09:08:47.985186 90901 sgd_solver.cpp:106] Iteration 41700, lr = 0.1
I0905 09:08:54.086096 90901 solver.cpp:228] Iteration 41710, loss = 0.163503
I0905 09:08:54.086303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163504 (* 1 = 0.163504 loss)
I0905 09:08:54.086325 90901 sgd_solver.cpp:106] Iteration 41710, lr = 0.1
I0905 09:09:00.110177 90901 solver.cpp:228] Iteration 41720, loss = 0.145558
I0905 09:09:00.110230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145559 (* 1 = 0.145559 loss)
I0905 09:09:00.110244 90901 sgd_solver.cpp:106] Iteration 41720, lr = 0.1
I0905 09:09:06.205560 90901 solver.cpp:228] Iteration 41730, loss = 0.161356
I0905 09:09:06.205620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161357 (* 1 = 0.161357 loss)
I0905 09:09:06.205634 90901 sgd_solver.cpp:106] Iteration 41730, lr = 0.1
I0905 09:09:12.281523 90901 solver.cpp:228] Iteration 41740, loss = 0.184424
I0905 09:09:12.281572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184425 (* 1 = 0.184425 loss)
I0905 09:09:12.281585 90901 sgd_solver.cpp:106] Iteration 41740, lr = 0.1
I0905 09:09:18.363668 90901 solver.cpp:228] Iteration 41750, loss = 0.518403
I0905 09:09:18.363724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.518404 (* 1 = 0.518404 loss)
I0905 09:09:18.363737 90901 sgd_solver.cpp:106] Iteration 41750, lr = 0.1
I0905 09:09:24.732327 90901 solver.cpp:228] Iteration 41760, loss = 0.307656
I0905 09:09:24.732482 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307657 (* 1 = 0.307657 loss)
I0905 09:09:24.732524 90901 sgd_solver.cpp:106] Iteration 41760, lr = 0.1
I0905 09:09:30.813536 90901 solver.cpp:228] Iteration 41770, loss = 0.0578284
I0905 09:09:30.813580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0578293 (* 1 = 0.0578293 loss)
I0905 09:09:30.813593 90901 sgd_solver.cpp:106] Iteration 41770, lr = 0.1
I0905 09:09:36.866715 90901 solver.cpp:228] Iteration 41780, loss = 0.424311
I0905 09:09:36.866757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424312 (* 1 = 0.424312 loss)
I0905 09:09:36.866771 90901 sgd_solver.cpp:106] Iteration 41780, lr = 0.1
I0905 09:09:42.404942 90901 solver.cpp:228] Iteration 41790, loss = 0.37068
I0905 09:09:42.404999 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370681 (* 1 = 0.370681 loss)
I0905 09:09:42.405012 90901 sgd_solver.cpp:106] Iteration 41790, lr = 0.1
I0905 09:09:47.658370 90901 solver.cpp:228] Iteration 41800, loss = 0.139031
I0905 09:09:47.658430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139032 (* 1 = 0.139032 loss)
I0905 09:09:47.658447 90901 sgd_solver.cpp:106] Iteration 41800, lr = 0.1
I0905 09:09:53.362556 90901 solver.cpp:228] Iteration 41810, loss = 0.383537
I0905 09:09:53.362606 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383538 (* 1 = 0.383538 loss)
I0905 09:09:53.362618 90901 sgd_solver.cpp:106] Iteration 41810, lr = 0.1
I0905 09:09:59.767688 90901 solver.cpp:228] Iteration 41820, loss = 0.2428
I0905 09:09:59.767853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242801 (* 1 = 0.242801 loss)
I0905 09:09:59.767915 90901 sgd_solver.cpp:106] Iteration 41820, lr = 0.1
I0905 09:10:05.823120 90901 solver.cpp:228] Iteration 41830, loss = 0.275981
I0905 09:10:05.823163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275982 (* 1 = 0.275982 loss)
I0905 09:10:05.823174 90901 sgd_solver.cpp:106] Iteration 41830, lr = 0.1
I0905 09:10:11.894078 90901 solver.cpp:228] Iteration 41840, loss = 0.213538
I0905 09:10:11.894124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213539 (* 1 = 0.213539 loss)
I0905 09:10:11.894145 90901 sgd_solver.cpp:106] Iteration 41840, lr = 0.1
I0905 09:10:18.258599 90901 solver.cpp:228] Iteration 41850, loss = 0.137692
I0905 09:10:18.258638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137693 (* 1 = 0.137693 loss)
I0905 09:10:18.258647 90901 sgd_solver.cpp:106] Iteration 41850, lr = 0.1
I0905 09:10:24.338479 90901 solver.cpp:228] Iteration 41860, loss = 0.254753
I0905 09:10:24.338532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254754 (* 1 = 0.254754 loss)
I0905 09:10:24.338546 90901 sgd_solver.cpp:106] Iteration 41860, lr = 0.1
I0905 09:10:30.472121 90901 solver.cpp:228] Iteration 41870, loss = 0.214909
I0905 09:10:30.472250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21491 (* 1 = 0.21491 loss)
I0905 09:10:30.472301 90901 sgd_solver.cpp:106] Iteration 41870, lr = 0.1
I0905 09:10:36.476229 90901 solver.cpp:228] Iteration 41880, loss = 0.333268
I0905 09:10:36.476289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333268 (* 1 = 0.333268 loss)
I0905 09:10:36.476305 90901 sgd_solver.cpp:106] Iteration 41880, lr = 0.1
I0905 09:10:42.654269 90901 solver.cpp:228] Iteration 41890, loss = 0.628346
I0905 09:10:42.654320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.628347 (* 1 = 0.628347 loss)
I0905 09:10:42.654335 90901 sgd_solver.cpp:106] Iteration 41890, lr = 0.1
I0905 09:10:48.694850 90901 solver.cpp:228] Iteration 41900, loss = 0.236745
I0905 09:10:48.694908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236746 (* 1 = 0.236746 loss)
I0905 09:10:48.694923 90901 sgd_solver.cpp:106] Iteration 41900, lr = 0.1
I0905 09:10:54.781061 90901 solver.cpp:228] Iteration 41910, loss = 0.411609
I0905 09:10:54.781100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41161 (* 1 = 0.41161 loss)
I0905 09:10:54.781112 90901 sgd_solver.cpp:106] Iteration 41910, lr = 0.1
I0905 09:11:00.855316 90901 solver.cpp:228] Iteration 41920, loss = 0.283137
I0905 09:11:00.855604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283138 (* 1 = 0.283138 loss)
I0905 09:11:00.855621 90901 sgd_solver.cpp:106] Iteration 41920, lr = 0.1
I0905 09:11:07.028729 90901 solver.cpp:228] Iteration 41930, loss = 0.363502
I0905 09:11:07.028775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363503 (* 1 = 0.363503 loss)
I0905 09:11:07.028789 90901 sgd_solver.cpp:106] Iteration 41930, lr = 0.1
I0905 09:11:13.008179 90901 solver.cpp:228] Iteration 41940, loss = 0.175537
I0905 09:11:13.008226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175538 (* 1 = 0.175538 loss)
I0905 09:11:13.008240 90901 sgd_solver.cpp:106] Iteration 41940, lr = 0.1
I0905 09:11:19.110548 90901 solver.cpp:228] Iteration 41950, loss = 0.427764
I0905 09:11:19.110606 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427765 (* 1 = 0.427765 loss)
I0905 09:11:19.110620 90901 sgd_solver.cpp:106] Iteration 41950, lr = 0.1
I0905 09:11:25.172917 90901 solver.cpp:228] Iteration 41960, loss = 0.225003
I0905 09:11:25.172966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225004 (* 1 = 0.225004 loss)
I0905 09:11:25.172981 90901 sgd_solver.cpp:106] Iteration 41960, lr = 0.1
I0905 09:11:30.732893 90901 solver.cpp:228] Iteration 41970, loss = 0.352189
I0905 09:11:30.732954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.352189 (* 1 = 0.352189 loss)
I0905 09:11:30.732970 90901 sgd_solver.cpp:106] Iteration 41970, lr = 0.1
I0905 09:11:36.394345 90901 solver.cpp:228] Iteration 41980, loss = 0.0920885
I0905 09:11:36.394491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0920893 (* 1 = 0.0920893 loss)
I0905 09:11:36.394541 90901 sgd_solver.cpp:106] Iteration 41980, lr = 0.1
I0905 09:11:42.162384 90901 solver.cpp:228] Iteration 41990, loss = 0.197613
I0905 09:11:42.162436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197613 (* 1 = 0.197613 loss)
I0905 09:11:42.162451 90901 sgd_solver.cpp:106] Iteration 41990, lr = 0.1
I0905 09:11:48.555595 90901 solver.cpp:228] Iteration 42000, loss = 0.294357
I0905 09:11:48.555655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294358 (* 1 = 0.294358 loss)
I0905 09:11:48.555668 90901 sgd_solver.cpp:106] Iteration 42000, lr = 0.1
I0905 09:11:54.677214 90901 solver.cpp:228] Iteration 42010, loss = 0.42662
I0905 09:11:54.677268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426621 (* 1 = 0.426621 loss)
I0905 09:11:54.677280 90901 sgd_solver.cpp:106] Iteration 42010, lr = 0.1
I0905 09:12:00.739702 90901 solver.cpp:228] Iteration 42020, loss = 0.28277
I0905 09:12:00.739742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282771 (* 1 = 0.282771 loss)
I0905 09:12:00.739756 90901 sgd_solver.cpp:106] Iteration 42020, lr = 0.1
I0905 09:12:06.513633 90901 solver.cpp:228] Iteration 42030, loss = 0.417505
I0905 09:12:06.513809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417506 (* 1 = 0.417506 loss)
I0905 09:12:06.513837 90901 sgd_solver.cpp:106] Iteration 42030, lr = 0.1
I0905 09:12:12.570811 90901 solver.cpp:228] Iteration 42040, loss = 0.260552
I0905 09:12:12.570858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260553 (* 1 = 0.260553 loss)
I0905 09:12:12.570873 90901 sgd_solver.cpp:106] Iteration 42040, lr = 0.1
I0905 09:12:18.649986 90901 solver.cpp:228] Iteration 42050, loss = 0.186953
I0905 09:12:18.650054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186954 (* 1 = 0.186954 loss)
I0905 09:12:18.650068 90901 sgd_solver.cpp:106] Iteration 42050, lr = 0.1
I0905 09:12:25.024112 90901 solver.cpp:228] Iteration 42060, loss = 0.0625549
I0905 09:12:25.024175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0625557 (* 1 = 0.0625557 loss)
I0905 09:12:25.024189 90901 sgd_solver.cpp:106] Iteration 42060, lr = 0.1
I0905 09:12:31.103157 90901 solver.cpp:228] Iteration 42070, loss = 0.0820074
I0905 09:12:31.103212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0820082 (* 1 = 0.0820082 loss)
I0905 09:12:31.103227 90901 sgd_solver.cpp:106] Iteration 42070, lr = 0.1
I0905 09:12:36.868842 90901 solver.cpp:228] Iteration 42080, loss = 0.188956
I0905 09:12:36.869005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188957 (* 1 = 0.188957 loss)
I0905 09:12:36.869029 90901 sgd_solver.cpp:106] Iteration 42080, lr = 0.1
I0905 09:12:43.261461 90901 solver.cpp:228] Iteration 42090, loss = 0.353779
I0905 09:12:43.261512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35378 (* 1 = 0.35378 loss)
I0905 09:12:43.261524 90901 sgd_solver.cpp:106] Iteration 42090, lr = 0.1
I0905 09:12:49.637186 90901 solver.cpp:228] Iteration 42100, loss = 0.279203
I0905 09:12:49.637225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279204 (* 1 = 0.279204 loss)
I0905 09:12:49.637238 90901 sgd_solver.cpp:106] Iteration 42100, lr = 0.1
I0905 09:12:55.423382 90901 solver.cpp:228] Iteration 42110, loss = 0.839651
I0905 09:12:55.423436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.839652 (* 1 = 0.839652 loss)
I0905 09:12:55.423450 90901 sgd_solver.cpp:106] Iteration 42110, lr = 0.1
I0905 09:13:01.807981 90901 solver.cpp:228] Iteration 42120, loss = 0.108135
I0905 09:13:01.808029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108136 (* 1 = 0.108136 loss)
I0905 09:13:01.808043 90901 sgd_solver.cpp:106] Iteration 42120, lr = 0.1
I0905 09:13:07.863801 90901 solver.cpp:228] Iteration 42130, loss = 0.253503
I0905 09:13:07.863952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253504 (* 1 = 0.253504 loss)
I0905 09:13:07.863978 90901 sgd_solver.cpp:106] Iteration 42130, lr = 0.1
I0905 09:13:13.883621 90901 solver.cpp:228] Iteration 42140, loss = 0.273564
I0905 09:13:13.883671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273565 (* 1 = 0.273565 loss)
I0905 09:13:13.883684 90901 sgd_solver.cpp:106] Iteration 42140, lr = 0.1
I0905 09:13:19.360738 90901 solver.cpp:228] Iteration 42150, loss = 0.115302
I0905 09:13:19.360791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115303 (* 1 = 0.115303 loss)
I0905 09:13:19.360805 90901 sgd_solver.cpp:106] Iteration 42150, lr = 0.1
I0905 09:13:24.820822 90901 solver.cpp:228] Iteration 42160, loss = 0.0936883
I0905 09:13:24.820865 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.093689 (* 1 = 0.093689 loss)
I0905 09:13:24.820879 90901 sgd_solver.cpp:106] Iteration 42160, lr = 0.1
I0905 09:13:31.202103 90901 solver.cpp:228] Iteration 42170, loss = 0.31075
I0905 09:13:31.202154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31075 (* 1 = 0.31075 loss)
I0905 09:13:31.202168 90901 sgd_solver.cpp:106] Iteration 42170, lr = 0.1
I0905 09:13:37.295835 90901 solver.cpp:228] Iteration 42180, loss = 0.188748
I0905 09:13:37.295899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188748 (* 1 = 0.188748 loss)
I0905 09:13:37.295914 90901 sgd_solver.cpp:106] Iteration 42180, lr = 0.1
I0905 09:13:43.344409 90901 solver.cpp:228] Iteration 42190, loss = 0.101767
I0905 09:13:43.344673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101768 (* 1 = 0.101768 loss)
I0905 09:13:43.344689 90901 sgd_solver.cpp:106] Iteration 42190, lr = 0.1
I0905 09:13:49.394099 90901 solver.cpp:228] Iteration 42200, loss = 0.48693
I0905 09:13:49.394140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.486931 (* 1 = 0.486931 loss)
I0905 09:13:49.394155 90901 sgd_solver.cpp:106] Iteration 42200, lr = 0.1
I0905 09:13:55.158290 90901 solver.cpp:228] Iteration 42210, loss = 0.328065
I0905 09:13:55.158342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328066 (* 1 = 0.328066 loss)
I0905 09:13:55.158355 90901 sgd_solver.cpp:106] Iteration 42210, lr = 0.1
I0905 09:14:01.265811 90901 solver.cpp:228] Iteration 42220, loss = 0.138961
I0905 09:14:01.265871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138961 (* 1 = 0.138961 loss)
I0905 09:14:01.265884 90901 sgd_solver.cpp:106] Iteration 42220, lr = 0.1
I0905 09:14:07.657631 90901 solver.cpp:228] Iteration 42230, loss = 0.280309
I0905 09:14:07.657666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28031 (* 1 = 0.28031 loss)
I0905 09:14:07.657682 90901 sgd_solver.cpp:106] Iteration 42230, lr = 0.1
I0905 09:14:13.383704 90901 solver.cpp:228] Iteration 42240, loss = 0.377809
I0905 09:14:13.383836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37781 (* 1 = 0.37781 loss)
I0905 09:14:13.383869 90901 sgd_solver.cpp:106] Iteration 42240, lr = 0.1
I0905 09:14:20.143204 90901 solver.cpp:228] Iteration 42250, loss = 0.136317
I0905 09:14:20.143301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136317 (* 1 = 0.136317 loss)
I0905 09:14:20.143329 90901 sgd_solver.cpp:106] Iteration 42250, lr = 0.1
I0905 09:14:25.881088 90901 solver.cpp:228] Iteration 42260, loss = 0.174405
I0905 09:14:25.881132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174405 (* 1 = 0.174405 loss)
I0905 09:14:25.881145 90901 sgd_solver.cpp:106] Iteration 42260, lr = 0.1
I0905 09:14:31.950739 90901 solver.cpp:228] Iteration 42270, loss = 0.369566
I0905 09:14:31.950785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369566 (* 1 = 0.369566 loss)
I0905 09:14:31.950799 90901 sgd_solver.cpp:106] Iteration 42270, lr = 0.1
I0905 09:14:38.341672 90901 solver.cpp:228] Iteration 42280, loss = 0.257979
I0905 09:14:38.341724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25798 (* 1 = 0.25798 loss)
I0905 09:14:38.341738 90901 sgd_solver.cpp:106] Iteration 42280, lr = 0.1
I0905 09:14:44.427244 90901 solver.cpp:228] Iteration 42290, loss = 0.338012
I0905 09:14:44.427474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338013 (* 1 = 0.338013 loss)
I0905 09:14:44.427489 90901 sgd_solver.cpp:106] Iteration 42290, lr = 0.1
I0905 09:14:50.507004 90901 solver.cpp:228] Iteration 42300, loss = 0.479782
I0905 09:14:50.507048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.479783 (* 1 = 0.479783 loss)
I0905 09:14:50.507062 90901 sgd_solver.cpp:106] Iteration 42300, lr = 0.1
I0905 09:14:56.585639 90901 solver.cpp:228] Iteration 42310, loss = 0.337138
I0905 09:14:56.585681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337139 (* 1 = 0.337139 loss)
I0905 09:14:56.585693 90901 sgd_solver.cpp:106] Iteration 42310, lr = 0.1
I0905 09:15:02.376585 90901 solver.cpp:228] Iteration 42320, loss = 0.0853176
I0905 09:15:02.376631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853183 (* 1 = 0.0853183 loss)
I0905 09:15:02.376644 90901 sgd_solver.cpp:106] Iteration 42320, lr = 0.1
I0905 09:15:07.642390 90901 solver.cpp:228] Iteration 42330, loss = 0.407515
I0905 09:15:07.642438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407516 (* 1 = 0.407516 loss)
I0905 09:15:07.642453 90901 sgd_solver.cpp:106] Iteration 42330, lr = 0.1
I0905 09:15:13.619910 90901 solver.cpp:228] Iteration 42340, loss = 0.27573
I0905 09:15:13.619958 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275731 (* 1 = 0.275731 loss)
I0905 09:15:13.619971 90901 sgd_solver.cpp:106] Iteration 42340, lr = 0.1
I0905 09:15:19.712626 90901 solver.cpp:228] Iteration 42350, loss = 0.51558
I0905 09:15:19.712817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515581 (* 1 = 0.515581 loss)
I0905 09:15:19.712857 90901 sgd_solver.cpp:106] Iteration 42350, lr = 0.1
I0905 09:15:25.938371 90901 solver.cpp:228] Iteration 42360, loss = 0.282068
I0905 09:15:25.938421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282069 (* 1 = 0.282069 loss)
I0905 09:15:25.938433 90901 sgd_solver.cpp:106] Iteration 42360, lr = 0.1
I0905 09:15:31.845052 90901 solver.cpp:228] Iteration 42370, loss = 0.210393
I0905 09:15:31.845098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210394 (* 1 = 0.210394 loss)
I0905 09:15:31.845111 90901 sgd_solver.cpp:106] Iteration 42370, lr = 0.1
I0905 09:15:38.192811 90901 solver.cpp:228] Iteration 42380, loss = 0.22396
I0905 09:15:38.192860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223961 (* 1 = 0.223961 loss)
I0905 09:15:38.192873 90901 sgd_solver.cpp:106] Iteration 42380, lr = 0.1
I0905 09:15:44.250740 90901 solver.cpp:228] Iteration 42390, loss = 0.166488
I0905 09:15:44.250810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166488 (* 1 = 0.166488 loss)
I0905 09:15:44.250824 90901 sgd_solver.cpp:106] Iteration 42390, lr = 0.1
I0905 09:15:50.043727 90901 solver.cpp:337] Iteration 42400, Testing net (#0)
I0905 09:16:32.195888 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.871562
I0905 09:16:32.196059 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.308654 (* 1 = 0.308654 loss)
I0905 09:16:32.413048 90901 solver.cpp:228] Iteration 42400, loss = 0.495097
I0905 09:16:32.413120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.495098 (* 1 = 0.495098 loss)
I0905 09:16:32.413141 90901 sgd_solver.cpp:106] Iteration 42400, lr = 0.1
I0905 09:16:38.230578 90901 solver.cpp:228] Iteration 42410, loss = 0.815196
I0905 09:16:38.230638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.815197 (* 1 = 0.815197 loss)
I0905 09:16:38.230654 90901 sgd_solver.cpp:106] Iteration 42410, lr = 0.1
I0905 09:16:44.638094 90901 solver.cpp:228] Iteration 42420, loss = 0.356709
I0905 09:16:44.638139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35671 (* 1 = 0.35671 loss)
I0905 09:16:44.638151 90901 sgd_solver.cpp:106] Iteration 42420, lr = 0.1
I0905 09:16:50.325901 90901 solver.cpp:228] Iteration 42430, loss = 0.131302
I0905 09:16:50.325960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131303 (* 1 = 0.131303 loss)
I0905 09:16:50.325974 90901 sgd_solver.cpp:106] Iteration 42430, lr = 0.1
I0905 09:16:55.896314 90901 solver.cpp:228] Iteration 42440, loss = 0.231532
I0905 09:16:55.896373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231533 (* 1 = 0.231533 loss)
I0905 09:16:55.896389 90901 sgd_solver.cpp:106] Iteration 42440, lr = 0.1
I0905 09:17:01.529793 90901 solver.cpp:228] Iteration 42450, loss = 0.336457
I0905 09:17:01.529840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336458 (* 1 = 0.336458 loss)
I0905 09:17:01.529853 90901 sgd_solver.cpp:106] Iteration 42450, lr = 0.1
I0905 09:17:07.843116 90901 solver.cpp:228] Iteration 42460, loss = 0.23565
I0905 09:17:07.843202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235651 (* 1 = 0.235651 loss)
I0905 09:17:07.843217 90901 sgd_solver.cpp:106] Iteration 42460, lr = 0.1
I0905 09:17:13.912691 90901 solver.cpp:228] Iteration 42470, loss = 0.220322
I0905 09:17:13.912735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220322 (* 1 = 0.220322 loss)
I0905 09:17:13.912750 90901 sgd_solver.cpp:106] Iteration 42470, lr = 0.1
I0905 09:17:19.958446 90901 solver.cpp:228] Iteration 42480, loss = 0.433989
I0905 09:17:19.958499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43399 (* 1 = 0.43399 loss)
I0905 09:17:19.958514 90901 sgd_solver.cpp:106] Iteration 42480, lr = 0.1
I0905 09:17:26.346720 90901 solver.cpp:228] Iteration 42490, loss = 0.264475
I0905 09:17:26.346777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264475 (* 1 = 0.264475 loss)
I0905 09:17:26.346791 90901 sgd_solver.cpp:106] Iteration 42490, lr = 0.1
I0905 09:17:32.415798 90901 solver.cpp:228] Iteration 42500, loss = 0.335969
I0905 09:17:32.415844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33597 (* 1 = 0.33597 loss)
I0905 09:17:32.415858 90901 sgd_solver.cpp:106] Iteration 42500, lr = 0.1
I0905 09:17:38.516239 90901 solver.cpp:228] Iteration 42510, loss = 0.626675
I0905 09:17:38.516449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.626675 (* 1 = 0.626675 loss)
I0905 09:17:38.516474 90901 sgd_solver.cpp:106] Iteration 42510, lr = 0.1
I0905 09:17:44.609715 90901 solver.cpp:228] Iteration 42520, loss = 0.463173
I0905 09:17:44.609760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463174 (* 1 = 0.463174 loss)
I0905 09:17:44.609774 90901 sgd_solver.cpp:106] Iteration 42520, lr = 0.1
I0905 09:17:50.679064 90901 solver.cpp:228] Iteration 42530, loss = 0.118261
I0905 09:17:50.679129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118261 (* 1 = 0.118261 loss)
I0905 09:17:50.679147 90901 sgd_solver.cpp:106] Iteration 42530, lr = 0.1
I0905 09:17:56.785866 90901 solver.cpp:228] Iteration 42540, loss = 0.27712
I0905 09:17:56.785908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277121 (* 1 = 0.277121 loss)
I0905 09:17:56.785920 90901 sgd_solver.cpp:106] Iteration 42540, lr = 0.1
I0905 09:18:02.541120 90901 solver.cpp:228] Iteration 42550, loss = 0.741042
I0905 09:18:02.541178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.741043 (* 1 = 0.741043 loss)
I0905 09:18:02.541193 90901 sgd_solver.cpp:106] Iteration 42550, lr = 0.1
I0905 09:18:08.929273 90901 solver.cpp:228] Iteration 42560, loss = 0.436313
I0905 09:18:08.929417 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436314 (* 1 = 0.436314 loss)
I0905 09:18:08.929456 90901 sgd_solver.cpp:106] Iteration 42560, lr = 0.1
I0905 09:18:15.050073 90901 solver.cpp:228] Iteration 42570, loss = 0.371168
I0905 09:18:15.050139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371169 (* 1 = 0.371169 loss)
I0905 09:18:15.050155 90901 sgd_solver.cpp:106] Iteration 42570, lr = 0.1
I0905 09:18:21.176731 90901 solver.cpp:228] Iteration 42580, loss = 0.242982
I0905 09:18:21.176791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242983 (* 1 = 0.242983 loss)
I0905 09:18:21.176805 90901 sgd_solver.cpp:106] Iteration 42580, lr = 0.1
I0905 09:18:27.192109 90901 solver.cpp:228] Iteration 42590, loss = 0.201659
I0905 09:18:27.192178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20166 (* 1 = 0.20166 loss)
I0905 09:18:27.192193 90901 sgd_solver.cpp:106] Iteration 42590, lr = 0.1
I0905 09:18:33.252039 90901 solver.cpp:228] Iteration 42600, loss = 0.29276
I0905 09:18:33.252099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292761 (* 1 = 0.292761 loss)
I0905 09:18:33.252113 90901 sgd_solver.cpp:106] Iteration 42600, lr = 0.1
I0905 09:18:38.983973 90901 solver.cpp:228] Iteration 42610, loss = 0.452775
I0905 09:18:38.984109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.452775 (* 1 = 0.452775 loss)
I0905 09:18:38.984146 90901 sgd_solver.cpp:106] Iteration 42610, lr = 0.1
I0905 09:18:44.560235 90901 solver.cpp:228] Iteration 42620, loss = 0.34537
I0905 09:18:44.560278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345371 (* 1 = 0.345371 loss)
I0905 09:18:44.560292 90901 sgd_solver.cpp:106] Iteration 42620, lr = 0.1
I0905 09:18:50.262022 90901 solver.cpp:228] Iteration 42630, loss = 0.174055
I0905 09:18:50.262079 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174056 (* 1 = 0.174056 loss)
I0905 09:18:50.262094 90901 sgd_solver.cpp:106] Iteration 42630, lr = 0.1
I0905 09:18:56.343058 90901 solver.cpp:228] Iteration 42640, loss = 0.240196
I0905 09:18:56.343111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240197 (* 1 = 0.240197 loss)
I0905 09:18:56.343124 90901 sgd_solver.cpp:106] Iteration 42640, lr = 0.1
I0905 09:19:02.765228 90901 solver.cpp:228] Iteration 42650, loss = 0.146911
I0905 09:19:02.765261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146911 (* 1 = 0.146911 loss)
I0905 09:19:02.765276 90901 sgd_solver.cpp:106] Iteration 42650, lr = 0.1
I0905 09:19:08.837427 90901 solver.cpp:228] Iteration 42660, loss = 0.322641
I0905 09:19:08.837486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322641 (* 1 = 0.322641 loss)
I0905 09:19:08.837505 90901 sgd_solver.cpp:106] Iteration 42660, lr = 0.1
I0905 09:19:14.892354 90901 solver.cpp:228] Iteration 42670, loss = 0.236668
I0905 09:19:14.892525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236669 (* 1 = 0.236669 loss)
I0905 09:19:14.892540 90901 sgd_solver.cpp:106] Iteration 42670, lr = 0.1
I0905 09:19:20.957674 90901 solver.cpp:228] Iteration 42680, loss = 0.138829
I0905 09:19:20.957722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13883 (* 1 = 0.13883 loss)
I0905 09:19:20.957736 90901 sgd_solver.cpp:106] Iteration 42680, lr = 0.1
I0905 09:19:27.049046 90901 solver.cpp:228] Iteration 42690, loss = 0.13994
I0905 09:19:27.049098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139941 (* 1 = 0.139941 loss)
I0905 09:19:27.049111 90901 sgd_solver.cpp:106] Iteration 42690, lr = 0.1
I0905 09:19:33.219735 90901 solver.cpp:228] Iteration 42700, loss = 0.474375
I0905 09:19:33.219784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.474376 (* 1 = 0.474376 loss)
I0905 09:19:33.219799 90901 sgd_solver.cpp:106] Iteration 42700, lr = 0.1
I0905 09:19:39.563577 90901 solver.cpp:228] Iteration 42710, loss = 0.341792
I0905 09:19:39.563640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341792 (* 1 = 0.341792 loss)
I0905 09:19:39.563653 90901 sgd_solver.cpp:106] Iteration 42710, lr = 0.1
I0905 09:19:45.637814 90901 solver.cpp:228] Iteration 42720, loss = 0.305832
I0905 09:19:45.637982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305833 (* 1 = 0.305833 loss)
I0905 09:19:45.638003 90901 sgd_solver.cpp:106] Iteration 42720, lr = 0.1
I0905 09:19:51.691138 90901 solver.cpp:228] Iteration 42730, loss = 0.309163
I0905 09:19:51.691190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309164 (* 1 = 0.309164 loss)
I0905 09:19:51.691205 90901 sgd_solver.cpp:106] Iteration 42730, lr = 0.1
I0905 09:19:57.778209 90901 solver.cpp:228] Iteration 42740, loss = 0.227077
I0905 09:19:57.778280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227078 (* 1 = 0.227078 loss)
I0905 09:19:57.778295 90901 sgd_solver.cpp:106] Iteration 42740, lr = 0.1
I0905 09:20:03.827590 90901 solver.cpp:228] Iteration 42750, loss = 0.092624
I0905 09:20:03.827644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0926249 (* 1 = 0.0926249 loss)
I0905 09:20:03.827658 90901 sgd_solver.cpp:106] Iteration 42750, lr = 0.1
I0905 09:20:09.885279 90901 solver.cpp:228] Iteration 42760, loss = 0.100169
I0905 09:20:09.885314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10017 (* 1 = 0.10017 loss)
I0905 09:20:09.885327 90901 sgd_solver.cpp:106] Iteration 42760, lr = 0.1
I0905 09:20:15.978711 90901 solver.cpp:228] Iteration 42770, loss = 0.196978
I0905 09:20:15.978880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196978 (* 1 = 0.196978 loss)
I0905 09:20:15.978919 90901 sgd_solver.cpp:106] Iteration 42770, lr = 0.1
I0905 09:20:22.394204 90901 solver.cpp:228] Iteration 42780, loss = 0.117225
I0905 09:20:22.394271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117226 (* 1 = 0.117226 loss)
I0905 09:20:22.394289 90901 sgd_solver.cpp:106] Iteration 42780, lr = 0.1
I0905 09:20:27.058075 90901 solver.cpp:228] Iteration 42790, loss = 0.38111
I0905 09:20:27.058138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381111 (* 1 = 0.381111 loss)
I0905 09:20:27.058152 90901 sgd_solver.cpp:106] Iteration 42790, lr = 0.1
I0905 09:20:31.708746 90901 solver.cpp:228] Iteration 42800, loss = 0.422146
I0905 09:20:31.708803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422147 (* 1 = 0.422147 loss)
I0905 09:20:31.708817 90901 sgd_solver.cpp:106] Iteration 42800, lr = 0.1
I0905 09:20:36.517326 90901 solver.cpp:228] Iteration 42810, loss = 0.517099
I0905 09:20:36.517371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.5171 (* 1 = 0.5171 loss)
I0905 09:20:36.517384 90901 sgd_solver.cpp:106] Iteration 42810, lr = 0.1
I0905 09:20:41.602428 90901 solver.cpp:228] Iteration 42820, loss = 0.15642
I0905 09:20:41.602470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156421 (* 1 = 0.156421 loss)
I0905 09:20:41.602483 90901 sgd_solver.cpp:106] Iteration 42820, lr = 0.1
I0905 09:20:46.670948 90901 solver.cpp:228] Iteration 42830, loss = 0.222198
I0905 09:20:46.671241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222199 (* 1 = 0.222199 loss)
I0905 09:20:46.671258 90901 sgd_solver.cpp:106] Iteration 42830, lr = 0.1
I0905 09:20:51.695385 90901 solver.cpp:228] Iteration 42840, loss = 0.271689
I0905 09:20:51.695446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271689 (* 1 = 0.271689 loss)
I0905 09:20:51.695459 90901 sgd_solver.cpp:106] Iteration 42840, lr = 0.1
I0905 09:20:56.739884 90901 solver.cpp:228] Iteration 42850, loss = 0.246376
I0905 09:20:56.739944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246377 (* 1 = 0.246377 loss)
I0905 09:20:56.739962 90901 sgd_solver.cpp:106] Iteration 42850, lr = 0.1
I0905 09:21:01.773567 90901 solver.cpp:228] Iteration 42860, loss = 0.206145
I0905 09:21:01.773625 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206146 (* 1 = 0.206146 loss)
I0905 09:21:01.773640 90901 sgd_solver.cpp:106] Iteration 42860, lr = 0.1
I0905 09:21:06.849278 90901 solver.cpp:228] Iteration 42870, loss = 0.921807
I0905 09:21:06.849334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.921808 (* 1 = 0.921808 loss)
I0905 09:21:06.849349 90901 sgd_solver.cpp:106] Iteration 42870, lr = 0.1
I0905 09:21:11.923387 90901 solver.cpp:228] Iteration 42880, loss = 0.296963
I0905 09:21:11.923452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296964 (* 1 = 0.296964 loss)
I0905 09:21:11.923467 90901 sgd_solver.cpp:106] Iteration 42880, lr = 0.1
I0905 09:21:16.983348 90901 solver.cpp:228] Iteration 42890, loss = 0.691488
I0905 09:21:16.983526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.691489 (* 1 = 0.691489 loss)
I0905 09:21:16.983568 90901 sgd_solver.cpp:106] Iteration 42890, lr = 0.1
I0905 09:21:22.070987 90901 solver.cpp:228] Iteration 42900, loss = 0.113725
I0905 09:21:22.071063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113726 (* 1 = 0.113726 loss)
I0905 09:21:22.071079 90901 sgd_solver.cpp:106] Iteration 42900, lr = 0.1
I0905 09:21:27.161509 90901 solver.cpp:228] Iteration 42910, loss = 0.596473
I0905 09:21:27.161566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.596474 (* 1 = 0.596474 loss)
I0905 09:21:27.161581 90901 sgd_solver.cpp:106] Iteration 42910, lr = 0.1
I0905 09:21:32.216109 90901 solver.cpp:228] Iteration 42920, loss = 0.501378
I0905 09:21:32.216162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501379 (* 1 = 0.501379 loss)
I0905 09:21:32.216176 90901 sgd_solver.cpp:106] Iteration 42920, lr = 0.1
I0905 09:21:37.241367 90901 solver.cpp:228] Iteration 42930, loss = 0.845133
I0905 09:21:37.241436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.845134 (* 1 = 0.845134 loss)
I0905 09:21:37.241451 90901 sgd_solver.cpp:106] Iteration 42930, lr = 0.1
I0905 09:21:42.294929 90901 solver.cpp:228] Iteration 42940, loss = 0.206972
I0905 09:21:42.294991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206973 (* 1 = 0.206973 loss)
I0905 09:21:42.295006 90901 sgd_solver.cpp:106] Iteration 42940, lr = 0.1
I0905 09:21:47.659926 90901 solver.cpp:228] Iteration 42950, loss = 0.512561
I0905 09:21:47.660169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.512561 (* 1 = 0.512561 loss)
I0905 09:21:47.660194 90901 sgd_solver.cpp:106] Iteration 42950, lr = 0.1
I0905 09:21:53.779284 90901 solver.cpp:228] Iteration 42960, loss = 0.252363
I0905 09:21:53.779340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252364 (* 1 = 0.252364 loss)
I0905 09:21:53.779353 90901 sgd_solver.cpp:106] Iteration 42960, lr = 0.1
I0905 09:21:59.873988 90901 solver.cpp:228] Iteration 42970, loss = 0.164298
I0905 09:21:59.874058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164298 (* 1 = 0.164298 loss)
I0905 09:21:59.874073 90901 sgd_solver.cpp:106] Iteration 42970, lr = 0.1
I0905 09:22:05.988152 90901 solver.cpp:228] Iteration 42980, loss = 0.190111
I0905 09:22:05.988205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190112 (* 1 = 0.190112 loss)
I0905 09:22:05.988219 90901 sgd_solver.cpp:106] Iteration 42980, lr = 0.1
I0905 09:22:12.064249 90901 solver.cpp:228] Iteration 42990, loss = 0.161298
I0905 09:22:12.064313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161299 (* 1 = 0.161299 loss)
I0905 09:22:12.064329 90901 sgd_solver.cpp:106] Iteration 42990, lr = 0.1
I0905 09:22:17.790402 90901 solver.cpp:228] Iteration 43000, loss = 0.213732
I0905 09:22:17.790567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213733 (* 1 = 0.213733 loss)
I0905 09:22:17.790598 90901 sgd_solver.cpp:106] Iteration 43000, lr = 0.1
I0905 09:22:23.253337 90901 solver.cpp:228] Iteration 43010, loss = 0.243431
I0905 09:22:23.253386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243432 (* 1 = 0.243432 loss)
I0905 09:22:23.253399 90901 sgd_solver.cpp:106] Iteration 43010, lr = 0.1
I0905 09:22:29.295276 90901 solver.cpp:228] Iteration 43020, loss = 0.34724
I0905 09:22:29.295361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347241 (* 1 = 0.347241 loss)
I0905 09:22:29.295377 90901 sgd_solver.cpp:106] Iteration 43020, lr = 0.1
I0905 09:22:35.391196 90901 solver.cpp:228] Iteration 43030, loss = 0.158534
I0905 09:22:35.391273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158535 (* 1 = 0.158535 loss)
I0905 09:22:35.391289 90901 sgd_solver.cpp:106] Iteration 43030, lr = 0.1
I0905 09:22:41.445375 90901 solver.cpp:228] Iteration 43040, loss = 0.3982
I0905 09:22:41.445448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3982 (* 1 = 0.3982 loss)
I0905 09:22:41.445464 90901 sgd_solver.cpp:106] Iteration 43040, lr = 0.1
I0905 09:22:47.552291 90901 solver.cpp:228] Iteration 43050, loss = 0.241814
I0905 09:22:47.552351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241815 (* 1 = 0.241815 loss)
I0905 09:22:47.552366 90901 sgd_solver.cpp:106] Iteration 43050, lr = 0.1
I0905 09:22:53.424084 90901 solver.cpp:228] Iteration 43060, loss = 0.317294
I0905 09:22:53.424264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317295 (* 1 = 0.317295 loss)
I0905 09:22:53.424281 90901 sgd_solver.cpp:106] Iteration 43060, lr = 0.1
I0905 09:22:59.623594 90901 solver.cpp:228] Iteration 43070, loss = 0.132214
I0905 09:22:59.623647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132215 (* 1 = 0.132215 loss)
I0905 09:22:59.623662 90901 sgd_solver.cpp:106] Iteration 43070, lr = 0.1
I0905 09:23:05.662284 90901 solver.cpp:228] Iteration 43080, loss = 0.1865
I0905 09:23:05.662349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186501 (* 1 = 0.186501 loss)
I0905 09:23:05.662364 90901 sgd_solver.cpp:106] Iteration 43080, lr = 0.1
I0905 09:23:12.021909 90901 solver.cpp:228] Iteration 43090, loss = 0.442544
I0905 09:23:12.021957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442545 (* 1 = 0.442545 loss)
I0905 09:23:12.021970 90901 sgd_solver.cpp:106] Iteration 43090, lr = 0.1
I0905 09:23:18.137644 90901 solver.cpp:228] Iteration 43100, loss = 0.140143
I0905 09:23:18.137692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140144 (* 1 = 0.140144 loss)
I0905 09:23:18.137708 90901 sgd_solver.cpp:106] Iteration 43100, lr = 0.1
I0905 09:23:24.177840 90901 solver.cpp:228] Iteration 43110, loss = 0.27911
I0905 09:23:24.178118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279111 (* 1 = 0.279111 loss)
I0905 09:23:24.178145 90901 sgd_solver.cpp:106] Iteration 43110, lr = 0.1
I0905 09:23:30.245383 90901 solver.cpp:228] Iteration 43120, loss = 0.239729
I0905 09:23:30.245425 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23973 (* 1 = 0.23973 loss)
I0905 09:23:30.245440 90901 sgd_solver.cpp:106] Iteration 43120, lr = 0.1
I0905 09:23:36.316251 90901 solver.cpp:228] Iteration 43130, loss = 0.403055
I0905 09:23:36.316320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403056 (* 1 = 0.403056 loss)
I0905 09:23:36.316337 90901 sgd_solver.cpp:106] Iteration 43130, lr = 0.1
I0905 09:23:42.440636 90901 solver.cpp:228] Iteration 43140, loss = 0.34618
I0905 09:23:42.440687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346181 (* 1 = 0.346181 loss)
I0905 09:23:42.440706 90901 sgd_solver.cpp:106] Iteration 43140, lr = 0.1
I0905 09:23:48.552125 90901 solver.cpp:228] Iteration 43150, loss = 0.291762
I0905 09:23:48.552189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291763 (* 1 = 0.291763 loss)
I0905 09:23:48.552204 90901 sgd_solver.cpp:106] Iteration 43150, lr = 0.1
I0905 09:23:54.467425 90901 solver.cpp:228] Iteration 43160, loss = 0.241958
I0905 09:23:54.467643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241959 (* 1 = 0.241959 loss)
I0905 09:23:54.467660 90901 sgd_solver.cpp:106] Iteration 43160, lr = 0.1
I0905 09:24:00.583021 90901 solver.cpp:228] Iteration 43170, loss = 0.362539
I0905 09:24:00.583061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36254 (* 1 = 0.36254 loss)
I0905 09:24:00.583076 90901 sgd_solver.cpp:106] Iteration 43170, lr = 0.1
I0905 09:24:05.948843 90901 solver.cpp:228] Iteration 43180, loss = 0.482186
I0905 09:24:05.948890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482187 (* 1 = 0.482187 loss)
I0905 09:24:05.948904 90901 sgd_solver.cpp:106] Iteration 43180, lr = 0.1
I0905 09:24:11.300840 90901 solver.cpp:228] Iteration 43190, loss = 0.121494
I0905 09:24:11.300885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121495 (* 1 = 0.121495 loss)
I0905 09:24:11.300899 90901 sgd_solver.cpp:106] Iteration 43190, lr = 0.1
I0905 09:24:16.823614 90901 solver.cpp:337] Iteration 43200, Testing net (#0)
I0905 09:24:59.284044 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.82375
I0905 09:24:59.284240 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.420268 (* 1 = 0.420268 loss)
I0905 09:24:59.503353 90901 solver.cpp:228] Iteration 43200, loss = 0.215492
I0905 09:24:59.503409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215493 (* 1 = 0.215493 loss)
I0905 09:24:59.503427 90901 sgd_solver.cpp:106] Iteration 43200, lr = 0.1
I0905 09:25:05.606916 90901 solver.cpp:228] Iteration 43210, loss = 0.342942
I0905 09:25:05.606972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342943 (* 1 = 0.342943 loss)
I0905 09:25:05.606987 90901 sgd_solver.cpp:106] Iteration 43210, lr = 0.1
I0905 09:25:11.686841 90901 solver.cpp:228] Iteration 43220, loss = 0.418817
I0905 09:25:11.686900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418818 (* 1 = 0.418818 loss)
I0905 09:25:11.686915 90901 sgd_solver.cpp:106] Iteration 43220, lr = 0.1
I0905 09:25:18.085610 90901 solver.cpp:228] Iteration 43230, loss = 0.331671
I0905 09:25:18.085664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331672 (* 1 = 0.331672 loss)
I0905 09:25:18.085677 90901 sgd_solver.cpp:106] Iteration 43230, lr = 0.1
I0905 09:25:24.121484 90901 solver.cpp:228] Iteration 43240, loss = 0.457292
I0905 09:25:24.121544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457293 (* 1 = 0.457293 loss)
I0905 09:25:24.121562 90901 sgd_solver.cpp:106] Iteration 43240, lr = 0.1
I0905 09:25:30.215186 90901 solver.cpp:228] Iteration 43250, loss = 0.121236
I0905 09:25:30.215363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121237 (* 1 = 0.121237 loss)
I0905 09:25:30.215391 90901 sgd_solver.cpp:106] Iteration 43250, lr = 0.1
I0905 09:25:35.942354 90901 solver.cpp:228] Iteration 43260, loss = 0.298545
I0905 09:25:35.942421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298546 (* 1 = 0.298546 loss)
I0905 09:25:35.942438 90901 sgd_solver.cpp:106] Iteration 43260, lr = 0.1
I0905 09:25:42.699336 90901 solver.cpp:228] Iteration 43270, loss = 0.125567
I0905 09:25:42.699379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125568 (* 1 = 0.125568 loss)
I0905 09:25:42.699391 90901 sgd_solver.cpp:106] Iteration 43270, lr = 0.1
I0905 09:25:48.443696 90901 solver.cpp:228] Iteration 43280, loss = 0.944757
I0905 09:25:48.443765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.944758 (* 1 = 0.944758 loss)
I0905 09:25:48.443781 90901 sgd_solver.cpp:106] Iteration 43280, lr = 0.1
I0905 09:25:54.086818 90901 solver.cpp:228] Iteration 43290, loss = 0.23124
I0905 09:25:54.086879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231241 (* 1 = 0.231241 loss)
I0905 09:25:54.086894 90901 sgd_solver.cpp:106] Iteration 43290, lr = 0.1
I0905 09:25:59.440697 90901 solver.cpp:228] Iteration 43300, loss = 0.184087
I0905 09:25:59.440757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184088 (* 1 = 0.184088 loss)
I0905 09:25:59.440770 90901 sgd_solver.cpp:106] Iteration 43300, lr = 0.1
I0905 09:26:05.507000 90901 solver.cpp:228] Iteration 43310, loss = 0.478525
I0905 09:26:05.507218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478526 (* 1 = 0.478526 loss)
I0905 09:26:05.507249 90901 sgd_solver.cpp:106] Iteration 43310, lr = 0.1
I0905 09:26:11.563961 90901 solver.cpp:228] Iteration 43320, loss = 0.453432
I0905 09:26:11.564008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453433 (* 1 = 0.453433 loss)
I0905 09:26:11.564023 90901 sgd_solver.cpp:106] Iteration 43320, lr = 0.1
I0905 09:26:17.641963 90901 solver.cpp:228] Iteration 43330, loss = 0.324595
I0905 09:26:17.642035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324596 (* 1 = 0.324596 loss)
I0905 09:26:17.642050 90901 sgd_solver.cpp:106] Iteration 43330, lr = 0.1
I0905 09:26:24.087918 90901 solver.cpp:228] Iteration 43340, loss = 0.331212
I0905 09:26:24.087962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331213 (* 1 = 0.331213 loss)
I0905 09:26:24.087985 90901 sgd_solver.cpp:106] Iteration 43340, lr = 0.1
I0905 09:26:29.996556 90901 solver.cpp:228] Iteration 43350, loss = 0.240704
I0905 09:26:29.996613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240705 (* 1 = 0.240705 loss)
I0905 09:26:29.996628 90901 sgd_solver.cpp:106] Iteration 43350, lr = 0.1
I0905 09:26:36.242578 90901 solver.cpp:228] Iteration 43360, loss = 0.0984452
I0905 09:26:36.242768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0984463 (* 1 = 0.0984463 loss)
I0905 09:26:36.242796 90901 sgd_solver.cpp:106] Iteration 43360, lr = 0.1
I0905 09:26:42.272505 90901 solver.cpp:228] Iteration 43370, loss = 0.274435
I0905 09:26:42.272567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274436 (* 1 = 0.274436 loss)
I0905 09:26:42.272584 90901 sgd_solver.cpp:106] Iteration 43370, lr = 0.1
I0905 09:26:48.348781 90901 solver.cpp:228] Iteration 43380, loss = 0.276867
I0905 09:26:48.348848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276868 (* 1 = 0.276868 loss)
I0905 09:26:48.348863 90901 sgd_solver.cpp:106] Iteration 43380, lr = 0.1
I0905 09:26:54.393939 90901 solver.cpp:228] Iteration 43390, loss = 0.417004
I0905 09:26:54.393993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417005 (* 1 = 0.417005 loss)
I0905 09:26:54.394008 90901 sgd_solver.cpp:106] Iteration 43390, lr = 0.1
I0905 09:27:00.146533 90901 solver.cpp:228] Iteration 43400, loss = 0.314559
I0905 09:27:00.146595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31456 (* 1 = 0.31456 loss)
I0905 09:27:00.146610 90901 sgd_solver.cpp:106] Iteration 43400, lr = 0.1
I0905 09:27:06.562551 90901 solver.cpp:228] Iteration 43410, loss = 0.252003
I0905 09:27:06.562827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252004 (* 1 = 0.252004 loss)
I0905 09:27:06.562844 90901 sgd_solver.cpp:106] Iteration 43410, lr = 0.1
I0905 09:27:12.659660 90901 solver.cpp:228] Iteration 43420, loss = 0.435845
I0905 09:27:12.659732 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435846 (* 1 = 0.435846 loss)
I0905 09:27:12.659749 90901 sgd_solver.cpp:106] Iteration 43420, lr = 0.1
I0905 09:27:18.821622 90901 solver.cpp:228] Iteration 43430, loss = 0.23051
I0905 09:27:18.821676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230511 (* 1 = 0.230511 loss)
I0905 09:27:18.821691 90901 sgd_solver.cpp:106] Iteration 43430, lr = 0.1
I0905 09:27:25.060304 90901 solver.cpp:228] Iteration 43440, loss = 0.396158
I0905 09:27:25.060364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396159 (* 1 = 0.396159 loss)
I0905 09:27:25.060380 90901 sgd_solver.cpp:106] Iteration 43440, lr = 0.1
I0905 09:27:31.144179 90901 solver.cpp:228] Iteration 43450, loss = 0.373408
I0905 09:27:31.144230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373409 (* 1 = 0.373409 loss)
I0905 09:27:31.144243 90901 sgd_solver.cpp:106] Iteration 43450, lr = 0.1
I0905 09:27:37.503123 90901 solver.cpp:228] Iteration 43460, loss = 0.521772
I0905 09:27:37.503387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.521773 (* 1 = 0.521773 loss)
I0905 09:27:37.503402 90901 sgd_solver.cpp:106] Iteration 43460, lr = 0.1
I0905 09:27:42.757907 90901 solver.cpp:228] Iteration 43470, loss = 0.252347
I0905 09:27:42.757966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252348 (* 1 = 0.252348 loss)
I0905 09:27:42.757984 90901 sgd_solver.cpp:106] Iteration 43470, lr = 0.1
I0905 09:27:48.128597 90901 solver.cpp:228] Iteration 43480, loss = 0.191717
I0905 09:27:48.128669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191718 (* 1 = 0.191718 loss)
I0905 09:27:48.128692 90901 sgd_solver.cpp:106] Iteration 43480, lr = 0.1
I0905 09:27:54.196948 90901 solver.cpp:228] Iteration 43490, loss = 0.17621
I0905 09:27:54.197005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176211 (* 1 = 0.176211 loss)
I0905 09:27:54.197021 90901 sgd_solver.cpp:106] Iteration 43490, lr = 0.1
I0905 09:28:00.595055 90901 solver.cpp:228] Iteration 43500, loss = 0.302101
I0905 09:28:00.595111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302102 (* 1 = 0.302102 loss)
I0905 09:28:00.595126 90901 sgd_solver.cpp:106] Iteration 43500, lr = 0.1
I0905 09:28:06.356559 90901 solver.cpp:228] Iteration 43510, loss = 0.289035
I0905 09:28:06.356603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289036 (* 1 = 0.289036 loss)
I0905 09:28:06.356619 90901 sgd_solver.cpp:106] Iteration 43510, lr = 0.1
I0905 09:28:12.409451 90901 solver.cpp:228] Iteration 43520, loss = 0.280662
I0905 09:28:12.409595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280663 (* 1 = 0.280663 loss)
I0905 09:28:12.409616 90901 sgd_solver.cpp:106] Iteration 43520, lr = 0.1
I0905 09:28:18.785931 90901 solver.cpp:228] Iteration 43530, loss = 0.648089
I0905 09:28:18.785997 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64809 (* 1 = 0.64809 loss)
I0905 09:28:18.786011 90901 sgd_solver.cpp:106] Iteration 43530, lr = 0.1
I0905 09:28:24.598831 90901 solver.cpp:228] Iteration 43540, loss = 0.340345
I0905 09:28:24.598879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340346 (* 1 = 0.340346 loss)
I0905 09:28:24.598891 90901 sgd_solver.cpp:106] Iteration 43540, lr = 0.1
I0905 09:28:30.708279 90901 solver.cpp:228] Iteration 43550, loss = 0.545608
I0905 09:28:30.708340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.545609 (* 1 = 0.545609 loss)
I0905 09:28:30.708359 90901 sgd_solver.cpp:106] Iteration 43550, lr = 0.1
I0905 09:28:37.067543 90901 solver.cpp:228] Iteration 43560, loss = 0.301886
I0905 09:28:37.067612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301887 (* 1 = 0.301887 loss)
I0905 09:28:37.067628 90901 sgd_solver.cpp:106] Iteration 43560, lr = 0.1
I0905 09:28:43.155823 90901 solver.cpp:228] Iteration 43570, loss = 0.643418
I0905 09:28:43.156064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.643419 (* 1 = 0.643419 loss)
I0905 09:28:43.156083 90901 sgd_solver.cpp:106] Iteration 43570, lr = 0.1
I0905 09:28:49.290952 90901 solver.cpp:228] Iteration 43580, loss = 0.22069
I0905 09:28:49.290993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220692 (* 1 = 0.220692 loss)
I0905 09:28:49.291007 90901 sgd_solver.cpp:106] Iteration 43580, lr = 0.1
I0905 09:28:55.390944 90901 solver.cpp:228] Iteration 43590, loss = 0.519223
I0905 09:28:55.390987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519224 (* 1 = 0.519224 loss)
I0905 09:28:55.391000 90901 sgd_solver.cpp:106] Iteration 43590, lr = 0.1
I0905 09:29:01.638972 90901 solver.cpp:228] Iteration 43600, loss = 0.333379
I0905 09:29:01.639030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33338 (* 1 = 0.33338 loss)
I0905 09:29:01.639046 90901 sgd_solver.cpp:106] Iteration 43600, lr = 0.1
I0905 09:29:07.393911 90901 solver.cpp:228] Iteration 43610, loss = 0.401224
I0905 09:29:07.393970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401225 (* 1 = 0.401225 loss)
I0905 09:29:07.393985 90901 sgd_solver.cpp:106] Iteration 43610, lr = 0.1
I0905 09:29:13.815016 90901 solver.cpp:228] Iteration 43620, loss = 0.29444
I0905 09:29:13.815194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294441 (* 1 = 0.294441 loss)
I0905 09:29:13.815243 90901 sgd_solver.cpp:106] Iteration 43620, lr = 0.1
I0905 09:29:20.200495 90901 solver.cpp:228] Iteration 43630, loss = 0.162403
I0905 09:29:20.200552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162404 (* 1 = 0.162404 loss)
I0905 09:29:20.200567 90901 sgd_solver.cpp:106] Iteration 43630, lr = 0.1
I0905 09:29:26.121682 90901 solver.cpp:228] Iteration 43640, loss = 0.26295
I0905 09:29:26.121726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262951 (* 1 = 0.262951 loss)
I0905 09:29:26.121739 90901 sgd_solver.cpp:106] Iteration 43640, lr = 0.1
I0905 09:29:31.453979 90901 solver.cpp:228] Iteration 43650, loss = 0.162241
I0905 09:29:31.454041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162242 (* 1 = 0.162242 loss)
I0905 09:29:31.454056 90901 sgd_solver.cpp:106] Iteration 43650, lr = 0.1
I0905 09:29:37.240087 90901 solver.cpp:228] Iteration 43660, loss = 0.230871
I0905 09:29:37.240151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230872 (* 1 = 0.230872 loss)
I0905 09:29:37.240165 90901 sgd_solver.cpp:106] Iteration 43660, lr = 0.1
I0905 09:29:43.223762 90901 solver.cpp:228] Iteration 43670, loss = 0.233338
I0905 09:29:43.223822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233339 (* 1 = 0.233339 loss)
I0905 09:29:43.223836 90901 sgd_solver.cpp:106] Iteration 43670, lr = 0.1
I0905 09:29:49.076650 90901 solver.cpp:228] Iteration 43680, loss = 0.289618
I0905 09:29:49.076927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289619 (* 1 = 0.289619 loss)
I0905 09:29:49.076963 90901 sgd_solver.cpp:106] Iteration 43680, lr = 0.1
I0905 09:29:55.161396 90901 solver.cpp:228] Iteration 43690, loss = 0.182302
I0905 09:29:55.161458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182303 (* 1 = 0.182303 loss)
I0905 09:29:55.161473 90901 sgd_solver.cpp:106] Iteration 43690, lr = 0.1
I0905 09:30:01.456733 90901 solver.cpp:228] Iteration 43700, loss = 1.05139
I0905 09:30:01.456799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.05139 (* 1 = 1.05139 loss)
I0905 09:30:01.456815 90901 sgd_solver.cpp:106] Iteration 43700, lr = 0.1
I0905 09:30:07.647668 90901 solver.cpp:228] Iteration 43710, loss = 0.273207
I0905 09:30:07.647716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273208 (* 1 = 0.273208 loss)
I0905 09:30:07.647728 90901 sgd_solver.cpp:106] Iteration 43710, lr = 0.1
I0905 09:30:13.723173 90901 solver.cpp:228] Iteration 43720, loss = 0.234165
I0905 09:30:13.723222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234167 (* 1 = 0.234167 loss)
I0905 09:30:13.723235 90901 sgd_solver.cpp:106] Iteration 43720, lr = 0.1
I0905 09:30:19.767766 90901 solver.cpp:228] Iteration 43730, loss = 0.328758
I0905 09:30:19.767968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328759 (* 1 = 0.328759 loss)
I0905 09:30:19.768000 90901 sgd_solver.cpp:106] Iteration 43730, lr = 0.1
I0905 09:30:26.117775 90901 solver.cpp:228] Iteration 43740, loss = 0.125891
I0905 09:30:26.117830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125892 (* 1 = 0.125892 loss)
I0905 09:30:26.117853 90901 sgd_solver.cpp:106] Iteration 43740, lr = 0.1
I0905 09:30:32.160246 90901 solver.cpp:228] Iteration 43750, loss = 0.143936
I0905 09:30:32.160308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143938 (* 1 = 0.143938 loss)
I0905 09:30:32.160322 90901 sgd_solver.cpp:106] Iteration 43750, lr = 0.1
I0905 09:30:38.530422 90901 solver.cpp:228] Iteration 43760, loss = 0.112414
I0905 09:30:38.530499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112416 (* 1 = 0.112416 loss)
I0905 09:30:38.530516 90901 sgd_solver.cpp:106] Iteration 43760, lr = 0.1
I0905 09:30:44.392030 90901 solver.cpp:228] Iteration 43770, loss = 0.550314
I0905 09:30:44.392087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.550315 (* 1 = 0.550315 loss)
I0905 09:30:44.392102 90901 sgd_solver.cpp:106] Iteration 43770, lr = 0.1
I0905 09:30:50.673867 90901 solver.cpp:228] Iteration 43780, loss = 0.224015
I0905 09:30:50.674026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224016 (* 1 = 0.224016 loss)
I0905 09:30:50.674085 90901 sgd_solver.cpp:106] Iteration 43780, lr = 0.1
I0905 09:30:56.726210 90901 solver.cpp:228] Iteration 43790, loss = 0.641464
I0905 09:30:56.726271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.641465 (* 1 = 0.641465 loss)
I0905 09:30:56.726290 90901 sgd_solver.cpp:106] Iteration 43790, lr = 0.1
I0905 09:31:02.762344 90901 solver.cpp:228] Iteration 43800, loss = 0.272218
I0905 09:31:02.762416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27222 (* 1 = 0.27222 loss)
I0905 09:31:02.762431 90901 sgd_solver.cpp:106] Iteration 43800, lr = 0.1
I0905 09:31:08.855875 90901 solver.cpp:228] Iteration 43810, loss = 0.298091
I0905 09:31:08.855939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298092 (* 1 = 0.298092 loss)
I0905 09:31:08.855955 90901 sgd_solver.cpp:106] Iteration 43810, lr = 0.1
I0905 09:31:14.892623 90901 solver.cpp:228] Iteration 43820, loss = 0.224883
I0905 09:31:14.892680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224884 (* 1 = 0.224884 loss)
I0905 09:31:14.892694 90901 sgd_solver.cpp:106] Iteration 43820, lr = 0.1
I0905 09:31:20.149729 90901 solver.cpp:228] Iteration 43830, loss = 0.318939
I0905 09:31:20.149809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31894 (* 1 = 0.31894 loss)
I0905 09:31:20.149829 90901 sgd_solver.cpp:106] Iteration 43830, lr = 0.1
I0905 09:31:25.824302 90901 solver.cpp:228] Iteration 43840, loss = 0.245259
I0905 09:31:25.824530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24526 (* 1 = 0.24526 loss)
I0905 09:31:25.824558 90901 sgd_solver.cpp:106] Iteration 43840, lr = 0.1
I0905 09:31:31.893443 90901 solver.cpp:228] Iteration 43850, loss = 0.518848
I0905 09:31:31.893491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.518849 (* 1 = 0.518849 loss)
I0905 09:31:31.893504 90901 sgd_solver.cpp:106] Iteration 43850, lr = 0.1
I0905 09:31:37.986238 90901 solver.cpp:228] Iteration 43860, loss = 0.487032
I0905 09:31:37.986306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487033 (* 1 = 0.487033 loss)
I0905 09:31:37.986321 90901 sgd_solver.cpp:106] Iteration 43860, lr = 0.1
I0905 09:31:44.049470 90901 solver.cpp:228] Iteration 43870, loss = 0.447709
I0905 09:31:44.049535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44771 (* 1 = 0.44771 loss)
I0905 09:31:44.049551 90901 sgd_solver.cpp:106] Iteration 43870, lr = 0.1
I0905 09:31:50.139621 90901 solver.cpp:228] Iteration 43880, loss = 0.301342
I0905 09:31:50.139681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301343 (* 1 = 0.301343 loss)
I0905 09:31:50.139696 90901 sgd_solver.cpp:106] Iteration 43880, lr = 0.1
I0905 09:31:56.282769 90901 solver.cpp:228] Iteration 43890, loss = 0.193797
I0905 09:31:56.283001 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193798 (* 1 = 0.193798 loss)
I0905 09:31:56.283028 90901 sgd_solver.cpp:106] Iteration 43890, lr = 0.1
I0905 09:32:02.026443 90901 solver.cpp:228] Iteration 43900, loss = 0.409069
I0905 09:32:02.026509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409071 (* 1 = 0.409071 loss)
I0905 09:32:02.026522 90901 sgd_solver.cpp:106] Iteration 43900, lr = 0.1
I0905 09:32:08.483363 90901 solver.cpp:228] Iteration 43910, loss = 0.285035
I0905 09:32:08.483422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285036 (* 1 = 0.285036 loss)
I0905 09:32:08.483434 90901 sgd_solver.cpp:106] Iteration 43910, lr = 0.1
I0905 09:32:14.575541 90901 solver.cpp:228] Iteration 43920, loss = 0.225262
I0905 09:32:14.575601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225263 (* 1 = 0.225263 loss)
I0905 09:32:14.575616 90901 sgd_solver.cpp:106] Iteration 43920, lr = 0.1
I0905 09:32:20.678442 90901 solver.cpp:228] Iteration 43930, loss = 0.217025
I0905 09:32:20.678503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217026 (* 1 = 0.217026 loss)
I0905 09:32:20.678515 90901 sgd_solver.cpp:106] Iteration 43930, lr = 0.1
I0905 09:32:27.073690 90901 solver.cpp:228] Iteration 43940, loss = 0.186567
I0905 09:32:27.073846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186568 (* 1 = 0.186568 loss)
I0905 09:32:27.073869 90901 sgd_solver.cpp:106] Iteration 43940, lr = 0.1
I0905 09:32:33.120702 90901 solver.cpp:228] Iteration 43950, loss = 0.690971
I0905 09:32:33.120767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.690972 (* 1 = 0.690972 loss)
I0905 09:32:33.120782 90901 sgd_solver.cpp:106] Iteration 43950, lr = 0.1
I0905 09:32:39.204730 90901 solver.cpp:228] Iteration 43960, loss = 0.251236
I0905 09:32:39.204777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251237 (* 1 = 0.251237 loss)
I0905 09:32:39.204792 90901 sgd_solver.cpp:106] Iteration 43960, lr = 0.1
I0905 09:32:45.278244 90901 solver.cpp:228] Iteration 43970, loss = 0.268929
I0905 09:32:45.278277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26893 (* 1 = 0.26893 loss)
I0905 09:32:45.278290 90901 sgd_solver.cpp:106] Iteration 43970, lr = 0.1
I0905 09:32:51.271957 90901 solver.cpp:228] Iteration 43980, loss = 0.234526
I0905 09:32:51.272029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234527 (* 1 = 0.234527 loss)
I0905 09:32:51.272045 90901 sgd_solver.cpp:106] Iteration 43980, lr = 0.1
I0905 09:32:57.625959 90901 solver.cpp:228] Iteration 43990, loss = 0.427717
I0905 09:32:57.626183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427719 (* 1 = 0.427719 loss)
I0905 09:32:57.626199 90901 sgd_solver.cpp:106] Iteration 43990, lr = 0.1
I0905 09:33:03.046186 90901 solver.cpp:337] Iteration 44000, Testing net (#0)
I0905 09:33:44.363240 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.628438
I0905 09:33:44.363415 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.944781 (* 1 = 0.944781 loss)
I0905 09:33:44.580266 90901 solver.cpp:228] Iteration 44000, loss = 0.259028
I0905 09:33:44.580296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259029 (* 1 = 0.259029 loss)
I0905 09:33:44.580314 90901 sgd_solver.cpp:106] Iteration 44000, lr = 0.1
I0905 09:33:50.985334 90901 solver.cpp:228] Iteration 44010, loss = 0.2532
I0905 09:33:50.985375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253201 (* 1 = 0.253201 loss)
I0905 09:33:50.985388 90901 sgd_solver.cpp:106] Iteration 44010, lr = 0.1
I0905 09:33:57.052057 90901 solver.cpp:228] Iteration 44020, loss = 0.251932
I0905 09:33:57.052114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251934 (* 1 = 0.251934 loss)
I0905 09:33:57.052129 90901 sgd_solver.cpp:106] Iteration 44020, lr = 0.1
I0905 09:34:03.200702 90901 solver.cpp:228] Iteration 44030, loss = 0.405
I0905 09:34:03.200747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.405001 (* 1 = 0.405001 loss)
I0905 09:34:03.200759 90901 sgd_solver.cpp:106] Iteration 44030, lr = 0.1
I0905 09:34:09.517421 90901 solver.cpp:228] Iteration 44040, loss = 0.0745395
I0905 09:34:09.517460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0745408 (* 1 = 0.0745408 loss)
I0905 09:34:09.517474 90901 sgd_solver.cpp:106] Iteration 44040, lr = 0.1
I0905 09:34:15.601456 90901 solver.cpp:228] Iteration 44050, loss = 0.107578
I0905 09:34:15.603754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107579 (* 1 = 0.107579 loss)
I0905 09:34:15.603770 90901 sgd_solver.cpp:106] Iteration 44050, lr = 0.1
I0905 09:34:21.672194 90901 solver.cpp:228] Iteration 44060, loss = 0.347295
I0905 09:34:21.672246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347296 (* 1 = 0.347296 loss)
I0905 09:34:21.672260 90901 sgd_solver.cpp:106] Iteration 44060, lr = 0.1
I0905 09:34:28.066157 90901 solver.cpp:228] Iteration 44070, loss = 0.373125
I0905 09:34:28.066201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373126 (* 1 = 0.373126 loss)
I0905 09:34:28.066218 90901 sgd_solver.cpp:106] Iteration 44070, lr = 0.1
I0905 09:34:34.101848 90901 solver.cpp:228] Iteration 44080, loss = 0.204473
I0905 09:34:34.101891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204475 (* 1 = 0.204475 loss)
I0905 09:34:34.101904 90901 sgd_solver.cpp:106] Iteration 44080, lr = 0.1
I0905 09:34:40.215153 90901 solver.cpp:228] Iteration 44090, loss = 0.723509
I0905 09:34:40.215204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.723511 (* 1 = 0.723511 loss)
I0905 09:34:40.215217 90901 sgd_solver.cpp:106] Iteration 44090, lr = 0.1
I0905 09:34:46.290802 90901 solver.cpp:228] Iteration 44100, loss = 0.223398
I0905 09:34:46.291020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2234 (* 1 = 0.2234 loss)
I0905 09:34:46.291038 90901 sgd_solver.cpp:106] Iteration 44100, lr = 0.1
I0905 09:34:52.537395 90901 solver.cpp:228] Iteration 44110, loss = 0.0777931
I0905 09:34:52.537451 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0777943 (* 1 = 0.0777943 loss)
I0905 09:34:52.537467 90901 sgd_solver.cpp:106] Iteration 44110, lr = 0.1
I0905 09:34:58.048707 90901 solver.cpp:228] Iteration 44120, loss = 0.230983
I0905 09:34:58.048763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230985 (* 1 = 0.230985 loss)
I0905 09:34:58.048779 90901 sgd_solver.cpp:106] Iteration 44120, lr = 0.1
I0905 09:35:03.582468 90901 solver.cpp:228] Iteration 44130, loss = 0.0575376
I0905 09:35:03.582509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0575389 (* 1 = 0.0575389 loss)
I0905 09:35:03.582521 90901 sgd_solver.cpp:106] Iteration 44130, lr = 0.1
I0905 09:35:09.613234 90901 solver.cpp:228] Iteration 44140, loss = 0.139431
I0905 09:35:09.613276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139432 (* 1 = 0.139432 loss)
I0905 09:35:09.613287 90901 sgd_solver.cpp:106] Iteration 44140, lr = 0.1
I0905 09:35:15.690253 90901 solver.cpp:228] Iteration 44150, loss = 0.187225
I0905 09:35:15.690302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187227 (* 1 = 0.187227 loss)
I0905 09:35:15.690316 90901 sgd_solver.cpp:106] Iteration 44150, lr = 0.1
I0905 09:35:21.759588 90901 solver.cpp:228] Iteration 44160, loss = 0.111631
I0905 09:35:21.759822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111632 (* 1 = 0.111632 loss)
I0905 09:35:21.759850 90901 sgd_solver.cpp:106] Iteration 44160, lr = 0.1
I0905 09:35:27.845252 90901 solver.cpp:228] Iteration 44170, loss = 0.240987
I0905 09:35:27.845296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240989 (* 1 = 0.240989 loss)
I0905 09:35:27.845309 90901 sgd_solver.cpp:106] Iteration 44170, lr = 0.1
I0905 09:35:33.917397 90901 solver.cpp:228] Iteration 44180, loss = 0.283431
I0905 09:35:33.917438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283433 (* 1 = 0.283433 loss)
I0905 09:35:33.917449 90901 sgd_solver.cpp:106] Iteration 44180, lr = 0.1
I0905 09:35:39.703358 90901 solver.cpp:228] Iteration 44190, loss = 0.200711
I0905 09:35:39.703428 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200712 (* 1 = 0.200712 loss)
I0905 09:35:39.703443 90901 sgd_solver.cpp:106] Iteration 44190, lr = 0.1
I0905 09:35:45.746937 90901 solver.cpp:228] Iteration 44200, loss = 0.367844
I0905 09:35:45.746984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367845 (* 1 = 0.367845 loss)
I0905 09:35:45.746996 90901 sgd_solver.cpp:106] Iteration 44200, lr = 0.1
I0905 09:35:51.824527 90901 solver.cpp:228] Iteration 44210, loss = 0.208837
I0905 09:35:51.824733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208838 (* 1 = 0.208838 loss)
I0905 09:35:51.824764 90901 sgd_solver.cpp:106] Iteration 44210, lr = 0.1
I0905 09:35:57.899659 90901 solver.cpp:228] Iteration 44220, loss = 0.407691
I0905 09:35:57.899721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407692 (* 1 = 0.407692 loss)
I0905 09:35:57.899736 90901 sgd_solver.cpp:106] Iteration 44220, lr = 0.1
I0905 09:36:04.195226 90901 solver.cpp:228] Iteration 44230, loss = 0.188726
I0905 09:36:04.195271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188727 (* 1 = 0.188727 loss)
I0905 09:36:04.195286 90901 sgd_solver.cpp:106] Iteration 44230, lr = 0.1
I0905 09:36:10.385025 90901 solver.cpp:228] Iteration 44240, loss = 0.546416
I0905 09:36:10.385078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.546418 (* 1 = 0.546418 loss)
I0905 09:36:10.385093 90901 sgd_solver.cpp:106] Iteration 44240, lr = 0.1
I0905 09:36:16.089684 90901 solver.cpp:228] Iteration 44250, loss = 0.104392
I0905 09:36:16.089735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104393 (* 1 = 0.104393 loss)
I0905 09:36:16.089751 90901 sgd_solver.cpp:106] Iteration 44250, lr = 0.1
I0905 09:36:22.502414 90901 solver.cpp:228] Iteration 44260, loss = 0.716935
I0905 09:36:22.502559 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.716936 (* 1 = 0.716936 loss)
I0905 09:36:22.502599 90901 sgd_solver.cpp:106] Iteration 44260, lr = 0.1
I0905 09:36:28.510373 90901 solver.cpp:228] Iteration 44270, loss = 0.368978
I0905 09:36:28.510424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368979 (* 1 = 0.368979 loss)
I0905 09:36:28.510437 90901 sgd_solver.cpp:106] Iteration 44270, lr = 0.1
I0905 09:36:34.862006 90901 solver.cpp:228] Iteration 44280, loss = 0.184099
I0905 09:36:34.862052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1841 (* 1 = 0.1841 loss)
I0905 09:36:34.862067 90901 sgd_solver.cpp:106] Iteration 44280, lr = 0.1
I0905 09:36:40.809801 90901 solver.cpp:228] Iteration 44290, loss = 0.206962
I0905 09:36:40.809851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206963 (* 1 = 0.206963 loss)
I0905 09:36:40.809866 90901 sgd_solver.cpp:106] Iteration 44290, lr = 0.1
I0905 09:36:46.065191 90901 solver.cpp:228] Iteration 44300, loss = 0.139075
I0905 09:36:46.065237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139076 (* 1 = 0.139076 loss)
I0905 09:36:46.065250 90901 sgd_solver.cpp:106] Iteration 44300, lr = 0.1
I0905 09:36:51.931859 90901 solver.cpp:228] Iteration 44310, loss = 0.181512
I0905 09:36:51.931900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181513 (* 1 = 0.181513 loss)
I0905 09:36:51.931913 90901 sgd_solver.cpp:106] Iteration 44310, lr = 0.1
I0905 09:36:57.765837 90901 solver.cpp:228] Iteration 44320, loss = 0.191218
I0905 09:36:57.766006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191219 (* 1 = 0.191219 loss)
I0905 09:36:57.766026 90901 sgd_solver.cpp:106] Iteration 44320, lr = 0.1
I0905 09:37:04.024442 90901 solver.cpp:228] Iteration 44330, loss = 0.339989
I0905 09:37:04.024490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33999 (* 1 = 0.33999 loss)
I0905 09:37:04.024504 90901 sgd_solver.cpp:106] Iteration 44330, lr = 0.1
I0905 09:37:10.112234 90901 solver.cpp:228] Iteration 44340, loss = 0.528104
I0905 09:37:10.112270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528105 (* 1 = 0.528105 loss)
I0905 09:37:10.112283 90901 sgd_solver.cpp:106] Iteration 44340, lr = 0.1
I0905 09:37:16.521174 90901 solver.cpp:228] Iteration 44350, loss = 0.329789
I0905 09:37:16.521219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32979 (* 1 = 0.32979 loss)
I0905 09:37:16.521231 90901 sgd_solver.cpp:106] Iteration 44350, lr = 0.1
I0905 09:37:22.564055 90901 solver.cpp:228] Iteration 44360, loss = 0.201105
I0905 09:37:22.564093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201106 (* 1 = 0.201106 loss)
I0905 09:37:22.564108 90901 sgd_solver.cpp:106] Iteration 44360, lr = 0.1
I0905 09:37:28.631162 90901 solver.cpp:228] Iteration 44370, loss = 0.233817
I0905 09:37:28.631404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233818 (* 1 = 0.233818 loss)
I0905 09:37:28.631420 90901 sgd_solver.cpp:106] Iteration 44370, lr = 0.1
I0905 09:37:34.701396 90901 solver.cpp:228] Iteration 44380, loss = 0.266165
I0905 09:37:34.701442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266166 (* 1 = 0.266166 loss)
I0905 09:37:34.701454 90901 sgd_solver.cpp:106] Iteration 44380, lr = 0.1
I0905 09:37:40.785758 90901 solver.cpp:228] Iteration 44390, loss = 0.330047
I0905 09:37:40.785822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330048 (* 1 = 0.330048 loss)
I0905 09:37:40.785836 90901 sgd_solver.cpp:106] Iteration 44390, lr = 0.1
I0905 09:37:47.195796 90901 solver.cpp:228] Iteration 44400, loss = 0.188852
I0905 09:37:47.195842 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188853 (* 1 = 0.188853 loss)
I0905 09:37:47.195858 90901 sgd_solver.cpp:106] Iteration 44400, lr = 0.1
I0905 09:37:53.222446 90901 solver.cpp:228] Iteration 44410, loss = 0.2278
I0905 09:37:53.222504 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227801 (* 1 = 0.227801 loss)
I0905 09:37:53.222518 90901 sgd_solver.cpp:106] Iteration 44410, lr = 0.1
I0905 09:37:59.310539 90901 solver.cpp:228] Iteration 44420, loss = 0.498381
I0905 09:37:59.310727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498382 (* 1 = 0.498382 loss)
I0905 09:37:59.310771 90901 sgd_solver.cpp:106] Iteration 44420, lr = 0.1
I0905 09:38:05.713155 90901 solver.cpp:228] Iteration 44430, loss = 0.179818
I0905 09:38:05.713217 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179819 (* 1 = 0.179819 loss)
I0905 09:38:05.713232 90901 sgd_solver.cpp:106] Iteration 44430, lr = 0.1
I0905 09:38:11.793866 90901 solver.cpp:228] Iteration 44440, loss = 0.31633
I0905 09:38:11.793922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316331 (* 1 = 0.316331 loss)
I0905 09:38:11.793936 90901 sgd_solver.cpp:106] Iteration 44440, lr = 0.1
I0905 09:38:16.863772 90901 solver.cpp:228] Iteration 44450, loss = 0.149307
I0905 09:38:16.863821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149308 (* 1 = 0.149308 loss)
I0905 09:38:16.863833 90901 sgd_solver.cpp:106] Iteration 44450, lr = 0.1
I0905 09:38:21.895311 90901 solver.cpp:228] Iteration 44460, loss = 0.158635
I0905 09:38:21.895364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158637 (* 1 = 0.158637 loss)
I0905 09:38:21.895378 90901 sgd_solver.cpp:106] Iteration 44460, lr = 0.1
I0905 09:38:26.929100 90901 solver.cpp:228] Iteration 44470, loss = 0.198093
I0905 09:38:26.929155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198094 (* 1 = 0.198094 loss)
I0905 09:38:26.929168 90901 sgd_solver.cpp:106] Iteration 44470, lr = 0.1
I0905 09:38:31.575903 90901 solver.cpp:228] Iteration 44480, loss = 0.130438
I0905 09:38:31.576122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130439 (* 1 = 0.130439 loss)
I0905 09:38:31.576151 90901 sgd_solver.cpp:106] Iteration 44480, lr = 0.1
I0905 09:38:36.225064 90901 solver.cpp:228] Iteration 44490, loss = 0.153709
I0905 09:38:36.225126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15371 (* 1 = 0.15371 loss)
I0905 09:38:36.225139 90901 sgd_solver.cpp:106] Iteration 44490, lr = 0.1
I0905 09:38:41.075316 90901 solver.cpp:228] Iteration 44500, loss = 0.653122
I0905 09:38:41.075356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.653123 (* 1 = 0.653123 loss)
I0905 09:38:41.075368 90901 sgd_solver.cpp:106] Iteration 44500, lr = 0.1
I0905 09:38:46.113656 90901 solver.cpp:228] Iteration 44510, loss = 0.2448
I0905 09:38:46.113708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244801 (* 1 = 0.244801 loss)
I0905 09:38:46.113721 90901 sgd_solver.cpp:106] Iteration 44510, lr = 0.1
I0905 09:38:51.182209 90901 solver.cpp:228] Iteration 44520, loss = 0.353024
I0905 09:38:51.182260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353025 (* 1 = 0.353025 loss)
I0905 09:38:51.182273 90901 sgd_solver.cpp:106] Iteration 44520, lr = 0.1
I0905 09:38:56.219079 90901 solver.cpp:228] Iteration 44530, loss = 0.168093
I0905 09:38:56.219121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168094 (* 1 = 0.168094 loss)
I0905 09:38:56.219133 90901 sgd_solver.cpp:106] Iteration 44530, lr = 0.1
I0905 09:39:01.299060 90901 solver.cpp:228] Iteration 44540, loss = 0.385196
I0905 09:39:01.299113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385197 (* 1 = 0.385197 loss)
I0905 09:39:01.299127 90901 sgd_solver.cpp:106] Iteration 44540, lr = 0.1
I0905 09:39:06.357183 90901 solver.cpp:228] Iteration 44550, loss = 0.267837
I0905 09:39:06.357345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267838 (* 1 = 0.267838 loss)
I0905 09:39:06.357358 90901 sgd_solver.cpp:106] Iteration 44550, lr = 0.1
I0905 09:39:11.447022 90901 solver.cpp:228] Iteration 44560, loss = 0.491304
I0905 09:39:11.447067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491306 (* 1 = 0.491306 loss)
I0905 09:39:11.447080 90901 sgd_solver.cpp:106] Iteration 44560, lr = 0.1
I0905 09:39:16.540103 90901 solver.cpp:228] Iteration 44570, loss = 0.101023
I0905 09:39:16.540150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101024 (* 1 = 0.101024 loss)
I0905 09:39:16.540165 90901 sgd_solver.cpp:106] Iteration 44570, lr = 0.1
I0905 09:39:21.623036 90901 solver.cpp:228] Iteration 44580, loss = 0.187768
I0905 09:39:21.623090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187769 (* 1 = 0.187769 loss)
I0905 09:39:21.623103 90901 sgd_solver.cpp:106] Iteration 44580, lr = 0.1
I0905 09:39:26.679168 90901 solver.cpp:228] Iteration 44590, loss = 0.184385
I0905 09:39:26.679220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184386 (* 1 = 0.184386 loss)
I0905 09:39:26.679234 90901 sgd_solver.cpp:106] Iteration 44590, lr = 0.1
I0905 09:39:31.705683 90901 solver.cpp:228] Iteration 44600, loss = 0.240292
I0905 09:39:31.705731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240294 (* 1 = 0.240294 loss)
I0905 09:39:31.705744 90901 sgd_solver.cpp:106] Iteration 44600, lr = 0.1
I0905 09:39:37.081069 90901 solver.cpp:228] Iteration 44610, loss = 0.276023
I0905 09:39:37.081254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276024 (* 1 = 0.276024 loss)
I0905 09:39:37.081284 90901 sgd_solver.cpp:106] Iteration 44610, lr = 0.1
I0905 09:39:43.181573 90901 solver.cpp:228] Iteration 44620, loss = 0.204311
I0905 09:39:43.181612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204312 (* 1 = 0.204312 loss)
I0905 09:39:43.181633 90901 sgd_solver.cpp:106] Iteration 44620, lr = 0.1
I0905 09:39:49.299649 90901 solver.cpp:228] Iteration 44630, loss = 0.290744
I0905 09:39:49.299687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290746 (* 1 = 0.290746 loss)
I0905 09:39:49.299701 90901 sgd_solver.cpp:106] Iteration 44630, lr = 0.1
I0905 09:39:55.528092 90901 solver.cpp:228] Iteration 44640, loss = 0.156751
I0905 09:39:55.528126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156752 (* 1 = 0.156752 loss)
I0905 09:39:55.528138 90901 sgd_solver.cpp:106] Iteration 44640, lr = 0.1
I0905 09:40:01.731304 90901 solver.cpp:228] Iteration 44650, loss = 0.145148
I0905 09:40:01.731348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14515 (* 1 = 0.14515 loss)
I0905 09:40:01.731360 90901 sgd_solver.cpp:106] Iteration 44650, lr = 0.1
I0905 09:40:07.727810 90901 solver.cpp:228] Iteration 44660, loss = 0.442671
I0905 09:40:07.727991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442672 (* 1 = 0.442672 loss)
I0905 09:40:07.728008 90901 sgd_solver.cpp:106] Iteration 44660, lr = 0.1
I0905 09:40:13.817900 90901 solver.cpp:228] Iteration 44670, loss = 0.532683
I0905 09:40:13.817945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.532684 (* 1 = 0.532684 loss)
I0905 09:40:13.817958 90901 sgd_solver.cpp:106] Iteration 44670, lr = 0.1
I0905 09:40:19.761600 90901 solver.cpp:228] Iteration 44680, loss = 0.358766
I0905 09:40:19.761654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358767 (* 1 = 0.358767 loss)
I0905 09:40:19.761670 90901 sgd_solver.cpp:106] Iteration 44680, lr = 0.1
I0905 09:40:25.019769 90901 solver.cpp:228] Iteration 44690, loss = 0.399337
I0905 09:40:25.019815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399339 (* 1 = 0.399339 loss)
I0905 09:40:25.019826 90901 sgd_solver.cpp:106] Iteration 44690, lr = 0.1
I0905 09:40:30.760884 90901 solver.cpp:228] Iteration 44700, loss = 0.238637
I0905 09:40:30.760926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238638 (* 1 = 0.238638 loss)
I0905 09:40:30.760939 90901 sgd_solver.cpp:106] Iteration 44700, lr = 0.1
I0905 09:40:36.825974 90901 solver.cpp:228] Iteration 44710, loss = 0.35909
I0905 09:40:36.826020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359091 (* 1 = 0.359091 loss)
I0905 09:40:36.826032 90901 sgd_solver.cpp:106] Iteration 44710, lr = 0.1
I0905 09:40:42.897780 90901 solver.cpp:228] Iteration 44720, loss = 0.452787
I0905 09:40:42.897939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.452788 (* 1 = 0.452788 loss)
I0905 09:40:42.897982 90901 sgd_solver.cpp:106] Iteration 44720, lr = 0.1
I0905 09:40:48.958992 90901 solver.cpp:228] Iteration 44730, loss = 0.21623
I0905 09:40:48.959038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216231 (* 1 = 0.216231 loss)
I0905 09:40:48.959051 90901 sgd_solver.cpp:106] Iteration 44730, lr = 0.1
I0905 09:40:55.015593 90901 solver.cpp:228] Iteration 44740, loss = 0.0782619
I0905 09:40:55.015645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0782632 (* 1 = 0.0782632 loss)
I0905 09:40:55.015660 90901 sgd_solver.cpp:106] Iteration 44740, lr = 0.1
I0905 09:41:01.100833 90901 solver.cpp:228] Iteration 44750, loss = 0.0788144
I0905 09:41:01.100883 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0788157 (* 1 = 0.0788157 loss)
I0905 09:41:01.100898 90901 sgd_solver.cpp:106] Iteration 44750, lr = 0.1
I0905 09:41:07.383599 90901 solver.cpp:228] Iteration 44760, loss = 0.207873
I0905 09:41:07.383648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207874 (* 1 = 0.207874 loss)
I0905 09:41:07.383663 90901 sgd_solver.cpp:106] Iteration 44760, lr = 0.1
I0905 09:41:13.569566 90901 solver.cpp:228] Iteration 44770, loss = 0.267235
I0905 09:41:13.569850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267236 (* 1 = 0.267236 loss)
I0905 09:41:13.569875 90901 sgd_solver.cpp:106] Iteration 44770, lr = 0.1
I0905 09:41:19.315059 90901 solver.cpp:228] Iteration 44780, loss = 0.191175
I0905 09:41:19.315109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191176 (* 1 = 0.191176 loss)
I0905 09:41:19.315124 90901 sgd_solver.cpp:106] Iteration 44780, lr = 0.1
I0905 09:41:26.065016 90901 solver.cpp:228] Iteration 44790, loss = 0.384258
I0905 09:41:26.065093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.38426 (* 1 = 0.38426 loss)
I0905 09:41:26.065109 90901 sgd_solver.cpp:106] Iteration 44790, lr = 0.1
I0905 09:41:31.574261 90901 solver.cpp:337] Iteration 44800, Testing net (#0)
I0905 09:42:13.125643 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.635
I0905 09:42:13.125867 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.01159 (* 1 = 1.01159 loss)
I0905 09:42:13.326295 90901 solver.cpp:228] Iteration 44800, loss = 0.180652
I0905 09:42:13.326329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180654 (* 1 = 0.180654 loss)
I0905 09:42:13.326352 90901 sgd_solver.cpp:106] Iteration 44800, lr = 0.1
I0905 09:42:19.070319 90901 solver.cpp:228] Iteration 44810, loss = 0.459857
I0905 09:42:19.070364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459858 (* 1 = 0.459858 loss)
I0905 09:42:19.070384 90901 sgd_solver.cpp:106] Iteration 44810, lr = 0.1
I0905 09:42:25.153754 90901 solver.cpp:228] Iteration 44820, loss = 0.611988
I0905 09:42:25.153800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.611989 (* 1 = 0.611989 loss)
I0905 09:42:25.153813 90901 sgd_solver.cpp:106] Iteration 44820, lr = 0.1
I0905 09:42:31.253574 90901 solver.cpp:228] Iteration 44830, loss = 0.339211
I0905 09:42:31.253628 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339212 (* 1 = 0.339212 loss)
I0905 09:42:31.253659 90901 sgd_solver.cpp:106] Iteration 44830, lr = 0.1
I0905 09:42:37.640172 90901 solver.cpp:228] Iteration 44840, loss = 0.349353
I0905 09:42:37.640239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349354 (* 1 = 0.349354 loss)
I0905 09:42:37.640254 90901 sgd_solver.cpp:106] Iteration 44840, lr = 0.1
I0905 09:42:43.729454 90901 solver.cpp:228] Iteration 44850, loss = 0.407874
I0905 09:42:43.729632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407875 (* 1 = 0.407875 loss)
I0905 09:42:43.729648 90901 sgd_solver.cpp:106] Iteration 44850, lr = 0.1
I0905 09:42:49.791892 90901 solver.cpp:228] Iteration 44860, loss = 0.129259
I0905 09:42:49.791939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12926 (* 1 = 0.12926 loss)
I0905 09:42:49.791954 90901 sgd_solver.cpp:106] Iteration 44860, lr = 0.1
I0905 09:42:55.864111 90901 solver.cpp:228] Iteration 44870, loss = 0.522882
I0905 09:42:55.864159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.522883 (* 1 = 0.522883 loss)
I0905 09:42:55.864174 90901 sgd_solver.cpp:106] Iteration 44870, lr = 0.1
I0905 09:43:01.938680 90901 solver.cpp:228] Iteration 44880, loss = 0.264431
I0905 09:43:01.938730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264432 (* 1 = 0.264432 loss)
I0905 09:43:01.938750 90901 sgd_solver.cpp:106] Iteration 44880, lr = 0.1
I0905 09:43:08.192747 90901 solver.cpp:228] Iteration 44890, loss = 0.100545
I0905 09:43:08.192798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100546 (* 1 = 0.100546 loss)
I0905 09:43:08.192811 90901 sgd_solver.cpp:106] Iteration 44890, lr = 0.1
I0905 09:43:14.142091 90901 solver.cpp:228] Iteration 44900, loss = 0.279745
I0905 09:43:14.142321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279746 (* 1 = 0.279746 loss)
I0905 09:43:14.142338 90901 sgd_solver.cpp:106] Iteration 44900, lr = 0.1
I0905 09:43:20.571722 90901 solver.cpp:228] Iteration 44910, loss = 0.207707
I0905 09:43:20.571770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207709 (* 1 = 0.207709 loss)
I0905 09:43:20.571784 90901 sgd_solver.cpp:106] Iteration 44910, lr = 0.1
I0905 09:43:26.945317 90901 solver.cpp:228] Iteration 44920, loss = 0.159318
I0905 09:43:26.945353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159319 (* 1 = 0.159319 loss)
I0905 09:43:26.945370 90901 sgd_solver.cpp:106] Iteration 44920, lr = 0.1
I0905 09:43:32.948865 90901 solver.cpp:228] Iteration 44930, loss = 0.187535
I0905 09:43:32.948900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187536 (* 1 = 0.187536 loss)
I0905 09:43:32.948912 90901 sgd_solver.cpp:106] Iteration 44930, lr = 0.1
I0905 09:43:39.143527 90901 solver.cpp:228] Iteration 44940, loss = 0.281357
I0905 09:43:39.143571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281358 (* 1 = 0.281358 loss)
I0905 09:43:39.143584 90901 sgd_solver.cpp:106] Iteration 44940, lr = 0.1
I0905 09:43:45.210327 90901 solver.cpp:228] Iteration 44950, loss = 0.366374
I0905 09:43:45.210489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366375 (* 1 = 0.366375 loss)
I0905 09:43:45.210546 90901 sgd_solver.cpp:106] Iteration 44950, lr = 0.1
I0905 09:43:51.261363 90901 solver.cpp:228] Iteration 44960, loss = 0.269031
I0905 09:43:51.261409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269032 (* 1 = 0.269032 loss)
I0905 09:43:51.261425 90901 sgd_solver.cpp:106] Iteration 44960, lr = 0.1
I0905 09:43:57.063618 90901 solver.cpp:228] Iteration 44970, loss = 0.438238
I0905 09:43:57.063679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438239 (* 1 = 0.438239 loss)
I0905 09:43:57.063694 90901 sgd_solver.cpp:106] Iteration 44970, lr = 0.1
I0905 09:44:02.315665 90901 solver.cpp:228] Iteration 44980, loss = 0.288739
I0905 09:44:02.315717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288741 (* 1 = 0.288741 loss)
I0905 09:44:02.315732 90901 sgd_solver.cpp:106] Iteration 44980, lr = 0.1
I0905 09:44:08.228992 90901 solver.cpp:228] Iteration 44990, loss = 0.215323
I0905 09:44:08.229053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215325 (* 1 = 0.215325 loss)
I0905 09:44:08.229068 90901 sgd_solver.cpp:106] Iteration 44990, lr = 0.1
I0905 09:44:14.629468 90901 solver.cpp:228] Iteration 45000, loss = 0.468094
I0905 09:44:14.629523 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468095 (* 1 = 0.468095 loss)
I0905 09:44:14.629537 90901 sgd_solver.cpp:106] Iteration 45000, lr = 0.1
I0905 09:44:20.374404 90901 solver.cpp:228] Iteration 45010, loss = 0.185803
I0905 09:44:20.374558 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185805 (* 1 = 0.185805 loss)
I0905 09:44:20.374585 90901 sgd_solver.cpp:106] Iteration 45010, lr = 0.1
I0905 09:44:26.202373 90901 solver.cpp:228] Iteration 45020, loss = 0.177366
I0905 09:44:26.202430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177368 (* 1 = 0.177368 loss)
I0905 09:44:26.202443 90901 sgd_solver.cpp:106] Iteration 45020, lr = 0.1
I0905 09:44:32.586102 90901 solver.cpp:228] Iteration 45030, loss = 0.215377
I0905 09:44:32.586165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215378 (* 1 = 0.215378 loss)
I0905 09:44:32.586179 90901 sgd_solver.cpp:106] Iteration 45030, lr = 0.1
I0905 09:44:38.636294 90901 solver.cpp:228] Iteration 45040, loss = 0.270562
I0905 09:44:38.636343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270563 (* 1 = 0.270563 loss)
I0905 09:44:38.636358 90901 sgd_solver.cpp:106] Iteration 45040, lr = 0.1
I0905 09:44:44.740051 90901 solver.cpp:228] Iteration 45050, loss = 0.203856
I0905 09:44:44.740097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203857 (* 1 = 0.203857 loss)
I0905 09:44:44.740109 90901 sgd_solver.cpp:106] Iteration 45050, lr = 0.1
I0905 09:44:50.966584 90901 solver.cpp:228] Iteration 45060, loss = 0.204965
I0905 09:44:50.966800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204966 (* 1 = 0.204966 loss)
I0905 09:44:50.966815 90901 sgd_solver.cpp:106] Iteration 45060, lr = 0.1
I0905 09:44:56.890532 90901 solver.cpp:228] Iteration 45070, loss = 0.211794
I0905 09:44:56.890589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211795 (* 1 = 0.211795 loss)
I0905 09:44:56.890604 90901 sgd_solver.cpp:106] Iteration 45070, lr = 0.1
I0905 09:45:03.064537 90901 solver.cpp:228] Iteration 45080, loss = 0.166351
I0905 09:45:03.064580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166352 (* 1 = 0.166352 loss)
I0905 09:45:03.064599 90901 sgd_solver.cpp:106] Iteration 45080, lr = 0.1
I0905 09:45:09.329947 90901 solver.cpp:228] Iteration 45090, loss = 0.0925858
I0905 09:45:09.329995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.092587 (* 1 = 0.092587 loss)
I0905 09:45:09.330009 90901 sgd_solver.cpp:106] Iteration 45090, lr = 0.1
I0905 09:45:15.419154 90901 solver.cpp:228] Iteration 45100, loss = 0.402914
I0905 09:45:15.419205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402915 (* 1 = 0.402915 loss)
I0905 09:45:15.419221 90901 sgd_solver.cpp:106] Iteration 45100, lr = 0.1
I0905 09:45:21.498445 90901 solver.cpp:228] Iteration 45110, loss = 0.556638
I0905 09:45:21.498615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556639 (* 1 = 0.556639 loss)
I0905 09:45:21.498657 90901 sgd_solver.cpp:106] Iteration 45110, lr = 0.1
I0905 09:45:27.766692 90901 solver.cpp:228] Iteration 45120, loss = 0.41821
I0905 09:45:27.766736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418211 (* 1 = 0.418211 loss)
I0905 09:45:27.766748 90901 sgd_solver.cpp:106] Iteration 45120, lr = 0.1
I0905 09:45:33.615083 90901 solver.cpp:228] Iteration 45130, loss = 0.388268
I0905 09:45:33.615130 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.388269 (* 1 = 0.388269 loss)
I0905 09:45:33.615145 90901 sgd_solver.cpp:106] Iteration 45130, lr = 0.1
I0905 09:45:39.821979 90901 solver.cpp:228] Iteration 45140, loss = 0.472339
I0905 09:45:39.822028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472341 (* 1 = 0.472341 loss)
I0905 09:45:39.822042 90901 sgd_solver.cpp:106] Iteration 45140, lr = 0.1
I0905 09:45:45.517937 90901 solver.cpp:228] Iteration 45150, loss = 0.225231
I0905 09:45:45.517983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225233 (* 1 = 0.225233 loss)
I0905 09:45:45.517997 90901 sgd_solver.cpp:106] Iteration 45150, lr = 0.1
I0905 09:45:50.946602 90901 solver.cpp:228] Iteration 45160, loss = 0.0530319
I0905 09:45:50.946681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0530332 (* 1 = 0.0530332 loss)
I0905 09:45:50.946705 90901 sgd_solver.cpp:106] Iteration 45160, lr = 0.1
I0905 09:45:56.435621 90901 solver.cpp:228] Iteration 45170, loss = 0.29428
I0905 09:45:56.435852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294281 (* 1 = 0.294281 loss)
I0905 09:45:56.435869 90901 sgd_solver.cpp:106] Iteration 45170, lr = 0.1
I0905 09:46:02.728852 90901 solver.cpp:228] Iteration 45180, loss = 0.27853
I0905 09:46:02.728895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278531 (* 1 = 0.278531 loss)
I0905 09:46:02.728909 90901 sgd_solver.cpp:106] Iteration 45180, lr = 0.1
I0905 09:46:08.828464 90901 solver.cpp:228] Iteration 45190, loss = 0.428866
I0905 09:46:08.828516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428868 (* 1 = 0.428868 loss)
I0905 09:46:08.828531 90901 sgd_solver.cpp:106] Iteration 45190, lr = 0.1
I0905 09:46:14.919880 90901 solver.cpp:228] Iteration 45200, loss = 0.316988
I0905 09:46:14.919934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316989 (* 1 = 0.316989 loss)
I0905 09:46:14.919946 90901 sgd_solver.cpp:106] Iteration 45200, lr = 0.1
I0905 09:46:21.342598 90901 solver.cpp:228] Iteration 45210, loss = 0.239822
I0905 09:46:21.342676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239823 (* 1 = 0.239823 loss)
I0905 09:46:21.342692 90901 sgd_solver.cpp:106] Iteration 45210, lr = 0.1
I0905 09:46:27.428654 90901 solver.cpp:228] Iteration 45220, loss = 0.12215
I0905 09:46:27.428860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122151 (* 1 = 0.122151 loss)
I0905 09:46:27.428879 90901 sgd_solver.cpp:106] Iteration 45220, lr = 0.1
I0905 09:46:33.477437 90901 solver.cpp:228] Iteration 45230, loss = 0.491212
I0905 09:46:33.477495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491213 (* 1 = 0.491213 loss)
I0905 09:46:33.477509 90901 sgd_solver.cpp:106] Iteration 45230, lr = 0.1
I0905 09:46:39.572190 90901 solver.cpp:228] Iteration 45240, loss = 0.403852
I0905 09:46:39.572253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403854 (* 1 = 0.403854 loss)
I0905 09:46:39.572268 90901 sgd_solver.cpp:106] Iteration 45240, lr = 0.1
I0905 09:46:45.305621 90901 solver.cpp:228] Iteration 45250, loss = 0.317141
I0905 09:46:45.305665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317142 (* 1 = 0.317142 loss)
I0905 09:46:45.305678 90901 sgd_solver.cpp:106] Iteration 45250, lr = 0.1
I0905 09:46:51.031563 90901 solver.cpp:228] Iteration 45260, loss = 0.439835
I0905 09:46:51.031606 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439836 (* 1 = 0.439836 loss)
I0905 09:46:51.031620 90901 sgd_solver.cpp:106] Iteration 45260, lr = 0.1
I0905 09:46:57.778177 90901 solver.cpp:228] Iteration 45270, loss = 0.139937
I0905 09:46:57.778352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139938 (* 1 = 0.139938 loss)
I0905 09:46:57.778379 90901 sgd_solver.cpp:106] Iteration 45270, lr = 0.1
I0905 09:47:03.679420 90901 solver.cpp:228] Iteration 45280, loss = 0.373629
I0905 09:47:03.679466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37363 (* 1 = 0.37363 loss)
I0905 09:47:03.679478 90901 sgd_solver.cpp:106] Iteration 45280, lr = 0.1
I0905 09:47:09.582360 90901 solver.cpp:228] Iteration 45290, loss = 0.219421
I0905 09:47:09.582413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219422 (* 1 = 0.219422 loss)
I0905 09:47:09.582427 90901 sgd_solver.cpp:106] Iteration 45290, lr = 0.1
I0905 09:47:15.669872 90901 solver.cpp:228] Iteration 45300, loss = 0.39188
I0905 09:47:15.669929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391881 (* 1 = 0.391881 loss)
I0905 09:47:15.669944 90901 sgd_solver.cpp:106] Iteration 45300, lr = 0.1
I0905 09:47:21.779577 90901 solver.cpp:228] Iteration 45310, loss = 0.2503
I0905 09:47:21.779623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250301 (* 1 = 0.250301 loss)
I0905 09:47:21.779638 90901 sgd_solver.cpp:106] Iteration 45310, lr = 0.1
I0905 09:47:27.840427 90901 solver.cpp:228] Iteration 45320, loss = 0.295275
I0905 09:47:27.840580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295276 (* 1 = 0.295276 loss)
I0905 09:47:27.840611 90901 sgd_solver.cpp:106] Iteration 45320, lr = 0.1
I0905 09:47:33.404453 90901 solver.cpp:228] Iteration 45330, loss = 0.372546
I0905 09:47:33.404513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372547 (* 1 = 0.372547 loss)
I0905 09:47:33.404528 90901 sgd_solver.cpp:106] Iteration 45330, lr = 0.1
I0905 09:47:38.812263 90901 solver.cpp:228] Iteration 45340, loss = 0.233767
I0905 09:47:38.812335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233768 (* 1 = 0.233768 loss)
I0905 09:47:38.812350 90901 sgd_solver.cpp:106] Iteration 45340, lr = 0.1
I0905 09:47:44.891571 90901 solver.cpp:228] Iteration 45350, loss = 0.113333
I0905 09:47:44.891621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113334 (* 1 = 0.113334 loss)
I0905 09:47:44.891633 90901 sgd_solver.cpp:106] Iteration 45350, lr = 0.1
I0905 09:47:51.280843 90901 solver.cpp:228] Iteration 45360, loss = 0.428021
I0905 09:47:51.280887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428022 (* 1 = 0.428022 loss)
I0905 09:47:51.280906 90901 sgd_solver.cpp:106] Iteration 45360, lr = 0.1
I0905 09:47:57.388937 90901 solver.cpp:228] Iteration 45370, loss = 0.158464
I0905 09:47:57.388983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158465 (* 1 = 0.158465 loss)
I0905 09:47:57.388998 90901 sgd_solver.cpp:106] Iteration 45370, lr = 0.1
I0905 09:48:03.467435 90901 solver.cpp:228] Iteration 45380, loss = 0.113166
I0905 09:48:03.467696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113167 (* 1 = 0.113167 loss)
I0905 09:48:03.467725 90901 sgd_solver.cpp:106] Iteration 45380, lr = 0.1
I0905 09:48:09.246868 90901 solver.cpp:228] Iteration 45390, loss = 0.291478
I0905 09:48:09.246927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291479 (* 1 = 0.291479 loss)
I0905 09:48:09.246942 90901 sgd_solver.cpp:106] Iteration 45390, lr = 0.1
I0905 09:48:15.696399 90901 solver.cpp:228] Iteration 45400, loss = 0.248133
I0905 09:48:15.696439 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248134 (* 1 = 0.248134 loss)
I0905 09:48:15.696454 90901 sgd_solver.cpp:106] Iteration 45400, lr = 0.1
I0905 09:48:21.596531 90901 solver.cpp:228] Iteration 45410, loss = 0.3181
I0905 09:48:21.596575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318101 (* 1 = 0.318101 loss)
I0905 09:48:21.596587 90901 sgd_solver.cpp:106] Iteration 45410, lr = 0.1
I0905 09:48:27.818102 90901 solver.cpp:228] Iteration 45420, loss = 0.555521
I0905 09:48:27.818143 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555522 (* 1 = 0.555522 loss)
I0905 09:48:27.818157 90901 sgd_solver.cpp:106] Iteration 45420, lr = 0.1
I0905 09:48:33.849553 90901 solver.cpp:228] Iteration 45430, loss = 0.163782
I0905 09:48:33.849694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163783 (* 1 = 0.163783 loss)
I0905 09:48:33.849720 90901 sgd_solver.cpp:106] Iteration 45430, lr = 0.1
I0905 09:48:39.910465 90901 solver.cpp:228] Iteration 45440, loss = 0.592948
I0905 09:48:39.910531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.59295 (* 1 = 0.59295 loss)
I0905 09:48:39.910545 90901 sgd_solver.cpp:106] Iteration 45440, lr = 0.1
I0905 09:48:46.021428 90901 solver.cpp:228] Iteration 45450, loss = 0.225476
I0905 09:48:46.021472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225477 (* 1 = 0.225477 loss)
I0905 09:48:46.021486 90901 sgd_solver.cpp:106] Iteration 45450, lr = 0.1
I0905 09:48:52.425629 90901 solver.cpp:228] Iteration 45460, loss = 0.193754
I0905 09:48:52.425688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193755 (* 1 = 0.193755 loss)
I0905 09:48:52.425701 90901 sgd_solver.cpp:106] Iteration 45460, lr = 0.1
I0905 09:48:58.200985 90901 solver.cpp:228] Iteration 45470, loss = 0.354036
I0905 09:48:58.201035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354037 (* 1 = 0.354037 loss)
I0905 09:48:58.201048 90901 sgd_solver.cpp:106] Iteration 45470, lr = 0.1
I0905 09:49:04.607563 90901 solver.cpp:228] Iteration 45480, loss = 0.144478
I0905 09:49:04.607771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144479 (* 1 = 0.144479 loss)
I0905 09:49:04.607805 90901 sgd_solver.cpp:106] Iteration 45480, lr = 0.1
I0905 09:49:10.680963 90901 solver.cpp:228] Iteration 45490, loss = 0.161977
I0905 09:49:10.681025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161978 (* 1 = 0.161978 loss)
I0905 09:49:10.681041 90901 sgd_solver.cpp:106] Iteration 45490, lr = 0.1
I0905 09:49:16.547353 90901 solver.cpp:228] Iteration 45500, loss = 0.225795
I0905 09:49:16.547401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225796 (* 1 = 0.225796 loss)
I0905 09:49:16.547415 90901 sgd_solver.cpp:106] Iteration 45500, lr = 0.1
I0905 09:49:21.822656 90901 solver.cpp:228] Iteration 45510, loss = 0.444114
I0905 09:49:21.822703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444116 (* 1 = 0.444116 loss)
I0905 09:49:21.822721 90901 sgd_solver.cpp:106] Iteration 45510, lr = 0.1
I0905 09:49:27.736878 90901 solver.cpp:228] Iteration 45520, loss = 0.470099
I0905 09:49:27.736922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4701 (* 1 = 0.4701 loss)
I0905 09:49:27.736933 90901 sgd_solver.cpp:106] Iteration 45520, lr = 0.1
I0905 09:49:33.797696 90901 solver.cpp:228] Iteration 45530, loss = 0.207809
I0905 09:49:33.797741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20781 (* 1 = 0.20781 loss)
I0905 09:49:33.797755 90901 sgd_solver.cpp:106] Iteration 45530, lr = 0.1
I0905 09:49:40.100497 90901 solver.cpp:228] Iteration 45540, loss = 0.300565
I0905 09:49:40.100627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300566 (* 1 = 0.300566 loss)
I0905 09:49:40.100672 90901 sgd_solver.cpp:106] Iteration 45540, lr = 0.1
I0905 09:49:46.015707 90901 solver.cpp:228] Iteration 45550, loss = 0.169171
I0905 09:49:46.015763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169172 (* 1 = 0.169172 loss)
I0905 09:49:46.015779 90901 sgd_solver.cpp:106] Iteration 45550, lr = 0.1
I0905 09:49:52.084054 90901 solver.cpp:228] Iteration 45560, loss = 0.0828106
I0905 09:49:52.084103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0828118 (* 1 = 0.0828118 loss)
I0905 09:49:52.084116 90901 sgd_solver.cpp:106] Iteration 45560, lr = 0.1
I0905 09:49:58.505697 90901 solver.cpp:228] Iteration 45570, loss = 0.181305
I0905 09:49:58.505749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181306 (* 1 = 0.181306 loss)
I0905 09:49:58.505764 90901 sgd_solver.cpp:106] Iteration 45570, lr = 0.1
I0905 09:50:04.554374 90901 solver.cpp:228] Iteration 45580, loss = 0.209893
I0905 09:50:04.554422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209895 (* 1 = 0.209895 loss)
I0905 09:50:04.554436 90901 sgd_solver.cpp:106] Iteration 45580, lr = 0.1
I0905 09:50:10.719295 90901 solver.cpp:228] Iteration 45590, loss = 0.251939
I0905 09:50:10.719477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251941 (* 1 = 0.251941 loss)
I0905 09:50:10.719494 90901 sgd_solver.cpp:106] Iteration 45590, lr = 0.1
I0905 09:50:16.235636 90901 solver.cpp:337] Iteration 45600, Testing net (#0)
I0905 09:50:58.792003 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.866562
I0905 09:50:58.792153 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.311021 (* 1 = 0.311021 loss)
I0905 09:50:59.112056 90901 solver.cpp:228] Iteration 45600, loss = 0.0718614
I0905 09:50:59.112092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0718626 (* 1 = 0.0718626 loss)
I0905 09:50:59.112107 90901 sgd_solver.cpp:106] Iteration 45600, lr = 0.1
I0905 09:51:04.655910 90901 solver.cpp:228] Iteration 45610, loss = 0.18045
I0905 09:51:04.655956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180451 (* 1 = 0.180451 loss)
I0905 09:51:04.655969 90901 sgd_solver.cpp:106] Iteration 45610, lr = 0.1
I0905 09:51:09.925370 90901 solver.cpp:228] Iteration 45620, loss = 0.355061
I0905 09:51:09.925424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355062 (* 1 = 0.355062 loss)
I0905 09:51:09.925442 90901 sgd_solver.cpp:106] Iteration 45620, lr = 0.1
I0905 09:51:16.363720 90901 solver.cpp:228] Iteration 45630, loss = 0.183859
I0905 09:51:16.363775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18386 (* 1 = 0.18386 loss)
I0905 09:51:16.363787 90901 sgd_solver.cpp:106] Iteration 45630, lr = 0.1
I0905 09:51:22.429620 90901 solver.cpp:228] Iteration 45640, loss = 0.173835
I0905 09:51:22.429675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173836 (* 1 = 0.173836 loss)
I0905 09:51:22.429689 90901 sgd_solver.cpp:106] Iteration 45640, lr = 0.1
I0905 09:51:28.521344 90901 solver.cpp:228] Iteration 45650, loss = 0.395202
I0905 09:51:28.521399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395203 (* 1 = 0.395203 loss)
I0905 09:51:28.521412 90901 sgd_solver.cpp:106] Iteration 45650, lr = 0.1
I0905 09:51:34.614450 90901 solver.cpp:228] Iteration 45660, loss = 0.157468
I0905 09:51:34.614742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15747 (* 1 = 0.15747 loss)
I0905 09:51:34.614758 90901 sgd_solver.cpp:106] Iteration 45660, lr = 0.1
I0905 09:51:40.764917 90901 solver.cpp:228] Iteration 45670, loss = 0.149663
I0905 09:51:40.764981 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149664 (* 1 = 0.149664 loss)
I0905 09:51:40.764993 90901 sgd_solver.cpp:106] Iteration 45670, lr = 0.1
I0905 09:51:47.047386 90901 solver.cpp:228] Iteration 45680, loss = 0.893976
I0905 09:51:47.047446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.893978 (* 1 = 0.893978 loss)
I0905 09:51:47.047459 90901 sgd_solver.cpp:106] Iteration 45680, lr = 0.1
I0905 09:51:53.117244 90901 solver.cpp:228] Iteration 45690, loss = 0.501064
I0905 09:51:53.117302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501066 (* 1 = 0.501066 loss)
I0905 09:51:53.117316 90901 sgd_solver.cpp:106] Iteration 45690, lr = 0.1
I0905 09:51:59.532935 90901 solver.cpp:228] Iteration 45700, loss = 0.39636
I0905 09:51:59.532984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396361 (* 1 = 0.396361 loss)
I0905 09:51:59.532997 90901 sgd_solver.cpp:106] Iteration 45700, lr = 0.1
I0905 09:52:05.642446 90901 solver.cpp:228] Iteration 45710, loss = 0.355025
I0905 09:52:05.642663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355026 (* 1 = 0.355026 loss)
I0905 09:52:05.642684 90901 sgd_solver.cpp:106] Iteration 45710, lr = 0.1
I0905 09:52:11.697577 90901 solver.cpp:228] Iteration 45720, loss = 0.541279
I0905 09:52:11.697633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541281 (* 1 = 0.541281 loss)
I0905 09:52:11.697648 90901 sgd_solver.cpp:106] Iteration 45720, lr = 0.1
I0905 09:52:17.769301 90901 solver.cpp:228] Iteration 45730, loss = 0.560786
I0905 09:52:17.769351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.560787 (* 1 = 0.560787 loss)
I0905 09:52:17.769363 90901 sgd_solver.cpp:106] Iteration 45730, lr = 0.1
I0905 09:52:23.841848 90901 solver.cpp:228] Iteration 45740, loss = 0.390194
I0905 09:52:23.841893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390196 (* 1 = 0.390196 loss)
I0905 09:52:23.841907 90901 sgd_solver.cpp:106] Iteration 45740, lr = 0.1
I0905 09:52:29.948895 90901 solver.cpp:228] Iteration 45750, loss = 0.323277
I0905 09:52:29.948935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323278 (* 1 = 0.323278 loss)
I0905 09:52:29.948948 90901 sgd_solver.cpp:106] Iteration 45750, lr = 0.1
I0905 09:52:36.006755 90901 solver.cpp:228] Iteration 45760, loss = 0.443774
I0905 09:52:36.006925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443776 (* 1 = 0.443776 loss)
I0905 09:52:36.006966 90901 sgd_solver.cpp:106] Iteration 45760, lr = 0.1
I0905 09:52:42.112295 90901 solver.cpp:228] Iteration 45770, loss = 0.1127
I0905 09:52:42.112349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112701 (* 1 = 0.112701 loss)
I0905 09:52:42.112363 90901 sgd_solver.cpp:106] Iteration 45770, lr = 0.1
I0905 09:52:48.099179 90901 solver.cpp:228] Iteration 45780, loss = 0.437993
I0905 09:52:48.099222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.437994 (* 1 = 0.437994 loss)
I0905 09:52:48.099234 90901 sgd_solver.cpp:106] Iteration 45780, lr = 0.1
I0905 09:52:53.666136 90901 solver.cpp:228] Iteration 45790, loss = 0.250208
I0905 09:52:53.666187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250209 (* 1 = 0.250209 loss)
I0905 09:52:53.666200 90901 sgd_solver.cpp:106] Iteration 45790, lr = 0.1
I0905 09:52:59.176923 90901 solver.cpp:228] Iteration 45800, loss = 0.123139
I0905 09:52:59.176973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123141 (* 1 = 0.123141 loss)
I0905 09:52:59.176988 90901 sgd_solver.cpp:106] Iteration 45800, lr = 0.1
I0905 09:53:05.307003 90901 solver.cpp:228] Iteration 45810, loss = 0.0742066
I0905 09:53:05.307052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0742079 (* 1 = 0.0742079 loss)
I0905 09:53:05.307065 90901 sgd_solver.cpp:106] Iteration 45810, lr = 0.1
I0905 09:53:11.388864 90901 solver.cpp:228] Iteration 45820, loss = 0.426019
I0905 09:53:11.389108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426021 (* 1 = 0.426021 loss)
I0905 09:53:11.389134 90901 sgd_solver.cpp:106] Iteration 45820, lr = 0.1
I0905 09:53:17.476096 90901 solver.cpp:228] Iteration 45830, loss = 0.524393
I0905 09:53:17.476145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.524394 (* 1 = 0.524394 loss)
I0905 09:53:17.476156 90901 sgd_solver.cpp:106] Iteration 45830, lr = 0.1
I0905 09:53:23.563168 90901 solver.cpp:228] Iteration 45840, loss = 0.339445
I0905 09:53:23.563225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339446 (* 1 = 0.339446 loss)
I0905 09:53:23.563238 90901 sgd_solver.cpp:106] Iteration 45840, lr = 0.1
I0905 09:53:29.976148 90901 solver.cpp:228] Iteration 45850, loss = 0.231677
I0905 09:53:29.976207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231678 (* 1 = 0.231678 loss)
I0905 09:53:29.976222 90901 sgd_solver.cpp:106] Iteration 45850, lr = 0.1
I0905 09:53:36.076216 90901 solver.cpp:228] Iteration 45860, loss = 0.181254
I0905 09:53:36.076268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181256 (* 1 = 0.181256 loss)
I0905 09:53:36.076283 90901 sgd_solver.cpp:106] Iteration 45860, lr = 0.1
I0905 09:53:42.171094 90901 solver.cpp:228] Iteration 45870, loss = 0.127889
I0905 09:53:42.171253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127891 (* 1 = 0.127891 loss)
I0905 09:53:42.171279 90901 sgd_solver.cpp:106] Iteration 45870, lr = 0.1
I0905 09:53:48.256422 90901 solver.cpp:228] Iteration 45880, loss = 0.186608
I0905 09:53:48.256463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18661 (* 1 = 0.18661 loss)
I0905 09:53:48.256474 90901 sgd_solver.cpp:106] Iteration 45880, lr = 0.1
I0905 09:53:54.329810 90901 solver.cpp:228] Iteration 45890, loss = 0.549822
I0905 09:53:54.329856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.549824 (* 1 = 0.549824 loss)
I0905 09:53:54.329870 90901 sgd_solver.cpp:106] Iteration 45890, lr = 0.1
I0905 09:54:00.723881 90901 solver.cpp:228] Iteration 45900, loss = 0.367371
I0905 09:54:00.723923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367372 (* 1 = 0.367372 loss)
I0905 09:54:00.723937 90901 sgd_solver.cpp:106] Iteration 45900, lr = 0.1
I0905 09:54:06.760082 90901 solver.cpp:228] Iteration 45910, loss = 0.50773
I0905 09:54:06.760118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507732 (* 1 = 0.507732 loss)
I0905 09:54:06.760131 90901 sgd_solver.cpp:106] Iteration 45910, lr = 0.1
I0905 09:54:12.872745 90901 solver.cpp:228] Iteration 45920, loss = 0.48023
I0905 09:54:12.872917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480232 (* 1 = 0.480232 loss)
I0905 09:54:12.872939 90901 sgd_solver.cpp:106] Iteration 45920, lr = 0.1
I0905 09:54:18.937343 90901 solver.cpp:228] Iteration 45930, loss = 0.273888
I0905 09:54:18.937397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27389 (* 1 = 0.27389 loss)
I0905 09:54:18.937412 90901 sgd_solver.cpp:106] Iteration 45930, lr = 0.1
I0905 09:54:25.061537 90901 solver.cpp:228] Iteration 45940, loss = 0.160287
I0905 09:54:25.061578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160288 (* 1 = 0.160288 loss)
I0905 09:54:25.061589 90901 sgd_solver.cpp:106] Iteration 45940, lr = 0.1
I0905 09:54:31.155652 90901 solver.cpp:228] Iteration 45950, loss = 0.332828
I0905 09:54:31.155705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33283 (* 1 = 0.33283 loss)
I0905 09:54:31.155719 90901 sgd_solver.cpp:106] Iteration 45950, lr = 0.1
I0905 09:54:36.917124 90901 solver.cpp:228] Iteration 45960, loss = 0.32618
I0905 09:54:36.917172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326182 (* 1 = 0.326182 loss)
I0905 09:54:36.917186 90901 sgd_solver.cpp:106] Iteration 45960, lr = 0.1
I0905 09:54:42.185408 90901 solver.cpp:228] Iteration 45970, loss = 0.153163
I0905 09:54:42.185459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153164 (* 1 = 0.153164 loss)
I0905 09:54:42.185473 90901 sgd_solver.cpp:106] Iteration 45970, lr = 0.1
I0905 09:54:48.119210 90901 solver.cpp:228] Iteration 45980, loss = 0.0996106
I0905 09:54:48.119385 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.099612 (* 1 = 0.099612 loss)
I0905 09:54:48.119426 90901 sgd_solver.cpp:106] Iteration 45980, lr = 0.1
I0905 09:54:54.207329 90901 solver.cpp:228] Iteration 45990, loss = 0.231392
I0905 09:54:54.207376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231393 (* 1 = 0.231393 loss)
I0905 09:54:54.207391 90901 sgd_solver.cpp:106] Iteration 45990, lr = 0.1
I0905 09:55:00.270859 90901 solver.cpp:228] Iteration 46000, loss = 0.154261
I0905 09:55:00.270918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154263 (* 1 = 0.154263 loss)
I0905 09:55:00.270937 90901 sgd_solver.cpp:106] Iteration 46000, lr = 0.1
I0905 09:55:06.376318 90901 solver.cpp:228] Iteration 46010, loss = 0.294744
I0905 09:55:06.376369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294745 (* 1 = 0.294745 loss)
I0905 09:55:06.376382 90901 sgd_solver.cpp:106] Iteration 46010, lr = 0.1
I0905 09:55:12.462019 90901 solver.cpp:228] Iteration 46020, loss = 0.62474
I0905 09:55:12.462066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.624741 (* 1 = 0.624741 loss)
I0905 09:55:12.462080 90901 sgd_solver.cpp:106] Iteration 46020, lr = 0.1
I0905 09:55:18.888550 90901 solver.cpp:228] Iteration 46030, loss = 0.0563786
I0905 09:55:18.888773 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.05638 (* 1 = 0.05638 loss)
I0905 09:55:18.888803 90901 sgd_solver.cpp:106] Iteration 46030, lr = 0.1
I0905 09:55:24.967761 90901 solver.cpp:228] Iteration 46040, loss = 0.363925
I0905 09:55:24.967813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363927 (* 1 = 0.363927 loss)
I0905 09:55:24.967825 90901 sgd_solver.cpp:106] Iteration 46040, lr = 0.1
I0905 09:55:31.085320 90901 solver.cpp:228] Iteration 46050, loss = 0.162609
I0905 09:55:31.085376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16261 (* 1 = 0.16261 loss)
I0905 09:55:31.085388 90901 sgd_solver.cpp:106] Iteration 46050, lr = 0.1
I0905 09:55:37.498539 90901 solver.cpp:228] Iteration 46060, loss = 0.197718
I0905 09:55:37.498594 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19772 (* 1 = 0.19772 loss)
I0905 09:55:37.498608 90901 sgd_solver.cpp:106] Iteration 46060, lr = 0.1
I0905 09:55:43.556303 90901 solver.cpp:228] Iteration 46070, loss = 0.261431
I0905 09:55:43.556346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261433 (* 1 = 0.261433 loss)
I0905 09:55:43.556360 90901 sgd_solver.cpp:106] Iteration 46070, lr = 0.1
I0905 09:55:49.615327 90901 solver.cpp:228] Iteration 46080, loss = 0.391483
I0905 09:55:49.615545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391484 (* 1 = 0.391484 loss)
I0905 09:55:49.615572 90901 sgd_solver.cpp:106] Iteration 46080, lr = 0.1
I0905 09:55:55.739907 90901 solver.cpp:228] Iteration 46090, loss = 0.268378
I0905 09:55:55.739953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268379 (* 1 = 0.268379 loss)
I0905 09:55:55.739967 90901 sgd_solver.cpp:106] Iteration 46090, lr = 0.1
I0905 09:56:01.704658 90901 solver.cpp:228] Iteration 46100, loss = 0.203801
I0905 09:56:01.704702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203802 (* 1 = 0.203802 loss)
I0905 09:56:01.704718 90901 sgd_solver.cpp:106] Iteration 46100, lr = 0.1
I0905 09:56:07.569859 90901 solver.cpp:228] Iteration 46110, loss = 0.253046
I0905 09:56:07.569905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253047 (* 1 = 0.253047 loss)
I0905 09:56:07.569918 90901 sgd_solver.cpp:106] Iteration 46110, lr = 0.1
I0905 09:56:12.615036 90901 solver.cpp:228] Iteration 46120, loss = 0.138857
I0905 09:56:12.615082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138858 (* 1 = 0.138858 loss)
I0905 09:56:12.615095 90901 sgd_solver.cpp:106] Iteration 46120, lr = 0.1
I0905 09:56:17.665545 90901 solver.cpp:228] Iteration 46130, loss = 0.185355
I0905 09:56:17.665603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185356 (* 1 = 0.185356 loss)
I0905 09:56:17.665617 90901 sgd_solver.cpp:106] Iteration 46130, lr = 0.1
I0905 09:56:22.615739 90901 solver.cpp:228] Iteration 46140, loss = 0.810857
I0905 09:56:22.615902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.810858 (* 1 = 0.810858 loss)
I0905 09:56:22.615934 90901 sgd_solver.cpp:106] Iteration 46140, lr = 0.1
I0905 09:56:27.272140 90901 solver.cpp:228] Iteration 46150, loss = 0.140499
I0905 09:56:27.272186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1405 (* 1 = 0.1405 loss)
I0905 09:56:27.272199 90901 sgd_solver.cpp:106] Iteration 46150, lr = 0.1
I0905 09:56:31.925139 90901 solver.cpp:228] Iteration 46160, loss = 0.543826
I0905 09:56:31.925185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543827 (* 1 = 0.543827 loss)
I0905 09:56:31.925199 90901 sgd_solver.cpp:106] Iteration 46160, lr = 0.1
I0905 09:56:36.897238 90901 solver.cpp:228] Iteration 46170, loss = 0.301955
I0905 09:56:36.897296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301957 (* 1 = 0.301957 loss)
I0905 09:56:36.897308 90901 sgd_solver.cpp:106] Iteration 46170, lr = 0.1
I0905 09:56:41.962502 90901 solver.cpp:228] Iteration 46180, loss = 0.216201
I0905 09:56:41.962546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216202 (* 1 = 0.216202 loss)
I0905 09:56:41.962561 90901 sgd_solver.cpp:106] Iteration 46180, lr = 0.1
I0905 09:56:47.017243 90901 solver.cpp:228] Iteration 46190, loss = 0.224845
I0905 09:56:47.017289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224846 (* 1 = 0.224846 loss)
I0905 09:56:47.017303 90901 sgd_solver.cpp:106] Iteration 46190, lr = 0.1
I0905 09:56:52.064162 90901 solver.cpp:228] Iteration 46200, loss = 0.461961
I0905 09:56:52.064224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461962 (* 1 = 0.461962 loss)
I0905 09:56:52.064239 90901 sgd_solver.cpp:106] Iteration 46200, lr = 0.1
I0905 09:56:57.157470 90901 solver.cpp:228] Iteration 46210, loss = 0.337509
I0905 09:56:57.157591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33751 (* 1 = 0.33751 loss)
I0905 09:56:57.157624 90901 sgd_solver.cpp:106] Iteration 46210, lr = 0.1
I0905 09:57:02.194586 90901 solver.cpp:228] Iteration 46220, loss = 0.190564
I0905 09:57:02.194641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190565 (* 1 = 0.190565 loss)
I0905 09:57:02.194664 90901 sgd_solver.cpp:106] Iteration 46220, lr = 0.1
I0905 09:57:07.255677 90901 solver.cpp:228] Iteration 46230, loss = 0.0925574
I0905 09:57:07.255728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0925587 (* 1 = 0.0925587 loss)
I0905 09:57:07.255743 90901 sgd_solver.cpp:106] Iteration 46230, lr = 0.1
I0905 09:57:12.322902 90901 solver.cpp:228] Iteration 46240, loss = 0.158564
I0905 09:57:12.322947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158566 (* 1 = 0.158566 loss)
I0905 09:57:12.322960 90901 sgd_solver.cpp:106] Iteration 46240, lr = 0.1
I0905 09:57:17.377271 90901 solver.cpp:228] Iteration 46250, loss = 0.164612
I0905 09:57:17.377342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164613 (* 1 = 0.164613 loss)
I0905 09:57:17.377359 90901 sgd_solver.cpp:106] Iteration 46250, lr = 0.1
I0905 09:57:22.477818 90901 solver.cpp:228] Iteration 46260, loss = 0.250002
I0905 09:57:22.477870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250004 (* 1 = 0.250004 loss)
I0905 09:57:22.477885 90901 sgd_solver.cpp:106] Iteration 46260, lr = 0.1
I0905 09:57:27.521278 90901 solver.cpp:228] Iteration 46270, loss = 0.357169
I0905 09:57:27.521477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35717 (* 1 = 0.35717 loss)
I0905 09:57:27.521522 90901 sgd_solver.cpp:106] Iteration 46270, lr = 0.1
I0905 09:57:33.248961 90901 solver.cpp:228] Iteration 46280, loss = 0.329214
I0905 09:57:33.249020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329215 (* 1 = 0.329215 loss)
I0905 09:57:33.249035 90901 sgd_solver.cpp:106] Iteration 46280, lr = 0.1
I0905 09:57:39.394837 90901 solver.cpp:228] Iteration 46290, loss = 0.241658
I0905 09:57:39.394887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241659 (* 1 = 0.241659 loss)
I0905 09:57:39.394901 90901 sgd_solver.cpp:106] Iteration 46290, lr = 0.1
I0905 09:57:45.671070 90901 solver.cpp:228] Iteration 46300, loss = 0.226522
I0905 09:57:45.671114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226523 (* 1 = 0.226523 loss)
I0905 09:57:45.671126 90901 sgd_solver.cpp:106] Iteration 46300, lr = 0.1
I0905 09:57:51.741652 90901 solver.cpp:228] Iteration 46310, loss = 0.154416
I0905 09:57:51.741703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154417 (* 1 = 0.154417 loss)
I0905 09:57:51.741717 90901 sgd_solver.cpp:106] Iteration 46310, lr = 0.1
I0905 09:57:57.867359 90901 solver.cpp:228] Iteration 46320, loss = 0.404908
I0905 09:57:57.867529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40491 (* 1 = 0.40491 loss)
I0905 09:57:57.867575 90901 sgd_solver.cpp:106] Iteration 46320, lr = 0.1
I0905 09:58:03.925876 90901 solver.cpp:228] Iteration 46330, loss = 0.597148
I0905 09:58:03.925930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.597149 (* 1 = 0.597149 loss)
I0905 09:58:03.925943 90901 sgd_solver.cpp:106] Iteration 46330, lr = 0.1
I0905 09:58:10.007112 90901 solver.cpp:228] Iteration 46340, loss = 0.450222
I0905 09:58:10.007154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450223 (* 1 = 0.450223 loss)
I0905 09:58:10.007172 90901 sgd_solver.cpp:106] Iteration 46340, lr = 0.1
I0905 09:58:15.813673 90901 solver.cpp:228] Iteration 46350, loss = 0.124277
I0905 09:58:15.813717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124278 (* 1 = 0.124278 loss)
I0905 09:58:15.813730 90901 sgd_solver.cpp:106] Iteration 46350, lr = 0.1
I0905 09:58:21.383921 90901 solver.cpp:228] Iteration 46360, loss = 0.307394
I0905 09:58:21.383965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307395 (* 1 = 0.307395 loss)
I0905 09:58:21.383980 90901 sgd_solver.cpp:106] Iteration 46360, lr = 0.1
I0905 09:58:27.062410 90901 solver.cpp:228] Iteration 46370, loss = 0.232067
I0905 09:58:27.062454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232069 (* 1 = 0.232069 loss)
I0905 09:58:27.062468 90901 sgd_solver.cpp:106] Iteration 46370, lr = 0.1
I0905 09:58:33.170668 90901 solver.cpp:228] Iteration 46380, loss = 0.369836
I0905 09:58:33.170910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369837 (* 1 = 0.369837 loss)
I0905 09:58:33.170928 90901 sgd_solver.cpp:106] Iteration 46380, lr = 0.1
I0905 09:58:39.348291 90901 solver.cpp:228] Iteration 46390, loss = 0.125723
I0905 09:58:39.348347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125724 (* 1 = 0.125724 loss)
I0905 09:58:39.348361 90901 sgd_solver.cpp:106] Iteration 46390, lr = 0.1
I0905 09:58:45.322746 90901 solver.cpp:337] Iteration 46400, Testing net (#0)
I0905 09:59:27.752179 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.807813
I0905 09:59:27.752362 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.506733 (* 1 = 0.506733 loss)
I0905 09:59:28.178637 90901 solver.cpp:228] Iteration 46400, loss = 0.221576
I0905 09:59:28.178705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221577 (* 1 = 0.221577 loss)
I0905 09:59:28.178722 90901 sgd_solver.cpp:106] Iteration 46400, lr = 0.1
I0905 09:59:34.301784 90901 solver.cpp:228] Iteration 46410, loss = 0.223606
I0905 09:59:34.301825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223607 (* 1 = 0.223607 loss)
I0905 09:59:34.301837 90901 sgd_solver.cpp:106] Iteration 46410, lr = 0.1
I0905 09:59:40.345502 90901 solver.cpp:228] Iteration 46420, loss = 0.203151
I0905 09:59:40.345540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203152 (* 1 = 0.203152 loss)
I0905 09:59:40.345556 90901 sgd_solver.cpp:106] Iteration 46420, lr = 0.1
I0905 09:59:46.643136 90901 solver.cpp:228] Iteration 46430, loss = 0.458282
I0905 09:59:46.643177 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458283 (* 1 = 0.458283 loss)
I0905 09:59:46.643190 90901 sgd_solver.cpp:106] Iteration 46430, lr = 0.1
I0905 09:59:52.831544 90901 solver.cpp:228] Iteration 46440, loss = 0.0830261
I0905 09:59:52.831583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0830273 (* 1 = 0.0830273 loss)
I0905 09:59:52.831595 90901 sgd_solver.cpp:106] Iteration 46440, lr = 0.1
I0905 09:59:58.910940 90901 solver.cpp:228] Iteration 46450, loss = 0.315051
I0905 09:59:58.911098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315052 (* 1 = 0.315052 loss)
I0905 09:59:58.911145 90901 sgd_solver.cpp:106] Iteration 46450, lr = 0.1
I0905 10:00:04.258329 90901 solver.cpp:228] Iteration 46460, loss = 0.550949
I0905 10:00:04.258376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.55095 (* 1 = 0.55095 loss)
I0905 10:00:04.258390 90901 sgd_solver.cpp:106] Iteration 46460, lr = 0.1
I0905 10:00:09.546016 90901 solver.cpp:228] Iteration 46470, loss = 0.24149
I0905 10:00:09.546072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241491 (* 1 = 0.241491 loss)
I0905 10:00:09.546087 90901 sgd_solver.cpp:106] Iteration 46470, lr = 0.1
I0905 10:00:15.939388 90901 solver.cpp:228] Iteration 46480, loss = 0.452031
I0905 10:00:15.939437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.452032 (* 1 = 0.452032 loss)
I0905 10:00:15.939452 90901 sgd_solver.cpp:106] Iteration 46480, lr = 0.1
I0905 10:00:21.993158 90901 solver.cpp:228] Iteration 46490, loss = 0.285779
I0905 10:00:21.993211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28578 (* 1 = 0.28578 loss)
I0905 10:00:21.993222 90901 sgd_solver.cpp:106] Iteration 46490, lr = 0.1
I0905 10:00:28.090328 90901 solver.cpp:228] Iteration 46500, loss = 0.521559
I0905 10:00:28.090380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.52156 (* 1 = 0.52156 loss)
I0905 10:00:28.090394 90901 sgd_solver.cpp:106] Iteration 46500, lr = 0.1
I0905 10:00:34.141149 90901 solver.cpp:228] Iteration 46510, loss = 0.297244
I0905 10:00:34.141324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297246 (* 1 = 0.297246 loss)
I0905 10:00:34.141371 90901 sgd_solver.cpp:106] Iteration 46510, lr = 0.1
I0905 10:00:40.177306 90901 solver.cpp:228] Iteration 46520, loss = 0.140397
I0905 10:00:40.177361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140398 (* 1 = 0.140398 loss)
I0905 10:00:40.177373 90901 sgd_solver.cpp:106] Iteration 46520, lr = 0.1
I0905 10:00:46.299757 90901 solver.cpp:228] Iteration 46530, loss = 0.0941926
I0905 10:00:46.299800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0941938 (* 1 = 0.0941938 loss)
I0905 10:00:46.299814 90901 sgd_solver.cpp:106] Iteration 46530, lr = 0.1
I0905 10:00:52.694936 90901 solver.cpp:228] Iteration 46540, loss = 0.089684
I0905 10:00:52.694969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0896852 (* 1 = 0.0896852 loss)
I0905 10:00:52.694983 90901 sgd_solver.cpp:106] Iteration 46540, lr = 0.1
I0905 10:00:58.769489 90901 solver.cpp:228] Iteration 46550, loss = 0.290415
I0905 10:00:58.769546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290416 (* 1 = 0.290416 loss)
I0905 10:00:58.769559 90901 sgd_solver.cpp:106] Iteration 46550, lr = 0.1
I0905 10:01:04.840252 90901 solver.cpp:228] Iteration 46560, loss = 0.240666
I0905 10:01:04.840436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240667 (* 1 = 0.240667 loss)
I0905 10:01:04.840466 90901 sgd_solver.cpp:106] Iteration 46560, lr = 0.1
I0905 10:01:10.948457 90901 solver.cpp:228] Iteration 46570, loss = 0.330016
I0905 10:01:10.948503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330017 (* 1 = 0.330017 loss)
I0905 10:01:10.948515 90901 sgd_solver.cpp:106] Iteration 46570, lr = 0.1
I0905 10:01:17.237776 90901 solver.cpp:228] Iteration 46580, loss = 0.420643
I0905 10:01:17.237845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.420644 (* 1 = 0.420644 loss)
I0905 10:01:17.237860 90901 sgd_solver.cpp:106] Iteration 46580, lr = 0.1
I0905 10:01:23.457782 90901 solver.cpp:228] Iteration 46590, loss = 0.216912
I0905 10:01:23.457834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216913 (* 1 = 0.216913 loss)
I0905 10:01:23.457849 90901 sgd_solver.cpp:106] Iteration 46590, lr = 0.1
I0905 10:01:29.512678 90901 solver.cpp:228] Iteration 46600, loss = 0.187157
I0905 10:01:29.512720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187159 (* 1 = 0.187159 loss)
I0905 10:01:29.512737 90901 sgd_solver.cpp:106] Iteration 46600, lr = 0.1
I0905 10:01:35.622725 90901 solver.cpp:228] Iteration 46610, loss = 0.300168
I0905 10:01:35.622882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300169 (* 1 = 0.300169 loss)
I0905 10:01:35.622931 90901 sgd_solver.cpp:106] Iteration 46610, lr = 0.1
I0905 10:01:41.684309 90901 solver.cpp:228] Iteration 46620, loss = 0.19929
I0905 10:01:41.684360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199292 (* 1 = 0.199292 loss)
I0905 10:01:41.684372 90901 sgd_solver.cpp:106] Iteration 46620, lr = 0.1
I0905 10:01:47.653589 90901 solver.cpp:228] Iteration 46630, loss = 0.178724
I0905 10:01:47.653635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178726 (* 1 = 0.178726 loss)
I0905 10:01:47.653648 90901 sgd_solver.cpp:106] Iteration 46630, lr = 0.1
I0905 10:01:52.922217 90901 solver.cpp:228] Iteration 46640, loss = 0.267404
I0905 10:01:52.922261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267405 (* 1 = 0.267405 loss)
I0905 10:01:52.922276 90901 sgd_solver.cpp:106] Iteration 46640, lr = 0.1
I0905 10:01:58.738991 90901 solver.cpp:228] Iteration 46650, loss = 0.169445
I0905 10:01:58.739035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169446 (* 1 = 0.169446 loss)
I0905 10:01:58.739048 90901 sgd_solver.cpp:106] Iteration 46650, lr = 0.1
I0905 10:02:04.483613 90901 solver.cpp:228] Iteration 46660, loss = 0.119844
I0905 10:02:04.483662 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119846 (* 1 = 0.119846 loss)
I0905 10:02:04.483676 90901 sgd_solver.cpp:106] Iteration 46660, lr = 0.1
I0905 10:02:10.916442 90901 solver.cpp:228] Iteration 46670, loss = 0.347781
I0905 10:02:10.916676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347782 (* 1 = 0.347782 loss)
I0905 10:02:10.916725 90901 sgd_solver.cpp:106] Iteration 46670, lr = 0.1
I0905 10:02:17.029803 90901 solver.cpp:228] Iteration 46680, loss = 0.360281
I0905 10:02:17.029847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360282 (* 1 = 0.360282 loss)
I0905 10:02:17.029860 90901 sgd_solver.cpp:106] Iteration 46680, lr = 0.1
I0905 10:02:23.083360 90901 solver.cpp:228] Iteration 46690, loss = 0.321538
I0905 10:02:23.083410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321539 (* 1 = 0.321539 loss)
I0905 10:02:23.083425 90901 sgd_solver.cpp:106] Iteration 46690, lr = 0.1
I0905 10:02:29.459337 90901 solver.cpp:228] Iteration 46700, loss = 0.392713
I0905 10:02:29.459380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392714 (* 1 = 0.392714 loss)
I0905 10:02:29.459393 90901 sgd_solver.cpp:106] Iteration 46700, lr = 0.1
I0905 10:02:35.544386 90901 solver.cpp:228] Iteration 46710, loss = 0.141906
I0905 10:02:35.544445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141907 (* 1 = 0.141907 loss)
I0905 10:02:35.544461 90901 sgd_solver.cpp:106] Iteration 46710, lr = 0.1
I0905 10:02:41.800648 90901 solver.cpp:228] Iteration 46720, loss = 0.221155
I0905 10:02:41.800793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221157 (* 1 = 0.221157 loss)
I0905 10:02:41.800838 90901 sgd_solver.cpp:106] Iteration 46720, lr = 0.1
I0905 10:02:48.005587 90901 solver.cpp:228] Iteration 46730, loss = 0.439247
I0905 10:02:48.005633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439248 (* 1 = 0.439248 loss)
I0905 10:02:48.005645 90901 sgd_solver.cpp:106] Iteration 46730, lr = 0.1
I0905 10:02:54.087610 90901 solver.cpp:228] Iteration 46740, loss = 0.177939
I0905 10:02:54.087658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177941 (* 1 = 0.177941 loss)
I0905 10:02:54.087671 90901 sgd_solver.cpp:106] Iteration 46740, lr = 0.1
I0905 10:03:00.164568 90901 solver.cpp:228] Iteration 46750, loss = 0.177785
I0905 10:03:00.164623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177787 (* 1 = 0.177787 loss)
I0905 10:03:00.164638 90901 sgd_solver.cpp:106] Iteration 46750, lr = 0.1
I0905 10:03:06.255677 90901 solver.cpp:228] Iteration 46760, loss = 0.144745
I0905 10:03:06.255722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144747 (* 1 = 0.144747 loss)
I0905 10:03:06.255733 90901 sgd_solver.cpp:106] Iteration 46760, lr = 0.1
I0905 10:03:12.664410 90901 solver.cpp:228] Iteration 46770, loss = 0.333455
I0905 10:03:12.664587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333457 (* 1 = 0.333457 loss)
I0905 10:03:12.664638 90901 sgd_solver.cpp:106] Iteration 46770, lr = 0.1
I0905 10:03:18.738811 90901 solver.cpp:228] Iteration 46780, loss = 0.243445
I0905 10:03:18.738863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243447 (* 1 = 0.243447 loss)
I0905 10:03:18.738878 90901 sgd_solver.cpp:106] Iteration 46780, lr = 0.1
I0905 10:03:24.476526 90901 solver.cpp:228] Iteration 46790, loss = 0.298954
I0905 10:03:24.476582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298955 (* 1 = 0.298955 loss)
I0905 10:03:24.476595 90901 sgd_solver.cpp:106] Iteration 46790, lr = 0.1
I0905 10:03:30.863782 90901 solver.cpp:228] Iteration 46800, loss = 0.547888
I0905 10:03:30.863828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547889 (* 1 = 0.547889 loss)
I0905 10:03:30.863842 90901 sgd_solver.cpp:106] Iteration 46800, lr = 0.1
I0905 10:03:36.676856 90901 solver.cpp:228] Iteration 46810, loss = 0.361365
I0905 10:03:36.676913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361366 (* 1 = 0.361366 loss)
I0905 10:03:36.676926 90901 sgd_solver.cpp:106] Iteration 46810, lr = 0.1
I0905 10:03:41.944957 90901 solver.cpp:228] Iteration 46820, loss = 0.226483
I0905 10:03:41.945004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226484 (* 1 = 0.226484 loss)
I0905 10:03:41.945017 90901 sgd_solver.cpp:106] Iteration 46820, lr = 0.1
I0905 10:03:47.556545 90901 solver.cpp:228] Iteration 46830, loss = 0.262055
I0905 10:03:47.556751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262056 (* 1 = 0.262056 loss)
I0905 10:03:47.556795 90901 sgd_solver.cpp:106] Iteration 46830, lr = 0.1
I0905 10:03:53.649370 90901 solver.cpp:228] Iteration 46840, loss = 0.171884
I0905 10:03:53.649423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171885 (* 1 = 0.171885 loss)
I0905 10:03:53.649436 90901 sgd_solver.cpp:106] Iteration 46840, lr = 0.1
I0905 10:03:59.932694 90901 solver.cpp:228] Iteration 46850, loss = 0.355456
I0905 10:03:59.932740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355457 (* 1 = 0.355457 loss)
I0905 10:03:59.932754 90901 sgd_solver.cpp:106] Iteration 46850, lr = 0.1
I0905 10:04:06.150859 90901 solver.cpp:228] Iteration 46860, loss = 0.453578
I0905 10:04:06.150907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453579 (* 1 = 0.453579 loss)
I0905 10:04:06.150919 90901 sgd_solver.cpp:106] Iteration 46860, lr = 0.1
I0905 10:04:11.903093 90901 solver.cpp:228] Iteration 46870, loss = 0.376358
I0905 10:04:11.903144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376359 (* 1 = 0.376359 loss)
I0905 10:04:11.903158 90901 sgd_solver.cpp:106] Iteration 46870, lr = 0.1
I0905 10:04:18.320137 90901 solver.cpp:228] Iteration 46880, loss = 0.220185
I0905 10:04:18.320273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220187 (* 1 = 0.220187 loss)
I0905 10:04:18.320322 90901 sgd_solver.cpp:106] Iteration 46880, lr = 0.1
I0905 10:04:24.385767 90901 solver.cpp:228] Iteration 46890, loss = 0.158723
I0905 10:04:24.385810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158724 (* 1 = 0.158724 loss)
I0905 10:04:24.385828 90901 sgd_solver.cpp:106] Iteration 46890, lr = 0.1
I0905 10:04:30.473258 90901 solver.cpp:228] Iteration 46900, loss = 0.201004
I0905 10:04:30.473306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201006 (* 1 = 0.201006 loss)
I0905 10:04:30.473320 90901 sgd_solver.cpp:106] Iteration 46900, lr = 0.1
I0905 10:04:36.561540 90901 solver.cpp:228] Iteration 46910, loss = 0.197902
I0905 10:04:36.561591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197903 (* 1 = 0.197903 loss)
I0905 10:04:36.561604 90901 sgd_solver.cpp:106] Iteration 46910, lr = 0.1
I0905 10:04:42.664209 90901 solver.cpp:228] Iteration 46920, loss = 0.641529
I0905 10:04:42.664263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64153 (* 1 = 0.64153 loss)
I0905 10:04:42.664276 90901 sgd_solver.cpp:106] Iteration 46920, lr = 0.1
I0905 10:04:49.050285 90901 solver.cpp:228] Iteration 46930, loss = 0.284506
I0905 10:04:49.050443 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284507 (* 1 = 0.284507 loss)
I0905 10:04:49.050489 90901 sgd_solver.cpp:106] Iteration 46930, lr = 0.1
I0905 10:04:55.117877 90901 solver.cpp:228] Iteration 46940, loss = 0.220227
I0905 10:04:55.117926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220228 (* 1 = 0.220228 loss)
I0905 10:04:55.117941 90901 sgd_solver.cpp:106] Iteration 46940, lr = 0.1
I0905 10:05:01.212693 90901 solver.cpp:228] Iteration 46950, loss = 0.165064
I0905 10:05:01.212743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165065 (* 1 = 0.165065 loss)
I0905 10:05:01.212756 90901 sgd_solver.cpp:106] Iteration 46950, lr = 0.1
I0905 10:05:07.488809 90901 solver.cpp:228] Iteration 46960, loss = 0.313307
I0905 10:05:07.488872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313309 (* 1 = 0.313309 loss)
I0905 10:05:07.488888 90901 sgd_solver.cpp:106] Iteration 46960, lr = 0.1
I0905 10:05:13.669996 90901 solver.cpp:228] Iteration 46970, loss = 0.257295
I0905 10:05:13.670040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257297 (* 1 = 0.257297 loss)
I0905 10:05:13.670053 90901 sgd_solver.cpp:106] Iteration 46970, lr = 0.1
I0905 10:05:19.743813 90901 solver.cpp:228] Iteration 46980, loss = 0.417308
I0905 10:05:19.744055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.41731 (* 1 = 0.41731 loss)
I0905 10:05:19.744072 90901 sgd_solver.cpp:106] Iteration 46980, lr = 0.1
I0905 10:05:25.412577 90901 solver.cpp:228] Iteration 46990, loss = 0.327084
I0905 10:05:25.412634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327085 (* 1 = 0.327085 loss)
I0905 10:05:25.412652 90901 sgd_solver.cpp:106] Iteration 46990, lr = 0.1
I0905 10:05:30.756285 90901 solver.cpp:228] Iteration 47000, loss = 0.634193
I0905 10:05:30.756355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.634194 (* 1 = 0.634194 loss)
I0905 10:05:30.756369 90901 sgd_solver.cpp:106] Iteration 47000, lr = 0.1
I0905 10:05:36.473047 90901 solver.cpp:228] Iteration 47010, loss = 0.445759
I0905 10:05:36.473126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445761 (* 1 = 0.445761 loss)
I0905 10:05:36.473143 90901 sgd_solver.cpp:106] Iteration 47010, lr = 0.1
I0905 10:05:42.564201 90901 solver.cpp:228] Iteration 47020, loss = 0.260528
I0905 10:05:42.564257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260529 (* 1 = 0.260529 loss)
I0905 10:05:42.564271 90901 sgd_solver.cpp:106] Iteration 47020, lr = 0.1
I0905 10:05:48.976502 90901 solver.cpp:228] Iteration 47030, loss = 0.380032
I0905 10:05:48.976577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380033 (* 1 = 0.380033 loss)
I0905 10:05:48.976593 90901 sgd_solver.cpp:106] Iteration 47030, lr = 0.1
I0905 10:05:54.753295 90901 solver.cpp:228] Iteration 47040, loss = 0.0851197
I0905 10:05:54.753602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0851209 (* 1 = 0.0851209 loss)
I0905 10:05:54.753619 90901 sgd_solver.cpp:106] Iteration 47040, lr = 0.1
I0905 10:06:01.100620 90901 solver.cpp:228] Iteration 47050, loss = 0.274191
I0905 10:06:01.100687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274192 (* 1 = 0.274192 loss)
I0905 10:06:01.100702 90901 sgd_solver.cpp:106] Iteration 47050, lr = 0.1
I0905 10:06:07.179004 90901 solver.cpp:228] Iteration 47060, loss = 0.203251
I0905 10:06:07.179080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203252 (* 1 = 0.203252 loss)
I0905 10:06:07.179097 90901 sgd_solver.cpp:106] Iteration 47060, lr = 0.1
I0905 10:06:13.613899 90901 solver.cpp:228] Iteration 47070, loss = 0.339617
I0905 10:06:13.613940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339618 (* 1 = 0.339618 loss)
I0905 10:06:13.613953 90901 sgd_solver.cpp:106] Iteration 47070, lr = 0.1
I0905 10:06:19.459336 90901 solver.cpp:228] Iteration 47080, loss = 0.306646
I0905 10:06:19.459390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306647 (* 1 = 0.306647 loss)
I0905 10:06:19.459404 90901 sgd_solver.cpp:106] Iteration 47080, lr = 0.1
I0905 10:06:25.771317 90901 solver.cpp:228] Iteration 47090, loss = 0.43905
I0905 10:06:25.771512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439051 (* 1 = 0.439051 loss)
I0905 10:06:25.771541 90901 sgd_solver.cpp:106] Iteration 47090, lr = 0.1
I0905 10:06:31.943625 90901 solver.cpp:228] Iteration 47100, loss = 0.296732
I0905 10:06:31.943689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296733 (* 1 = 0.296733 loss)
I0905 10:06:31.943706 90901 sgd_solver.cpp:106] Iteration 47100, lr = 0.1
I0905 10:06:38.130607 90901 solver.cpp:228] Iteration 47110, loss = 0.534538
I0905 10:06:38.130712 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.534539 (* 1 = 0.534539 loss)
I0905 10:06:38.130744 90901 sgd_solver.cpp:106] Iteration 47110, lr = 0.1
I0905 10:06:44.060400 90901 solver.cpp:228] Iteration 47120, loss = 0.106846
I0905 10:06:44.060447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106848 (* 1 = 0.106848 loss)
I0905 10:06:44.060461 90901 sgd_solver.cpp:106] Iteration 47120, lr = 0.1
I0905 10:06:50.379598 90901 solver.cpp:228] Iteration 47130, loss = 0.137318
I0905 10:06:50.379657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137319 (* 1 = 0.137319 loss)
I0905 10:06:50.379670 90901 sgd_solver.cpp:106] Iteration 47130, lr = 0.1
I0905 10:06:56.556181 90901 solver.cpp:228] Iteration 47140, loss = 0.234516
I0905 10:06:56.556416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234517 (* 1 = 0.234517 loss)
I0905 10:06:56.556463 90901 sgd_solver.cpp:106] Iteration 47140, lr = 0.1
I0905 10:07:02.820369 90901 solver.cpp:228] Iteration 47150, loss = 0.462333
I0905 10:07:02.820430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462334 (* 1 = 0.462334 loss)
I0905 10:07:02.820446 90901 sgd_solver.cpp:106] Iteration 47150, lr = 0.1
I0905 10:07:08.892000 90901 solver.cpp:228] Iteration 47160, loss = 0.625615
I0905 10:07:08.892055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.625616 (* 1 = 0.625616 loss)
I0905 10:07:08.892071 90901 sgd_solver.cpp:106] Iteration 47160, lr = 0.1
I0905 10:07:14.151098 90901 solver.cpp:228] Iteration 47170, loss = 0.102657
I0905 10:07:14.151145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102659 (* 1 = 0.102659 loss)
I0905 10:07:14.151159 90901 sgd_solver.cpp:106] Iteration 47170, lr = 0.1
I0905 10:07:19.816586 90901 solver.cpp:228] Iteration 47180, loss = 0.178771
I0905 10:07:19.816633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178772 (* 1 = 0.178772 loss)
I0905 10:07:19.816646 90901 sgd_solver.cpp:106] Iteration 47180, lr = 0.1
I0905 10:07:25.902668 90901 solver.cpp:228] Iteration 47190, loss = 0.206213
I0905 10:07:25.902720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206214 (* 1 = 0.206214 loss)
I0905 10:07:25.902734 90901 sgd_solver.cpp:106] Iteration 47190, lr = 0.1
I0905 10:07:31.763170 90901 solver.cpp:337] Iteration 47200, Testing net (#0)
I0905 10:08:13.996688 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.641875
I0905 10:08:13.996868 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.22742 (* 1 = 1.22742 loss)
I0905 10:08:14.212987 90901 solver.cpp:228] Iteration 47200, loss = 0.291857
I0905 10:08:14.213060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291858 (* 1 = 0.291858 loss)
I0905 10:08:14.213080 90901 sgd_solver.cpp:106] Iteration 47200, lr = 0.1
I0905 10:08:20.276294 90901 solver.cpp:228] Iteration 47210, loss = 0.37977
I0905 10:08:20.276338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379771 (* 1 = 0.379771 loss)
I0905 10:08:20.276351 90901 sgd_solver.cpp:106] Iteration 47210, lr = 0.1
I0905 10:08:26.077992 90901 solver.cpp:228] Iteration 47220, loss = 0.652039
I0905 10:08:26.078043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.65204 (* 1 = 0.65204 loss)
I0905 10:08:26.078058 90901 sgd_solver.cpp:106] Iteration 47220, lr = 0.1
I0905 10:08:32.156759 90901 solver.cpp:228] Iteration 47230, loss = 0.555252
I0905 10:08:32.156803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.555254 (* 1 = 0.555254 loss)
I0905 10:08:32.156818 90901 sgd_solver.cpp:106] Iteration 47230, lr = 0.1
I0905 10:08:38.257812 90901 solver.cpp:228] Iteration 47240, loss = 0.659931
I0905 10:08:38.257869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.659932 (* 1 = 0.659932 loss)
I0905 10:08:38.257885 90901 sgd_solver.cpp:106] Iteration 47240, lr = 0.1
I0905 10:08:44.343694 90901 solver.cpp:228] Iteration 47250, loss = 0.156879
I0905 10:08:44.343849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15688 (* 1 = 0.15688 loss)
I0905 10:08:44.343889 90901 sgd_solver.cpp:106] Iteration 47250, lr = 0.1
I0905 10:08:50.727394 90901 solver.cpp:228] Iteration 47260, loss = 0.315841
I0905 10:08:50.727454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315842 (* 1 = 0.315842 loss)
I0905 10:08:50.727469 90901 sgd_solver.cpp:106] Iteration 47260, lr = 0.1
I0905 10:08:56.692404 90901 solver.cpp:228] Iteration 47270, loss = 0.285859
I0905 10:08:56.692453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28586 (* 1 = 0.28586 loss)
I0905 10:08:56.692466 90901 sgd_solver.cpp:106] Iteration 47270, lr = 0.1
I0905 10:09:01.960655 90901 solver.cpp:228] Iteration 47280, loss = 0.230755
I0905 10:09:01.960700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230756 (* 1 = 0.230756 loss)
I0905 10:09:01.960714 90901 sgd_solver.cpp:106] Iteration 47280, lr = 0.1
I0905 10:09:07.736249 90901 solver.cpp:228] Iteration 47290, loss = 0.150114
I0905 10:09:07.736289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150116 (* 1 = 0.150116 loss)
I0905 10:09:07.736299 90901 sgd_solver.cpp:106] Iteration 47290, lr = 0.1
I0905 10:09:13.483177 90901 solver.cpp:228] Iteration 47300, loss = 0.156731
I0905 10:09:13.483259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156732 (* 1 = 0.156732 loss)
I0905 10:09:13.483275 90901 sgd_solver.cpp:106] Iteration 47300, lr = 0.1
I0905 10:09:19.946398 90901 solver.cpp:228] Iteration 47310, loss = 0.187022
I0905 10:09:19.946605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187023 (* 1 = 0.187023 loss)
I0905 10:09:19.946646 90901 sgd_solver.cpp:106] Iteration 47310, lr = 0.1
I0905 10:09:26.031539 90901 solver.cpp:228] Iteration 47320, loss = 0.133904
I0905 10:09:26.031615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133905 (* 1 = 0.133905 loss)
I0905 10:09:26.031630 90901 sgd_solver.cpp:106] Iteration 47320, lr = 0.1
I0905 10:09:32.069573 90901 solver.cpp:228] Iteration 47330, loss = 0.421947
I0905 10:09:32.069628 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421948 (* 1 = 0.421948 loss)
I0905 10:09:32.069643 90901 sgd_solver.cpp:106] Iteration 47330, lr = 0.1
I0905 10:09:38.104068 90901 solver.cpp:228] Iteration 47340, loss = 0.468408
I0905 10:09:38.104125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46841 (* 1 = 0.46841 loss)
I0905 10:09:38.104140 90901 sgd_solver.cpp:106] Iteration 47340, lr = 0.1
I0905 10:09:44.298898 90901 solver.cpp:228] Iteration 47350, loss = 0.618474
I0905 10:09:44.298969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.618475 (* 1 = 0.618475 loss)
I0905 10:09:44.298986 90901 sgd_solver.cpp:106] Iteration 47350, lr = 0.1
I0905 10:09:50.560058 90901 solver.cpp:228] Iteration 47360, loss = 0.289994
I0905 10:09:50.560272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289995 (* 1 = 0.289995 loss)
I0905 10:09:50.560291 90901 sgd_solver.cpp:106] Iteration 47360, lr = 0.1
I0905 10:09:56.605365 90901 solver.cpp:228] Iteration 47370, loss = 0.319764
I0905 10:09:56.605438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319765 (* 1 = 0.319765 loss)
I0905 10:09:56.605456 90901 sgd_solver.cpp:106] Iteration 47370, lr = 0.1
I0905 10:10:02.322409 90901 solver.cpp:228] Iteration 47380, loss = 0.183363
I0905 10:10:02.322475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183364 (* 1 = 0.183364 loss)
I0905 10:10:02.322492 90901 sgd_solver.cpp:106] Iteration 47380, lr = 0.1
I0905 10:10:08.773213 90901 solver.cpp:228] Iteration 47390, loss = 0.221397
I0905 10:10:08.773262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221398 (* 1 = 0.221398 loss)
I0905 10:10:08.773275 90901 sgd_solver.cpp:106] Iteration 47390, lr = 0.1
I0905 10:10:15.186102 90901 solver.cpp:228] Iteration 47400, loss = 0.406671
I0905 10:10:15.186162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406672 (* 1 = 0.406672 loss)
I0905 10:10:15.186177 90901 sgd_solver.cpp:106] Iteration 47400, lr = 0.1
I0905 10:10:21.282888 90901 solver.cpp:228] Iteration 47410, loss = 0.380949
I0905 10:10:21.283116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380951 (* 1 = 0.380951 loss)
I0905 10:10:21.283133 90901 sgd_solver.cpp:106] Iteration 47410, lr = 0.1
I0905 10:10:27.279814 90901 solver.cpp:228] Iteration 47420, loss = 0.224689
I0905 10:10:27.279888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224691 (* 1 = 0.224691 loss)
I0905 10:10:27.279906 90901 sgd_solver.cpp:106] Iteration 47420, lr = 0.1
I0905 10:10:33.655863 90901 solver.cpp:228] Iteration 47430, loss = 0.355504
I0905 10:10:33.655926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355506 (* 1 = 0.355506 loss)
I0905 10:10:33.655942 90901 sgd_solver.cpp:106] Iteration 47430, lr = 0.1
I0905 10:10:39.744258 90901 solver.cpp:228] Iteration 47440, loss = 0.136507
I0905 10:10:39.744316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136509 (* 1 = 0.136509 loss)
I0905 10:10:39.744333 90901 sgd_solver.cpp:106] Iteration 47440, lr = 0.1
I0905 10:10:45.708590 90901 solver.cpp:228] Iteration 47450, loss = 0.728371
I0905 10:10:45.708628 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.728372 (* 1 = 0.728372 loss)
I0905 10:10:45.708641 90901 sgd_solver.cpp:106] Iteration 47450, lr = 0.1
I0905 10:10:51.281172 90901 solver.cpp:228] Iteration 47460, loss = 0.628761
I0905 10:10:51.281226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.628762 (* 1 = 0.628762 loss)
I0905 10:10:51.281239 90901 sgd_solver.cpp:106] Iteration 47460, lr = 0.1
I0905 10:10:56.697317 90901 solver.cpp:228] Iteration 47470, loss = 0.124798
I0905 10:10:56.697526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124799 (* 1 = 0.124799 loss)
I0905 10:10:56.697543 90901 sgd_solver.cpp:106] Iteration 47470, lr = 0.1
I0905 10:11:02.841758 90901 solver.cpp:228] Iteration 47480, loss = 0.289178
I0905 10:11:02.841827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289179 (* 1 = 0.289179 loss)
I0905 10:11:02.841843 90901 sgd_solver.cpp:106] Iteration 47480, lr = 0.1
I0905 10:11:08.899742 90901 solver.cpp:228] Iteration 47490, loss = 0.272598
I0905 10:11:08.899801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272599 (* 1 = 0.272599 loss)
I0905 10:11:08.899821 90901 sgd_solver.cpp:106] Iteration 47490, lr = 0.1
I0905 10:11:14.991523 90901 solver.cpp:228] Iteration 47500, loss = 0.262697
I0905 10:11:14.991574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262698 (* 1 = 0.262698 loss)
I0905 10:11:14.991590 90901 sgd_solver.cpp:106] Iteration 47500, lr = 0.1
I0905 10:11:21.423533 90901 solver.cpp:228] Iteration 47510, loss = 0.216382
I0905 10:11:21.423570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216383 (* 1 = 0.216383 loss)
I0905 10:11:21.423583 90901 sgd_solver.cpp:106] Iteration 47510, lr = 0.1
I0905 10:11:27.478389 90901 solver.cpp:228] Iteration 47520, loss = 0.186878
I0905 10:11:27.478582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186879 (* 1 = 0.186879 loss)
I0905 10:11:27.478597 90901 sgd_solver.cpp:106] Iteration 47520, lr = 0.1
I0905 10:11:33.557677 90901 solver.cpp:228] Iteration 47530, loss = 0.220013
I0905 10:11:33.557719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220015 (* 1 = 0.220015 loss)
I0905 10:11:33.557731 90901 sgd_solver.cpp:106] Iteration 47530, lr = 0.1
I0905 10:11:39.631330 90901 solver.cpp:228] Iteration 47540, loss = 0.365932
I0905 10:11:39.631384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365934 (* 1 = 0.365934 loss)
I0905 10:11:39.631403 90901 sgd_solver.cpp:106] Iteration 47540, lr = 0.1
I0905 10:11:45.696388 90901 solver.cpp:228] Iteration 47550, loss = 0.273247
I0905 10:11:45.696441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273249 (* 1 = 0.273249 loss)
I0905 10:11:45.696455 90901 sgd_solver.cpp:106] Iteration 47550, lr = 0.1
I0905 10:11:51.745769 90901 solver.cpp:228] Iteration 47560, loss = 0.148292
I0905 10:11:51.745834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148293 (* 1 = 0.148293 loss)
I0905 10:11:51.745848 90901 sgd_solver.cpp:106] Iteration 47560, lr = 0.1
I0905 10:11:58.143878 90901 solver.cpp:228] Iteration 47570, loss = 0.111467
I0905 10:11:58.144071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111468 (* 1 = 0.111468 loss)
I0905 10:11:58.144116 90901 sgd_solver.cpp:106] Iteration 47570, lr = 0.1
I0905 10:12:04.234925 90901 solver.cpp:228] Iteration 47580, loss = 0.131572
I0905 10:12:04.234966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131573 (* 1 = 0.131573 loss)
I0905 10:12:04.234980 90901 sgd_solver.cpp:106] Iteration 47580, lr = 0.1
I0905 10:12:10.339229 90901 solver.cpp:228] Iteration 47590, loss = 0.286818
I0905 10:12:10.339279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28682 (* 1 = 0.28682 loss)
I0905 10:12:10.339293 90901 sgd_solver.cpp:106] Iteration 47590, lr = 0.1
I0905 10:12:16.741216 90901 solver.cpp:228] Iteration 47600, loss = 0.0839833
I0905 10:12:16.741261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0839846 (* 1 = 0.0839846 loss)
I0905 10:12:16.741276 90901 sgd_solver.cpp:106] Iteration 47600, lr = 0.1
I0905 10:12:22.810252 90901 solver.cpp:228] Iteration 47610, loss = 0.543085
I0905 10:12:22.810297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543086 (* 1 = 0.543086 loss)
I0905 10:12:22.810310 90901 sgd_solver.cpp:106] Iteration 47610, lr = 0.1
I0905 10:12:28.843441 90901 solver.cpp:228] Iteration 47620, loss = 0.409938
I0905 10:12:28.843647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40994 (* 1 = 0.40994 loss)
I0905 10:12:28.843668 90901 sgd_solver.cpp:106] Iteration 47620, lr = 0.1
I0905 10:12:34.664881 90901 solver.cpp:228] Iteration 47630, loss = 0.307879
I0905 10:12:34.664932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30788 (* 1 = 0.30788 loss)
I0905 10:12:34.664945 90901 sgd_solver.cpp:106] Iteration 47630, lr = 0.1
I0905 10:12:40.243333 90901 solver.cpp:228] Iteration 47640, loss = 0.249518
I0905 10:12:40.243408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24952 (* 1 = 0.24952 loss)
I0905 10:12:40.243424 90901 sgd_solver.cpp:106] Iteration 47640, lr = 0.1
I0905 10:12:45.844319 90901 solver.cpp:228] Iteration 47650, loss = 0.211922
I0905 10:12:45.844357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211923 (* 1 = 0.211923 loss)
I0905 10:12:45.844375 90901 sgd_solver.cpp:106] Iteration 47650, lr = 0.1
I0905 10:12:51.877559 90901 solver.cpp:228] Iteration 47660, loss = 0.450097
I0905 10:12:51.877601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450098 (* 1 = 0.450098 loss)
I0905 10:12:51.877616 90901 sgd_solver.cpp:106] Iteration 47660, lr = 0.1
I0905 10:12:57.922878 90901 solver.cpp:228] Iteration 47670, loss = 0.213112
I0905 10:12:57.922919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213114 (* 1 = 0.213114 loss)
I0905 10:12:57.922933 90901 sgd_solver.cpp:106] Iteration 47670, lr = 0.1
I0905 10:13:04.026695 90901 solver.cpp:228] Iteration 47680, loss = 0.258373
I0905 10:13:04.026829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258374 (* 1 = 0.258374 loss)
I0905 10:13:04.026846 90901 sgd_solver.cpp:106] Iteration 47680, lr = 0.1
I0905 10:13:10.430697 90901 solver.cpp:228] Iteration 47690, loss = 0.315656
I0905 10:13:10.430753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315658 (* 1 = 0.315658 loss)
I0905 10:13:10.430765 90901 sgd_solver.cpp:106] Iteration 47690, lr = 0.1
I0905 10:13:16.452399 90901 solver.cpp:228] Iteration 47700, loss = 0.471141
I0905 10:13:16.452446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.471143 (* 1 = 0.471143 loss)
I0905 10:13:16.452461 90901 sgd_solver.cpp:106] Iteration 47700, lr = 0.1
I0905 10:13:22.627830 90901 solver.cpp:228] Iteration 47710, loss = 0.517119
I0905 10:13:22.627876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.517121 (* 1 = 0.517121 loss)
I0905 10:13:22.627889 90901 sgd_solver.cpp:106] Iteration 47710, lr = 0.1
I0905 10:13:28.691822 90901 solver.cpp:228] Iteration 47720, loss = 0.238655
I0905 10:13:28.691869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238657 (* 1 = 0.238657 loss)
I0905 10:13:28.691882 90901 sgd_solver.cpp:106] Iteration 47720, lr = 0.1
I0905 10:13:34.752823 90901 solver.cpp:228] Iteration 47730, loss = 0.953541
I0905 10:13:34.753046 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.953542 (* 1 = 0.953542 loss)
I0905 10:13:34.753075 90901 sgd_solver.cpp:106] Iteration 47730, lr = 0.1
I0905 10:13:40.526496 90901 solver.cpp:228] Iteration 47740, loss = 0.348553
I0905 10:13:40.526541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348555 (* 1 = 0.348555 loss)
I0905 10:13:40.526553 90901 sgd_solver.cpp:106] Iteration 47740, lr = 0.1
I0905 10:13:46.967149 90901 solver.cpp:228] Iteration 47750, loss = 0.301821
I0905 10:13:46.967200 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301822 (* 1 = 0.301822 loss)
I0905 10:13:46.967214 90901 sgd_solver.cpp:106] Iteration 47750, lr = 0.1
I0905 10:13:53.012893 90901 solver.cpp:228] Iteration 47760, loss = 0.315497
I0905 10:13:53.012960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315499 (* 1 = 0.315499 loss)
I0905 10:13:53.012974 90901 sgd_solver.cpp:106] Iteration 47760, lr = 0.1
I0905 10:13:58.048280 90901 solver.cpp:228] Iteration 47770, loss = 0.216157
I0905 10:13:58.048328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216159 (* 1 = 0.216159 loss)
I0905 10:13:58.048341 90901 sgd_solver.cpp:106] Iteration 47770, lr = 0.1
I0905 10:14:03.108988 90901 solver.cpp:228] Iteration 47780, loss = 0.201882
I0905 10:14:03.109041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201883 (* 1 = 0.201883 loss)
I0905 10:14:03.109055 90901 sgd_solver.cpp:106] Iteration 47780, lr = 0.1
I0905 10:14:08.148627 90901 solver.cpp:228] Iteration 47790, loss = 0.234953
I0905 10:14:08.148764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234954 (* 1 = 0.234954 loss)
I0905 10:14:08.148808 90901 sgd_solver.cpp:106] Iteration 47790, lr = 0.1
I0905 10:14:13.180732 90901 solver.cpp:228] Iteration 47800, loss = 0.647474
I0905 10:14:13.180776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.647475 (* 1 = 0.647475 loss)
I0905 10:14:13.180789 90901 sgd_solver.cpp:106] Iteration 47800, lr = 0.1
I0905 10:14:18.226773 90901 solver.cpp:228] Iteration 47810, loss = 0.187574
I0905 10:14:18.226814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187575 (* 1 = 0.187575 loss)
I0905 10:14:18.226826 90901 sgd_solver.cpp:106] Iteration 47810, lr = 0.1
I0905 10:14:23.032593 90901 solver.cpp:228] Iteration 47820, loss = 0.18458
I0905 10:14:23.032650 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184581 (* 1 = 0.184581 loss)
I0905 10:14:23.032663 90901 sgd_solver.cpp:106] Iteration 47820, lr = 0.1
I0905 10:14:27.685611 90901 solver.cpp:228] Iteration 47830, loss = 0.299928
I0905 10:14:27.685683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29993 (* 1 = 0.29993 loss)
I0905 10:14:27.685699 90901 sgd_solver.cpp:106] Iteration 47830, lr = 0.1
I0905 10:14:32.366900 90901 solver.cpp:228] Iteration 47840, loss = 0.372767
I0905 10:14:32.366941 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372768 (* 1 = 0.372768 loss)
I0905 10:14:32.366953 90901 sgd_solver.cpp:106] Iteration 47840, lr = 0.1
I0905 10:14:37.432025 90901 solver.cpp:228] Iteration 47850, loss = 0.193814
I0905 10:14:37.432078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193815 (* 1 = 0.193815 loss)
I0905 10:14:37.432091 90901 sgd_solver.cpp:106] Iteration 47850, lr = 0.1
I0905 10:14:42.517536 90901 solver.cpp:228] Iteration 47860, loss = 0.0813105
I0905 10:14:42.517691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0813116 (* 1 = 0.0813116 loss)
I0905 10:14:42.517741 90901 sgd_solver.cpp:106] Iteration 47860, lr = 0.1
I0905 10:14:47.572031 90901 solver.cpp:228] Iteration 47870, loss = 0.210753
I0905 10:14:47.572075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210754 (* 1 = 0.210754 loss)
I0905 10:14:47.572088 90901 sgd_solver.cpp:106] Iteration 47870, lr = 0.1
I0905 10:14:52.609571 90901 solver.cpp:228] Iteration 47880, loss = 0.18931
I0905 10:14:52.609629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189312 (* 1 = 0.189312 loss)
I0905 10:14:52.609642 90901 sgd_solver.cpp:106] Iteration 47880, lr = 0.1
I0905 10:14:57.641893 90901 solver.cpp:228] Iteration 47890, loss = 0.292048
I0905 10:14:57.641937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29205 (* 1 = 0.29205 loss)
I0905 10:14:57.641949 90901 sgd_solver.cpp:106] Iteration 47890, lr = 0.1
I0905 10:15:02.744498 90901 solver.cpp:228] Iteration 47900, loss = 0.738695
I0905 10:15:02.744541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.738697 (* 1 = 0.738697 loss)
I0905 10:15:02.744554 90901 sgd_solver.cpp:106] Iteration 47900, lr = 0.1
I0905 10:15:07.788882 90901 solver.cpp:228] Iteration 47910, loss = 0.357347
I0905 10:15:07.788933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357349 (* 1 = 0.357349 loss)
I0905 10:15:07.788945 90901 sgd_solver.cpp:106] Iteration 47910, lr = 0.1
I0905 10:15:12.889684 90901 solver.cpp:228] Iteration 47920, loss = 0.0567635
I0905 10:15:12.889878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0567648 (* 1 = 0.0567648 loss)
I0905 10:15:12.889899 90901 sgd_solver.cpp:106] Iteration 47920, lr = 0.1
I0905 10:15:18.278715 90901 solver.cpp:228] Iteration 47930, loss = 0.309675
I0905 10:15:18.278760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309676 (* 1 = 0.309676 loss)
I0905 10:15:18.278774 90901 sgd_solver.cpp:106] Iteration 47930, lr = 0.1
I0905 10:15:24.419296 90901 solver.cpp:228] Iteration 47940, loss = 0.295959
I0905 10:15:24.419345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295961 (* 1 = 0.295961 loss)
I0905 10:15:24.419359 90901 sgd_solver.cpp:106] Iteration 47940, lr = 0.1
I0905 10:15:30.740470 90901 solver.cpp:228] Iteration 47950, loss = 0.434345
I0905 10:15:30.740514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434346 (* 1 = 0.434346 loss)
I0905 10:15:30.740526 90901 sgd_solver.cpp:106] Iteration 47950, lr = 0.1
I0905 10:15:36.548429 90901 solver.cpp:228] Iteration 47960, loss = 0.258338
I0905 10:15:36.548472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258339 (* 1 = 0.258339 loss)
I0905 10:15:36.548486 90901 sgd_solver.cpp:106] Iteration 47960, lr = 0.1
I0905 10:15:42.593019 90901 solver.cpp:228] Iteration 47970, loss = 0.25153
I0905 10:15:42.593062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251531 (* 1 = 0.251531 loss)
I0905 10:15:42.593076 90901 sgd_solver.cpp:106] Iteration 47970, lr = 0.1
I0905 10:15:49.014592 90901 solver.cpp:228] Iteration 47980, loss = 0.265136
I0905 10:15:49.014761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265137 (* 1 = 0.265137 loss)
I0905 10:15:49.014813 90901 sgd_solver.cpp:106] Iteration 47980, lr = 0.1
I0905 10:15:54.781621 90901 solver.cpp:228] Iteration 47990, loss = 0.324807
I0905 10:15:54.781682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324808 (* 1 = 0.324808 loss)
I0905 10:15:54.781695 90901 sgd_solver.cpp:106] Iteration 47990, lr = 0.1
I0905 10:16:00.608786 90901 solver.cpp:337] Iteration 48000, Testing net (#0)
I0905 10:16:41.793323 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.84125
I0905 10:16:41.793485 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.367085 (* 1 = 0.367085 loss)
I0905 10:16:42.011674 90901 solver.cpp:228] Iteration 48000, loss = 0.327528
I0905 10:16:42.011705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327529 (* 1 = 0.327529 loss)
I0905 10:16:42.011723 90901 sgd_solver.cpp:106] Iteration 48000, lr = 0.1
I0905 10:16:47.757374 90901 solver.cpp:228] Iteration 48010, loss = 0.0689161
I0905 10:16:47.757411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0689173 (* 1 = 0.0689173 loss)
I0905 10:16:47.757424 90901 sgd_solver.cpp:106] Iteration 48010, lr = 0.1
I0905 10:16:54.201840 90901 solver.cpp:228] Iteration 48020, loss = 0.455369
I0905 10:16:54.201936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45537 (* 1 = 0.45537 loss)
I0905 10:16:54.201956 90901 sgd_solver.cpp:106] Iteration 48020, lr = 0.1
I0905 10:17:00.302865 90901 solver.cpp:228] Iteration 48030, loss = 0.224743
I0905 10:17:00.302911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224744 (* 1 = 0.224744 loss)
I0905 10:17:00.302925 90901 sgd_solver.cpp:106] Iteration 48030, lr = 0.1
I0905 10:17:06.378710 90901 solver.cpp:228] Iteration 48040, loss = 0.34097
I0905 10:17:06.378757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340971 (* 1 = 0.340971 loss)
I0905 10:17:06.378770 90901 sgd_solver.cpp:106] Iteration 48040, lr = 0.1
I0905 10:17:12.423631 90901 solver.cpp:228] Iteration 48050, loss = 0.108735
I0905 10:17:12.423858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108736 (* 1 = 0.108736 loss)
I0905 10:17:12.423892 90901 sgd_solver.cpp:106] Iteration 48050, lr = 0.1
I0905 10:17:18.505791 90901 solver.cpp:228] Iteration 48060, loss = 0.365457
I0905 10:17:18.505831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365458 (* 1 = 0.365458 loss)
I0905 10:17:18.505844 90901 sgd_solver.cpp:106] Iteration 48060, lr = 0.1
I0905 10:17:24.533571 90901 solver.cpp:228] Iteration 48070, loss = 0.10403
I0905 10:17:24.533614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104031 (* 1 = 0.104031 loss)
I0905 10:17:24.533627 90901 sgd_solver.cpp:106] Iteration 48070, lr = 0.1
I0905 10:17:30.856221 90901 solver.cpp:228] Iteration 48080, loss = 0.0774288
I0905 10:17:30.856288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0774299 (* 1 = 0.0774299 loss)
I0905 10:17:30.856307 90901 sgd_solver.cpp:106] Iteration 48080, lr = 0.1
I0905 10:17:37.017974 90901 solver.cpp:228] Iteration 48090, loss = 0.210101
I0905 10:17:37.018015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210102 (* 1 = 0.210102 loss)
I0905 10:17:37.018028 90901 sgd_solver.cpp:106] Iteration 48090, lr = 0.1
I0905 10:17:43.032153 90901 solver.cpp:228] Iteration 48100, loss = 0.296066
I0905 10:17:43.032315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296068 (* 1 = 0.296068 loss)
I0905 10:17:43.032342 90901 sgd_solver.cpp:106] Iteration 48100, lr = 0.1
I0905 10:17:49.403769 90901 solver.cpp:228] Iteration 48110, loss = 0.116282
I0905 10:17:49.403827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116283 (* 1 = 0.116283 loss)
I0905 10:17:49.403843 90901 sgd_solver.cpp:106] Iteration 48110, lr = 0.1
I0905 10:17:55.477962 90901 solver.cpp:228] Iteration 48120, loss = 0.202002
I0905 10:17:55.478003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202003 (* 1 = 0.202003 loss)
I0905 10:17:55.478018 90901 sgd_solver.cpp:106] Iteration 48120, lr = 0.1
I0905 10:18:00.891535 90901 solver.cpp:228] Iteration 48130, loss = 0.188656
I0905 10:18:00.891582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188657 (* 1 = 0.188657 loss)
I0905 10:18:00.891594 90901 sgd_solver.cpp:106] Iteration 48130, lr = 0.1
I0905 10:18:06.465706 90901 solver.cpp:228] Iteration 48140, loss = 0.214925
I0905 10:18:06.465754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214927 (* 1 = 0.214927 loss)
I0905 10:18:06.465766 90901 sgd_solver.cpp:106] Iteration 48140, lr = 0.1
I0905 10:18:12.449723 90901 solver.cpp:228] Iteration 48150, loss = 1.03529
I0905 10:18:12.449769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.03529 (* 1 = 1.03529 loss)
I0905 10:18:12.449782 90901 sgd_solver.cpp:106] Iteration 48150, lr = 0.1
I0905 10:18:18.486253 90901 solver.cpp:228] Iteration 48160, loss = 0.399804
I0905 10:18:18.486415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399805 (* 1 = 0.399805 loss)
I0905 10:18:18.486462 90901 sgd_solver.cpp:106] Iteration 48160, lr = 0.1
I0905 10:18:24.559483 90901 solver.cpp:228] Iteration 48170, loss = 0.178017
I0905 10:18:24.559525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178018 (* 1 = 0.178018 loss)
I0905 10:18:24.559538 90901 sgd_solver.cpp:106] Iteration 48170, lr = 0.1
I0905 10:18:30.661396 90901 solver.cpp:228] Iteration 48180, loss = 0.301115
I0905 10:18:30.661449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301116 (* 1 = 0.301116 loss)
I0905 10:18:30.661468 90901 sgd_solver.cpp:106] Iteration 48180, lr = 0.1
I0905 10:18:37.032253 90901 solver.cpp:228] Iteration 48190, loss = 0.270549
I0905 10:18:37.032296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27055 (* 1 = 0.27055 loss)
I0905 10:18:37.032310 90901 sgd_solver.cpp:106] Iteration 48190, lr = 0.1
I0905 10:18:42.772863 90901 solver.cpp:228] Iteration 48200, loss = 0.379889
I0905 10:18:42.772913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37989 (* 1 = 0.37989 loss)
I0905 10:18:42.772925 90901 sgd_solver.cpp:106] Iteration 48200, lr = 0.1
I0905 10:18:49.210675 90901 solver.cpp:228] Iteration 48210, loss = 0.240191
I0905 10:18:49.210901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240192 (* 1 = 0.240192 loss)
I0905 10:18:49.210925 90901 sgd_solver.cpp:106] Iteration 48210, lr = 0.1
I0905 10:18:55.287060 90901 solver.cpp:228] Iteration 48220, loss = 0.144045
I0905 10:18:55.287118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144047 (* 1 = 0.144047 loss)
I0905 10:18:55.287133 90901 sgd_solver.cpp:106] Iteration 48220, lr = 0.1
I0905 10:19:01.350538 90901 solver.cpp:228] Iteration 48230, loss = 0.373839
I0905 10:19:01.350594 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37384 (* 1 = 0.37384 loss)
I0905 10:19:01.350608 90901 sgd_solver.cpp:106] Iteration 48230, lr = 0.1
I0905 10:19:07.439494 90901 solver.cpp:228] Iteration 48240, loss = 0.515856
I0905 10:19:07.439538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515858 (* 1 = 0.515858 loss)
I0905 10:19:07.439549 90901 sgd_solver.cpp:106] Iteration 48240, lr = 0.1
I0905 10:19:13.165666 90901 solver.cpp:228] Iteration 48250, loss = 0.436646
I0905 10:19:13.165725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436647 (* 1 = 0.436647 loss)
I0905 10:19:13.165740 90901 sgd_solver.cpp:106] Iteration 48250, lr = 0.1
I0905 10:19:19.571050 90901 solver.cpp:228] Iteration 48260, loss = 0.566532
I0905 10:19:19.571249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566533 (* 1 = 0.566533 loss)
I0905 10:19:19.571269 90901 sgd_solver.cpp:106] Iteration 48260, lr = 0.1
I0905 10:19:25.680806 90901 solver.cpp:228] Iteration 48270, loss = 0.293417
I0905 10:19:25.680845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293418 (* 1 = 0.293418 loss)
I0905 10:19:25.680860 90901 sgd_solver.cpp:106] Iteration 48270, lr = 0.1
I0905 10:19:32.023633 90901 solver.cpp:228] Iteration 48280, loss = 0.406569
I0905 10:19:32.023672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40657 (* 1 = 0.40657 loss)
I0905 10:19:32.023686 90901 sgd_solver.cpp:106] Iteration 48280, lr = 0.1
I0905 10:19:38.081722 90901 solver.cpp:228] Iteration 48290, loss = 0.0480461
I0905 10:19:38.081761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0480473 (* 1 = 0.0480473 loss)
I0905 10:19:38.081774 90901 sgd_solver.cpp:106] Iteration 48290, lr = 0.1
I0905 10:19:44.148255 90901 solver.cpp:228] Iteration 48300, loss = 0.328131
I0905 10:19:44.148300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328132 (* 1 = 0.328132 loss)
I0905 10:19:44.148314 90901 sgd_solver.cpp:106] Iteration 48300, lr = 0.1
I0905 10:19:49.852293 90901 solver.cpp:228] Iteration 48310, loss = 0.192615
I0905 10:19:49.852464 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192616 (* 1 = 0.192616 loss)
I0905 10:19:49.852481 90901 sgd_solver.cpp:106] Iteration 48310, lr = 0.1
I0905 10:19:55.130452 90901 solver.cpp:228] Iteration 48320, loss = 0.0761023
I0905 10:19:55.130491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0761034 (* 1 = 0.0761034 loss)
I0905 10:19:55.130507 90901 sgd_solver.cpp:106] Iteration 48320, lr = 0.1
I0905 10:20:01.146819 90901 solver.cpp:228] Iteration 48330, loss = 0.1625
I0905 10:20:01.146853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162501 (* 1 = 0.162501 loss)
I0905 10:20:01.146867 90901 sgd_solver.cpp:106] Iteration 48330, lr = 0.1
I0905 10:20:07.251901 90901 solver.cpp:228] Iteration 48340, loss = 0.280559
I0905 10:20:07.251948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280561 (* 1 = 0.280561 loss)
I0905 10:20:07.251961 90901 sgd_solver.cpp:106] Iteration 48340, lr = 0.1
I0905 10:20:13.296170 90901 solver.cpp:228] Iteration 48350, loss = 0.149034
I0905 10:20:13.296219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149036 (* 1 = 0.149036 loss)
I0905 10:20:13.296232 90901 sgd_solver.cpp:106] Iteration 48350, lr = 0.1
I0905 10:20:19.352779 90901 solver.cpp:228] Iteration 48360, loss = 0.587006
I0905 10:20:19.352825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.587007 (* 1 = 0.587007 loss)
I0905 10:20:19.352838 90901 sgd_solver.cpp:106] Iteration 48360, lr = 0.1
I0905 10:20:25.434651 90901 solver.cpp:228] Iteration 48370, loss = 0.24639
I0905 10:20:25.434892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246391 (* 1 = 0.246391 loss)
I0905 10:20:25.434944 90901 sgd_solver.cpp:106] Iteration 48370, lr = 0.1
I0905 10:20:31.873131 90901 solver.cpp:228] Iteration 48380, loss = 0.444484
I0905 10:20:31.873175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444485 (* 1 = 0.444485 loss)
I0905 10:20:31.873189 90901 sgd_solver.cpp:106] Iteration 48380, lr = 0.1
I0905 10:20:37.960397 90901 solver.cpp:228] Iteration 48390, loss = 0.43598
I0905 10:20:37.960435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435982 (* 1 = 0.435982 loss)
I0905 10:20:37.960451 90901 sgd_solver.cpp:106] Iteration 48390, lr = 0.1
I0905 10:20:44.006345 90901 solver.cpp:228] Iteration 48400, loss = 0.261261
I0905 10:20:44.006394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261263 (* 1 = 0.261263 loss)
I0905 10:20:44.006408 90901 sgd_solver.cpp:106] Iteration 48400, lr = 0.1
I0905 10:20:50.065706 90901 solver.cpp:228] Iteration 48410, loss = 0.173638
I0905 10:20:50.065779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173639 (* 1 = 0.173639 loss)
I0905 10:20:50.065796 90901 sgd_solver.cpp:106] Iteration 48410, lr = 0.1
I0905 10:20:56.151257 90901 solver.cpp:228] Iteration 48420, loss = 0.278971
I0905 10:20:56.151381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278972 (* 1 = 0.278972 loss)
I0905 10:20:56.151429 90901 sgd_solver.cpp:106] Iteration 48420, lr = 0.1
I0905 10:21:02.248569 90901 solver.cpp:228] Iteration 48430, loss = 0.292075
I0905 10:21:02.248615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292076 (* 1 = 0.292076 loss)
I0905 10:21:02.248633 90901 sgd_solver.cpp:106] Iteration 48430, lr = 0.1
I0905 10:21:08.300786 90901 solver.cpp:228] Iteration 48440, loss = 0.230788
I0905 10:21:08.300858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230789 (* 1 = 0.230789 loss)
I0905 10:21:08.300875 90901 sgd_solver.cpp:106] Iteration 48440, lr = 0.1
I0905 10:21:14.615084 90901 solver.cpp:228] Iteration 48450, loss = 0.144768
I0905 10:21:14.615144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144769 (* 1 = 0.144769 loss)
I0905 10:21:14.615160 90901 sgd_solver.cpp:106] Iteration 48450, lr = 0.1
I0905 10:21:20.763113 90901 solver.cpp:228] Iteration 48460, loss = 0.10892
I0905 10:21:20.763169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108921 (* 1 = 0.108921 loss)
I0905 10:21:20.763183 90901 sgd_solver.cpp:106] Iteration 48460, lr = 0.1
I0905 10:21:26.806514 90901 solver.cpp:228] Iteration 48470, loss = 0.17799
I0905 10:21:26.806709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177991 (* 1 = 0.177991 loss)
I0905 10:21:26.806735 90901 sgd_solver.cpp:106] Iteration 48470, lr = 0.1
I0905 10:21:32.894568 90901 solver.cpp:228] Iteration 48480, loss = 0.866952
I0905 10:21:32.894609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.866953 (* 1 = 0.866953 loss)
I0905 10:21:32.894623 90901 sgd_solver.cpp:106] Iteration 48480, lr = 0.1
I0905 10:21:38.145457 90901 solver.cpp:228] Iteration 48490, loss = 0.178103
I0905 10:21:38.145510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178104 (* 1 = 0.178104 loss)
I0905 10:21:38.145524 90901 sgd_solver.cpp:106] Iteration 48490, lr = 0.1
I0905 10:21:43.494642 90901 solver.cpp:228] Iteration 48500, loss = 0.167342
I0905 10:21:43.494688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167343 (* 1 = 0.167343 loss)
I0905 10:21:43.494699 90901 sgd_solver.cpp:106] Iteration 48500, lr = 0.1
I0905 10:21:49.584089 90901 solver.cpp:228] Iteration 48510, loss = 0.403097
I0905 10:21:49.584146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403098 (* 1 = 0.403098 loss)
I0905 10:21:49.584161 90901 sgd_solver.cpp:106] Iteration 48510, lr = 0.1
I0905 10:21:55.662382 90901 solver.cpp:228] Iteration 48520, loss = 0.0956124
I0905 10:21:55.662436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0956136 (* 1 = 0.0956136 loss)
I0905 10:21:55.662448 90901 sgd_solver.cpp:106] Iteration 48520, lr = 0.1
I0905 10:22:01.724390 90901 solver.cpp:228] Iteration 48530, loss = 0.319491
I0905 10:22:01.724547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319492 (* 1 = 0.319492 loss)
I0905 10:22:01.724565 90901 sgd_solver.cpp:106] Iteration 48530, lr = 0.1
I0905 10:22:07.812810 90901 solver.cpp:228] Iteration 48540, loss = 0.431961
I0905 10:22:07.812855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.431962 (* 1 = 0.431962 loss)
I0905 10:22:07.812868 90901 sgd_solver.cpp:106] Iteration 48540, lr = 0.1
I0905 10:22:13.889742 90901 solver.cpp:228] Iteration 48550, loss = 0.394829
I0905 10:22:13.889791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39483 (* 1 = 0.39483 loss)
I0905 10:22:13.889803 90901 sgd_solver.cpp:106] Iteration 48550, lr = 0.1
I0905 10:22:19.978591 90901 solver.cpp:228] Iteration 48560, loss = 0.138192
I0905 10:22:19.978655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138193 (* 1 = 0.138193 loss)
I0905 10:22:19.978672 90901 sgd_solver.cpp:106] Iteration 48560, lr = 0.1
I0905 10:22:26.016003 90901 solver.cpp:228] Iteration 48570, loss = 0.249761
I0905 10:22:26.016074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249762 (* 1 = 0.249762 loss)
I0905 10:22:26.016089 90901 sgd_solver.cpp:106] Iteration 48570, lr = 0.1
I0905 10:22:32.088316 90901 solver.cpp:228] Iteration 48580, loss = 0.566694
I0905 10:22:32.088454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566695 (* 1 = 0.566695 loss)
I0905 10:22:32.088510 90901 sgd_solver.cpp:106] Iteration 48580, lr = 0.1
I0905 10:22:38.478533 90901 solver.cpp:228] Iteration 48590, loss = 0.34175
I0905 10:22:38.478579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341751 (* 1 = 0.341751 loss)
I0905 10:22:38.478591 90901 sgd_solver.cpp:106] Iteration 48590, lr = 0.1
I0905 10:22:44.546543 90901 solver.cpp:228] Iteration 48600, loss = 0.242401
I0905 10:22:44.546597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242402 (* 1 = 0.242402 loss)
I0905 10:22:44.546610 90901 sgd_solver.cpp:106] Iteration 48600, lr = 0.1
I0905 10:22:50.662775 90901 solver.cpp:228] Iteration 48610, loss = 0.15798
I0905 10:22:50.662830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157982 (* 1 = 0.157982 loss)
I0905 10:22:50.662843 90901 sgd_solver.cpp:106] Iteration 48610, lr = 0.1
I0905 10:22:56.734442 90901 solver.cpp:228] Iteration 48620, loss = 0.256262
I0905 10:22:56.734489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256264 (* 1 = 0.256264 loss)
I0905 10:22:56.734503 90901 sgd_solver.cpp:106] Iteration 48620, lr = 0.1
I0905 10:23:02.795366 90901 solver.cpp:228] Iteration 48630, loss = 0.853946
I0905 10:23:02.795603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.853947 (* 1 = 0.853947 loss)
I0905 10:23:02.795619 90901 sgd_solver.cpp:106] Iteration 48630, lr = 0.1
I0905 10:23:08.876227 90901 solver.cpp:228] Iteration 48640, loss = 0.187327
I0905 10:23:08.876281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187329 (* 1 = 0.187329 loss)
I0905 10:23:08.876294 90901 sgd_solver.cpp:106] Iteration 48640, lr = 0.1
I0905 10:23:14.950269 90901 solver.cpp:228] Iteration 48650, loss = 0.148673
I0905 10:23:14.950325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148674 (* 1 = 0.148674 loss)
I0905 10:23:14.950340 90901 sgd_solver.cpp:106] Iteration 48650, lr = 0.1
I0905 10:23:20.858146 90901 solver.cpp:228] Iteration 48660, loss = 0.203651
I0905 10:23:20.858191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203652 (* 1 = 0.203652 loss)
I0905 10:23:20.858204 90901 sgd_solver.cpp:106] Iteration 48660, lr = 0.1
I0905 10:23:26.425050 90901 solver.cpp:228] Iteration 48670, loss = 0.039099
I0905 10:23:26.425104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0391002 (* 1 = 0.0391002 loss)
I0905 10:23:26.425117 90901 sgd_solver.cpp:106] Iteration 48670, lr = 0.1
I0905 10:23:31.617578 90901 solver.cpp:228] Iteration 48680, loss = 0.323579
I0905 10:23:31.617624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32358 (* 1 = 0.32358 loss)
I0905 10:23:31.617637 90901 sgd_solver.cpp:106] Iteration 48680, lr = 0.1
I0905 10:23:37.682282 90901 solver.cpp:228] Iteration 48690, loss = 0.118817
I0905 10:23:37.682498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118818 (* 1 = 0.118818 loss)
I0905 10:23:37.682515 90901 sgd_solver.cpp:106] Iteration 48690, lr = 0.1
I0905 10:23:44.001513 90901 solver.cpp:228] Iteration 48700, loss = 0.0820921
I0905 10:23:44.001561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0820933 (* 1 = 0.0820933 loss)
I0905 10:23:44.001576 90901 sgd_solver.cpp:106] Iteration 48700, lr = 0.1
I0905 10:23:50.109374 90901 solver.cpp:228] Iteration 48710, loss = 0.125591
I0905 10:23:50.109433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125592 (* 1 = 0.125592 loss)
I0905 10:23:50.109447 90901 sgd_solver.cpp:106] Iteration 48710, lr = 0.1
I0905 10:23:56.185853 90901 solver.cpp:228] Iteration 48720, loss = 0.246869
I0905 10:23:56.185906 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246871 (* 1 = 0.246871 loss)
I0905 10:23:56.185922 90901 sgd_solver.cpp:106] Iteration 48720, lr = 0.1
I0905 10:24:02.262512 90901 solver.cpp:228] Iteration 48730, loss = 0.0627002
I0905 10:24:02.262565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0627013 (* 1 = 0.0627013 loss)
I0905 10:24:02.262580 90901 sgd_solver.cpp:106] Iteration 48730, lr = 0.1
I0905 10:24:08.348541 90901 solver.cpp:228] Iteration 48740, loss = 0.256777
I0905 10:24:08.348654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256778 (* 1 = 0.256778 loss)
I0905 10:24:08.348682 90901 sgd_solver.cpp:106] Iteration 48740, lr = 0.1
I0905 10:24:14.438355 90901 solver.cpp:228] Iteration 48750, loss = 0.0881179
I0905 10:24:14.438402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.088119 (* 1 = 0.088119 loss)
I0905 10:24:14.438415 90901 sgd_solver.cpp:106] Iteration 48750, lr = 0.1
I0905 10:24:20.840955 90901 solver.cpp:228] Iteration 48760, loss = 0.339611
I0905 10:24:20.840994 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339612 (* 1 = 0.339612 loss)
I0905 10:24:20.841008 90901 sgd_solver.cpp:106] Iteration 48760, lr = 0.1
I0905 10:24:26.612509 90901 solver.cpp:228] Iteration 48770, loss = 0.198087
I0905 10:24:26.612556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198088 (* 1 = 0.198088 loss)
I0905 10:24:26.612571 90901 sgd_solver.cpp:106] Iteration 48770, lr = 0.1
I0905 10:24:32.845870 90901 solver.cpp:228] Iteration 48780, loss = 0.401183
I0905 10:24:32.845916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401184 (* 1 = 0.401184 loss)
I0905 10:24:32.845932 90901 sgd_solver.cpp:106] Iteration 48780, lr = 0.1
I0905 10:24:39.036500 90901 solver.cpp:228] Iteration 48790, loss = 0.111117
I0905 10:24:39.036768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111118 (* 1 = 0.111118 loss)
I0905 10:24:39.036784 90901 sgd_solver.cpp:106] Iteration 48790, lr = 0.1
I0905 10:24:44.870908 90901 solver.cpp:337] Iteration 48800, Testing net (#0)
I0905 10:25:25.954107 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.855625
I0905 10:25:25.954262 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.357301 (* 1 = 0.357301 loss)
I0905 10:25:26.170487 90901 solver.cpp:228] Iteration 48800, loss = 0.492305
I0905 10:25:26.170516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492306 (* 1 = 0.492306 loss)
I0905 10:25:26.170533 90901 sgd_solver.cpp:106] Iteration 48800, lr = 0.1
I0905 10:25:32.248392 90901 solver.cpp:228] Iteration 48810, loss = 0.175688
I0905 10:25:32.248448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175689 (* 1 = 0.175689 loss)
I0905 10:25:32.248463 90901 sgd_solver.cpp:106] Iteration 48810, lr = 0.1
I0905 10:25:37.994443 90901 solver.cpp:228] Iteration 48820, loss = 0.216242
I0905 10:25:37.994488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216243 (* 1 = 0.216243 loss)
I0905 10:25:37.994503 90901 sgd_solver.cpp:106] Iteration 48820, lr = 0.1
I0905 10:25:44.100786 90901 solver.cpp:228] Iteration 48830, loss = 0.133963
I0905 10:25:44.100828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133964 (* 1 = 0.133964 loss)
I0905 10:25:44.100842 90901 sgd_solver.cpp:106] Iteration 48830, lr = 0.1
I0905 10:25:50.210189 90901 solver.cpp:228] Iteration 48840, loss = 0.280583
I0905 10:25:50.210240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280584 (* 1 = 0.280584 loss)
I0905 10:25:50.210253 90901 sgd_solver.cpp:106] Iteration 48840, lr = 0.1
I0905 10:25:56.604539 90901 solver.cpp:228] Iteration 48850, loss = 0.0809751
I0905 10:25:56.604725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0809763 (* 1 = 0.0809763 loss)
I0905 10:25:56.604755 90901 sgd_solver.cpp:106] Iteration 48850, lr = 0.1
I0905 10:26:02.689968 90901 solver.cpp:228] Iteration 48860, loss = 0.149472
I0905 10:26:02.690016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149474 (* 1 = 0.149474 loss)
I0905 10:26:02.690029 90901 sgd_solver.cpp:106] Iteration 48860, lr = 0.1
I0905 10:26:08.785945 90901 solver.cpp:228] Iteration 48870, loss = 0.158517
I0905 10:26:08.785995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158518 (* 1 = 0.158518 loss)
I0905 10:26:08.786010 90901 sgd_solver.cpp:106] Iteration 48870, lr = 0.1
I0905 10:26:14.852336 90901 solver.cpp:228] Iteration 48880, loss = 0.308398
I0905 10:26:14.852381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308399 (* 1 = 0.308399 loss)
I0905 10:26:14.852396 90901 sgd_solver.cpp:106] Iteration 48880, lr = 0.1
I0905 10:26:20.991618 90901 solver.cpp:228] Iteration 48890, loss = 0.233465
I0905 10:26:20.991672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233466 (* 1 = 0.233466 loss)
I0905 10:26:20.991683 90901 sgd_solver.cpp:106] Iteration 48890, lr = 0.1
I0905 10:26:27.307709 90901 solver.cpp:228] Iteration 48900, loss = 0.100074
I0905 10:26:27.307837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100075 (* 1 = 0.100075 loss)
I0905 10:26:27.307878 90901 sgd_solver.cpp:106] Iteration 48900, lr = 0.1
I0905 10:26:33.307580 90901 solver.cpp:228] Iteration 48910, loss = 0.0727405
I0905 10:26:33.307631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0727416 (* 1 = 0.0727416 loss)
I0905 10:26:33.307644 90901 sgd_solver.cpp:106] Iteration 48910, lr = 0.1
I0905 10:26:39.575561 90901 solver.cpp:228] Iteration 48920, loss = 0.057305
I0905 10:26:39.575605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0573061 (* 1 = 0.0573061 loss)
I0905 10:26:39.575618 90901 sgd_solver.cpp:106] Iteration 48920, lr = 0.1
I0905 10:26:45.036454 90901 solver.cpp:228] Iteration 48930, loss = 0.312342
I0905 10:26:45.036504 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312343 (* 1 = 0.312343 loss)
I0905 10:26:45.036516 90901 sgd_solver.cpp:106] Iteration 48930, lr = 0.1
I0905 10:26:51.475098 90901 solver.cpp:228] Iteration 48940, loss = 0.124429
I0905 10:26:51.475159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12443 (* 1 = 0.12443 loss)
I0905 10:26:51.475173 90901 sgd_solver.cpp:106] Iteration 48940, lr = 0.1
I0905 10:26:57.063668 90901 solver.cpp:228] Iteration 48950, loss = 0.366672
I0905 10:26:57.063711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366673 (* 1 = 0.366673 loss)
I0905 10:26:57.063724 90901 sgd_solver.cpp:106] Iteration 48950, lr = 0.1
I0905 10:27:02.349822 90901 solver.cpp:228] Iteration 48960, loss = 0.317061
I0905 10:27:02.350024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317062 (* 1 = 0.317062 loss)
I0905 10:27:02.350051 90901 sgd_solver.cpp:106] Iteration 48960, lr = 0.1
I0905 10:27:08.469370 90901 solver.cpp:228] Iteration 48970, loss = 0.295763
I0905 10:27:08.469419 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295764 (* 1 = 0.295764 loss)
I0905 10:27:08.469432 90901 sgd_solver.cpp:106] Iteration 48970, lr = 0.1
I0905 10:27:14.799934 90901 solver.cpp:228] Iteration 48980, loss = 0.547506
I0905 10:27:14.799980 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547507 (* 1 = 0.547507 loss)
I0905 10:27:14.799993 90901 sgd_solver.cpp:106] Iteration 48980, lr = 0.1
I0905 10:27:21.184052 90901 solver.cpp:228] Iteration 48990, loss = 0.328366
I0905 10:27:21.184095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328367 (* 1 = 0.328367 loss)
I0905 10:27:21.184108 90901 sgd_solver.cpp:106] Iteration 48990, lr = 0.1
I0905 10:27:27.229344 90901 solver.cpp:228] Iteration 49000, loss = 1.2186
I0905 10:27:27.229403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.2186 (* 1 = 1.2186 loss)
I0905 10:27:27.229418 90901 sgd_solver.cpp:106] Iteration 49000, lr = 0.1
I0905 10:27:33.317068 90901 solver.cpp:228] Iteration 49010, loss = 0.320543
I0905 10:27:33.317241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320544 (* 1 = 0.320544 loss)
I0905 10:27:33.317271 90901 sgd_solver.cpp:106] Iteration 49010, lr = 0.1
I0905 10:27:39.400106 90901 solver.cpp:228] Iteration 49020, loss = 0.403199
I0905 10:27:39.400243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4032 (* 1 = 0.4032 loss)
I0905 10:27:39.400257 90901 sgd_solver.cpp:106] Iteration 49020, lr = 0.1
I0905 10:27:45.749034 90901 solver.cpp:228] Iteration 49030, loss = 0.352568
I0905 10:27:45.749074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35257 (* 1 = 0.35257 loss)
I0905 10:27:45.749096 90901 sgd_solver.cpp:106] Iteration 49030, lr = 0.1
I0905 10:27:51.663234 90901 solver.cpp:228] Iteration 49040, loss = 0.309972
I0905 10:27:51.663286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309973 (* 1 = 0.309973 loss)
I0905 10:27:51.663301 90901 sgd_solver.cpp:106] Iteration 49040, lr = 0.1
I0905 10:27:57.942248 90901 solver.cpp:228] Iteration 49050, loss = 0.296942
I0905 10:27:57.942291 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296943 (* 1 = 0.296943 loss)
I0905 10:27:57.942306 90901 sgd_solver.cpp:106] Iteration 49050, lr = 0.1
I0905 10:28:04.010888 90901 solver.cpp:228] Iteration 49060, loss = 0.286392
I0905 10:28:04.011086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286393 (* 1 = 0.286393 loss)
I0905 10:28:04.011122 90901 sgd_solver.cpp:106] Iteration 49060, lr = 0.1
I0905 10:28:09.778256 90901 solver.cpp:228] Iteration 49070, loss = 0.256459
I0905 10:28:09.778306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25646 (* 1 = 0.25646 loss)
I0905 10:28:09.778319 90901 sgd_solver.cpp:106] Iteration 49070, lr = 0.1
I0905 10:28:16.183161 90901 solver.cpp:228] Iteration 49080, loss = 0.374901
I0905 10:28:16.183217 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374903 (* 1 = 0.374903 loss)
I0905 10:28:16.183230 90901 sgd_solver.cpp:106] Iteration 49080, lr = 0.1
I0905 10:28:22.287436 90901 solver.cpp:228] Iteration 49090, loss = 0.384084
I0905 10:28:22.287488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384085 (* 1 = 0.384085 loss)
I0905 10:28:22.287502 90901 sgd_solver.cpp:106] Iteration 49090, lr = 0.1
I0905 10:28:28.688228 90901 solver.cpp:228] Iteration 49100, loss = 0.116974
I0905 10:28:28.688271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116975 (* 1 = 0.116975 loss)
I0905 10:28:28.688284 90901 sgd_solver.cpp:106] Iteration 49100, lr = 0.1
I0905 10:28:34.712491 90901 solver.cpp:228] Iteration 49110, loss = 0.336454
I0905 10:28:34.712730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336456 (* 1 = 0.336456 loss)
I0905 10:28:34.712760 90901 sgd_solver.cpp:106] Iteration 49110, lr = 0.1
I0905 10:28:40.804348 90901 solver.cpp:228] Iteration 49120, loss = 0.315027
I0905 10:28:40.804405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315028 (* 1 = 0.315028 loss)
I0905 10:28:40.804420 90901 sgd_solver.cpp:106] Iteration 49120, lr = 0.1
I0905 10:28:46.067945 90901 solver.cpp:228] Iteration 49130, loss = 0.264305
I0905 10:28:46.068008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264306 (* 1 = 0.264306 loss)
I0905 10:28:46.068023 90901 sgd_solver.cpp:106] Iteration 49130, lr = 0.1
I0905 10:28:51.768309 90901 solver.cpp:228] Iteration 49140, loss = 0.0630481
I0905 10:28:51.768355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0630493 (* 1 = 0.0630493 loss)
I0905 10:28:51.768368 90901 sgd_solver.cpp:106] Iteration 49140, lr = 0.1
I0905 10:28:57.848019 90901 solver.cpp:228] Iteration 49150, loss = 0.382846
I0905 10:28:57.848065 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382847 (* 1 = 0.382847 loss)
I0905 10:28:57.848079 90901 sgd_solver.cpp:106] Iteration 49150, lr = 0.1
I0905 10:29:03.911523 90901 solver.cpp:228] Iteration 49160, loss = 0.394495
I0905 10:29:03.911571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394496 (* 1 = 0.394496 loss)
I0905 10:29:03.911584 90901 sgd_solver.cpp:106] Iteration 49160, lr = 0.1
I0905 10:29:09.965708 90901 solver.cpp:228] Iteration 49170, loss = 0.718809
I0905 10:29:09.965860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.71881 (* 1 = 0.71881 loss)
I0905 10:29:09.965888 90901 sgd_solver.cpp:106] Iteration 49170, lr = 0.1
I0905 10:29:16.053100 90901 solver.cpp:228] Iteration 49180, loss = 0.278705
I0905 10:29:16.053155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278706 (* 1 = 0.278706 loss)
I0905 10:29:16.053171 90901 sgd_solver.cpp:106] Iteration 49180, lr = 0.1
I0905 10:29:22.148161 90901 solver.cpp:228] Iteration 49190, loss = 1.18372
I0905 10:29:22.148213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.18372 (* 1 = 1.18372 loss)
I0905 10:29:22.148227 90901 sgd_solver.cpp:106] Iteration 49190, lr = 0.1
I0905 10:29:28.203246 90901 solver.cpp:228] Iteration 49200, loss = 0.248527
I0905 10:29:28.203289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248528 (* 1 = 0.248528 loss)
I0905 10:29:28.203301 90901 sgd_solver.cpp:106] Iteration 49200, lr = 0.1
I0905 10:29:34.325274 90901 solver.cpp:228] Iteration 49210, loss = 0.513756
I0905 10:29:34.325322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513757 (* 1 = 0.513757 loss)
I0905 10:29:34.325335 90901 sgd_solver.cpp:106] Iteration 49210, lr = 0.1
I0905 10:29:40.409360 90901 solver.cpp:228] Iteration 49220, loss = 0.428509
I0905 10:29:40.409605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42851 (* 1 = 0.42851 loss)
I0905 10:29:40.409622 90901 sgd_solver.cpp:106] Iteration 49220, lr = 0.1
I0905 10:29:46.512348 90901 solver.cpp:228] Iteration 49230, loss = 0.27454
I0905 10:29:46.512390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274541 (* 1 = 0.274541 loss)
I0905 10:29:46.512403 90901 sgd_solver.cpp:106] Iteration 49230, lr = 0.1
I0905 10:29:52.564980 90901 solver.cpp:228] Iteration 49240, loss = 0.209497
I0905 10:29:52.565027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209498 (* 1 = 0.209498 loss)
I0905 10:29:52.565042 90901 sgd_solver.cpp:106] Iteration 49240, lr = 0.1
I0905 10:29:58.742923 90901 solver.cpp:228] Iteration 49250, loss = 0.243282
I0905 10:29:58.742969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243283 (* 1 = 0.243283 loss)
I0905 10:29:58.742983 90901 sgd_solver.cpp:106] Iteration 49250, lr = 0.1
I0905 10:30:04.936058 90901 solver.cpp:228] Iteration 49260, loss = 0.337038
I0905 10:30:04.936100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33704 (* 1 = 0.33704 loss)
I0905 10:30:04.936112 90901 sgd_solver.cpp:106] Iteration 49260, lr = 0.1
I0905 10:30:10.807534 90901 solver.cpp:228] Iteration 49270, loss = 0.446502
I0905 10:30:10.807709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446503 (* 1 = 0.446503 loss)
I0905 10:30:10.807750 90901 sgd_solver.cpp:106] Iteration 49270, lr = 0.1
I0905 10:30:17.190069 90901 solver.cpp:228] Iteration 49280, loss = 0.114998
I0905 10:30:17.190124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114999 (* 1 = 0.114999 loss)
I0905 10:30:17.190136 90901 sgd_solver.cpp:106] Iteration 49280, lr = 0.1
I0905 10:30:23.300148 90901 solver.cpp:228] Iteration 49290, loss = 0.407908
I0905 10:30:23.300211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407909 (* 1 = 0.407909 loss)
I0905 10:30:23.300226 90901 sgd_solver.cpp:106] Iteration 49290, lr = 0.1
I0905 10:30:29.169826 90901 solver.cpp:228] Iteration 49300, loss = 0.279897
I0905 10:30:29.169891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279898 (* 1 = 0.279898 loss)
I0905 10:30:29.169904 90901 sgd_solver.cpp:106] Iteration 49300, lr = 0.1
I0905 10:30:34.425967 90901 solver.cpp:228] Iteration 49310, loss = 0.473967
I0905 10:30:34.426010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.473969 (* 1 = 0.473969 loss)
I0905 10:30:34.426023 90901 sgd_solver.cpp:106] Iteration 49310, lr = 0.1
I0905 10:30:40.325618 90901 solver.cpp:228] Iteration 49320, loss = 0.265517
I0905 10:30:40.325667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265518 (* 1 = 0.265518 loss)
I0905 10:30:40.325681 90901 sgd_solver.cpp:106] Iteration 49320, lr = 0.1
I0905 10:30:46.380131 90901 solver.cpp:228] Iteration 49330, loss = 0.444316
I0905 10:30:46.380314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444317 (* 1 = 0.444317 loss)
I0905 10:30:46.380347 90901 sgd_solver.cpp:106] Iteration 49330, lr = 0.1
I0905 10:30:52.456188 90901 solver.cpp:228] Iteration 49340, loss = 0.120907
I0905 10:30:52.456240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120909 (* 1 = 0.120909 loss)
I0905 10:30:52.456254 90901 sgd_solver.cpp:106] Iteration 49340, lr = 0.1
I0905 10:30:58.255024 90901 solver.cpp:228] Iteration 49350, loss = 0.143616
I0905 10:30:58.255080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143617 (* 1 = 0.143617 loss)
I0905 10:30:58.255094 90901 sgd_solver.cpp:106] Iteration 49350, lr = 0.1
I0905 10:31:04.942373 90901 solver.cpp:228] Iteration 49360, loss = 0.335585
I0905 10:31:04.942420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335586 (* 1 = 0.335586 loss)
I0905 10:31:04.942433 90901 sgd_solver.cpp:106] Iteration 49360, lr = 0.1
I0905 10:31:10.983631 90901 solver.cpp:228] Iteration 49370, loss = 0.0492409
I0905 10:31:10.983685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0492419 (* 1 = 0.0492419 loss)
I0905 10:31:10.983703 90901 sgd_solver.cpp:106] Iteration 49370, lr = 0.1
I0905 10:31:17.061892 90901 solver.cpp:228] Iteration 49380, loss = 0.199932
I0905 10:31:17.062113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199933 (* 1 = 0.199933 loss)
I0905 10:31:17.062129 90901 sgd_solver.cpp:106] Iteration 49380, lr = 0.1
I0905 10:31:23.138257 90901 solver.cpp:228] Iteration 49390, loss = 0.316092
I0905 10:31:23.138320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316093 (* 1 = 0.316093 loss)
I0905 10:31:23.138339 90901 sgd_solver.cpp:106] Iteration 49390, lr = 0.1
I0905 10:31:29.229140 90901 solver.cpp:228] Iteration 49400, loss = 0.233554
I0905 10:31:29.229190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233555 (* 1 = 0.233555 loss)
I0905 10:31:29.229203 90901 sgd_solver.cpp:106] Iteration 49400, lr = 0.1
I0905 10:31:35.316936 90901 solver.cpp:228] Iteration 49410, loss = 0.220117
I0905 10:31:35.316988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220118 (* 1 = 0.220118 loss)
I0905 10:31:35.317000 90901 sgd_solver.cpp:106] Iteration 49410, lr = 0.1
I0905 10:31:41.721832 90901 solver.cpp:228] Iteration 49420, loss = 0.314279
I0905 10:31:41.721871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31428 (* 1 = 0.31428 loss)
I0905 10:31:41.721884 90901 sgd_solver.cpp:106] Iteration 49420, lr = 0.1
I0905 10:31:47.765851 90901 solver.cpp:228] Iteration 49430, loss = 0.327507
I0905 10:31:47.766002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327508 (* 1 = 0.327508 loss)
I0905 10:31:47.766029 90901 sgd_solver.cpp:106] Iteration 49430, lr = 0.1
I0905 10:31:52.851570 90901 solver.cpp:228] Iteration 49440, loss = 0.300082
I0905 10:31:52.851624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300083 (* 1 = 0.300083 loss)
I0905 10:31:52.851639 90901 sgd_solver.cpp:106] Iteration 49440, lr = 0.1
I0905 10:31:57.895550 90901 solver.cpp:228] Iteration 49450, loss = 0.40966
I0905 10:31:57.895601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.409662 (* 1 = 0.409662 loss)
I0905 10:31:57.895615 90901 sgd_solver.cpp:106] Iteration 49450, lr = 0.1
I0905 10:32:02.951542 90901 solver.cpp:228] Iteration 49460, loss = 0.199106
I0905 10:32:02.951589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199107 (* 1 = 0.199107 loss)
I0905 10:32:02.951601 90901 sgd_solver.cpp:106] Iteration 49460, lr = 0.1
I0905 10:32:07.984115 90901 solver.cpp:228] Iteration 49470, loss = 0.330604
I0905 10:32:07.984174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330605 (* 1 = 0.330605 loss)
I0905 10:32:07.984189 90901 sgd_solver.cpp:106] Iteration 49470, lr = 0.1
I0905 10:32:13.012779 90901 solver.cpp:228] Iteration 49480, loss = 0.267801
I0905 10:32:13.012852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267802 (* 1 = 0.267802 loss)
I0905 10:32:13.012867 90901 sgd_solver.cpp:106] Iteration 49480, lr = 0.1
I0905 10:32:17.907217 90901 solver.cpp:228] Iteration 49490, loss = 0.235085
I0905 10:32:17.907356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235086 (* 1 = 0.235086 loss)
I0905 10:32:17.907405 90901 sgd_solver.cpp:106] Iteration 49490, lr = 0.1
I0905 10:32:22.564585 90901 solver.cpp:228] Iteration 49500, loss = 0.255178
I0905 10:32:22.564630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25518 (* 1 = 0.25518 loss)
I0905 10:32:22.564646 90901 sgd_solver.cpp:106] Iteration 49500, lr = 0.1
I0905 10:32:27.216822 90901 solver.cpp:228] Iteration 49510, loss = 0.275501
I0905 10:32:27.216869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275503 (* 1 = 0.275503 loss)
I0905 10:32:27.216882 90901 sgd_solver.cpp:106] Iteration 49510, lr = 0.1
I0905 10:32:32.218499 90901 solver.cpp:228] Iteration 49520, loss = 0.295787
I0905 10:32:32.218542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295788 (* 1 = 0.295788 loss)
I0905 10:32:32.218556 90901 sgd_solver.cpp:106] Iteration 49520, lr = 0.1
I0905 10:32:37.284315 90901 solver.cpp:228] Iteration 49530, loss = 0.132176
I0905 10:32:37.284368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132177 (* 1 = 0.132177 loss)
I0905 10:32:37.284384 90901 sgd_solver.cpp:106] Iteration 49530, lr = 0.1
I0905 10:32:42.332288 90901 solver.cpp:228] Iteration 49540, loss = 0.490836
I0905 10:32:42.332334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.490837 (* 1 = 0.490837 loss)
I0905 10:32:42.332348 90901 sgd_solver.cpp:106] Iteration 49540, lr = 0.1
I0905 10:32:47.373558 90901 solver.cpp:228] Iteration 49550, loss = 0.0867684
I0905 10:32:47.373620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0867695 (* 1 = 0.0867695 loss)
I0905 10:32:47.373634 90901 sgd_solver.cpp:106] Iteration 49550, lr = 0.1
I0905 10:32:52.433573 90901 solver.cpp:228] Iteration 49560, loss = 0.294548
I0905 10:32:52.433782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294549 (* 1 = 0.294549 loss)
I0905 10:32:52.433815 90901 sgd_solver.cpp:106] Iteration 49560, lr = 0.1
I0905 10:32:57.477607 90901 solver.cpp:228] Iteration 49570, loss = 0.141828
I0905 10:32:57.477664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141829 (* 1 = 0.141829 loss)
I0905 10:32:57.477677 90901 sgd_solver.cpp:106] Iteration 49570, lr = 0.1
I0905 10:33:02.562587 90901 solver.cpp:228] Iteration 49580, loss = 0.640137
I0905 10:33:02.562634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.640138 (* 1 = 0.640138 loss)
I0905 10:33:02.562654 90901 sgd_solver.cpp:106] Iteration 49580, lr = 0.1
I0905 10:33:07.660323 90901 solver.cpp:228] Iteration 49590, loss = 0.174247
I0905 10:33:07.660369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174248 (* 1 = 0.174248 loss)
I0905 10:33:07.660382 90901 sgd_solver.cpp:106] Iteration 49590, lr = 0.1
I0905 10:33:12.858331 90901 solver.cpp:337] Iteration 49600, Testing net (#0)
I0905 10:33:55.374817 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.60875
I0905 10:33:55.375010 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.93343 (* 1 = 0.93343 loss)
I0905 10:33:55.592994 90901 solver.cpp:228] Iteration 49600, loss = 0.472945
I0905 10:33:55.593037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472946 (* 1 = 0.472946 loss)
I0905 10:33:55.593055 90901 sgd_solver.cpp:106] Iteration 49600, lr = 0.1
I0905 10:34:01.996484 90901 solver.cpp:228] Iteration 49610, loss = 0.471873
I0905 10:34:01.996526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.471874 (* 1 = 0.471874 loss)
I0905 10:34:01.996538 90901 sgd_solver.cpp:106] Iteration 49610, lr = 0.1
I0905 10:34:07.847193 90901 solver.cpp:228] Iteration 49620, loss = 0.129786
I0905 10:34:07.847252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129787 (* 1 = 0.129787 loss)
I0905 10:34:07.847266 90901 sgd_solver.cpp:106] Iteration 49620, lr = 0.1
I0905 10:34:12.825340 90901 solver.cpp:228] Iteration 49630, loss = 0.181669
I0905 10:34:12.825387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18167 (* 1 = 0.18167 loss)
I0905 10:34:12.825398 90901 sgd_solver.cpp:106] Iteration 49630, lr = 0.1
I0905 10:34:18.994396 90901 solver.cpp:228] Iteration 49640, loss = 0.402209
I0905 10:34:18.994441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40221 (* 1 = 0.40221 loss)
I0905 10:34:18.994453 90901 sgd_solver.cpp:106] Iteration 49640, lr = 0.1
I0905 10:34:25.284240 90901 solver.cpp:228] Iteration 49650, loss = 0.0635612
I0905 10:34:25.284288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0635622 (* 1 = 0.0635622 loss)
I0905 10:34:25.284303 90901 sgd_solver.cpp:106] Iteration 49650, lr = 0.1
I0905 10:34:31.450415 90901 solver.cpp:228] Iteration 49660, loss = 0.392452
I0905 10:34:31.450565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392453 (* 1 = 0.392453 loss)
I0905 10:34:31.450592 90901 sgd_solver.cpp:106] Iteration 49660, lr = 0.1
I0905 10:34:37.542915 90901 solver.cpp:228] Iteration 49670, loss = 0.604726
I0905 10:34:37.542958 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.604727 (* 1 = 0.604727 loss)
I0905 10:34:37.542970 90901 sgd_solver.cpp:106] Iteration 49670, lr = 0.1
I0905 10:34:43.547174 90901 solver.cpp:228] Iteration 49680, loss = 0.120472
I0905 10:34:43.547225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120473 (* 1 = 0.120473 loss)
I0905 10:34:43.547240 90901 sgd_solver.cpp:106] Iteration 49680, lr = 0.1
I0905 10:34:49.415487 90901 solver.cpp:228] Iteration 49690, loss = 0.403937
I0905 10:34:49.415537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403938 (* 1 = 0.403938 loss)
I0905 10:34:49.415554 90901 sgd_solver.cpp:106] Iteration 49690, lr = 0.1
I0905 10:34:55.687666 90901 solver.cpp:228] Iteration 49700, loss = 0.045736
I0905 10:34:55.687737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0457371 (* 1 = 0.0457371 loss)
I0905 10:34:55.687753 90901 sgd_solver.cpp:106] Iteration 49700, lr = 0.1
I0905 10:35:01.728647 90901 solver.cpp:228] Iteration 49710, loss = 0.296805
I0905 10:35:01.728804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296806 (* 1 = 0.296806 loss)
I0905 10:35:01.728833 90901 sgd_solver.cpp:106] Iteration 49710, lr = 0.1
I0905 10:35:08.017179 90901 solver.cpp:228] Iteration 49720, loss = 0.189641
I0905 10:35:08.017235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189643 (* 1 = 0.189643 loss)
I0905 10:35:08.017248 90901 sgd_solver.cpp:106] Iteration 49720, lr = 0.1
I0905 10:35:14.214972 90901 solver.cpp:228] Iteration 49730, loss = 0.620868
I0905 10:35:14.215023 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.620869 (* 1 = 0.620869 loss)
I0905 10:35:14.215039 90901 sgd_solver.cpp:106] Iteration 49730, lr = 0.1
I0905 10:35:20.248018 90901 solver.cpp:228] Iteration 49740, loss = 0.167961
I0905 10:35:20.248083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167962 (* 1 = 0.167962 loss)
I0905 10:35:20.248100 90901 sgd_solver.cpp:106] Iteration 49740, lr = 0.1
I0905 10:35:26.306948 90901 solver.cpp:228] Iteration 49750, loss = 0.166704
I0905 10:35:26.306995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166705 (* 1 = 0.166705 loss)
I0905 10:35:26.307008 90901 sgd_solver.cpp:106] Iteration 49750, lr = 0.1
I0905 10:35:32.352259 90901 solver.cpp:228] Iteration 49760, loss = 0.379893
I0905 10:35:32.352409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379894 (* 1 = 0.379894 loss)
I0905 10:35:32.352463 90901 sgd_solver.cpp:106] Iteration 49760, lr = 0.1
I0905 10:35:38.073684 90901 solver.cpp:228] Iteration 49770, loss = 0.329647
I0905 10:35:38.073753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329648 (* 1 = 0.329648 loss)
I0905 10:35:38.073768 90901 sgd_solver.cpp:106] Iteration 49770, lr = 0.1
I0905 10:35:44.505198 90901 solver.cpp:228] Iteration 49780, loss = 0.511273
I0905 10:35:44.505244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.511274 (* 1 = 0.511274 loss)
I0905 10:35:44.505254 90901 sgd_solver.cpp:106] Iteration 49780, lr = 0.1
I0905 10:35:50.899754 90901 solver.cpp:228] Iteration 49790, loss = 0.217754
I0905 10:35:50.899809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217755 (* 1 = 0.217755 loss)
I0905 10:35:50.899824 90901 sgd_solver.cpp:106] Iteration 49790, lr = 0.1
I0905 10:35:56.721757 90901 solver.cpp:228] Iteration 49800, loss = 0.355449
I0905 10:35:56.721806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35545 (* 1 = 0.35545 loss)
I0905 10:35:56.721819 90901 sgd_solver.cpp:106] Iteration 49800, lr = 0.1
I0905 10:36:01.970568 90901 solver.cpp:228] Iteration 49810, loss = 0.446007
I0905 10:36:01.970640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446008 (* 1 = 0.446008 loss)
I0905 10:36:01.970654 90901 sgd_solver.cpp:106] Iteration 49810, lr = 0.1
I0905 10:36:07.858847 90901 solver.cpp:228] Iteration 49820, loss = 0.0806044
I0905 10:36:07.859112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0806055 (* 1 = 0.0806055 loss)
I0905 10:36:07.859129 90901 sgd_solver.cpp:106] Iteration 49820, lr = 0.1
I0905 10:36:13.938160 90901 solver.cpp:228] Iteration 49830, loss = 0.178968
I0905 10:36:13.938213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178969 (* 1 = 0.178969 loss)
I0905 10:36:13.938227 90901 sgd_solver.cpp:106] Iteration 49830, lr = 0.1
I0905 10:36:20.025276 90901 solver.cpp:228] Iteration 49840, loss = 0.413948
I0905 10:36:20.025341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413949 (* 1 = 0.413949 loss)
I0905 10:36:20.025355 90901 sgd_solver.cpp:106] Iteration 49840, lr = 0.1
I0905 10:36:25.812360 90901 solver.cpp:228] Iteration 49850, loss = 0.217414
I0905 10:36:25.812404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217415 (* 1 = 0.217415 loss)
I0905 10:36:25.812417 90901 sgd_solver.cpp:106] Iteration 49850, lr = 0.1
I0905 10:36:32.147536 90901 solver.cpp:228] Iteration 49860, loss = 0.295599
I0905 10:36:32.147583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2956 (* 1 = 0.2956 loss)
I0905 10:36:32.147598 90901 sgd_solver.cpp:106] Iteration 49860, lr = 0.1
I0905 10:36:38.203022 90901 solver.cpp:228] Iteration 49870, loss = 0.297869
I0905 10:36:38.203178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29787 (* 1 = 0.29787 loss)
I0905 10:36:38.203220 90901 sgd_solver.cpp:106] Iteration 49870, lr = 0.1
I0905 10:36:44.269891 90901 solver.cpp:228] Iteration 49880, loss = 0.29515
I0905 10:36:44.269963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295151 (* 1 = 0.295151 loss)
I0905 10:36:44.269979 90901 sgd_solver.cpp:106] Iteration 49880, lr = 0.1
I0905 10:36:50.348006 90901 solver.cpp:228] Iteration 49890, loss = 0.396642
I0905 10:36:50.348052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396643 (* 1 = 0.396643 loss)
I0905 10:36:50.348063 90901 sgd_solver.cpp:106] Iteration 49890, lr = 0.1
I0905 10:36:56.758671 90901 solver.cpp:228] Iteration 49900, loss = 0.716161
I0905 10:36:56.758723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.716162 (* 1 = 0.716162 loss)
I0905 10:36:56.758743 90901 sgd_solver.cpp:106] Iteration 49900, lr = 0.1
I0905 10:37:02.826189 90901 solver.cpp:228] Iteration 49910, loss = 0.350542
I0905 10:37:02.826259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350543 (* 1 = 0.350543 loss)
I0905 10:37:02.826277 90901 sgd_solver.cpp:106] Iteration 49910, lr = 0.1
I0905 10:37:08.868120 90901 solver.cpp:228] Iteration 49920, loss = 0.20315
I0905 10:37:08.868257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203151 (* 1 = 0.203151 loss)
I0905 10:37:08.868283 90901 sgd_solver.cpp:106] Iteration 49920, lr = 0.1
I0905 10:37:14.936904 90901 solver.cpp:228] Iteration 49930, loss = 0.238263
I0905 10:37:14.936947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238264 (* 1 = 0.238264 loss)
I0905 10:37:14.936959 90901 sgd_solver.cpp:106] Iteration 49930, lr = 0.1
I0905 10:37:21.035332 90901 solver.cpp:228] Iteration 49940, loss = 0.419728
I0905 10:37:21.035401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419729 (* 1 = 0.419729 loss)
I0905 10:37:21.035418 90901 sgd_solver.cpp:106] Iteration 49940, lr = 0.1
I0905 10:37:27.123803 90901 solver.cpp:228] Iteration 49950, loss = 0.492213
I0905 10:37:27.123864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.492214 (* 1 = 0.492214 loss)
I0905 10:37:27.123878 90901 sgd_solver.cpp:106] Iteration 49950, lr = 0.1
I0905 10:37:33.171041 90901 solver.cpp:228] Iteration 49960, loss = 0.165518
I0905 10:37:33.171106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165519 (* 1 = 0.165519 loss)
I0905 10:37:33.171123 90901 sgd_solver.cpp:106] Iteration 49960, lr = 0.1
I0905 10:37:39.216809 90901 solver.cpp:228] Iteration 49970, loss = 0.1509
I0905 10:37:39.217015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150901 (* 1 = 0.150901 loss)
I0905 10:37:39.217033 90901 sgd_solver.cpp:106] Iteration 49970, lr = 0.1
I0905 10:37:44.947414 90901 solver.cpp:228] Iteration 49980, loss = 0.377503
I0905 10:37:44.947469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377504 (* 1 = 0.377504 loss)
I0905 10:37:44.947482 90901 sgd_solver.cpp:106] Iteration 49980, lr = 0.1
I0905 10:37:50.202699 90901 solver.cpp:228] Iteration 49990, loss = 0.369212
I0905 10:37:50.202765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369213 (* 1 = 0.369213 loss)
I0905 10:37:50.202778 90901 sgd_solver.cpp:106] Iteration 49990, lr = 0.1
I0905 10:37:56.232239 90901 solver.cpp:228] Iteration 50000, loss = 0.170289
I0905 10:37:56.232295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170291 (* 1 = 0.170291 loss)
I0905 10:37:56.232306 90901 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I0905 10:37:56.232316 90901 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I0905 10:38:02.292280 90901 solver.cpp:228] Iteration 50010, loss = 0.723081
I0905 10:38:02.292343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.723082 (* 1 = 0.723082 loss)
I0905 10:38:02.292357 90901 sgd_solver.cpp:106] Iteration 50010, lr = 0.01
I0905 10:38:08.390264 90901 solver.cpp:228] Iteration 50020, loss = 0.329241
I0905 10:38:08.390308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329242 (* 1 = 0.329242 loss)
I0905 10:38:08.390321 90901 sgd_solver.cpp:106] Iteration 50020, lr = 0.01
I0905 10:38:14.492771 90901 solver.cpp:228] Iteration 50030, loss = 0.163649
I0905 10:38:14.493021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16365 (* 1 = 0.16365 loss)
I0905 10:38:14.493038 90901 sgd_solver.cpp:106] Iteration 50030, lr = 0.01
I0905 10:38:20.564262 90901 solver.cpp:228] Iteration 50040, loss = 0.256454
I0905 10:38:20.564309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256455 (* 1 = 0.256455 loss)
I0905 10:38:20.564322 90901 sgd_solver.cpp:106] Iteration 50040, lr = 0.01
I0905 10:38:26.933521 90901 solver.cpp:228] Iteration 50050, loss = 0.373873
I0905 10:38:26.933576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373874 (* 1 = 0.373874 loss)
I0905 10:38:26.933591 90901 sgd_solver.cpp:106] Iteration 50050, lr = 0.01
I0905 10:38:33.005488 90901 solver.cpp:228] Iteration 50060, loss = 0.300164
I0905 10:38:33.005533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300165 (* 1 = 0.300165 loss)
I0905 10:38:33.005547 90901 sgd_solver.cpp:106] Iteration 50060, lr = 0.01
I0905 10:38:39.096524 90901 solver.cpp:228] Iteration 50070, loss = 0.22935
I0905 10:38:39.096560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229351 (* 1 = 0.229351 loss)
I0905 10:38:39.096573 90901 sgd_solver.cpp:106] Iteration 50070, lr = 0.01
I0905 10:38:45.187983 90901 solver.cpp:228] Iteration 50080, loss = 0.552415
I0905 10:38:45.188165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.552416 (* 1 = 0.552416 loss)
I0905 10:38:45.188185 90901 sgd_solver.cpp:106] Iteration 50080, lr = 0.01
I0905 10:38:51.281924 90901 solver.cpp:228] Iteration 50090, loss = 0.120288
I0905 10:38:51.281970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120289 (* 1 = 0.120289 loss)
I0905 10:38:51.281982 90901 sgd_solver.cpp:106] Iteration 50090, lr = 0.01
I0905 10:38:57.375782 90901 solver.cpp:228] Iteration 50100, loss = 0.401484
I0905 10:38:57.375833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401485 (* 1 = 0.401485 loss)
I0905 10:38:57.375847 90901 sgd_solver.cpp:106] Iteration 50100, lr = 0.01
I0905 10:39:03.475813 90901 solver.cpp:228] Iteration 50110, loss = 0.246895
I0905 10:39:03.475862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246896 (* 1 = 0.246896 loss)
I0905 10:39:03.475877 90901 sgd_solver.cpp:106] Iteration 50110, lr = 0.01
I0905 10:39:09.625491 90901 solver.cpp:228] Iteration 50120, loss = 0.152363
I0905 10:39:09.625536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152364 (* 1 = 0.152364 loss)
I0905 10:39:09.625550 90901 sgd_solver.cpp:106] Iteration 50120, lr = 0.01
I0905 10:39:15.996438 90901 solver.cpp:228] Iteration 50130, loss = 0.307796
I0905 10:39:15.996659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307797 (* 1 = 0.307797 loss)
I0905 10:39:15.996695 90901 sgd_solver.cpp:106] Iteration 50130, lr = 0.01
I0905 10:39:22.107264 90901 solver.cpp:228] Iteration 50140, loss = 0.118331
I0905 10:39:22.107309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118332 (* 1 = 0.118332 loss)
I0905 10:39:22.107322 90901 sgd_solver.cpp:106] Iteration 50140, lr = 0.01
I0905 10:39:28.036648 90901 solver.cpp:228] Iteration 50150, loss = 0.302561
I0905 10:39:28.036694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302562 (* 1 = 0.302562 loss)
I0905 10:39:28.036706 90901 sgd_solver.cpp:106] Iteration 50150, lr = 0.01
I0905 10:39:33.296237 90901 solver.cpp:228] Iteration 50160, loss = 0.105465
I0905 10:39:33.296280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105466 (* 1 = 0.105466 loss)
I0905 10:39:33.296293 90901 sgd_solver.cpp:106] Iteration 50160, lr = 0.01
I0905 10:39:38.917735 90901 solver.cpp:228] Iteration 50170, loss = 0.0734078
I0905 10:39:38.917776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0734088 (* 1 = 0.0734088 loss)
I0905 10:39:38.917788 90901 sgd_solver.cpp:106] Iteration 50170, lr = 0.01
I0905 10:39:44.980182 90901 solver.cpp:228] Iteration 50180, loss = 0.460154
I0905 10:39:44.980227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.460155 (* 1 = 0.460155 loss)
I0905 10:39:44.980240 90901 sgd_solver.cpp:106] Iteration 50180, lr = 0.01
I0905 10:39:51.073784 90901 solver.cpp:228] Iteration 50190, loss = 0.144498
I0905 10:39:51.073950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144499 (* 1 = 0.144499 loss)
I0905 10:39:51.073979 90901 sgd_solver.cpp:106] Iteration 50190, lr = 0.01
I0905 10:39:57.163230 90901 solver.cpp:228] Iteration 50200, loss = 0.313927
I0905 10:39:57.163281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313929 (* 1 = 0.313929 loss)
I0905 10:39:57.163297 90901 sgd_solver.cpp:106] Iteration 50200, lr = 0.01
I0905 10:40:03.263464 90901 solver.cpp:228] Iteration 50210, loss = 0.285848
I0905 10:40:03.263517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285849 (* 1 = 0.285849 loss)
I0905 10:40:03.263531 90901 sgd_solver.cpp:106] Iteration 50210, lr = 0.01
I0905 10:40:09.340168 90901 solver.cpp:228] Iteration 50220, loss = 0.0615637
I0905 10:40:09.340214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0615648 (* 1 = 0.0615648 loss)
I0905 10:40:09.340229 90901 sgd_solver.cpp:106] Iteration 50220, lr = 0.01
I0905 10:40:15.760439 90901 solver.cpp:228] Iteration 50230, loss = 0.132966
I0905 10:40:15.760490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132967 (* 1 = 0.132967 loss)
I0905 10:40:15.760505 90901 sgd_solver.cpp:106] Iteration 50230, lr = 0.01
I0905 10:40:21.818030 90901 solver.cpp:228] Iteration 50240, loss = 0.251007
I0905 10:40:21.818194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251008 (* 1 = 0.251008 loss)
I0905 10:40:21.818223 90901 sgd_solver.cpp:106] Iteration 50240, lr = 0.01
I0905 10:40:27.876588 90901 solver.cpp:228] Iteration 50250, loss = 0.399477
I0905 10:40:27.876657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399478 (* 1 = 0.399478 loss)
I0905 10:40:27.876672 90901 sgd_solver.cpp:106] Iteration 50250, lr = 0.01
I0905 10:40:33.643749 90901 solver.cpp:228] Iteration 50260, loss = 0.0857665
I0905 10:40:33.643795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0857676 (* 1 = 0.0857676 loss)
I0905 10:40:33.643807 90901 sgd_solver.cpp:106] Iteration 50260, lr = 0.01
I0905 10:40:40.049175 90901 solver.cpp:228] Iteration 50270, loss = 0.482581
I0905 10:40:40.049231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482582 (* 1 = 0.482582 loss)
I0905 10:40:40.049244 90901 sgd_solver.cpp:106] Iteration 50270, lr = 0.01
I0905 10:40:46.305912 90901 solver.cpp:228] Iteration 50280, loss = 0.243866
I0905 10:40:46.305968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243867 (* 1 = 0.243867 loss)
I0905 10:40:46.305980 90901 sgd_solver.cpp:106] Iteration 50280, lr = 0.01
I0905 10:40:52.140689 90901 solver.cpp:228] Iteration 50290, loss = 0.298286
I0905 10:40:52.140908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298287 (* 1 = 0.298287 loss)
I0905 10:40:52.140949 90901 sgd_solver.cpp:106] Iteration 50290, lr = 0.01
I0905 10:40:58.544152 90901 solver.cpp:228] Iteration 50300, loss = 0.19283
I0905 10:40:58.544203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192832 (* 1 = 0.192832 loss)
I0905 10:40:58.544219 90901 sgd_solver.cpp:106] Iteration 50300, lr = 0.01
I0905 10:41:04.612958 90901 solver.cpp:228] Iteration 50310, loss = 0.375442
I0905 10:41:04.613013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375443 (* 1 = 0.375443 loss)
I0905 10:41:04.613025 90901 sgd_solver.cpp:106] Iteration 50310, lr = 0.01
I0905 10:41:10.677754 90901 solver.cpp:228] Iteration 50320, loss = 0.384672
I0905 10:41:10.677808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384673 (* 1 = 0.384673 loss)
I0905 10:41:10.677819 90901 sgd_solver.cpp:106] Iteration 50320, lr = 0.01
I0905 10:41:16.409539 90901 solver.cpp:228] Iteration 50330, loss = 0.323561
I0905 10:41:16.409584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323562 (* 1 = 0.323562 loss)
I0905 10:41:16.409597 90901 sgd_solver.cpp:106] Iteration 50330, lr = 0.01
I0905 10:41:21.969094 90901 solver.cpp:228] Iteration 50340, loss = 0.279171
I0905 10:41:21.969139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279172 (* 1 = 0.279172 loss)
I0905 10:41:21.969152 90901 sgd_solver.cpp:106] Iteration 50340, lr = 0.01
I0905 10:41:27.619879 90901 solver.cpp:228] Iteration 50350, loss = 0.187087
I0905 10:41:27.620007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187088 (* 1 = 0.187088 loss)
I0905 10:41:27.620034 90901 sgd_solver.cpp:106] Iteration 50350, lr = 0.01
I0905 10:41:33.712484 90901 solver.cpp:228] Iteration 50360, loss = 0.673888
I0905 10:41:33.712530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.673889 (* 1 = 0.673889 loss)
I0905 10:41:33.712543 90901 sgd_solver.cpp:106] Iteration 50360, lr = 0.01
I0905 10:41:39.831542 90901 solver.cpp:228] Iteration 50370, loss = 0.148763
I0905 10:41:39.831588 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148764 (* 1 = 0.148764 loss)
I0905 10:41:39.831600 90901 sgd_solver.cpp:106] Iteration 50370, lr = 0.01
I0905 10:41:45.925292 90901 solver.cpp:228] Iteration 50380, loss = 0.120743
I0905 10:41:45.925340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120744 (* 1 = 0.120744 loss)
I0905 10:41:45.925353 90901 sgd_solver.cpp:106] Iteration 50380, lr = 0.01
I0905 10:41:52.215296 90901 solver.cpp:228] Iteration 50390, loss = 0.292769
I0905 10:41:52.215338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29277 (* 1 = 0.29277 loss)
I0905 10:41:52.215351 90901 sgd_solver.cpp:106] Iteration 50390, lr = 0.01
I0905 10:41:58.187880 90901 solver.cpp:337] Iteration 50400, Testing net (#0)
I0905 10:42:40.313522 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.915937
I0905 10:42:40.313707 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.213539 (* 1 = 0.213539 loss)
I0905 10:42:40.536089 90901 solver.cpp:228] Iteration 50400, loss = 0.415302
I0905 10:42:40.536121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415303 (* 1 = 0.415303 loss)
I0905 10:42:40.536140 90901 sgd_solver.cpp:106] Iteration 50400, lr = 0.01
I0905 10:42:46.626920 90901 solver.cpp:228] Iteration 50410, loss = 0.277181
I0905 10:42:46.626977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277182 (* 1 = 0.277182 loss)
I0905 10:42:46.626991 90901 sgd_solver.cpp:106] Iteration 50410, lr = 0.01
I0905 10:42:52.795442 90901 solver.cpp:228] Iteration 50420, loss = 0.20811
I0905 10:42:52.795490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208111 (* 1 = 0.208111 loss)
I0905 10:42:52.795505 90901 sgd_solver.cpp:106] Iteration 50420, lr = 0.01
I0905 10:42:59.031991 90901 solver.cpp:228] Iteration 50430, loss = 0.103438
I0905 10:42:59.032048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103439 (* 1 = 0.103439 loss)
I0905 10:42:59.032061 90901 sgd_solver.cpp:106] Iteration 50430, lr = 0.01
I0905 10:43:04.365686 90901 solver.cpp:228] Iteration 50440, loss = 0.573933
I0905 10:43:04.365743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.573934 (* 1 = 0.573934 loss)
I0905 10:43:04.365756 90901 sgd_solver.cpp:106] Iteration 50440, lr = 0.01
I0905 10:43:09.697509 90901 solver.cpp:228] Iteration 50450, loss = 0.189762
I0905 10:43:09.697571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189763 (* 1 = 0.189763 loss)
I0905 10:43:09.697587 90901 sgd_solver.cpp:106] Iteration 50450, lr = 0.01
I0905 10:43:15.782866 90901 solver.cpp:228] Iteration 50460, loss = 0.209563
I0905 10:43:15.783100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209564 (* 1 = 0.209564 loss)
I0905 10:43:15.783116 90901 sgd_solver.cpp:106] Iteration 50460, lr = 0.01
I0905 10:43:21.845881 90901 solver.cpp:228] Iteration 50470, loss = 0.0810417
I0905 10:43:21.845939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0810427 (* 1 = 0.0810427 loss)
I0905 10:43:21.845952 90901 sgd_solver.cpp:106] Iteration 50470, lr = 0.01
I0905 10:43:27.929759 90901 solver.cpp:228] Iteration 50480, loss = 0.20667
I0905 10:43:27.929814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206671 (* 1 = 0.206671 loss)
I0905 10:43:27.929828 90901 sgd_solver.cpp:106] Iteration 50480, lr = 0.01
I0905 10:43:33.951716 90901 solver.cpp:228] Iteration 50490, loss = 0.201778
I0905 10:43:33.951769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201779 (* 1 = 0.201779 loss)
I0905 10:43:33.951782 90901 sgd_solver.cpp:106] Iteration 50490, lr = 0.01
I0905 10:43:39.978286 90901 solver.cpp:228] Iteration 50500, loss = 0.213468
I0905 10:43:39.978329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213469 (* 1 = 0.213469 loss)
I0905 10:43:39.978341 90901 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I0905 10:43:46.408833 90901 solver.cpp:228] Iteration 50510, loss = 0.0943746
I0905 10:43:46.408916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0943756 (* 1 = 0.0943756 loss)
I0905 10:43:46.408929 90901 sgd_solver.cpp:106] Iteration 50510, lr = 0.01
I0905 10:43:52.518947 90901 solver.cpp:228] Iteration 50520, loss = 0.159535
I0905 10:43:52.518991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159536 (* 1 = 0.159536 loss)
I0905 10:43:52.519004 90901 sgd_solver.cpp:106] Iteration 50520, lr = 0.01
I0905 10:43:58.311883 90901 solver.cpp:228] Iteration 50530, loss = 0.0479686
I0905 10:43:58.311935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0479696 (* 1 = 0.0479696 loss)
I0905 10:43:58.311949 90901 sgd_solver.cpp:106] Iteration 50530, lr = 0.01
I0905 10:44:04.341861 90901 solver.cpp:228] Iteration 50540, loss = 0.21889
I0905 10:44:04.341910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218891 (* 1 = 0.218891 loss)
I0905 10:44:04.341923 90901 sgd_solver.cpp:106] Iteration 50540, lr = 0.01
I0905 10:44:10.439811 90901 solver.cpp:228] Iteration 50550, loss = 0.519772
I0905 10:44:10.439857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519773 (* 1 = 0.519773 loss)
I0905 10:44:10.439870 90901 sgd_solver.cpp:106] Iteration 50550, lr = 0.01
I0905 10:44:16.499662 90901 solver.cpp:228] Iteration 50560, loss = 0.489423
I0905 10:44:16.499866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489424 (* 1 = 0.489424 loss)
I0905 10:44:16.499881 90901 sgd_solver.cpp:106] Iteration 50560, lr = 0.01
I0905 10:44:22.590000 90901 solver.cpp:228] Iteration 50570, loss = 0.292756
I0905 10:44:22.590040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292757 (* 1 = 0.292757 loss)
I0905 10:44:22.590061 90901 sgd_solver.cpp:106] Iteration 50570, lr = 0.01
I0905 10:44:28.700218 90901 solver.cpp:228] Iteration 50580, loss = 0.276722
I0905 10:44:28.700283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276723 (* 1 = 0.276723 loss)
I0905 10:44:28.700297 90901 sgd_solver.cpp:106] Iteration 50580, lr = 0.01
I0905 10:44:35.082859 90901 solver.cpp:228] Iteration 50590, loss = 0.193813
I0905 10:44:35.082927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193814 (* 1 = 0.193814 loss)
I0905 10:44:35.082942 90901 sgd_solver.cpp:106] Iteration 50590, lr = 0.01
I0905 10:44:41.139271 90901 solver.cpp:228] Iteration 50600, loss = 0.3112
I0905 10:44:41.139312 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311202 (* 1 = 0.311202 loss)
I0905 10:44:41.139327 90901 sgd_solver.cpp:106] Iteration 50600, lr = 0.01
I0905 10:44:47.147377 90901 solver.cpp:228] Iteration 50610, loss = 0.208194
I0905 10:44:47.147568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208195 (* 1 = 0.208195 loss)
I0905 10:44:47.147598 90901 sgd_solver.cpp:106] Iteration 50610, lr = 0.01
I0905 10:44:52.405138 90901 solver.cpp:228] Iteration 50620, loss = 0.181613
I0905 10:44:52.405181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181614 (* 1 = 0.181614 loss)
I0905 10:44:52.405194 90901 sgd_solver.cpp:106] Iteration 50620, lr = 0.01
I0905 10:44:58.130522 90901 solver.cpp:228] Iteration 50630, loss = 0.0798075
I0905 10:44:58.130571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0798085 (* 1 = 0.0798085 loss)
I0905 10:44:58.130584 90901 sgd_solver.cpp:106] Iteration 50630, lr = 0.01
I0905 10:45:04.178117 90901 solver.cpp:228] Iteration 50640, loss = 0.0807254
I0905 10:45:04.178165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0807264 (* 1 = 0.0807264 loss)
I0905 10:45:04.178177 90901 sgd_solver.cpp:106] Iteration 50640, lr = 0.01
I0905 10:45:10.214905 90901 solver.cpp:228] Iteration 50650, loss = 0.0766437
I0905 10:45:10.214954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0766447 (* 1 = 0.0766447 loss)
I0905 10:45:10.214968 90901 sgd_solver.cpp:106] Iteration 50650, lr = 0.01
I0905 10:45:16.265599 90901 solver.cpp:228] Iteration 50660, loss = 0.114006
I0905 10:45:16.265641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114007 (* 1 = 0.114007 loss)
I0905 10:45:16.265655 90901 sgd_solver.cpp:106] Iteration 50660, lr = 0.01
I0905 10:45:22.655249 90901 solver.cpp:228] Iteration 50670, loss = 0.103468
I0905 10:45:22.655472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103469 (* 1 = 0.103469 loss)
I0905 10:45:22.655509 90901 sgd_solver.cpp:106] Iteration 50670, lr = 0.01
I0905 10:45:28.699359 90901 solver.cpp:228] Iteration 50680, loss = 0.340852
I0905 10:45:28.699414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340853 (* 1 = 0.340853 loss)
I0905 10:45:28.699426 90901 sgd_solver.cpp:106] Iteration 50680, lr = 0.01
I0905 10:45:34.774580 90901 solver.cpp:228] Iteration 50690, loss = 0.537918
I0905 10:45:34.774641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.537919 (* 1 = 0.537919 loss)
I0905 10:45:34.774657 90901 sgd_solver.cpp:106] Iteration 50690, lr = 0.01
I0905 10:45:40.877365 90901 solver.cpp:228] Iteration 50700, loss = 0.14214
I0905 10:45:40.877423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142141 (* 1 = 0.142141 loss)
I0905 10:45:40.877435 90901 sgd_solver.cpp:106] Iteration 50700, lr = 0.01
I0905 10:45:46.941886 90901 solver.cpp:228] Iteration 50710, loss = 0.142261
I0905 10:45:46.941936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142262 (* 1 = 0.142262 loss)
I0905 10:45:46.941948 90901 sgd_solver.cpp:106] Iteration 50710, lr = 0.01
I0905 10:45:52.992329 90901 solver.cpp:228] Iteration 50720, loss = 0.0570432
I0905 10:45:52.992565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0570442 (* 1 = 0.0570442 loss)
I0905 10:45:52.992588 90901 sgd_solver.cpp:106] Iteration 50720, lr = 0.01
I0905 10:45:59.081594 90901 solver.cpp:228] Iteration 50730, loss = 0.0545745
I0905 10:45:59.081636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545755 (* 1 = 0.0545755 loss)
I0905 10:45:59.081648 90901 sgd_solver.cpp:106] Iteration 50730, lr = 0.01
I0905 10:46:05.142810 90901 solver.cpp:228] Iteration 50740, loss = 0.375034
I0905 10:46:05.142864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375035 (* 1 = 0.375035 loss)
I0905 10:46:05.142881 90901 sgd_solver.cpp:106] Iteration 50740, lr = 0.01
I0905 10:46:11.219110 90901 solver.cpp:228] Iteration 50750, loss = 0.0526328
I0905 10:46:11.219149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0526338 (* 1 = 0.0526338 loss)
I0905 10:46:11.219162 90901 sgd_solver.cpp:106] Iteration 50750, lr = 0.01
I0905 10:46:17.304656 90901 solver.cpp:228] Iteration 50760, loss = 0.127984
I0905 10:46:17.304705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127985 (* 1 = 0.127985 loss)
I0905 10:46:17.304723 90901 sgd_solver.cpp:106] Iteration 50760, lr = 0.01
I0905 10:46:23.674338 90901 solver.cpp:228] Iteration 50770, loss = 0.205868
I0905 10:46:23.674487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205869 (* 1 = 0.205869 loss)
I0905 10:46:23.674536 90901 sgd_solver.cpp:106] Iteration 50770, lr = 0.01
I0905 10:46:29.453281 90901 solver.cpp:228] Iteration 50780, loss = 0.136467
I0905 10:46:29.453337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136468 (* 1 = 0.136468 loss)
I0905 10:46:29.453351 90901 sgd_solver.cpp:106] Iteration 50780, lr = 0.01
I0905 10:46:35.375322 90901 solver.cpp:228] Iteration 50790, loss = 0.334494
I0905 10:46:35.375371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334495 (* 1 = 0.334495 loss)
I0905 10:46:35.375385 90901 sgd_solver.cpp:106] Iteration 50790, lr = 0.01
I0905 10:46:40.932668 90901 solver.cpp:228] Iteration 50800, loss = 0.438836
I0905 10:46:40.932721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438837 (* 1 = 0.438837 loss)
I0905 10:46:40.932735 90901 sgd_solver.cpp:106] Iteration 50800, lr = 0.01
I0905 10:46:46.528867 90901 solver.cpp:228] Iteration 50810, loss = 0.185645
I0905 10:46:46.528914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185646 (* 1 = 0.185646 loss)
I0905 10:46:46.528928 90901 sgd_solver.cpp:106] Iteration 50810, lr = 0.01
I0905 10:46:52.615463 90901 solver.cpp:228] Iteration 50820, loss = 0.335187
I0905 10:46:52.615520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335188 (* 1 = 0.335188 loss)
I0905 10:46:52.615533 90901 sgd_solver.cpp:106] Iteration 50820, lr = 0.01
I0905 10:46:58.686457 90901 solver.cpp:228] Iteration 50830, loss = 0.180335
I0905 10:46:58.686590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180336 (* 1 = 0.180336 loss)
I0905 10:46:58.686627 90901 sgd_solver.cpp:106] Iteration 50830, lr = 0.01
I0905 10:47:04.801551 90901 solver.cpp:228] Iteration 50840, loss = 0.0839584
I0905 10:47:04.801605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0839595 (* 1 = 0.0839595 loss)
I0905 10:47:04.801620 90901 sgd_solver.cpp:106] Iteration 50840, lr = 0.01
I0905 10:47:10.898766 90901 solver.cpp:228] Iteration 50850, loss = 0.213519
I0905 10:47:10.898826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21352 (* 1 = 0.21352 loss)
I0905 10:47:10.898844 90901 sgd_solver.cpp:106] Iteration 50850, lr = 0.01
I0905 10:47:16.959381 90901 solver.cpp:228] Iteration 50860, loss = 0.0607277
I0905 10:47:16.959424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0607288 (* 1 = 0.0607288 loss)
I0905 10:47:16.959436 90901 sgd_solver.cpp:106] Iteration 50860, lr = 0.01
I0905 10:47:23.347770 90901 solver.cpp:228] Iteration 50870, loss = 0.126778
I0905 10:47:23.347823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126779 (* 1 = 0.126779 loss)
I0905 10:47:23.347838 90901 sgd_solver.cpp:106] Iteration 50870, lr = 0.01
I0905 10:47:29.412860 90901 solver.cpp:228] Iteration 50880, loss = 0.102862
I0905 10:47:29.413060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102863 (* 1 = 0.102863 loss)
I0905 10:47:29.413089 90901 sgd_solver.cpp:106] Iteration 50880, lr = 0.01
I0905 10:47:35.795840 90901 solver.cpp:228] Iteration 50890, loss = 0.292407
I0905 10:47:35.795893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292408 (* 1 = 0.292408 loss)
I0905 10:47:35.795907 90901 sgd_solver.cpp:106] Iteration 50890, lr = 0.01
I0905 10:47:41.860463 90901 solver.cpp:228] Iteration 50900, loss = 0.320979
I0905 10:47:41.860517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32098 (* 1 = 0.32098 loss)
I0905 10:47:41.860532 90901 sgd_solver.cpp:106] Iteration 50900, lr = 0.01
I0905 10:47:47.927783 90901 solver.cpp:228] Iteration 50910, loss = 0.152314
I0905 10:47:47.927855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152315 (* 1 = 0.152315 loss)
I0905 10:47:47.927870 90901 sgd_solver.cpp:106] Iteration 50910, lr = 0.01
I0905 10:47:54.028342 90901 solver.cpp:228] Iteration 50920, loss = 0.305543
I0905 10:47:54.028388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305544 (* 1 = 0.305544 loss)
I0905 10:47:54.028401 90901 sgd_solver.cpp:106] Iteration 50920, lr = 0.01
I0905 10:48:00.087770 90901 solver.cpp:228] Iteration 50930, loss = 0.200096
I0905 10:48:00.087966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200098 (* 1 = 0.200098 loss)
I0905 10:48:00.087998 90901 sgd_solver.cpp:106] Iteration 50930, lr = 0.01
I0905 10:48:06.122834 90901 solver.cpp:228] Iteration 50940, loss = 0.377491
I0905 10:48:06.122880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377492 (* 1 = 0.377492 loss)
I0905 10:48:06.122895 90901 sgd_solver.cpp:106] Iteration 50940, lr = 0.01
I0905 10:48:11.879837 90901 solver.cpp:228] Iteration 50950, loss = 0.12172
I0905 10:48:11.879884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121722 (* 1 = 0.121722 loss)
I0905 10:48:11.879899 90901 sgd_solver.cpp:106] Iteration 50950, lr = 0.01
I0905 10:48:18.262843 90901 solver.cpp:228] Iteration 50960, loss = 0.404165
I0905 10:48:18.262890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404166 (* 1 = 0.404166 loss)
I0905 10:48:18.262902 90901 sgd_solver.cpp:106] Iteration 50960, lr = 0.01
I0905 10:48:24.010380 90901 solver.cpp:228] Iteration 50970, loss = 0.0485977
I0905 10:48:24.010427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0485988 (* 1 = 0.0485988 loss)
I0905 10:48:24.010442 90901 sgd_solver.cpp:106] Iteration 50970, lr = 0.01
I0905 10:48:29.276600 90901 solver.cpp:228] Iteration 50980, loss = 0.800083
I0905 10:48:29.276651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.800084 (* 1 = 0.800084 loss)
I0905 10:48:29.276665 90901 sgd_solver.cpp:106] Iteration 50980, lr = 0.01
I0905 10:48:35.259596 90901 solver.cpp:228] Iteration 50990, loss = 0.179348
I0905 10:48:35.259812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179349 (* 1 = 0.179349 loss)
I0905 10:48:35.259832 90901 sgd_solver.cpp:106] Iteration 50990, lr = 0.01
I0905 10:48:41.335850 90901 solver.cpp:228] Iteration 51000, loss = 0.289893
I0905 10:48:41.335894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289894 (* 1 = 0.289894 loss)
I0905 10:48:41.335907 90901 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I0905 10:48:47.390182 90901 solver.cpp:228] Iteration 51010, loss = 0.200368
I0905 10:48:47.390254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200369 (* 1 = 0.200369 loss)
I0905 10:48:47.390269 90901 sgd_solver.cpp:106] Iteration 51010, lr = 0.01
I0905 10:48:53.485013 90901 solver.cpp:228] Iteration 51020, loss = 0.168203
I0905 10:48:53.485059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168204 (* 1 = 0.168204 loss)
I0905 10:48:53.485070 90901 sgd_solver.cpp:106] Iteration 51020, lr = 0.01
I0905 10:48:59.912395 90901 solver.cpp:228] Iteration 51030, loss = 0.564369
I0905 10:48:59.912446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.56437 (* 1 = 0.56437 loss)
I0905 10:48:59.912458 90901 sgd_solver.cpp:106] Iteration 51030, lr = 0.01
I0905 10:49:05.976272 90901 solver.cpp:228] Iteration 51040, loss = 0.115265
I0905 10:49:05.976389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115266 (* 1 = 0.115266 loss)
I0905 10:49:05.976404 90901 sgd_solver.cpp:106] Iteration 51040, lr = 0.01
I0905 10:49:12.059984 90901 solver.cpp:228] Iteration 51050, loss = 0.24468
I0905 10:49:12.060035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244681 (* 1 = 0.244681 loss)
I0905 10:49:12.060050 90901 sgd_solver.cpp:106] Iteration 51050, lr = 0.01
I0905 10:49:18.115705 90901 solver.cpp:228] Iteration 51060, loss = 0.213384
I0905 10:49:18.115756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213385 (* 1 = 0.213385 loss)
I0905 10:49:18.115773 90901 sgd_solver.cpp:106] Iteration 51060, lr = 0.01
I0905 10:49:24.162508 90901 solver.cpp:228] Iteration 51070, loss = 0.170168
I0905 10:49:24.162564 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170169 (* 1 = 0.170169 loss)
I0905 10:49:24.162575 90901 sgd_solver.cpp:106] Iteration 51070, lr = 0.01
I0905 10:49:30.241895 90901 solver.cpp:228] Iteration 51080, loss = 0.162737
I0905 10:49:30.241955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162738 (* 1 = 0.162738 loss)
I0905 10:49:30.241971 90901 sgd_solver.cpp:106] Iteration 51080, lr = 0.01
I0905 10:49:36.626371 90901 solver.cpp:228] Iteration 51090, loss = 0.243102
I0905 10:49:36.626507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243103 (* 1 = 0.243103 loss)
I0905 10:49:36.626552 90901 sgd_solver.cpp:106] Iteration 51090, lr = 0.01
I0905 10:49:42.582918 90901 solver.cpp:228] Iteration 51100, loss = 0.637078
I0905 10:49:42.582967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.637079 (* 1 = 0.637079 loss)
I0905 10:49:42.582985 90901 sgd_solver.cpp:106] Iteration 51100, lr = 0.01
I0905 10:49:47.775568 90901 solver.cpp:228] Iteration 51110, loss = 0.0656326
I0905 10:49:47.775616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0656337 (* 1 = 0.0656337 loss)
I0905 10:49:47.775643 90901 sgd_solver.cpp:106] Iteration 51110, lr = 0.01
I0905 10:49:52.808534 90901 solver.cpp:228] Iteration 51120, loss = 0.494943
I0905 10:49:52.808578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.494944 (* 1 = 0.494944 loss)
I0905 10:49:52.808591 90901 sgd_solver.cpp:106] Iteration 51120, lr = 0.01
I0905 10:49:57.869168 90901 solver.cpp:228] Iteration 51130, loss = 0.40133
I0905 10:49:57.869215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401331 (* 1 = 0.401331 loss)
I0905 10:49:57.869228 90901 sgd_solver.cpp:106] Iteration 51130, lr = 0.01
I0905 10:50:02.951870 90901 solver.cpp:228] Iteration 51140, loss = 0.184949
I0905 10:50:02.951920 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18495 (* 1 = 0.18495 loss)
I0905 10:50:02.951934 90901 sgd_solver.cpp:106] Iteration 51140, lr = 0.01
I0905 10:50:08.037580 90901 solver.cpp:228] Iteration 51150, loss = 0.0310981
I0905 10:50:08.037823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0310991 (* 1 = 0.0310991 loss)
I0905 10:50:08.037856 90901 sgd_solver.cpp:106] Iteration 51150, lr = 0.01
I0905 10:50:12.677556 90901 solver.cpp:228] Iteration 51160, loss = 0.112368
I0905 10:50:12.677603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112369 (* 1 = 0.112369 loss)
I0905 10:50:12.677616 90901 sgd_solver.cpp:106] Iteration 51160, lr = 0.01
I0905 10:50:17.324793 90901 solver.cpp:228] Iteration 51170, loss = 0.0834844
I0905 10:50:17.324844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0834855 (* 1 = 0.0834855 loss)
I0905 10:50:17.324856 90901 sgd_solver.cpp:106] Iteration 51170, lr = 0.01
I0905 10:50:22.140115 90901 solver.cpp:228] Iteration 51180, loss = 0.287764
I0905 10:50:22.140172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287765 (* 1 = 0.287765 loss)
I0905 10:50:22.140187 90901 sgd_solver.cpp:106] Iteration 51180, lr = 0.01
I0905 10:50:27.202088 90901 solver.cpp:228] Iteration 51190, loss = 0.128123
I0905 10:50:27.202136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128124 (* 1 = 0.128124 loss)
I0905 10:50:27.202147 90901 sgd_solver.cpp:106] Iteration 51190, lr = 0.01
I0905 10:50:32.004900 90901 solver.cpp:337] Iteration 51200, Testing net (#0)
I0905 10:51:07.141948 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.824375
I0905 10:51:07.142161 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.401372 (* 1 = 0.401372 loss)
I0905 10:51:07.365643 90901 solver.cpp:228] Iteration 51200, loss = 0.0422962
I0905 10:51:07.365669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0422973 (* 1 = 0.0422973 loss)
I0905 10:51:07.365685 90901 sgd_solver.cpp:106] Iteration 51200, lr = 0.01
I0905 10:51:13.463665 90901 solver.cpp:228] Iteration 51210, loss = 0.365106
I0905 10:51:13.463711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365107 (* 1 = 0.365107 loss)
I0905 10:51:13.463724 90901 sgd_solver.cpp:106] Iteration 51210, lr = 0.01
I0905 10:51:19.550324 90901 solver.cpp:228] Iteration 51220, loss = 0.170725
I0905 10:51:19.550379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170726 (* 1 = 0.170726 loss)
I0905 10:51:19.550395 90901 sgd_solver.cpp:106] Iteration 51220, lr = 0.01
I0905 10:51:25.298102 90901 solver.cpp:228] Iteration 51230, loss = 0.256993
I0905 10:51:25.298137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256994 (* 1 = 0.256994 loss)
I0905 10:51:25.298151 90901 sgd_solver.cpp:106] Iteration 51230, lr = 0.01
I0905 10:51:31.651851 90901 solver.cpp:228] Iteration 51240, loss = 0.047292
I0905 10:51:31.651891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0472931 (* 1 = 0.0472931 loss)
I0905 10:51:31.651906 90901 sgd_solver.cpp:106] Iteration 51240, lr = 0.01
I0905 10:51:37.706285 90901 solver.cpp:228] Iteration 51250, loss = 0.582697
I0905 10:51:37.706424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.582698 (* 1 = 0.582698 loss)
I0905 10:51:37.706465 90901 sgd_solver.cpp:106] Iteration 51250, lr = 0.01
I0905 10:51:43.793990 90901 solver.cpp:228] Iteration 51260, loss = 0.0646242
I0905 10:51:43.794040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0646254 (* 1 = 0.0646254 loss)
I0905 10:51:43.794054 90901 sgd_solver.cpp:106] Iteration 51260, lr = 0.01
I0905 10:51:49.855703 90901 solver.cpp:228] Iteration 51270, loss = 0.0889197
I0905 10:51:49.855761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0889209 (* 1 = 0.0889209 loss)
I0905 10:51:49.855774 90901 sgd_solver.cpp:106] Iteration 51270, lr = 0.01
I0905 10:51:55.935864 90901 solver.cpp:228] Iteration 51280, loss = 0.146679
I0905 10:51:55.935907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14668 (* 1 = 0.14668 loss)
I0905 10:51:55.935921 90901 sgd_solver.cpp:106] Iteration 51280, lr = 0.01
I0905 10:52:01.442508 90901 solver.cpp:228] Iteration 51290, loss = 0.124512
I0905 10:52:01.442562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124513 (* 1 = 0.124513 loss)
I0905 10:52:01.442575 90901 sgd_solver.cpp:106] Iteration 51290, lr = 0.01
I0905 10:52:06.920614 90901 solver.cpp:228] Iteration 51300, loss = 0.175482
I0905 10:52:06.920665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175483 (* 1 = 0.175483 loss)
I0905 10:52:06.920678 90901 sgd_solver.cpp:106] Iteration 51300, lr = 0.01
I0905 10:52:12.954951 90901 solver.cpp:228] Iteration 51310, loss = 0.0978325
I0905 10:52:12.955152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0978336 (* 1 = 0.0978336 loss)
I0905 10:52:12.955168 90901 sgd_solver.cpp:106] Iteration 51310, lr = 0.01
I0905 10:52:18.742013 90901 solver.cpp:228] Iteration 51320, loss = 0.0998286
I0905 10:52:18.742082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0998298 (* 1 = 0.0998298 loss)
I0905 10:52:18.742097 90901 sgd_solver.cpp:106] Iteration 51320, lr = 0.01
I0905 10:52:25.085011 90901 solver.cpp:228] Iteration 51330, loss = 0.163537
I0905 10:52:25.085050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163538 (* 1 = 0.163538 loss)
I0905 10:52:25.085063 90901 sgd_solver.cpp:106] Iteration 51330, lr = 0.01
I0905 10:52:31.151734 90901 solver.cpp:228] Iteration 51340, loss = 0.300949
I0905 10:52:31.151779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30095 (* 1 = 0.30095 loss)
I0905 10:52:31.151793 90901 sgd_solver.cpp:106] Iteration 51340, lr = 0.01
I0905 10:52:37.221006 90901 solver.cpp:228] Iteration 51350, loss = 0.23811
I0905 10:52:37.221070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238111 (* 1 = 0.238111 loss)
I0905 10:52:37.221087 90901 sgd_solver.cpp:106] Iteration 51350, lr = 0.01
I0905 10:52:43.286309 90901 solver.cpp:228] Iteration 51360, loss = 0.162943
I0905 10:52:43.286478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162944 (* 1 = 0.162944 loss)
I0905 10:52:43.286514 90901 sgd_solver.cpp:106] Iteration 51360, lr = 0.01
I0905 10:52:49.371942 90901 solver.cpp:228] Iteration 51370, loss = 0.438142
I0905 10:52:49.371987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438143 (* 1 = 0.438143 loss)
I0905 10:52:49.372000 90901 sgd_solver.cpp:106] Iteration 51370, lr = 0.01
I0905 10:52:55.460577 90901 solver.cpp:228] Iteration 51380, loss = 0.100135
I0905 10:52:55.460638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100136 (* 1 = 0.100136 loss)
I0905 10:52:55.460654 90901 sgd_solver.cpp:106] Iteration 51380, lr = 0.01
I0905 10:53:01.679714 90901 solver.cpp:228] Iteration 51390, loss = 0.0724636
I0905 10:53:01.679771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0724648 (* 1 = 0.0724648 loss)
I0905 10:53:01.679783 90901 sgd_solver.cpp:106] Iteration 51390, lr = 0.01
I0905 10:53:07.904253 90901 solver.cpp:228] Iteration 51400, loss = 0.218859
I0905 10:53:07.904301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218861 (* 1 = 0.218861 loss)
I0905 10:53:07.904314 90901 sgd_solver.cpp:106] Iteration 51400, lr = 0.01
I0905 10:53:13.972795 90901 solver.cpp:228] Iteration 51410, loss = 0.163168
I0905 10:53:13.972949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163169 (* 1 = 0.163169 loss)
I0905 10:53:13.972970 90901 sgd_solver.cpp:106] Iteration 51410, lr = 0.01
I0905 10:53:20.051355 90901 solver.cpp:228] Iteration 51420, loss = 0.329188
I0905 10:53:20.051415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32919 (* 1 = 0.32919 loss)
I0905 10:53:20.051429 90901 sgd_solver.cpp:106] Iteration 51420, lr = 0.01
I0905 10:53:26.122730 90901 solver.cpp:228] Iteration 51430, loss = 0.227885
I0905 10:53:26.122782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227886 (* 1 = 0.227886 loss)
I0905 10:53:26.122795 90901 sgd_solver.cpp:106] Iteration 51430, lr = 0.01
I0905 10:53:32.217732 90901 solver.cpp:228] Iteration 51440, loss = 0.264647
I0905 10:53:32.217777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264648 (* 1 = 0.264648 loss)
I0905 10:53:32.217790 90901 sgd_solver.cpp:106] Iteration 51440, lr = 0.01
I0905 10:53:38.255915 90901 solver.cpp:228] Iteration 51450, loss = 0.208104
I0905 10:53:38.255951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208105 (* 1 = 0.208105 loss)
I0905 10:53:38.255966 90901 sgd_solver.cpp:106] Iteration 51450, lr = 0.01
I0905 10:53:44.283553 90901 solver.cpp:228] Iteration 51460, loss = 0.0672582
I0905 10:53:44.283746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0672594 (* 1 = 0.0672594 loss)
I0905 10:53:44.283759 90901 sgd_solver.cpp:106] Iteration 51460, lr = 0.01
I0905 10:53:49.685235 90901 solver.cpp:228] Iteration 51470, loss = 0.133374
I0905 10:53:49.685281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133375 (* 1 = 0.133375 loss)
I0905 10:53:49.685294 90901 sgd_solver.cpp:106] Iteration 51470, lr = 0.01
I0905 10:53:55.377846 90901 solver.cpp:228] Iteration 51480, loss = 0.209999
I0905 10:53:55.377889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210001 (* 1 = 0.210001 loss)
I0905 10:53:55.377902 90901 sgd_solver.cpp:106] Iteration 51480, lr = 0.01
I0905 10:54:01.249001 90901 solver.cpp:228] Iteration 51490, loss = 0.154732
I0905 10:54:01.249069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154733 (* 1 = 0.154733 loss)
I0905 10:54:01.249083 90901 sgd_solver.cpp:106] Iteration 51490, lr = 0.01
I0905 10:54:07.339455 90901 solver.cpp:228] Iteration 51500, loss = 0.240385
I0905 10:54:07.339498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240386 (* 1 = 0.240386 loss)
I0905 10:54:07.339510 90901 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I0905 10:54:13.431306 90901 solver.cpp:228] Iteration 51510, loss = 0.537079
I0905 10:54:13.431346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.53708 (* 1 = 0.53708 loss)
I0905 10:54:13.431361 90901 sgd_solver.cpp:106] Iteration 51510, lr = 0.01
I0905 10:54:19.343454 90901 solver.cpp:228] Iteration 51520, loss = 0.425469
I0905 10:54:19.343580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.42547 (* 1 = 0.42547 loss)
I0905 10:54:19.343595 90901 sgd_solver.cpp:106] Iteration 51520, lr = 0.01
I0905 10:54:25.203995 90901 solver.cpp:228] Iteration 51530, loss = 0.352779
I0905 10:54:25.204047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35278 (* 1 = 0.35278 loss)
I0905 10:54:25.204059 90901 sgd_solver.cpp:106] Iteration 51530, lr = 0.01
I0905 10:54:31.334774 90901 solver.cpp:228] Iteration 51540, loss = 0.519888
I0905 10:54:31.334837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.519889 (* 1 = 0.519889 loss)
I0905 10:54:31.334853 90901 sgd_solver.cpp:106] Iteration 51540, lr = 0.01
I0905 10:54:37.413884 90901 solver.cpp:228] Iteration 51550, loss = 0.093552
I0905 10:54:37.413933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0935532 (* 1 = 0.0935532 loss)
I0905 10:54:37.413945 90901 sgd_solver.cpp:106] Iteration 51550, lr = 0.01
I0905 10:54:43.528144 90901 solver.cpp:228] Iteration 51560, loss = 0.415395
I0905 10:54:43.528190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415396 (* 1 = 0.415396 loss)
I0905 10:54:43.528205 90901 sgd_solver.cpp:106] Iteration 51560, lr = 0.01
I0905 10:54:49.587251 90901 solver.cpp:228] Iteration 51570, loss = 0.135302
I0905 10:54:49.587415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135303 (* 1 = 0.135303 loss)
I0905 10:54:49.587458 90901 sgd_solver.cpp:106] Iteration 51570, lr = 0.01
I0905 10:54:55.676523 90901 solver.cpp:228] Iteration 51580, loss = 0.41283
I0905 10:54:55.676566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412831 (* 1 = 0.412831 loss)
I0905 10:54:55.676579 90901 sgd_solver.cpp:106] Iteration 51580, lr = 0.01
I0905 10:55:01.740839 90901 solver.cpp:228] Iteration 51590, loss = 0.332826
I0905 10:55:01.740887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332828 (* 1 = 0.332828 loss)
I0905 10:55:01.740901 90901 sgd_solver.cpp:106] Iteration 51590, lr = 0.01
I0905 10:55:07.780730 90901 solver.cpp:228] Iteration 51600, loss = 0.135011
I0905 10:55:07.780776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135012 (* 1 = 0.135012 loss)
I0905 10:55:07.780792 90901 sgd_solver.cpp:106] Iteration 51600, lr = 0.01
I0905 10:55:14.149909 90901 solver.cpp:228] Iteration 51610, loss = 0.171957
I0905 10:55:14.149968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171959 (* 1 = 0.171959 loss)
I0905 10:55:14.149983 90901 sgd_solver.cpp:106] Iteration 51610, lr = 0.01
I0905 10:55:20.208564 90901 solver.cpp:228] Iteration 51620, loss = 0.385604
I0905 10:55:20.208794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385605 (* 1 = 0.385605 loss)
I0905 10:55:20.208827 90901 sgd_solver.cpp:106] Iteration 51620, lr = 0.01
I0905 10:55:26.306941 90901 solver.cpp:228] Iteration 51630, loss = 0.254791
I0905 10:55:26.306993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254792 (* 1 = 0.254792 loss)
I0905 10:55:26.307006 90901 sgd_solver.cpp:106] Iteration 51630, lr = 0.01
I0905 10:55:32.575273 90901 solver.cpp:228] Iteration 51640, loss = 0.238281
I0905 10:55:32.575342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238282 (* 1 = 0.238282 loss)
I0905 10:55:32.575356 90901 sgd_solver.cpp:106] Iteration 51640, lr = 0.01
I0905 10:55:37.805850 90901 solver.cpp:228] Iteration 51650, loss = 0.132758
I0905 10:55:37.805898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132759 (* 1 = 0.132759 loss)
I0905 10:55:37.805912 90901 sgd_solver.cpp:106] Iteration 51650, lr = 0.01
I0905 10:55:43.351704 90901 solver.cpp:228] Iteration 51660, loss = 0.209159
I0905 10:55:43.351747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20916 (* 1 = 0.20916 loss)
I0905 10:55:43.351759 90901 sgd_solver.cpp:106] Iteration 51660, lr = 0.01
I0905 10:55:49.425582 90901 solver.cpp:228] Iteration 51670, loss = 0.173055
I0905 10:55:49.425632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173056 (* 1 = 0.173056 loss)
I0905 10:55:49.425645 90901 sgd_solver.cpp:106] Iteration 51670, lr = 0.01
I0905 10:55:55.518018 90901 solver.cpp:228] Iteration 51680, loss = 0.210193
I0905 10:55:55.518193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210194 (* 1 = 0.210194 loss)
I0905 10:55:55.518221 90901 sgd_solver.cpp:106] Iteration 51680, lr = 0.01
I0905 10:56:01.569859 90901 solver.cpp:228] Iteration 51690, loss = 0.181267
I0905 10:56:01.569916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181268 (* 1 = 0.181268 loss)
I0905 10:56:01.569929 90901 sgd_solver.cpp:106] Iteration 51690, lr = 0.01
I0905 10:56:07.899440 90901 solver.cpp:228] Iteration 51700, loss = 0.231712
I0905 10:56:07.899498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231713 (* 1 = 0.231713 loss)
I0905 10:56:07.899513 90901 sgd_solver.cpp:106] Iteration 51700, lr = 0.01
I0905 10:56:13.705314 90901 solver.cpp:228] Iteration 51710, loss = 0.647333
I0905 10:56:13.705358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.647335 (* 1 = 0.647335 loss)
I0905 10:56:13.705371 90901 sgd_solver.cpp:106] Iteration 51710, lr = 0.01
I0905 10:56:19.758536 90901 solver.cpp:228] Iteration 51720, loss = 0.19373
I0905 10:56:19.758587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193731 (* 1 = 0.193731 loss)
I0905 10:56:19.758601 90901 sgd_solver.cpp:106] Iteration 51720, lr = 0.01
I0905 10:56:26.181068 90901 solver.cpp:228] Iteration 51730, loss = 0.1487
I0905 10:56:26.181252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148701 (* 1 = 0.148701 loss)
I0905 10:56:26.181267 90901 sgd_solver.cpp:106] Iteration 51730, lr = 0.01
I0905 10:56:32.257787 90901 solver.cpp:228] Iteration 51740, loss = 0.346151
I0905 10:56:32.257836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346152 (* 1 = 0.346152 loss)
I0905 10:56:32.257853 90901 sgd_solver.cpp:106] Iteration 51740, lr = 0.01
I0905 10:56:38.324326 90901 solver.cpp:228] Iteration 51750, loss = 0.355285
I0905 10:56:38.324378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355286 (* 1 = 0.355286 loss)
I0905 10:56:38.324393 90901 sgd_solver.cpp:106] Iteration 51750, lr = 0.01
I0905 10:56:44.369660 90901 solver.cpp:228] Iteration 51760, loss = 0.133598
I0905 10:56:44.369709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1336 (* 1 = 0.1336 loss)
I0905 10:56:44.369720 90901 sgd_solver.cpp:106] Iteration 51760, lr = 0.01
I0905 10:56:50.446184 90901 solver.cpp:228] Iteration 51770, loss = 0.181411
I0905 10:56:50.446244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181413 (* 1 = 0.181413 loss)
I0905 10:56:50.446259 90901 sgd_solver.cpp:106] Iteration 51770, lr = 0.01
I0905 10:56:56.713646 90901 solver.cpp:228] Iteration 51780, loss = 0.213359
I0905 10:56:56.713922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21336 (* 1 = 0.21336 loss)
I0905 10:56:56.713939 90901 sgd_solver.cpp:106] Iteration 51780, lr = 0.01
I0905 10:57:02.913393 90901 solver.cpp:228] Iteration 51790, loss = 0.251055
I0905 10:57:02.913445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251056 (* 1 = 0.251056 loss)
I0905 10:57:02.913460 90901 sgd_solver.cpp:106] Iteration 51790, lr = 0.01
I0905 10:57:08.955040 90901 solver.cpp:228] Iteration 51800, loss = 0.113841
I0905 10:57:08.955090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113842 (* 1 = 0.113842 loss)
I0905 10:57:08.955103 90901 sgd_solver.cpp:106] Iteration 51800, lr = 0.01
I0905 10:57:15.369562 90901 solver.cpp:228] Iteration 51810, loss = 0.151206
I0905 10:57:15.369603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151207 (* 1 = 0.151207 loss)
I0905 10:57:15.369616 90901 sgd_solver.cpp:106] Iteration 51810, lr = 0.01
I0905 10:57:21.340423 90901 solver.cpp:228] Iteration 51820, loss = 0.525163
I0905 10:57:21.340468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.525164 (* 1 = 0.525164 loss)
I0905 10:57:21.340481 90901 sgd_solver.cpp:106] Iteration 51820, lr = 0.01
I0905 10:57:26.911682 90901 solver.cpp:228] Iteration 51830, loss = 0.319677
I0905 10:57:26.911875 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319678 (* 1 = 0.319678 loss)
I0905 10:57:26.911891 90901 sgd_solver.cpp:106] Iteration 51830, lr = 0.01
I0905 10:57:32.298779 90901 solver.cpp:228] Iteration 51840, loss = 0.839727
I0905 10:57:32.298825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.839728 (* 1 = 0.839728 loss)
I0905 10:57:32.298837 90901 sgd_solver.cpp:106] Iteration 51840, lr = 0.01
I0905 10:57:38.653312 90901 solver.cpp:228] Iteration 51850, loss = 0.362066
I0905 10:57:38.653359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362067 (* 1 = 0.362067 loss)
I0905 10:57:38.653372 90901 sgd_solver.cpp:106] Iteration 51850, lr = 0.01
I0905 10:57:44.746140 90901 solver.cpp:228] Iteration 51860, loss = 0.245962
I0905 10:57:44.746178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245963 (* 1 = 0.245963 loss)
I0905 10:57:44.746193 90901 sgd_solver.cpp:106] Iteration 51860, lr = 0.01
I0905 10:57:50.832052 90901 solver.cpp:228] Iteration 51870, loss = 0.588859
I0905 10:57:50.832094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.58886 (* 1 = 0.58886 loss)
I0905 10:57:50.832108 90901 sgd_solver.cpp:106] Iteration 51870, lr = 0.01
I0905 10:57:56.903925 90901 solver.cpp:228] Iteration 51880, loss = 0.397643
I0905 10:57:56.903966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397644 (* 1 = 0.397644 loss)
I0905 10:57:56.903981 90901 sgd_solver.cpp:106] Iteration 51880, lr = 0.01
I0905 10:58:02.971920 90901 solver.cpp:228] Iteration 51890, loss = 0.282075
I0905 10:58:02.972085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282076 (* 1 = 0.282076 loss)
I0905 10:58:02.972126 90901 sgd_solver.cpp:106] Iteration 51890, lr = 0.01
I0905 10:58:09.074899 90901 solver.cpp:228] Iteration 51900, loss = 0.181548
I0905 10:58:09.074945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18155 (* 1 = 0.18155 loss)
I0905 10:58:09.074960 90901 sgd_solver.cpp:106] Iteration 51900, lr = 0.01
I0905 10:58:15.137670 90901 solver.cpp:228] Iteration 51910, loss = 0.290776
I0905 10:58:15.137734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290777 (* 1 = 0.290777 loss)
I0905 10:58:15.137750 90901 sgd_solver.cpp:106] Iteration 51910, lr = 0.01
I0905 10:58:21.244367 90901 solver.cpp:228] Iteration 51920, loss = 0.160779
I0905 10:58:21.244422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16078 (* 1 = 0.16078 loss)
I0905 10:58:21.244436 90901 sgd_solver.cpp:106] Iteration 51920, lr = 0.01
I0905 10:58:27.278714 90901 solver.cpp:228] Iteration 51930, loss = 0.569449
I0905 10:58:27.278765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.56945 (* 1 = 0.56945 loss)
I0905 10:58:27.278779 90901 sgd_solver.cpp:106] Iteration 51930, lr = 0.01
I0905 10:58:33.386359 90901 solver.cpp:228] Iteration 51940, loss = 0.212872
I0905 10:58:33.386574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212873 (* 1 = 0.212873 loss)
I0905 10:58:33.386600 90901 sgd_solver.cpp:106] Iteration 51940, lr = 0.01
I0905 10:58:39.401576 90901 solver.cpp:228] Iteration 51950, loss = 0.248366
I0905 10:58:39.401633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248367 (* 1 = 0.248367 loss)
I0905 10:58:39.401648 90901 sgd_solver.cpp:106] Iteration 51950, lr = 0.01
I0905 10:58:45.829556 90901 solver.cpp:228] Iteration 51960, loss = 0.200227
I0905 10:58:45.829599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200228 (* 1 = 0.200228 loss)
I0905 10:58:45.829612 90901 sgd_solver.cpp:106] Iteration 51960, lr = 0.01
I0905 10:58:51.569419 90901 solver.cpp:228] Iteration 51970, loss = 0.224505
I0905 10:58:51.569463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224507 (* 1 = 0.224507 loss)
I0905 10:58:51.569475 90901 sgd_solver.cpp:106] Iteration 51970, lr = 0.01
I0905 10:58:57.993098 90901 solver.cpp:228] Iteration 51980, loss = 0.653758
I0905 10:58:57.993147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.653759 (* 1 = 0.653759 loss)
I0905 10:58:57.993160 90901 sgd_solver.cpp:106] Iteration 51980, lr = 0.01
I0905 10:59:03.743043 90901 solver.cpp:228] Iteration 51990, loss = 0.162801
I0905 10:59:03.743263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162802 (* 1 = 0.162802 loss)
I0905 10:59:03.743280 90901 sgd_solver.cpp:106] Iteration 51990, lr = 0.01
I0905 10:59:09.753945 90901 solver.cpp:337] Iteration 52000, Testing net (#0)
I0905 10:59:51.026865 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.796562
I0905 10:59:51.027083 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.484624 (* 1 = 0.484624 loss)
I0905 10:59:51.433341 90901 solver.cpp:228] Iteration 52000, loss = 0.525611
I0905 10:59:51.433400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.525612 (* 1 = 0.525612 loss)
I0905 10:59:51.433418 90901 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I0905 10:59:57.612099 90901 solver.cpp:228] Iteration 52010, loss = 0.276284
I0905 10:59:57.612152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276285 (* 1 = 0.276285 loss)
I0905 10:59:57.612169 90901 sgd_solver.cpp:106] Iteration 52010, lr = 0.01
I0905 11:00:03.682658 90901 solver.cpp:228] Iteration 52020, loss = 0.198721
I0905 11:00:03.682713 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198722 (* 1 = 0.198722 loss)
I0905 11:00:03.682729 90901 sgd_solver.cpp:106] Iteration 52020, lr = 0.01
I0905 11:00:10.065428 90901 solver.cpp:228] Iteration 52030, loss = 0.418788
I0905 11:00:10.065469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418789 (* 1 = 0.418789 loss)
I0905 11:00:10.065482 90901 sgd_solver.cpp:106] Iteration 52030, lr = 0.01
I0905 11:00:16.125022 90901 solver.cpp:228] Iteration 52040, loss = 0.0879704
I0905 11:00:16.125082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0879716 (* 1 = 0.0879716 loss)
I0905 11:00:16.125097 90901 sgd_solver.cpp:106] Iteration 52040, lr = 0.01
I0905 11:00:22.275446 90901 solver.cpp:228] Iteration 52050, loss = 0.182945
I0905 11:00:22.275614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182946 (* 1 = 0.182946 loss)
I0905 11:00:22.275640 90901 sgd_solver.cpp:106] Iteration 52050, lr = 0.01
I0905 11:00:28.632752 90901 solver.cpp:228] Iteration 52060, loss = 0.341188
I0905 11:00:28.632794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341189 (* 1 = 0.341189 loss)
I0905 11:00:28.632808 90901 sgd_solver.cpp:106] Iteration 52060, lr = 0.01
I0905 11:00:34.664846 90901 solver.cpp:228] Iteration 52070, loss = 0.116365
I0905 11:00:34.664908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116366 (* 1 = 0.116366 loss)
I0905 11:00:34.664922 90901 sgd_solver.cpp:106] Iteration 52070, lr = 0.01
I0905 11:00:40.741755 90901 solver.cpp:228] Iteration 52080, loss = 0.361622
I0905 11:00:40.741807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361624 (* 1 = 0.361624 loss)
I0905 11:00:40.741825 90901 sgd_solver.cpp:106] Iteration 52080, lr = 0.01
I0905 11:00:46.933413 90901 solver.cpp:228] Iteration 52090, loss = 0.231916
I0905 11:00:46.933452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231918 (* 1 = 0.231918 loss)
I0905 11:00:46.933465 90901 sgd_solver.cpp:106] Iteration 52090, lr = 0.01
I0905 11:00:53.154016 90901 solver.cpp:228] Iteration 52100, loss = 0.354405
I0905 11:00:53.154147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354406 (* 1 = 0.354406 loss)
I0905 11:00:53.154175 90901 sgd_solver.cpp:106] Iteration 52100, lr = 0.01
I0905 11:00:59.111665 90901 solver.cpp:228] Iteration 52110, loss = 0.140835
I0905 11:00:59.111711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140836 (* 1 = 0.140836 loss)
I0905 11:00:59.111723 90901 sgd_solver.cpp:106] Iteration 52110, lr = 0.01
I0905 11:01:04.676141 90901 solver.cpp:228] Iteration 52120, loss = 0.353067
I0905 11:01:04.676192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353069 (* 1 = 0.353069 loss)
I0905 11:01:04.676205 90901 sgd_solver.cpp:106] Iteration 52120, lr = 0.01
I0905 11:01:10.092206 90901 solver.cpp:228] Iteration 52130, loss = 0.100393
I0905 11:01:10.092247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100394 (* 1 = 0.100394 loss)
I0905 11:01:10.092272 90901 sgd_solver.cpp:106] Iteration 52130, lr = 0.01
I0905 11:01:16.527004 90901 solver.cpp:228] Iteration 52140, loss = 0.322377
I0905 11:01:16.527046 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322378 (* 1 = 0.322378 loss)
I0905 11:01:16.527060 90901 sgd_solver.cpp:106] Iteration 52140, lr = 0.01
I0905 11:01:22.295505 90901 solver.cpp:228] Iteration 52150, loss = 0.403371
I0905 11:01:22.295575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403372 (* 1 = 0.403372 loss)
I0905 11:01:22.295589 90901 sgd_solver.cpp:106] Iteration 52150, lr = 0.01
I0905 11:01:28.355552 90901 solver.cpp:228] Iteration 52160, loss = 0.139634
I0905 11:01:28.355712 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139635 (* 1 = 0.139635 loss)
I0905 11:01:28.355751 90901 sgd_solver.cpp:106] Iteration 52160, lr = 0.01
I0905 11:01:34.412696 90901 solver.cpp:228] Iteration 52170, loss = 0.0553513
I0905 11:01:34.412741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0553525 (* 1 = 0.0553525 loss)
I0905 11:01:34.412755 90901 sgd_solver.cpp:106] Iteration 52170, lr = 0.01
I0905 11:01:40.793053 90901 solver.cpp:228] Iteration 52180, loss = 0.117876
I0905 11:01:40.793128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117877 (* 1 = 0.117877 loss)
I0905 11:01:40.793143 90901 sgd_solver.cpp:106] Iteration 52180, lr = 0.01
I0905 11:01:46.876086 90901 solver.cpp:228] Iteration 52190, loss = 0.137133
I0905 11:01:46.876152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137134 (* 1 = 0.137134 loss)
I0905 11:01:46.876168 90901 sgd_solver.cpp:106] Iteration 52190, lr = 0.01
I0905 11:01:52.943931 90901 solver.cpp:228] Iteration 52200, loss = 0.149134
I0905 11:01:52.943994 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149136 (* 1 = 0.149136 loss)
I0905 11:01:52.944008 90901 sgd_solver.cpp:106] Iteration 52200, lr = 0.01
I0905 11:01:59.071002 90901 solver.cpp:228] Iteration 52210, loss = 0.198206
I0905 11:01:59.071305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198207 (* 1 = 0.198207 loss)
I0905 11:01:59.071323 90901 sgd_solver.cpp:106] Iteration 52210, lr = 0.01
I0905 11:02:05.127437 90901 solver.cpp:228] Iteration 52220, loss = 0.224378
I0905 11:02:05.127493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22438 (* 1 = 0.22438 loss)
I0905 11:02:05.127508 90901 sgd_solver.cpp:106] Iteration 52220, lr = 0.01
I0905 11:02:11.381372 90901 solver.cpp:228] Iteration 52230, loss = 0.0936636
I0905 11:02:11.381443 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0936649 (* 1 = 0.0936649 loss)
I0905 11:02:11.381456 90901 sgd_solver.cpp:106] Iteration 52230, lr = 0.01
I0905 11:02:17.654849 90901 solver.cpp:228] Iteration 52240, loss = 0.326527
I0905 11:02:17.654902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326529 (* 1 = 0.326529 loss)
I0905 11:02:17.654917 90901 sgd_solver.cpp:106] Iteration 52240, lr = 0.01
I0905 11:02:23.707700 90901 solver.cpp:228] Iteration 52250, loss = 0.137643
I0905 11:02:23.707751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137645 (* 1 = 0.137645 loss)
I0905 11:02:23.707764 90901 sgd_solver.cpp:106] Iteration 52250, lr = 0.01
I0905 11:02:29.789716 90901 solver.cpp:228] Iteration 52260, loss = 0.355758
I0905 11:02:29.789914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355759 (* 1 = 0.355759 loss)
I0905 11:02:29.789945 90901 sgd_solver.cpp:106] Iteration 52260, lr = 0.01
I0905 11:02:35.985702 90901 solver.cpp:228] Iteration 52270, loss = 0.435021
I0905 11:02:35.985777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435022 (* 1 = 0.435022 loss)
I0905 11:02:35.985792 90901 sgd_solver.cpp:106] Iteration 52270, lr = 0.01
I0905 11:02:41.972514 90901 solver.cpp:228] Iteration 52280, loss = 0.202313
I0905 11:02:41.972590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202314 (* 1 = 0.202314 loss)
I0905 11:02:41.972605 90901 sgd_solver.cpp:106] Iteration 52280, lr = 0.01
I0905 11:02:47.818173 90901 solver.cpp:228] Iteration 52290, loss = 0.219165
I0905 11:02:47.818246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219167 (* 1 = 0.219167 loss)
I0905 11:02:47.818264 90901 sgd_solver.cpp:106] Iteration 52290, lr = 0.01
I0905 11:02:53.378700 90901 solver.cpp:228] Iteration 52300, loss = 0.0603787
I0905 11:02:53.378767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0603801 (* 1 = 0.0603801 loss)
I0905 11:02:53.378780 90901 sgd_solver.cpp:106] Iteration 52300, lr = 0.01
I0905 11:02:58.956558 90901 solver.cpp:228] Iteration 52310, loss = 0.195217
I0905 11:02:58.956632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195218 (* 1 = 0.195218 loss)
I0905 11:02:58.956647 90901 sgd_solver.cpp:106] Iteration 52310, lr = 0.01
I0905 11:03:05.050377 90901 solver.cpp:228] Iteration 52320, loss = 0.358891
I0905 11:03:05.052145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358892 (* 1 = 0.358892 loss)
I0905 11:03:05.052161 90901 sgd_solver.cpp:106] Iteration 52320, lr = 0.01
I0905 11:03:11.128193 90901 solver.cpp:228] Iteration 52330, loss = 0.205586
I0905 11:03:11.128253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205588 (* 1 = 0.205588 loss)
I0905 11:03:11.128268 90901 sgd_solver.cpp:106] Iteration 52330, lr = 0.01
I0905 11:03:17.575228 90901 solver.cpp:228] Iteration 52340, loss = 0.298401
I0905 11:03:17.575287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298403 (* 1 = 0.298403 loss)
I0905 11:03:17.575304 90901 sgd_solver.cpp:106] Iteration 52340, lr = 0.01
I0905 11:03:23.640611 90901 solver.cpp:228] Iteration 52350, loss = 0.280261
I0905 11:03:23.640667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280262 (* 1 = 0.280262 loss)
I0905 11:03:23.640681 90901 sgd_solver.cpp:106] Iteration 52350, lr = 0.01
I0905 11:03:29.707054 90901 solver.cpp:228] Iteration 52360, loss = 0.0939968
I0905 11:03:29.707108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.093998 (* 1 = 0.093998 loss)
I0905 11:03:29.707123 90901 sgd_solver.cpp:106] Iteration 52360, lr = 0.01
I0905 11:03:35.789474 90901 solver.cpp:228] Iteration 52370, loss = 0.455418
I0905 11:03:35.789665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455419 (* 1 = 0.455419 loss)
I0905 11:03:35.789681 90901 sgd_solver.cpp:106] Iteration 52370, lr = 0.01
I0905 11:03:41.858590 90901 solver.cpp:228] Iteration 52380, loss = 0.295692
I0905 11:03:41.858693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295693 (* 1 = 0.295693 loss)
I0905 11:03:41.858711 90901 sgd_solver.cpp:106] Iteration 52380, lr = 0.01
I0905 11:03:47.870414 90901 solver.cpp:228] Iteration 52390, loss = 0.0652947
I0905 11:03:47.870482 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0652959 (* 1 = 0.0652959 loss)
I0905 11:03:47.870497 90901 sgd_solver.cpp:106] Iteration 52390, lr = 0.01
I0905 11:03:54.059139 90901 solver.cpp:228] Iteration 52400, loss = 0.0815665
I0905 11:03:54.059209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0815678 (* 1 = 0.0815678 loss)
I0905 11:03:54.059224 90901 sgd_solver.cpp:106] Iteration 52400, lr = 0.01
I0905 11:04:00.167017 90901 solver.cpp:228] Iteration 52410, loss = 0.24677
I0905 11:04:00.167098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246771 (* 1 = 0.246771 loss)
I0905 11:04:00.167115 90901 sgd_solver.cpp:106] Iteration 52410, lr = 0.01
I0905 11:04:06.191810 90901 solver.cpp:228] Iteration 52420, loss = 0.281878
I0905 11:04:06.191943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281879 (* 1 = 0.281879 loss)
I0905 11:04:06.191970 90901 sgd_solver.cpp:106] Iteration 52420, lr = 0.01
I0905 11:04:12.573854 90901 solver.cpp:228] Iteration 52430, loss = 0.185545
I0905 11:04:12.573921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185547 (* 1 = 0.185547 loss)
I0905 11:04:12.573936 90901 sgd_solver.cpp:106] Iteration 52430, lr = 0.01
I0905 11:04:18.617733 90901 solver.cpp:228] Iteration 52440, loss = 0.255247
I0905 11:04:18.617815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255248 (* 1 = 0.255248 loss)
I0905 11:04:18.617830 90901 sgd_solver.cpp:106] Iteration 52440, lr = 0.01
I0905 11:04:25.029815 90901 solver.cpp:228] Iteration 52450, loss = 0.117311
I0905 11:04:25.029881 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117312 (* 1 = 0.117312 loss)
I0905 11:04:25.029898 90901 sgd_solver.cpp:106] Iteration 52450, lr = 0.01
I0905 11:04:31.099773 90901 solver.cpp:228] Iteration 52460, loss = 0.30644
I0905 11:04:31.099853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306442 (* 1 = 0.306442 loss)
I0905 11:04:31.099869 90901 sgd_solver.cpp:106] Iteration 52460, lr = 0.01
I0905 11:04:36.809695 90901 solver.cpp:228] Iteration 52470, loss = 0.0553708
I0905 11:04:36.809864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0553721 (* 1 = 0.0553721 loss)
I0905 11:04:36.809893 90901 sgd_solver.cpp:106] Iteration 52470, lr = 0.01
I0905 11:04:42.088965 90901 solver.cpp:228] Iteration 52480, loss = 0.105727
I0905 11:04:42.089021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105728 (* 1 = 0.105728 loss)
I0905 11:04:42.089035 90901 sgd_solver.cpp:106] Iteration 52480, lr = 0.01
I0905 11:04:48.145323 90901 solver.cpp:228] Iteration 52490, loss = 0.0671881
I0905 11:04:48.145390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0671894 (* 1 = 0.0671894 loss)
I0905 11:04:48.145409 90901 sgd_solver.cpp:106] Iteration 52490, lr = 0.01
I0905 11:04:54.225476 90901 solver.cpp:228] Iteration 52500, loss = 0.325276
I0905 11:04:54.225546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325278 (* 1 = 0.325278 loss)
I0905 11:04:54.225561 90901 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I0905 11:05:00.658202 90901 solver.cpp:228] Iteration 52510, loss = 0.455992
I0905 11:05:00.658262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455993 (* 1 = 0.455993 loss)
I0905 11:05:00.658277 90901 sgd_solver.cpp:106] Iteration 52510, lr = 0.01
I0905 11:05:06.574059 90901 solver.cpp:228] Iteration 52520, loss = 0.0881724
I0905 11:05:06.574117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0881736 (* 1 = 0.0881736 loss)
I0905 11:05:06.574132 90901 sgd_solver.cpp:106] Iteration 52520, lr = 0.01
I0905 11:05:12.790532 90901 solver.cpp:228] Iteration 52530, loss = 0.361518
I0905 11:05:12.790799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361519 (* 1 = 0.361519 loss)
I0905 11:05:12.790817 90901 sgd_solver.cpp:106] Iteration 52530, lr = 0.01
I0905 11:05:18.871852 90901 solver.cpp:228] Iteration 52540, loss = 0.244834
I0905 11:05:18.871927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244835 (* 1 = 0.244835 loss)
I0905 11:05:18.871942 90901 sgd_solver.cpp:106] Iteration 52540, lr = 0.01
I0905 11:05:24.968971 90901 solver.cpp:228] Iteration 52550, loss = 0.090438
I0905 11:05:24.969039 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0904393 (* 1 = 0.0904393 loss)
I0905 11:05:24.969055 90901 sgd_solver.cpp:106] Iteration 52550, lr = 0.01
I0905 11:05:31.012030 90901 solver.cpp:228] Iteration 52560, loss = 0.320892
I0905 11:05:31.012063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320893 (* 1 = 0.320893 loss)
I0905 11:05:31.012078 90901 sgd_solver.cpp:106] Iteration 52560, lr = 0.01
I0905 11:05:37.419646 90901 solver.cpp:228] Iteration 52570, loss = 0.26856
I0905 11:05:37.419710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268561 (* 1 = 0.268561 loss)
I0905 11:05:37.419724 90901 sgd_solver.cpp:106] Iteration 52570, lr = 0.01
I0905 11:05:43.254117 90901 solver.cpp:228] Iteration 52580, loss = 0.16704
I0905 11:05:43.254319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167041 (* 1 = 0.167041 loss)
I0905 11:05:43.254348 90901 sgd_solver.cpp:106] Iteration 52580, lr = 0.01
I0905 11:05:49.623169 90901 solver.cpp:228] Iteration 52590, loss = 0.135885
I0905 11:05:49.623246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135886 (* 1 = 0.135886 loss)
I0905 11:05:49.623261 90901 sgd_solver.cpp:106] Iteration 52590, lr = 0.01
I0905 11:05:55.733160 90901 solver.cpp:228] Iteration 52600, loss = 0.0734132
I0905 11:05:55.733227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0734145 (* 1 = 0.0734145 loss)
I0905 11:05:55.733242 90901 sgd_solver.cpp:106] Iteration 52600, lr = 0.01
I0905 11:06:01.512092 90901 solver.cpp:228] Iteration 52610, loss = 0.0494293
I0905 11:06:01.512171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0494307 (* 1 = 0.0494307 loss)
I0905 11:06:01.512187 90901 sgd_solver.cpp:106] Iteration 52610, lr = 0.01
I0905 11:06:07.930210 90901 solver.cpp:228] Iteration 52620, loss = 0.155539
I0905 11:06:07.930275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155541 (* 1 = 0.155541 loss)
I0905 11:06:07.930294 90901 sgd_solver.cpp:106] Iteration 52620, lr = 0.01
I0905 11:06:13.994951 90901 solver.cpp:228] Iteration 52630, loss = 0.300759
I0905 11:06:13.995177 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30076 (* 1 = 0.30076 loss)
I0905 11:06:13.995193 90901 sgd_solver.cpp:106] Iteration 52630, lr = 0.01
I0905 11:06:19.949412 90901 solver.cpp:228] Iteration 52640, loss = 0.113868
I0905 11:06:19.949465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113869 (* 1 = 0.113869 loss)
I0905 11:06:19.949478 90901 sgd_solver.cpp:106] Iteration 52640, lr = 0.01
I0905 11:06:25.203856 90901 solver.cpp:228] Iteration 52650, loss = 0.113747
I0905 11:06:25.203907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113748 (* 1 = 0.113748 loss)
I0905 11:06:25.203919 90901 sgd_solver.cpp:106] Iteration 52650, lr = 0.01
I0905 11:06:30.712477 90901 solver.cpp:228] Iteration 52660, loss = 0.23249
I0905 11:06:30.712535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232491 (* 1 = 0.232491 loss)
I0905 11:06:30.712550 90901 sgd_solver.cpp:106] Iteration 52660, lr = 0.01
I0905 11:06:37.087180 90901 solver.cpp:228] Iteration 52670, loss = 0.475861
I0905 11:06:37.087236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.475863 (* 1 = 0.475863 loss)
I0905 11:06:37.087250 90901 sgd_solver.cpp:106] Iteration 52670, lr = 0.01
I0905 11:06:43.151446 90901 solver.cpp:228] Iteration 52680, loss = 0.0701573
I0905 11:06:43.151504 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0701588 (* 1 = 0.0701588 loss)
I0905 11:06:43.151518 90901 sgd_solver.cpp:106] Iteration 52680, lr = 0.01
I0905 11:06:49.220765 90901 solver.cpp:228] Iteration 52690, loss = 0.130322
I0905 11:06:49.220968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130324 (* 1 = 0.130324 loss)
I0905 11:06:49.220983 90901 sgd_solver.cpp:106] Iteration 52690, lr = 0.01
I0905 11:06:55.319927 90901 solver.cpp:228] Iteration 52700, loss = 0.161774
I0905 11:06:55.319977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161775 (* 1 = 0.161775 loss)
I0905 11:06:55.319994 90901 sgd_solver.cpp:106] Iteration 52700, lr = 0.01
I0905 11:07:01.381279 90901 solver.cpp:228] Iteration 52710, loss = 0.358779
I0905 11:07:01.381350 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358781 (* 1 = 0.358781 loss)
I0905 11:07:01.381366 90901 sgd_solver.cpp:106] Iteration 52710, lr = 0.01
I0905 11:07:07.784654 90901 solver.cpp:228] Iteration 52720, loss = 0.19334
I0905 11:07:07.784725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193342 (* 1 = 0.193342 loss)
I0905 11:07:07.784741 90901 sgd_solver.cpp:106] Iteration 52720, lr = 0.01
I0905 11:07:13.863428 90901 solver.cpp:228] Iteration 52730, loss = 0.163782
I0905 11:07:13.863500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163783 (* 1 = 0.163783 loss)
I0905 11:07:13.863515 90901 sgd_solver.cpp:106] Iteration 52730, lr = 0.01
I0905 11:07:19.946295 90901 solver.cpp:228] Iteration 52740, loss = 0.0735359
I0905 11:07:19.946544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0735373 (* 1 = 0.0735373 loss)
I0905 11:07:19.946563 90901 sgd_solver.cpp:106] Iteration 52740, lr = 0.01
I0905 11:07:26.038362 90901 solver.cpp:228] Iteration 52750, loss = 0.0871753
I0905 11:07:26.038441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0871768 (* 1 = 0.0871768 loss)
I0905 11:07:26.038456 90901 sgd_solver.cpp:106] Iteration 52750, lr = 0.01
I0905 11:07:32.308815 90901 solver.cpp:228] Iteration 52760, loss = 0.24697
I0905 11:07:32.308899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246971 (* 1 = 0.246971 loss)
I0905 11:07:32.308917 90901 sgd_solver.cpp:106] Iteration 52760, lr = 0.01
I0905 11:07:37.525162 90901 solver.cpp:228] Iteration 52770, loss = 0.271102
I0905 11:07:37.525228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271104 (* 1 = 0.271104 loss)
I0905 11:07:37.525244 90901 sgd_solver.cpp:106] Iteration 52770, lr = 0.01
I0905 11:07:42.544562 90901 solver.cpp:228] Iteration 52780, loss = 0.0820035
I0905 11:07:42.544601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0820049 (* 1 = 0.0820049 loss)
I0905 11:07:42.544616 90901 sgd_solver.cpp:106] Iteration 52780, lr = 0.01
I0905 11:07:47.596766 90901 solver.cpp:228] Iteration 52790, loss = 0.277616
I0905 11:07:47.596825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277617 (* 1 = 0.277617 loss)
I0905 11:07:47.596839 90901 sgd_solver.cpp:106] Iteration 52790, lr = 0.01
I0905 11:07:52.440989 90901 solver.cpp:337] Iteration 52800, Testing net (#0)
I0905 11:08:26.461558 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.80375
I0905 11:08:26.461752 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.461954 (* 1 = 0.461954 loss)
I0905 11:08:26.678071 90901 solver.cpp:228] Iteration 52800, loss = 0.117013
I0905 11:08:26.678130 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117015 (* 1 = 0.117015 loss)
I0905 11:08:26.678158 90901 sgd_solver.cpp:106] Iteration 52800, lr = 0.01
I0905 11:08:31.710095 90901 solver.cpp:228] Iteration 52810, loss = 0.0991862
I0905 11:08:31.710162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0991877 (* 1 = 0.0991877 loss)
I0905 11:08:31.710180 90901 sgd_solver.cpp:106] Iteration 52810, lr = 0.01
I0905 11:08:36.779876 90901 solver.cpp:228] Iteration 52820, loss = 0.271154
I0905 11:08:36.779930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271155 (* 1 = 0.271155 loss)
I0905 11:08:36.779945 90901 sgd_solver.cpp:106] Iteration 52820, lr = 0.01
I0905 11:08:41.828052 90901 solver.cpp:228] Iteration 52830, loss = 0.15169
I0905 11:08:41.828114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151692 (* 1 = 0.151692 loss)
I0905 11:08:41.828132 90901 sgd_solver.cpp:106] Iteration 52830, lr = 0.01
I0905 11:08:46.879412 90901 solver.cpp:228] Iteration 52840, loss = 0.208872
I0905 11:08:46.879474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208873 (* 1 = 0.208873 loss)
I0905 11:08:46.879488 90901 sgd_solver.cpp:106] Iteration 52840, lr = 0.01
I0905 11:08:51.934561 90901 solver.cpp:228] Iteration 52850, loss = 0.193364
I0905 11:08:51.934619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193365 (* 1 = 0.193365 loss)
I0905 11:08:51.934658 90901 sgd_solver.cpp:106] Iteration 52850, lr = 0.01
I0905 11:08:57.313565 90901 solver.cpp:228] Iteration 52860, loss = 0.149667
I0905 11:08:57.313751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149669 (* 1 = 0.149669 loss)
I0905 11:08:57.313782 90901 sgd_solver.cpp:106] Iteration 52860, lr = 0.01
I0905 11:09:03.054822 90901 solver.cpp:228] Iteration 52870, loss = 0.221293
I0905 11:09:03.054889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221294 (* 1 = 0.221294 loss)
I0905 11:09:03.054904 90901 sgd_solver.cpp:106] Iteration 52870, lr = 0.01
I0905 11:09:09.101982 90901 solver.cpp:228] Iteration 52880, loss = 0.218345
I0905 11:09:09.102051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218346 (* 1 = 0.218346 loss)
I0905 11:09:09.102067 90901 sgd_solver.cpp:106] Iteration 52880, lr = 0.01
I0905 11:09:15.498029 90901 solver.cpp:228] Iteration 52890, loss = 0.304071
I0905 11:09:15.498067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304072 (* 1 = 0.304072 loss)
I0905 11:09:15.498080 90901 sgd_solver.cpp:106] Iteration 52890, lr = 0.01
I0905 11:09:21.575659 90901 solver.cpp:228] Iteration 52900, loss = 0.15512
I0905 11:09:21.575722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155121 (* 1 = 0.155121 loss)
I0905 11:09:21.575739 90901 sgd_solver.cpp:106] Iteration 52900, lr = 0.01
I0905 11:09:27.676684 90901 solver.cpp:228] Iteration 52910, loss = 0.121159
I0905 11:09:27.676826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12116 (* 1 = 0.12116 loss)
I0905 11:09:27.676854 90901 sgd_solver.cpp:106] Iteration 52910, lr = 0.01
I0905 11:09:33.805838 90901 solver.cpp:228] Iteration 52920, loss = 0.0704528
I0905 11:09:33.805910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0704542 (* 1 = 0.0704542 loss)
I0905 11:09:33.805925 90901 sgd_solver.cpp:106] Iteration 52920, lr = 0.01
I0905 11:09:39.902861 90901 solver.cpp:228] Iteration 52930, loss = 0.288838
I0905 11:09:39.902935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288839 (* 1 = 0.288839 loss)
I0905 11:09:39.902958 90901 sgd_solver.cpp:106] Iteration 52930, lr = 0.01
I0905 11:09:46.293860 90901 solver.cpp:228] Iteration 52940, loss = 0.171423
I0905 11:09:46.293912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171425 (* 1 = 0.171425 loss)
I0905 11:09:46.293927 90901 sgd_solver.cpp:106] Iteration 52940, lr = 0.01
I0905 11:09:52.125854 90901 solver.cpp:228] Iteration 52950, loss = 0.286117
I0905 11:09:52.125915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286118 (* 1 = 0.286118 loss)
I0905 11:09:52.125931 90901 sgd_solver.cpp:106] Iteration 52950, lr = 0.01
I0905 11:09:58.317281 90901 solver.cpp:228] Iteration 52960, loss = 0.327139
I0905 11:09:58.317488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32714 (* 1 = 0.32714 loss)
I0905 11:09:58.317528 90901 sgd_solver.cpp:106] Iteration 52960, lr = 0.01
I0905 11:10:03.579852 90901 solver.cpp:228] Iteration 52970, loss = 0.350372
I0905 11:10:03.579900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350374 (* 1 = 0.350374 loss)
I0905 11:10:03.579915 90901 sgd_solver.cpp:106] Iteration 52970, lr = 0.01
I0905 11:10:09.058997 90901 solver.cpp:228] Iteration 52980, loss = 0.234745
I0905 11:10:09.059062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234747 (* 1 = 0.234747 loss)
I0905 11:10:09.059077 90901 sgd_solver.cpp:106] Iteration 52980, lr = 0.01
I0905 11:10:15.166187 90901 solver.cpp:228] Iteration 52990, loss = 0.185239
I0905 11:10:15.166254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185241 (* 1 = 0.185241 loss)
I0905 11:10:15.166268 90901 sgd_solver.cpp:106] Iteration 52990, lr = 0.01
I0905 11:10:21.586994 90901 solver.cpp:228] Iteration 53000, loss = 0.190596
I0905 11:10:21.587046 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190597 (* 1 = 0.190597 loss)
I0905 11:10:21.587060 90901 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I0905 11:10:27.622382 90901 solver.cpp:228] Iteration 53010, loss = 0.158681
I0905 11:10:27.622434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158682 (* 1 = 0.158682 loss)
I0905 11:10:27.622448 90901 sgd_solver.cpp:106] Iteration 53010, lr = 0.01
I0905 11:10:33.730029 90901 solver.cpp:228] Iteration 53020, loss = 0.265184
I0905 11:10:33.730182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265185 (* 1 = 0.265185 loss)
I0905 11:10:33.730211 90901 sgd_solver.cpp:106] Iteration 53020, lr = 0.01
I0905 11:10:39.802009 90901 solver.cpp:228] Iteration 53030, loss = 0.216115
I0905 11:10:39.802062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216116 (* 1 = 0.216116 loss)
I0905 11:10:39.802076 90901 sgd_solver.cpp:106] Iteration 53030, lr = 0.01
I0905 11:10:45.898102 90901 solver.cpp:228] Iteration 53040, loss = 0.115106
I0905 11:10:45.898165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115107 (* 1 = 0.115107 loss)
I0905 11:10:45.898178 90901 sgd_solver.cpp:106] Iteration 53040, lr = 0.01
I0905 11:10:52.090351 90901 solver.cpp:228] Iteration 53050, loss = 0.22793
I0905 11:10:52.090414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227932 (* 1 = 0.227932 loss)
I0905 11:10:52.090430 90901 sgd_solver.cpp:106] Iteration 53050, lr = 0.01
I0905 11:10:58.360849 90901 solver.cpp:228] Iteration 53060, loss = 0.108427
I0905 11:10:58.360911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108429 (* 1 = 0.108429 loss)
I0905 11:10:58.360926 90901 sgd_solver.cpp:106] Iteration 53060, lr = 0.01
I0905 11:11:04.419018 90901 solver.cpp:228] Iteration 53070, loss = 0.0968637
I0905 11:11:04.419224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.096865 (* 1 = 0.096865 loss)
I0905 11:11:04.419240 90901 sgd_solver.cpp:106] Iteration 53070, lr = 0.01
I0905 11:11:10.485132 90901 solver.cpp:228] Iteration 53080, loss = 0.211404
I0905 11:11:10.485198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211406 (* 1 = 0.211406 loss)
I0905 11:11:10.485213 90901 sgd_solver.cpp:106] Iteration 53080, lr = 0.01
I0905 11:11:16.575002 90901 solver.cpp:228] Iteration 53090, loss = 0.366863
I0905 11:11:16.575070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366864 (* 1 = 0.366864 loss)
I0905 11:11:16.575084 90901 sgd_solver.cpp:106] Iteration 53090, lr = 0.01
I0905 11:11:22.963286 90901 solver.cpp:228] Iteration 53100, loss = 0.406509
I0905 11:11:22.963348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40651 (* 1 = 0.40651 loss)
I0905 11:11:22.963363 90901 sgd_solver.cpp:106] Iteration 53100, lr = 0.01
I0905 11:11:28.967597 90901 solver.cpp:228] Iteration 53110, loss = 0.520362
I0905 11:11:28.967658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520363 (* 1 = 0.520363 loss)
I0905 11:11:28.967672 90901 sgd_solver.cpp:106] Iteration 53110, lr = 0.01
I0905 11:11:35.111969 90901 solver.cpp:228] Iteration 53120, loss = 0.114968
I0905 11:11:35.112196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11497 (* 1 = 0.11497 loss)
I0905 11:11:35.112212 90901 sgd_solver.cpp:106] Iteration 53120, lr = 0.01
I0905 11:11:41.222039 90901 solver.cpp:228] Iteration 53130, loss = 0.160077
I0905 11:11:41.222086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160078 (* 1 = 0.160078 loss)
I0905 11:11:41.222098 90901 sgd_solver.cpp:106] Iteration 53130, lr = 0.01
I0905 11:11:46.919303 90901 solver.cpp:228] Iteration 53140, loss = 0.286217
I0905 11:11:46.919374 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286219 (* 1 = 0.286219 loss)
I0905 11:11:46.919390 90901 sgd_solver.cpp:106] Iteration 53140, lr = 0.01
I0905 11:11:52.182240 90901 solver.cpp:228] Iteration 53150, loss = 0.0808513
I0905 11:11:52.182284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0808526 (* 1 = 0.0808526 loss)
I0905 11:11:52.182297 90901 sgd_solver.cpp:106] Iteration 53150, lr = 0.01
I0905 11:11:58.545457 90901 solver.cpp:228] Iteration 53160, loss = 0.345703
I0905 11:11:58.545519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345704 (* 1 = 0.345704 loss)
I0905 11:11:58.545536 90901 sgd_solver.cpp:106] Iteration 53160, lr = 0.01
I0905 11:12:04.261569 90901 solver.cpp:228] Iteration 53170, loss = 0.161948
I0905 11:12:04.261628 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161949 (* 1 = 0.161949 loss)
I0905 11:12:04.261642 90901 sgd_solver.cpp:106] Iteration 53170, lr = 0.01
I0905 11:12:10.656628 90901 solver.cpp:228] Iteration 53180, loss = 0.0764697
I0905 11:12:10.656817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.076471 (* 1 = 0.076471 loss)
I0905 11:12:10.656846 90901 sgd_solver.cpp:106] Iteration 53180, lr = 0.01
I0905 11:12:16.736016 90901 solver.cpp:228] Iteration 53190, loss = 0.125371
I0905 11:12:16.736093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125373 (* 1 = 0.125373 loss)
I0905 11:12:16.736109 90901 sgd_solver.cpp:106] Iteration 53190, lr = 0.01
I0905 11:12:22.814136 90901 solver.cpp:228] Iteration 53200, loss = 0.0512889
I0905 11:12:22.814201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0512902 (* 1 = 0.0512902 loss)
I0905 11:12:22.814224 90901 sgd_solver.cpp:106] Iteration 53200, lr = 0.01
I0905 11:12:28.899860 90901 solver.cpp:228] Iteration 53210, loss = 0.157605
I0905 11:12:28.899933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157607 (* 1 = 0.157607 loss)
I0905 11:12:28.899948 90901 sgd_solver.cpp:106] Iteration 53210, lr = 0.01
I0905 11:12:35.155735 90901 solver.cpp:228] Iteration 53220, loss = 0.0996023
I0905 11:12:35.155807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0996036 (* 1 = 0.0996036 loss)
I0905 11:12:35.155820 90901 sgd_solver.cpp:106] Iteration 53220, lr = 0.01
I0905 11:12:41.362814 90901 solver.cpp:228] Iteration 53230, loss = 0.0612611
I0905 11:12:41.363035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0612625 (* 1 = 0.0612625 loss)
I0905 11:12:41.363067 90901 sgd_solver.cpp:106] Iteration 53230, lr = 0.01
I0905 11:12:47.422865 90901 solver.cpp:228] Iteration 53240, loss = 0.194402
I0905 11:12:47.422937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194403 (* 1 = 0.194403 loss)
I0905 11:12:47.422953 90901 sgd_solver.cpp:106] Iteration 53240, lr = 0.01
I0905 11:12:53.825631 90901 solver.cpp:228] Iteration 53250, loss = 0.244281
I0905 11:12:53.825706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244282 (* 1 = 0.244282 loss)
I0905 11:12:53.825719 90901 sgd_solver.cpp:106] Iteration 53250, lr = 0.01
I0905 11:12:59.889600 90901 solver.cpp:228] Iteration 53260, loss = 0.193814
I0905 11:12:59.889674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193815 (* 1 = 0.193815 loss)
I0905 11:12:59.889691 90901 sgd_solver.cpp:106] Iteration 53260, lr = 0.01
I0905 11:13:05.579623 90901 solver.cpp:228] Iteration 53270, loss = 0.128714
I0905 11:13:05.579697 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128715 (* 1 = 0.128715 loss)
I0905 11:13:05.579712 90901 sgd_solver.cpp:106] Iteration 53270, lr = 0.01
I0905 11:13:11.764814 90901 solver.cpp:228] Iteration 53280, loss = 0.0372519
I0905 11:13:11.765066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0372532 (* 1 = 0.0372532 loss)
I0905 11:13:11.765085 90901 sgd_solver.cpp:106] Iteration 53280, lr = 0.01
I0905 11:13:18.158663 90901 solver.cpp:228] Iteration 53290, loss = 0.167765
I0905 11:13:18.158726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167767 (* 1 = 0.167767 loss)
I0905 11:13:18.158742 90901 sgd_solver.cpp:106] Iteration 53290, lr = 0.01
I0905 11:13:24.196326 90901 solver.cpp:228] Iteration 53300, loss = 0.0841545
I0905 11:13:24.196403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0841559 (* 1 = 0.0841559 loss)
I0905 11:13:24.196418 90901 sgd_solver.cpp:106] Iteration 53300, lr = 0.01
I0905 11:13:30.614420 90901 solver.cpp:228] Iteration 53310, loss = 0.0305239
I0905 11:13:30.614501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0305251 (* 1 = 0.0305251 loss)
I0905 11:13:30.614518 90901 sgd_solver.cpp:106] Iteration 53310, lr = 0.01
I0905 11:13:35.897665 90901 solver.cpp:228] Iteration 53320, loss = 0.193114
I0905 11:13:35.897713 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193115 (* 1 = 0.193115 loss)
I0905 11:13:35.897727 90901 sgd_solver.cpp:106] Iteration 53320, lr = 0.01
I0905 11:13:41.507377 90901 solver.cpp:228] Iteration 53330, loss = 0.33865
I0905 11:13:41.507423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338652 (* 1 = 0.338652 loss)
I0905 11:13:41.507437 90901 sgd_solver.cpp:106] Iteration 53330, lr = 0.01
I0905 11:13:47.561906 90901 solver.cpp:228] Iteration 53340, loss = 0.391053
I0905 11:13:47.562075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391054 (* 1 = 0.391054 loss)
I0905 11:13:47.562119 90901 sgd_solver.cpp:106] Iteration 53340, lr = 0.01
I0905 11:13:53.396569 90901 solver.cpp:228] Iteration 53350, loss = 0.0611377
I0905 11:13:53.396620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.061139 (* 1 = 0.061139 loss)
I0905 11:13:53.396634 90901 sgd_solver.cpp:106] Iteration 53350, lr = 0.01
I0905 11:13:59.584127 90901 solver.cpp:228] Iteration 53360, loss = 0.464625
I0905 11:13:59.584202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464626 (* 1 = 0.464626 loss)
I0905 11:13:59.584218 90901 sgd_solver.cpp:106] Iteration 53360, lr = 0.01
I0905 11:14:05.783627 90901 solver.cpp:228] Iteration 53370, loss = 0.493301
I0905 11:14:05.783699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.493303 (* 1 = 0.493303 loss)
I0905 11:14:05.783716 90901 sgd_solver.cpp:106] Iteration 53370, lr = 0.01
I0905 11:14:11.835853 90901 solver.cpp:228] Iteration 53380, loss = 0.286036
I0905 11:14:11.835916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286038 (* 1 = 0.286038 loss)
I0905 11:14:11.835932 90901 sgd_solver.cpp:106] Iteration 53380, lr = 0.01
I0905 11:14:17.922857 90901 solver.cpp:228] Iteration 53390, loss = 0.199643
I0905 11:14:17.923027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199645 (* 1 = 0.199645 loss)
I0905 11:14:17.923046 90901 sgd_solver.cpp:106] Iteration 53390, lr = 0.01
I0905 11:14:23.990438 90901 solver.cpp:228] Iteration 53400, loss = 0.049247
I0905 11:14:23.990509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0492484 (* 1 = 0.0492484 loss)
I0905 11:14:23.990525 90901 sgd_solver.cpp:106] Iteration 53400, lr = 0.01
I0905 11:14:30.166623 90901 solver.cpp:228] Iteration 53410, loss = 0.0706894
I0905 11:14:30.166709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0706908 (* 1 = 0.0706908 loss)
I0905 11:14:30.166723 90901 sgd_solver.cpp:106] Iteration 53410, lr = 0.01
I0905 11:14:36.336067 90901 solver.cpp:228] Iteration 53420, loss = 0.559423
I0905 11:14:36.336129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.559425 (* 1 = 0.559425 loss)
I0905 11:14:36.336144 90901 sgd_solver.cpp:106] Iteration 53420, lr = 0.01
I0905 11:14:42.500236 90901 solver.cpp:228] Iteration 53430, loss = 0.0719524
I0905 11:14:42.500298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0719538 (* 1 = 0.0719538 loss)
I0905 11:14:42.500313 90901 sgd_solver.cpp:106] Iteration 53430, lr = 0.01
I0905 11:14:48.586230 90901 solver.cpp:228] Iteration 53440, loss = 0.14114
I0905 11:14:48.586508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141141 (* 1 = 0.141141 loss)
I0905 11:14:48.586525 90901 sgd_solver.cpp:106] Iteration 53440, lr = 0.01
I0905 11:14:54.873795 90901 solver.cpp:228] Iteration 53450, loss = 0.253187
I0905 11:14:54.873852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253188 (* 1 = 0.253188 loss)
I0905 11:14:54.873865 90901 sgd_solver.cpp:106] Iteration 53450, lr = 0.01
I0905 11:15:01.011852 90901 solver.cpp:228] Iteration 53460, loss = 0.0740263
I0905 11:15:01.011890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0740277 (* 1 = 0.0740277 loss)
I0905 11:15:01.011903 90901 sgd_solver.cpp:106] Iteration 53460, lr = 0.01
I0905 11:15:07.066085 90901 solver.cpp:228] Iteration 53470, loss = 0.0379526
I0905 11:15:07.066143 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.037954 (* 1 = 0.037954 loss)
I0905 11:15:07.066156 90901 sgd_solver.cpp:106] Iteration 53470, lr = 0.01
I0905 11:15:13.109715 90901 solver.cpp:228] Iteration 53480, loss = 0.0459817
I0905 11:15:13.109771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0459831 (* 1 = 0.0459831 loss)
I0905 11:15:13.109786 90901 sgd_solver.cpp:106] Iteration 53480, lr = 0.01
I0905 11:15:19.458039 90901 solver.cpp:228] Iteration 53490, loss = 0.100092
I0905 11:15:19.458278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100094 (* 1 = 0.100094 loss)
I0905 11:15:19.458294 90901 sgd_solver.cpp:106] Iteration 53490, lr = 0.01
I0905 11:15:25.130440 90901 solver.cpp:228] Iteration 53500, loss = 0.0290392
I0905 11:15:25.130511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0290406 (* 1 = 0.0290406 loss)
I0905 11:15:25.130527 90901 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I0905 11:15:30.700799 90901 solver.cpp:228] Iteration 53510, loss = 0.449877
I0905 11:15:30.700873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449879 (* 1 = 0.449879 loss)
I0905 11:15:30.700889 90901 sgd_solver.cpp:106] Iteration 53510, lr = 0.01
I0905 11:15:36.386950 90901 solver.cpp:228] Iteration 53520, loss = 0.148971
I0905 11:15:36.387033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148973 (* 1 = 0.148973 loss)
I0905 11:15:36.387049 90901 sgd_solver.cpp:106] Iteration 53520, lr = 0.01
I0905 11:15:42.484360 90901 solver.cpp:228] Iteration 53530, loss = 0.428287
I0905 11:15:42.484421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428288 (* 1 = 0.428288 loss)
I0905 11:15:42.484437 90901 sgd_solver.cpp:106] Iteration 53530, lr = 0.01
I0905 11:15:48.584756 90901 solver.cpp:228] Iteration 53540, loss = 0.511165
I0905 11:15:48.584810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.511166 (* 1 = 0.511166 loss)
I0905 11:15:48.584823 90901 sgd_solver.cpp:106] Iteration 53540, lr = 0.01
I0905 11:15:54.373664 90901 solver.cpp:228] Iteration 53550, loss = 0.26666
I0905 11:15:54.373926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266662 (* 1 = 0.266662 loss)
I0905 11:15:54.373944 90901 sgd_solver.cpp:106] Iteration 53550, lr = 0.01
I0905 11:16:00.512971 90901 solver.cpp:228] Iteration 53560, loss = 0.335737
I0905 11:16:00.513026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335739 (* 1 = 0.335739 loss)
I0905 11:16:00.513041 90901 sgd_solver.cpp:106] Iteration 53560, lr = 0.01
I0905 11:16:06.917389 90901 solver.cpp:228] Iteration 53570, loss = 0.332367
I0905 11:16:06.917448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332369 (* 1 = 0.332369 loss)
I0905 11:16:06.917460 90901 sgd_solver.cpp:106] Iteration 53570, lr = 0.01
I0905 11:16:12.972616 90901 solver.cpp:228] Iteration 53580, loss = 0.211898
I0905 11:16:12.972671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2119 (* 1 = 0.2119 loss)
I0905 11:16:12.972686 90901 sgd_solver.cpp:106] Iteration 53580, lr = 0.01
I0905 11:16:19.072271 90901 solver.cpp:228] Iteration 53590, loss = 0.590892
I0905 11:16:19.072335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.590894 (* 1 = 0.590894 loss)
I0905 11:16:19.072350 90901 sgd_solver.cpp:106] Iteration 53590, lr = 0.01
I0905 11:16:24.899543 90901 solver.cpp:337] Iteration 53600, Testing net (#0)
I0905 11:17:07.171784 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.78625
I0905 11:17:07.171928 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.523367 (* 1 = 0.523367 loss)
I0905 11:17:07.372424 90901 solver.cpp:228] Iteration 53600, loss = 0.0654093
I0905 11:17:07.372457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0654108 (* 1 = 0.0654108 loss)
I0905 11:17:07.372473 90901 sgd_solver.cpp:106] Iteration 53600, lr = 0.01
I0905 11:17:12.626518 90901 solver.cpp:228] Iteration 53610, loss = 0.205615
I0905 11:17:12.626586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205616 (* 1 = 0.205616 loss)
I0905 11:17:12.626600 90901 sgd_solver.cpp:106] Iteration 53610, lr = 0.01
I0905 11:17:18.257884 90901 solver.cpp:228] Iteration 53620, loss = 0.181367
I0905 11:17:18.257936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181369 (* 1 = 0.181369 loss)
I0905 11:17:18.257956 90901 sgd_solver.cpp:106] Iteration 53620, lr = 0.01
I0905 11:17:24.374572 90901 solver.cpp:228] Iteration 53630, loss = 0.184331
I0905 11:17:24.374622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184332 (* 1 = 0.184332 loss)
I0905 11:17:24.374660 90901 sgd_solver.cpp:106] Iteration 53630, lr = 0.01
I0905 11:17:30.477399 90901 solver.cpp:228] Iteration 53640, loss = 0.182206
I0905 11:17:30.477438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182207 (* 1 = 0.182207 loss)
I0905 11:17:30.477452 90901 sgd_solver.cpp:106] Iteration 53640, lr = 0.01
I0905 11:17:36.536224 90901 solver.cpp:228] Iteration 53650, loss = 0.142737
I0905 11:17:36.536303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142739 (* 1 = 0.142739 loss)
I0905 11:17:36.536320 90901 sgd_solver.cpp:106] Iteration 53650, lr = 0.01
I0905 11:17:42.602483 90901 solver.cpp:228] Iteration 53660, loss = 0.179392
I0905 11:17:42.603194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179394 (* 1 = 0.179394 loss)
I0905 11:17:42.603220 90901 sgd_solver.cpp:106] Iteration 53660, lr = 0.01
I0905 11:17:48.676151 90901 solver.cpp:228] Iteration 53670, loss = 0.180045
I0905 11:17:48.676211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180046 (* 1 = 0.180046 loss)
I0905 11:17:48.676225 90901 sgd_solver.cpp:106] Iteration 53670, lr = 0.01
I0905 11:17:54.643677 90901 solver.cpp:228] Iteration 53680, loss = 0.220839
I0905 11:17:54.643745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220841 (* 1 = 0.220841 loss)
I0905 11:17:54.643760 90901 sgd_solver.cpp:106] Iteration 53680, lr = 0.01
I0905 11:18:00.711962 90901 solver.cpp:228] Iteration 53690, loss = 0.307474
I0905 11:18:00.712034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307475 (* 1 = 0.307475 loss)
I0905 11:18:00.712050 90901 sgd_solver.cpp:106] Iteration 53690, lr = 0.01
I0905 11:18:06.914961 90901 solver.cpp:228] Iteration 53700, loss = 0.247976
I0905 11:18:06.915035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247978 (* 1 = 0.247978 loss)
I0905 11:18:06.915051 90901 sgd_solver.cpp:106] Iteration 53700, lr = 0.01
I0905 11:18:12.997004 90901 solver.cpp:228] Iteration 53710, loss = 0.104099
I0905 11:18:12.997263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1041 (* 1 = 0.1041 loss)
I0905 11:18:12.997293 90901 sgd_solver.cpp:106] Iteration 53710, lr = 0.01
I0905 11:18:19.063467 90901 solver.cpp:228] Iteration 53720, loss = 0.242423
I0905 11:18:19.063519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242424 (* 1 = 0.242424 loss)
I0905 11:18:19.063534 90901 sgd_solver.cpp:106] Iteration 53720, lr = 0.01
I0905 11:18:25.453608 90901 solver.cpp:228] Iteration 53730, loss = 0.366893
I0905 11:18:25.453660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366894 (* 1 = 0.366894 loss)
I0905 11:18:25.453675 90901 sgd_solver.cpp:106] Iteration 53730, lr = 0.01
I0905 11:18:31.544113 90901 solver.cpp:228] Iteration 53740, loss = 0.0863506
I0905 11:18:31.544181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0863521 (* 1 = 0.0863521 loss)
I0905 11:18:31.544201 90901 sgd_solver.cpp:106] Iteration 53740, lr = 0.01
I0905 11:18:37.667541 90901 solver.cpp:228] Iteration 53750, loss = 0.334254
I0905 11:18:37.667604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334256 (* 1 = 0.334256 loss)
I0905 11:18:37.667618 90901 sgd_solver.cpp:106] Iteration 53750, lr = 0.01
I0905 11:18:43.769284 90901 solver.cpp:228] Iteration 53760, loss = 0.315796
I0905 11:18:43.769495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315797 (* 1 = 0.315797 loss)
I0905 11:18:43.769527 90901 sgd_solver.cpp:106] Iteration 53760, lr = 0.01
I0905 11:18:50.170534 90901 solver.cpp:228] Iteration 53770, loss = 0.189642
I0905 11:18:50.170600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189643 (* 1 = 0.189643 loss)
I0905 11:18:50.170615 90901 sgd_solver.cpp:106] Iteration 53770, lr = 0.01
I0905 11:18:56.099395 90901 solver.cpp:228] Iteration 53780, loss = 0.267111
I0905 11:18:56.099454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267112 (* 1 = 0.267112 loss)
I0905 11:18:56.099469 90901 sgd_solver.cpp:106] Iteration 53780, lr = 0.01
I0905 11:19:01.066593 90901 solver.cpp:228] Iteration 53790, loss = 0.46271
I0905 11:19:01.066642 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462712 (* 1 = 0.462712 loss)
I0905 11:19:01.066655 90901 sgd_solver.cpp:106] Iteration 53790, lr = 0.01
I0905 11:19:07.180762 90901 solver.cpp:228] Iteration 53800, loss = 0.295304
I0905 11:19:07.180821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295305 (* 1 = 0.295305 loss)
I0905 11:19:07.180836 90901 sgd_solver.cpp:106] Iteration 53800, lr = 0.01
I0905 11:19:12.915494 90901 solver.cpp:228] Iteration 53810, loss = 0.281718
I0905 11:19:12.915556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281719 (* 1 = 0.281719 loss)
I0905 11:19:12.915577 90901 sgd_solver.cpp:106] Iteration 53810, lr = 0.01
I0905 11:19:19.264416 90901 solver.cpp:228] Iteration 53820, loss = 0.12026
I0905 11:19:19.264582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120262 (* 1 = 0.120262 loss)
I0905 11:19:19.264610 90901 sgd_solver.cpp:106] Iteration 53820, lr = 0.01
I0905 11:19:25.358466 90901 solver.cpp:228] Iteration 53830, loss = 0.216625
I0905 11:19:25.358526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216627 (* 1 = 0.216627 loss)
I0905 11:19:25.358541 90901 sgd_solver.cpp:106] Iteration 53830, lr = 0.01
I0905 11:19:31.722847 90901 solver.cpp:228] Iteration 53840, loss = 0.274142
I0905 11:19:31.722913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274144 (* 1 = 0.274144 loss)
I0905 11:19:31.722929 90901 sgd_solver.cpp:106] Iteration 53840, lr = 0.01
I0905 11:19:37.485931 90901 solver.cpp:228] Iteration 53850, loss = 0.285882
I0905 11:19:37.485977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285884 (* 1 = 0.285884 loss)
I0905 11:19:37.485991 90901 sgd_solver.cpp:106] Iteration 53850, lr = 0.01
I0905 11:19:43.910861 90901 solver.cpp:228] Iteration 53860, loss = 0.105442
I0905 11:19:43.910930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105443 (* 1 = 0.105443 loss)
I0905 11:19:43.910946 90901 sgd_solver.cpp:106] Iteration 53860, lr = 0.01
I0905 11:19:49.773779 90901 solver.cpp:228] Iteration 53870, loss = 0.0948276
I0905 11:19:49.774027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0948292 (* 1 = 0.0948292 loss)
I0905 11:19:49.774044 90901 sgd_solver.cpp:106] Iteration 53870, lr = 0.01
I0905 11:19:56.031121 90901 solver.cpp:228] Iteration 53880, loss = 0.0177234
I0905 11:19:56.031180 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.017725 (* 1 = 0.017725 loss)
I0905 11:19:56.031208 90901 sgd_solver.cpp:106] Iteration 53880, lr = 0.01
I0905 11:20:02.218205 90901 solver.cpp:228] Iteration 53890, loss = 0.131065
I0905 11:20:02.218274 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131067 (* 1 = 0.131067 loss)
I0905 11:20:02.218291 90901 sgd_solver.cpp:106] Iteration 53890, lr = 0.01
I0905 11:20:08.128830 90901 solver.cpp:228] Iteration 53900, loss = 0.190343
I0905 11:20:08.128887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190345 (* 1 = 0.190345 loss)
I0905 11:20:08.128902 90901 sgd_solver.cpp:106] Iteration 53900, lr = 0.01
I0905 11:20:14.589406 90901 solver.cpp:228] Iteration 53910, loss = 0.0970514
I0905 11:20:14.589478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0970531 (* 1 = 0.0970531 loss)
I0905 11:20:14.589491 90901 sgd_solver.cpp:106] Iteration 53910, lr = 0.01
I0905 11:20:20.661247 90901 solver.cpp:228] Iteration 53920, loss = 0.0980616
I0905 11:20:20.661422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0980632 (* 1 = 0.0980632 loss)
I0905 11:20:20.661458 90901 sgd_solver.cpp:106] Iteration 53920, lr = 0.01
I0905 11:20:26.742841 90901 solver.cpp:228] Iteration 53930, loss = 0.220344
I0905 11:20:26.742908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220345 (* 1 = 0.220345 loss)
I0905 11:20:26.742923 90901 sgd_solver.cpp:106] Iteration 53930, lr = 0.01
I0905 11:20:32.800462 90901 solver.cpp:228] Iteration 53940, loss = 0.175043
I0905 11:20:32.800539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175045 (* 1 = 0.175045 loss)
I0905 11:20:32.800555 90901 sgd_solver.cpp:106] Iteration 53940, lr = 0.01
I0905 11:20:39.215473 90901 solver.cpp:228] Iteration 53950, loss = 0.274924
I0905 11:20:39.215519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274925 (* 1 = 0.274925 loss)
I0905 11:20:39.215531 90901 sgd_solver.cpp:106] Iteration 53950, lr = 0.01
I0905 11:20:45.139199 90901 solver.cpp:228] Iteration 53960, loss = 0.403063
I0905 11:20:45.139258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403064 (* 1 = 0.403064 loss)
I0905 11:20:45.139272 90901 sgd_solver.cpp:106] Iteration 53960, lr = 0.01
I0905 11:20:50.715579 90901 solver.cpp:228] Iteration 53970, loss = 0.13565
I0905 11:20:50.715795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135652 (* 1 = 0.135652 loss)
I0905 11:20:50.715823 90901 sgd_solver.cpp:106] Iteration 53970, lr = 0.01
I0905 11:20:56.149817 90901 solver.cpp:228] Iteration 53980, loss = 0.0940806
I0905 11:20:56.149869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0940821 (* 1 = 0.0940821 loss)
I0905 11:20:56.149888 90901 sgd_solver.cpp:106] Iteration 53980, lr = 0.01
I0905 11:21:02.197873 90901 solver.cpp:228] Iteration 53990, loss = 0.321931
I0905 11:21:02.198012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321933 (* 1 = 0.321933 loss)
I0905 11:21:02.198071 90901 sgd_solver.cpp:106] Iteration 53990, lr = 0.01
I0905 11:21:08.573456 90901 solver.cpp:228] Iteration 54000, loss = 0.225082
I0905 11:21:08.573503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225083 (* 1 = 0.225083 loss)
I0905 11:21:08.573518 90901 sgd_solver.cpp:106] Iteration 54000, lr = 0.01
I0905 11:21:14.627742 90901 solver.cpp:228] Iteration 54010, loss = 0.24115
I0905 11:21:14.627807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241152 (* 1 = 0.241152 loss)
I0905 11:21:14.627822 90901 sgd_solver.cpp:106] Iteration 54010, lr = 0.01
I0905 11:21:20.704298 90901 solver.cpp:228] Iteration 54020, loss = 0.129105
I0905 11:21:20.704361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129106 (* 1 = 0.129106 loss)
I0905 11:21:20.704375 90901 sgd_solver.cpp:106] Iteration 54020, lr = 0.01
I0905 11:21:26.603297 90901 solver.cpp:228] Iteration 54030, loss = 0.144645
I0905 11:21:26.603567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144646 (* 1 = 0.144646 loss)
I0905 11:21:26.603585 90901 sgd_solver.cpp:106] Iteration 54030, lr = 0.01
I0905 11:21:32.524564 90901 solver.cpp:228] Iteration 54040, loss = 0.399503
I0905 11:21:32.524643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399505 (* 1 = 0.399505 loss)
I0905 11:21:32.524659 90901 sgd_solver.cpp:106] Iteration 54040, lr = 0.01
I0905 11:21:38.899512 90901 solver.cpp:228] Iteration 54050, loss = 0.118896
I0905 11:21:38.899569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118898 (* 1 = 0.118898 loss)
I0905 11:21:38.899585 90901 sgd_solver.cpp:106] Iteration 54050, lr = 0.01
I0905 11:21:45.005915 90901 solver.cpp:228] Iteration 54060, loss = 0.0816483
I0905 11:21:45.005977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0816497 (* 1 = 0.0816497 loss)
I0905 11:21:45.005992 90901 sgd_solver.cpp:106] Iteration 54060, lr = 0.01
I0905 11:21:51.091691 90901 solver.cpp:228] Iteration 54070, loss = 0.13937
I0905 11:21:51.091744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139371 (* 1 = 0.139371 loss)
I0905 11:21:51.091759 90901 sgd_solver.cpp:106] Iteration 54070, lr = 0.01
I0905 11:21:57.489169 90901 solver.cpp:228] Iteration 54080, loss = 0.269402
I0905 11:21:57.489363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269403 (* 1 = 0.269403 loss)
I0905 11:21:57.489399 90901 sgd_solver.cpp:106] Iteration 54080, lr = 0.01
I0905 11:22:03.539033 90901 solver.cpp:228] Iteration 54090, loss = 0.318324
I0905 11:22:03.539095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318325 (* 1 = 0.318325 loss)
I0905 11:22:03.539110 90901 sgd_solver.cpp:106] Iteration 54090, lr = 0.01
I0905 11:22:09.656394 90901 solver.cpp:228] Iteration 54100, loss = 0.0958001
I0905 11:22:09.656447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0958015 (* 1 = 0.0958015 loss)
I0905 11:22:09.656462 90901 sgd_solver.cpp:106] Iteration 54100, lr = 0.01
I0905 11:22:15.696357 90901 solver.cpp:228] Iteration 54110, loss = 0.10081
I0905 11:22:15.696420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100812 (* 1 = 0.100812 loss)
I0905 11:22:15.696440 90901 sgd_solver.cpp:106] Iteration 54110, lr = 0.01
I0905 11:22:21.801060 90901 solver.cpp:228] Iteration 54120, loss = 0.231101
I0905 11:22:21.801103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231102 (* 1 = 0.231102 loss)
I0905 11:22:21.801116 90901 sgd_solver.cpp:106] Iteration 54120, lr = 0.01
I0905 11:22:27.907778 90901 solver.cpp:228] Iteration 54130, loss = 0.305731
I0905 11:22:27.907948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305732 (* 1 = 0.305732 loss)
I0905 11:22:27.907995 90901 sgd_solver.cpp:106] Iteration 54130, lr = 0.01
I0905 11:22:33.867156 90901 solver.cpp:228] Iteration 54140, loss = 0.0398138
I0905 11:22:33.867224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0398152 (* 1 = 0.0398152 loss)
I0905 11:22:33.867239 90901 sgd_solver.cpp:106] Iteration 54140, lr = 0.01
I0905 11:22:38.815637 90901 solver.cpp:228] Iteration 54150, loss = 0.117967
I0905 11:22:38.815682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117968 (* 1 = 0.117968 loss)
I0905 11:22:38.815696 90901 sgd_solver.cpp:106] Iteration 54150, lr = 0.01
I0905 11:22:44.746104 90901 solver.cpp:228] Iteration 54160, loss = 0.168972
I0905 11:22:44.746155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168973 (* 1 = 0.168973 loss)
I0905 11:22:44.746170 90901 sgd_solver.cpp:106] Iteration 54160, lr = 0.01
I0905 11:22:50.610558 90901 solver.cpp:228] Iteration 54170, loss = 0.0803132
I0905 11:22:50.610599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0803146 (* 1 = 0.0803146 loss)
I0905 11:22:50.610611 90901 sgd_solver.cpp:106] Iteration 54170, lr = 0.01
I0905 11:22:56.918560 90901 solver.cpp:228] Iteration 54180, loss = 0.139175
I0905 11:22:56.918612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139177 (* 1 = 0.139177 loss)
I0905 11:22:56.918627 90901 sgd_solver.cpp:106] Iteration 54180, lr = 0.01
I0905 11:23:02.833045 90901 solver.cpp:228] Iteration 54190, loss = 0.253397
I0905 11:23:02.833320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253398 (* 1 = 0.253398 loss)
I0905 11:23:02.833348 90901 sgd_solver.cpp:106] Iteration 54190, lr = 0.01
I0905 11:23:08.947700 90901 solver.cpp:228] Iteration 54200, loss = 0.0612155
I0905 11:23:08.947741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0612169 (* 1 = 0.0612169 loss)
I0905 11:23:08.947756 90901 sgd_solver.cpp:106] Iteration 54200, lr = 0.01
I0905 11:23:15.190016 90901 solver.cpp:228] Iteration 54210, loss = 0.2854
I0905 11:23:15.190095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285402 (* 1 = 0.285402 loss)
I0905 11:23:15.190110 90901 sgd_solver.cpp:106] Iteration 54210, lr = 0.01
I0905 11:23:21.125795 90901 solver.cpp:228] Iteration 54220, loss = 0.15963
I0905 11:23:21.125844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159632 (* 1 = 0.159632 loss)
I0905 11:23:21.125859 90901 sgd_solver.cpp:106] Iteration 54220, lr = 0.01
I0905 11:23:27.343631 90901 solver.cpp:228] Iteration 54230, loss = 0.0809839
I0905 11:23:27.343677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0809855 (* 1 = 0.0809855 loss)
I0905 11:23:27.343689 90901 sgd_solver.cpp:106] Iteration 54230, lr = 0.01
I0905 11:23:33.464660 90901 solver.cpp:228] Iteration 54240, loss = 0.341284
I0905 11:23:33.464828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341285 (* 1 = 0.341285 loss)
I0905 11:23:33.464874 90901 sgd_solver.cpp:106] Iteration 54240, lr = 0.01
I0905 11:23:39.561051 90901 solver.cpp:228] Iteration 54250, loss = 0.279403
I0905 11:23:39.561102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279405 (* 1 = 0.279405 loss)
I0905 11:23:39.561116 90901 sgd_solver.cpp:106] Iteration 54250, lr = 0.01
I0905 11:23:45.636806 90901 solver.cpp:228] Iteration 54260, loss = 0.363607
I0905 11:23:45.636850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363608 (* 1 = 0.363608 loss)
I0905 11:23:45.636862 90901 sgd_solver.cpp:106] Iteration 54260, lr = 0.01
I0905 11:23:51.980638 90901 solver.cpp:228] Iteration 54270, loss = 0.121016
I0905 11:23:51.980690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121017 (* 1 = 0.121017 loss)
I0905 11:23:51.980702 90901 sgd_solver.cpp:106] Iteration 54270, lr = 0.01
I0905 11:23:58.075620 90901 solver.cpp:228] Iteration 54280, loss = 0.086892
I0905 11:23:58.075670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0868936 (* 1 = 0.0868936 loss)
I0905 11:23:58.075683 90901 sgd_solver.cpp:106] Iteration 54280, lr = 0.01
I0905 11:24:04.141924 90901 solver.cpp:228] Iteration 54290, loss = 0.160212
I0905 11:24:04.142098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160213 (* 1 = 0.160213 loss)
I0905 11:24:04.142134 90901 sgd_solver.cpp:106] Iteration 54290, lr = 0.01
I0905 11:24:10.533056 90901 solver.cpp:228] Iteration 54300, loss = 0.276036
I0905 11:24:10.533099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276037 (* 1 = 0.276037 loss)
I0905 11:24:10.533112 90901 sgd_solver.cpp:106] Iteration 54300, lr = 0.01
I0905 11:24:16.599611 90901 solver.cpp:228] Iteration 54310, loss = 0.408914
I0905 11:24:16.599654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.408915 (* 1 = 0.408915 loss)
I0905 11:24:16.599668 90901 sgd_solver.cpp:106] Iteration 54310, lr = 0.01
I0905 11:24:22.471251 90901 solver.cpp:228] Iteration 54320, loss = 0.168697
I0905 11:24:22.471307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168699 (* 1 = 0.168699 loss)
I0905 11:24:22.471323 90901 sgd_solver.cpp:106] Iteration 54320, lr = 0.01
I0905 11:24:27.929184 90901 solver.cpp:228] Iteration 54330, loss = 0.178483
I0905 11:24:27.929237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178485 (* 1 = 0.178485 loss)
I0905 11:24:27.929251 90901 sgd_solver.cpp:106] Iteration 54330, lr = 0.01
I0905 11:24:33.582701 90901 solver.cpp:228] Iteration 54340, loss = 0.0775672
I0905 11:24:33.582752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0775688 (* 1 = 0.0775688 loss)
I0905 11:24:33.582765 90901 sgd_solver.cpp:106] Iteration 54340, lr = 0.01
I0905 11:24:39.637293 90901 solver.cpp:228] Iteration 54350, loss = 0.231634
I0905 11:24:39.637459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231635 (* 1 = 0.231635 loss)
I0905 11:24:39.637501 90901 sgd_solver.cpp:106] Iteration 54350, lr = 0.01
I0905 11:24:46.019230 90901 solver.cpp:228] Iteration 54360, loss = 0.0592083
I0905 11:24:46.019275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0592099 (* 1 = 0.0592099 loss)
I0905 11:24:46.019289 90901 sgd_solver.cpp:106] Iteration 54360, lr = 0.01
I0905 11:24:52.094321 90901 solver.cpp:228] Iteration 54370, loss = 0.284245
I0905 11:24:52.094364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284247 (* 1 = 0.284247 loss)
I0905 11:24:52.094377 90901 sgd_solver.cpp:106] Iteration 54370, lr = 0.01
I0905 11:24:58.171627 90901 solver.cpp:228] Iteration 54380, loss = 0.157206
I0905 11:24:58.171671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157208 (* 1 = 0.157208 loss)
I0905 11:24:58.171685 90901 sgd_solver.cpp:106] Iteration 54380, lr = 0.01
I0905 11:25:04.218201 90901 solver.cpp:228] Iteration 54390, loss = 0.127121
I0905 11:25:04.218245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127122 (* 1 = 0.127122 loss)
I0905 11:25:04.218260 90901 sgd_solver.cpp:106] Iteration 54390, lr = 0.01
I0905 11:25:10.389765 90901 solver.cpp:337] Iteration 54400, Testing net (#0)
I0905 11:25:46.878954 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.764375
I0905 11:25:46.879138 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.644651 (* 1 = 0.644651 loss)
I0905 11:25:47.096132 90901 solver.cpp:228] Iteration 54400, loss = 0.302298
I0905 11:25:47.096200 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3023 (* 1 = 0.3023 loss)
I0905 11:25:47.096221 90901 sgd_solver.cpp:106] Iteration 54400, lr = 0.01
I0905 11:25:52.161685 90901 solver.cpp:228] Iteration 54410, loss = 0.296817
I0905 11:25:52.161753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296818 (* 1 = 0.296818 loss)
I0905 11:25:52.161769 90901 sgd_solver.cpp:106] Iteration 54410, lr = 0.01
I0905 11:25:57.234380 90901 solver.cpp:228] Iteration 54420, loss = 0.107531
I0905 11:25:57.234438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107532 (* 1 = 0.107532 loss)
I0905 11:25:57.234452 90901 sgd_solver.cpp:106] Iteration 54420, lr = 0.01
I0905 11:26:02.265748 90901 solver.cpp:228] Iteration 54430, loss = 0.305201
I0905 11:26:02.265799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305203 (* 1 = 0.305203 loss)
I0905 11:26:02.265815 90901 sgd_solver.cpp:106] Iteration 54430, lr = 0.01
I0905 11:26:07.312621 90901 solver.cpp:228] Iteration 54440, loss = 0.315074
I0905 11:26:07.312664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315075 (* 1 = 0.315075 loss)
I0905 11:26:07.312676 90901 sgd_solver.cpp:106] Iteration 54440, lr = 0.01
I0905 11:26:12.194542 90901 solver.cpp:228] Iteration 54450, loss = 0.103963
I0905 11:26:12.194609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103965 (* 1 = 0.103965 loss)
I0905 11:26:12.194625 90901 sgd_solver.cpp:106] Iteration 54450, lr = 0.01
I0905 11:26:16.843063 90901 solver.cpp:228] Iteration 54460, loss = 0.266024
I0905 11:26:16.843122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266026 (* 1 = 0.266026 loss)
I0905 11:26:16.843139 90901 sgd_solver.cpp:106] Iteration 54460, lr = 0.01
I0905 11:26:21.480820 90901 solver.cpp:228] Iteration 54470, loss = 0.038272
I0905 11:26:21.481056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0382735 (* 1 = 0.0382735 loss)
I0905 11:26:21.481078 90901 sgd_solver.cpp:106] Iteration 54470, lr = 0.01
I0905 11:26:26.538410 90901 solver.cpp:228] Iteration 54480, loss = 0.0265797
I0905 11:26:26.538453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0265812 (* 1 = 0.0265812 loss)
I0905 11:26:26.538466 90901 sgd_solver.cpp:106] Iteration 54480, lr = 0.01
I0905 11:26:31.569023 90901 solver.cpp:228] Iteration 54490, loss = 0.279527
I0905 11:26:31.569077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279529 (* 1 = 0.279529 loss)
I0905 11:26:31.569092 90901 sgd_solver.cpp:106] Iteration 54490, lr = 0.01
I0905 11:26:36.640631 90901 solver.cpp:228] Iteration 54500, loss = 0.181538
I0905 11:26:36.640692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18154 (* 1 = 0.18154 loss)
I0905 11:26:36.640707 90901 sgd_solver.cpp:106] Iteration 54500, lr = 0.01
I0905 11:26:41.675854 90901 solver.cpp:228] Iteration 54510, loss = 0.114864
I0905 11:26:41.675904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114865 (* 1 = 0.114865 loss)
I0905 11:26:41.675917 90901 sgd_solver.cpp:106] Iteration 54510, lr = 0.01
I0905 11:26:47.719864 90901 solver.cpp:228] Iteration 54520, loss = 0.256057
I0905 11:26:47.719905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256059 (* 1 = 0.256059 loss)
I0905 11:26:47.719918 90901 sgd_solver.cpp:106] Iteration 54520, lr = 0.01
I0905 11:26:53.821488 90901 solver.cpp:228] Iteration 54530, loss = 0.0927762
I0905 11:26:53.821660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0927778 (* 1 = 0.0927778 loss)
I0905 11:26:53.821674 90901 sgd_solver.cpp:106] Iteration 54530, lr = 0.01
I0905 11:26:59.904897 90901 solver.cpp:228] Iteration 54540, loss = 0.317285
I0905 11:26:59.904934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317286 (* 1 = 0.317286 loss)
I0905 11:26:59.904947 90901 sgd_solver.cpp:106] Iteration 54540, lr = 0.01
I0905 11:27:06.329818 90901 solver.cpp:228] Iteration 54550, loss = 0.109662
I0905 11:27:06.329859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109664 (* 1 = 0.109664 loss)
I0905 11:27:06.329875 90901 sgd_solver.cpp:106] Iteration 54550, lr = 0.01
I0905 11:27:12.399762 90901 solver.cpp:228] Iteration 54560, loss = 0.102937
I0905 11:27:12.399824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102938 (* 1 = 0.102938 loss)
I0905 11:27:12.399839 90901 sgd_solver.cpp:106] Iteration 54560, lr = 0.01
I0905 11:27:18.504762 90901 solver.cpp:228] Iteration 54570, loss = 0.448174
I0905 11:27:18.504809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448176 (* 1 = 0.448176 loss)
I0905 11:27:18.504822 90901 sgd_solver.cpp:106] Iteration 54570, lr = 0.01
I0905 11:27:24.569912 90901 solver.cpp:228] Iteration 54580, loss = 0.237961
I0905 11:27:24.570114 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237962 (* 1 = 0.237962 loss)
I0905 11:27:24.570135 90901 sgd_solver.cpp:106] Iteration 54580, lr = 0.01
I0905 11:27:30.967589 90901 solver.cpp:228] Iteration 54590, loss = 0.0934682
I0905 11:27:30.967631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0934698 (* 1 = 0.0934698 loss)
I0905 11:27:30.967643 90901 sgd_solver.cpp:106] Iteration 54590, lr = 0.01
I0905 11:27:37.028087 90901 solver.cpp:228] Iteration 54600, loss = 0.237135
I0905 11:27:37.028126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237137 (* 1 = 0.237137 loss)
I0905 11:27:37.028142 90901 sgd_solver.cpp:106] Iteration 54600, lr = 0.01
I0905 11:27:43.052650 90901 solver.cpp:228] Iteration 54610, loss = 0.433871
I0905 11:27:43.052705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433873 (* 1 = 0.433873 loss)
I0905 11:27:43.052718 90901 sgd_solver.cpp:106] Iteration 54610, lr = 0.01
I0905 11:27:49.418169 90901 solver.cpp:228] Iteration 54620, loss = 0.114307
I0905 11:27:49.418207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114308 (* 1 = 0.114308 loss)
I0905 11:27:49.418223 90901 sgd_solver.cpp:106] Iteration 54620, lr = 0.01
I0905 11:27:55.465458 90901 solver.cpp:228] Iteration 54630, loss = 0.124801
I0905 11:27:55.465634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124802 (* 1 = 0.124802 loss)
I0905 11:27:55.465672 90901 sgd_solver.cpp:106] Iteration 54630, lr = 0.01
I0905 11:28:01.489442 90901 solver.cpp:228] Iteration 54640, loss = 0.147927
I0905 11:28:01.489485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147928 (* 1 = 0.147928 loss)
I0905 11:28:01.489497 90901 sgd_solver.cpp:106] Iteration 54640, lr = 0.01
I0905 11:28:07.056967 90901 solver.cpp:228] Iteration 54650, loss = 0.175312
I0905 11:28:07.057014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175314 (* 1 = 0.175314 loss)
I0905 11:28:07.057027 90901 sgd_solver.cpp:106] Iteration 54650, lr = 0.01
I0905 11:28:12.663931 90901 solver.cpp:228] Iteration 54660, loss = 0.0948081
I0905 11:28:12.663971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0948097 (* 1 = 0.0948097 loss)
I0905 11:28:12.663985 90901 sgd_solver.cpp:106] Iteration 54660, lr = 0.01
I0905 11:28:18.375669 90901 solver.cpp:228] Iteration 54670, loss = 0.350683
I0905 11:28:18.375708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350685 (* 1 = 0.350685 loss)
I0905 11:28:18.375721 90901 sgd_solver.cpp:106] Iteration 54670, lr = 0.01
I0905 11:28:24.756299 90901 solver.cpp:228] Iteration 54680, loss = 0.183579
I0905 11:28:24.756361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183581 (* 1 = 0.183581 loss)
I0905 11:28:24.756377 90901 sgd_solver.cpp:106] Iteration 54680, lr = 0.01
I0905 11:28:30.849228 90901 solver.cpp:228] Iteration 54690, loss = 0.139353
I0905 11:28:30.849395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139354 (* 1 = 0.139354 loss)
I0905 11:28:30.849422 90901 sgd_solver.cpp:106] Iteration 54690, lr = 0.01
I0905 11:28:37.003689 90901 solver.cpp:228] Iteration 54700, loss = 0.0805942
I0905 11:28:37.003737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0805958 (* 1 = 0.0805958 loss)
I0905 11:28:37.003753 90901 sgd_solver.cpp:106] Iteration 54700, lr = 0.01
I0905 11:28:43.301936 90901 solver.cpp:228] Iteration 54710, loss = 0.364213
I0905 11:28:43.301977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364214 (* 1 = 0.364214 loss)
I0905 11:28:43.301990 90901 sgd_solver.cpp:106] Iteration 54710, lr = 0.01
I0905 11:28:49.429008 90901 solver.cpp:228] Iteration 54720, loss = 0.205407
I0905 11:28:49.429062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205409 (* 1 = 0.205409 loss)
I0905 11:28:49.429076 90901 sgd_solver.cpp:106] Iteration 54720, lr = 0.01
I0905 11:28:55.234391 90901 solver.cpp:228] Iteration 54730, loss = 0.428371
I0905 11:28:55.234442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428373 (* 1 = 0.428373 loss)
I0905 11:28:55.234457 90901 sgd_solver.cpp:106] Iteration 54730, lr = 0.01
I0905 11:29:01.638595 90901 solver.cpp:228] Iteration 54740, loss = 0.275883
I0905 11:29:01.638839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275885 (* 1 = 0.275885 loss)
I0905 11:29:01.638869 90901 sgd_solver.cpp:106] Iteration 54740, lr = 0.01
I0905 11:29:07.671403 90901 solver.cpp:228] Iteration 54750, loss = 0.218079
I0905 11:29:07.671455 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218081 (* 1 = 0.218081 loss)
I0905 11:29:07.671469 90901 sgd_solver.cpp:106] Iteration 54750, lr = 0.01
I0905 11:29:14.033010 90901 solver.cpp:228] Iteration 54760, loss = 0.194734
I0905 11:29:14.033071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194736 (* 1 = 0.194736 loss)
I0905 11:29:14.033087 90901 sgd_solver.cpp:106] Iteration 54760, lr = 0.01
I0905 11:29:20.078136 90901 solver.cpp:228] Iteration 54770, loss = 0.048748
I0905 11:29:20.078197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0487497 (* 1 = 0.0487497 loss)
I0905 11:29:20.078212 90901 sgd_solver.cpp:106] Iteration 54770, lr = 0.01
I0905 11:29:26.161589 90901 solver.cpp:228] Iteration 54780, loss = 0.206799
I0905 11:29:26.161638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206801 (* 1 = 0.206801 loss)
I0905 11:29:26.161649 90901 sgd_solver.cpp:106] Iteration 54780, lr = 0.01
I0905 11:29:31.916231 90901 solver.cpp:228] Iteration 54790, loss = 0.289854
I0905 11:29:31.916431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289856 (* 1 = 0.289856 loss)
I0905 11:29:31.916470 90901 sgd_solver.cpp:106] Iteration 54790, lr = 0.01
I0905 11:29:38.324576 90901 solver.cpp:228] Iteration 54800, loss = 0.271894
I0905 11:29:38.324635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271895 (* 1 = 0.271895 loss)
I0905 11:29:38.324650 90901 sgd_solver.cpp:106] Iteration 54800, lr = 0.01
I0905 11:29:44.722327 90901 solver.cpp:228] Iteration 54810, loss = 0.0666947
I0905 11:29:44.722393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0666964 (* 1 = 0.0666964 loss)
I0905 11:29:44.722407 90901 sgd_solver.cpp:106] Iteration 54810, lr = 0.01
I0905 11:29:50.791203 90901 solver.cpp:228] Iteration 54820, loss = 0.234336
I0905 11:29:50.791260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234338 (* 1 = 0.234338 loss)
I0905 11:29:50.791275 90901 sgd_solver.cpp:106] Iteration 54820, lr = 0.01
I0905 11:29:56.312010 90901 solver.cpp:228] Iteration 54830, loss = 0.11699
I0905 11:29:56.312072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116992 (* 1 = 0.116992 loss)
I0905 11:29:56.312088 90901 sgd_solver.cpp:106] Iteration 54830, lr = 0.01
I0905 11:30:01.380326 90901 solver.cpp:228] Iteration 54840, loss = 0.0765589
I0905 11:30:01.380381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0765606 (* 1 = 0.0765606 loss)
I0905 11:30:01.380406 90901 sgd_solver.cpp:106] Iteration 54840, lr = 0.01
I0905 11:30:07.741312 90901 solver.cpp:228] Iteration 54850, loss = 0.194297
I0905 11:30:07.741463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194299 (* 1 = 0.194299 loss)
I0905 11:30:07.741494 90901 sgd_solver.cpp:106] Iteration 54850, lr = 0.01
I0905 11:30:13.756973 90901 solver.cpp:228] Iteration 54860, loss = 0.202984
I0905 11:30:13.757040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202986 (* 1 = 0.202986 loss)
I0905 11:30:13.757056 90901 sgd_solver.cpp:106] Iteration 54860, lr = 0.01
I0905 11:30:20.132807 90901 solver.cpp:228] Iteration 54870, loss = 0.380024
I0905 11:30:20.132874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380025 (* 1 = 0.380025 loss)
I0905 11:30:20.132889 90901 sgd_solver.cpp:106] Iteration 54870, lr = 0.01
I0905 11:30:26.165638 90901 solver.cpp:228] Iteration 54880, loss = 0.0784608
I0905 11:30:26.165700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0784624 (* 1 = 0.0784624 loss)
I0905 11:30:26.165715 90901 sgd_solver.cpp:106] Iteration 54880, lr = 0.01
I0905 11:30:32.549631 90901 solver.cpp:228] Iteration 54890, loss = 0.328525
I0905 11:30:32.549695 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328526 (* 1 = 0.328526 loss)
I0905 11:30:32.549710 90901 sgd_solver.cpp:106] Iteration 54890, lr = 0.01
I0905 11:30:38.329581 90901 solver.cpp:228] Iteration 54900, loss = 0.168197
I0905 11:30:38.329831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168199 (* 1 = 0.168199 loss)
I0905 11:30:38.329848 90901 sgd_solver.cpp:106] Iteration 54900, lr = 0.01
I0905 11:30:44.668923 90901 solver.cpp:228] Iteration 54910, loss = 0.11436
I0905 11:30:44.668967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114361 (* 1 = 0.114361 loss)
I0905 11:30:44.668982 90901 sgd_solver.cpp:106] Iteration 54910, lr = 0.01
I0905 11:30:50.443264 90901 solver.cpp:228] Iteration 54920, loss = 0.144209
I0905 11:30:50.443325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144211 (* 1 = 0.144211 loss)
I0905 11:30:50.443342 90901 sgd_solver.cpp:106] Iteration 54920, lr = 0.01
I0905 11:30:56.847872 90901 solver.cpp:228] Iteration 54930, loss = 0.438881
I0905 11:30:56.847934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438883 (* 1 = 0.438883 loss)
I0905 11:30:56.847947 90901 sgd_solver.cpp:106] Iteration 54930, lr = 0.01
I0905 11:31:03.222546 90901 solver.cpp:228] Iteration 54940, loss = 0.362252
I0905 11:31:03.222605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362253 (* 1 = 0.362253 loss)
I0905 11:31:03.222620 90901 sgd_solver.cpp:106] Iteration 54940, lr = 0.01
I0905 11:31:08.970468 90901 solver.cpp:228] Iteration 54950, loss = 0.121945
I0905 11:31:08.970602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121947 (* 1 = 0.121947 loss)
I0905 11:31:08.970645 90901 sgd_solver.cpp:106] Iteration 54950, lr = 0.01
I0905 11:31:15.028400 90901 solver.cpp:228] Iteration 54960, loss = 0.25907
I0905 11:31:15.028465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259072 (* 1 = 0.259072 loss)
I0905 11:31:15.028482 90901 sgd_solver.cpp:106] Iteration 54960, lr = 0.01
I0905 11:31:21.078635 90901 solver.cpp:228] Iteration 54970, loss = 0.0853535
I0905 11:31:21.078693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853551 (* 1 = 0.0853551 loss)
I0905 11:31:21.078708 90901 sgd_solver.cpp:106] Iteration 54970, lr = 0.01
I0905 11:31:27.126792 90901 solver.cpp:228] Iteration 54980, loss = 0.0875403
I0905 11:31:27.126848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.087542 (* 1 = 0.087542 loss)
I0905 11:31:27.126864 90901 sgd_solver.cpp:106] Iteration 54980, lr = 0.01
I0905 11:31:33.527148 90901 solver.cpp:228] Iteration 54990, loss = 0.107647
I0905 11:31:33.527216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107648 (* 1 = 0.107648 loss)
I0905 11:31:33.527231 90901 sgd_solver.cpp:106] Iteration 54990, lr = 0.01
I0905 11:31:39.601042 90901 solver.cpp:228] Iteration 55000, loss = 0.498275
I0905 11:31:39.601236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498277 (* 1 = 0.498277 loss)
I0905 11:31:39.601274 90901 sgd_solver.cpp:106] Iteration 55000, lr = 0.01
I0905 11:31:45.286263 90901 solver.cpp:228] Iteration 55010, loss = 0.110366
I0905 11:31:45.286329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110368 (* 1 = 0.110368 loss)
I0905 11:31:45.286344 90901 sgd_solver.cpp:106] Iteration 55010, lr = 0.01
I0905 11:31:50.528398 90901 solver.cpp:228] Iteration 55020, loss = 0.110529
I0905 11:31:50.528456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11053 (* 1 = 0.11053 loss)
I0905 11:31:50.528471 90901 sgd_solver.cpp:106] Iteration 55020, lr = 0.01
I0905 11:31:56.212198 90901 solver.cpp:228] Iteration 55030, loss = 0.0693174
I0905 11:31:56.212265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0693191 (* 1 = 0.0693191 loss)
I0905 11:31:56.212280 90901 sgd_solver.cpp:106] Iteration 55030, lr = 0.01
I0905 11:32:02.573505 90901 solver.cpp:228] Iteration 55040, loss = 0.105245
I0905 11:32:02.573563 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105247 (* 1 = 0.105247 loss)
I0905 11:32:02.573578 90901 sgd_solver.cpp:106] Iteration 55040, lr = 0.01
I0905 11:32:08.604655 90901 solver.cpp:228] Iteration 55050, loss = 0.281465
I0905 11:32:08.604717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281467 (* 1 = 0.281467 loss)
I0905 11:32:08.604732 90901 sgd_solver.cpp:106] Iteration 55050, lr = 0.01
I0905 11:32:14.696599 90901 solver.cpp:228] Iteration 55060, loss = 0.337471
I0905 11:32:14.696825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337473 (* 1 = 0.337473 loss)
I0905 11:32:14.696857 90901 sgd_solver.cpp:106] Iteration 55060, lr = 0.01
I0905 11:32:21.078660 90901 solver.cpp:228] Iteration 55070, loss = 0.48493
I0905 11:32:21.078714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.484931 (* 1 = 0.484931 loss)
I0905 11:32:21.078730 90901 sgd_solver.cpp:106] Iteration 55070, lr = 0.01
I0905 11:32:27.132055 90901 solver.cpp:228] Iteration 55080, loss = 0.226812
I0905 11:32:27.132119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226814 (* 1 = 0.226814 loss)
I0905 11:32:27.132138 90901 sgd_solver.cpp:106] Iteration 55080, lr = 0.01
I0905 11:32:33.183434 90901 solver.cpp:228] Iteration 55090, loss = 0.357184
I0905 11:32:33.183497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357186 (* 1 = 0.357186 loss)
I0905 11:32:33.183521 90901 sgd_solver.cpp:106] Iteration 55090, lr = 0.01
I0905 11:32:39.588712 90901 solver.cpp:228] Iteration 55100, loss = 0.0558684
I0905 11:32:39.588763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0558701 (* 1 = 0.0558701 loss)
I0905 11:32:39.588778 90901 sgd_solver.cpp:106] Iteration 55100, lr = 0.01
I0905 11:32:45.378341 90901 solver.cpp:228] Iteration 55110, loss = 0.099222
I0905 11:32:45.378490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0992236 (* 1 = 0.0992236 loss)
I0905 11:32:45.378536 90901 sgd_solver.cpp:106] Iteration 55110, lr = 0.01
I0905 11:32:51.468854 90901 solver.cpp:228] Iteration 55120, loss = 0.177789
I0905 11:32:51.468915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17779 (* 1 = 0.17779 loss)
I0905 11:32:51.468930 90901 sgd_solver.cpp:106] Iteration 55120, lr = 0.01
I0905 11:32:57.644673 90901 solver.cpp:228] Iteration 55130, loss = 0.389238
I0905 11:32:57.644731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389239 (* 1 = 0.389239 loss)
I0905 11:32:57.644748 90901 sgd_solver.cpp:106] Iteration 55130, lr = 0.01
I0905 11:33:03.968420 90901 solver.cpp:228] Iteration 55140, loss = 0.329507
I0905 11:33:03.968472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329508 (* 1 = 0.329508 loss)
I0905 11:33:03.968489 90901 sgd_solver.cpp:106] Iteration 55140, lr = 0.01
I0905 11:33:10.039542 90901 solver.cpp:228] Iteration 55150, loss = 0.248416
I0905 11:33:10.039598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248418 (* 1 = 0.248418 loss)
I0905 11:33:10.039613 90901 sgd_solver.cpp:106] Iteration 55150, lr = 0.01
I0905 11:33:16.417687 90901 solver.cpp:228] Iteration 55160, loss = 0.197109
I0905 11:33:16.417888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197111 (* 1 = 0.197111 loss)
I0905 11:33:16.417903 90901 sgd_solver.cpp:106] Iteration 55160, lr = 0.01
I0905 11:33:22.513766 90901 solver.cpp:228] Iteration 55170, loss = 0.113592
I0905 11:33:22.513825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113593 (* 1 = 0.113593 loss)
I0905 11:33:22.513839 90901 sgd_solver.cpp:106] Iteration 55170, lr = 0.01
I0905 11:33:28.598275 90901 solver.cpp:228] Iteration 55180, loss = 0.329027
I0905 11:33:28.598345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329029 (* 1 = 0.329029 loss)
I0905 11:33:28.598362 90901 sgd_solver.cpp:106] Iteration 55180, lr = 0.01
I0905 11:33:34.019515 90901 solver.cpp:228] Iteration 55190, loss = 0.207139
I0905 11:33:34.019578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20714 (* 1 = 0.20714 loss)
I0905 11:33:34.019593 90901 sgd_solver.cpp:106] Iteration 55190, lr = 0.01
I0905 11:33:39.069653 90901 solver.cpp:337] Iteration 55200, Testing net (#0)
I0905 11:34:21.528710 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.91625
I0905 11:34:21.528934 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.212146 (* 1 = 0.212146 loss)
I0905 11:34:21.761847 90901 solver.cpp:228] Iteration 55200, loss = 0.0565079
I0905 11:34:21.761914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0565095 (* 1 = 0.0565095 loss)
I0905 11:34:21.761940 90901 sgd_solver.cpp:106] Iteration 55200, lr = 0.01
I0905 11:34:27.573648 90901 solver.cpp:228] Iteration 55210, loss = 0.0190168
I0905 11:34:27.573715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0190183 (* 1 = 0.0190183 loss)
I0905 11:34:27.573729 90901 sgd_solver.cpp:106] Iteration 55210, lr = 0.01
I0905 11:34:34.237687 90901 solver.cpp:228] Iteration 55220, loss = 0.066384
I0905 11:34:34.237753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0663855 (* 1 = 0.0663855 loss)
I0905 11:34:34.237768 90901 sgd_solver.cpp:106] Iteration 55220, lr = 0.01
I0905 11:34:40.282361 90901 solver.cpp:228] Iteration 55230, loss = 0.27115
I0905 11:34:40.282418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271152 (* 1 = 0.271152 loss)
I0905 11:34:40.282430 90901 sgd_solver.cpp:106] Iteration 55230, lr = 0.01
I0905 11:34:46.313215 90901 solver.cpp:228] Iteration 55240, loss = 0.399616
I0905 11:34:46.313266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399618 (* 1 = 0.399618 loss)
I0905 11:34:46.313279 90901 sgd_solver.cpp:106] Iteration 55240, lr = 0.01
I0905 11:34:52.386512 90901 solver.cpp:228] Iteration 55250, loss = 0.204874
I0905 11:34:52.386783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204876 (* 1 = 0.204876 loss)
I0905 11:34:52.386801 90901 sgd_solver.cpp:106] Iteration 55250, lr = 0.01
I0905 11:34:58.471999 90901 solver.cpp:228] Iteration 55260, loss = 0.166797
I0905 11:34:58.472064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166799 (* 1 = 0.166799 loss)
I0905 11:34:58.472077 90901 sgd_solver.cpp:106] Iteration 55260, lr = 0.01
I0905 11:35:04.530452 90901 solver.cpp:228] Iteration 55270, loss = 0.0623562
I0905 11:35:04.530513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0623577 (* 1 = 0.0623577 loss)
I0905 11:35:04.530526 90901 sgd_solver.cpp:106] Iteration 55270, lr = 0.01
I0905 11:35:10.592087 90901 solver.cpp:228] Iteration 55280, loss = 0.159571
I0905 11:35:10.592150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159572 (* 1 = 0.159572 loss)
I0905 11:35:10.592166 90901 sgd_solver.cpp:106] Iteration 55280, lr = 0.01
I0905 11:35:16.352289 90901 solver.cpp:228] Iteration 55290, loss = 0.403958
I0905 11:35:16.352351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40396 (* 1 = 0.40396 loss)
I0905 11:35:16.352370 90901 sgd_solver.cpp:106] Iteration 55290, lr = 0.01
I0905 11:35:22.402281 90901 solver.cpp:228] Iteration 55300, loss = 0.0958244
I0905 11:35:22.402505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0958259 (* 1 = 0.0958259 loss)
I0905 11:35:22.402523 90901 sgd_solver.cpp:106] Iteration 55300, lr = 0.01
I0905 11:35:27.887074 90901 solver.cpp:228] Iteration 55310, loss = 0.186687
I0905 11:35:27.887136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186688 (* 1 = 0.186688 loss)
I0905 11:35:27.887152 90901 sgd_solver.cpp:106] Iteration 55310, lr = 0.01
I0905 11:35:33.651682 90901 solver.cpp:228] Iteration 55320, loss = 0.159223
I0905 11:35:33.651751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159224 (* 1 = 0.159224 loss)
I0905 11:35:33.651765 90901 sgd_solver.cpp:106] Iteration 55320, lr = 0.01
I0905 11:35:39.726794 90901 solver.cpp:228] Iteration 55330, loss = 0.0925322
I0905 11:35:39.726864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0925337 (* 1 = 0.0925337 loss)
I0905 11:35:39.726879 90901 sgd_solver.cpp:106] Iteration 55330, lr = 0.01
I0905 11:35:46.119680 90901 solver.cpp:228] Iteration 55340, loss = 0.406217
I0905 11:35:46.119745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406218 (* 1 = 0.406218 loss)
I0905 11:35:46.119760 90901 sgd_solver.cpp:106] Iteration 55340, lr = 0.01
I0905 11:35:52.197057 90901 solver.cpp:228] Iteration 55350, loss = 0.330691
I0905 11:35:52.197120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330692 (* 1 = 0.330692 loss)
I0905 11:35:52.197136 90901 sgd_solver.cpp:106] Iteration 55350, lr = 0.01
I0905 11:35:57.959256 90901 solver.cpp:228] Iteration 55360, loss = 0.103096
I0905 11:35:57.959542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103097 (* 1 = 0.103097 loss)
I0905 11:35:57.959558 90901 sgd_solver.cpp:106] Iteration 55360, lr = 0.01
I0905 11:36:04.301667 90901 solver.cpp:228] Iteration 55370, loss = 0.143009
I0905 11:36:04.301725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14301 (* 1 = 0.14301 loss)
I0905 11:36:04.301738 90901 sgd_solver.cpp:106] Iteration 55370, lr = 0.01
I0905 11:36:10.367576 90901 solver.cpp:228] Iteration 55380, loss = 0.210896
I0905 11:36:10.367631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210898 (* 1 = 0.210898 loss)
I0905 11:36:10.367647 90901 sgd_solver.cpp:106] Iteration 55380, lr = 0.01
I0905 11:36:16.463032 90901 solver.cpp:228] Iteration 55390, loss = 0.263884
I0905 11:36:16.463078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263885 (* 1 = 0.263885 loss)
I0905 11:36:16.463093 90901 sgd_solver.cpp:106] Iteration 55390, lr = 0.01
I0905 11:36:22.495854 90901 solver.cpp:228] Iteration 55400, loss = 0.112324
I0905 11:36:22.495898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112326 (* 1 = 0.112326 loss)
I0905 11:36:22.495911 90901 sgd_solver.cpp:106] Iteration 55400, lr = 0.01
I0905 11:36:28.573585 90901 solver.cpp:228] Iteration 55410, loss = 0.162942
I0905 11:36:28.573762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162944 (* 1 = 0.162944 loss)
I0905 11:36:28.573799 90901 sgd_solver.cpp:106] Iteration 55410, lr = 0.01
I0905 11:36:34.278695 90901 solver.cpp:228] Iteration 55420, loss = 0.11246
I0905 11:36:34.278760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112461 (* 1 = 0.112461 loss)
I0905 11:36:34.278776 90901 sgd_solver.cpp:106] Iteration 55420, lr = 0.01
I0905 11:36:40.717375 90901 solver.cpp:228] Iteration 55430, loss = 0.47678
I0905 11:36:40.717449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476782 (* 1 = 0.476782 loss)
I0905 11:36:40.717464 90901 sgd_solver.cpp:106] Iteration 55430, lr = 0.01
I0905 11:36:46.739498 90901 solver.cpp:228] Iteration 55440, loss = 0.18533
I0905 11:36:46.739562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185331 (* 1 = 0.185331 loss)
I0905 11:36:46.739581 90901 sgd_solver.cpp:106] Iteration 55440, lr = 0.01
I0905 11:36:53.023787 90901 solver.cpp:228] Iteration 55450, loss = 0.161694
I0905 11:36:53.023860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161695 (* 1 = 0.161695 loss)
I0905 11:36:53.023876 90901 sgd_solver.cpp:106] Iteration 55450, lr = 0.01
I0905 11:36:58.940819 90901 solver.cpp:228] Iteration 55460, loss = 0.0636298
I0905 11:36:58.941010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0636312 (* 1 = 0.0636312 loss)
I0905 11:36:58.941030 90901 sgd_solver.cpp:106] Iteration 55460, lr = 0.01
I0905 11:37:05.287319 90901 solver.cpp:228] Iteration 55470, loss = 0.177297
I0905 11:37:05.287382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177298 (* 1 = 0.177298 loss)
I0905 11:37:05.287397 90901 sgd_solver.cpp:106] Iteration 55470, lr = 0.01
I0905 11:37:11.036147 90901 solver.cpp:228] Iteration 55480, loss = 0.0732251
I0905 11:37:11.036216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0732265 (* 1 = 0.0732265 loss)
I0905 11:37:11.036232 90901 sgd_solver.cpp:106] Iteration 55480, lr = 0.01
I0905 11:37:16.298094 90901 solver.cpp:228] Iteration 55490, loss = 0.217248
I0905 11:37:16.298171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217249 (* 1 = 0.217249 loss)
I0905 11:37:16.298187 90901 sgd_solver.cpp:106] Iteration 55490, lr = 0.01
I0905 11:37:22.270772 90901 solver.cpp:228] Iteration 55500, loss = 0.206346
I0905 11:37:22.270855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206347 (* 1 = 0.206347 loss)
I0905 11:37:22.270872 90901 sgd_solver.cpp:106] Iteration 55500, lr = 0.01
I0905 11:37:28.333890 90901 solver.cpp:228] Iteration 55510, loss = 0.0935105
I0905 11:37:28.333945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0935119 (* 1 = 0.0935119 loss)
I0905 11:37:28.333959 90901 sgd_solver.cpp:106] Iteration 55510, lr = 0.01
I0905 11:37:34.443780 90901 solver.cpp:228] Iteration 55520, loss = 0.0773636
I0905 11:37:34.444020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0773649 (* 1 = 0.0773649 loss)
I0905 11:37:34.444048 90901 sgd_solver.cpp:106] Iteration 55520, lr = 0.01
I0905 11:37:40.547962 90901 solver.cpp:228] Iteration 55530, loss = 0.139639
I0905 11:37:40.548018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139641 (* 1 = 0.139641 loss)
I0905 11:37:40.548033 90901 sgd_solver.cpp:106] Iteration 55530, lr = 0.01
I0905 11:37:46.642674 90901 solver.cpp:228] Iteration 55540, loss = 0.313664
I0905 11:37:46.642734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313665 (* 1 = 0.313665 loss)
I0905 11:37:46.642748 90901 sgd_solver.cpp:106] Iteration 55540, lr = 0.01
I0905 11:37:52.418777 90901 solver.cpp:228] Iteration 55550, loss = 0.246646
I0905 11:37:52.418835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246647 (* 1 = 0.246647 loss)
I0905 11:37:52.418849 90901 sgd_solver.cpp:106] Iteration 55550, lr = 0.01
I0905 11:37:58.509587 90901 solver.cpp:228] Iteration 55560, loss = 0.165831
I0905 11:37:58.509645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165832 (* 1 = 0.165832 loss)
I0905 11:37:58.509660 90901 sgd_solver.cpp:106] Iteration 55560, lr = 0.01
I0905 11:38:04.972244 90901 solver.cpp:228] Iteration 55570, loss = 0.267017
I0905 11:38:04.972431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267018 (* 1 = 0.267018 loss)
I0905 11:38:04.972470 90901 sgd_solver.cpp:106] Iteration 55570, lr = 0.01
I0905 11:38:10.735005 90901 solver.cpp:228] Iteration 55580, loss = 0.172757
I0905 11:38:10.735062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172758 (* 1 = 0.172758 loss)
I0905 11:38:10.735076 90901 sgd_solver.cpp:106] Iteration 55580, lr = 0.01
I0905 11:38:17.170969 90901 solver.cpp:228] Iteration 55590, loss = 0.456204
I0905 11:38:17.171044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.456205 (* 1 = 0.456205 loss)
I0905 11:38:17.171056 90901 sgd_solver.cpp:106] Iteration 55590, lr = 0.01
I0905 11:38:23.004359 90901 solver.cpp:228] Iteration 55600, loss = 0.158423
I0905 11:38:23.004418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158425 (* 1 = 0.158425 loss)
I0905 11:38:23.004432 90901 sgd_solver.cpp:106] Iteration 55600, lr = 0.01
I0905 11:38:29.039659 90901 solver.cpp:228] Iteration 55610, loss = 0.075415
I0905 11:38:29.039718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0754163 (* 1 = 0.0754163 loss)
I0905 11:38:29.039733 90901 sgd_solver.cpp:106] Iteration 55610, lr = 0.01
I0905 11:38:35.450587 90901 solver.cpp:228] Iteration 55620, loss = 0.334592
I0905 11:38:35.450840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334593 (* 1 = 0.334593 loss)
I0905 11:38:35.450857 90901 sgd_solver.cpp:106] Iteration 55620, lr = 0.01
I0905 11:38:41.502300 90901 solver.cpp:228] Iteration 55630, loss = 0.150105
I0905 11:38:41.502357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150107 (* 1 = 0.150107 loss)
I0905 11:38:41.502370 90901 sgd_solver.cpp:106] Iteration 55630, lr = 0.01
I0905 11:38:47.593359 90901 solver.cpp:228] Iteration 55640, loss = 0.223574
I0905 11:38:47.593418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223576 (* 1 = 0.223576 loss)
I0905 11:38:47.593433 90901 sgd_solver.cpp:106] Iteration 55640, lr = 0.01
I0905 11:38:53.329955 90901 solver.cpp:228] Iteration 55650, loss = 0.237471
I0905 11:38:53.330014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237472 (* 1 = 0.237472 loss)
I0905 11:38:53.330030 90901 sgd_solver.cpp:106] Iteration 55650, lr = 0.01
I0905 11:38:58.873826 90901 solver.cpp:228] Iteration 55660, loss = 0.0955402
I0905 11:38:58.873879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0955415 (* 1 = 0.0955415 loss)
I0905 11:38:58.873893 90901 sgd_solver.cpp:106] Iteration 55660, lr = 0.01
I0905 11:39:04.403224 90901 solver.cpp:228] Iteration 55670, loss = 0.508815
I0905 11:39:04.403272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.508816 (* 1 = 0.508816 loss)
I0905 11:39:04.403286 90901 sgd_solver.cpp:106] Iteration 55670, lr = 0.01
I0905 11:39:10.627883 90901 solver.cpp:228] Iteration 55680, loss = 0.513088
I0905 11:39:10.628064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.513089 (* 1 = 0.513089 loss)
I0905 11:39:10.628115 90901 sgd_solver.cpp:106] Iteration 55680, lr = 0.01
I0905 11:39:16.731142 90901 solver.cpp:228] Iteration 55690, loss = 0.240856
I0905 11:39:16.731197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240857 (* 1 = 0.240857 loss)
I0905 11:39:16.731215 90901 sgd_solver.cpp:106] Iteration 55690, lr = 0.01
I0905 11:39:22.530697 90901 solver.cpp:228] Iteration 55700, loss = 0.181739
I0905 11:39:22.530764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18174 (* 1 = 0.18174 loss)
I0905 11:39:22.530781 90901 sgd_solver.cpp:106] Iteration 55700, lr = 0.01
I0905 11:39:28.683966 90901 solver.cpp:228] Iteration 55710, loss = 0.154328
I0905 11:39:28.684010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154329 (* 1 = 0.154329 loss)
I0905 11:39:28.684022 90901 sgd_solver.cpp:106] Iteration 55710, lr = 0.01
I0905 11:39:34.665741 90901 solver.cpp:228] Iteration 55720, loss = 0.106061
I0905 11:39:34.665817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106062 (* 1 = 0.106062 loss)
I0905 11:39:34.665832 90901 sgd_solver.cpp:106] Iteration 55720, lr = 0.01
I0905 11:39:40.735414 90901 solver.cpp:228] Iteration 55730, loss = 0.032974
I0905 11:39:40.735553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0329754 (* 1 = 0.0329754 loss)
I0905 11:39:40.735581 90901 sgd_solver.cpp:106] Iteration 55730, lr = 0.01
I0905 11:39:46.783980 90901 solver.cpp:228] Iteration 55740, loss = 0.154374
I0905 11:39:46.784024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154375 (* 1 = 0.154375 loss)
I0905 11:39:46.784039 90901 sgd_solver.cpp:106] Iteration 55740, lr = 0.01
I0905 11:39:53.198861 90901 solver.cpp:228] Iteration 55750, loss = 0.076506
I0905 11:39:53.198909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0765074 (* 1 = 0.0765074 loss)
I0905 11:39:53.198928 90901 sgd_solver.cpp:106] Iteration 55750, lr = 0.01
I0905 11:39:59.281896 90901 solver.cpp:228] Iteration 55760, loss = 0.290291
I0905 11:39:59.281936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290292 (* 1 = 0.290292 loss)
I0905 11:39:59.281949 90901 sgd_solver.cpp:106] Iteration 55760, lr = 0.01
I0905 11:40:05.369050 90901 solver.cpp:228] Iteration 55770, loss = 0.164285
I0905 11:40:05.369107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164286 (* 1 = 0.164286 loss)
I0905 11:40:05.369122 90901 sgd_solver.cpp:106] Iteration 55770, lr = 0.01
I0905 11:40:11.466655 90901 solver.cpp:228] Iteration 55780, loss = 0.0412163
I0905 11:40:11.466934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0412177 (* 1 = 0.0412177 loss)
I0905 11:40:11.466954 90901 sgd_solver.cpp:106] Iteration 55780, lr = 0.01
I0905 11:40:17.532364 90901 solver.cpp:228] Iteration 55790, loss = 0.136965
I0905 11:40:17.532412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136966 (* 1 = 0.136966 loss)
I0905 11:40:17.532426 90901 sgd_solver.cpp:106] Iteration 55790, lr = 0.01
I0905 11:40:23.955543 90901 solver.cpp:228] Iteration 55800, loss = 0.217533
I0905 11:40:23.955577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217535 (* 1 = 0.217535 loss)
I0905 11:40:23.955591 90901 sgd_solver.cpp:106] Iteration 55800, lr = 0.01
I0905 11:40:30.013532 90901 solver.cpp:228] Iteration 55810, loss = 0.279231
I0905 11:40:30.013583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279233 (* 1 = 0.279233 loss)
I0905 11:40:30.013609 90901 sgd_solver.cpp:106] Iteration 55810, lr = 0.01
I0905 11:40:35.751821 90901 solver.cpp:228] Iteration 55820, loss = 0.255835
I0905 11:40:35.751893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255836 (* 1 = 0.255836 loss)
I0905 11:40:35.751909 90901 sgd_solver.cpp:106] Iteration 55820, lr = 0.01
I0905 11:40:41.771062 90901 solver.cpp:228] Iteration 55830, loss = 0.252815
I0905 11:40:41.771204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252816 (* 1 = 0.252816 loss)
I0905 11:40:41.771245 90901 sgd_solver.cpp:106] Iteration 55830, lr = 0.01
I0905 11:40:47.179540 90901 solver.cpp:228] Iteration 55840, loss = 0.0366326
I0905 11:40:47.179590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0366341 (* 1 = 0.0366341 loss)
I0905 11:40:47.179602 90901 sgd_solver.cpp:106] Iteration 55840, lr = 0.01
I0905 11:40:52.805337 90901 solver.cpp:228] Iteration 55850, loss = 0.0856225
I0905 11:40:52.805384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.085624 (* 1 = 0.085624 loss)
I0905 11:40:52.805397 90901 sgd_solver.cpp:106] Iteration 55850, lr = 0.01
I0905 11:40:58.876850 90901 solver.cpp:228] Iteration 55860, loss = 0.186994
I0905 11:40:58.876894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186996 (* 1 = 0.186996 loss)
I0905 11:40:58.876909 90901 sgd_solver.cpp:106] Iteration 55860, lr = 0.01
I0905 11:41:05.282968 90901 solver.cpp:228] Iteration 55870, loss = 0.165493
I0905 11:41:05.283035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165495 (* 1 = 0.165495 loss)
I0905 11:41:05.283049 90901 sgd_solver.cpp:106] Iteration 55870, lr = 0.01
I0905 11:41:11.158854 90901 solver.cpp:228] Iteration 55880, loss = 0.125215
I0905 11:41:11.158907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125216 (* 1 = 0.125216 loss)
I0905 11:41:11.158921 90901 sgd_solver.cpp:106] Iteration 55880, lr = 0.01
I0905 11:41:17.408859 90901 solver.cpp:228] Iteration 55890, loss = 0.274087
I0905 11:41:17.409010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274088 (* 1 = 0.274088 loss)
I0905 11:41:17.409057 90901 sgd_solver.cpp:106] Iteration 55890, lr = 0.01
I0905 11:41:23.557021 90901 solver.cpp:228] Iteration 55900, loss = 0.304581
I0905 11:41:23.557067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304583 (* 1 = 0.304583 loss)
I0905 11:41:23.557080 90901 sgd_solver.cpp:106] Iteration 55900, lr = 0.01
I0905 11:41:29.651820 90901 solver.cpp:228] Iteration 55910, loss = 0.572226
I0905 11:41:29.651873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572228 (* 1 = 0.572228 loss)
I0905 11:41:29.651887 90901 sgd_solver.cpp:106] Iteration 55910, lr = 0.01
I0905 11:41:35.816259 90901 solver.cpp:228] Iteration 55920, loss = 0.131014
I0905 11:41:35.816320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131016 (* 1 = 0.131016 loss)
I0905 11:41:35.816335 90901 sgd_solver.cpp:106] Iteration 55920, lr = 0.01
I0905 11:41:42.000349 90901 solver.cpp:228] Iteration 55930, loss = 0.201119
I0905 11:41:42.000394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20112 (* 1 = 0.20112 loss)
I0905 11:41:42.000408 90901 sgd_solver.cpp:106] Iteration 55930, lr = 0.01
I0905 11:41:48.227241 90901 solver.cpp:228] Iteration 55940, loss = 0.108684
I0905 11:41:48.227412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108686 (* 1 = 0.108686 loss)
I0905 11:41:48.227427 90901 sgd_solver.cpp:106] Iteration 55940, lr = 0.01
I0905 11:41:54.317757 90901 solver.cpp:228] Iteration 55950, loss = 0.205303
I0905 11:41:54.317796 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205304 (* 1 = 0.205304 loss)
I0905 11:41:54.317809 90901 sgd_solver.cpp:106] Iteration 55950, lr = 0.01
I0905 11:42:00.377243 90901 solver.cpp:228] Iteration 55960, loss = 0.323801
I0905 11:42:00.377291 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323802 (* 1 = 0.323802 loss)
I0905 11:42:00.377305 90901 sgd_solver.cpp:106] Iteration 55960, lr = 0.01
I0905 11:42:06.163884 90901 solver.cpp:228] Iteration 55970, loss = 0.120371
I0905 11:42:06.163930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120372 (* 1 = 0.120372 loss)
I0905 11:42:06.163943 90901 sgd_solver.cpp:106] Iteration 55970, lr = 0.01
I0905 11:42:12.563066 90901 solver.cpp:228] Iteration 55980, loss = 0.145327
I0905 11:42:12.563113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145329 (* 1 = 0.145329 loss)
I0905 11:42:12.563127 90901 sgd_solver.cpp:106] Iteration 55980, lr = 0.01
I0905 11:42:18.854277 90901 solver.cpp:228] Iteration 55990, loss = 0.0688921
I0905 11:42:18.854457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0688936 (* 1 = 0.0688936 loss)
I0905 11:42:18.854475 90901 sgd_solver.cpp:106] Iteration 55990, lr = 0.01
I0905 11:42:24.761169 90901 solver.cpp:337] Iteration 56000, Testing net (#0)
I0905 11:43:05.744371 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.922813
I0905 11:43:05.744510 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.201463 (* 1 = 0.201463 loss)
I0905 11:43:05.962573 90901 solver.cpp:228] Iteration 56000, loss = 0.616469
I0905 11:43:05.962601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.616471 (* 1 = 0.616471 loss)
I0905 11:43:05.962615 90901 sgd_solver.cpp:106] Iteration 56000, lr = 0.01
I0905 11:43:11.363679 90901 solver.cpp:228] Iteration 56010, loss = 0.0650738
I0905 11:43:11.363739 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0650752 (* 1 = 0.0650752 loss)
I0905 11:43:11.363754 90901 sgd_solver.cpp:106] Iteration 56010, lr = 0.01
I0905 11:43:16.395907 90901 solver.cpp:228] Iteration 56020, loss = 0.120791
I0905 11:43:16.395959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120792 (* 1 = 0.120792 loss)
I0905 11:43:16.395972 90901 sgd_solver.cpp:106] Iteration 56020, lr = 0.01
I0905 11:43:21.465651 90901 solver.cpp:228] Iteration 56030, loss = 0.270501
I0905 11:43:21.465700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270502 (* 1 = 0.270502 loss)
I0905 11:43:21.465713 90901 sgd_solver.cpp:106] Iteration 56030, lr = 0.01
I0905 11:43:26.558425 90901 solver.cpp:228] Iteration 56040, loss = 0.572336
I0905 11:43:26.558470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572338 (* 1 = 0.572338 loss)
I0905 11:43:26.558483 90901 sgd_solver.cpp:106] Iteration 56040, lr = 0.01
I0905 11:43:31.619041 90901 solver.cpp:228] Iteration 56050, loss = 0.0883167
I0905 11:43:31.619089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0883181 (* 1 = 0.0883181 loss)
I0905 11:43:31.619103 90901 sgd_solver.cpp:106] Iteration 56050, lr = 0.01
I0905 11:43:36.686563 90901 solver.cpp:228] Iteration 56060, loss = 0.0955015
I0905 11:43:36.686779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.095503 (* 1 = 0.095503 loss)
I0905 11:43:36.686816 90901 sgd_solver.cpp:106] Iteration 56060, lr = 0.01
I0905 11:43:41.721285 90901 solver.cpp:228] Iteration 56070, loss = 0.242436
I0905 11:43:41.721333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242438 (* 1 = 0.242438 loss)
I0905 11:43:41.721345 90901 sgd_solver.cpp:106] Iteration 56070, lr = 0.01
I0905 11:43:46.813092 90901 solver.cpp:228] Iteration 56080, loss = 0.334083
I0905 11:43:46.813145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.334084 (* 1 = 0.334084 loss)
I0905 11:43:46.813159 90901 sgd_solver.cpp:106] Iteration 56080, lr = 0.01
I0905 11:43:51.890084 90901 solver.cpp:228] Iteration 56090, loss = 0.400078
I0905 11:43:51.890130 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400079 (* 1 = 0.400079 loss)
I0905 11:43:51.890143 90901 sgd_solver.cpp:106] Iteration 56090, lr = 0.01
I0905 11:43:56.966835 90901 solver.cpp:228] Iteration 56100, loss = 0.253944
I0905 11:43:56.966874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253945 (* 1 = 0.253945 loss)
I0905 11:43:56.966886 90901 sgd_solver.cpp:106] Iteration 56100, lr = 0.01
I0905 11:44:02.012611 90901 solver.cpp:228] Iteration 56110, loss = 0.0868811
I0905 11:44:02.012655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0868825 (* 1 = 0.0868825 loss)
I0905 11:44:02.012666 90901 sgd_solver.cpp:106] Iteration 56110, lr = 0.01
I0905 11:44:07.093780 90901 solver.cpp:228] Iteration 56120, loss = 0.151408
I0905 11:44:07.093961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15141 (* 1 = 0.15141 loss)
I0905 11:44:07.094004 90901 sgd_solver.cpp:106] Iteration 56120, lr = 0.01
I0905 11:44:12.128895 90901 solver.cpp:228] Iteration 56130, loss = 0.0510924
I0905 11:44:12.128945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0510939 (* 1 = 0.0510939 loss)
I0905 11:44:12.128958 90901 sgd_solver.cpp:106] Iteration 56130, lr = 0.01
I0905 11:44:17.008962 90901 solver.cpp:228] Iteration 56140, loss = 0.117093
I0905 11:44:17.009003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117095 (* 1 = 0.117095 loss)
I0905 11:44:17.009016 90901 sgd_solver.cpp:106] Iteration 56140, lr = 0.01
I0905 11:44:21.653823 90901 solver.cpp:228] Iteration 56150, loss = 0.154868
I0905 11:44:21.653869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154869 (* 1 = 0.154869 loss)
I0905 11:44:21.653882 90901 sgd_solver.cpp:106] Iteration 56150, lr = 0.01
I0905 11:44:26.308709 90901 solver.cpp:228] Iteration 56160, loss = 0.154264
I0905 11:44:26.308753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154265 (* 1 = 0.154265 loss)
I0905 11:44:26.308766 90901 sgd_solver.cpp:106] Iteration 56160, lr = 0.01
I0905 11:44:31.355677 90901 solver.cpp:228] Iteration 56170, loss = 0.1399
I0905 11:44:31.355731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139901 (* 1 = 0.139901 loss)
I0905 11:44:31.355744 90901 sgd_solver.cpp:106] Iteration 56170, lr = 0.01
I0905 11:44:37.817431 90901 solver.cpp:228] Iteration 56180, loss = 0.147088
I0905 11:44:37.817656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14709 (* 1 = 0.14709 loss)
I0905 11:44:37.817680 90901 sgd_solver.cpp:106] Iteration 56180, lr = 0.01
I0905 11:44:43.584609 90901 solver.cpp:228] Iteration 56190, loss = 0.114952
I0905 11:44:43.584652 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114953 (* 1 = 0.114953 loss)
I0905 11:44:43.584666 90901 sgd_solver.cpp:106] Iteration 56190, lr = 0.01
I0905 11:44:49.678141 90901 solver.cpp:228] Iteration 56200, loss = 0.47253
I0905 11:44:49.678184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472531 (* 1 = 0.472531 loss)
I0905 11:44:49.678196 90901 sgd_solver.cpp:106] Iteration 56200, lr = 0.01
I0905 11:44:56.049207 90901 solver.cpp:228] Iteration 56210, loss = 0.0547394
I0905 11:44:56.049257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0547408 (* 1 = 0.0547408 loss)
I0905 11:44:56.049271 90901 sgd_solver.cpp:106] Iteration 56210, lr = 0.01
I0905 11:45:02.110342 90901 solver.cpp:228] Iteration 56220, loss = 0.0377087
I0905 11:45:02.110393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0377102 (* 1 = 0.0377102 loss)
I0905 11:45:02.110405 90901 sgd_solver.cpp:106] Iteration 56220, lr = 0.01
I0905 11:45:08.435909 90901 solver.cpp:228] Iteration 56230, loss = 0.266418
I0905 11:45:08.436089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26642 (* 1 = 0.26642 loss)
I0905 11:45:08.436136 90901 sgd_solver.cpp:106] Iteration 56230, lr = 0.01
I0905 11:45:14.240931 90901 solver.cpp:228] Iteration 56240, loss = 0.0767267
I0905 11:45:14.240983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0767281 (* 1 = 0.0767281 loss)
I0905 11:45:14.240999 90901 sgd_solver.cpp:106] Iteration 56240, lr = 0.01
I0905 11:45:20.638670 90901 solver.cpp:228] Iteration 56250, loss = 0.234611
I0905 11:45:20.638715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234612 (* 1 = 0.234612 loss)
I0905 11:45:20.638728 90901 sgd_solver.cpp:106] Iteration 56250, lr = 0.01
I0905 11:45:26.720906 90901 solver.cpp:228] Iteration 56260, loss = 0.397556
I0905 11:45:26.720983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397558 (* 1 = 0.397558 loss)
I0905 11:45:26.721024 90901 sgd_solver.cpp:106] Iteration 56260, lr = 0.01
I0905 11:45:32.803045 90901 solver.cpp:228] Iteration 56270, loss = 0.36937
I0905 11:45:32.803097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369371 (* 1 = 0.369371 loss)
I0905 11:45:32.803109 90901 sgd_solver.cpp:106] Iteration 56270, lr = 0.01
I0905 11:45:39.221662 90901 solver.cpp:228] Iteration 56280, loss = 0.123168
I0905 11:45:39.221837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12317 (* 1 = 0.12317 loss)
I0905 11:45:39.221884 90901 sgd_solver.cpp:106] Iteration 56280, lr = 0.01
I0905 11:45:45.320703 90901 solver.cpp:228] Iteration 56290, loss = 0.113784
I0905 11:45:45.320747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113786 (* 1 = 0.113786 loss)
I0905 11:45:45.320761 90901 sgd_solver.cpp:106] Iteration 56290, lr = 0.01
I0905 11:45:51.370569 90901 solver.cpp:228] Iteration 56300, loss = 0.159902
I0905 11:45:51.370622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159903 (* 1 = 0.159903 loss)
I0905 11:45:51.370645 90901 sgd_solver.cpp:106] Iteration 56300, lr = 0.01
I0905 11:45:57.459461 90901 solver.cpp:228] Iteration 56310, loss = 0.572217
I0905 11:45:57.459503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572218 (* 1 = 0.572218 loss)
I0905 11:45:57.459517 90901 sgd_solver.cpp:106] Iteration 56310, lr = 0.01
I0905 11:46:03.491207 90901 solver.cpp:228] Iteration 56320, loss = 0.275849
I0905 11:46:03.491261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27585 (* 1 = 0.27585 loss)
I0905 11:46:03.491274 90901 sgd_solver.cpp:106] Iteration 56320, lr = 0.01
I0905 11:46:09.061635 90901 solver.cpp:228] Iteration 56330, loss = 0.0311837
I0905 11:46:09.061684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0311852 (* 1 = 0.0311852 loss)
I0905 11:46:09.061698 90901 sgd_solver.cpp:106] Iteration 56330, lr = 0.01
I0905 11:46:14.436455 90901 solver.cpp:228] Iteration 56340, loss = 0.0374302
I0905 11:46:14.436697 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0374317 (* 1 = 0.0374317 loss)
I0905 11:46:14.436729 90901 sgd_solver.cpp:106] Iteration 56340, lr = 0.01
I0905 11:46:20.498641 90901 solver.cpp:228] Iteration 56350, loss = 0.105279
I0905 11:46:20.498692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105281 (* 1 = 0.105281 loss)
I0905 11:46:20.498704 90901 sgd_solver.cpp:106] Iteration 56350, lr = 0.01
I0905 11:46:26.548377 90901 solver.cpp:228] Iteration 56360, loss = 0.0781348
I0905 11:46:26.548440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0781363 (* 1 = 0.0781363 loss)
I0905 11:46:26.548455 90901 sgd_solver.cpp:106] Iteration 56360, lr = 0.01
I0905 11:46:32.927521 90901 solver.cpp:228] Iteration 56370, loss = 0.272437
I0905 11:46:32.927597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272438 (* 1 = 0.272438 loss)
I0905 11:46:32.927618 90901 sgd_solver.cpp:106] Iteration 56370, lr = 0.01
I0905 11:46:39.004480 90901 solver.cpp:228] Iteration 56380, loss = 0.102639
I0905 11:46:39.004537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10264 (* 1 = 0.10264 loss)
I0905 11:46:39.004551 90901 sgd_solver.cpp:106] Iteration 56380, lr = 0.01
I0905 11:46:45.090832 90901 solver.cpp:228] Iteration 56390, loss = 0.072446
I0905 11:46:45.091064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0724474 (* 1 = 0.0724474 loss)
I0905 11:46:45.091097 90901 sgd_solver.cpp:106] Iteration 56390, lr = 0.01
I0905 11:46:51.209882 90901 solver.cpp:228] Iteration 56400, loss = 0.04411
I0905 11:46:51.209928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0441114 (* 1 = 0.0441114 loss)
I0905 11:46:51.209942 90901 sgd_solver.cpp:106] Iteration 56400, lr = 0.01
I0905 11:46:57.301502 90901 solver.cpp:228] Iteration 56410, loss = 0.107187
I0905 11:46:57.301569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107189 (* 1 = 0.107189 loss)
I0905 11:46:57.301584 90901 sgd_solver.cpp:106] Iteration 56410, lr = 0.01
I0905 11:47:03.689968 90901 solver.cpp:228] Iteration 56420, loss = 0.10174
I0905 11:47:03.690016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101742 (* 1 = 0.101742 loss)
I0905 11:47:03.690027 90901 sgd_solver.cpp:106] Iteration 56420, lr = 0.01
I0905 11:47:09.750185 90901 solver.cpp:228] Iteration 56430, loss = 0.28565
I0905 11:47:09.750229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285652 (* 1 = 0.285652 loss)
I0905 11:47:09.750241 90901 sgd_solver.cpp:106] Iteration 56430, lr = 0.01
I0905 11:47:15.868212 90901 solver.cpp:228] Iteration 56440, loss = 0.355749
I0905 11:47:15.868351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355751 (* 1 = 0.355751 loss)
I0905 11:47:15.868381 90901 sgd_solver.cpp:106] Iteration 56440, lr = 0.01
I0905 11:47:21.640199 90901 solver.cpp:228] Iteration 56450, loss = 0.269618
I0905 11:47:21.640239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269619 (* 1 = 0.269619 loss)
I0905 11:47:21.640250 90901 sgd_solver.cpp:106] Iteration 56450, lr = 0.01
I0905 11:47:28.068408 90901 solver.cpp:228] Iteration 56460, loss = 0.0641647
I0905 11:47:28.068449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0641661 (* 1 = 0.0641661 loss)
I0905 11:47:28.068462 90901 sgd_solver.cpp:106] Iteration 56460, lr = 0.01
I0905 11:47:33.919761 90901 solver.cpp:228] Iteration 56470, loss = 0.215871
I0905 11:47:33.919809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215873 (* 1 = 0.215873 loss)
I0905 11:47:33.919822 90901 sgd_solver.cpp:106] Iteration 56470, lr = 0.01
I0905 11:47:40.235090 90901 solver.cpp:228] Iteration 56480, loss = 0.123204
I0905 11:47:40.235136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123206 (* 1 = 0.123206 loss)
I0905 11:47:40.235149 90901 sgd_solver.cpp:106] Iteration 56480, lr = 0.01
I0905 11:47:46.326117 90901 solver.cpp:228] Iteration 56490, loss = 0.148948
I0905 11:47:46.326258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148949 (* 1 = 0.148949 loss)
I0905 11:47:46.326285 90901 sgd_solver.cpp:106] Iteration 56490, lr = 0.01
I0905 11:47:52.141592 90901 solver.cpp:228] Iteration 56500, loss = 0.186402
I0905 11:47:52.141643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186404 (* 1 = 0.186404 loss)
I0905 11:47:52.141656 90901 sgd_solver.cpp:106] Iteration 56500, lr = 0.01
I0905 11:47:57.390897 90901 solver.cpp:228] Iteration 56510, loss = 0.116138
I0905 11:47:57.390949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116139 (* 1 = 0.116139 loss)
I0905 11:47:57.390962 90901 sgd_solver.cpp:106] Iteration 56510, lr = 0.01
I0905 11:48:03.264446 90901 solver.cpp:228] Iteration 56520, loss = 0.215469
I0905 11:48:03.264487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215471 (* 1 = 0.215471 loss)
I0905 11:48:03.264500 90901 sgd_solver.cpp:106] Iteration 56520, lr = 0.01
I0905 11:48:09.301786 90901 solver.cpp:228] Iteration 56530, loss = 0.159093
I0905 11:48:09.301836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159094 (* 1 = 0.159094 loss)
I0905 11:48:09.301849 90901 sgd_solver.cpp:106] Iteration 56530, lr = 0.01
I0905 11:48:15.393232 90901 solver.cpp:228] Iteration 56540, loss = 0.157216
I0905 11:48:15.393277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157218 (* 1 = 0.157218 loss)
I0905 11:48:15.393292 90901 sgd_solver.cpp:106] Iteration 56540, lr = 0.01
I0905 11:48:21.465857 90901 solver.cpp:228] Iteration 56550, loss = 0.105511
I0905 11:48:21.466061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105513 (* 1 = 0.105513 loss)
I0905 11:48:21.466095 90901 sgd_solver.cpp:106] Iteration 56550, lr = 0.01
I0905 11:48:27.509256 90901 solver.cpp:228] Iteration 56560, loss = 0.0801683
I0905 11:48:27.509317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0801697 (* 1 = 0.0801697 loss)
I0905 11:48:27.509338 90901 sgd_solver.cpp:106] Iteration 56560, lr = 0.01
I0905 11:48:33.651188 90901 solver.cpp:228] Iteration 56570, loss = 0.107822
I0905 11:48:33.651235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107823 (* 1 = 0.107823 loss)
I0905 11:48:33.651247 90901 sgd_solver.cpp:106] Iteration 56570, lr = 0.01
I0905 11:48:39.858995 90901 solver.cpp:228] Iteration 56580, loss = 0.0633141
I0905 11:48:39.859040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0633155 (* 1 = 0.0633155 loss)
I0905 11:48:39.859055 90901 sgd_solver.cpp:106] Iteration 56580, lr = 0.01
I0905 11:48:45.904273 90901 solver.cpp:228] Iteration 56590, loss = 0.282136
I0905 11:48:45.904315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282137 (* 1 = 0.282137 loss)
I0905 11:48:45.904330 90901 sgd_solver.cpp:106] Iteration 56590, lr = 0.01
I0905 11:48:51.866698 90901 solver.cpp:228] Iteration 56600, loss = 0.226361
I0905 11:48:51.866935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226362 (* 1 = 0.226362 loss)
I0905 11:48:51.866951 90901 sgd_solver.cpp:106] Iteration 56600, lr = 0.01
I0905 11:48:57.971709 90901 solver.cpp:228] Iteration 56610, loss = 0.080083
I0905 11:48:57.971753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0800845 (* 1 = 0.0800845 loss)
I0905 11:48:57.971766 90901 sgd_solver.cpp:106] Iteration 56610, lr = 0.01
I0905 11:49:04.097888 90901 solver.cpp:228] Iteration 56620, loss = 0.126145
I0905 11:49:04.097929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126147 (* 1 = 0.126147 loss)
I0905 11:49:04.097941 90901 sgd_solver.cpp:106] Iteration 56620, lr = 0.01
I0905 11:49:10.241521 90901 solver.cpp:228] Iteration 56630, loss = 0.195786
I0905 11:49:10.241575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195788 (* 1 = 0.195788 loss)
I0905 11:49:10.241592 90901 sgd_solver.cpp:106] Iteration 56630, lr = 0.01
I0905 11:49:16.267249 90901 solver.cpp:228] Iteration 56640, loss = 0.159209
I0905 11:49:16.267297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15921 (* 1 = 0.15921 loss)
I0905 11:49:16.267315 90901 sgd_solver.cpp:106] Iteration 56640, lr = 0.01
I0905 11:49:22.386363 90901 solver.cpp:228] Iteration 56650, loss = 0.0496455
I0905 11:49:22.386541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0496469 (* 1 = 0.0496469 loss)
I0905 11:49:22.386587 90901 sgd_solver.cpp:106] Iteration 56650, lr = 0.01
I0905 11:49:28.614583 90901 solver.cpp:228] Iteration 56660, loss = 0.140806
I0905 11:49:28.614625 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140807 (* 1 = 0.140807 loss)
I0905 11:49:28.614677 90901 sgd_solver.cpp:106] Iteration 56660, lr = 0.01
I0905 11:49:34.820461 90901 solver.cpp:228] Iteration 56670, loss = 0.248419
I0905 11:49:34.820546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24842 (* 1 = 0.24842 loss)
I0905 11:49:34.820565 90901 sgd_solver.cpp:106] Iteration 56670, lr = 0.01
I0905 11:49:40.109045 90901 solver.cpp:228] Iteration 56680, loss = 0.128016
I0905 11:49:40.109087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128017 (* 1 = 0.128017 loss)
I0905 11:49:40.109099 90901 sgd_solver.cpp:106] Iteration 56680, lr = 0.01
I0905 11:49:45.473186 90901 solver.cpp:228] Iteration 56690, loss = 0.434368
I0905 11:49:45.473251 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.43437 (* 1 = 0.43437 loss)
I0905 11:49:45.473266 90901 sgd_solver.cpp:106] Iteration 56690, lr = 0.01
I0905 11:49:51.566822 90901 solver.cpp:228] Iteration 56700, loss = 0.145915
I0905 11:49:51.566871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145916 (* 1 = 0.145916 loss)
I0905 11:49:51.566884 90901 sgd_solver.cpp:106] Iteration 56700, lr = 0.01
I0905 11:49:57.946929 90901 solver.cpp:228] Iteration 56710, loss = 0.0856327
I0905 11:49:57.947160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0856342 (* 1 = 0.0856342 loss)
I0905 11:49:57.947175 90901 sgd_solver.cpp:106] Iteration 56710, lr = 0.01
I0905 11:50:04.030156 90901 solver.cpp:228] Iteration 56720, loss = 0.295623
I0905 11:50:04.030211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295625 (* 1 = 0.295625 loss)
I0905 11:50:04.030227 90901 sgd_solver.cpp:106] Iteration 56720, lr = 0.01
I0905 11:50:09.774370 90901 solver.cpp:228] Iteration 56730, loss = 0.08922
I0905 11:50:09.774428 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0892215 (* 1 = 0.0892215 loss)
I0905 11:50:09.774442 90901 sgd_solver.cpp:106] Iteration 56730, lr = 0.01
I0905 11:50:16.170366 90901 solver.cpp:228] Iteration 56740, loss = 0.336337
I0905 11:50:16.170414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336339 (* 1 = 0.336339 loss)
I0905 11:50:16.170428 90901 sgd_solver.cpp:106] Iteration 56740, lr = 0.01
I0905 11:50:22.248911 90901 solver.cpp:228] Iteration 56750, loss = 0.126976
I0905 11:50:22.248966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126977 (* 1 = 0.126977 loss)
I0905 11:50:22.248980 90901 sgd_solver.cpp:106] Iteration 56750, lr = 0.01
I0905 11:50:28.327723 90901 solver.cpp:228] Iteration 56760, loss = 0.312858
I0905 11:50:28.327904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31286 (* 1 = 0.31286 loss)
I0905 11:50:28.327950 90901 sgd_solver.cpp:106] Iteration 56760, lr = 0.01
I0905 11:50:34.411299 90901 solver.cpp:228] Iteration 56770, loss = 0.325865
I0905 11:50:34.411352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325866 (* 1 = 0.325866 loss)
I0905 11:50:34.411365 90901 sgd_solver.cpp:106] Iteration 56770, lr = 0.01
I0905 11:50:40.499873 90901 solver.cpp:228] Iteration 56780, loss = 0.296355
I0905 11:50:40.499922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296357 (* 1 = 0.296357 loss)
I0905 11:50:40.499933 90901 sgd_solver.cpp:106] Iteration 56780, lr = 0.01
I0905 11:50:46.571270 90901 solver.cpp:228] Iteration 56790, loss = 0.514855
I0905 11:50:46.571313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514856 (* 1 = 0.514856 loss)
I0905 11:50:46.571326 90901 sgd_solver.cpp:106] Iteration 56790, lr = 0.01
I0905 11:50:52.431830 90901 solver.cpp:337] Iteration 56800, Testing net (#0)
I0905 11:51:33.571946 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.770312
I0905 11:51:33.572144 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.558584 (* 1 = 0.558584 loss)
I0905 11:51:33.803894 90901 solver.cpp:228] Iteration 56800, loss = 0.663293
I0905 11:51:33.803966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.663294 (* 1 = 0.663294 loss)
I0905 11:51:33.803987 90901 sgd_solver.cpp:106] Iteration 56800, lr = 0.01
I0905 11:51:39.542647 90901 solver.cpp:228] Iteration 56810, loss = 0.0592024
I0905 11:51:39.542703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0592039 (* 1 = 0.0592039 loss)
I0905 11:51:39.542719 90901 sgd_solver.cpp:106] Iteration 56810, lr = 0.01
I0905 11:51:45.943660 90901 solver.cpp:228] Iteration 56820, loss = 0.109353
I0905 11:51:45.943706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109355 (* 1 = 0.109355 loss)
I0905 11:51:45.943718 90901 sgd_solver.cpp:106] Iteration 56820, lr = 0.01
I0905 11:51:52.269022 90901 solver.cpp:228] Iteration 56830, loss = 0.137842
I0905 11:51:52.269078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137844 (* 1 = 0.137844 loss)
I0905 11:51:52.269093 90901 sgd_solver.cpp:106] Iteration 56830, lr = 0.01
I0905 11:51:58.136440 90901 solver.cpp:228] Iteration 56840, loss = 0.227391
I0905 11:51:58.136502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227393 (* 1 = 0.227393 loss)
I0905 11:51:58.136523 90901 sgd_solver.cpp:106] Iteration 56840, lr = 0.01
I0905 11:52:04.484200 90901 solver.cpp:228] Iteration 56850, loss = 0.325991
I0905 11:52:04.484395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325992 (* 1 = 0.325992 loss)
I0905 11:52:04.484454 90901 sgd_solver.cpp:106] Iteration 56850, lr = 0.01
I0905 11:52:10.533115 90901 solver.cpp:228] Iteration 56860, loss = 0.20037
I0905 11:52:10.533160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200371 (* 1 = 0.200371 loss)
I0905 11:52:10.533174 90901 sgd_solver.cpp:106] Iteration 56860, lr = 0.01
I0905 11:52:16.593195 90901 solver.cpp:228] Iteration 56870, loss = 0.103789
I0905 11:52:16.593257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10379 (* 1 = 0.10379 loss)
I0905 11:52:16.593273 90901 sgd_solver.cpp:106] Iteration 56870, lr = 0.01
I0905 11:52:22.367995 90901 solver.cpp:228] Iteration 56880, loss = 0.132277
I0905 11:52:22.368041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132279 (* 1 = 0.132279 loss)
I0905 11:52:22.368054 90901 sgd_solver.cpp:106] Iteration 56880, lr = 0.01
I0905 11:52:28.784924 90901 solver.cpp:228] Iteration 56890, loss = 0.153009
I0905 11:52:28.784971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15301 (* 1 = 0.15301 loss)
I0905 11:52:28.784986 90901 sgd_solver.cpp:106] Iteration 56890, lr = 0.01
I0905 11:52:34.817800 90901 solver.cpp:228] Iteration 56900, loss = 0.191989
I0905 11:52:34.817947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19199 (* 1 = 0.19199 loss)
I0905 11:52:34.817975 90901 sgd_solver.cpp:106] Iteration 56900, lr = 0.01
I0905 11:52:40.898900 90901 solver.cpp:228] Iteration 56910, loss = 0.43612
I0905 11:52:40.898944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436122 (* 1 = 0.436122 loss)
I0905 11:52:40.898957 90901 sgd_solver.cpp:106] Iteration 56910, lr = 0.01
I0905 11:52:46.985877 90901 solver.cpp:228] Iteration 56920, loss = 0.076187
I0905 11:52:46.985921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0761884 (* 1 = 0.0761884 loss)
I0905 11:52:46.985934 90901 sgd_solver.cpp:106] Iteration 56920, lr = 0.01
I0905 11:52:53.405555 90901 solver.cpp:228] Iteration 56930, loss = 0.0478775
I0905 11:52:53.405596 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0478789 (* 1 = 0.0478789 loss)
I0905 11:52:53.405607 90901 sgd_solver.cpp:106] Iteration 56930, lr = 0.01
I0905 11:52:59.480638 90901 solver.cpp:228] Iteration 56940, loss = 0.101183
I0905 11:52:59.480687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101185 (* 1 = 0.101185 loss)
I0905 11:52:59.480706 90901 sgd_solver.cpp:106] Iteration 56940, lr = 0.01
I0905 11:53:05.857297 90901 solver.cpp:228] Iteration 56950, loss = 0.296708
I0905 11:53:05.857403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29671 (* 1 = 0.29671 loss)
I0905 11:53:05.857419 90901 sgd_solver.cpp:106] Iteration 56950, lr = 0.01
I0905 11:53:11.717473 90901 solver.cpp:228] Iteration 56960, loss = 0.116492
I0905 11:53:11.717533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116493 (* 1 = 0.116493 loss)
I0905 11:53:11.717550 90901 sgd_solver.cpp:106] Iteration 56960, lr = 0.01
I0905 11:53:16.987117 90901 solver.cpp:228] Iteration 56970, loss = 0.204798
I0905 11:53:16.987159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2048 (* 1 = 0.2048 loss)
I0905 11:53:16.987171 90901 sgd_solver.cpp:106] Iteration 56970, lr = 0.01
I0905 11:53:22.543169 90901 solver.cpp:228] Iteration 56980, loss = 0.146619
I0905 11:53:22.543207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146621 (* 1 = 0.146621 loss)
I0905 11:53:22.543220 90901 sgd_solver.cpp:106] Iteration 56980, lr = 0.01
I0905 11:53:28.963567 90901 solver.cpp:228] Iteration 56990, loss = 0.240831
I0905 11:53:28.963608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240832 (* 1 = 0.240832 loss)
I0905 11:53:28.963621 90901 sgd_solver.cpp:106] Iteration 56990, lr = 0.01
I0905 11:53:35.062095 90901 solver.cpp:228] Iteration 57000, loss = 0.0696162
I0905 11:53:35.062149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0696176 (* 1 = 0.0696176 loss)
I0905 11:53:35.062188 90901 sgd_solver.cpp:106] Iteration 57000, lr = 0.01
I0905 11:53:41.132179 90901 solver.cpp:228] Iteration 57010, loss = 0.234213
I0905 11:53:41.132388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234214 (* 1 = 0.234214 loss)
I0905 11:53:41.132405 90901 sgd_solver.cpp:106] Iteration 57010, lr = 0.01
I0905 11:53:47.142818 90901 solver.cpp:228] Iteration 57020, loss = 0.0625528
I0905 11:53:47.142858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0625543 (* 1 = 0.0625543 loss)
I0905 11:53:47.142871 90901 sgd_solver.cpp:106] Iteration 57020, lr = 0.01
I0905 11:53:53.255717 90901 solver.cpp:228] Iteration 57030, loss = 0.0175334
I0905 11:53:53.255761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0175349 (* 1 = 0.0175349 loss)
I0905 11:53:53.255775 90901 sgd_solver.cpp:106] Iteration 57030, lr = 0.01
I0905 11:53:59.699018 90901 solver.cpp:228] Iteration 57040, loss = 0.397495
I0905 11:53:59.699069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397497 (* 1 = 0.397497 loss)
I0905 11:53:59.699084 90901 sgd_solver.cpp:106] Iteration 57040, lr = 0.01
I0905 11:54:05.428892 90901 solver.cpp:228] Iteration 57050, loss = 0.191171
I0905 11:54:05.428933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191172 (* 1 = 0.191172 loss)
I0905 11:54:05.428946 90901 sgd_solver.cpp:106] Iteration 57050, lr = 0.01
I0905 11:54:11.835904 90901 solver.cpp:228] Iteration 57060, loss = 0.293316
I0905 11:54:11.835995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293317 (* 1 = 0.293317 loss)
I0905 11:54:11.836012 90901 sgd_solver.cpp:106] Iteration 57060, lr = 0.01
I0905 11:54:17.862671 90901 solver.cpp:228] Iteration 57070, loss = 0.100312
I0905 11:54:17.862709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100313 (* 1 = 0.100313 loss)
I0905 11:54:17.862721 90901 sgd_solver.cpp:106] Iteration 57070, lr = 0.01
I0905 11:54:24.209247 90901 solver.cpp:228] Iteration 57080, loss = 0.156581
I0905 11:54:24.209285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156583 (* 1 = 0.156583 loss)
I0905 11:54:24.209297 90901 sgd_solver.cpp:106] Iteration 57080, lr = 0.01
I0905 11:54:30.314077 90901 solver.cpp:228] Iteration 57090, loss = 0.141288
I0905 11:54:30.314116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141289 (* 1 = 0.141289 loss)
I0905 11:54:30.314127 90901 sgd_solver.cpp:106] Iteration 57090, lr = 0.01
I0905 11:54:36.340235 90901 solver.cpp:228] Iteration 57100, loss = 0.53883
I0905 11:54:36.340276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.538831 (* 1 = 0.538831 loss)
I0905 11:54:36.340287 90901 sgd_solver.cpp:106] Iteration 57100, lr = 0.01
I0905 11:54:42.431108 90901 solver.cpp:228] Iteration 57110, loss = 0.135394
I0905 11:54:42.431278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135396 (* 1 = 0.135396 loss)
I0905 11:54:42.431294 90901 sgd_solver.cpp:106] Iteration 57110, lr = 0.01
I0905 11:54:48.520323 90901 solver.cpp:228] Iteration 57120, loss = 0.356526
I0905 11:54:48.520362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356527 (* 1 = 0.356527 loss)
I0905 11:54:48.520375 90901 sgd_solver.cpp:106] Iteration 57120, lr = 0.01
I0905 11:54:54.716879 90901 solver.cpp:228] Iteration 57130, loss = 0.522395
I0905 11:54:54.716922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.522397 (* 1 = 0.522397 loss)
I0905 11:54:54.716934 90901 sgd_solver.cpp:106] Iteration 57130, lr = 0.01
I0905 11:55:00.690127 90901 solver.cpp:228] Iteration 57140, loss = 0.106387
I0905 11:55:00.690210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106388 (* 1 = 0.106388 loss)
I0905 11:55:00.690228 90901 sgd_solver.cpp:106] Iteration 57140, lr = 0.01
I0905 11:55:05.669791 90901 solver.cpp:228] Iteration 57150, loss = 0.100707
I0905 11:55:05.669878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100709 (* 1 = 0.100709 loss)
I0905 11:55:05.669904 90901 sgd_solver.cpp:106] Iteration 57150, lr = 0.01
I0905 11:55:11.483058 90901 solver.cpp:228] Iteration 57160, loss = 0.037271
I0905 11:55:11.483139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0372726 (* 1 = 0.0372726 loss)
I0905 11:55:11.483160 90901 sgd_solver.cpp:106] Iteration 57160, lr = 0.01
I0905 11:55:17.427907 90901 solver.cpp:228] Iteration 57170, loss = 0.220885
I0905 11:55:17.428196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220886 (* 1 = 0.220886 loss)
I0905 11:55:17.428223 90901 sgd_solver.cpp:106] Iteration 57170, lr = 0.01
I0905 11:55:23.374194 90901 solver.cpp:228] Iteration 57180, loss = 0.333918
I0905 11:55:23.374310 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33392 (* 1 = 0.33392 loss)
I0905 11:55:23.374337 90901 sgd_solver.cpp:106] Iteration 57180, lr = 0.01
I0905 11:55:29.618897 90901 solver.cpp:228] Iteration 57190, loss = 0.103675
I0905 11:55:29.618986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103677 (* 1 = 0.103677 loss)
I0905 11:55:29.619002 90901 sgd_solver.cpp:106] Iteration 57190, lr = 0.01
I0905 11:55:35.565862 90901 solver.cpp:228] Iteration 57200, loss = 0.115383
I0905 11:55:35.565943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115385 (* 1 = 0.115385 loss)
I0905 11:55:35.565960 90901 sgd_solver.cpp:106] Iteration 57200, lr = 0.01
I0905 11:55:41.500049 90901 solver.cpp:228] Iteration 57210, loss = 0.0955116
I0905 11:55:41.500143 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0955132 (* 1 = 0.0955132 loss)
I0905 11:55:41.500160 90901 sgd_solver.cpp:106] Iteration 57210, lr = 0.01
I0905 11:55:47.471482 90901 solver.cpp:228] Iteration 57220, loss = 0.216294
I0905 11:55:47.478730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216296 (* 1 = 0.216296 loss)
I0905 11:55:47.478768 90901 sgd_solver.cpp:106] Iteration 57220, lr = 0.01
I0905 11:55:53.444679 90901 solver.cpp:228] Iteration 57230, loss = 0.461633
I0905 11:55:53.444751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461634 (* 1 = 0.461634 loss)
I0905 11:55:53.444767 90901 sgd_solver.cpp:106] Iteration 57230, lr = 0.01
I0905 11:55:59.746376 90901 solver.cpp:228] Iteration 57240, loss = 0.046063
I0905 11:55:59.746466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0460646 (* 1 = 0.0460646 loss)
I0905 11:55:59.746492 90901 sgd_solver.cpp:106] Iteration 57240, lr = 0.01
I0905 11:56:06.011852 90901 solver.cpp:228] Iteration 57250, loss = 0.283924
I0905 11:56:06.011948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283926 (* 1 = 0.283926 loss)
I0905 11:56:06.011971 90901 sgd_solver.cpp:106] Iteration 57250, lr = 0.01
I0905 11:56:11.654911 90901 solver.cpp:228] Iteration 57260, loss = 0.123164
I0905 11:56:11.654984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123166 (* 1 = 0.123166 loss)
I0905 11:56:11.655004 90901 sgd_solver.cpp:106] Iteration 57260, lr = 0.01
I0905 11:56:17.637485 90901 solver.cpp:228] Iteration 57270, loss = 0.223997
I0905 11:56:17.638710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223999 (* 1 = 0.223999 loss)
I0905 11:56:17.638741 90901 sgd_solver.cpp:106] Iteration 57270, lr = 0.01
I0905 11:56:23.303764 90901 solver.cpp:228] Iteration 57280, loss = 0.145076
I0905 11:56:23.303843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145077 (* 1 = 0.145077 loss)
I0905 11:56:23.303860 90901 sgd_solver.cpp:106] Iteration 57280, lr = 0.01
I0905 11:56:28.954746 90901 solver.cpp:228] Iteration 57290, loss = 0.160206
I0905 11:56:28.954843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160208 (* 1 = 0.160208 loss)
I0905 11:56:28.954870 90901 sgd_solver.cpp:106] Iteration 57290, lr = 0.01
I0905 11:56:35.086583 90901 solver.cpp:228] Iteration 57300, loss = 0.0662882
I0905 11:56:35.086705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0662898 (* 1 = 0.0662898 loss)
I0905 11:56:35.086737 90901 sgd_solver.cpp:106] Iteration 57300, lr = 0.01
I0905 11:56:41.516461 90901 solver.cpp:228] Iteration 57310, loss = 0.215262
I0905 11:56:41.516553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215264 (* 1 = 0.215264 loss)
I0905 11:56:41.516584 90901 sgd_solver.cpp:106] Iteration 57310, lr = 0.01
I0905 11:56:47.478478 90901 solver.cpp:228] Iteration 57320, loss = 0.153546
I0905 11:56:47.478560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153547 (* 1 = 0.153547 loss)
I0905 11:56:47.478577 90901 sgd_solver.cpp:106] Iteration 57320, lr = 0.01
I0905 11:56:53.163574 90901 solver.cpp:228] Iteration 57330, loss = 0.16635
I0905 11:56:53.163791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166352 (* 1 = 0.166352 loss)
I0905 11:56:53.163816 90901 sgd_solver.cpp:106] Iteration 57330, lr = 0.01
I0905 11:56:59.169021 90901 solver.cpp:228] Iteration 57340, loss = 0.20174
I0905 11:56:59.169137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201742 (* 1 = 0.201742 loss)
I0905 11:56:59.169165 90901 sgd_solver.cpp:106] Iteration 57340, lr = 0.01
I0905 11:57:05.138336 90901 solver.cpp:228] Iteration 57350, loss = 0.099492
I0905 11:57:05.138425 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0994936 (* 1 = 0.0994936 loss)
I0905 11:57:05.138442 90901 sgd_solver.cpp:106] Iteration 57350, lr = 0.01
I0905 11:57:11.090016 90901 solver.cpp:228] Iteration 57360, loss = 0.211029
I0905 11:57:11.090175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21103 (* 1 = 0.21103 loss)
I0905 11:57:11.090198 90901 sgd_solver.cpp:106] Iteration 57360, lr = 0.01
I0905 11:57:16.673405 90901 solver.cpp:228] Iteration 57370, loss = 0.148746
I0905 11:57:16.673488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148747 (* 1 = 0.148747 loss)
I0905 11:57:16.673503 90901 sgd_solver.cpp:106] Iteration 57370, lr = 0.01
I0905 11:57:22.281275 90901 solver.cpp:228] Iteration 57380, loss = 0.255661
I0905 11:57:22.281368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255662 (* 1 = 0.255662 loss)
I0905 11:57:22.281397 90901 sgd_solver.cpp:106] Iteration 57380, lr = 0.01
I0905 11:57:27.924680 90901 solver.cpp:228] Iteration 57390, loss = 0.363986
I0905 11:57:27.937232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363988 (* 1 = 0.363988 loss)
I0905 11:57:27.937273 90901 sgd_solver.cpp:106] Iteration 57390, lr = 0.01
I0905 11:57:33.865164 90901 solver.cpp:228] Iteration 57400, loss = 0.0533439
I0905 11:57:33.865303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0533455 (* 1 = 0.0533455 loss)
I0905 11:57:33.865335 90901 sgd_solver.cpp:106] Iteration 57400, lr = 0.01
I0905 11:57:39.372130 90901 solver.cpp:228] Iteration 57410, loss = 0.137922
I0905 11:57:39.372228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137924 (* 1 = 0.137924 loss)
I0905 11:57:39.372258 90901 sgd_solver.cpp:106] Iteration 57410, lr = 0.01
I0905 11:57:45.507287 90901 solver.cpp:228] Iteration 57420, loss = 0.169054
I0905 11:57:45.507410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169055 (* 1 = 0.169055 loss)
I0905 11:57:45.507426 90901 sgd_solver.cpp:106] Iteration 57420, lr = 0.01
I0905 11:57:51.474872 90901 solver.cpp:228] Iteration 57430, loss = 0.131393
I0905 11:57:51.474943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131395 (* 1 = 0.131395 loss)
I0905 11:57:51.474958 90901 sgd_solver.cpp:106] Iteration 57430, lr = 0.01
I0905 11:57:57.116972 90901 solver.cpp:228] Iteration 57440, loss = 0.213533
I0905 11:57:57.117054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213535 (* 1 = 0.213535 loss)
I0905 11:57:57.117071 90901 sgd_solver.cpp:106] Iteration 57440, lr = 0.01
I0905 11:58:03.385699 90901 solver.cpp:228] Iteration 57450, loss = 0.0607336
I0905 11:58:03.385973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0607351 (* 1 = 0.0607351 loss)
I0905 11:58:03.385993 90901 sgd_solver.cpp:106] Iteration 57450, lr = 0.01
I0905 11:58:09.376116 90901 solver.cpp:228] Iteration 57460, loss = 0.150714
I0905 11:58:09.376219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150716 (* 1 = 0.150716 loss)
I0905 11:58:09.376250 90901 sgd_solver.cpp:106] Iteration 57460, lr = 0.01
I0905 11:58:15.359788 90901 solver.cpp:228] Iteration 57470, loss = 0.371336
I0905 11:58:15.359959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371337 (* 1 = 0.371337 loss)
I0905 11:58:15.359992 90901 sgd_solver.cpp:106] Iteration 57470, lr = 0.01
I0905 11:58:21.329128 90901 solver.cpp:228] Iteration 57480, loss = 0.133903
I0905 11:58:21.329252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133905 (* 1 = 0.133905 loss)
I0905 11:58:21.329284 90901 sgd_solver.cpp:106] Iteration 57480, lr = 0.01
I0905 11:58:27.303385 90901 solver.cpp:228] Iteration 57490, loss = 0.373979
I0905 11:58:27.303489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37398 (* 1 = 0.37398 loss)
I0905 11:58:27.303516 90901 sgd_solver.cpp:106] Iteration 57490, lr = 0.01
I0905 11:58:33.244035 90901 solver.cpp:228] Iteration 57500, loss = 0.178565
I0905 11:58:33.244123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178566 (* 1 = 0.178566 loss)
I0905 11:58:33.244143 90901 sgd_solver.cpp:106] Iteration 57500, lr = 0.01
I0905 11:58:39.530961 90901 solver.cpp:228] Iteration 57510, loss = 0.073959
I0905 11:58:39.531159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0739606 (* 1 = 0.0739606 loss)
I0905 11:58:39.531180 90901 sgd_solver.cpp:106] Iteration 57510, lr = 0.01
I0905 11:58:45.160135 90901 solver.cpp:228] Iteration 57520, loss = 0.375875
I0905 11:58:45.160204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375877 (* 1 = 0.375877 loss)
I0905 11:58:45.160223 90901 sgd_solver.cpp:106] Iteration 57520, lr = 0.01
I0905 11:58:51.098471 90901 solver.cpp:228] Iteration 57530, loss = 0.115531
I0905 11:58:51.098572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115532 (* 1 = 0.115532 loss)
I0905 11:58:51.098601 90901 sgd_solver.cpp:106] Iteration 57530, lr = 0.01
I0905 11:58:56.995231 90901 solver.cpp:228] Iteration 57540, loss = 0.175619
I0905 11:58:56.995328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175621 (* 1 = 0.175621 loss)
I0905 11:58:56.995358 90901 sgd_solver.cpp:106] Iteration 57540, lr = 0.01
I0905 11:59:02.699745 90901 solver.cpp:228] Iteration 57550, loss = 0.330489
I0905 11:59:02.699839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33049 (* 1 = 0.33049 loss)
I0905 11:59:02.699865 90901 sgd_solver.cpp:106] Iteration 57550, lr = 0.01
I0905 11:59:08.630918 90901 solver.cpp:228] Iteration 57560, loss = 0.230101
I0905 11:59:08.630995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230103 (* 1 = 0.230103 loss)
I0905 11:59:08.631011 90901 sgd_solver.cpp:106] Iteration 57560, lr = 0.01
I0905 11:59:14.628090 90901 solver.cpp:228] Iteration 57570, loss = 0.180721
I0905 11:59:14.628440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180723 (* 1 = 0.180723 loss)
I0905 11:59:14.628470 90901 sgd_solver.cpp:106] Iteration 57570, lr = 0.01
I0905 11:59:20.634400 90901 solver.cpp:228] Iteration 57580, loss = 0.186761
I0905 11:59:20.634491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186763 (* 1 = 0.186763 loss)
I0905 11:59:20.634522 90901 sgd_solver.cpp:106] Iteration 57580, lr = 0.01
I0905 11:59:26.611688 90901 solver.cpp:228] Iteration 57590, loss = 0.122641
I0905 11:59:26.611765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122643 (* 1 = 0.122643 loss)
I0905 11:59:26.611783 90901 sgd_solver.cpp:106] Iteration 57590, lr = 0.01
I0905 11:59:32.060272 90901 solver.cpp:337] Iteration 57600, Testing net (#0)
I0905 12:00:11.987381 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.892187
I0905 12:00:11.988342 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.2631 (* 1 = 0.2631 loss)
I0905 12:00:12.196651 90901 solver.cpp:228] Iteration 57600, loss = 0.302122
I0905 12:00:12.196710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302124 (* 1 = 0.302124 loss)
I0905 12:00:12.196730 90901 sgd_solver.cpp:106] Iteration 57600, lr = 0.01
I0905 12:00:18.441849 90901 solver.cpp:228] Iteration 57610, loss = 0.299628
I0905 12:00:18.441906 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29963 (* 1 = 0.29963 loss)
I0905 12:00:18.441921 90901 sgd_solver.cpp:106] Iteration 57610, lr = 0.01
I0905 12:00:24.428850 90901 solver.cpp:228] Iteration 57620, loss = 0.192175
I0905 12:00:24.428917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192176 (* 1 = 0.192176 loss)
I0905 12:00:24.428936 90901 sgd_solver.cpp:106] Iteration 57620, lr = 0.01
I0905 12:00:30.120510 90901 solver.cpp:228] Iteration 57630, loss = 0.184376
I0905 12:00:30.120635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184377 (* 1 = 0.184377 loss)
I0905 12:00:30.120661 90901 sgd_solver.cpp:106] Iteration 57630, lr = 0.01
I0905 12:00:36.333006 90901 solver.cpp:228] Iteration 57640, loss = 0.109705
I0905 12:00:36.333112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109707 (* 1 = 0.109707 loss)
I0905 12:00:36.333142 90901 sgd_solver.cpp:106] Iteration 57640, lr = 0.01
I0905 12:00:42.559027 90901 solver.cpp:228] Iteration 57650, loss = 0.0662753
I0905 12:00:42.559269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0662769 (* 1 = 0.0662769 loss)
I0905 12:00:42.559299 90901 sgd_solver.cpp:106] Iteration 57650, lr = 0.01
I0905 12:00:48.196209 90901 solver.cpp:228] Iteration 57660, loss = 0.074967
I0905 12:00:48.196271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0749685 (* 1 = 0.0749685 loss)
I0905 12:00:48.196286 90901 sgd_solver.cpp:106] Iteration 57660, lr = 0.01
I0905 12:00:54.484325 90901 solver.cpp:228] Iteration 57670, loss = 0.44874
I0905 12:00:54.484429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448742 (* 1 = 0.448742 loss)
I0905 12:00:54.484460 90901 sgd_solver.cpp:106] Iteration 57670, lr = 0.01
I0905 12:01:00.785986 90901 solver.cpp:228] Iteration 57680, loss = 0.180434
I0905 12:01:00.786103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180435 (* 1 = 0.180435 loss)
I0905 12:01:00.786128 90901 sgd_solver.cpp:106] Iteration 57680, lr = 0.01
I0905 12:01:06.457864 90901 solver.cpp:228] Iteration 57690, loss = 0.534515
I0905 12:01:06.457943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.534516 (* 1 = 0.534516 loss)
I0905 12:01:06.457960 90901 sgd_solver.cpp:106] Iteration 57690, lr = 0.01
I0905 12:01:11.453860 90901 solver.cpp:228] Iteration 57700, loss = 0.381455
I0905 12:01:11.453972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381457 (* 1 = 0.381457 loss)
I0905 12:01:11.454006 90901 sgd_solver.cpp:106] Iteration 57700, lr = 0.01
I0905 12:01:16.459717 90901 solver.cpp:228] Iteration 57710, loss = 0.702487
I0905 12:01:16.459971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.702488 (* 1 = 0.702488 loss)
I0905 12:01:16.459990 90901 sgd_solver.cpp:106] Iteration 57710, lr = 0.01
I0905 12:01:21.463114 90901 solver.cpp:228] Iteration 57720, loss = 0.177841
I0905 12:01:21.463182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177842 (* 1 = 0.177842 loss)
I0905 12:01:21.463201 90901 sgd_solver.cpp:106] Iteration 57720, lr = 0.01
I0905 12:01:26.471058 90901 solver.cpp:228] Iteration 57730, loss = 0.173852
I0905 12:01:26.471163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173853 (* 1 = 0.173853 loss)
I0905 12:01:26.471194 90901 sgd_solver.cpp:106] Iteration 57730, lr = 0.01
I0905 12:01:31.457034 90901 solver.cpp:228] Iteration 57740, loss = 0.0380687
I0905 12:01:31.457123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0380702 (* 1 = 0.0380702 loss)
I0905 12:01:31.457141 90901 sgd_solver.cpp:106] Iteration 57740, lr = 0.01
I0905 12:01:36.448395 90901 solver.cpp:228] Iteration 57750, loss = 0.271208
I0905 12:01:36.448479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27121 (* 1 = 0.27121 loss)
I0905 12:01:36.448495 90901 sgd_solver.cpp:106] Iteration 57750, lr = 0.01
I0905 12:01:41.420465 90901 solver.cpp:228] Iteration 57760, loss = 0.188114
I0905 12:01:41.420532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188116 (* 1 = 0.188116 loss)
I0905 12:01:41.420550 90901 sgd_solver.cpp:106] Iteration 57760, lr = 0.01
I0905 12:01:46.403520 90901 solver.cpp:228] Iteration 57770, loss = 0.14391
I0905 12:01:46.403589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143912 (* 1 = 0.143912 loss)
I0905 12:01:46.403606 90901 sgd_solver.cpp:106] Iteration 57770, lr = 0.01
I0905 12:01:51.420385 90901 solver.cpp:228] Iteration 57780, loss = 0.642729
I0905 12:01:51.420658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.64273 (* 1 = 0.64273 loss)
I0905 12:01:51.420694 90901 sgd_solver.cpp:106] Iteration 57780, lr = 0.01
I0905 12:01:56.240119 90901 solver.cpp:228] Iteration 57790, loss = 0.467775
I0905 12:01:56.240232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467777 (* 1 = 0.467777 loss)
I0905 12:01:56.240264 90901 sgd_solver.cpp:106] Iteration 57790, lr = 0.01
I0905 12:02:00.905874 90901 solver.cpp:228] Iteration 57800, loss = 0.228174
I0905 12:02:00.905951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228176 (* 1 = 0.228176 loss)
I0905 12:02:00.905967 90901 sgd_solver.cpp:106] Iteration 57800, lr = 0.01
I0905 12:02:05.579656 90901 solver.cpp:228] Iteration 57810, loss = 0.135762
I0905 12:02:05.579766 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135764 (* 1 = 0.135764 loss)
I0905 12:02:05.579795 90901 sgd_solver.cpp:106] Iteration 57810, lr = 0.01
I0905 12:02:10.555178 90901 solver.cpp:228] Iteration 57820, loss = 0.205678
I0905 12:02:10.555265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205679 (* 1 = 0.205679 loss)
I0905 12:02:10.555284 90901 sgd_solver.cpp:106] Iteration 57820, lr = 0.01
I0905 12:02:15.557567 90901 solver.cpp:228] Iteration 57830, loss = 0.132943
I0905 12:02:15.557668 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132944 (* 1 = 0.132944 loss)
I0905 12:02:15.557698 90901 sgd_solver.cpp:106] Iteration 57830, lr = 0.01
I0905 12:02:20.513007 90901 solver.cpp:228] Iteration 57840, loss = 0.100377
I0905 12:02:20.513159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100379 (* 1 = 0.100379 loss)
I0905 12:02:20.513180 90901 sgd_solver.cpp:106] Iteration 57840, lr = 0.01
I0905 12:02:26.183326 90901 solver.cpp:228] Iteration 57850, loss = 0.141684
I0905 12:02:26.186753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141685 (* 1 = 0.141685 loss)
I0905 12:02:26.186792 90901 sgd_solver.cpp:106] Iteration 57850, lr = 0.01
I0905 12:02:32.489732 90901 solver.cpp:228] Iteration 57860, loss = 0.207746
I0905 12:02:32.489859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207748 (* 1 = 0.207748 loss)
I0905 12:02:32.489891 90901 sgd_solver.cpp:106] Iteration 57860, lr = 0.01
I0905 12:02:38.446383 90901 solver.cpp:228] Iteration 57870, loss = 0.211756
I0905 12:02:38.446480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211758 (* 1 = 0.211758 loss)
I0905 12:02:38.446511 90901 sgd_solver.cpp:106] Iteration 57870, lr = 0.01
I0905 12:02:44.409451 90901 solver.cpp:228] Iteration 57880, loss = 0.103847
I0905 12:02:44.409526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103848 (* 1 = 0.103848 loss)
I0905 12:02:44.409544 90901 sgd_solver.cpp:106] Iteration 57880, lr = 0.01
I0905 12:02:50.073689 90901 solver.cpp:228] Iteration 57890, loss = 0.14308
I0905 12:02:50.073828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143082 (* 1 = 0.143082 loss)
I0905 12:02:50.073846 90901 sgd_solver.cpp:106] Iteration 57890, lr = 0.01
I0905 12:02:55.946084 90901 solver.cpp:228] Iteration 57900, loss = 0.104903
I0905 12:02:55.946158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104904 (* 1 = 0.104904 loss)
I0905 12:02:55.946187 90901 sgd_solver.cpp:106] Iteration 57900, lr = 0.01
I0905 12:03:01.683284 90901 solver.cpp:228] Iteration 57910, loss = 0.337533
I0905 12:03:01.683521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337535 (* 1 = 0.337535 loss)
I0905 12:03:01.683542 90901 sgd_solver.cpp:106] Iteration 57910, lr = 0.01
I0905 12:03:08.002509 90901 solver.cpp:228] Iteration 57920, loss = 0.144404
I0905 12:03:08.002589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144405 (* 1 = 0.144405 loss)
I0905 12:03:08.002609 90901 sgd_solver.cpp:106] Iteration 57920, lr = 0.01
I0905 12:03:13.657480 90901 solver.cpp:228] Iteration 57930, loss = 0.0858907
I0905 12:03:13.657577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0858921 (* 1 = 0.0858921 loss)
I0905 12:03:13.657606 90901 sgd_solver.cpp:106] Iteration 57930, lr = 0.01
I0905 12:03:19.965723 90901 solver.cpp:228] Iteration 57940, loss = 0.0559471
I0905 12:03:19.965785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0559485 (* 1 = 0.0559485 loss)
I0905 12:03:19.965802 90901 sgd_solver.cpp:106] Iteration 57940, lr = 0.01
I0905 12:03:25.631275 90901 solver.cpp:228] Iteration 57950, loss = 0.234697
I0905 12:03:25.631366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234698 (* 1 = 0.234698 loss)
I0905 12:03:25.631395 90901 sgd_solver.cpp:106] Iteration 57950, lr = 0.01
I0905 12:03:31.578418 90901 solver.cpp:228] Iteration 57960, loss = 0.286913
I0905 12:03:31.578514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286914 (* 1 = 0.286914 loss)
I0905 12:03:31.578539 90901 sgd_solver.cpp:106] Iteration 57960, lr = 0.01
I0905 12:03:37.520998 90901 solver.cpp:228] Iteration 57970, loss = 0.11151
I0905 12:03:37.522588 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111512 (* 1 = 0.111512 loss)
I0905 12:03:37.522642 90901 sgd_solver.cpp:106] Iteration 57970, lr = 0.01
I0905 12:03:43.790035 90901 solver.cpp:228] Iteration 57980, loss = 0.243831
I0905 12:03:43.790129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243832 (* 1 = 0.243832 loss)
I0905 12:03:43.790154 90901 sgd_solver.cpp:106] Iteration 57980, lr = 0.01
I0905 12:03:49.732118 90901 solver.cpp:228] Iteration 57990, loss = 0.204718
I0905 12:03:49.732215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204719 (* 1 = 0.204719 loss)
I0905 12:03:49.732242 90901 sgd_solver.cpp:106] Iteration 57990, lr = 0.01
I0905 12:03:55.665994 90901 solver.cpp:228] Iteration 58000, loss = 0.15545
I0905 12:03:55.666168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155451 (* 1 = 0.155451 loss)
I0905 12:03:55.666203 90901 sgd_solver.cpp:106] Iteration 58000, lr = 0.01
I0905 12:04:01.890307 90901 solver.cpp:228] Iteration 58010, loss = 0.10573
I0905 12:04:01.890390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105732 (* 1 = 0.105732 loss)
I0905 12:04:01.890406 90901 sgd_solver.cpp:106] Iteration 58010, lr = 0.01
I0905 12:04:07.891773 90901 solver.cpp:228] Iteration 58020, loss = 0.26248
I0905 12:04:07.892057 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262481 (* 1 = 0.262481 loss)
I0905 12:04:07.892086 90901 sgd_solver.cpp:106] Iteration 58020, lr = 0.01
I0905 12:04:13.529964 90901 solver.cpp:228] Iteration 58030, loss = 0.339767
I0905 12:04:13.530102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339769 (* 1 = 0.339769 loss)
I0905 12:04:13.530133 90901 sgd_solver.cpp:106] Iteration 58030, lr = 0.01
I0905 12:04:19.440357 90901 solver.cpp:228] Iteration 58040, loss = 0.158101
I0905 12:04:19.440462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158103 (* 1 = 0.158103 loss)
I0905 12:04:19.440492 90901 sgd_solver.cpp:106] Iteration 58040, lr = 0.01
I0905 12:04:24.709278 90901 solver.cpp:228] Iteration 58050, loss = 0.316731
I0905 12:04:24.709349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316732 (* 1 = 0.316732 loss)
I0905 12:04:24.709365 90901 sgd_solver.cpp:106] Iteration 58050, lr = 0.01
I0905 12:04:30.598682 90901 solver.cpp:228] Iteration 58060, loss = 0.304633
I0905 12:04:30.598780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304634 (* 1 = 0.304634 loss)
I0905 12:04:30.598812 90901 sgd_solver.cpp:106] Iteration 58060, lr = 0.01
I0905 12:04:36.585227 90901 solver.cpp:228] Iteration 58070, loss = 0.0645809
I0905 12:04:36.585355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0645824 (* 1 = 0.0645824 loss)
I0905 12:04:36.585384 90901 sgd_solver.cpp:106] Iteration 58070, lr = 0.01
I0905 12:04:42.242539 90901 solver.cpp:228] Iteration 58080, loss = 0.119866
I0905 12:04:42.242733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119868 (* 1 = 0.119868 loss)
I0905 12:04:42.242751 90901 sgd_solver.cpp:106] Iteration 58080, lr = 0.01
I0905 12:04:48.554486 90901 solver.cpp:228] Iteration 58090, loss = 0.105011
I0905 12:04:48.554554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105012 (* 1 = 0.105012 loss)
I0905 12:04:48.554570 90901 sgd_solver.cpp:106] Iteration 58090, lr = 0.01
I0905 12:04:54.200660 90901 solver.cpp:228] Iteration 58100, loss = 0.345533
I0905 12:04:54.200744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345535 (* 1 = 0.345535 loss)
I0905 12:04:54.200762 90901 sgd_solver.cpp:106] Iteration 58100, lr = 0.01
I0905 12:05:00.458295 90901 solver.cpp:228] Iteration 58110, loss = 0.163929
I0905 12:05:00.458397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16393 (* 1 = 0.16393 loss)
I0905 12:05:00.458426 90901 sgd_solver.cpp:106] Iteration 58110, lr = 0.01
I0905 12:05:06.120503 90901 solver.cpp:228] Iteration 58120, loss = 0.102453
I0905 12:05:06.120597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102455 (* 1 = 0.102455 loss)
I0905 12:05:06.120616 90901 sgd_solver.cpp:106] Iteration 58120, lr = 0.01
I0905 12:05:12.389884 90901 solver.cpp:228] Iteration 58130, loss = 0.426306
I0905 12:05:12.390259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426307 (* 1 = 0.426307 loss)
I0905 12:05:12.390293 90901 sgd_solver.cpp:106] Iteration 58130, lr = 0.01
I0905 12:05:18.345201 90901 solver.cpp:228] Iteration 58140, loss = 0.541985
I0905 12:05:18.345371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541986 (* 1 = 0.541986 loss)
I0905 12:05:18.345399 90901 sgd_solver.cpp:106] Iteration 58140, lr = 0.01
I0905 12:05:23.996057 90901 solver.cpp:228] Iteration 58150, loss = 0.204157
I0905 12:05:23.996122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204158 (* 1 = 0.204158 loss)
I0905 12:05:23.996139 90901 sgd_solver.cpp:106] Iteration 58150, lr = 0.01
I0905 12:05:30.191521 90901 solver.cpp:228] Iteration 58160, loss = 0.206982
I0905 12:05:30.191609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206983 (* 1 = 0.206983 loss)
I0905 12:05:30.191642 90901 sgd_solver.cpp:106] Iteration 58160, lr = 0.01
I0905 12:05:36.217036 90901 solver.cpp:228] Iteration 58170, loss = 0.0990035
I0905 12:05:36.217131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0990049 (* 1 = 0.0990049 loss)
I0905 12:05:36.217159 90901 sgd_solver.cpp:106] Iteration 58170, lr = 0.01
I0905 12:05:42.218610 90901 solver.cpp:228] Iteration 58180, loss = 0.118402
I0905 12:05:42.218874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118404 (* 1 = 0.118404 loss)
I0905 12:05:42.218899 90901 sgd_solver.cpp:106] Iteration 58180, lr = 0.01
I0905 12:05:48.185988 90901 solver.cpp:228] Iteration 58190, loss = 0.25794
I0905 12:05:48.186965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257941 (* 1 = 0.257941 loss)
I0905 12:05:48.186995 90901 sgd_solver.cpp:106] Iteration 58190, lr = 0.01
I0905 12:05:53.970780 90901 solver.cpp:228] Iteration 58200, loss = 0.0296586
I0905 12:05:53.970857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.02966 (* 1 = 0.02966 loss)
I0905 12:05:53.970875 90901 sgd_solver.cpp:106] Iteration 58200, lr = 0.01
I0905 12:06:00.093010 90901 solver.cpp:228] Iteration 58210, loss = 0.210253
I0905 12:06:00.093161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210254 (* 1 = 0.210254 loss)
I0905 12:06:00.093183 90901 sgd_solver.cpp:106] Iteration 58210, lr = 0.01
I0905 12:06:06.065261 90901 solver.cpp:228] Iteration 58220, loss = 0.186121
I0905 12:06:06.065366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186122 (* 1 = 0.186122 loss)
I0905 12:06:06.065398 90901 sgd_solver.cpp:106] Iteration 58220, lr = 0.01
I0905 12:06:11.739282 90901 solver.cpp:228] Iteration 58230, loss = 0.0664667
I0905 12:06:11.739385 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0664681 (* 1 = 0.0664681 loss)
I0905 12:06:11.739416 90901 sgd_solver.cpp:106] Iteration 58230, lr = 0.01
I0905 12:06:17.964731 90901 solver.cpp:228] Iteration 58240, loss = 0.363272
I0905 12:06:17.964848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363274 (* 1 = 0.363274 loss)
I0905 12:06:17.964881 90901 sgd_solver.cpp:106] Iteration 58240, lr = 0.01
I0905 12:06:23.604234 90901 solver.cpp:228] Iteration 58250, loss = 0.304688
I0905 12:06:23.604466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30469 (* 1 = 0.30469 loss)
I0905 12:06:23.604496 90901 sgd_solver.cpp:106] Iteration 58250, lr = 0.01
I0905 12:06:29.348698 90901 solver.cpp:228] Iteration 58260, loss = 0.259024
I0905 12:06:29.348779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259026 (* 1 = 0.259026 loss)
I0905 12:06:29.348798 90901 sgd_solver.cpp:106] Iteration 58260, lr = 0.01
I0905 12:06:35.562257 90901 solver.cpp:228] Iteration 58270, loss = 0.155682
I0905 12:06:35.562356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155683 (* 1 = 0.155683 loss)
I0905 12:06:35.562374 90901 sgd_solver.cpp:106] Iteration 58270, lr = 0.01
I0905 12:06:40.815788 90901 solver.cpp:228] Iteration 58280, loss = 0.176269
I0905 12:06:40.815876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17627 (* 1 = 0.17627 loss)
I0905 12:06:40.815896 90901 sgd_solver.cpp:106] Iteration 58280, lr = 0.01
I0905 12:06:46.364961 90901 solver.cpp:228] Iteration 58290, loss = 0.228535
I0905 12:06:46.365047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228536 (* 1 = 0.228536 loss)
I0905 12:06:46.365077 90901 sgd_solver.cpp:106] Iteration 58290, lr = 0.01
I0905 12:06:52.052309 90901 solver.cpp:228] Iteration 58300, loss = 0.355347
I0905 12:06:52.052454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355348 (* 1 = 0.355348 loss)
I0905 12:06:52.052492 90901 sgd_solver.cpp:106] Iteration 58300, lr = 0.01
I0905 12:06:57.727041 90901 solver.cpp:228] Iteration 58310, loss = 0.132709
I0905 12:06:57.729320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13271 (* 1 = 0.13271 loss)
I0905 12:06:57.729351 90901 sgd_solver.cpp:106] Iteration 58310, lr = 0.01
I0905 12:07:03.742429 90901 solver.cpp:228] Iteration 58320, loss = 0.320116
I0905 12:07:03.742545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320118 (* 1 = 0.320118 loss)
I0905 12:07:03.742576 90901 sgd_solver.cpp:106] Iteration 58320, lr = 0.01
I0905 12:07:09.485088 90901 solver.cpp:228] Iteration 58330, loss = 0.294571
I0905 12:07:09.485198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294572 (* 1 = 0.294572 loss)
I0905 12:07:09.485222 90901 sgd_solver.cpp:106] Iteration 58330, lr = 0.01
I0905 12:07:15.451473 90901 solver.cpp:228] Iteration 58340, loss = 0.394763
I0905 12:07:15.451553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394765 (* 1 = 0.394765 loss)
I0905 12:07:15.451570 90901 sgd_solver.cpp:106] Iteration 58340, lr = 0.01
I0905 12:07:21.776190 90901 solver.cpp:228] Iteration 58350, loss = 0.248726
I0905 12:07:21.776247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248727 (* 1 = 0.248727 loss)
I0905 12:07:21.776262 90901 sgd_solver.cpp:106] Iteration 58350, lr = 0.01
I0905 12:07:27.808775 90901 solver.cpp:228] Iteration 58360, loss = 0.148518
I0905 12:07:27.809031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148519 (* 1 = 0.148519 loss)
I0905 12:07:27.809048 90901 sgd_solver.cpp:106] Iteration 58360, lr = 0.01
I0905 12:07:33.497087 90901 solver.cpp:228] Iteration 58370, loss = 0.41665
I0905 12:07:33.497164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416651 (* 1 = 0.416651 loss)
I0905 12:07:33.497180 90901 sgd_solver.cpp:106] Iteration 58370, lr = 0.01
I0905 12:07:39.890841 90901 solver.cpp:228] Iteration 58380, loss = 0.0941931
I0905 12:07:39.890899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0941944 (* 1 = 0.0941944 loss)
I0905 12:07:39.890915 90901 sgd_solver.cpp:106] Iteration 58380, lr = 0.01
I0905 12:07:45.950886 90901 solver.cpp:228] Iteration 58390, loss = 0.158604
I0905 12:07:45.950953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158605 (* 1 = 0.158605 loss)
I0905 12:07:45.950968 90901 sgd_solver.cpp:106] Iteration 58390, lr = 0.01
I0905 12:07:51.768640 90901 solver.cpp:337] Iteration 58400, Testing net (#0)
I0905 12:08:34.282091 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.84875
I0905 12:08:34.282587 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.366144 (* 1 = 0.366144 loss)
I0905 12:08:34.483351 90901 solver.cpp:228] Iteration 58400, loss = 0.0971769
I0905 12:08:34.483431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0971783 (* 1 = 0.0971783 loss)
I0905 12:08:34.483454 90901 sgd_solver.cpp:106] Iteration 58400, lr = 0.01
I0905 12:08:39.954038 90901 solver.cpp:228] Iteration 58410, loss = 0.185518
I0905 12:08:39.954088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185519 (* 1 = 0.185519 loss)
I0905 12:08:39.954102 90901 sgd_solver.cpp:106] Iteration 58410, lr = 0.01
I0905 12:08:45.545608 90901 solver.cpp:228] Iteration 58420, loss = 0.215458
I0905 12:08:45.545655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215459 (* 1 = 0.215459 loss)
I0905 12:08:45.545668 90901 sgd_solver.cpp:106] Iteration 58420, lr = 0.01
I0905 12:08:51.607368 90901 solver.cpp:228] Iteration 58430, loss = 0.176028
I0905 12:08:51.607420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17603 (* 1 = 0.17603 loss)
I0905 12:08:51.607434 90901 sgd_solver.cpp:106] Iteration 58430, lr = 0.01
I0905 12:08:57.668848 90901 solver.cpp:228] Iteration 58440, loss = 0.0620045
I0905 12:08:57.668900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0620058 (* 1 = 0.0620058 loss)
I0905 12:08:57.668912 90901 sgd_solver.cpp:106] Iteration 58440, lr = 0.01
I0905 12:09:03.761907 90901 solver.cpp:228] Iteration 58450, loss = 0.0549328
I0905 12:09:03.761968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0549341 (* 1 = 0.0549341 loss)
I0905 12:09:03.761981 90901 sgd_solver.cpp:106] Iteration 58450, lr = 0.01
I0905 12:09:09.826831 90901 solver.cpp:228] Iteration 58460, loss = 0.203263
I0905 12:09:09.827045 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203264 (* 1 = 0.203264 loss)
I0905 12:09:09.827064 90901 sgd_solver.cpp:106] Iteration 58460, lr = 0.01
I0905 12:09:15.872987 90901 solver.cpp:228] Iteration 58470, loss = 0.252551
I0905 12:09:15.873042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252552 (* 1 = 0.252552 loss)
I0905 12:09:15.873056 90901 sgd_solver.cpp:106] Iteration 58470, lr = 0.01
I0905 12:09:21.995034 90901 solver.cpp:228] Iteration 58480, loss = 0.188112
I0905 12:09:21.995075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188113 (* 1 = 0.188113 loss)
I0905 12:09:21.995087 90901 sgd_solver.cpp:106] Iteration 58480, lr = 0.01
I0905 12:09:28.083884 90901 solver.cpp:228] Iteration 58490, loss = 0.1479
I0905 12:09:28.083925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147902 (* 1 = 0.147902 loss)
I0905 12:09:28.083937 90901 sgd_solver.cpp:106] Iteration 58490, lr = 0.01
I0905 12:09:34.156431 90901 solver.cpp:228] Iteration 58500, loss = 0.161125
I0905 12:09:34.156471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161126 (* 1 = 0.161126 loss)
I0905 12:09:34.156484 90901 sgd_solver.cpp:106] Iteration 58500, lr = 0.01
I0905 12:09:40.325929 90901 solver.cpp:228] Iteration 58510, loss = 0.424855
I0905 12:09:40.326061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424856 (* 1 = 0.424856 loss)
I0905 12:09:40.326086 90901 sgd_solver.cpp:106] Iteration 58510, lr = 0.01
I0905 12:09:46.393484 90901 solver.cpp:228] Iteration 58520, loss = 0.313077
I0905 12:09:46.393527 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313079 (* 1 = 0.313079 loss)
I0905 12:09:46.393539 90901 sgd_solver.cpp:106] Iteration 58520, lr = 0.01
I0905 12:09:52.699992 90901 solver.cpp:228] Iteration 58530, loss = 0.230114
I0905 12:09:52.700036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230115 (* 1 = 0.230115 loss)
I0905 12:09:52.700048 90901 sgd_solver.cpp:106] Iteration 58530, lr = 0.01
I0905 12:09:58.791267 90901 solver.cpp:228] Iteration 58540, loss = 0.0251456
I0905 12:09:58.791301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0251468 (* 1 = 0.0251468 loss)
I0905 12:09:58.791312 90901 sgd_solver.cpp:106] Iteration 58540, lr = 0.01
I0905 12:10:04.814982 90901 solver.cpp:228] Iteration 58550, loss = 0.166512
I0905 12:10:04.815022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166514 (* 1 = 0.166514 loss)
I0905 12:10:04.815032 90901 sgd_solver.cpp:106] Iteration 58550, lr = 0.01
I0905 12:10:10.894873 90901 solver.cpp:228] Iteration 58560, loss = 0.144992
I0905 12:10:10.895051 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144993 (* 1 = 0.144993 loss)
I0905 12:10:10.895077 90901 sgd_solver.cpp:106] Iteration 58560, lr = 0.01
I0905 12:10:16.960902 90901 solver.cpp:228] Iteration 58570, loss = 0.227592
I0905 12:10:16.960952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227593 (* 1 = 0.227593 loss)
I0905 12:10:16.960968 90901 sgd_solver.cpp:106] Iteration 58570, lr = 0.01
I0905 12:10:22.814061 90901 solver.cpp:228] Iteration 58580, loss = 0.130653
I0905 12:10:22.814100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130654 (* 1 = 0.130654 loss)
I0905 12:10:22.814112 90901 sgd_solver.cpp:106] Iteration 58580, lr = 0.01
I0905 12:10:28.222368 90901 solver.cpp:228] Iteration 58590, loss = 0.239972
I0905 12:10:28.222407 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239973 (* 1 = 0.239973 loss)
I0905 12:10:28.222419 90901 sgd_solver.cpp:106] Iteration 58590, lr = 0.01
I0905 12:10:33.607815 90901 solver.cpp:228] Iteration 58600, loss = 0.135312
I0905 12:10:33.607869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135314 (* 1 = 0.135314 loss)
I0905 12:10:33.607882 90901 sgd_solver.cpp:106] Iteration 58600, lr = 0.01
I0905 12:10:40.120623 90901 solver.cpp:228] Iteration 58610, loss = 0.175365
I0905 12:10:40.120678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175366 (* 1 = 0.175366 loss)
I0905 12:10:40.120692 90901 sgd_solver.cpp:106] Iteration 58610, lr = 0.01
I0905 12:10:46.459446 90901 solver.cpp:228] Iteration 58620, loss = 0.261497
I0905 12:10:46.459702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261498 (* 1 = 0.261498 loss)
I0905 12:10:46.459718 90901 sgd_solver.cpp:106] Iteration 58620, lr = 0.01
I0905 12:10:52.505085 90901 solver.cpp:228] Iteration 58630, loss = 0.0388013
I0905 12:10:52.505136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0388025 (* 1 = 0.0388025 loss)
I0905 12:10:52.505149 90901 sgd_solver.cpp:106] Iteration 58630, lr = 0.01
I0905 12:10:58.576795 90901 solver.cpp:228] Iteration 58640, loss = 0.213757
I0905 12:10:58.576841 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213758 (* 1 = 0.213758 loss)
I0905 12:10:58.576854 90901 sgd_solver.cpp:106] Iteration 58640, lr = 0.01
I0905 12:11:04.697760 90901 solver.cpp:228] Iteration 58650, loss = 0.144547
I0905 12:11:04.697796 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144549 (* 1 = 0.144549 loss)
I0905 12:11:04.697806 90901 sgd_solver.cpp:106] Iteration 58650, lr = 0.01
I0905 12:11:10.407999 90901 solver.cpp:228] Iteration 58660, loss = 0.0683732
I0905 12:11:10.408041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0683744 (* 1 = 0.0683744 loss)
I0905 12:11:10.408053 90901 sgd_solver.cpp:106] Iteration 58660, lr = 0.01
I0905 12:11:16.763756 90901 solver.cpp:228] Iteration 58670, loss = 0.438875
I0905 12:11:16.763911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438877 (* 1 = 0.438877 loss)
I0905 12:11:16.763939 90901 sgd_solver.cpp:106] Iteration 58670, lr = 0.01
I0905 12:11:22.758143 90901 solver.cpp:228] Iteration 58680, loss = 0.146926
I0905 12:11:22.758203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146927 (* 1 = 0.146927 loss)
I0905 12:11:22.758214 90901 sgd_solver.cpp:106] Iteration 58680, lr = 0.01
I0905 12:11:28.955720 90901 solver.cpp:228] Iteration 58690, loss = 0.0719767
I0905 12:11:28.955761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.071978 (* 1 = 0.071978 loss)
I0905 12:11:28.955772 90901 sgd_solver.cpp:106] Iteration 58690, lr = 0.01
I0905 12:11:35.052734 90901 solver.cpp:228] Iteration 58700, loss = 0.199394
I0905 12:11:35.052784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199395 (* 1 = 0.199395 loss)
I0905 12:11:35.052796 90901 sgd_solver.cpp:106] Iteration 58700, lr = 0.01
I0905 12:11:41.467154 90901 solver.cpp:228] Iteration 58710, loss = 0.603204
I0905 12:11:41.467213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.603205 (* 1 = 0.603205 loss)
I0905 12:11:41.467228 90901 sgd_solver.cpp:106] Iteration 58710, lr = 0.01
I0905 12:11:47.506395 90901 solver.cpp:228] Iteration 58720, loss = 0.105855
I0905 12:11:47.506557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105856 (* 1 = 0.105856 loss)
I0905 19:19:06.141178 90901 sgd_solver.cpp:106] Iteration 58720, lr = 0.01
I0905 19:19:16.815120 90901 solver.cpp:228] Iteration 58730, loss = 0.405189
I0905 19:19:16.815202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40519 (* 1 = 0.40519 loss)
I0905 19:19:16.815219 90901 sgd_solver.cpp:106] Iteration 58730, lr = 0.01
I0905 19:19:28.715483 90901 solver.cpp:228] Iteration 58740, loss = 0.15359
I0905 19:19:28.715548 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153591 (* 1 = 0.153591 loss)
I0905 19:19:28.715566 90901 sgd_solver.cpp:106] Iteration 58740, lr = 0.01
I0905 19:19:45.203514 90901 solver.cpp:228] Iteration 58750, loss = 0.433576
I0905 19:19:45.203738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433577 (* 1 = 0.433577 loss)
I0905 19:19:45.203758 90901 sgd_solver.cpp:106] Iteration 58750, lr = 0.01
I0905 19:20:04.120899 90901 solver.cpp:228] Iteration 58760, loss = 0.333042
I0905 19:20:04.120962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333043 (* 1 = 0.333043 loss)
I0905 19:20:04.120980 90901 sgd_solver.cpp:106] Iteration 58760, lr = 0.01
I0905 19:20:22.991420 90901 solver.cpp:228] Iteration 58770, loss = 0.174806
I0905 19:20:22.991678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174807 (* 1 = 0.174807 loss)
I0905 19:20:22.991700 90901 sgd_solver.cpp:106] Iteration 58770, lr = 0.01
I0905 19:20:42.785208 90901 solver.cpp:228] Iteration 58780, loss = 0.244009
I0905 19:20:42.785307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24401 (* 1 = 0.24401 loss)
I0905 19:20:42.785332 90901 sgd_solver.cpp:106] Iteration 58780, lr = 0.01
I0905 19:21:01.979974 90901 solver.cpp:228] Iteration 58790, loss = 0.218739
I0905 19:21:01.980132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21874 (* 1 = 0.21874 loss)
I0905 19:21:01.980146 90901 sgd_solver.cpp:106] Iteration 58790, lr = 0.01
I0905 19:21:20.009496 90901 solver.cpp:228] Iteration 58800, loss = 0.0823326
I0905 19:21:20.009594 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0823339 (* 1 = 0.0823339 loss)
I0905 19:21:20.009613 90901 sgd_solver.cpp:106] Iteration 58800, lr = 0.01
I0905 19:21:36.949323 90901 solver.cpp:228] Iteration 58810, loss = 0.180158
I0905 19:21:36.949499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180159 (* 1 = 0.180159 loss)
I0905 19:21:36.949533 90901 sgd_solver.cpp:106] Iteration 58810, lr = 0.01
I0905 19:21:53.955018 90901 solver.cpp:228] Iteration 58820, loss = 0.24337
I0905 19:21:53.955086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243371 (* 1 = 0.243371 loss)
I0905 19:21:53.955106 90901 sgd_solver.cpp:106] Iteration 58820, lr = 0.01
I0905 19:22:12.044725 90901 solver.cpp:228] Iteration 58830, loss = 0.337344
I0905 19:22:12.058744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337346 (* 1 = 0.337346 loss)
I0905 19:22:12.058779 90901 sgd_solver.cpp:106] Iteration 58830, lr = 0.01
I0905 19:22:29.766495 90901 solver.cpp:228] Iteration 58840, loss = 0.217343
I0905 19:22:29.766571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217344 (* 1 = 0.217344 loss)
I0905 19:22:29.766589 90901 sgd_solver.cpp:106] Iteration 58840, lr = 0.01
I0905 19:22:43.010579 90901 solver.cpp:228] Iteration 58850, loss = 0.0290653
I0905 19:22:43.010844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0290667 (* 1 = 0.0290667 loss)
I0905 19:22:43.010864 90901 sgd_solver.cpp:106] Iteration 58850, lr = 0.01
I0905 19:22:54.878584 90901 solver.cpp:228] Iteration 58860, loss = 0.129118
I0905 19:22:54.878682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129119 (* 1 = 0.129119 loss)
I0905 19:22:54.878702 90901 sgd_solver.cpp:106] Iteration 58860, lr = 0.01
I0905 19:23:03.684238 90901 solver.cpp:228] Iteration 58870, loss = 0.213953
I0905 19:23:03.684300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213954 (* 1 = 0.213954 loss)
I0905 19:23:03.684312 90901 sgd_solver.cpp:106] Iteration 58870, lr = 0.01
I0905 19:23:12.415604 90901 solver.cpp:228] Iteration 58880, loss = 0.0536722
I0905 19:23:12.415736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0536735 (* 1 = 0.0536735 loss)
I0905 19:23:12.415766 90901 sgd_solver.cpp:106] Iteration 58880, lr = 0.01
I0905 19:23:26.291784 90901 solver.cpp:228] Iteration 58890, loss = 0.151929
I0905 19:23:26.292002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151931 (* 1 = 0.151931 loss)
I0905 19:23:26.292032 90901 sgd_solver.cpp:106] Iteration 58890, lr = 0.01
I0905 19:23:41.544843 90901 solver.cpp:228] Iteration 58900, loss = 0.221526
I0905 19:23:41.544940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221527 (* 1 = 0.221527 loss)
I0905 19:23:41.544965 90901 sgd_solver.cpp:106] Iteration 58900, lr = 0.01
I0905 19:23:57.346019 90901 solver.cpp:228] Iteration 58910, loss = 0.187691
I0905 19:23:57.346228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187692 (* 1 = 0.187692 loss)
I0905 19:23:57.346261 90901 sgd_solver.cpp:106] Iteration 58910, lr = 0.01
I0905 19:24:12.289407 90901 solver.cpp:228] Iteration 58920, loss = 0.500918
I0905 19:24:12.289485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.50092 (* 1 = 0.50092 loss)
I0905 19:24:12.289506 90901 sgd_solver.cpp:106] Iteration 58920, lr = 0.01
I0905 19:24:28.514699 90901 solver.cpp:228] Iteration 58930, loss = 0.0681594
I0905 19:24:28.514894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0681607 (* 1 = 0.0681607 loss)
I0905 19:24:28.514928 90901 sgd_solver.cpp:106] Iteration 58930, lr = 0.01
I0905 19:24:45.067147 90901 solver.cpp:228] Iteration 58940, loss = 0.172358
I0905 19:24:45.067234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17236 (* 1 = 0.17236 loss)
I0905 19:24:45.067252 90901 sgd_solver.cpp:106] Iteration 58940, lr = 0.01
I0905 19:25:01.501426 90901 solver.cpp:228] Iteration 58950, loss = 0.203925
I0905 19:25:01.501626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203926 (* 1 = 0.203926 loss)
I0905 19:25:01.501655 90901 sgd_solver.cpp:106] Iteration 58950, lr = 0.01
I0905 19:25:17.854243 90901 solver.cpp:228] Iteration 58960, loss = 0.115583
I0905 19:25:17.854316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115584 (* 1 = 0.115584 loss)
I0905 19:25:17.854333 90901 sgd_solver.cpp:106] Iteration 58960, lr = 0.01
I0905 19:25:34.520119 90901 solver.cpp:228] Iteration 58970, loss = 0.0468165
I0905 19:25:34.520294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0468178 (* 1 = 0.0468178 loss)
I0905 19:25:34.520330 90901 sgd_solver.cpp:106] Iteration 58970, lr = 0.01
I0905 19:25:48.356370 90901 solver.cpp:228] Iteration 58980, loss = 0.2685
I0905 19:25:48.356427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268501 (* 1 = 0.268501 loss)
I0905 19:25:48.356444 90901 sgd_solver.cpp:106] Iteration 58980, lr = 0.01
I0905 19:26:04.521180 90901 solver.cpp:228] Iteration 58990, loss = 0.117643
I0905 19:26:04.521486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117645 (* 1 = 0.117645 loss)
I0905 19:26:04.521503 90901 sgd_solver.cpp:106] Iteration 58990, lr = 0.01
I0905 19:26:20.142771 90901 solver.cpp:228] Iteration 59000, loss = 0.304196
I0905 19:26:20.142848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304197 (* 1 = 0.304197 loss)
I0905 19:26:20.142868 90901 sgd_solver.cpp:106] Iteration 59000, lr = 0.01
I0905 19:26:36.018244 90901 solver.cpp:228] Iteration 59010, loss = 0.470885
I0905 19:26:36.018457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.470886 (* 1 = 0.470886 loss)
I0905 19:26:36.018476 90901 sgd_solver.cpp:106] Iteration 59010, lr = 0.01
I0905 19:26:51.531045 90901 solver.cpp:228] Iteration 59020, loss = 0.186396
I0905 19:26:51.531118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186397 (* 1 = 0.186397 loss)
I0905 19:26:51.531136 90901 sgd_solver.cpp:106] Iteration 59020, lr = 0.01
I0905 19:27:08.637075 90901 solver.cpp:228] Iteration 59030, loss = 0.0793501
I0905 19:27:08.637238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0793514 (* 1 = 0.0793514 loss)
I0905 19:27:08.637281 90901 sgd_solver.cpp:106] Iteration 59030, lr = 0.01
I0905 19:27:23.139127 90901 solver.cpp:228] Iteration 59040, loss = 0.158307
I0905 19:27:23.139206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158308 (* 1 = 0.158308 loss)
I0905 19:27:23.139225 90901 sgd_solver.cpp:106] Iteration 59040, lr = 0.01
I0905 19:27:37.703672 90901 solver.cpp:228] Iteration 59050, loss = 0.195395
I0905 19:27:37.703742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195396 (* 1 = 0.195396 loss)
I0905 19:27:37.703760 90901 sgd_solver.cpp:106] Iteration 59050, lr = 0.01
I0905 19:27:51.232379 90901 solver.cpp:228] Iteration 59060, loss = 0.257619
I0905 19:27:51.232661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25762 (* 1 = 0.25762 loss)
I0905 19:27:51.232683 90901 sgd_solver.cpp:106] Iteration 59060, lr = 0.01
I0905 19:28:05.501250 90901 solver.cpp:228] Iteration 59070, loss = 0.157083
I0905 19:28:05.501313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157084 (* 1 = 0.157084 loss)
I0905 19:28:05.501332 90901 sgd_solver.cpp:106] Iteration 59070, lr = 0.01
I0905 19:28:19.753062 90901 solver.cpp:228] Iteration 59080, loss = 0.407403
I0905 19:28:19.753135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.407405 (* 1 = 0.407405 loss)
I0905 19:28:19.753160 90901 sgd_solver.cpp:106] Iteration 59080, lr = 0.01
I0905 19:28:34.166371 90901 solver.cpp:228] Iteration 59090, loss = 0.377303
I0905 19:28:34.166558 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377305 (* 1 = 0.377305 loss)
I0905 19:28:34.166580 90901 sgd_solver.cpp:106] Iteration 59090, lr = 0.01
I0905 19:28:49.025094 90901 solver.cpp:228] Iteration 59100, loss = 0.158213
I0905 19:28:49.025169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158214 (* 1 = 0.158214 loss)
I0905 19:28:49.025189 90901 sgd_solver.cpp:106] Iteration 59100, lr = 0.01
I0905 19:29:04.655629 90901 solver.cpp:228] Iteration 59110, loss = 0.0879965
I0905 19:29:04.655782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0879977 (* 1 = 0.0879977 loss)
I0905 19:29:04.655813 90901 sgd_solver.cpp:106] Iteration 59110, lr = 0.01
I0905 19:29:20.809646 90901 solver.cpp:228] Iteration 59120, loss = 0.0812986
I0905 19:29:20.809715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0812998 (* 1 = 0.0812998 loss)
I0905 19:29:20.809732 90901 sgd_solver.cpp:106] Iteration 59120, lr = 0.01
I0905 19:29:37.146378 90901 solver.cpp:228] Iteration 59130, loss = 0.109576
I0905 19:29:37.146538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109577 (* 1 = 0.109577 loss)
I0905 19:29:37.146554 90901 sgd_solver.cpp:106] Iteration 59130, lr = 0.01
I0905 19:29:50.966017 90901 solver.cpp:228] Iteration 59140, loss = 0.562831
I0905 19:29:50.966086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.562832 (* 1 = 0.562832 loss)
I0905 19:29:50.966102 90901 sgd_solver.cpp:106] Iteration 59140, lr = 0.01
I0905 19:30:04.736929 90901 solver.cpp:228] Iteration 59150, loss = 0.123708
I0905 19:30:04.737012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123709 (* 1 = 0.123709 loss)
I0905 19:30:04.737032 90901 sgd_solver.cpp:106] Iteration 59150, lr = 0.01
I0905 19:30:18.916525 90901 solver.cpp:228] Iteration 59160, loss = 0.0292665
I0905 19:30:18.916710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0292676 (* 1 = 0.0292676 loss)
I0905 19:30:18.916739 90901 sgd_solver.cpp:106] Iteration 59160, lr = 0.01
I0905 19:30:33.080507 90901 solver.cpp:228] Iteration 59170, loss = 0.122267
I0905 19:30:33.080575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122268 (* 1 = 0.122268 loss)
I0905 19:30:33.080591 90901 sgd_solver.cpp:106] Iteration 59170, lr = 0.01
I0905 19:30:44.871793 90901 solver.cpp:228] Iteration 59180, loss = 0.0684052
I0905 19:30:44.871906 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684064 (* 1 = 0.0684064 loss)
I0905 19:30:44.871929 90901 sgd_solver.cpp:106] Iteration 59180, lr = 0.01
I0905 19:30:55.261899 90901 solver.cpp:228] Iteration 59190, loss = 0.0940804
I0905 19:30:55.262085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0940816 (* 1 = 0.0940816 loss)
I0905 19:30:55.262106 90901 sgd_solver.cpp:106] Iteration 59190, lr = 0.01
I0905 19:31:05.302777 90901 solver.cpp:337] Iteration 59200, Testing net (#0)
I0905 19:32:48.379971 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.84875
I0905 19:32:48.380149 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.367181 (* 1 = 0.367181 loss)
I0905 19:32:49.223740 90901 solver.cpp:228] Iteration 59200, loss = 0.287952
I0905 19:32:49.223820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287953 (* 1 = 0.287953 loss)
I0905 19:32:49.223844 90901 sgd_solver.cpp:106] Iteration 59200, lr = 0.01
I0905 19:33:03.055668 90901 solver.cpp:228] Iteration 59210, loss = 0.13782
I0905 19:33:03.055742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137821 (* 1 = 0.137821 loss)
I0905 19:33:03.055758 90901 sgd_solver.cpp:106] Iteration 59210, lr = 0.01
I0905 19:33:15.508545 90901 solver.cpp:228] Iteration 59220, loss = 0.308921
I0905 19:33:15.508610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308922 (* 1 = 0.308922 loss)
I0905 19:33:15.508626 90901 sgd_solver.cpp:106] Iteration 59220, lr = 0.01
I0905 19:33:27.347473 90901 solver.cpp:228] Iteration 59230, loss = 0.262583
I0905 19:33:27.347731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262584 (* 1 = 0.262584 loss)
I0905 19:33:27.347749 90901 sgd_solver.cpp:106] Iteration 59230, lr = 0.01
I0905 19:33:39.341509 90901 solver.cpp:228] Iteration 59240, loss = 0.205019
I0905 19:33:39.341579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205021 (* 1 = 0.205021 loss)
I0905 19:33:39.341598 90901 sgd_solver.cpp:106] Iteration 59240, lr = 0.01
I0905 19:33:51.908416 90901 solver.cpp:228] Iteration 59250, loss = 0.134925
I0905 19:33:51.908478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134927 (* 1 = 0.134927 loss)
I0905 19:33:51.908496 90901 sgd_solver.cpp:106] Iteration 59250, lr = 0.01
I0905 19:34:08.566406 90901 solver.cpp:228] Iteration 59260, loss = 0.262552
I0905 19:34:08.566592 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262553 (* 1 = 0.262553 loss)
I0905 19:34:08.566622 90901 sgd_solver.cpp:106] Iteration 59260, lr = 0.01
I0905 19:34:27.537686 90901 solver.cpp:228] Iteration 59270, loss = 0.215793
I0905 19:34:27.537770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215794 (* 1 = 0.215794 loss)
I0905 19:34:27.537792 90901 sgd_solver.cpp:106] Iteration 59270, lr = 0.01
I0905 19:34:45.399983 90901 solver.cpp:228] Iteration 59280, loss = 0.394464
I0905 19:34:45.400215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394465 (* 1 = 0.394465 loss)
I0905 19:34:45.400249 90901 sgd_solver.cpp:106] Iteration 59280, lr = 0.01
I0905 19:35:03.765286 90901 solver.cpp:228] Iteration 59290, loss = 0.137087
I0905 19:35:03.765367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137088 (* 1 = 0.137088 loss)
I0905 19:35:03.765386 90901 sgd_solver.cpp:106] Iteration 59290, lr = 0.01
I0905 19:35:21.218276 90901 solver.cpp:228] Iteration 59300, loss = 0.230334
I0905 19:35:21.218477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230335 (* 1 = 0.230335 loss)
I0905 19:35:21.218508 90901 sgd_solver.cpp:106] Iteration 59300, lr = 0.01
I0905 19:35:40.074154 90901 solver.cpp:228] Iteration 59310, loss = 0.113963
I0905 19:35:40.074234 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113964 (* 1 = 0.113964 loss)
I0905 19:35:40.074256 90901 sgd_solver.cpp:106] Iteration 59310, lr = 0.01
I0905 19:35:58.947000 90901 solver.cpp:228] Iteration 59320, loss = 0.0769242
I0905 19:35:58.947160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0769253 (* 1 = 0.0769253 loss)
I0905 19:35:58.947185 90901 sgd_solver.cpp:106] Iteration 59320, lr = 0.01
I0905 19:36:18.483397 90901 solver.cpp:228] Iteration 59330, loss = 0.0390509
I0905 19:36:18.483481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.039052 (* 1 = 0.039052 loss)
I0905 19:36:18.483501 90901 sgd_solver.cpp:106] Iteration 59330, lr = 0.01
I0905 19:36:38.114820 90901 solver.cpp:228] Iteration 59340, loss = 0.34655
I0905 19:36:38.120160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346551 (* 1 = 0.346551 loss)
I0905 19:36:38.120188 90901 sgd_solver.cpp:106] Iteration 59340, lr = 0.01
I0905 19:36:54.154832 90901 solver.cpp:228] Iteration 59350, loss = 0.487668
I0905 19:36:54.154901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487669 (* 1 = 0.487669 loss)
I0905 19:36:54.154919 90901 sgd_solver.cpp:106] Iteration 59350, lr = 0.01
I0905 19:37:05.565165 90901 solver.cpp:228] Iteration 59360, loss = 0.0513232
I0905 19:37:05.565259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0513244 (* 1 = 0.0513244 loss)
I0905 19:37:05.565281 90901 sgd_solver.cpp:106] Iteration 59360, lr = 0.01
I0905 19:37:22.373564 90901 solver.cpp:228] Iteration 59370, loss = 0.207857
I0905 19:37:22.386703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207859 (* 1 = 0.207859 loss)
I0905 19:37:22.386736 90901 sgd_solver.cpp:106] Iteration 59370, lr = 0.01
I0905 19:37:39.284564 90901 solver.cpp:228] Iteration 59380, loss = 0.0818826
I0905 19:37:39.284636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0818838 (* 1 = 0.0818838 loss)
I0905 19:37:39.284656 90901 sgd_solver.cpp:106] Iteration 59380, lr = 0.01
I0905 19:37:55.890601 90901 solver.cpp:228] Iteration 59390, loss = 0.541225
I0905 19:37:55.890959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541226 (* 1 = 0.541226 loss)
I0905 19:37:55.890985 90901 sgd_solver.cpp:106] Iteration 59390, lr = 0.01
I0905 19:38:14.115052 90901 solver.cpp:228] Iteration 59400, loss = 0.0827467
I0905 19:38:14.115170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0827479 (* 1 = 0.0827479 loss)
I0905 19:38:14.115195 90901 sgd_solver.cpp:106] Iteration 59400, lr = 0.01
I0905 19:38:31.747004 90901 solver.cpp:228] Iteration 59410, loss = 0.118018
I0905 19:38:31.747164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118019 (* 1 = 0.118019 loss)
I0905 19:38:31.747197 90901 sgd_solver.cpp:106] Iteration 59410, lr = 0.01
I0905 19:38:47.595890 90901 solver.cpp:228] Iteration 59420, loss = 0.277785
I0905 19:38:47.595989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277786 (* 1 = 0.277786 loss)
I0905 19:38:47.596014 90901 sgd_solver.cpp:106] Iteration 59420, lr = 0.01
I0905 19:39:04.809888 90901 solver.cpp:228] Iteration 59430, loss = 0.156761
I0905 19:39:04.810142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156763 (* 1 = 0.156763 loss)
I0905 19:39:04.810186 90901 sgd_solver.cpp:106] Iteration 59430, lr = 0.01
I0905 19:39:22.372292 90901 solver.cpp:228] Iteration 59440, loss = 0.247826
I0905 19:39:22.372354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247827 (* 1 = 0.247827 loss)
I0905 19:39:22.372373 90901 sgd_solver.cpp:106] Iteration 59440, lr = 0.01
I0905 19:39:40.607738 90901 solver.cpp:228] Iteration 59450, loss = 0.267743
I0905 19:39:40.609074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267745 (* 1 = 0.267745 loss)
I0905 19:39:40.609107 90901 sgd_solver.cpp:106] Iteration 59450, lr = 0.01
I0905 19:39:57.812036 90901 solver.cpp:228] Iteration 59460, loss = 0.0916257
I0905 19:39:57.812113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0916269 (* 1 = 0.0916269 loss)
I0905 19:39:57.812129 90901 sgd_solver.cpp:106] Iteration 59460, lr = 0.01
I0905 19:40:10.985744 90901 solver.cpp:228] Iteration 59470, loss = 0.121535
I0905 19:40:10.985960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121536 (* 1 = 0.121536 loss)
I0905 19:40:10.985982 90901 sgd_solver.cpp:106] Iteration 59470, lr = 0.01
I0905 19:40:24.626513 90901 solver.cpp:228] Iteration 59480, loss = 0.0755563
I0905 19:40:24.626591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0755576 (* 1 = 0.0755576 loss)
I0905 19:40:24.626616 90901 sgd_solver.cpp:106] Iteration 59480, lr = 0.01
I0905 19:40:38.217594 90901 solver.cpp:228] Iteration 59490, loss = 0.307396
I0905 19:40:38.217672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307397 (* 1 = 0.307397 loss)
I0905 19:40:38.217689 90901 sgd_solver.cpp:106] Iteration 59490, lr = 0.01
I0905 19:40:51.419399 90901 solver.cpp:228] Iteration 59500, loss = 0.157189
I0905 19:40:51.419601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157191 (* 1 = 0.157191 loss)
I0905 19:40:51.419631 90901 sgd_solver.cpp:106] Iteration 59500, lr = 0.01
I0905 19:41:03.873311 90901 solver.cpp:228] Iteration 59510, loss = 0.394419
I0905 19:41:03.873399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394421 (* 1 = 0.394421 loss)
I0905 19:41:03.873417 90901 sgd_solver.cpp:106] Iteration 59510, lr = 0.01
I0905 19:41:16.015563 90901 solver.cpp:228] Iteration 59520, loss = 0.286738
I0905 19:41:16.015669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286739 (* 1 = 0.286739 loss)
I0905 19:41:16.015689 90901 sgd_solver.cpp:106] Iteration 59520, lr = 0.01
I0905 19:41:28.354341 90901 solver.cpp:228] Iteration 59530, loss = 0.0569642
I0905 19:41:28.354523 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0569655 (* 1 = 0.0569655 loss)
I0905 19:41:28.354543 90901 sgd_solver.cpp:106] Iteration 59530, lr = 0.01
I0905 19:41:40.149245 90901 solver.cpp:228] Iteration 59540, loss = 0.462212
I0905 19:41:40.149320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462214 (* 1 = 0.462214 loss)
I0905 19:41:40.149338 90901 sgd_solver.cpp:106] Iteration 59540, lr = 0.01
I0905 19:41:55.548981 90901 solver.cpp:228] Iteration 59550, loss = 0.0547904
I0905 19:41:55.549046 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0547917 (* 1 = 0.0547917 loss)
I0905 19:41:55.549068 90901 sgd_solver.cpp:106] Iteration 59550, lr = 0.01
I0905 19:42:14.496187 90901 solver.cpp:228] Iteration 59560, loss = 0.0908657
I0905 19:42:14.496449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.090867 (* 1 = 0.090867 loss)
I0905 19:42:14.496471 90901 sgd_solver.cpp:106] Iteration 59560, lr = 0.01
I0905 19:42:33.970787 90901 solver.cpp:228] Iteration 59570, loss = 0.214129
I0905 19:42:33.970875 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21413 (* 1 = 0.21413 loss)
I0905 19:42:33.970891 90901 sgd_solver.cpp:106] Iteration 59570, lr = 0.01
I0905 19:42:51.521832 90901 solver.cpp:228] Iteration 59580, loss = 0.155204
I0905 19:42:51.521996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155205 (* 1 = 0.155205 loss)
I0905 19:42:51.522024 90901 sgd_solver.cpp:106] Iteration 59580, lr = 0.01
I0905 19:43:08.158956 90901 solver.cpp:228] Iteration 59590, loss = 0.0443745
I0905 19:43:08.159083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0443758 (* 1 = 0.0443758 loss)
I0905 19:43:08.159107 90901 sgd_solver.cpp:106] Iteration 59590, lr = 0.01
I0905 19:43:24.432461 90901 solver.cpp:228] Iteration 59600, loss = 0.0995749
I0905 19:43:24.432648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0995762 (* 1 = 0.0995762 loss)
I0905 19:43:24.432665 90901 sgd_solver.cpp:106] Iteration 59600, lr = 0.01
I0905 19:43:39.864702 90901 solver.cpp:228] Iteration 59610, loss = 0.250922
I0905 19:43:39.864773 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250923 (* 1 = 0.250923 loss)
I0905 19:43:39.864795 90901 sgd_solver.cpp:106] Iteration 59610, lr = 0.01
I0905 19:43:52.480124 90901 solver.cpp:228] Iteration 59620, loss = 0.111861
I0905 19:43:52.480196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111862 (* 1 = 0.111862 loss)
I0905 19:43:52.480216 90901 sgd_solver.cpp:106] Iteration 59620, lr = 0.01
I0905 19:44:05.170202 90901 solver.cpp:228] Iteration 59630, loss = 0.111891
I0905 19:44:05.170442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111893 (* 1 = 0.111893 loss)
I0905 19:44:05.170465 90901 sgd_solver.cpp:106] Iteration 59630, lr = 0.01
I0905 19:44:17.384516 90901 solver.cpp:228] Iteration 59640, loss = 0.196882
I0905 19:44:17.384603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196884 (* 1 = 0.196884 loss)
I0905 19:44:17.384624 90901 sgd_solver.cpp:106] Iteration 59640, lr = 0.01
I0905 19:44:33.711397 90901 solver.cpp:228] Iteration 59650, loss = 0.153701
I0905 19:44:33.711495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153702 (* 1 = 0.153702 loss)
I0905 19:44:33.711518 90901 sgd_solver.cpp:106] Iteration 59650, lr = 0.01
I0905 19:44:51.666260 90901 solver.cpp:228] Iteration 59660, loss = 0.237865
I0905 19:44:51.666551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237867 (* 1 = 0.237867 loss)
I0905 19:44:51.666574 90901 sgd_solver.cpp:106] Iteration 59660, lr = 0.01
I0905 19:45:11.842213 90901 solver.cpp:228] Iteration 59670, loss = 0.121084
I0905 19:45:11.842311 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121086 (* 1 = 0.121086 loss)
I0905 19:45:11.842342 90901 sgd_solver.cpp:106] Iteration 59670, lr = 0.01
I0905 19:45:30.353643 90901 solver.cpp:228] Iteration 59680, loss = 0.126613
I0905 19:45:30.353847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126615 (* 1 = 0.126615 loss)
I0905 19:45:30.353873 90901 sgd_solver.cpp:106] Iteration 59680, lr = 0.01
I0905 19:45:49.918896 90901 solver.cpp:228] Iteration 59690, loss = 0.0982353
I0905 19:45:49.918968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0982366 (* 1 = 0.0982366 loss)
I0905 19:45:49.918984 90901 sgd_solver.cpp:106] Iteration 59690, lr = 0.01
I0905 19:46:09.687660 90901 solver.cpp:228] Iteration 59700, loss = 0.154047
I0905 19:46:09.687855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154048 (* 1 = 0.154048 loss)
I0905 19:46:09.687882 90901 sgd_solver.cpp:106] Iteration 59700, lr = 0.01
I0905 19:46:28.549720 90901 solver.cpp:228] Iteration 59710, loss = 0.0304244
I0905 19:46:28.549799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0304257 (* 1 = 0.0304257 loss)
I0905 19:46:28.549816 90901 sgd_solver.cpp:106] Iteration 59710, lr = 0.01
I0905 19:46:47.858556 90901 solver.cpp:228] Iteration 59720, loss = 0.243069
I0905 19:46:47.858781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24307 (* 1 = 0.24307 loss)
I0905 19:46:47.858806 90901 sgd_solver.cpp:106] Iteration 59720, lr = 0.01
I0905 19:47:07.603019 90901 solver.cpp:228] Iteration 59730, loss = 0.163714
I0905 19:47:07.603082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163715 (* 1 = 0.163715 loss)
I0905 19:47:07.603096 90901 sgd_solver.cpp:106] Iteration 59730, lr = 0.01
I0905 19:47:25.602903 90901 solver.cpp:228] Iteration 59740, loss = 0.233804
I0905 19:47:25.603116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233805 (* 1 = 0.233805 loss)
I0905 19:47:25.603147 90901 sgd_solver.cpp:106] Iteration 59740, lr = 0.01
I0905 19:47:41.370649 90901 solver.cpp:228] Iteration 59750, loss = 0.356173
I0905 19:47:41.370733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356174 (* 1 = 0.356174 loss)
I0905 19:47:41.370753 90901 sgd_solver.cpp:106] Iteration 59750, lr = 0.01
I0905 19:47:53.813040 90901 solver.cpp:228] Iteration 59760, loss = 0.329815
I0905 19:47:53.813112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329816 (* 1 = 0.329816 loss)
I0905 19:47:53.813129 90901 sgd_solver.cpp:106] Iteration 59760, lr = 0.01
I0905 19:48:09.357478 90901 solver.cpp:228] Iteration 59770, loss = 0.254846
I0905 19:48:09.357645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254847 (* 1 = 0.254847 loss)
I0905 19:48:09.357664 90901 sgd_solver.cpp:106] Iteration 59770, lr = 0.01
I0905 19:48:21.144963 90901 solver.cpp:228] Iteration 59780, loss = 0.168259
I0905 19:48:21.145040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16826 (* 1 = 0.16826 loss)
I0905 19:48:21.145058 90901 sgd_solver.cpp:106] Iteration 59780, lr = 0.01
I0905 19:48:30.442616 90901 solver.cpp:228] Iteration 59790, loss = 0.176104
I0905 19:48:30.442693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176106 (* 1 = 0.176106 loss)
I0905 19:48:30.442709 90901 sgd_solver.cpp:106] Iteration 59790, lr = 0.01
I0905 19:48:41.857331 90901 solver.cpp:228] Iteration 59800, loss = 0.191548
I0905 19:48:41.857534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191549 (* 1 = 0.191549 loss)
I0905 19:48:41.857554 90901 sgd_solver.cpp:106] Iteration 59800, lr = 0.01
I0905 19:48:54.792233 90901 solver.cpp:228] Iteration 59810, loss = 0.152415
I0905 19:48:54.792302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152417 (* 1 = 0.152417 loss)
I0905 19:48:54.792318 90901 sgd_solver.cpp:106] Iteration 59810, lr = 0.01
I0905 19:49:09.158918 90901 solver.cpp:228] Iteration 59820, loss = 0.463425
I0905 19:49:09.158977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463427 (* 1 = 0.463427 loss)
I0905 19:49:09.158992 90901 sgd_solver.cpp:106] Iteration 59820, lr = 0.01
I0905 19:49:25.283356 90901 solver.cpp:228] Iteration 59830, loss = 0.0729052
I0905 19:49:25.283609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0729066 (* 1 = 0.0729066 loss)
I0905 19:49:25.283629 90901 sgd_solver.cpp:106] Iteration 59830, lr = 0.01
I0905 19:49:40.628654 90901 solver.cpp:228] Iteration 59840, loss = 0.0416914
I0905 19:49:40.628722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0416928 (* 1 = 0.0416928 loss)
I0905 19:49:40.628738 90901 sgd_solver.cpp:106] Iteration 59840, lr = 0.01
I0905 19:49:54.712534 90901 solver.cpp:228] Iteration 59850, loss = 0.278666
I0905 19:49:54.712622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278667 (* 1 = 0.278667 loss)
I0905 19:49:54.712642 90901 sgd_solver.cpp:106] Iteration 59850, lr = 0.01
I0905 19:50:02.566342 90901 solver.cpp:228] Iteration 59860, loss = 0.130005
I0905 19:50:02.566517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130006 (* 1 = 0.130006 loss)
I0905 19:50:02.566540 90901 sgd_solver.cpp:106] Iteration 59860, lr = 0.01
I0905 19:50:10.400851 90901 solver.cpp:228] Iteration 59870, loss = 0.212021
I0905 19:50:10.400928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212022 (* 1 = 0.212022 loss)
I0905 19:50:10.400946 90901 sgd_solver.cpp:106] Iteration 59870, lr = 0.01
I0905 19:50:20.243160 90901 solver.cpp:228] Iteration 59880, loss = 0.269769
I0905 19:50:20.243232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269771 (* 1 = 0.269771 loss)
I0905 19:50:20.243250 90901 sgd_solver.cpp:106] Iteration 59880, lr = 0.01
I0905 19:50:31.980319 90901 solver.cpp:228] Iteration 59890, loss = 0.0799924
I0905 19:50:31.980404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0799939 (* 1 = 0.0799939 loss)
I0905 19:50:31.980422 90901 sgd_solver.cpp:106] Iteration 59890, lr = 0.01
I0905 19:50:42.583892 90901 solver.cpp:228] Iteration 59900, loss = 0.0843165
I0905 19:50:42.584126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0843179 (* 1 = 0.0843179 loss)
I0905 19:50:42.584162 90901 sgd_solver.cpp:106] Iteration 59900, lr = 0.01
I0905 19:50:54.311147 90901 solver.cpp:228] Iteration 59910, loss = 0.50728
I0905 19:50:54.311221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507282 (* 1 = 0.507282 loss)
I0905 19:50:54.311239 90901 sgd_solver.cpp:106] Iteration 59910, lr = 0.01
I0905 19:51:06.603296 90901 solver.cpp:228] Iteration 59920, loss = 0.142263
I0905 19:51:06.603377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142264 (* 1 = 0.142264 loss)
I0905 19:51:06.603396 90901 sgd_solver.cpp:106] Iteration 59920, lr = 0.01
I0905 19:51:19.124040 90901 solver.cpp:228] Iteration 59930, loss = 0.391736
I0905 19:51:19.124192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391737 (* 1 = 0.391737 loss)
I0905 19:51:19.124222 90901 sgd_solver.cpp:106] Iteration 59930, lr = 0.01
I0905 19:51:32.483841 90901 solver.cpp:228] Iteration 59940, loss = 0.218745
I0905 19:51:32.483927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218747 (* 1 = 0.218747 loss)
I0905 19:51:32.483949 90901 sgd_solver.cpp:106] Iteration 59940, lr = 0.01
I0905 19:51:47.230779 90901 solver.cpp:228] Iteration 59950, loss = 0.249052
I0905 19:51:47.230859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249053 (* 1 = 0.249053 loss)
I0905 19:51:47.230876 90901 sgd_solver.cpp:106] Iteration 59950, lr = 0.01
I0905 19:52:04.671794 90901 solver.cpp:228] Iteration 59960, loss = 0.170828
I0905 19:52:04.672058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17083 (* 1 = 0.17083 loss)
I0905 19:52:04.672091 90901 sgd_solver.cpp:106] Iteration 59960, lr = 0.01
I0905 19:52:21.084682 90901 solver.cpp:228] Iteration 59970, loss = 0.26503
I0905 19:52:21.084774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265032 (* 1 = 0.265032 loss)
I0905 19:52:21.084796 90901 sgd_solver.cpp:106] Iteration 59970, lr = 0.01
I0905 19:52:39.012024 90901 solver.cpp:228] Iteration 59980, loss = 0.178474
I0905 19:52:39.012339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178475 (* 1 = 0.178475 loss)
I0905 19:52:39.012362 90901 sgd_solver.cpp:106] Iteration 59980, lr = 0.01
I0905 19:52:56.499820 90901 solver.cpp:228] Iteration 59990, loss = 0.365703
I0905 19:52:56.499909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365704 (* 1 = 0.365704 loss)
I0905 19:52:56.499927 90901 sgd_solver.cpp:106] Iteration 59990, lr = 0.01
I0905 19:53:13.729138 90901 solver.cpp:337] Iteration 60000, Testing net (#0)
I0905 19:55:23.899163 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.92875
I0905 19:55:23.899343 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.186189 (* 1 = 0.186189 loss)
I0905 19:55:24.883617 90901 solver.cpp:228] Iteration 60000, loss = 0.281707
I0905 19:55:24.883702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281708 (* 1 = 0.281708 loss)
I0905 19:55:24.883724 90901 sgd_solver.cpp:106] Iteration 60000, lr = 0.01
I0905 19:55:41.741765 90901 solver.cpp:228] Iteration 60010, loss = 0.41371
I0905 19:55:41.741842 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413711 (* 1 = 0.413711 loss)
I0905 19:55:41.741865 90901 sgd_solver.cpp:106] Iteration 60010, lr = 0.01
I0905 19:55:56.830335 90901 solver.cpp:228] Iteration 60020, loss = 0.163152
I0905 19:55:56.830515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163154 (* 1 = 0.163154 loss)
I0905 19:55:56.830529 90901 sgd_solver.cpp:106] Iteration 60020, lr = 0.01
I0905 19:56:08.914484 90901 solver.cpp:228] Iteration 60030, loss = 0.0342046
I0905 19:56:08.914566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0342061 (* 1 = 0.0342061 loss)
I0905 19:56:08.914585 90901 sgd_solver.cpp:106] Iteration 60030, lr = 0.01
I0905 19:56:22.174926 90901 solver.cpp:228] Iteration 60040, loss = 0.386584
I0905 19:56:22.175009 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386585 (* 1 = 0.386585 loss)
I0905 19:56:22.175029 90901 sgd_solver.cpp:106] Iteration 60040, lr = 0.01
I0905 19:56:40.779474 90901 solver.cpp:228] Iteration 60050, loss = 0.132446
I0905 19:56:40.779656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132447 (* 1 = 0.132447 loss)
I0905 19:56:40.779683 90901 sgd_solver.cpp:106] Iteration 60050, lr = 0.01
I0905 19:57:00.038424 90901 solver.cpp:228] Iteration 60060, loss = 0.396827
I0905 19:57:00.038501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396829 (* 1 = 0.396829 loss)
I0905 19:57:00.038522 90901 sgd_solver.cpp:106] Iteration 60060, lr = 0.01
I0905 19:57:19.835124 90901 solver.cpp:228] Iteration 60070, loss = 0.410816
I0905 19:57:19.835345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410818 (* 1 = 0.410818 loss)
I0905 19:57:19.835376 90901 sgd_solver.cpp:106] Iteration 60070, lr = 0.01
I0905 19:57:39.174078 90901 solver.cpp:228] Iteration 60080, loss = 0.0928856
I0905 19:57:39.174144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0928871 (* 1 = 0.0928871 loss)
I0905 19:57:39.174160 90901 sgd_solver.cpp:106] Iteration 60080, lr = 0.01
I0905 19:57:57.201120 90901 solver.cpp:228] Iteration 60090, loss = 0.322608
I0905 19:57:57.201344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32261 (* 1 = 0.32261 loss)
I0905 19:57:57.201380 90901 sgd_solver.cpp:106] Iteration 60090, lr = 0.01
I0905 19:58:18.962880 90901 solver.cpp:228] Iteration 60100, loss = 0.118277
I0905 19:58:18.962954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118279 (* 1 = 0.118279 loss)
I0905 19:58:18.962970 90901 sgd_solver.cpp:106] Iteration 60100, lr = 0.01
I0905 19:58:38.314569 90901 solver.cpp:228] Iteration 60110, loss = 0.167528
I0905 19:58:38.315052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167529 (* 1 = 0.167529 loss)
I0905 19:58:38.315109 90901 sgd_solver.cpp:106] Iteration 60110, lr = 0.01
I0905 19:58:57.619647 90901 solver.cpp:228] Iteration 60120, loss = 0.219274
I0905 19:58:57.619714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219275 (* 1 = 0.219275 loss)
I0905 19:58:57.619734 90901 sgd_solver.cpp:106] Iteration 60120, lr = 0.01
I0905 19:59:16.700902 90901 solver.cpp:228] Iteration 60130, loss = 0.064607
I0905 19:59:16.701071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0646085 (* 1 = 0.0646085 loss)
I0905 19:59:16.701103 90901 sgd_solver.cpp:106] Iteration 60130, lr = 0.01
I0905 19:59:36.641897 90901 solver.cpp:228] Iteration 60140, loss = 0.214095
I0905 19:59:36.641974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214096 (* 1 = 0.214096 loss)
I0905 19:59:36.641991 90901 sgd_solver.cpp:106] Iteration 60140, lr = 0.01
I0905 19:59:55.815057 90901 solver.cpp:228] Iteration 60150, loss = 0.28282
I0905 19:59:55.815256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282822 (* 1 = 0.282822 loss)
I0905 19:59:55.815286 90901 sgd_solver.cpp:106] Iteration 60150, lr = 0.01
I0905 20:00:14.456768 90901 solver.cpp:228] Iteration 60160, loss = 0.365201
I0905 20:00:14.456851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365203 (* 1 = 0.365203 loss)
I0905 20:00:14.456871 90901 sgd_solver.cpp:106] Iteration 60160, lr = 0.01
I0905 20:00:34.732758 90901 solver.cpp:228] Iteration 60170, loss = 0.128481
I0905 20:00:34.732925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128483 (* 1 = 0.128483 loss)
I0905 20:00:34.732947 90901 sgd_solver.cpp:106] Iteration 60170, lr = 0.01
I0905 20:00:53.506069 90901 solver.cpp:228] Iteration 60180, loss = 0.224503
I0905 20:00:53.506166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224505 (* 1 = 0.224505 loss)
I0905 20:00:53.506191 90901 sgd_solver.cpp:106] Iteration 60180, lr = 0.01
I0905 20:01:14.410079 90901 solver.cpp:228] Iteration 60190, loss = 0.296493
I0905 20:01:14.410270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296494 (* 1 = 0.296494 loss)
I0905 20:01:14.410302 90901 sgd_solver.cpp:106] Iteration 60190, lr = 0.01
I0905 20:01:25.440551 90901 solver.cpp:228] Iteration 60200, loss = 0.380394
I0905 20:01:25.440614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380396 (* 1 = 0.380396 loss)
I0905 20:01:25.440630 90901 sgd_solver.cpp:106] Iteration 60200, lr = 0.01
I0905 20:01:38.453383 90901 solver.cpp:228] Iteration 60210, loss = 0.25334
I0905 20:01:38.453486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253342 (* 1 = 0.253342 loss)
I0905 20:01:38.453505 90901 sgd_solver.cpp:106] Iteration 60210, lr = 0.01
I0905 20:01:49.509904 90901 solver.cpp:228] Iteration 60220, loss = 0.158329
I0905 20:01:49.510071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158331 (* 1 = 0.158331 loss)
I0905 20:01:49.510104 90901 sgd_solver.cpp:106] Iteration 60220, lr = 0.01
I0905 20:02:02.119825 90901 solver.cpp:228] Iteration 60230, loss = 0.0812115
I0905 20:02:02.119889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0812129 (* 1 = 0.0812129 loss)
I0905 20:02:02.119910 90901 sgd_solver.cpp:106] Iteration 60230, lr = 0.01
I0905 20:02:15.243734 90901 solver.cpp:228] Iteration 60240, loss = 0.0605924
I0905 20:02:15.243813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0605939 (* 1 = 0.0605939 loss)
I0905 20:02:15.243830 90901 sgd_solver.cpp:106] Iteration 60240, lr = 0.01
I0905 20:02:31.622961 90901 solver.cpp:228] Iteration 60250, loss = 0.122902
I0905 20:02:31.623301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122903 (* 1 = 0.122903 loss)
I0905 20:02:31.623332 90901 sgd_solver.cpp:106] Iteration 60250, lr = 0.01
I0905 20:02:49.421584 90901 solver.cpp:228] Iteration 60260, loss = 0.172256
I0905 20:02:49.421684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172258 (* 1 = 0.172258 loss)
I0905 20:02:49.421705 90901 sgd_solver.cpp:106] Iteration 60260, lr = 0.01
I0905 20:03:07.846609 90901 solver.cpp:228] Iteration 60270, loss = 0.177041
I0905 20:03:07.846882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177043 (* 1 = 0.177043 loss)
I0905 20:03:07.846911 90901 sgd_solver.cpp:106] Iteration 60270, lr = 0.01
I0905 20:03:25.118623 90901 solver.cpp:228] Iteration 60280, loss = 0.0756238
I0905 20:03:25.118711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0756253 (* 1 = 0.0756253 loss)
I0905 20:03:25.118732 90901 sgd_solver.cpp:106] Iteration 60280, lr = 0.01
I0905 20:03:41.738713 90901 solver.cpp:228] Iteration 60290, loss = 0.0540127
I0905 20:03:41.738983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0540142 (* 1 = 0.0540142 loss)
I0905 20:03:41.739004 90901 sgd_solver.cpp:106] Iteration 60290, lr = 0.01
I0905 20:03:55.145675 90901 solver.cpp:228] Iteration 60300, loss = 0.258202
I0905 20:03:55.145777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258203 (* 1 = 0.258203 loss)
I0905 20:03:55.145799 90901 sgd_solver.cpp:106] Iteration 60300, lr = 0.01
I0905 20:04:07.283370 90901 solver.cpp:228] Iteration 60310, loss = 0.267022
I0905 20:04:07.283457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267023 (* 1 = 0.267023 loss)
I0905 20:04:07.283475 90901 sgd_solver.cpp:106] Iteration 60310, lr = 0.01
I0905 20:04:18.859987 90901 solver.cpp:228] Iteration 60320, loss = 0.203004
I0905 20:04:18.860167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203006 (* 1 = 0.203006 loss)
I0905 20:04:18.860198 90901 sgd_solver.cpp:106] Iteration 60320, lr = 0.01
I0905 20:04:34.849236 90901 solver.cpp:228] Iteration 60330, loss = 0.173225
I0905 20:04:34.849324 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173227 (* 1 = 0.173227 loss)
I0905 20:04:34.849345 90901 sgd_solver.cpp:106] Iteration 60330, lr = 0.01
I0905 20:04:53.192165 90901 solver.cpp:228] Iteration 60340, loss = 0.102245
I0905 20:04:53.192363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102247 (* 1 = 0.102247 loss)
I0905 20:04:53.192396 90901 sgd_solver.cpp:106] Iteration 60340, lr = 0.01
I0905 20:05:10.063959 90901 solver.cpp:228] Iteration 60350, loss = 0.515502
I0905 20:05:10.064054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515503 (* 1 = 0.515503 loss)
I0905 20:05:10.064074 90901 sgd_solver.cpp:106] Iteration 60350, lr = 0.01
I0905 20:05:29.514432 90901 solver.cpp:228] Iteration 60360, loss = 0.153746
I0905 20:05:29.514722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153747 (* 1 = 0.153747 loss)
I0905 20:05:29.514746 90901 sgd_solver.cpp:106] Iteration 60360, lr = 0.01
I0905 20:05:47.304939 90901 solver.cpp:228] Iteration 60370, loss = 0.0875532
I0905 20:05:47.305021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0875547 (* 1 = 0.0875547 loss)
I0905 20:05:47.305039 90901 sgd_solver.cpp:106] Iteration 60370, lr = 0.01
I0905 20:06:06.898732 90901 solver.cpp:228] Iteration 60380, loss = 0.0334893
I0905 20:06:06.898939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0334908 (* 1 = 0.0334908 loss)
I0905 20:06:06.898957 90901 sgd_solver.cpp:106] Iteration 60380, lr = 0.01
I0905 20:06:25.054563 90901 solver.cpp:228] Iteration 60390, loss = 0.0527887
I0905 20:06:25.054631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0527902 (* 1 = 0.0527902 loss)
I0905 20:06:25.054656 90901 sgd_solver.cpp:106] Iteration 60390, lr = 0.01
I0905 20:06:43.732934 90901 solver.cpp:228] Iteration 60400, loss = 0.310493
I0905 20:06:43.733206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310495 (* 1 = 0.310495 loss)
I0905 20:06:43.733240 90901 sgd_solver.cpp:106] Iteration 60400, lr = 0.01
I0905 20:07:03.801476 90901 solver.cpp:228] Iteration 60410, loss = 0.36545
I0905 20:07:03.801566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.365452 (* 1 = 0.365452 loss)
I0905 20:07:03.801589 90901 sgd_solver.cpp:106] Iteration 60410, lr = 0.01
I0905 20:07:23.133986 90901 solver.cpp:228] Iteration 60420, loss = 0.443671
I0905 20:07:23.134157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.443672 (* 1 = 0.443672 loss)
I0905 20:07:23.134191 90901 sgd_solver.cpp:106] Iteration 60420, lr = 0.01
I0905 20:07:41.471989 90901 solver.cpp:228] Iteration 60430, loss = 0.228554
I0905 20:07:41.472126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228555 (* 1 = 0.228555 loss)
I0905 20:07:41.472153 90901 sgd_solver.cpp:106] Iteration 60430, lr = 0.01
I0905 20:08:00.939574 90901 solver.cpp:228] Iteration 60440, loss = 0.341235
I0905 20:08:00.939800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341236 (* 1 = 0.341236 loss)
I0905 20:08:00.939831 90901 sgd_solver.cpp:106] Iteration 60440, lr = 0.01
I0905 20:08:20.212182 90901 solver.cpp:228] Iteration 60450, loss = 0.190143
I0905 20:08:20.212294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190144 (* 1 = 0.190144 loss)
I0905 20:08:20.212323 90901 sgd_solver.cpp:106] Iteration 60450, lr = 0.01
I0905 20:08:37.104257 90901 solver.cpp:228] Iteration 60460, loss = 0.169286
I0905 20:08:37.104445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169287 (* 1 = 0.169287 loss)
I0905 20:08:37.104480 90901 sgd_solver.cpp:106] Iteration 60460, lr = 0.01
I0905 20:08:55.145812 90901 solver.cpp:228] Iteration 60470, loss = 0.258148
I0905 20:08:55.145908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25815 (* 1 = 0.25815 loss)
I0905 20:08:55.145934 90901 sgd_solver.cpp:106] Iteration 60470, lr = 0.01
I0905 20:09:13.798311 90901 solver.cpp:228] Iteration 60480, loss = 0.0795842
I0905 20:09:13.798528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0795857 (* 1 = 0.0795857 loss)
I0905 20:09:13.798554 90901 sgd_solver.cpp:106] Iteration 60480, lr = 0.01
I0905 20:09:32.747189 90901 solver.cpp:228] Iteration 60490, loss = 0.419455
I0905 20:09:32.747265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419456 (* 1 = 0.419456 loss)
I0905 20:09:32.747282 90901 sgd_solver.cpp:106] Iteration 60490, lr = 0.01
I0905 20:09:51.084568 90901 solver.cpp:228] Iteration 60500, loss = 0.156107
I0905 20:09:51.084794 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156108 (* 1 = 0.156108 loss)
I0905 20:09:51.084825 90901 sgd_solver.cpp:106] Iteration 60500, lr = 0.01
I0905 20:10:09.383345 90901 solver.cpp:228] Iteration 60510, loss = 0.0304257
I0905 20:10:09.383421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0304271 (* 1 = 0.0304271 loss)
I0905 20:10:09.383441 90901 sgd_solver.cpp:106] Iteration 60510, lr = 0.01
I0905 20:10:28.226236 90901 solver.cpp:228] Iteration 60520, loss = 0.182395
I0905 20:10:28.226433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182396 (* 1 = 0.182396 loss)
I0905 20:10:28.226464 90901 sgd_solver.cpp:106] Iteration 60520, lr = 0.01
I0905 20:10:47.218253 90901 solver.cpp:228] Iteration 60530, loss = 0.108067
I0905 20:10:47.218332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108069 (* 1 = 0.108069 loss)
I0905 20:10:47.218353 90901 sgd_solver.cpp:106] Iteration 60530, lr = 0.01
I0905 20:11:06.506739 90901 solver.cpp:228] Iteration 60540, loss = 0.146294
I0905 20:11:06.506958 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146296 (* 1 = 0.146296 loss)
I0905 20:11:06.506989 90901 sgd_solver.cpp:106] Iteration 60540, lr = 0.01
I0905 20:11:27.422591 90901 solver.cpp:228] Iteration 60550, loss = 0.310036
I0905 20:11:27.422685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310037 (* 1 = 0.310037 loss)
I0905 20:11:27.422703 90901 sgd_solver.cpp:106] Iteration 60550, lr = 0.01
I0905 20:11:49.329181 90901 solver.cpp:228] Iteration 60560, loss = 0.438472
I0905 20:11:49.329475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438473 (* 1 = 0.438473 loss)
I0905 20:11:49.329507 90901 sgd_solver.cpp:106] Iteration 60560, lr = 0.01
I0905 20:12:10.585808 90901 solver.cpp:228] Iteration 60570, loss = 0.0743893
I0905 20:12:10.585886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0743908 (* 1 = 0.0743908 loss)
I0905 20:12:10.585898 90901 sgd_solver.cpp:106] Iteration 60570, lr = 0.01
I0905 20:12:29.355937 90901 solver.cpp:228] Iteration 60580, loss = 0.287957
I0905 20:12:29.356137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287958 (* 1 = 0.287958 loss)
I0905 20:12:29.356166 90901 sgd_solver.cpp:106] Iteration 60580, lr = 0.01
I0905 20:12:49.968211 90901 solver.cpp:228] Iteration 60590, loss = 0.203039
I0905 20:12:49.968281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20304 (* 1 = 0.20304 loss)
I0905 20:12:49.968300 90901 sgd_solver.cpp:106] Iteration 60590, lr = 0.01
I0905 20:13:09.846714 90901 solver.cpp:228] Iteration 60600, loss = 0.231887
I0905 20:13:09.846884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231888 (* 1 = 0.231888 loss)
I0905 20:13:09.846936 90901 sgd_solver.cpp:106] Iteration 60600, lr = 0.01
I0905 20:13:30.023622 90901 solver.cpp:228] Iteration 60610, loss = 0.10583
I0905 20:13:30.023711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105831 (* 1 = 0.105831 loss)
I0905 20:13:30.023736 90901 sgd_solver.cpp:106] Iteration 60610, lr = 0.01
I0905 20:13:49.737002 90901 solver.cpp:228] Iteration 60620, loss = 0.423279
I0905 20:13:49.737233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.423281 (* 1 = 0.423281 loss)
I0905 20:13:49.737257 90901 sgd_solver.cpp:106] Iteration 60620, lr = 0.01
I0905 20:14:03.934212 90901 solver.cpp:228] Iteration 60630, loss = 0.221046
I0905 20:14:03.934279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221047 (* 1 = 0.221047 loss)
I0905 20:14:03.934298 90901 sgd_solver.cpp:106] Iteration 60630, lr = 0.01
I0905 20:14:14.791700 90901 solver.cpp:228] Iteration 60640, loss = 0.140814
I0905 20:14:14.791790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140815 (* 1 = 0.140815 loss)
I0905 20:14:14.791810 90901 sgd_solver.cpp:106] Iteration 60640, lr = 0.01
I0905 20:14:31.872282 90901 solver.cpp:228] Iteration 60650, loss = 0.2598
I0905 20:14:31.872434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259801 (* 1 = 0.259801 loss)
I0905 20:14:31.872468 90901 sgd_solver.cpp:106] Iteration 60650, lr = 0.01
I0905 20:14:47.759316 90901 solver.cpp:228] Iteration 60660, loss = 0.132578
I0905 20:14:47.759395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132579 (* 1 = 0.132579 loss)
I0905 20:14:47.759415 90901 sgd_solver.cpp:106] Iteration 60660, lr = 0.01
I0905 20:14:59.463922 90901 solver.cpp:228] Iteration 60670, loss = 0.0695244
I0905 20:14:59.464011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.069526 (* 1 = 0.069526 loss)
I0905 20:14:59.464037 90901 sgd_solver.cpp:106] Iteration 60670, lr = 0.01
I0905 20:15:09.560855 90901 solver.cpp:228] Iteration 60680, loss = 0.116479
I0905 20:15:09.570758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116481 (* 1 = 0.116481 loss)
I0905 20:15:09.570773 90901 sgd_solver.cpp:106] Iteration 60680, lr = 0.01
I0905 20:15:20.083698 90901 solver.cpp:228] Iteration 60690, loss = 0.106367
I0905 20:15:20.083809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106368 (* 1 = 0.106368 loss)
I0905 20:15:20.083837 90901 sgd_solver.cpp:106] Iteration 60690, lr = 0.01
I0905 20:15:31.430917 90901 solver.cpp:228] Iteration 60700, loss = 0.0368955
I0905 20:15:31.430990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0368971 (* 1 = 0.0368971 loss)
I0905 20:15:31.431008 90901 sgd_solver.cpp:106] Iteration 60700, lr = 0.01
I0905 20:15:42.589944 90901 solver.cpp:228] Iteration 60710, loss = 0.416654
I0905 20:15:42.590147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416655 (* 1 = 0.416655 loss)
I0905 20:15:42.590176 90901 sgd_solver.cpp:106] Iteration 60710, lr = 0.01
I0905 20:15:54.630595 90901 solver.cpp:228] Iteration 60720, loss = 0.157094
I0905 20:15:54.630679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157096 (* 1 = 0.157096 loss)
I0905 20:15:54.630698 90901 sgd_solver.cpp:106] Iteration 60720, lr = 0.01
I0905 20:16:07.972548 90901 solver.cpp:228] Iteration 60730, loss = 0.195979
I0905 20:16:07.972630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19598 (* 1 = 0.19598 loss)
I0905 20:16:07.972645 90901 sgd_solver.cpp:106] Iteration 60730, lr = 0.01
I0905 20:16:20.163233 90901 solver.cpp:228] Iteration 60740, loss = 0.182636
I0905 20:16:20.163429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182637 (* 1 = 0.182637 loss)
I0905 20:16:20.163452 90901 sgd_solver.cpp:106] Iteration 60740, lr = 0.01
I0905 20:16:33.301275 90901 solver.cpp:228] Iteration 60750, loss = 0.107142
I0905 20:16:33.301373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107143 (* 1 = 0.107143 loss)
I0905 20:16:33.301393 90901 sgd_solver.cpp:106] Iteration 60750, lr = 0.01
I0905 20:16:45.537935 90901 solver.cpp:228] Iteration 60760, loss = 0.256738
I0905 20:16:45.538039 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256739 (* 1 = 0.256739 loss)
I0905 20:16:45.538058 90901 sgd_solver.cpp:106] Iteration 60760, lr = 0.01
I0905 20:16:58.193619 90901 solver.cpp:228] Iteration 60770, loss = 0.244341
I0905 20:16:58.193783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244342 (* 1 = 0.244342 loss)
I0905 20:16:58.193805 90901 sgd_solver.cpp:106] Iteration 60770, lr = 0.01
I0905 20:17:09.885557 90901 solver.cpp:228] Iteration 60780, loss = 0.469071
I0905 20:17:09.885624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469072 (* 1 = 0.469072 loss)
I0905 20:17:09.885644 90901 sgd_solver.cpp:106] Iteration 60780, lr = 0.01
I0905 20:17:20.504443 90901 solver.cpp:228] Iteration 60790, loss = 0.138868
I0905 20:17:20.504541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138869 (* 1 = 0.138869 loss)
I0905 20:17:20.504559 90901 sgd_solver.cpp:106] Iteration 60790, lr = 0.01
I0905 20:17:31.718863 90901 solver.cpp:337] Iteration 60800, Testing net (#0)
I0905 20:19:10.926232 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.810313
I0905 20:19:10.934721 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.473604 (* 1 = 0.473604 loss)
I0905 20:19:11.592267 90901 solver.cpp:228] Iteration 60800, loss = 0.333068
I0905 20:19:11.592335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33307 (* 1 = 0.33307 loss)
I0905 20:19:11.592355 90901 sgd_solver.cpp:106] Iteration 60800, lr = 0.01
I0905 20:19:27.564206 90901 solver.cpp:228] Iteration 60810, loss = 0.267359
I0905 20:19:27.564270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26736 (* 1 = 0.26736 loss)
I0905 20:19:27.564288 90901 sgd_solver.cpp:106] Iteration 60810, lr = 0.01
I0905 20:19:44.464632 90901 solver.cpp:228] Iteration 60820, loss = 0.102776
I0905 20:19:44.464839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102778 (* 1 = 0.102778 loss)
I0905 20:19:44.464869 90901 sgd_solver.cpp:106] Iteration 60820, lr = 0.01
I0905 20:19:59.194015 90901 solver.cpp:228] Iteration 60830, loss = 0.187835
I0905 20:19:59.194123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187837 (* 1 = 0.187837 loss)
I0905 20:19:59.194154 90901 sgd_solver.cpp:106] Iteration 60830, lr = 0.01
I0905 20:20:16.208608 90901 solver.cpp:228] Iteration 60840, loss = 0.140975
I0905 20:20:16.208880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140977 (* 1 = 0.140977 loss)
I0905 20:20:16.208895 90901 sgd_solver.cpp:106] Iteration 60840, lr = 0.01
I0905 20:20:31.054164 90901 solver.cpp:228] Iteration 60850, loss = 0.0161814
I0905 20:20:31.054244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0161829 (* 1 = 0.0161829 loss)
I0905 20:20:31.054261 90901 sgd_solver.cpp:106] Iteration 60850, lr = 0.01
I0905 20:20:47.543213 90901 solver.cpp:228] Iteration 60860, loss = 0.156527
I0905 20:20:47.543387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156529 (* 1 = 0.156529 loss)
I0905 20:20:47.543419 90901 sgd_solver.cpp:106] Iteration 60860, lr = 0.01
I0905 20:21:03.930977 90901 solver.cpp:228] Iteration 60870, loss = 0.0706096
I0905 20:21:03.931043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0706111 (* 1 = 0.0706111 loss)
I0905 20:21:03.931056 90901 sgd_solver.cpp:106] Iteration 60870, lr = 0.01
I0905 20:21:21.982455 90901 solver.cpp:228] Iteration 60880, loss = 0.0907934
I0905 20:21:21.982653 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0907949 (* 1 = 0.0907949 loss)
I0905 20:21:21.982687 90901 sgd_solver.cpp:106] Iteration 60880, lr = 0.01
I0905 20:21:38.980041 90901 solver.cpp:228] Iteration 60890, loss = 0.131629
I0905 20:21:38.980129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13163 (* 1 = 0.13163 loss)
I0905 20:21:38.980149 90901 sgd_solver.cpp:106] Iteration 60890, lr = 0.01
I0905 20:21:55.329649 90901 solver.cpp:228] Iteration 60900, loss = 0.131516
I0905 20:21:55.329870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131518 (* 1 = 0.131518 loss)
I0905 20:21:55.329908 90901 sgd_solver.cpp:106] Iteration 60900, lr = 0.01
I0905 20:22:11.051636 90901 solver.cpp:228] Iteration 60910, loss = 0.128271
I0905 20:22:11.051713 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128273 (* 1 = 0.128273 loss)
I0905 20:22:11.051735 90901 sgd_solver.cpp:106] Iteration 60910, lr = 0.01
I0905 20:22:28.327543 90901 solver.cpp:228] Iteration 60920, loss = 0.20484
I0905 20:22:28.327703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204841 (* 1 = 0.204841 loss)
I0905 20:22:28.327738 90901 sgd_solver.cpp:106] Iteration 60920, lr = 0.01
I0905 20:22:45.315583 90901 solver.cpp:228] Iteration 60930, loss = 0.119663
I0905 20:22:45.315663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119665 (* 1 = 0.119665 loss)
I0905 20:22:45.315683 90901 sgd_solver.cpp:106] Iteration 60930, lr = 0.01
I0905 20:23:02.011072 90901 solver.cpp:228] Iteration 60940, loss = 0.0710023
I0905 20:23:02.011319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0710036 (* 1 = 0.0710036 loss)
I0905 20:23:02.011348 90901 sgd_solver.cpp:106] Iteration 60940, lr = 0.01
I0905 20:23:19.938659 90901 solver.cpp:228] Iteration 60950, loss = 0.127701
I0905 20:23:19.938750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127702 (* 1 = 0.127702 loss)
I0905 20:23:19.938767 90901 sgd_solver.cpp:106] Iteration 60950, lr = 0.01
I0905 20:23:37.195123 90901 solver.cpp:228] Iteration 60960, loss = 0.0943457
I0905 20:23:37.195317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.094347 (* 1 = 0.094347 loss)
I0905 20:23:37.195346 90901 sgd_solver.cpp:106] Iteration 60960, lr = 0.01
I0905 20:23:53.487257 90901 solver.cpp:228] Iteration 60970, loss = 0.101115
I0905 20:23:53.487337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101116 (* 1 = 0.101116 loss)
I0905 20:23:53.487355 90901 sgd_solver.cpp:106] Iteration 60970, lr = 0.01
I0905 20:24:10.211779 90901 solver.cpp:228] Iteration 60980, loss = 0.256086
I0905 20:24:10.211966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256087 (* 1 = 0.256087 loss)
I0905 20:24:10.211987 90901 sgd_solver.cpp:106] Iteration 60980, lr = 0.01
I0905 20:24:28.037139 90901 solver.cpp:228] Iteration 60990, loss = 0.106718
I0905 20:24:28.037248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10672 (* 1 = 0.10672 loss)
I0905 20:24:28.037268 90901 sgd_solver.cpp:106] Iteration 60990, lr = 0.01
I0905 20:24:46.500186 90901 solver.cpp:228] Iteration 61000, loss = 0.122896
I0905 20:24:46.500429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122898 (* 1 = 0.122898 loss)
I0905 20:24:46.500452 90901 sgd_solver.cpp:106] Iteration 61000, lr = 0.01
I0905 20:25:02.751315 90901 solver.cpp:228] Iteration 61010, loss = 0.0913933
I0905 20:25:02.751427 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0913947 (* 1 = 0.0913947 loss)
I0905 20:25:02.751451 90901 sgd_solver.cpp:106] Iteration 61010, lr = 0.01
I0905 20:25:21.748167 90901 solver.cpp:228] Iteration 61020, loss = 0.143809
I0905 20:25:21.748369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14381 (* 1 = 0.14381 loss)
I0905 20:25:21.748399 90901 sgd_solver.cpp:106] Iteration 61020, lr = 0.01
I0905 20:25:38.420047 90901 solver.cpp:228] Iteration 61030, loss = 0.390447
I0905 20:25:38.420166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390448 (* 1 = 0.390448 loss)
I0905 20:25:38.420205 90901 sgd_solver.cpp:106] Iteration 61030, lr = 0.01
I0905 20:25:56.676426 90901 solver.cpp:228] Iteration 61040, loss = 0.166771
I0905 20:25:56.676627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166772 (* 1 = 0.166772 loss)
I0905 20:25:56.676661 90901 sgd_solver.cpp:106] Iteration 61040, lr = 0.01
I0905 20:26:13.433145 90901 solver.cpp:228] Iteration 61050, loss = 0.131771
I0905 20:26:13.433241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131773 (* 1 = 0.131773 loss)
I0905 20:26:13.433259 90901 sgd_solver.cpp:106] Iteration 61050, lr = 0.01
I0905 20:26:29.863984 90901 solver.cpp:228] Iteration 61060, loss = 0.468007
I0905 20:26:29.864126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468008 (* 1 = 0.468008 loss)
I0905 20:26:29.864167 90901 sgd_solver.cpp:106] Iteration 61060, lr = 0.01
I0905 20:26:46.786679 90901 solver.cpp:228] Iteration 61070, loss = 0.148584
I0905 20:26:46.786754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148585 (* 1 = 0.148585 loss)
I0905 20:26:46.786770 90901 sgd_solver.cpp:106] Iteration 61070, lr = 0.01
I0905 20:27:03.995347 90901 solver.cpp:228] Iteration 61080, loss = 0.298408
I0905 20:27:03.995533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298409 (* 1 = 0.298409 loss)
I0905 20:27:03.995558 90901 sgd_solver.cpp:106] Iteration 61080, lr = 0.01
I0905 20:27:20.491120 90901 solver.cpp:228] Iteration 61090, loss = 0.129797
I0905 20:27:20.491206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129798 (* 1 = 0.129798 loss)
I0905 20:27:20.491227 90901 sgd_solver.cpp:106] Iteration 61090, lr = 0.01
I0905 20:27:38.706028 90901 solver.cpp:228] Iteration 61100, loss = 0.107115
I0905 20:27:38.706236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107116 (* 1 = 0.107116 loss)
I0905 20:27:38.706274 90901 sgd_solver.cpp:106] Iteration 61100, lr = 0.01
I0905 20:27:56.515422 90901 solver.cpp:228] Iteration 61110, loss = 0.196246
I0905 20:27:56.515491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196247 (* 1 = 0.196247 loss)
I0905 20:27:56.515511 90901 sgd_solver.cpp:106] Iteration 61110, lr = 0.01
I0905 20:28:12.665541 90901 solver.cpp:228] Iteration 61120, loss = 0.690573
I0905 20:28:12.665871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.690575 (* 1 = 0.690575 loss)
I0905 20:28:12.665935 90901 sgd_solver.cpp:106] Iteration 61120, lr = 0.01
I0905 20:28:32.073693 90901 solver.cpp:228] Iteration 61130, loss = 0.070185
I0905 20:28:32.073776 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0701864 (* 1 = 0.0701864 loss)
I0905 20:28:32.073794 90901 sgd_solver.cpp:106] Iteration 61130, lr = 0.01
I0905 20:28:49.144660 90901 solver.cpp:228] Iteration 61140, loss = 0.192649
I0905 20:28:49.144927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192651 (* 1 = 0.192651 loss)
I0905 20:28:49.144958 90901 sgd_solver.cpp:106] Iteration 61140, lr = 0.01
I0905 20:29:07.144525 90901 solver.cpp:228] Iteration 61150, loss = 0.18672
I0905 20:29:07.144594 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186721 (* 1 = 0.186721 loss)
I0905 20:29:07.144613 90901 sgd_solver.cpp:106] Iteration 61150, lr = 0.01
I0905 20:29:23.200959 90901 solver.cpp:228] Iteration 61160, loss = 0.374743
I0905 20:29:23.201118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374744 (* 1 = 0.374744 loss)
I0905 20:29:23.201146 90901 sgd_solver.cpp:106] Iteration 61160, lr = 0.01
I0905 20:29:38.678844 90901 solver.cpp:228] Iteration 61170, loss = 0.313005
I0905 20:29:38.678930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313006 (* 1 = 0.313006 loss)
I0905 20:29:38.678949 90901 sgd_solver.cpp:106] Iteration 61170, lr = 0.01
I0905 20:29:53.063560 90901 solver.cpp:228] Iteration 61180, loss = 0.162497
I0905 20:29:53.063638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162498 (* 1 = 0.162498 loss)
I0905 20:29:53.063664 90901 sgd_solver.cpp:106] Iteration 61180, lr = 0.01
I0905 20:30:05.042491 90901 solver.cpp:228] Iteration 61190, loss = 0.392862
I0905 20:30:05.042680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.392863 (* 1 = 0.392863 loss)
I0905 20:30:05.042698 90901 sgd_solver.cpp:106] Iteration 61190, lr = 0.01
I0905 20:30:18.108853 90901 solver.cpp:228] Iteration 61200, loss = 0.193499
I0905 20:30:18.108960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1935 (* 1 = 0.1935 loss)
I0905 20:30:18.108994 90901 sgd_solver.cpp:106] Iteration 61200, lr = 0.01
I0905 20:30:28.540446 90901 solver.cpp:228] Iteration 61210, loss = 0.577198
I0905 20:30:28.540668 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.577199 (* 1 = 0.577199 loss)
I0905 20:30:28.540702 90901 sgd_solver.cpp:106] Iteration 61210, lr = 0.01
I0905 20:30:39.761754 90901 solver.cpp:228] Iteration 61220, loss = 0.196245
I0905 20:30:39.761973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196246 (* 1 = 0.196246 loss)
I0905 20:30:39.761996 90901 sgd_solver.cpp:106] Iteration 61220, lr = 0.01
I0905 20:30:50.629549 90901 solver.cpp:228] Iteration 61230, loss = 0.547337
I0905 20:30:50.629637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547338 (* 1 = 0.547338 loss)
I0905 20:30:50.629653 90901 sgd_solver.cpp:106] Iteration 61230, lr = 0.01
I0905 20:30:59.614373 90901 solver.cpp:228] Iteration 61240, loss = 0.563721
I0905 20:30:59.614439 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.563722 (* 1 = 0.563722 loss)
I0905 20:30:59.614455 90901 sgd_solver.cpp:106] Iteration 61240, lr = 0.01
I0905 20:31:09.932652 90901 solver.cpp:228] Iteration 61250, loss = 0.399839
I0905 20:31:09.932834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39984 (* 1 = 0.39984 loss)
I0905 20:31:09.932873 90901 sgd_solver.cpp:106] Iteration 61250, lr = 0.01
I0905 20:31:19.310950 90901 solver.cpp:228] Iteration 61260, loss = 0.162872
I0905 20:31:19.311018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162873 (* 1 = 0.162873 loss)
I0905 20:31:19.311034 90901 sgd_solver.cpp:106] Iteration 61260, lr = 0.01
I0905 20:31:32.131832 90901 solver.cpp:228] Iteration 61270, loss = 0.0710537
I0905 20:31:32.131891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0710551 (* 1 = 0.0710551 loss)
I0905 20:31:32.131912 90901 sgd_solver.cpp:106] Iteration 61270, lr = 0.01
I0905 20:31:42.273967 90901 solver.cpp:228] Iteration 61280, loss = 0.123025
I0905 20:31:42.274153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123026 (* 1 = 0.123026 loss)
I0905 20:31:42.274181 90901 sgd_solver.cpp:106] Iteration 61280, lr = 0.01
I0905 20:31:52.656515 90901 solver.cpp:228] Iteration 61290, loss = 0.12407
I0905 20:31:52.656584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124071 (* 1 = 0.124071 loss)
I0905 20:31:52.656602 90901 sgd_solver.cpp:106] Iteration 61290, lr = 0.01
I0905 20:32:03.743633 90901 solver.cpp:228] Iteration 61300, loss = 0.138567
I0905 20:32:03.743706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138568 (* 1 = 0.138568 loss)
I0905 20:32:03.743726 90901 sgd_solver.cpp:106] Iteration 61300, lr = 0.01
I0905 20:32:14.226163 90901 solver.cpp:228] Iteration 61310, loss = 0.122009
I0905 20:32:14.226480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12201 (* 1 = 0.12201 loss)
I0905 20:32:14.226505 90901 sgd_solver.cpp:106] Iteration 61310, lr = 0.01
I0905 20:32:26.080981 90901 solver.cpp:228] Iteration 61320, loss = 0.149863
I0905 20:32:26.081058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149864 (* 1 = 0.149864 loss)
I0905 20:32:26.081078 90901 sgd_solver.cpp:106] Iteration 61320, lr = 0.01
I0905 20:32:39.040992 90901 solver.cpp:228] Iteration 61330, loss = 0.0937758
I0905 20:32:39.041064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0937771 (* 1 = 0.0937771 loss)
I0905 20:32:39.041081 90901 sgd_solver.cpp:106] Iteration 61330, lr = 0.01
I0905 20:32:56.034435 90901 solver.cpp:228] Iteration 61340, loss = 0.0554835
I0905 20:32:56.034567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0554847 (* 1 = 0.0554847 loss)
I0905 20:32:56.034590 90901 sgd_solver.cpp:106] Iteration 61340, lr = 0.01
I0905 20:33:13.361776 90901 solver.cpp:228] Iteration 61350, loss = 0.111911
I0905 20:33:13.361856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111912 (* 1 = 0.111912 loss)
I0905 20:33:13.361877 90901 sgd_solver.cpp:106] Iteration 61350, lr = 0.01
I0905 20:33:30.959225 90901 solver.cpp:228] Iteration 61360, loss = 0.0621602
I0905 20:33:30.959367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0621616 (* 1 = 0.0621616 loss)
I0905 20:33:30.959399 90901 sgd_solver.cpp:106] Iteration 61360, lr = 0.01
I0905 20:33:48.694136 90901 solver.cpp:228] Iteration 61370, loss = 0.119911
I0905 20:33:48.694216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119913 (* 1 = 0.119913 loss)
I0905 20:33:48.694234 90901 sgd_solver.cpp:106] Iteration 61370, lr = 0.01
I0905 20:34:04.734045 90901 solver.cpp:228] Iteration 61380, loss = 0.317237
I0905 20:34:04.734217 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317238 (* 1 = 0.317238 loss)
I0905 20:34:04.734236 90901 sgd_solver.cpp:106] Iteration 61380, lr = 0.01
I0905 20:34:23.683389 90901 solver.cpp:228] Iteration 61390, loss = 0.14352
I0905 20:34:23.683470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143521 (* 1 = 0.143521 loss)
I0905 20:34:23.683493 90901 sgd_solver.cpp:106] Iteration 61390, lr = 0.01
I0905 20:34:41.329952 90901 solver.cpp:228] Iteration 61400, loss = 0.0805728
I0905 20:34:41.330127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0805741 (* 1 = 0.0805741 loss)
I0905 20:34:41.330147 90901 sgd_solver.cpp:106] Iteration 61400, lr = 0.01
I0905 20:34:59.426007 90901 solver.cpp:228] Iteration 61410, loss = 0.0771686
I0905 20:34:59.426131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0771699 (* 1 = 0.0771699 loss)
I0905 20:34:59.426180 90901 sgd_solver.cpp:106] Iteration 61410, lr = 0.01
I0905 20:35:17.750402 90901 solver.cpp:228] Iteration 61420, loss = 0.220731
I0905 20:35:17.758795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220732 (* 1 = 0.220732 loss)
I0905 20:35:17.758818 90901 sgd_solver.cpp:106] Iteration 61420, lr = 0.01
I0905 20:35:34.967983 90901 solver.cpp:228] Iteration 61430, loss = 0.0996854
I0905 20:35:34.968070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0996867 (* 1 = 0.0996867 loss)
I0905 20:35:34.968091 90901 sgd_solver.cpp:106] Iteration 61430, lr = 0.01
I0905 20:35:49.540225 90901 solver.cpp:228] Iteration 61440, loss = 0.404123
I0905 20:35:49.540452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404124 (* 1 = 0.404124 loss)
I0905 20:35:49.540482 90901 sgd_solver.cpp:106] Iteration 61440, lr = 0.01
I0905 20:36:04.638329 90901 solver.cpp:228] Iteration 61450, loss = 0.249487
I0905 20:36:04.638411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249489 (* 1 = 0.249489 loss)
I0905 20:36:04.638428 90901 sgd_solver.cpp:106] Iteration 61450, lr = 0.01
I0905 20:36:19.266206 90901 solver.cpp:228] Iteration 61460, loss = 0.0803055
I0905 20:36:19.266269 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0803068 (* 1 = 0.0803068 loss)
I0905 20:36:19.266283 90901 sgd_solver.cpp:106] Iteration 61460, lr = 0.01
I0905 20:36:33.295076 90901 solver.cpp:228] Iteration 61470, loss = 0.361676
I0905 20:36:33.295372 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361678 (* 1 = 0.361678 loss)
I0905 20:36:33.295392 90901 sgd_solver.cpp:106] Iteration 61470, lr = 0.01
I0905 20:36:45.548050 90901 solver.cpp:228] Iteration 61480, loss = 0.204708
I0905 20:36:45.548125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204709 (* 1 = 0.204709 loss)
I0905 20:36:45.548141 90901 sgd_solver.cpp:106] Iteration 61480, lr = 0.01
I0905 20:36:57.761601 90901 solver.cpp:228] Iteration 61490, loss = 0.276094
I0905 20:36:57.761685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276095 (* 1 = 0.276095 loss)
I0905 20:36:57.761706 90901 sgd_solver.cpp:106] Iteration 61490, lr = 0.01
I0905 20:37:10.458636 90901 solver.cpp:228] Iteration 61500, loss = 0.0523467
I0905 20:37:10.458789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.052348 (* 1 = 0.052348 loss)
I0905 20:37:10.458811 90901 sgd_solver.cpp:106] Iteration 61500, lr = 0.01
I0905 20:37:23.204859 90901 solver.cpp:228] Iteration 61510, loss = 0.0439742
I0905 20:37:23.204942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0439755 (* 1 = 0.0439755 loss)
I0905 20:37:23.204962 90901 sgd_solver.cpp:106] Iteration 61510, lr = 0.01
I0905 20:37:35.707144 90901 solver.cpp:228] Iteration 61520, loss = 0.0811793
I0905 20:37:35.707224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0811806 (* 1 = 0.0811806 loss)
I0905 20:37:35.707243 90901 sgd_solver.cpp:106] Iteration 61520, lr = 0.01
I0905 20:37:48.369925 90901 solver.cpp:228] Iteration 61530, loss = 0.116843
I0905 20:37:48.370138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116844 (* 1 = 0.116844 loss)
I0905 20:37:48.370177 90901 sgd_solver.cpp:106] Iteration 61530, lr = 0.01
I0905 20:38:03.248821 90901 solver.cpp:228] Iteration 61540, loss = 0.131736
I0905 20:38:03.248901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131738 (* 1 = 0.131738 loss)
I0905 20:38:03.248917 90901 sgd_solver.cpp:106] Iteration 61540, lr = 0.01
I0905 20:38:18.988806 90901 solver.cpp:228] Iteration 61550, loss = 0.553027
I0905 20:38:18.988955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.553028 (* 1 = 0.553028 loss)
I0905 20:38:18.988984 90901 sgd_solver.cpp:106] Iteration 61550, lr = 0.01
I0905 20:38:33.646670 90901 solver.cpp:228] Iteration 61560, loss = 0.200808
I0905 20:38:33.646790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200809 (* 1 = 0.200809 loss)
I0905 20:38:33.646816 90901 sgd_solver.cpp:106] Iteration 61560, lr = 0.01
I0905 20:38:44.998584 90901 solver.cpp:228] Iteration 61570, loss = 0.216257
I0905 20:38:44.998667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216258 (* 1 = 0.216258 loss)
I0905 20:38:44.998685 90901 sgd_solver.cpp:106] Iteration 61570, lr = 0.01
I0905 20:38:59.325681 90901 solver.cpp:228] Iteration 61580, loss = 0.217138
I0905 20:38:59.325876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21714 (* 1 = 0.21714 loss)
I0905 20:38:59.325901 90901 sgd_solver.cpp:106] Iteration 61580, lr = 0.01
I0905 20:39:12.161098 90901 solver.cpp:228] Iteration 61590, loss = 0.0511987
I0905 20:39:12.161198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0512 (* 1 = 0.0512 loss)
I0905 20:39:12.161217 90901 sgd_solver.cpp:106] Iteration 61590, lr = 0.01
I0905 20:39:27.686452 90901 solver.cpp:337] Iteration 61600, Testing net (#0)
I0905 20:41:16.708827 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.931875
I0905 20:41:16.709029 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.187737 (* 1 = 0.187737 loss)
I0905 20:41:17.125444 90901 solver.cpp:228] Iteration 61600, loss = 0.0524046
I0905 20:41:17.125511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0524059 (* 1 = 0.0524059 loss)
I0905 20:41:17.125530 90901 sgd_solver.cpp:106] Iteration 61600, lr = 0.01
I0905 20:41:32.522665 90901 solver.cpp:228] Iteration 61610, loss = 0.0591927
I0905 20:41:32.522719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.059194 (* 1 = 0.059194 loss)
I0905 20:41:32.522742 90901 sgd_solver.cpp:106] Iteration 61610, lr = 0.01
I0905 20:41:50.846482 90901 solver.cpp:228] Iteration 61620, loss = 0.0393665
I0905 20:41:50.846654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0393678 (* 1 = 0.0393678 loss)
I0905 20:41:50.846691 90901 sgd_solver.cpp:106] Iteration 61620, lr = 0.01
I0905 20:42:07.753051 90901 solver.cpp:228] Iteration 61630, loss = 0.102104
I0905 20:42:07.753134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102105 (* 1 = 0.102105 loss)
I0905 20:42:07.753152 90901 sgd_solver.cpp:106] Iteration 61630, lr = 0.01
I0905 20:42:21.846340 90901 solver.cpp:228] Iteration 61640, loss = 0.360742
I0905 20:42:21.846511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360744 (* 1 = 0.360744 loss)
I0905 20:42:21.846552 90901 sgd_solver.cpp:106] Iteration 61640, lr = 0.01
I0905 20:42:33.405282 90901 solver.cpp:228] Iteration 61650, loss = 0.111182
I0905 20:42:33.405356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111183 (* 1 = 0.111183 loss)
I0905 20:42:33.405378 90901 sgd_solver.cpp:106] Iteration 61650, lr = 0.01
I0905 20:42:45.934815 90901 solver.cpp:228] Iteration 61660, loss = 0.186557
I0905 20:42:45.934900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186559 (* 1 = 0.186559 loss)
I0905 20:42:45.934919 90901 sgd_solver.cpp:106] Iteration 61660, lr = 0.01
I0905 20:43:03.970116 90901 solver.cpp:228] Iteration 61670, loss = 0.192095
I0905 20:43:03.970268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192096 (* 1 = 0.192096 loss)
I0905 20:43:03.970298 90901 sgd_solver.cpp:106] Iteration 61670, lr = 0.01
I0905 20:43:18.986832 90901 solver.cpp:228] Iteration 61680, loss = 0.0948317
I0905 20:43:18.986912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.094833 (* 1 = 0.094833 loss)
I0905 20:43:18.986932 90901 sgd_solver.cpp:106] Iteration 61680, lr = 0.01
I0905 20:43:36.513897 90901 solver.cpp:228] Iteration 61690, loss = 0.536581
I0905 20:43:36.514091 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.536583 (* 1 = 0.536583 loss)
I0905 20:43:36.514108 90901 sgd_solver.cpp:106] Iteration 61690, lr = 0.01
I0905 20:43:54.279284 90901 solver.cpp:228] Iteration 61700, loss = 0.126625
I0905 20:43:54.279362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126627 (* 1 = 0.126627 loss)
I0905 20:43:54.279376 90901 sgd_solver.cpp:106] Iteration 61700, lr = 0.01
I0905 20:44:13.816057 90901 solver.cpp:228] Iteration 61710, loss = 0.228431
I0905 20:44:13.822720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228433 (* 1 = 0.228433 loss)
I0905 20:44:13.822742 90901 sgd_solver.cpp:106] Iteration 61710, lr = 0.01
I0905 20:44:31.981370 90901 solver.cpp:228] Iteration 61720, loss = 0.20639
I0905 20:44:31.981457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206392 (* 1 = 0.206392 loss)
I0905 20:44:31.981477 90901 sgd_solver.cpp:106] Iteration 61720, lr = 0.01
I0905 20:44:50.825413 90901 solver.cpp:228] Iteration 61730, loss = 0.0647103
I0905 20:44:50.825593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0647116 (* 1 = 0.0647116 loss)
I0905 20:44:50.825623 90901 sgd_solver.cpp:106] Iteration 61730, lr = 0.01
I0905 20:45:07.395640 90901 solver.cpp:228] Iteration 61740, loss = 0.506317
I0905 20:45:07.395727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.506318 (* 1 = 0.506318 loss)
I0905 20:45:07.395750 90901 sgd_solver.cpp:106] Iteration 61740, lr = 0.01
I0905 20:45:24.948138 90901 solver.cpp:228] Iteration 61750, loss = 0.184245
I0905 20:45:24.948384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184246 (* 1 = 0.184246 loss)
I0905 20:45:24.948407 90901 sgd_solver.cpp:106] Iteration 61750, lr = 0.01
I0905 20:45:42.785780 90901 solver.cpp:228] Iteration 61760, loss = 0.0712776
I0905 20:45:42.785886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.071279 (* 1 = 0.071279 loss)
I0905 20:45:42.785905 90901 sgd_solver.cpp:106] Iteration 61760, lr = 0.01
I0905 20:46:01.266351 90901 solver.cpp:228] Iteration 61770, loss = 0.0704364
I0905 20:46:01.266547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0704378 (* 1 = 0.0704378 loss)
I0905 20:46:01.266573 90901 sgd_solver.cpp:106] Iteration 61770, lr = 0.01
I0905 20:46:20.419139 90901 solver.cpp:228] Iteration 61780, loss = 0.232736
I0905 20:46:20.419270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232738 (* 1 = 0.232738 loss)
I0905 20:46:20.419291 90901 sgd_solver.cpp:106] Iteration 61780, lr = 0.01
I0905 20:46:38.625021 90901 solver.cpp:228] Iteration 61790, loss = 0.50744
I0905 20:46:38.625162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507441 (* 1 = 0.507441 loss)
I0905 20:46:38.625186 90901 sgd_solver.cpp:106] Iteration 61790, lr = 0.01
I0905 20:46:56.912751 90901 solver.cpp:228] Iteration 61800, loss = 0.353953
I0905 20:46:56.912812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353955 (* 1 = 0.353955 loss)
I0905 20:46:56.912829 90901 sgd_solver.cpp:106] Iteration 61800, lr = 0.01
I0905 20:47:14.930333 90901 solver.cpp:228] Iteration 61810, loss = 0.269474
I0905 20:47:14.930572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269476 (* 1 = 0.269476 loss)
I0905 20:47:14.930599 90901 sgd_solver.cpp:106] Iteration 61810, lr = 0.01
I0905 20:47:33.162364 90901 solver.cpp:228] Iteration 61820, loss = 0.284247
I0905 20:47:33.162467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284249 (* 1 = 0.284249 loss)
I0905 20:47:33.162490 90901 sgd_solver.cpp:106] Iteration 61820, lr = 0.01
I0905 20:47:51.757752 90901 solver.cpp:228] Iteration 61830, loss = 0.228174
I0905 20:47:51.757959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228176 (* 1 = 0.228176 loss)
I0905 20:47:51.757992 90901 sgd_solver.cpp:106] Iteration 61830, lr = 0.01
I0905 20:48:10.940604 90901 solver.cpp:228] Iteration 61840, loss = 0.222285
I0905 20:48:10.940696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222287 (* 1 = 0.222287 loss)
I0905 20:48:10.940717 90901 sgd_solver.cpp:106] Iteration 61840, lr = 0.01
I0905 20:48:28.399940 90901 solver.cpp:228] Iteration 61850, loss = 0.218156
I0905 20:48:28.400127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218158 (* 1 = 0.218158 loss)
I0905 20:48:28.400159 90901 sgd_solver.cpp:106] Iteration 61850, lr = 0.01
I0905 20:48:47.264047 90901 solver.cpp:228] Iteration 61860, loss = 0.224805
I0905 20:48:47.264154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224806 (* 1 = 0.224806 loss)
I0905 20:48:47.264180 90901 sgd_solver.cpp:106] Iteration 61860, lr = 0.01
I0905 20:49:06.502877 90901 solver.cpp:228] Iteration 61870, loss = 0.0862404
I0905 20:49:06.503111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0862418 (* 1 = 0.0862418 loss)
I0905 20:49:06.503142 90901 sgd_solver.cpp:106] Iteration 61870, lr = 0.01
I0905 20:49:25.100924 90901 solver.cpp:228] Iteration 61880, loss = 0.199196
I0905 20:49:25.101034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199198 (* 1 = 0.199198 loss)
I0905 20:49:25.101056 90901 sgd_solver.cpp:106] Iteration 61880, lr = 0.01
I0905 20:49:43.676764 90901 solver.cpp:228] Iteration 61890, loss = 0.0579861
I0905 20:49:43.676982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0579875 (* 1 = 0.0579875 loss)
I0905 20:49:43.677002 90901 sgd_solver.cpp:106] Iteration 61890, lr = 0.01
I0905 20:50:01.720199 90901 solver.cpp:228] Iteration 61900, loss = 0.307816
I0905 20:50:01.720302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307817 (* 1 = 0.307817 loss)
I0905 20:50:01.720324 90901 sgd_solver.cpp:106] Iteration 61900, lr = 0.01
I0905 20:50:20.676622 90901 solver.cpp:228] Iteration 61910, loss = 0.0816438
I0905 20:50:20.676826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0816453 (* 1 = 0.0816453 loss)
I0905 20:50:20.676851 90901 sgd_solver.cpp:106] Iteration 61910, lr = 0.01
I0905 20:50:37.973295 90901 solver.cpp:228] Iteration 61920, loss = 0.328493
I0905 20:50:37.973377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328494 (* 1 = 0.328494 loss)
I0905 20:50:37.973397 90901 sgd_solver.cpp:106] Iteration 61920, lr = 0.01
I0905 20:50:54.894076 90901 solver.cpp:228] Iteration 61930, loss = 0.107922
I0905 20:50:54.894278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107923 (* 1 = 0.107923 loss)
I0905 20:50:54.894309 90901 sgd_solver.cpp:106] Iteration 61930, lr = 0.01
I0905 20:51:13.053153 90901 solver.cpp:228] Iteration 61940, loss = 0.0528119
I0905 20:51:13.053233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0528133 (* 1 = 0.0528133 loss)
I0905 20:51:13.053251 90901 sgd_solver.cpp:106] Iteration 61940, lr = 0.01
I0905 20:51:31.556080 90901 solver.cpp:228] Iteration 61950, loss = 0.164133
I0905 20:51:31.556290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164135 (* 1 = 0.164135 loss)
I0905 20:51:31.556318 90901 sgd_solver.cpp:106] Iteration 61950, lr = 0.01
I0905 20:51:49.820302 90901 solver.cpp:228] Iteration 61960, loss = 0.122638
I0905 20:51:49.820389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12264 (* 1 = 0.12264 loss)
I0905 20:51:49.820405 90901 sgd_solver.cpp:106] Iteration 61960, lr = 0.01
I0905 20:52:07.999176 90901 solver.cpp:228] Iteration 61970, loss = 0.182701
I0905 20:52:07.999341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182703 (* 1 = 0.182703 loss)
I0905 20:52:07.999371 90901 sgd_solver.cpp:106] Iteration 61970, lr = 0.01
I0905 20:52:26.757776 90901 solver.cpp:228] Iteration 61980, loss = 0.0580866
I0905 20:52:26.757957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.058088 (* 1 = 0.058088 loss)
I0905 20:52:26.757987 90901 sgd_solver.cpp:106] Iteration 61980, lr = 0.01
I0905 20:52:44.527786 90901 solver.cpp:228] Iteration 61990, loss = 0.387222
I0905 20:52:44.527956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387223 (* 1 = 0.387223 loss)
I0905 20:52:44.527987 90901 sgd_solver.cpp:106] Iteration 61990, lr = 0.01
I0905 20:53:02.560698 90901 solver.cpp:228] Iteration 62000, loss = 0.0712289
I0905 20:53:02.560806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0712304 (* 1 = 0.0712304 loss)
I0905 20:53:02.560824 90901 sgd_solver.cpp:106] Iteration 62000, lr = 0.01
I0905 20:53:19.384945 90901 solver.cpp:228] Iteration 62010, loss = 0.159332
I0905 20:53:19.385107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159334 (* 1 = 0.159334 loss)
I0905 20:53:19.385138 90901 sgd_solver.cpp:106] Iteration 62010, lr = 0.01
I0905 20:53:37.410305 90901 solver.cpp:228] Iteration 62020, loss = 0.124575
I0905 20:53:37.410374 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124577 (* 1 = 0.124577 loss)
I0905 20:53:37.410394 90901 sgd_solver.cpp:106] Iteration 62020, lr = 0.01
I0905 20:53:54.318812 90901 solver.cpp:228] Iteration 62030, loss = 0.458681
I0905 20:53:54.319008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458682 (* 1 = 0.458682 loss)
I0905 20:53:54.319051 90901 sgd_solver.cpp:106] Iteration 62030, lr = 0.01
I0905 20:54:13.006631 90901 solver.cpp:228] Iteration 62040, loss = 0.0677425
I0905 20:54:13.006705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.067744 (* 1 = 0.067744 loss)
I0905 20:54:13.006734 90901 sgd_solver.cpp:106] Iteration 62040, lr = 0.01
I0905 20:54:30.704763 90901 solver.cpp:228] Iteration 62050, loss = 0.213771
I0905 20:54:30.704982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213773 (* 1 = 0.213773 loss)
I0905 20:54:30.705010 90901 sgd_solver.cpp:106] Iteration 62050, lr = 0.01
I0905 20:54:48.581543 90901 solver.cpp:228] Iteration 62060, loss = 0.134111
I0905 20:54:48.581605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134113 (* 1 = 0.134113 loss)
I0905 20:54:48.581622 90901 sgd_solver.cpp:106] Iteration 62060, lr = 0.01
I0905 20:55:07.727948 90901 solver.cpp:228] Iteration 62070, loss = 0.180695
I0905 20:55:07.728176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180697 (* 1 = 0.180697 loss)
I0905 20:55:07.728199 90901 sgd_solver.cpp:106] Iteration 62070, lr = 0.01
I0905 20:55:25.253324 90901 solver.cpp:228] Iteration 62080, loss = 0.242884
I0905 20:55:25.253401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242886 (* 1 = 0.242886 loss)
I0905 20:55:25.253422 90901 sgd_solver.cpp:106] Iteration 62080, lr = 0.01
I0905 20:55:42.089779 90901 solver.cpp:228] Iteration 62090, loss = 0.290333
I0905 20:55:42.089926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290334 (* 1 = 0.290334 loss)
I0905 20:55:42.089946 90901 sgd_solver.cpp:106] Iteration 62090, lr = 0.01
I0905 20:55:59.261013 90901 solver.cpp:228] Iteration 62100, loss = 0.167545
I0905 20:55:59.261087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167547 (* 1 = 0.167547 loss)
I0905 20:55:59.261106 90901 sgd_solver.cpp:106] Iteration 62100, lr = 0.01
I0905 20:56:13.710883 90901 solver.cpp:228] Iteration 62110, loss = 0.330285
I0905 20:56:13.711105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330286 (* 1 = 0.330286 loss)
I0905 20:56:13.711128 90901 sgd_solver.cpp:106] Iteration 62110, lr = 0.01
I0905 20:56:26.981431 90901 solver.cpp:228] Iteration 62120, loss = 0.133658
I0905 20:56:26.981529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133659 (* 1 = 0.133659 loss)
I0905 20:56:26.981549 90901 sgd_solver.cpp:106] Iteration 62120, lr = 0.01
I0905 20:56:38.466562 90901 solver.cpp:228] Iteration 62130, loss = 0.156849
I0905 20:56:38.466645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15685 (* 1 = 0.15685 loss)
I0905 20:56:38.466676 90901 sgd_solver.cpp:106] Iteration 62130, lr = 0.01
I0905 20:56:48.282348 90901 solver.cpp:228] Iteration 62140, loss = 0.173071
I0905 20:56:48.282527 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173072 (* 1 = 0.173072 loss)
I0905 20:56:48.282546 90901 sgd_solver.cpp:106] Iteration 62140, lr = 0.01
I0905 20:56:57.649785 90901 solver.cpp:228] Iteration 62150, loss = 0.89047
I0905 20:56:57.649898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.890472 (* 1 = 0.890472 loss)
I0905 20:56:57.649916 90901 sgd_solver.cpp:106] Iteration 62150, lr = 0.01
I0905 20:57:06.482945 90901 solver.cpp:228] Iteration 62160, loss = 0.0671981
I0905 20:57:06.483038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0671996 (* 1 = 0.0671996 loss)
I0905 20:57:06.483062 90901 sgd_solver.cpp:106] Iteration 62160, lr = 0.01
I0905 20:57:14.640056 90901 solver.cpp:228] Iteration 62170, loss = 0.212918
I0905 20:57:14.640128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21292 (* 1 = 0.21292 loss)
I0905 20:57:14.640146 90901 sgd_solver.cpp:106] Iteration 62170, lr = 0.01
I0905 20:57:23.593298 90901 solver.cpp:228] Iteration 62180, loss = 0.0471928
I0905 20:57:23.593549 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0471942 (* 1 = 0.0471942 loss)
I0905 20:57:23.593569 90901 sgd_solver.cpp:106] Iteration 62180, lr = 0.01
I0905 20:57:31.977638 90901 solver.cpp:228] Iteration 62190, loss = 0.442809
I0905 20:57:31.977711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44281 (* 1 = 0.44281 loss)
I0905 20:57:31.977727 90901 sgd_solver.cpp:106] Iteration 62190, lr = 0.01
I0905 20:57:39.600337 90901 solver.cpp:228] Iteration 62200, loss = 0.215514
I0905 20:57:39.600441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215516 (* 1 = 0.215516 loss)
I0905 20:57:39.600462 90901 sgd_solver.cpp:106] Iteration 62200, lr = 0.01
I0905 20:57:47.610772 90901 solver.cpp:228] Iteration 62210, loss = 0.126698
I0905 20:57:47.610844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126699 (* 1 = 0.126699 loss)
I0905 20:57:47.610859 90901 sgd_solver.cpp:106] Iteration 62210, lr = 0.01
I0905 20:57:56.286947 90901 solver.cpp:228] Iteration 62220, loss = 0.294322
I0905 20:57:56.287220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294323 (* 1 = 0.294323 loss)
I0905 20:57:56.287242 90901 sgd_solver.cpp:106] Iteration 62220, lr = 0.01
I0905 20:58:08.795228 90901 solver.cpp:228] Iteration 62230, loss = 0.0958352
I0905 20:58:08.795305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0958366 (* 1 = 0.0958366 loss)
I0905 20:58:08.795322 90901 sgd_solver.cpp:106] Iteration 62230, lr = 0.01
I0905 20:58:20.241168 90901 solver.cpp:228] Iteration 62240, loss = 0.278526
I0905 20:58:20.241255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278527 (* 1 = 0.278527 loss)
I0905 20:58:20.241276 90901 sgd_solver.cpp:106] Iteration 62240, lr = 0.01
I0905 20:58:35.738576 90901 solver.cpp:228] Iteration 62250, loss = 0.404335
I0905 20:58:35.738759 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.404336 (* 1 = 0.404336 loss)
I0905 20:58:35.738772 90901 sgd_solver.cpp:106] Iteration 62250, lr = 0.01
I0905 20:58:54.261871 90901 solver.cpp:228] Iteration 62260, loss = 0.382571
I0905 20:58:54.261951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382572 (* 1 = 0.382572 loss)
I0905 20:58:54.261971 90901 sgd_solver.cpp:106] Iteration 62260, lr = 0.01
I0905 20:59:12.370003 90901 solver.cpp:228] Iteration 62270, loss = 0.084471
I0905 20:59:12.370187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0844724 (* 1 = 0.0844724 loss)
I0905 20:59:12.370221 90901 sgd_solver.cpp:106] Iteration 62270, lr = 0.01
I0905 20:59:29.970914 90901 solver.cpp:228] Iteration 62280, loss = 0.135909
I0905 20:59:29.970986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135911 (* 1 = 0.135911 loss)
I0905 20:59:29.971005 90901 sgd_solver.cpp:106] Iteration 62280, lr = 0.01
I0905 20:59:47.180363 90901 solver.cpp:228] Iteration 62290, loss = 0.256884
I0905 20:59:47.180654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256886 (* 1 = 0.256886 loss)
I0905 20:59:47.180685 90901 sgd_solver.cpp:106] Iteration 62290, lr = 0.01
I0905 21:00:05.927628 90901 solver.cpp:228] Iteration 62300, loss = 0.148131
I0905 21:00:05.927700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148132 (* 1 = 0.148132 loss)
I0905 21:00:05.927717 90901 sgd_solver.cpp:106] Iteration 62300, lr = 0.01
I0905 21:00:26.192370 90901 solver.cpp:228] Iteration 62310, loss = 0.063792
I0905 21:00:26.192533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0637935 (* 1 = 0.0637935 loss)
I0905 21:00:26.192570 90901 sgd_solver.cpp:106] Iteration 62310, lr = 0.01
I0905 21:00:44.208600 90901 solver.cpp:228] Iteration 62320, loss = 0.313781
I0905 21:00:44.208676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313783 (* 1 = 0.313783 loss)
I0905 21:00:44.208694 90901 sgd_solver.cpp:106] Iteration 62320, lr = 0.01
I0905 21:01:03.328644 90901 solver.cpp:228] Iteration 62330, loss = 0.187752
I0905 21:01:03.328840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187754 (* 1 = 0.187754 loss)
I0905 21:01:03.328881 90901 sgd_solver.cpp:106] Iteration 62330, lr = 0.01
I0905 21:01:22.771450 90901 solver.cpp:228] Iteration 62340, loss = 0.195448
I0905 21:01:22.771533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19545 (* 1 = 0.19545 loss)
I0905 21:01:22.771553 90901 sgd_solver.cpp:106] Iteration 62340, lr = 0.01
I0905 21:01:40.855594 90901 solver.cpp:228] Iteration 62350, loss = 0.336818
I0905 21:01:40.855857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33682 (* 1 = 0.33682 loss)
I0905 21:01:40.855901 90901 sgd_solver.cpp:106] Iteration 62350, lr = 0.01
I0905 21:01:59.999866 90901 solver.cpp:228] Iteration 62360, loss = 0.100547
I0905 21:01:59.999949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100549 (* 1 = 0.100549 loss)
I0905 21:01:59.999969 90901 sgd_solver.cpp:106] Iteration 62360, lr = 0.01
I0905 21:02:21.024823 90901 solver.cpp:228] Iteration 62370, loss = 0.0692367
I0905 21:02:21.024981 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0692381 (* 1 = 0.0692381 loss)
I0905 21:02:21.025010 90901 sgd_solver.cpp:106] Iteration 62370, lr = 0.01
I0905 21:02:41.860363 90901 solver.cpp:228] Iteration 62380, loss = 0.0172494
I0905 21:02:41.860440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0172508 (* 1 = 0.0172508 loss)
I0905 21:02:41.860456 90901 sgd_solver.cpp:106] Iteration 62380, lr = 0.01
I0905 21:03:00.950018 90901 solver.cpp:228] Iteration 62390, loss = 0.130812
I0905 21:03:00.950228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130814 (* 1 = 0.130814 loss)
I0905 21:03:00.950259 90901 sgd_solver.cpp:106] Iteration 62390, lr = 0.01
I0905 21:03:17.900367 90901 solver.cpp:337] Iteration 62400, Testing net (#0)
I0905 21:05:18.573166 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.878125
I0905 21:05:18.573348 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.325535 (* 1 = 0.325535 loss)
I0905 21:05:19.205016 90901 solver.cpp:228] Iteration 62400, loss = 0.123312
I0905 21:05:19.205083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123314 (* 1 = 0.123314 loss)
I0905 21:05:19.205102 90901 sgd_solver.cpp:106] Iteration 62400, lr = 0.01
I0905 21:05:37.931623 90901 solver.cpp:228] Iteration 62410, loss = 0.137385
I0905 21:05:37.931727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137386 (* 1 = 0.137386 loss)
I0905 21:05:37.931746 90901 sgd_solver.cpp:106] Iteration 62410, lr = 0.01
I0905 21:05:56.668256 90901 solver.cpp:228] Iteration 62420, loss = 0.289072
I0905 21:05:56.668474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289073 (* 1 = 0.289073 loss)
I0905 21:05:56.668527 90901 sgd_solver.cpp:106] Iteration 62420, lr = 0.01
I0905 21:06:12.668457 90901 solver.cpp:228] Iteration 62430, loss = 0.150025
I0905 21:06:12.668530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150026 (* 1 = 0.150026 loss)
I0905 21:06:12.668546 90901 sgd_solver.cpp:106] Iteration 62430, lr = 0.01
I0905 21:06:28.116766 90901 solver.cpp:228] Iteration 62440, loss = 0.133488
I0905 21:06:28.116961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133489 (* 1 = 0.133489 loss)
I0905 21:06:28.116979 90901 sgd_solver.cpp:106] Iteration 62440, lr = 0.01
I0905 21:06:45.757704 90901 solver.cpp:228] Iteration 62450, loss = 0.0668744
I0905 21:06:45.757807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0668759 (* 1 = 0.0668759 loss)
I0905 21:06:45.757833 90901 sgd_solver.cpp:106] Iteration 62450, lr = 0.01
I0905 21:07:00.528822 90901 solver.cpp:228] Iteration 62460, loss = 0.335362
I0905 21:07:00.530550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335363 (* 1 = 0.335363 loss)
I0905 21:07:00.530580 90901 sgd_solver.cpp:106] Iteration 62460, lr = 0.01
I0905 21:07:17.712803 90901 solver.cpp:228] Iteration 62470, loss = 0.138033
I0905 21:07:17.712910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138034 (* 1 = 0.138034 loss)
I0905 21:07:17.712940 90901 sgd_solver.cpp:106] Iteration 62470, lr = 0.01
I0905 21:07:35.101421 90901 solver.cpp:228] Iteration 62480, loss = 0.0956248
I0905 21:07:35.101742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0956264 (* 1 = 0.0956264 loss)
I0905 21:07:35.101764 90901 sgd_solver.cpp:106] Iteration 62480, lr = 0.01
I0905 21:07:51.603734 90901 solver.cpp:228] Iteration 62490, loss = 0.0782468
I0905 21:07:51.603845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0782483 (* 1 = 0.0782483 loss)
I0905 21:07:51.603875 90901 sgd_solver.cpp:106] Iteration 62490, lr = 0.01
I0905 21:08:06.188635 90901 solver.cpp:228] Iteration 62500, loss = 0.0966884
I0905 21:08:06.188829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.09669 (* 1 = 0.09669 loss)
I0905 21:08:06.188851 90901 sgd_solver.cpp:106] Iteration 62500, lr = 0.01
I0905 21:08:18.401746 90901 solver.cpp:228] Iteration 62510, loss = 0.264751
I0905 21:08:18.401821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264752 (* 1 = 0.264752 loss)
I0905 21:08:18.401839 90901 sgd_solver.cpp:106] Iteration 62510, lr = 0.01
I0905 21:08:27.620642 90901 solver.cpp:228] Iteration 62520, loss = 0.110209
I0905 21:08:27.620734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110211 (* 1 = 0.110211 loss)
I0905 21:08:27.620754 90901 sgd_solver.cpp:106] Iteration 62520, lr = 0.01
I0905 21:08:35.651175 90901 solver.cpp:228] Iteration 62530, loss = 0.0798668
I0905 21:08:35.651250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0798684 (* 1 = 0.0798684 loss)
I0905 21:08:35.651268 90901 sgd_solver.cpp:106] Iteration 62530, lr = 0.01
I0905 21:08:43.775447 90901 solver.cpp:228] Iteration 62540, loss = 0.179682
I0905 21:08:43.775651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179684 (* 1 = 0.179684 loss)
I0905 21:08:43.775679 90901 sgd_solver.cpp:106] Iteration 62540, lr = 0.01
I0905 21:08:55.566251 90901 solver.cpp:228] Iteration 62550, loss = 0.191162
I0905 21:08:55.566354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191164 (* 1 = 0.191164 loss)
I0905 21:08:55.566383 90901 sgd_solver.cpp:106] Iteration 62550, lr = 0.01
I0905 21:09:07.976207 90901 solver.cpp:228] Iteration 62560, loss = 0.282135
I0905 21:09:07.976291 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282136 (* 1 = 0.282136 loss)
I0905 21:09:07.976313 90901 sgd_solver.cpp:106] Iteration 62560, lr = 0.01
I0905 21:09:23.409814 90901 solver.cpp:228] Iteration 62570, loss = 0.0545361
I0905 21:09:23.409981 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545376 (* 1 = 0.0545376 loss)
I0905 21:09:23.410012 90901 sgd_solver.cpp:106] Iteration 62570, lr = 0.01
I0905 21:09:41.838222 90901 solver.cpp:228] Iteration 62580, loss = 0.702132
I0905 21:09:41.838291 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.702133 (* 1 = 0.702133 loss)
I0905 21:09:41.838310 90901 sgd_solver.cpp:106] Iteration 62580, lr = 0.01
I0905 21:09:59.963906 90901 solver.cpp:228] Iteration 62590, loss = 0.13104
I0905 21:09:59.964084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131041 (* 1 = 0.131041 loss)
I0905 21:09:59.964123 90901 sgd_solver.cpp:106] Iteration 62590, lr = 0.01
I0905 21:10:15.725229 90901 solver.cpp:228] Iteration 62600, loss = 0.0805005
I0905 21:10:15.725347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.080502 (* 1 = 0.080502 loss)
I0905 21:10:15.725378 90901 sgd_solver.cpp:106] Iteration 62600, lr = 0.01
I0905 21:10:32.473870 90901 solver.cpp:228] Iteration 62610, loss = 0.0667025
I0905 21:10:32.474066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.066704 (* 1 = 0.066704 loss)
I0905 21:10:32.474086 90901 sgd_solver.cpp:106] Iteration 62610, lr = 0.01
I0905 21:10:48.739514 90901 solver.cpp:228] Iteration 62620, loss = 0.104458
I0905 21:10:48.739578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10446 (* 1 = 0.10446 loss)
I0905 21:10:48.739596 90901 sgd_solver.cpp:106] Iteration 62620, lr = 0.01
I0905 21:11:02.544287 90901 solver.cpp:228] Iteration 62630, loss = 0.116312
I0905 21:11:02.544517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116314 (* 1 = 0.116314 loss)
I0905 21:11:02.544545 90901 sgd_solver.cpp:106] Iteration 62630, lr = 0.01
I0905 21:11:19.784076 90901 solver.cpp:228] Iteration 62640, loss = 0.135644
I0905 21:11:19.784178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135645 (* 1 = 0.135645 loss)
I0905 21:11:19.784209 90901 sgd_solver.cpp:106] Iteration 62640, lr = 0.01
I0905 21:11:37.397061 90901 solver.cpp:228] Iteration 62650, loss = 0.191781
I0905 21:11:37.397264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191783 (* 1 = 0.191783 loss)
I0905 21:11:37.397310 90901 sgd_solver.cpp:106] Iteration 62650, lr = 0.01
I0905 21:11:55.525950 90901 solver.cpp:228] Iteration 62660, loss = 0.184115
I0905 21:11:55.526032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184117 (* 1 = 0.184117 loss)
I0905 21:11:55.526052 90901 sgd_solver.cpp:106] Iteration 62660, lr = 0.01
I0905 21:12:13.796991 90901 solver.cpp:228] Iteration 62670, loss = 0.229853
I0905 21:12:13.797174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229855 (* 1 = 0.229855 loss)
I0905 21:12:13.797190 90901 sgd_solver.cpp:106] Iteration 62670, lr = 0.01
I0905 21:12:30.740823 90901 solver.cpp:228] Iteration 62680, loss = 0.0705821
I0905 21:12:30.740913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0705837 (* 1 = 0.0705837 loss)
I0905 21:12:30.740934 90901 sgd_solver.cpp:106] Iteration 62680, lr = 0.01
I0905 21:12:49.315706 90901 solver.cpp:228] Iteration 62690, loss = 0.144341
I0905 21:12:49.315879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144343 (* 1 = 0.144343 loss)
I0905 21:12:49.315913 90901 sgd_solver.cpp:106] Iteration 62690, lr = 0.01
I0905 21:13:08.694428 90901 solver.cpp:228] Iteration 62700, loss = 0.133793
I0905 21:13:08.694522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133795 (* 1 = 0.133795 loss)
I0905 21:13:08.694541 90901 sgd_solver.cpp:106] Iteration 62700, lr = 0.01
I0905 21:13:24.569332 90901 solver.cpp:228] Iteration 62710, loss = 0.253621
I0905 21:13:24.569530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253622 (* 1 = 0.253622 loss)
I0905 21:13:24.569550 90901 sgd_solver.cpp:106] Iteration 62710, lr = 0.01
I0905 21:13:42.540359 90901 solver.cpp:228] Iteration 62720, loss = 0.189953
I0905 21:13:42.540446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189954 (* 1 = 0.189954 loss)
I0905 21:13:42.540467 90901 sgd_solver.cpp:106] Iteration 62720, lr = 0.01
I0905 21:14:00.408143 90901 solver.cpp:228] Iteration 62730, loss = 0.0801769
I0905 21:14:00.408352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0801786 (* 1 = 0.0801786 loss)
I0905 21:14:00.408385 90901 sgd_solver.cpp:106] Iteration 62730, lr = 0.01
I0905 21:14:18.668185 90901 solver.cpp:228] Iteration 62740, loss = 0.108053
I0905 21:14:18.668267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108055 (* 1 = 0.108055 loss)
I0905 21:14:18.668292 90901 sgd_solver.cpp:106] Iteration 62740, lr = 0.01
I0905 21:14:40.082592 90901 solver.cpp:228] Iteration 62750, loss = 0.228625
I0905 21:14:40.082835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228626 (* 1 = 0.228626 loss)
I0905 21:14:40.082857 90901 sgd_solver.cpp:106] Iteration 62750, lr = 0.01
I0905 21:15:00.614153 90901 solver.cpp:228] Iteration 62760, loss = 0.0624375
I0905 21:15:00.614231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0624391 (* 1 = 0.0624391 loss)
I0905 21:15:00.614248 90901 sgd_solver.cpp:106] Iteration 62760, lr = 0.01
I0905 21:15:20.921064 90901 solver.cpp:228] Iteration 62770, loss = 0.296092
I0905 21:15:20.921314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296094 (* 1 = 0.296094 loss)
I0905 21:15:20.921345 90901 sgd_solver.cpp:106] Iteration 62770, lr = 0.01
I0905 21:15:38.532253 90901 solver.cpp:228] Iteration 62780, loss = 0.782188
I0905 21:15:38.532340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.78219 (* 1 = 0.78219 loss)
I0905 21:15:38.532362 90901 sgd_solver.cpp:106] Iteration 62780, lr = 0.01
I0905 21:15:55.677516 90901 solver.cpp:228] Iteration 62790, loss = 0.145511
I0905 21:15:55.677726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145513 (* 1 = 0.145513 loss)
I0905 21:15:55.677747 90901 sgd_solver.cpp:106] Iteration 62790, lr = 0.01
I0905 21:16:07.750358 90901 solver.cpp:228] Iteration 62800, loss = 0.165819
I0905 21:16:07.750430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165821 (* 1 = 0.165821 loss)
I0905 21:16:07.750447 90901 sgd_solver.cpp:106] Iteration 62800, lr = 0.01
I0905 21:16:23.103229 90901 solver.cpp:228] Iteration 62810, loss = 0.175569
I0905 21:16:23.103312 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175571 (* 1 = 0.175571 loss)
I0905 21:16:23.103328 90901 sgd_solver.cpp:106] Iteration 62810, lr = 0.01
I0905 21:16:36.623646 90901 solver.cpp:228] Iteration 62820, loss = 0.11058
I0905 21:16:36.623868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110582 (* 1 = 0.110582 loss)
I0905 21:16:36.623900 90901 sgd_solver.cpp:106] Iteration 62820, lr = 0.01
I0905 21:16:48.246829 90901 solver.cpp:228] Iteration 62830, loss = 0.069117
I0905 21:16:48.246906 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0691186 (* 1 = 0.0691186 loss)
I0905 21:16:48.246927 90901 sgd_solver.cpp:106] Iteration 62830, lr = 0.01
I0905 21:17:00.715415 90901 solver.cpp:228] Iteration 62840, loss = 0.053403
I0905 21:17:00.715479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0534046 (* 1 = 0.0534046 loss)
I0905 21:17:00.715492 90901 sgd_solver.cpp:106] Iteration 62840, lr = 0.01
I0905 21:17:13.919792 90901 solver.cpp:228] Iteration 62850, loss = 0.909276
I0905 21:17:13.920001 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.909278 (* 1 = 0.909278 loss)
I0905 21:17:13.920032 90901 sgd_solver.cpp:106] Iteration 62850, lr = 0.01
I0905 21:17:28.141259 90901 solver.cpp:228] Iteration 62860, loss = 0.359747
I0905 21:17:28.141352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359749 (* 1 = 0.359749 loss)
I0905 21:17:28.141371 90901 sgd_solver.cpp:106] Iteration 62860, lr = 0.01
I0905 21:17:45.584434 90901 solver.cpp:228] Iteration 62870, loss = 0.187348
I0905 21:17:45.584611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18735 (* 1 = 0.18735 loss)
I0905 21:17:45.584651 90901 sgd_solver.cpp:106] Iteration 62870, lr = 0.01
I0905 21:18:02.319998 90901 solver.cpp:228] Iteration 62880, loss = 0.289737
I0905 21:18:02.320094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289738 (* 1 = 0.289738 loss)
I0905 21:18:02.320117 90901 sgd_solver.cpp:106] Iteration 62880, lr = 0.01
I0905 21:18:18.413864 90901 solver.cpp:228] Iteration 62890, loss = 0.149865
I0905 21:18:18.414105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149867 (* 1 = 0.149867 loss)
I0905 21:18:18.414134 90901 sgd_solver.cpp:106] Iteration 62890, lr = 0.01
I0905 21:18:34.478808 90901 solver.cpp:228] Iteration 62900, loss = 0.0570012
I0905 21:18:34.478871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0570028 (* 1 = 0.0570028 loss)
I0905 21:18:34.478888 90901 sgd_solver.cpp:106] Iteration 62900, lr = 0.01
I0905 21:18:52.231395 90901 solver.cpp:228] Iteration 62910, loss = 0.166819
I0905 21:18:52.231572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166821 (* 1 = 0.166821 loss)
I0905 21:18:52.231591 90901 sgd_solver.cpp:106] Iteration 62910, lr = 0.01
I0905 21:19:11.098707 90901 solver.cpp:228] Iteration 62920, loss = 0.210784
I0905 21:19:11.098788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210785 (* 1 = 0.210785 loss)
I0905 21:19:11.098804 90901 sgd_solver.cpp:106] Iteration 62920, lr = 0.01
I0905 21:19:30.472139 90901 solver.cpp:228] Iteration 62930, loss = 0.0945543
I0905 21:19:30.472375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0945559 (* 1 = 0.0945559 loss)
I0905 21:19:30.472405 90901 sgd_solver.cpp:106] Iteration 62930, lr = 0.01
I0905 21:19:47.204522 90901 solver.cpp:228] Iteration 62940, loss = 0.196389
I0905 21:19:47.204638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196391 (* 1 = 0.196391 loss)
I0905 21:19:47.204663 90901 sgd_solver.cpp:106] Iteration 62940, lr = 0.01
I0905 21:20:04.322952 90901 solver.cpp:228] Iteration 62950, loss = 0.0424866
I0905 21:20:04.323171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0424882 (* 1 = 0.0424882 loss)
I0905 21:20:04.323204 90901 sgd_solver.cpp:106] Iteration 62950, lr = 0.01
I0905 21:20:22.796739 90901 solver.cpp:228] Iteration 62960, loss = 0.15386
I0905 21:20:22.796802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153861 (* 1 = 0.153861 loss)
I0905 21:20:22.796821 90901 sgd_solver.cpp:106] Iteration 62960, lr = 0.01
I0905 21:20:39.855360 90901 solver.cpp:228] Iteration 62970, loss = 0.0515051
I0905 21:20:39.855587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0515067 (* 1 = 0.0515067 loss)
I0905 21:20:39.855625 90901 sgd_solver.cpp:106] Iteration 62970, lr = 0.01
I0905 21:20:57.790655 90901 solver.cpp:228] Iteration 62980, loss = 0.120011
I0905 21:20:57.790760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120013 (* 1 = 0.120013 loss)
I0905 21:20:57.790779 90901 sgd_solver.cpp:106] Iteration 62980, lr = 0.01
I0905 21:21:17.115887 90901 solver.cpp:228] Iteration 62990, loss = 0.239829
I0905 21:21:17.116049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23983 (* 1 = 0.23983 loss)
I0905 21:21:17.116075 90901 sgd_solver.cpp:106] Iteration 62990, lr = 0.01
I0905 21:21:33.859506 90901 solver.cpp:228] Iteration 63000, loss = 0.343548
I0905 21:21:33.859581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343549 (* 1 = 0.343549 loss)
I0905 21:21:33.859598 90901 sgd_solver.cpp:106] Iteration 63000, lr = 0.01
I0905 21:21:51.691279 90901 solver.cpp:228] Iteration 63010, loss = 0.222746
I0905 21:21:51.691457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222747 (* 1 = 0.222747 loss)
I0905 21:21:51.691479 90901 sgd_solver.cpp:106] Iteration 63010, lr = 0.01
I0905 21:22:07.915925 90901 solver.cpp:228] Iteration 63020, loss = 0.166836
I0905 21:22:07.915999 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166838 (* 1 = 0.166838 loss)
I0905 21:22:07.916023 90901 sgd_solver.cpp:106] Iteration 63020, lr = 0.01
I0905 21:22:25.431740 90901 solver.cpp:228] Iteration 63030, loss = 0.397822
I0905 21:22:25.431951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397824 (* 1 = 0.397824 loss)
I0905 21:22:25.431972 90901 sgd_solver.cpp:106] Iteration 63030, lr = 0.01
I0905 21:22:43.313321 90901 solver.cpp:228] Iteration 63040, loss = 0.275409
I0905 21:22:43.313412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27541 (* 1 = 0.27541 loss)
I0905 21:22:43.313436 90901 sgd_solver.cpp:106] Iteration 63040, lr = 0.01
I0905 21:23:00.902266 90901 solver.cpp:228] Iteration 63050, loss = 0.501392
I0905 21:23:00.902565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501394 (* 1 = 0.501394 loss)
I0905 21:23:00.902595 90901 sgd_solver.cpp:106] Iteration 63050, lr = 0.01
I0905 21:23:18.981489 90901 solver.cpp:228] Iteration 63060, loss = 0.0461894
I0905 21:23:18.981580 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.046191 (* 1 = 0.046191 loss)
I0905 21:23:18.981595 90901 sgd_solver.cpp:106] Iteration 63060, lr = 0.01
I0905 21:23:36.395380 90901 solver.cpp:228] Iteration 63070, loss = 0.220305
I0905 21:23:36.395961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220307 (* 1 = 0.220307 loss)
I0905 21:23:36.396010 90901 sgd_solver.cpp:106] Iteration 63070, lr = 0.01
I0905 21:23:54.794730 90901 solver.cpp:228] Iteration 63080, loss = 0.12599
I0905 21:23:54.794826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125992 (* 1 = 0.125992 loss)
I0905 21:23:54.794850 90901 sgd_solver.cpp:106] Iteration 63080, lr = 0.01
I0905 21:24:13.780755 90901 solver.cpp:228] Iteration 63090, loss = 0.237892
I0905 21:24:13.780975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237893 (* 1 = 0.237893 loss)
I0905 21:24:13.781008 90901 sgd_solver.cpp:106] Iteration 63090, lr = 0.01
I0905 21:24:31.927692 90901 solver.cpp:228] Iteration 63100, loss = 0.213086
I0905 21:24:31.927767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213087 (* 1 = 0.213087 loss)
I0905 21:24:31.927783 90901 sgd_solver.cpp:106] Iteration 63100, lr = 0.01
I0905 21:24:51.077630 90901 solver.cpp:228] Iteration 63110, loss = 0.219452
I0905 21:24:51.077848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219454 (* 1 = 0.219454 loss)
I0905 21:24:51.077870 90901 sgd_solver.cpp:106] Iteration 63110, lr = 0.01
I0905 21:25:09.271728 90901 solver.cpp:228] Iteration 63120, loss = 0.364773
I0905 21:25:09.271809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364774 (* 1 = 0.364774 loss)
I0905 21:25:09.271827 90901 sgd_solver.cpp:106] Iteration 63120, lr = 0.01
I0905 21:25:27.703727 90901 solver.cpp:228] Iteration 63130, loss = 0.473878
I0905 21:25:27.703951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.47388 (* 1 = 0.47388 loss)
I0905 21:25:27.703971 90901 sgd_solver.cpp:106] Iteration 63130, lr = 0.01
I0905 21:25:45.304855 90901 solver.cpp:228] Iteration 63140, loss = 0.273039
I0905 21:25:45.304947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273041 (* 1 = 0.273041 loss)
I0905 21:25:45.304968 90901 sgd_solver.cpp:106] Iteration 63140, lr = 0.01
I0905 21:26:02.335434 90901 solver.cpp:228] Iteration 63150, loss = 0.210055
I0905 21:26:02.335634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210057 (* 1 = 0.210057 loss)
I0905 21:26:02.335672 90901 sgd_solver.cpp:106] Iteration 63150, lr = 0.01
I0905 21:26:20.819162 90901 solver.cpp:228] Iteration 63160, loss = 0.104319
I0905 21:26:20.819231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104321 (* 1 = 0.104321 loss)
I0905 21:26:20.819248 90901 sgd_solver.cpp:106] Iteration 63160, lr = 0.01
I0905 21:26:39.905709 90901 solver.cpp:228] Iteration 63170, loss = 0.12839
I0905 21:26:39.906033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128392 (* 1 = 0.128392 loss)
I0905 21:26:39.906059 90901 sgd_solver.cpp:106] Iteration 63170, lr = 0.01
I0905 21:26:57.292023 90901 solver.cpp:228] Iteration 63180, loss = 0.528506
I0905 21:26:57.292093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.528508 (* 1 = 0.528508 loss)
I0905 21:26:57.292111 90901 sgd_solver.cpp:106] Iteration 63180, lr = 0.01
I0905 21:27:14.281602 90901 solver.cpp:228] Iteration 63190, loss = 0.485206
I0905 21:27:14.281729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.485207 (* 1 = 0.485207 loss)
I0905 21:27:14.281749 90901 sgd_solver.cpp:106] Iteration 63190, lr = 0.01
I0905 21:27:33.148723 90901 solver.cpp:337] Iteration 63200, Testing net (#0)
I0905 21:29:18.649461 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.838437
I0905 21:29:18.649647 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.424961 (* 1 = 0.424961 loss)
I0905 21:29:19.454540 90901 solver.cpp:228] Iteration 63200, loss = 0.194154
I0905 21:29:19.454618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194155 (* 1 = 0.194155 loss)
I0905 21:29:19.454655 90901 sgd_solver.cpp:106] Iteration 63200, lr = 0.01
I0905 21:29:34.082964 90901 solver.cpp:228] Iteration 63210, loss = 0.181748
I0905 21:29:34.083045 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181749 (* 1 = 0.181749 loss)
I0905 21:29:34.083065 90901 sgd_solver.cpp:106] Iteration 63210, lr = 0.01
I0905 21:29:47.958838 90901 solver.cpp:228] Iteration 63220, loss = 0.15379
I0905 21:29:47.958910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153791 (* 1 = 0.153791 loss)
I0905 21:29:47.958927 90901 sgd_solver.cpp:106] Iteration 63220, lr = 0.01
I0905 21:29:57.648360 90901 solver.cpp:228] Iteration 63230, loss = 0.304102
I0905 21:29:57.648571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.304103 (* 1 = 0.304103 loss)
I0905 21:29:57.648591 90901 sgd_solver.cpp:106] Iteration 63230, lr = 0.01
I0905 21:30:05.447867 90901 solver.cpp:228] Iteration 63240, loss = 0.199969
I0905 21:30:05.447960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199971 (* 1 = 0.199971 loss)
I0905 21:30:05.447983 90901 sgd_solver.cpp:106] Iteration 63240, lr = 0.01
I0905 21:30:13.891926 90901 solver.cpp:228] Iteration 63250, loss = 0.152085
I0905 21:30:13.891997 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152087 (* 1 = 0.152087 loss)
I0905 21:30:13.892015 90901 sgd_solver.cpp:106] Iteration 63250, lr = 0.01
I0905 21:30:24.841202 90901 solver.cpp:228] Iteration 63260, loss = 0.10968
I0905 21:30:24.841295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109682 (* 1 = 0.109682 loss)
I0905 21:30:24.841313 90901 sgd_solver.cpp:106] Iteration 63260, lr = 0.01
I0905 21:30:35.647372 90901 solver.cpp:228] Iteration 63270, loss = 0.842406
I0905 21:30:35.647558 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.842408 (* 1 = 0.842408 loss)
I0905 21:30:35.647588 90901 sgd_solver.cpp:106] Iteration 63270, lr = 0.01
I0905 21:30:49.364135 90901 solver.cpp:228] Iteration 63280, loss = 0.0971786
I0905 21:30:49.364205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0971802 (* 1 = 0.0971802 loss)
I0905 21:30:49.364224 90901 sgd_solver.cpp:106] Iteration 63280, lr = 0.01
I0905 21:31:05.447103 90901 solver.cpp:228] Iteration 63290, loss = 0.279309
I0905 21:31:05.447166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279311 (* 1 = 0.279311 loss)
I0905 21:31:05.447183 90901 sgd_solver.cpp:106] Iteration 63290, lr = 0.01
I0905 21:31:21.040144 90901 solver.cpp:228] Iteration 63300, loss = 0.176592
I0905 21:31:21.040338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176593 (* 1 = 0.176593 loss)
I0905 21:31:21.040359 90901 sgd_solver.cpp:106] Iteration 63300, lr = 0.01
I0905 21:31:38.598737 90901 solver.cpp:228] Iteration 63310, loss = 0.21893
I0905 21:31:38.598805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218931 (* 1 = 0.218931 loss)
I0905 21:31:38.598824 90901 sgd_solver.cpp:106] Iteration 63310, lr = 0.01
I0905 21:31:56.188755 90901 solver.cpp:228] Iteration 63320, loss = 0.291683
I0905 21:31:56.188940 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291684 (* 1 = 0.291684 loss)
I0905 21:31:56.188979 90901 sgd_solver.cpp:106] Iteration 63320, lr = 0.01
I0905 21:32:13.366658 90901 solver.cpp:228] Iteration 63330, loss = 0.0791805
I0905 21:32:13.366752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0791822 (* 1 = 0.0791822 loss)
I0905 21:32:13.366770 90901 sgd_solver.cpp:106] Iteration 63330, lr = 0.01
I0905 21:32:31.338737 90901 solver.cpp:228] Iteration 63340, loss = 0.0879816
I0905 21:32:31.338948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0879833 (* 1 = 0.0879833 loss)
I0905 21:32:31.338980 90901 sgd_solver.cpp:106] Iteration 63340, lr = 0.01
I0905 21:32:48.808080 90901 solver.cpp:228] Iteration 63350, loss = 0.197633
I0905 21:32:48.808184 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197635 (* 1 = 0.197635 loss)
I0905 21:32:48.808203 90901 sgd_solver.cpp:106] Iteration 63350, lr = 0.01
I0905 21:33:04.915699 90901 solver.cpp:228] Iteration 63360, loss = 0.175517
I0905 21:33:04.926692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175519 (* 1 = 0.175519 loss)
I0905 21:33:04.926709 90901 sgd_solver.cpp:106] Iteration 63360, lr = 0.01
I0905 21:33:22.224956 90901 solver.cpp:228] Iteration 63370, loss = 0.0345537
I0905 21:33:22.225025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0345554 (* 1 = 0.0345554 loss)
I0905 21:33:22.225041 90901 sgd_solver.cpp:106] Iteration 63370, lr = 0.01
I0905 21:33:39.135434 90901 solver.cpp:228] Iteration 63380, loss = 0.196337
I0905 21:33:39.135704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196339 (* 1 = 0.196339 loss)
I0905 21:33:39.135718 90901 sgd_solver.cpp:106] Iteration 63380, lr = 0.01
I0905 21:33:57.125560 90901 solver.cpp:228] Iteration 63390, loss = 0.212806
I0905 21:33:57.125707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212808 (* 1 = 0.212808 loss)
I0905 21:33:57.125742 90901 sgd_solver.cpp:106] Iteration 63390, lr = 0.01
I0905 21:34:14.210481 90901 solver.cpp:228] Iteration 63400, loss = 0.203687
I0905 21:34:14.210685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203689 (* 1 = 0.203689 loss)
I0905 21:34:14.210705 90901 sgd_solver.cpp:106] Iteration 63400, lr = 0.01
I0905 21:34:30.170203 90901 solver.cpp:228] Iteration 63410, loss = 0.17423
I0905 21:34:30.170313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174232 (* 1 = 0.174232 loss)
I0905 21:34:30.170334 90901 sgd_solver.cpp:106] Iteration 63410, lr = 0.01
I0905 21:34:45.595257 90901 solver.cpp:228] Iteration 63420, loss = 0.377972
I0905 21:34:45.595466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.377974 (* 1 = 0.377974 loss)
I0905 21:34:45.595480 90901 sgd_solver.cpp:106] Iteration 63420, lr = 0.01
I0905 21:35:02.668417 90901 solver.cpp:228] Iteration 63430, loss = 0.288276
I0905 21:35:02.668509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288278 (* 1 = 0.288278 loss)
I0905 21:35:02.668529 90901 sgd_solver.cpp:106] Iteration 63430, lr = 0.01
I0905 21:35:16.760735 90901 solver.cpp:228] Iteration 63440, loss = 0.23227
I0905 21:35:16.760977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232272 (* 1 = 0.232272 loss)
I0905 21:35:16.761008 90901 sgd_solver.cpp:106] Iteration 63440, lr = 0.01
I0905 21:35:31.592758 90901 solver.cpp:228] Iteration 63450, loss = 0.284809
I0905 21:35:31.592828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284811 (* 1 = 0.284811 loss)
I0905 21:35:31.592844 90901 sgd_solver.cpp:106] Iteration 63450, lr = 0.01
I0905 21:35:47.510387 90901 solver.cpp:228] Iteration 63460, loss = 0.183237
I0905 21:35:47.510571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183239 (* 1 = 0.183239 loss)
I0905 21:35:47.510603 90901 sgd_solver.cpp:106] Iteration 63460, lr = 0.01
I0905 21:35:59.526736 90901 solver.cpp:228] Iteration 63470, loss = 0.0638774
I0905 21:35:59.526830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.063879 (* 1 = 0.063879 loss)
I0905 21:35:59.526846 90901 sgd_solver.cpp:106] Iteration 63470, lr = 0.01
I0905 21:36:11.003121 90901 solver.cpp:228] Iteration 63480, loss = 0.0975335
I0905 21:36:11.003227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0975352 (* 1 = 0.0975352 loss)
I0905 21:36:11.003248 90901 sgd_solver.cpp:106] Iteration 63480, lr = 0.01
I0905 21:36:23.159451 90901 solver.cpp:228] Iteration 63490, loss = 0.284507
I0905 21:36:23.159659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284509 (* 1 = 0.284509 loss)
I0905 21:36:23.159677 90901 sgd_solver.cpp:106] Iteration 63490, lr = 0.01
I0905 21:36:34.523054 90901 solver.cpp:228] Iteration 63500, loss = 0.164126
I0905 21:36:34.523160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164127 (* 1 = 0.164127 loss)
I0905 21:36:34.523185 90901 sgd_solver.cpp:106] Iteration 63500, lr = 0.01
I0905 21:36:45.753904 90901 solver.cpp:228] Iteration 63510, loss = 0.459318
I0905 21:36:45.753984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.459319 (* 1 = 0.459319 loss)
I0905 21:36:45.754003 90901 sgd_solver.cpp:106] Iteration 63510, lr = 0.01
I0905 21:36:55.907008 90901 solver.cpp:228] Iteration 63520, loss = 0.106201
I0905 21:36:55.907160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106203 (* 1 = 0.106203 loss)
I0905 21:36:55.907181 90901 sgd_solver.cpp:106] Iteration 63520, lr = 0.01
I0905 21:37:11.647483 90901 solver.cpp:228] Iteration 63530, loss = 0.189676
I0905 21:37:11.647574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189678 (* 1 = 0.189678 loss)
I0905 21:37:11.647594 90901 sgd_solver.cpp:106] Iteration 63530, lr = 0.01
I0905 21:37:28.659963 90901 solver.cpp:228] Iteration 63540, loss = 0.472901
I0905 21:37:28.660173 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.472903 (* 1 = 0.472903 loss)
I0905 21:37:28.660192 90901 sgd_solver.cpp:106] Iteration 63540, lr = 0.01
I0905 21:37:44.490257 90901 solver.cpp:228] Iteration 63550, loss = 0.187503
I0905 21:37:44.490327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187505 (* 1 = 0.187505 loss)
I0905 21:37:44.490345 90901 sgd_solver.cpp:106] Iteration 63550, lr = 0.01
I0905 21:38:02.105842 90901 solver.cpp:228] Iteration 63560, loss = 0.251991
I0905 21:38:02.106036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251992 (* 1 = 0.251992 loss)
I0905 21:38:02.106083 90901 sgd_solver.cpp:106] Iteration 63560, lr = 0.01
I0905 21:38:18.002238 90901 solver.cpp:228] Iteration 63570, loss = 0.199143
I0905 21:38:18.002327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199145 (* 1 = 0.199145 loss)
I0905 21:38:18.002347 90901 sgd_solver.cpp:106] Iteration 63570, lr = 0.01
I0905 21:38:33.813303 90901 solver.cpp:228] Iteration 63580, loss = 0.0850531
I0905 21:38:33.813439 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0850549 (* 1 = 0.0850549 loss)
I0905 21:38:33.813457 90901 sgd_solver.cpp:106] Iteration 63580, lr = 0.01
I0905 21:38:49.223692 90901 solver.cpp:228] Iteration 63590, loss = 0.0850039
I0905 21:38:49.223783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0850057 (* 1 = 0.0850057 loss)
I0905 21:38:49.223808 90901 sgd_solver.cpp:106] Iteration 63590, lr = 0.01
I0905 21:39:03.433603 90901 solver.cpp:228] Iteration 63600, loss = 0.381699
I0905 21:39:03.433676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381701 (* 1 = 0.381701 loss)
I0905 21:39:03.433692 90901 sgd_solver.cpp:106] Iteration 63600, lr = 0.01
I0905 21:39:17.297715 90901 solver.cpp:228] Iteration 63610, loss = 0.183733
I0905 21:39:17.297894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183735 (* 1 = 0.183735 loss)
I0905 21:39:17.297946 90901 sgd_solver.cpp:106] Iteration 63610, lr = 0.01
I0905 21:39:32.306748 90901 solver.cpp:228] Iteration 63620, loss = 0.542188
I0905 21:39:32.306839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.54219 (* 1 = 0.54219 loss)
I0905 21:39:32.306861 90901 sgd_solver.cpp:106] Iteration 63620, lr = 0.01
I0905 21:39:43.466828 90901 solver.cpp:228] Iteration 63630, loss = 0.236519
I0905 21:39:43.466897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236521 (* 1 = 0.236521 loss)
I0905 21:39:43.466913 90901 sgd_solver.cpp:106] Iteration 63630, lr = 0.01
I0905 21:39:55.102469 90901 solver.cpp:228] Iteration 63640, loss = 0.40292
I0905 21:39:55.102754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.402922 (* 1 = 0.402922 loss)
I0905 21:39:55.102774 90901 sgd_solver.cpp:106] Iteration 63640, lr = 0.01
I0905 21:40:07.347126 90901 solver.cpp:228] Iteration 63650, loss = 0.301265
I0905 21:40:07.347211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301267 (* 1 = 0.301267 loss)
I0905 21:40:07.347229 90901 sgd_solver.cpp:106] Iteration 63650, lr = 0.01
I0905 21:40:19.588524 90901 solver.cpp:228] Iteration 63660, loss = 0.313338
I0905 21:40:19.588589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31334 (* 1 = 0.31334 loss)
I0905 21:40:19.588608 90901 sgd_solver.cpp:106] Iteration 63660, lr = 0.01
I0905 21:40:32.773661 90901 solver.cpp:228] Iteration 63670, loss = 0.277267
I0905 21:40:32.773902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277269 (* 1 = 0.277269 loss)
I0905 21:40:32.773921 90901 sgd_solver.cpp:106] Iteration 63670, lr = 0.01
I0905 21:40:49.215726 90901 solver.cpp:228] Iteration 63680, loss = 0.167838
I0905 21:40:49.215811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16784 (* 1 = 0.16784 loss)
I0905 21:40:49.215829 90901 sgd_solver.cpp:106] Iteration 63680, lr = 0.01
I0905 21:41:06.970003 90901 solver.cpp:228] Iteration 63690, loss = 0.164313
I0905 21:41:06.970263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164315 (* 1 = 0.164315 loss)
I0905 21:41:06.970286 90901 sgd_solver.cpp:106] Iteration 63690, lr = 0.01
I0905 21:41:26.633713 90901 solver.cpp:228] Iteration 63700, loss = 0.144025
I0905 21:41:26.633783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144027 (* 1 = 0.144027 loss)
I0905 21:41:26.633805 90901 sgd_solver.cpp:106] Iteration 63700, lr = 0.01
I0905 21:41:44.456944 90901 solver.cpp:228] Iteration 63710, loss = 0.285387
I0905 21:41:44.457139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285389 (* 1 = 0.285389 loss)
I0905 21:41:44.457161 90901 sgd_solver.cpp:106] Iteration 63710, lr = 0.01
I0905 21:42:02.951887 90901 solver.cpp:228] Iteration 63720, loss = 0.115754
I0905 21:42:02.951967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115756 (* 1 = 0.115756 loss)
I0905 21:42:02.951989 90901 sgd_solver.cpp:106] Iteration 63720, lr = 0.01
I0905 21:42:21.641124 90901 solver.cpp:228] Iteration 63730, loss = 0.23601
I0905 21:42:21.641343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236012 (* 1 = 0.236012 loss)
I0905 21:42:21.641386 90901 sgd_solver.cpp:106] Iteration 63730, lr = 0.01
I0905 21:42:39.066253 90901 solver.cpp:228] Iteration 63740, loss = 0.249476
I0905 21:42:39.066314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249477 (* 1 = 0.249477 loss)
I0905 21:42:39.066332 90901 sgd_solver.cpp:106] Iteration 63740, lr = 0.01
I0905 21:42:58.661566 90901 solver.cpp:228] Iteration 63750, loss = 0.125629
I0905 21:42:58.661825 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12563 (* 1 = 0.12563 loss)
I0905 21:42:58.661855 90901 sgd_solver.cpp:106] Iteration 63750, lr = 0.01
I0905 21:43:17.717871 90901 solver.cpp:228] Iteration 63760, loss = 0.0803105
I0905 21:43:17.717954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0803122 (* 1 = 0.0803122 loss)
I0905 21:43:17.717973 90901 sgd_solver.cpp:106] Iteration 63760, lr = 0.01
I0905 21:43:36.834818 90901 solver.cpp:228] Iteration 63770, loss = 0.149289
I0905 21:43:36.835017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149291 (* 1 = 0.149291 loss)
I0905 21:43:36.835049 90901 sgd_solver.cpp:106] Iteration 63770, lr = 0.01
I0905 21:43:54.521595 90901 solver.cpp:228] Iteration 63780, loss = 0.189049
I0905 21:43:54.521667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189051 (* 1 = 0.189051 loss)
I0905 21:43:54.521680 90901 sgd_solver.cpp:106] Iteration 63780, lr = 0.01
I0905 21:44:13.035661 90901 solver.cpp:228] Iteration 63790, loss = 0.258904
I0905 21:44:13.035856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258906 (* 1 = 0.258906 loss)
I0905 21:44:13.035878 90901 sgd_solver.cpp:106] Iteration 63790, lr = 0.01
I0905 21:44:33.332424 90901 solver.cpp:228] Iteration 63800, loss = 0.276504
I0905 21:44:33.332535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276506 (* 1 = 0.276506 loss)
I0905 21:44:33.332556 90901 sgd_solver.cpp:106] Iteration 63800, lr = 0.01
I0905 21:44:51.637209 90901 solver.cpp:228] Iteration 63810, loss = 0.0552444
I0905 21:44:51.637342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0552463 (* 1 = 0.0552463 loss)
I0905 21:44:51.637359 90901 sgd_solver.cpp:106] Iteration 63810, lr = 0.01
I0905 21:45:11.483376 90901 solver.cpp:228] Iteration 63820, loss = 0.151755
I0905 21:45:11.483470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151757 (* 1 = 0.151757 loss)
I0905 21:45:11.483487 90901 sgd_solver.cpp:106] Iteration 63820, lr = 0.01
I0905 21:45:24.728384 90901 solver.cpp:228] Iteration 63830, loss = 0.0488932
I0905 21:45:24.728590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.048895 (* 1 = 0.048895 loss)
I0905 21:45:24.728610 90901 sgd_solver.cpp:106] Iteration 63830, lr = 0.01
I0905 21:45:35.826411 90901 solver.cpp:228] Iteration 63840, loss = 0.355995
I0905 21:45:35.826503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355997 (* 1 = 0.355997 loss)
I0905 21:45:35.826521 90901 sgd_solver.cpp:106] Iteration 63840, lr = 0.01
I0905 21:45:47.015987 90901 solver.cpp:228] Iteration 63850, loss = 0.0726528
I0905 21:45:47.016078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0726546 (* 1 = 0.0726546 loss)
I0905 21:45:47.016103 90901 sgd_solver.cpp:106] Iteration 63850, lr = 0.01
I0905 21:45:57.937537 90901 solver.cpp:228] Iteration 63860, loss = 0.172891
I0905 21:45:57.937682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172892 (* 1 = 0.172892 loss)
I0905 21:45:57.937696 90901 sgd_solver.cpp:106] Iteration 63860, lr = 0.01
I0905 21:46:09.108208 90901 solver.cpp:228] Iteration 63870, loss = 0.403617
I0905 21:46:09.108327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403619 (* 1 = 0.403619 loss)
I0905 21:46:09.108351 90901 sgd_solver.cpp:106] Iteration 63870, lr = 0.01
I0905 21:46:19.872555 90901 solver.cpp:228] Iteration 63880, loss = 0.0784326
I0905 21:46:19.872635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0784344 (* 1 = 0.0784344 loss)
I0905 21:46:19.872654 90901 sgd_solver.cpp:106] Iteration 63880, lr = 0.01
I0905 21:46:34.461366 90901 solver.cpp:228] Iteration 63890, loss = 0.435486
I0905 21:46:34.461534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435488 (* 1 = 0.435488 loss)
I0905 21:46:34.461575 90901 sgd_solver.cpp:106] Iteration 63890, lr = 0.01
I0905 21:46:51.837508 90901 solver.cpp:228] Iteration 63900, loss = 0.138537
I0905 21:46:51.837574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138539 (* 1 = 0.138539 loss)
I0905 21:46:51.837591 90901 sgd_solver.cpp:106] Iteration 63900, lr = 0.01
I0905 21:47:08.642539 90901 solver.cpp:228] Iteration 63910, loss = 0.255873
I0905 21:47:08.642702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255875 (* 1 = 0.255875 loss)
I0905 21:47:08.642719 90901 sgd_solver.cpp:106] Iteration 63910, lr = 0.01
I0905 21:47:27.317579 90901 solver.cpp:228] Iteration 63920, loss = 0.189512
I0905 21:47:27.317680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189514 (* 1 = 0.189514 loss)
I0905 21:47:27.317700 90901 sgd_solver.cpp:106] Iteration 63920, lr = 0.01
I0905 21:47:43.373740 90901 solver.cpp:228] Iteration 63930, loss = 0.132029
I0905 21:47:43.373891 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132031 (* 1 = 0.132031 loss)
I0905 21:47:43.373911 90901 sgd_solver.cpp:106] Iteration 63930, lr = 0.01
I0905 21:48:01.899826 90901 solver.cpp:228] Iteration 63940, loss = 0.025729
I0905 21:48:01.899952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0257308 (* 1 = 0.0257308 loss)
I0905 21:48:01.899971 90901 sgd_solver.cpp:106] Iteration 63940, lr = 0.01
I0905 21:48:20.912832 90901 solver.cpp:228] Iteration 63950, loss = 0.151121
I0905 21:48:20.912978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151123 (* 1 = 0.151123 loss)
I0905 21:48:20.912998 90901 sgd_solver.cpp:106] Iteration 63950, lr = 0.01
I0905 21:48:40.356983 90901 solver.cpp:228] Iteration 63960, loss = 0.194842
I0905 21:48:40.357069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194844 (* 1 = 0.194844 loss)
I0905 21:48:40.357089 90901 sgd_solver.cpp:106] Iteration 63960, lr = 0.01
I0905 21:48:59.062352 90901 solver.cpp:228] Iteration 63970, loss = 0.176005
I0905 21:48:59.062535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176007 (* 1 = 0.176007 loss)
I0905 21:48:59.062585 90901 sgd_solver.cpp:106] Iteration 63970, lr = 0.01
I0905 21:49:16.861093 90901 solver.cpp:228] Iteration 63980, loss = 0.157324
I0905 21:49:16.861177 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157326 (* 1 = 0.157326 loss)
I0905 21:49:16.861196 90901 sgd_solver.cpp:106] Iteration 63980, lr = 0.01
I0905 21:49:35.099578 90901 solver.cpp:228] Iteration 63990, loss = 0.244214
I0905 21:49:35.100044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244216 (* 1 = 0.244216 loss)
I0905 21:49:35.100080 90901 sgd_solver.cpp:106] Iteration 63990, lr = 0.01
I0905 21:49:51.627241 90901 solver.cpp:337] Iteration 64000, Testing net (#0)
I0905 21:51:44.443425 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.813438
I0905 21:51:44.443637 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.539306 (* 1 = 0.539306 loss)
I0905 21:51:45.042913 90901 solver.cpp:228] Iteration 64000, loss = 0.314219
I0905 21:51:45.042979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31422 (* 1 = 0.31422 loss)
I0905 21:51:45.042999 90901 sgd_solver.cpp:106] Iteration 64000, lr = 0.01
I0905 21:52:04.095775 90901 solver.cpp:228] Iteration 64010, loss = 0.0747246
I0905 21:52:04.095927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0747263 (* 1 = 0.0747263 loss)
I0905 21:52:04.095948 90901 sgd_solver.cpp:106] Iteration 64010, lr = 0.01
I0905 21:52:20.877100 90901 solver.cpp:228] Iteration 64020, loss = 0.419242
I0905 21:52:20.877305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419244 (* 1 = 0.419244 loss)
I0905 21:52:20.877352 90901 sgd_solver.cpp:106] Iteration 64020, lr = 0.01
I0905 21:52:38.259048 90901 solver.cpp:228] Iteration 64030, loss = 0.180554
I0905 21:52:38.259147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180556 (* 1 = 0.180556 loss)
I0905 21:52:38.259166 90901 sgd_solver.cpp:106] Iteration 64030, lr = 0.01
I0905 21:52:55.211102 90901 solver.cpp:228] Iteration 64040, loss = 0.425479
I0905 21:52:55.211382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425481 (* 1 = 0.425481 loss)
I0905 21:52:55.211413 90901 sgd_solver.cpp:106] Iteration 64040, lr = 0.01
I0905 21:53:11.808360 90901 solver.cpp:228] Iteration 64050, loss = 0.748514
I0905 21:53:11.808501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.748516 (* 1 = 0.748516 loss)
I0905 21:53:11.808521 90901 sgd_solver.cpp:106] Iteration 64050, lr = 0.01
I0905 21:53:29.901556 90901 solver.cpp:228] Iteration 64060, loss = 0.439266
I0905 21:53:29.901811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.439268 (* 1 = 0.439268 loss)
I0905 21:53:29.901842 90901 sgd_solver.cpp:106] Iteration 64060, lr = 0.01
I0905 21:53:46.734748 90901 solver.cpp:228] Iteration 64070, loss = 0.0734282
I0905 21:53:46.734822 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0734301 (* 1 = 0.0734301 loss)
I0905 21:53:46.734844 90901 sgd_solver.cpp:106] Iteration 64070, lr = 0.01
I0905 21:54:04.238580 90901 solver.cpp:228] Iteration 64080, loss = 0.181677
I0905 21:54:04.239132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181679 (* 1 = 0.181679 loss)
I0905 21:54:04.239151 90901 sgd_solver.cpp:106] Iteration 64080, lr = 0.01
I0905 21:54:15.535576 90901 solver.cpp:228] Iteration 64090, loss = 0.182675
I0905 21:54:15.535683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182677 (* 1 = 0.182677 loss)
I0905 21:54:15.535708 90901 sgd_solver.cpp:106] Iteration 64090, lr = 0.01
I0905 21:54:31.057945 90901 solver.cpp:228] Iteration 64100, loss = 0.0743682
I0905 21:54:31.058022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.07437 (* 1 = 0.07437 loss)
I0905 21:54:31.058038 90901 sgd_solver.cpp:106] Iteration 64100, lr = 0.01
I0905 21:54:48.034272 90901 solver.cpp:228] Iteration 64110, loss = 0.217303
I0905 21:54:48.034438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217305 (* 1 = 0.217305 loss)
I0905 21:54:48.034485 90901 sgd_solver.cpp:106] Iteration 64110, lr = 0.01
I0905 21:55:03.440501 90901 solver.cpp:228] Iteration 64120, loss = 0.10977
I0905 21:55:03.440582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109772 (* 1 = 0.109772 loss)
I0905 21:55:03.440601 90901 sgd_solver.cpp:106] Iteration 64120, lr = 0.01
I0905 21:55:17.000144 90901 solver.cpp:228] Iteration 64130, loss = 0.289289
I0905 21:55:17.000241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289291 (* 1 = 0.289291 loss)
I0905 21:55:17.000258 90901 sgd_solver.cpp:106] Iteration 64130, lr = 0.01
I0905 21:55:28.784751 90901 solver.cpp:228] Iteration 64140, loss = 0.271472
I0905 21:55:28.785006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271474 (* 1 = 0.271474 loss)
I0905 21:55:28.785027 90901 sgd_solver.cpp:106] Iteration 64140, lr = 0.01
I0905 21:55:40.917244 90901 solver.cpp:228] Iteration 64150, loss = 0.160381
I0905 21:55:40.917316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160383 (* 1 = 0.160383 loss)
I0905 21:55:40.917332 90901 sgd_solver.cpp:106] Iteration 64150, lr = 0.01
I0905 21:55:48.754035 90901 solver.cpp:228] Iteration 64160, loss = 0.0688762
I0905 21:55:48.754112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0688779 (* 1 = 0.0688779 loss)
I0905 21:55:48.754132 90901 sgd_solver.cpp:106] Iteration 64160, lr = 0.01
I0905 21:55:56.470279 90901 solver.cpp:228] Iteration 64170, loss = 0.117856
I0905 21:55:56.470379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117858 (* 1 = 0.117858 loss)
I0905 21:55:56.470399 90901 sgd_solver.cpp:106] Iteration 64170, lr = 0.01
I0905 21:56:04.183658 90901 solver.cpp:228] Iteration 64180, loss = 0.240683
I0905 21:56:04.183832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240685 (* 1 = 0.240685 loss)
I0905 21:56:04.183868 90901 sgd_solver.cpp:106] Iteration 64180, lr = 0.01
I0905 21:56:12.098044 90901 solver.cpp:228] Iteration 64190, loss = 0.115008
I0905 21:56:12.098119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11501 (* 1 = 0.11501 loss)
I0905 21:56:12.098137 90901 sgd_solver.cpp:106] Iteration 64190, lr = 0.01
I0905 21:56:19.932093 90901 solver.cpp:228] Iteration 64200, loss = 0.387721
I0905 21:56:19.932159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387723 (* 1 = 0.387723 loss)
I0905 21:56:19.932174 90901 sgd_solver.cpp:106] Iteration 64200, lr = 0.01
I0905 21:56:27.189010 90901 solver.cpp:228] Iteration 64210, loss = 0.232541
I0905 21:56:27.189074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232542 (* 1 = 0.232542 loss)
I0905 21:56:27.189090 90901 sgd_solver.cpp:106] Iteration 64210, lr = 0.01
I0905 21:56:33.179271 90901 solver.cpp:228] Iteration 64220, loss = 0.245816
I0905 21:56:33.179340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245818 (* 1 = 0.245818 loss)
I0905 21:56:33.179358 90901 sgd_solver.cpp:106] Iteration 64220, lr = 0.01
I0905 21:56:45.107786 90901 solver.cpp:228] Iteration 64230, loss = 0.232251
I0905 21:56:45.107993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232253 (* 1 = 0.232253 loss)
I0905 21:56:45.108024 90901 sgd_solver.cpp:106] Iteration 64230, lr = 0.01
I0905 21:57:00.014461 90901 solver.cpp:228] Iteration 64240, loss = 0.0334554
I0905 21:57:00.014561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0334572 (* 1 = 0.0334572 loss)
I0905 21:57:00.014588 90901 sgd_solver.cpp:106] Iteration 64240, lr = 0.01
I0905 21:57:13.379701 90901 solver.cpp:228] Iteration 64250, loss = 0.578258
I0905 21:57:13.379771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578259 (* 1 = 0.578259 loss)
I0905 21:57:13.379786 90901 sgd_solver.cpp:106] Iteration 64250, lr = 0.01
I0905 21:57:26.962509 90901 solver.cpp:228] Iteration 64260, loss = 0.230503
I0905 21:57:26.962909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230504 (* 1 = 0.230504 loss)
I0905 21:57:26.962932 90901 sgd_solver.cpp:106] Iteration 64260, lr = 0.01
I0905 21:57:44.304656 90901 solver.cpp:228] Iteration 64270, loss = 0.174949
I0905 21:57:44.304749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174951 (* 1 = 0.174951 loss)
I0905 21:57:44.304771 90901 sgd_solver.cpp:106] Iteration 64270, lr = 0.01
I0905 21:58:01.401235 90901 solver.cpp:228] Iteration 64280, loss = 0.387674
I0905 21:58:01.401540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387676 (* 1 = 0.387676 loss)
I0905 21:58:01.401561 90901 sgd_solver.cpp:106] Iteration 64280, lr = 0.01
I0905 21:58:17.890256 90901 solver.cpp:228] Iteration 64290, loss = 0.150708
I0905 21:58:17.890355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15071 (* 1 = 0.15071 loss)
I0905 21:58:17.890393 90901 sgd_solver.cpp:106] Iteration 64290, lr = 0.01
I0905 21:58:36.530587 90901 solver.cpp:228] Iteration 64300, loss = 0.194035
I0905 21:58:36.530772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194037 (* 1 = 0.194037 loss)
I0905 21:58:36.530793 90901 sgd_solver.cpp:106] Iteration 64300, lr = 0.01
I0905 21:58:53.223809 90901 solver.cpp:228] Iteration 64310, loss = 0.224748
I0905 21:58:53.223912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22475 (* 1 = 0.22475 loss)
I0905 21:58:53.223947 90901 sgd_solver.cpp:106] Iteration 64310, lr = 0.01
I0905 21:59:10.799746 90901 solver.cpp:228] Iteration 64320, loss = 0.201716
I0905 21:59:10.799942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201717 (* 1 = 0.201717 loss)
I0905 21:59:10.799971 90901 sgd_solver.cpp:106] Iteration 64320, lr = 0.01
I0905 21:59:28.282791 90901 solver.cpp:228] Iteration 64330, loss = 0.201836
I0905 21:59:28.282887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201838 (* 1 = 0.201838 loss)
I0905 21:59:28.282919 90901 sgd_solver.cpp:106] Iteration 64330, lr = 0.01
I0905 21:59:45.308190 90901 solver.cpp:228] Iteration 64340, loss = 0.0468427
I0905 21:59:45.308358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0468445 (* 1 = 0.0468445 loss)
I0905 21:59:45.308385 90901 sgd_solver.cpp:106] Iteration 64340, lr = 0.01
I0905 22:00:04.695107 90901 solver.cpp:228] Iteration 64350, loss = 0.333972
I0905 22:00:04.695199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333974 (* 1 = 0.333974 loss)
I0905 22:00:04.695221 90901 sgd_solver.cpp:106] Iteration 64350, lr = 0.01
I0905 22:00:20.259028 90901 solver.cpp:228] Iteration 64360, loss = 0.135487
I0905 22:00:20.259222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135489 (* 1 = 0.135489 loss)
I0905 22:00:20.259241 90901 sgd_solver.cpp:106] Iteration 64360, lr = 0.01
I0905 22:00:38.548646 90901 solver.cpp:228] Iteration 64370, loss = 0.101307
I0905 22:00:38.548725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101309 (* 1 = 0.101309 loss)
I0905 22:00:38.548743 90901 sgd_solver.cpp:106] Iteration 64370, lr = 0.01
I0905 22:00:53.472025 90901 solver.cpp:228] Iteration 64380, loss = 0.367073
I0905 22:00:53.482784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367074 (* 1 = 0.367074 loss)
I0905 22:00:53.482816 90901 sgd_solver.cpp:106] Iteration 64380, lr = 0.01
I0905 22:01:04.493574 90901 solver.cpp:228] Iteration 64390, loss = 0.252708
I0905 22:01:04.493651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252709 (* 1 = 0.252709 loss)
I0905 22:01:04.493669 90901 sgd_solver.cpp:106] Iteration 64390, lr = 0.01
I0905 22:01:22.654850 90901 solver.cpp:228] Iteration 64400, loss = 0.0855246
I0905 22:01:22.654918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0855264 (* 1 = 0.0855264 loss)
I0905 22:01:22.654937 90901 sgd_solver.cpp:106] Iteration 64400, lr = 0.01
I0905 22:01:40.263747 90901 solver.cpp:228] Iteration 64410, loss = 0.114875
I0905 22:01:40.263953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114877 (* 1 = 0.114877 loss)
I0905 22:01:40.263988 90901 sgd_solver.cpp:106] Iteration 64410, lr = 0.01
I0905 22:01:59.561987 90901 solver.cpp:228] Iteration 64420, loss = 0.103346
I0905 22:01:59.562069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103348 (* 1 = 0.103348 loss)
I0905 22:01:59.562088 90901 sgd_solver.cpp:106] Iteration 64420, lr = 0.01
I0905 22:02:16.267696 90901 solver.cpp:228] Iteration 64430, loss = 0.306444
I0905 22:02:16.267922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306446 (* 1 = 0.306446 loss)
I0905 22:02:16.267946 90901 sgd_solver.cpp:106] Iteration 64430, lr = 0.01
I0905 22:02:35.634992 90901 solver.cpp:228] Iteration 64440, loss = 0.155958
I0905 22:02:35.635073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15596 (* 1 = 0.15596 loss)
I0905 22:02:35.635090 90901 sgd_solver.cpp:106] Iteration 64440, lr = 0.01
I0905 22:02:54.257714 90901 solver.cpp:228] Iteration 64450, loss = 0.397276
I0905 22:02:54.257910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.397277 (* 1 = 0.397277 loss)
I0905 22:02:54.257932 90901 sgd_solver.cpp:106] Iteration 64450, lr = 0.01
I0905 22:03:14.780776 90901 solver.cpp:228] Iteration 64460, loss = 0.0544466
I0905 22:03:14.780853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0544484 (* 1 = 0.0544484 loss)
I0905 22:03:14.780870 90901 sgd_solver.cpp:106] Iteration 64460, lr = 0.01
I0905 22:03:33.995877 90901 solver.cpp:228] Iteration 64470, loss = 0.129233
I0905 22:03:33.996017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129234 (* 1 = 0.129234 loss)
I0905 22:03:33.996049 90901 sgd_solver.cpp:106] Iteration 64470, lr = 0.01
I0905 22:03:53.931361 90901 solver.cpp:228] Iteration 64480, loss = 0.117812
I0905 22:03:53.931448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117814 (* 1 = 0.117814 loss)
I0905 22:03:53.931469 90901 sgd_solver.cpp:106] Iteration 64480, lr = 0.01
I0905 22:04:12.416445 90901 solver.cpp:228] Iteration 64490, loss = 0.0325061
I0905 22:04:12.418148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0325079 (* 1 = 0.0325079 loss)
I0905 22:04:12.418170 90901 sgd_solver.cpp:106] Iteration 64490, lr = 0.01
I0905 22:04:29.894538 90901 solver.cpp:228] Iteration 64500, loss = 0.168799
I0905 22:04:29.894613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168801 (* 1 = 0.168801 loss)
I0905 22:04:29.894640 90901 sgd_solver.cpp:106] Iteration 64500, lr = 0.01
I0905 22:04:46.221477 90901 solver.cpp:228] Iteration 64510, loss = 0.483411
I0905 22:04:46.221725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.483413 (* 1 = 0.483413 loss)
I0905 22:04:46.221750 90901 sgd_solver.cpp:106] Iteration 64510, lr = 0.01
I0905 22:05:03.816613 90901 solver.cpp:228] Iteration 64520, loss = 0.243076
I0905 22:05:03.816715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243078 (* 1 = 0.243078 loss)
I0905 22:05:03.816735 90901 sgd_solver.cpp:106] Iteration 64520, lr = 0.01
I0905 22:05:23.484942 90901 solver.cpp:228] Iteration 64530, loss = 0.127435
I0905 22:05:23.485126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127437 (* 1 = 0.127437 loss)
I0905 22:05:23.485172 90901 sgd_solver.cpp:106] Iteration 64530, lr = 0.01
I0905 22:05:41.553901 90901 solver.cpp:228] Iteration 64540, loss = 0.136559
I0905 22:05:41.553973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136561 (* 1 = 0.136561 loss)
I0905 22:05:41.553992 90901 sgd_solver.cpp:106] Iteration 64540, lr = 0.01
I0905 22:06:01.384058 90901 solver.cpp:228] Iteration 64550, loss = 0.0935647
I0905 22:06:01.384246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0935665 (* 1 = 0.0935665 loss)
I0905 22:06:01.384285 90901 sgd_solver.cpp:106] Iteration 64550, lr = 0.01
I0905 22:06:22.404429 90901 solver.cpp:228] Iteration 64560, loss = 0.0923652
I0905 22:06:22.404702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.092367 (* 1 = 0.092367 loss)
I0905 22:06:22.404806 90901 sgd_solver.cpp:106] Iteration 64560, lr = 0.01
I0905 22:06:40.216722 90901 solver.cpp:228] Iteration 64570, loss = 0.0371472
I0905 22:06:40.216986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.037149 (* 1 = 0.037149 loss)
I0905 22:06:40.217011 90901 sgd_solver.cpp:106] Iteration 64570, lr = 0.01
I0905 22:06:58.257097 90901 solver.cpp:228] Iteration 64580, loss = 0.239285
I0905 22:06:58.257174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239287 (* 1 = 0.239287 loss)
I0905 22:06:58.257195 90901 sgd_solver.cpp:106] Iteration 64580, lr = 0.01
I0905 22:07:17.216064 90901 solver.cpp:228] Iteration 64590, loss = 0.237065
I0905 22:07:17.216315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237067 (* 1 = 0.237067 loss)
I0905 22:07:17.216337 90901 sgd_solver.cpp:106] Iteration 64590, lr = 0.01
I0905 22:07:35.958253 90901 solver.cpp:228] Iteration 64600, loss = 0.107367
I0905 22:07:35.958326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107368 (* 1 = 0.107368 loss)
I0905 22:07:35.958348 90901 sgd_solver.cpp:106] Iteration 64600, lr = 0.01
I0905 22:07:54.021200 90901 solver.cpp:228] Iteration 64610, loss = 0.108401
I0905 22:07:54.021477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108403 (* 1 = 0.108403 loss)
I0905 22:07:54.021503 90901 sgd_solver.cpp:106] Iteration 64610, lr = 0.01
I0905 22:08:10.697458 90901 solver.cpp:228] Iteration 64620, loss = 0.231411
I0905 22:08:10.697532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231412 (* 1 = 0.231412 loss)
I0905 22:08:10.697552 90901 sgd_solver.cpp:106] Iteration 64620, lr = 0.01
I0905 22:08:25.154711 90901 solver.cpp:228] Iteration 64630, loss = 0.274074
I0905 22:08:25.154866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274075 (* 1 = 0.274075 loss)
I0905 22:08:25.154903 90901 sgd_solver.cpp:106] Iteration 64630, lr = 0.01
I0905 22:08:36.220161 90901 solver.cpp:228] Iteration 64640, loss = 0.390586
I0905 22:08:36.220247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390587 (* 1 = 0.390587 loss)
I0905 22:08:36.220266 90901 sgd_solver.cpp:106] Iteration 64640, lr = 0.01
I0905 22:08:51.547404 90901 solver.cpp:228] Iteration 64650, loss = 0.257187
I0905 22:08:51.547487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257188 (* 1 = 0.257188 loss)
I0905 22:08:51.547508 90901 sgd_solver.cpp:106] Iteration 64650, lr = 0.01
I0905 22:09:06.521332 90901 solver.cpp:228] Iteration 64660, loss = 0.096113
I0905 22:09:06.521544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0961149 (* 1 = 0.0961149 loss)
I0905 22:09:06.521562 90901 sgd_solver.cpp:106] Iteration 64660, lr = 0.01
I0905 22:09:21.798885 90901 solver.cpp:228] Iteration 64670, loss = 0.233868
I0905 22:09:21.798952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23387 (* 1 = 0.23387 loss)
I0905 22:09:21.798969 90901 sgd_solver.cpp:106] Iteration 64670, lr = 0.01
I0905 22:09:36.494822 90901 solver.cpp:228] Iteration 64680, loss = 0.251018
I0905 22:09:36.494915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25102 (* 1 = 0.25102 loss)
I0905 22:09:36.494936 90901 sgd_solver.cpp:106] Iteration 64680, lr = 0.01
I0905 22:09:51.403043 90901 solver.cpp:228] Iteration 64690, loss = 0.294415
I0905 22:09:51.403197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294417 (* 1 = 0.294417 loss)
I0905 22:09:51.403239 90901 sgd_solver.cpp:106] Iteration 64690, lr = 0.01
I0905 22:10:03.535428 90901 solver.cpp:228] Iteration 64700, loss = 0.129853
I0905 22:10:03.535488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129855 (* 1 = 0.129855 loss)
I0905 22:10:03.535509 90901 sgd_solver.cpp:106] Iteration 64700, lr = 0.01
I0905 22:10:13.201630 90901 solver.cpp:228] Iteration 64710, loss = 0.257545
I0905 22:10:13.201730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257546 (* 1 = 0.257546 loss)
I0905 22:10:13.201746 90901 sgd_solver.cpp:106] Iteration 64710, lr = 0.01
I0905 22:10:24.724231 90901 solver.cpp:228] Iteration 64720, loss = 0.208766
I0905 22:10:24.724434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208767 (* 1 = 0.208767 loss)
I0905 22:10:24.724455 90901 sgd_solver.cpp:106] Iteration 64720, lr = 0.01
I0905 22:10:39.699792 90901 solver.cpp:228] Iteration 64730, loss = 0.111046
I0905 22:10:39.699865 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111048 (* 1 = 0.111048 loss)
I0905 22:10:39.699883 90901 sgd_solver.cpp:106] Iteration 64730, lr = 0.01
I0905 22:10:52.718482 90901 solver.cpp:228] Iteration 64740, loss = 0.367693
I0905 22:10:52.718578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367694 (* 1 = 0.367694 loss)
I0905 22:10:52.718597 90901 sgd_solver.cpp:106] Iteration 64740, lr = 0.01
I0905 22:11:04.123880 90901 solver.cpp:228] Iteration 64750, loss = 0.137548
I0905 22:11:04.124047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13755 (* 1 = 0.13755 loss)
I0905 22:11:04.124079 90901 sgd_solver.cpp:106] Iteration 64750, lr = 0.01
I0905 22:11:17.778172 90901 solver.cpp:228] Iteration 64760, loss = 0.204097
I0905 22:11:17.778380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204099 (* 1 = 0.204099 loss)
I0905 22:11:17.778419 90901 sgd_solver.cpp:106] Iteration 64760, lr = 0.01
I0905 22:11:30.981286 90901 solver.cpp:228] Iteration 64770, loss = 0.200787
I0905 22:11:30.981348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200789 (* 1 = 0.200789 loss)
I0905 22:11:30.981364 90901 sgd_solver.cpp:106] Iteration 64770, lr = 0.01
I0905 22:11:45.455646 90901 solver.cpp:228] Iteration 64780, loss = 0.104682
I0905 22:11:45.455883 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104684 (* 1 = 0.104684 loss)
I0905 22:11:45.455907 90901 sgd_solver.cpp:106] Iteration 64780, lr = 0.01
I0905 22:11:58.979423 90901 solver.cpp:228] Iteration 64790, loss = 0.0873324
I0905 22:11:58.979503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0873341 (* 1 = 0.0873341 loss)
I0905 22:11:58.979521 90901 sgd_solver.cpp:106] Iteration 64790, lr = 0.01
I0905 22:12:11.522869 90901 solver.cpp:337] Iteration 64800, Testing net (#0)
I0905 22:13:45.529701 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.945625
I0905 22:13:45.529849 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.155635 (* 1 = 0.155635 loss)
I0905 22:13:45.809527 90901 solver.cpp:228] Iteration 64800, loss = 0.225077
I0905 22:13:45.809624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225078 (* 1 = 0.225078 loss)
I0905 22:13:45.809658 90901 sgd_solver.cpp:106] Iteration 64800, lr = 0.01
I0905 22:13:57.532181 90901 solver.cpp:228] Iteration 64810, loss = 0.0936405
I0905 22:13:57.532245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0936421 (* 1 = 0.0936421 loss)
I0905 22:13:57.532261 90901 sgd_solver.cpp:106] Iteration 64810, lr = 0.01
I0905 22:14:10.422359 90901 solver.cpp:228] Iteration 64820, loss = 0.0985828
I0905 22:14:10.422462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0985845 (* 1 = 0.0985845 loss)
I0905 22:14:10.422482 90901 sgd_solver.cpp:106] Iteration 64820, lr = 0.01
I0905 22:14:28.731938 90901 solver.cpp:228] Iteration 64830, loss = 0.0710667
I0905 22:14:28.732089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0710684 (* 1 = 0.0710684 loss)
I0905 22:14:28.732113 90901 sgd_solver.cpp:106] Iteration 64830, lr = 0.01
I0905 22:14:48.895258 90901 solver.cpp:228] Iteration 64840, loss = 0.295904
I0905 22:14:48.895331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295906 (* 1 = 0.295906 loss)
I0905 22:14:48.895361 90901 sgd_solver.cpp:106] Iteration 64840, lr = 0.01
I0905 22:15:07.590816 90901 solver.cpp:228] Iteration 64850, loss = 0.103877
I0905 22:15:07.591007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103878 (* 1 = 0.103878 loss)
I0905 22:15:07.591042 90901 sgd_solver.cpp:106] Iteration 64850, lr = 0.01
I0905 22:15:25.945421 90901 solver.cpp:228] Iteration 64860, loss = 0.784625
I0905 22:15:25.945526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.784627 (* 1 = 0.784627 loss)
I0905 22:15:25.945551 90901 sgd_solver.cpp:106] Iteration 64860, lr = 0.01
I0905 22:15:45.256417 90901 solver.cpp:228] Iteration 64870, loss = 0.0626487
I0905 22:15:45.256667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0626504 (* 1 = 0.0626504 loss)
I0905 22:15:45.256690 90901 sgd_solver.cpp:106] Iteration 64870, lr = 0.01
I0905 22:16:02.615945 90901 solver.cpp:228] Iteration 64880, loss = 0.122155
I0905 22:16:02.616037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122156 (* 1 = 0.122156 loss)
I0905 22:16:02.616058 90901 sgd_solver.cpp:106] Iteration 64880, lr = 0.01
I0905 22:16:21.834460 90901 solver.cpp:228] Iteration 64890, loss = 0.0750498
I0905 22:16:21.834671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0750515 (* 1 = 0.0750515 loss)
I0905 22:16:21.834692 90901 sgd_solver.cpp:106] Iteration 64890, lr = 0.01
I0905 22:16:40.831001 90901 solver.cpp:228] Iteration 64900, loss = 0.479463
I0905 22:16:40.831087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.479464 (* 1 = 0.479464 loss)
I0905 22:16:40.831110 90901 sgd_solver.cpp:106] Iteration 64900, lr = 0.01
I0905 22:16:59.391540 90901 solver.cpp:228] Iteration 64910, loss = 0.329613
I0905 22:16:59.391760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329614 (* 1 = 0.329614 loss)
I0905 22:16:59.391801 90901 sgd_solver.cpp:106] Iteration 64910, lr = 0.01
I0905 22:17:16.921619 90901 solver.cpp:228] Iteration 64920, loss = 0.235562
I0905 22:17:16.921715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235564 (* 1 = 0.235564 loss)
I0905 22:17:16.921741 90901 sgd_solver.cpp:106] Iteration 64920, lr = 0.01
I0905 22:17:35.323971 90901 solver.cpp:228] Iteration 64930, loss = 0.104967
I0905 22:17:35.324203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104969 (* 1 = 0.104969 loss)
I0905 22:17:35.324226 90901 sgd_solver.cpp:106] Iteration 64930, lr = 0.01
I0905 22:17:52.434480 90901 solver.cpp:228] Iteration 64940, loss = 0.194262
I0905 22:17:52.434566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194263 (* 1 = 0.194263 loss)
I0905 22:17:52.434584 90901 sgd_solver.cpp:106] Iteration 64940, lr = 0.01
I0905 22:18:10.287710 90901 solver.cpp:228] Iteration 64950, loss = 0.165182
I0905 22:18:10.287914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165184 (* 1 = 0.165184 loss)
I0905 22:18:10.287941 90901 sgd_solver.cpp:106] Iteration 64950, lr = 0.01
I0905 22:18:31.235457 90901 solver.cpp:228] Iteration 64960, loss = 0.400979
I0905 22:18:31.235538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400981 (* 1 = 0.400981 loss)
I0905 22:18:31.235558 90901 sgd_solver.cpp:106] Iteration 64960, lr = 0.01
I0905 22:18:48.931203 90901 solver.cpp:228] Iteration 64970, loss = 0.0964481
I0905 22:18:48.931386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0964498 (* 1 = 0.0964498 loss)
I0905 22:18:48.931417 90901 sgd_solver.cpp:106] Iteration 64970, lr = 0.01
I0905 22:19:08.370221 90901 solver.cpp:228] Iteration 64980, loss = 0.202178
I0905 22:19:08.370299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20218 (* 1 = 0.20218 loss)
I0905 22:19:08.370319 90901 sgd_solver.cpp:106] Iteration 64980, lr = 0.01
I0905 22:19:27.085270 90901 solver.cpp:228] Iteration 64990, loss = 0.111003
I0905 22:19:27.085502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111004 (* 1 = 0.111004 loss)
I0905 22:19:27.085541 90901 sgd_solver.cpp:106] Iteration 64990, lr = 0.01
I0905 22:19:45.652168 90901 solver.cpp:228] Iteration 65000, loss = 0.118301
I0905 22:19:45.652232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118303 (* 1 = 0.118303 loss)
I0905 22:19:45.652253 90901 sgd_solver.cpp:106] Iteration 65000, lr = 0.01
I0905 22:20:03.030880 90901 solver.cpp:228] Iteration 65010, loss = 0.100141
I0905 22:20:03.031075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100143 (* 1 = 0.100143 loss)
I0905 22:20:03.031103 90901 sgd_solver.cpp:106] Iteration 65010, lr = 0.01
I0905 22:20:17.722905 90901 solver.cpp:228] Iteration 65020, loss = 0.199192
I0905 22:20:17.722973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199193 (* 1 = 0.199193 loss)
I0905 22:20:17.722991 90901 sgd_solver.cpp:106] Iteration 65020, lr = 0.01
I0905 22:20:34.535950 90901 solver.cpp:228] Iteration 65030, loss = 0.192591
I0905 22:20:34.536191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192592 (* 1 = 0.192592 loss)
I0905 22:20:34.536216 90901 sgd_solver.cpp:106] Iteration 65030, lr = 0.01
I0905 22:20:51.064576 90901 solver.cpp:228] Iteration 65040, loss = 0.190128
I0905 22:20:51.064649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19013 (* 1 = 0.19013 loss)
I0905 22:20:51.064666 90901 sgd_solver.cpp:106] Iteration 65040, lr = 0.01
I0905 22:21:10.133980 90901 solver.cpp:228] Iteration 65050, loss = 0.0617469
I0905 22:21:10.134217 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0617485 (* 1 = 0.0617485 loss)
I0905 22:21:10.134239 90901 sgd_solver.cpp:106] Iteration 65050, lr = 0.01
I0905 22:21:27.311208 90901 solver.cpp:228] Iteration 65060, loss = 0.0522132
I0905 22:21:27.311290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0522148 (* 1 = 0.0522148 loss)
I0905 22:21:27.311309 90901 sgd_solver.cpp:106] Iteration 65060, lr = 0.01
I0905 22:21:47.384815 90901 solver.cpp:228] Iteration 65070, loss = 0.20625
I0905 22:21:47.384977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206251 (* 1 = 0.206251 loss)
I0905 22:21:47.384996 90901 sgd_solver.cpp:106] Iteration 65070, lr = 0.01
I0905 22:22:04.560587 90901 solver.cpp:228] Iteration 65080, loss = 0.0886459
I0905 22:22:04.560662 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0886475 (* 1 = 0.0886475 loss)
I0905 22:22:04.560680 90901 sgd_solver.cpp:106] Iteration 65080, lr = 0.01
I0905 22:22:24.190614 90901 solver.cpp:228] Iteration 65090, loss = 0.0588887
I0905 22:22:24.190845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0588903 (* 1 = 0.0588903 loss)
I0905 22:22:24.190882 90901 sgd_solver.cpp:106] Iteration 65090, lr = 0.01
I0905 22:22:41.435295 90901 solver.cpp:228] Iteration 65100, loss = 0.356292
I0905 22:22:41.435367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356293 (* 1 = 0.356293 loss)
I0905 22:22:41.435386 90901 sgd_solver.cpp:106] Iteration 65100, lr = 0.01
I0905 22:23:00.616417 90901 solver.cpp:228] Iteration 65110, loss = 0.202319
I0905 22:23:00.616694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202321 (* 1 = 0.202321 loss)
I0905 22:23:00.616732 90901 sgd_solver.cpp:106] Iteration 65110, lr = 0.01
I0905 22:23:18.159502 90901 solver.cpp:228] Iteration 65120, loss = 0.0521641
I0905 22:23:18.159572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0521656 (* 1 = 0.0521656 loss)
I0905 22:23:18.159591 90901 sgd_solver.cpp:106] Iteration 65120, lr = 0.01
I0905 22:23:36.660498 90901 solver.cpp:228] Iteration 65130, loss = 0.120005
I0905 22:23:36.660703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120006 (* 1 = 0.120006 loss)
I0905 22:23:36.660733 90901 sgd_solver.cpp:106] Iteration 65130, lr = 0.01
I0905 22:23:54.500075 90901 solver.cpp:228] Iteration 65140, loss = 0.0577892
I0905 22:23:54.500159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0577907 (* 1 = 0.0577907 loss)
I0905 22:23:54.500177 90901 sgd_solver.cpp:106] Iteration 65140, lr = 0.01
I0905 22:24:11.896396 90901 solver.cpp:228] Iteration 65150, loss = 0.258682
I0905 22:24:11.896709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258683 (* 1 = 0.258683 loss)
I0905 22:24:11.896734 90901 sgd_solver.cpp:106] Iteration 65150, lr = 0.01
I0905 22:24:29.344470 90901 solver.cpp:228] Iteration 65160, loss = 0.400457
I0905 22:24:29.344537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400459 (* 1 = 0.400459 loss)
I0905 22:24:29.344552 90901 sgd_solver.cpp:106] Iteration 65160, lr = 0.01
I0905 22:24:45.289880 90901 solver.cpp:228] Iteration 65170, loss = 0.366226
I0905 22:24:45.290101 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366228 (* 1 = 0.366228 loss)
I0905 22:24:45.290118 90901 sgd_solver.cpp:106] Iteration 65170, lr = 0.01
I0905 22:25:01.641232 90901 solver.cpp:228] Iteration 65180, loss = 0.193086
I0905 22:25:01.641331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193087 (* 1 = 0.193087 loss)
I0905 22:25:01.641365 90901 sgd_solver.cpp:106] Iteration 65180, lr = 0.01
I0905 22:25:14.454818 90901 solver.cpp:228] Iteration 65190, loss = 0.335863
I0905 22:25:14.454892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335864 (* 1 = 0.335864 loss)
I0905 22:25:14.454910 90901 sgd_solver.cpp:106] Iteration 65190, lr = 0.01
I0905 22:25:26.973386 90901 solver.cpp:228] Iteration 65200, loss = 0.106868
I0905 22:25:26.973574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106869 (* 1 = 0.106869 loss)
I0905 22:25:26.973615 90901 sgd_solver.cpp:106] Iteration 65200, lr = 0.01
I0905 22:25:37.545269 90901 solver.cpp:228] Iteration 65210, loss = 0.0496665
I0905 22:25:37.545347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.049668 (* 1 = 0.049668 loss)
I0905 22:25:37.545364 90901 sgd_solver.cpp:106] Iteration 65210, lr = 0.01
I0905 22:25:50.134155 90901 solver.cpp:228] Iteration 65220, loss = 0.253709
I0905 22:25:50.134212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25371 (* 1 = 0.25371 loss)
I0905 22:25:50.134230 90901 sgd_solver.cpp:106] Iteration 65220, lr = 0.01
I0905 22:26:02.498661 90901 solver.cpp:228] Iteration 65230, loss = 0.0682927
I0905 22:26:02.498937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0682942 (* 1 = 0.0682942 loss)
I0905 22:26:02.498970 90901 sgd_solver.cpp:106] Iteration 65230, lr = 0.01
I0905 22:26:14.705268 90901 solver.cpp:228] Iteration 65240, loss = 0.343882
I0905 22:26:14.705338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343884 (* 1 = 0.343884 loss)
I0905 22:26:14.705358 90901 sgd_solver.cpp:106] Iteration 65240, lr = 0.01
I0905 22:26:27.024546 90901 solver.cpp:228] Iteration 65250, loss = 0.282503
I0905 22:26:27.024629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282505 (* 1 = 0.282505 loss)
I0905 22:26:27.024646 90901 sgd_solver.cpp:106] Iteration 65250, lr = 0.01
I0905 22:26:40.000792 90901 solver.cpp:228] Iteration 65260, loss = 0.23452
I0905 22:26:40.000944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234521 (* 1 = 0.234521 loss)
I0905 22:26:40.000973 90901 sgd_solver.cpp:106] Iteration 65260, lr = 0.01
I0905 22:26:52.333585 90901 solver.cpp:228] Iteration 65270, loss = 0.116878
I0905 22:26:52.333717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116879 (* 1 = 0.116879 loss)
I0905 22:26:52.333740 90901 sgd_solver.cpp:106] Iteration 65270, lr = 0.01
I0905 22:27:02.744524 90901 solver.cpp:228] Iteration 65280, loss = 0.0908665
I0905 22:27:02.744578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.090868 (* 1 = 0.090868 loss)
I0905 22:27:02.744596 90901 sgd_solver.cpp:106] Iteration 65280, lr = 0.01
I0905 22:27:11.355063 90901 solver.cpp:228] Iteration 65290, loss = 0.0292729
I0905 22:27:11.355214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0292744 (* 1 = 0.0292744 loss)
I0905 22:27:11.355257 90901 sgd_solver.cpp:106] Iteration 65290, lr = 0.01
I0905 22:27:24.601959 90901 solver.cpp:228] Iteration 65300, loss = 0.322554
I0905 22:27:24.602037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322556 (* 1 = 0.322556 loss)
I0905 22:27:24.602056 90901 sgd_solver.cpp:106] Iteration 65300, lr = 0.01
I0905 22:27:40.315239 90901 solver.cpp:228] Iteration 65310, loss = 0.177583
I0905 22:27:40.315295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177584 (* 1 = 0.177584 loss)
I0905 22:27:40.315309 90901 sgd_solver.cpp:106] Iteration 65310, lr = 0.01
I0905 22:27:55.161922 90901 solver.cpp:228] Iteration 65320, loss = 0.0736597
I0905 22:27:55.162207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0736611 (* 1 = 0.0736611 loss)
I0905 22:27:55.162226 90901 sgd_solver.cpp:106] Iteration 65320, lr = 0.01
I0905 22:28:06.073060 90901 solver.cpp:228] Iteration 65330, loss = 0.425287
I0905 22:28:06.073128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425289 (* 1 = 0.425289 loss)
I0905 22:28:06.073145 90901 sgd_solver.cpp:106] Iteration 65330, lr = 0.01
I0905 22:28:17.217291 90901 solver.cpp:228] Iteration 65340, loss = 0.0331298
I0905 22:28:17.217373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0331312 (* 1 = 0.0331312 loss)
I0905 22:28:17.217393 90901 sgd_solver.cpp:106] Iteration 65340, lr = 0.01
I0905 22:28:28.725934 90901 solver.cpp:228] Iteration 65350, loss = 0.422877
I0905 22:28:28.726171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422878 (* 1 = 0.422878 loss)
I0905 22:28:28.726204 90901 sgd_solver.cpp:106] Iteration 65350, lr = 0.01
I0905 22:28:40.465499 90901 solver.cpp:228] Iteration 65360, loss = 0.3323
I0905 22:28:40.465562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332301 (* 1 = 0.332301 loss)
I0905 22:28:40.465579 90901 sgd_solver.cpp:106] Iteration 65360, lr = 0.01
I0905 22:28:52.733680 90901 solver.cpp:228] Iteration 65370, loss = 0.107804
I0905 22:28:52.733747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107805 (* 1 = 0.107805 loss)
I0905 22:28:52.733762 90901 sgd_solver.cpp:106] Iteration 65370, lr = 0.01
I0905 22:29:05.636845 90901 solver.cpp:228] Iteration 65380, loss = 0.130028
I0905 22:29:05.637054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130029 (* 1 = 0.130029 loss)
I0905 22:29:05.637079 90901 sgd_solver.cpp:106] Iteration 65380, lr = 0.01
I0905 22:29:19.859968 90901 solver.cpp:228] Iteration 65390, loss = 0.232099
I0905 22:29:19.860044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2321 (* 1 = 0.2321 loss)
I0905 22:29:19.860062 90901 sgd_solver.cpp:106] Iteration 65390, lr = 0.01
I0905 22:29:33.705507 90901 solver.cpp:228] Iteration 65400, loss = 0.200833
I0905 22:29:33.705597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200835 (* 1 = 0.200835 loss)
I0905 22:29:33.705615 90901 sgd_solver.cpp:106] Iteration 65400, lr = 0.01
I0905 22:29:51.110690 90901 solver.cpp:228] Iteration 65410, loss = 0.129603
I0905 22:29:51.110863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129604 (* 1 = 0.129604 loss)
I0905 22:29:51.110893 90901 sgd_solver.cpp:106] Iteration 65410, lr = 0.01
I0905 22:30:09.299029 90901 solver.cpp:228] Iteration 65420, loss = 0.103594
I0905 22:30:09.299098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103596 (* 1 = 0.103596 loss)
I0905 22:30:09.299115 90901 sgd_solver.cpp:106] Iteration 65420, lr = 0.01
I0905 22:30:27.271966 90901 solver.cpp:228] Iteration 65430, loss = 0.308162
I0905 22:30:27.272168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308164 (* 1 = 0.308164 loss)
I0905 22:30:27.272199 90901 sgd_solver.cpp:106] Iteration 65430, lr = 0.01
I0905 22:30:44.565655 90901 solver.cpp:228] Iteration 65440, loss = 0.0395542
I0905 22:30:44.565764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0395557 (* 1 = 0.0395557 loss)
I0905 22:30:44.565793 90901 sgd_solver.cpp:106] Iteration 65440, lr = 0.01
I0905 22:31:02.844523 90901 solver.cpp:228] Iteration 65450, loss = 0.076335
I0905 22:31:02.844811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0763365 (* 1 = 0.0763365 loss)
I0905 22:31:02.844849 90901 sgd_solver.cpp:106] Iteration 65450, lr = 0.01
I0905 22:31:21.185619 90901 solver.cpp:228] Iteration 65460, loss = 0.475109
I0905 22:31:21.185763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.47511 (* 1 = 0.47511 loss)
I0905 22:31:21.185786 90901 sgd_solver.cpp:106] Iteration 65460, lr = 0.01
I0905 22:31:40.445822 90901 solver.cpp:228] Iteration 65470, loss = 0.0718662
I0905 22:31:40.446769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0718677 (* 1 = 0.0718677 loss)
I0905 22:31:40.446792 90901 sgd_solver.cpp:106] Iteration 65470, lr = 0.01
I0905 22:31:59.057297 90901 solver.cpp:228] Iteration 65480, loss = 0.0782433
I0905 22:31:59.057358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0782449 (* 1 = 0.0782449 loss)
I0905 22:31:59.057374 90901 sgd_solver.cpp:106] Iteration 65480, lr = 0.01
I0905 22:32:15.640076 90901 solver.cpp:228] Iteration 65490, loss = 0.469272
I0905 22:32:15.640300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469274 (* 1 = 0.469274 loss)
I0905 22:32:15.640341 90901 sgd_solver.cpp:106] Iteration 65490, lr = 0.01
I0905 22:32:33.786316 90901 solver.cpp:228] Iteration 65500, loss = 0.117706
I0905 22:32:33.786387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117708 (* 1 = 0.117708 loss)
I0905 22:32:33.786404 90901 sgd_solver.cpp:106] Iteration 65500, lr = 0.01
I0905 22:32:51.861631 90901 solver.cpp:228] Iteration 65510, loss = 0.177612
I0905 22:32:51.861814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177614 (* 1 = 0.177614 loss)
I0905 22:32:51.861831 90901 sgd_solver.cpp:106] Iteration 65510, lr = 0.01
I0905 22:33:09.724212 90901 solver.cpp:228] Iteration 65520, loss = 0.105436
I0905 22:33:09.724295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105438 (* 1 = 0.105438 loss)
I0905 22:33:09.724318 90901 sgd_solver.cpp:106] Iteration 65520, lr = 0.01
I0905 22:33:29.276023 90901 solver.cpp:228] Iteration 65530, loss = 0.310629
I0905 22:33:29.276273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310631 (* 1 = 0.310631 loss)
I0905 22:33:29.276304 90901 sgd_solver.cpp:106] Iteration 65530, lr = 0.01
I0905 22:33:47.810132 90901 solver.cpp:228] Iteration 65540, loss = 0.27332
I0905 22:33:47.810205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273322 (* 1 = 0.273322 loss)
I0905 22:33:47.810223 90901 sgd_solver.cpp:106] Iteration 65540, lr = 0.01
I0905 22:34:07.525758 90901 solver.cpp:228] Iteration 65550, loss = 0.0871295
I0905 22:34:07.525918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0871311 (* 1 = 0.0871311 loss)
I0905 22:34:07.525949 90901 sgd_solver.cpp:106] Iteration 65550, lr = 0.01
I0905 22:34:20.315644 90901 solver.cpp:228] Iteration 65560, loss = 0.123645
I0905 22:34:20.315722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123646 (* 1 = 0.123646 loss)
I0905 22:34:20.315742 90901 sgd_solver.cpp:106] Iteration 65560, lr = 0.01
I0905 22:34:36.376540 90901 solver.cpp:228] Iteration 65570, loss = 0.174263
I0905 22:34:36.376607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174264 (* 1 = 0.174264 loss)
I0905 22:34:36.376626 90901 sgd_solver.cpp:106] Iteration 65570, lr = 0.01
I0905 22:34:55.003470 90901 solver.cpp:228] Iteration 65580, loss = 0.167488
I0905 22:34:55.003717 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16749 (* 1 = 0.16749 loss)
I0905 22:34:55.003742 90901 sgd_solver.cpp:106] Iteration 65580, lr = 0.01
I0905 22:35:15.432106 90901 solver.cpp:228] Iteration 65590, loss = 0.0753943
I0905 22:35:15.432185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0753959 (* 1 = 0.0753959 loss)
I0905 22:35:15.432205 90901 sgd_solver.cpp:106] Iteration 65590, lr = 0.01
I0905 22:35:35.378348 90901 solver.cpp:337] Iteration 65600, Testing net (#0)
I0905 22:37:44.323715 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.870938
I0905 22:37:44.323868 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.335282 (* 1 = 0.335282 loss)
I0905 22:37:45.054793 90901 solver.cpp:228] Iteration 65600, loss = 0.37163
I0905 22:37:45.054872 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371632 (* 1 = 0.371632 loss)
I0905 22:37:45.054894 90901 sgd_solver.cpp:106] Iteration 65600, lr = 0.01
I0905 22:37:57.636287 90901 solver.cpp:228] Iteration 65610, loss = 0.0743774
I0905 22:37:57.636359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.074379 (* 1 = 0.074379 loss)
I0905 22:37:57.636375 90901 sgd_solver.cpp:106] Iteration 65610, lr = 0.01
I0905 22:38:10.794868 90901 solver.cpp:228] Iteration 65620, loss = 0.20298
I0905 22:38:10.794937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202981 (* 1 = 0.202981 loss)
I0905 22:38:10.794957 90901 sgd_solver.cpp:106] Iteration 65620, lr = 0.01
I0905 22:38:30.157635 90901 solver.cpp:228] Iteration 65630, loss = 0.140744
I0905 22:38:30.157869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140746 (* 1 = 0.140746 loss)
I0905 22:38:30.157896 90901 sgd_solver.cpp:106] Iteration 65630, lr = 0.01
I0905 22:38:41.805811 90901 solver.cpp:228] Iteration 65640, loss = 0.0714508
I0905 22:38:41.805923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0714523 (* 1 = 0.0714523 loss)
I0905 22:38:41.805946 90901 sgd_solver.cpp:106] Iteration 65640, lr = 0.01
I0905 22:38:57.830799 90901 solver.cpp:228] Iteration 65650, loss = 0.0757522
I0905 22:38:57.831032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0757538 (* 1 = 0.0757538 loss)
I0905 22:38:57.831063 90901 sgd_solver.cpp:106] Iteration 65650, lr = 0.01
I0905 22:39:14.457092 90901 solver.cpp:228] Iteration 65660, loss = 0.124905
I0905 22:39:14.457279 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124907 (* 1 = 0.124907 loss)
I0905 22:39:14.457317 90901 sgd_solver.cpp:106] Iteration 65660, lr = 0.01
I0905 22:39:31.190284 90901 solver.cpp:228] Iteration 65670, loss = 0.333285
I0905 22:39:31.190361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333286 (* 1 = 0.333286 loss)
I0905 22:39:31.190381 90901 sgd_solver.cpp:106] Iteration 65670, lr = 0.01
I0905 22:39:49.626425 90901 solver.cpp:228] Iteration 65680, loss = 0.198265
I0905 22:39:49.626660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198266 (* 1 = 0.198266 loss)
I0905 22:39:49.626690 90901 sgd_solver.cpp:106] Iteration 65680, lr = 0.01
I0905 22:40:08.275298 90901 solver.cpp:228] Iteration 65690, loss = 0.113457
I0905 22:40:08.275421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113459 (* 1 = 0.113459 loss)
I0905 22:40:08.275446 90901 sgd_solver.cpp:106] Iteration 65690, lr = 0.01
I0905 22:40:25.641232 90901 solver.cpp:228] Iteration 65700, loss = 0.151619
I0905 22:40:25.641382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15162 (* 1 = 0.15162 loss)
I0905 22:40:25.641398 90901 sgd_solver.cpp:106] Iteration 65700, lr = 0.01
I0905 22:40:43.651873 90901 solver.cpp:228] Iteration 65710, loss = 0.461943
I0905 22:40:43.651952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.461945 (* 1 = 0.461945 loss)
I0905 22:40:43.651968 90901 sgd_solver.cpp:106] Iteration 65710, lr = 0.01
I0905 22:41:02.937263 90901 solver.cpp:228] Iteration 65720, loss = 0.356237
I0905 22:41:02.937618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356238 (* 1 = 0.356238 loss)
I0905 22:41:02.937647 90901 sgd_solver.cpp:106] Iteration 65720, lr = 0.01
I0905 22:41:20.311164 90901 solver.cpp:228] Iteration 65730, loss = 0.123692
I0905 22:41:20.311293 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123694 (* 1 = 0.123694 loss)
I0905 22:41:20.311313 90901 sgd_solver.cpp:106] Iteration 65730, lr = 0.01
I0905 22:41:38.566340 90901 solver.cpp:228] Iteration 65740, loss = 0.080718
I0905 22:41:38.566537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0807195 (* 1 = 0.0807195 loss)
I0905 22:41:38.566561 90901 sgd_solver.cpp:106] Iteration 65740, lr = 0.01
I0905 22:41:56.689977 90901 solver.cpp:228] Iteration 65750, loss = 0.0840351
I0905 22:41:56.690078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0840365 (* 1 = 0.0840365 loss)
I0905 22:41:56.690104 90901 sgd_solver.cpp:106] Iteration 65750, lr = 0.01
I0905 22:42:13.773772 90901 solver.cpp:228] Iteration 65760, loss = 0.184412
I0905 22:42:13.774020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184414 (* 1 = 0.184414 loss)
I0905 22:42:13.774055 90901 sgd_solver.cpp:106] Iteration 65760, lr = 0.01
I0905 22:42:31.855134 90901 solver.cpp:228] Iteration 65770, loss = 0.285594
I0905 22:42:31.855206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285595 (* 1 = 0.285595 loss)
I0905 22:42:31.855222 90901 sgd_solver.cpp:106] Iteration 65770, lr = 0.01
I0905 22:42:50.956679 90901 solver.cpp:228] Iteration 65780, loss = 0.203292
I0905 22:42:50.956876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203293 (* 1 = 0.203293 loss)
I0905 22:42:50.956909 90901 sgd_solver.cpp:106] Iteration 65780, lr = 0.01
I0905 22:43:07.829354 90901 solver.cpp:228] Iteration 65790, loss = 0.188965
I0905 22:43:07.829464 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188966 (* 1 = 0.188966 loss)
I0905 22:43:07.829486 90901 sgd_solver.cpp:106] Iteration 65790, lr = 0.01
I0905 22:43:26.637862 90901 solver.cpp:228] Iteration 65800, loss = 0.132367
I0905 22:43:26.638082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132368 (* 1 = 0.132368 loss)
I0905 22:43:26.638104 90901 sgd_solver.cpp:106] Iteration 65800, lr = 0.01
I0905 22:43:45.482584 90901 solver.cpp:228] Iteration 65810, loss = 0.243447
I0905 22:43:45.482672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243448 (* 1 = 0.243448 loss)
I0905 22:43:45.482692 90901 sgd_solver.cpp:106] Iteration 65810, lr = 0.01
I0905 22:44:03.866430 90901 solver.cpp:228] Iteration 65820, loss = 0.36216
I0905 22:44:03.866581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362161 (* 1 = 0.362161 loss)
I0905 22:44:03.866601 90901 sgd_solver.cpp:106] Iteration 65820, lr = 0.01
I0905 22:44:21.788486 90901 solver.cpp:228] Iteration 65830, loss = 0.148034
I0905 22:44:21.788547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148036 (* 1 = 0.148036 loss)
I0905 22:44:21.788564 90901 sgd_solver.cpp:106] Iteration 65830, lr = 0.01
I0905 22:44:39.344362 90901 solver.cpp:228] Iteration 65840, loss = 0.192319
I0905 22:44:39.344537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192321 (* 1 = 0.192321 loss)
I0905 22:44:39.344561 90901 sgd_solver.cpp:106] Iteration 65840, lr = 0.01
I0905 22:44:57.114711 90901 solver.cpp:228] Iteration 65850, loss = 0.106638
I0905 22:44:57.114806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10664 (* 1 = 0.10664 loss)
I0905 22:44:57.114823 90901 sgd_solver.cpp:106] Iteration 65850, lr = 0.01
I0905 22:45:11.408627 90901 solver.cpp:228] Iteration 65860, loss = 0.2438
I0905 22:45:11.408947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243802 (* 1 = 0.243802 loss)
I0905 22:45:11.408983 90901 sgd_solver.cpp:106] Iteration 65860, lr = 0.01
I0905 22:45:22.385396 90901 solver.cpp:228] Iteration 65870, loss = 0.0846086
I0905 22:45:22.385473 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.08461 (* 1 = 0.08461 loss)
I0905 22:45:22.385489 90901 sgd_solver.cpp:106] Iteration 65870, lr = 0.01
I0905 22:45:40.698462 90901 solver.cpp:228] Iteration 65880, loss = 0.142624
I0905 22:45:40.698535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142626 (* 1 = 0.142626 loss)
I0905 22:45:40.698554 90901 sgd_solver.cpp:106] Iteration 65880, lr = 0.01
I0905 22:45:58.200616 90901 solver.cpp:228] Iteration 65890, loss = 0.23929
I0905 22:45:58.200788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239291 (* 1 = 0.239291 loss)
I0905 22:45:58.200809 90901 sgd_solver.cpp:106] Iteration 65890, lr = 0.01
I0905 22:46:17.023059 90901 solver.cpp:228] Iteration 65900, loss = 0.175137
I0905 22:46:17.023171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175138 (* 1 = 0.175138 loss)
I0905 22:46:17.023191 90901 sgd_solver.cpp:106] Iteration 65900, lr = 0.01
I0905 22:46:32.669287 90901 solver.cpp:228] Iteration 65910, loss = 0.39682
I0905 22:46:32.669526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396821 (* 1 = 0.396821 loss)
I0905 22:46:32.669555 90901 sgd_solver.cpp:106] Iteration 65910, lr = 0.01
I0905 22:46:52.330775 90901 solver.cpp:228] Iteration 65920, loss = 0.0728029
I0905 22:46:52.330845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0728043 (* 1 = 0.0728043 loss)
I0905 22:46:52.330862 90901 sgd_solver.cpp:106] Iteration 65920, lr = 0.01
I0905 22:47:11.303465 90901 solver.cpp:228] Iteration 65930, loss = 0.0783459
I0905 22:47:11.303630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0783473 (* 1 = 0.0783473 loss)
I0905 22:47:11.303660 90901 sgd_solver.cpp:106] Iteration 65930, lr = 0.01
I0905 22:47:30.171200 90901 solver.cpp:228] Iteration 65940, loss = 0.203766
I0905 22:47:30.171296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203767 (* 1 = 0.203767 loss)
I0905 22:47:30.171319 90901 sgd_solver.cpp:106] Iteration 65940, lr = 0.01
I0905 22:47:42.607558 90901 solver.cpp:228] Iteration 65950, loss = 0.148499
I0905 22:47:42.607741 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148501 (* 1 = 0.148501 loss)
I0905 22:47:42.607756 90901 sgd_solver.cpp:106] Iteration 65950, lr = 0.01
I0905 22:47:58.011257 90901 solver.cpp:228] Iteration 65960, loss = 0.215708
I0905 22:47:58.011339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21571 (* 1 = 0.21571 loss)
I0905 22:47:58.011360 90901 sgd_solver.cpp:106] Iteration 65960, lr = 0.01
I0905 22:48:16.324290 90901 solver.cpp:228] Iteration 65970, loss = 0.358212
I0905 22:48:16.324502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358213 (* 1 = 0.358213 loss)
I0905 22:48:16.324522 90901 sgd_solver.cpp:106] Iteration 65970, lr = 0.01
I0905 22:48:34.893052 90901 solver.cpp:228] Iteration 65980, loss = 0.296783
I0905 22:48:34.893182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296784 (* 1 = 0.296784 loss)
I0905 22:48:34.893213 90901 sgd_solver.cpp:106] Iteration 65980, lr = 0.01
I0905 22:48:51.371901 90901 solver.cpp:228] Iteration 65990, loss = 0.339588
I0905 22:48:51.372061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339589 (* 1 = 0.339589 loss)
I0905 22:48:51.372081 90901 sgd_solver.cpp:106] Iteration 65990, lr = 0.01
I0905 22:49:08.799048 90901 solver.cpp:228] Iteration 66000, loss = 0.182192
I0905 22:49:08.799156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182194 (* 1 = 0.182194 loss)
I0905 22:49:08.799180 90901 sgd_solver.cpp:106] Iteration 66000, lr = 0.01
I0905 22:49:25.179244 90901 solver.cpp:228] Iteration 66010, loss = 0.0987798
I0905 22:49:25.182539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0987812 (* 1 = 0.0987812 loss)
I0905 22:49:25.182595 90901 sgd_solver.cpp:106] Iteration 66010, lr = 0.01
I0905 22:49:42.400712 90901 solver.cpp:228] Iteration 66020, loss = 0.0667565
I0905 22:49:42.400807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0667578 (* 1 = 0.0667578 loss)
I0905 22:49:42.400830 90901 sgd_solver.cpp:106] Iteration 66020, lr = 0.01
I0905 22:50:00.665575 90901 solver.cpp:228] Iteration 66030, loss = 0.271127
I0905 22:50:00.666720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271129 (* 1 = 0.271129 loss)
I0905 22:50:00.666736 90901 sgd_solver.cpp:106] Iteration 66030, lr = 0.01
I0905 22:50:18.854193 90901 solver.cpp:228] Iteration 66040, loss = 0.143048
I0905 22:50:18.854277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143049 (* 1 = 0.143049 loss)
I0905 22:50:18.854295 90901 sgd_solver.cpp:106] Iteration 66040, lr = 0.01
I0905 22:50:36.267855 90901 solver.cpp:228] Iteration 66050, loss = 0.112615
I0905 22:50:36.278753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112616 (* 1 = 0.112616 loss)
I0905 22:50:36.278786 90901 sgd_solver.cpp:106] Iteration 66050, lr = 0.01
I0905 22:50:53.158664 90901 solver.cpp:228] Iteration 66060, loss = 0.50352
I0905 22:50:53.158833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.503521 (* 1 = 0.503521 loss)
I0905 22:50:53.158859 90901 sgd_solver.cpp:106] Iteration 66060, lr = 0.01
I0905 22:51:09.776990 90901 solver.cpp:228] Iteration 66070, loss = 0.196436
I0905 22:51:09.777231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196438 (* 1 = 0.196438 loss)
I0905 22:51:09.777251 90901 sgd_solver.cpp:106] Iteration 66070, lr = 0.01
I0905 22:51:23.772351 90901 solver.cpp:228] Iteration 66080, loss = 0.141698
I0905 22:51:23.772429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141699 (* 1 = 0.141699 loss)
I0905 22:51:23.772449 90901 sgd_solver.cpp:106] Iteration 66080, lr = 0.01
I0905 22:51:37.811702 90901 solver.cpp:228] Iteration 66090, loss = 0.112455
I0905 22:51:37.811792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112456 (* 1 = 0.112456 loss)
I0905 22:51:37.811810 90901 sgd_solver.cpp:106] Iteration 66090, lr = 0.01
I0905 22:51:54.697465 90901 solver.cpp:228] Iteration 66100, loss = 0.237846
I0905 22:51:54.697674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237848 (* 1 = 0.237848 loss)
I0905 22:51:54.697716 90901 sgd_solver.cpp:106] Iteration 66100, lr = 0.01
I0905 22:52:10.490609 90901 solver.cpp:228] Iteration 66110, loss = 0.0775654
I0905 22:52:10.490686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0775667 (* 1 = 0.0775667 loss)
I0905 22:52:10.490707 90901 sgd_solver.cpp:106] Iteration 66110, lr = 0.01
I0905 22:52:27.071499 90901 solver.cpp:228] Iteration 66120, loss = 0.0657101
I0905 22:52:27.071673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0657114 (* 1 = 0.0657114 loss)
I0905 22:52:27.071717 90901 sgd_solver.cpp:106] Iteration 66120, lr = 0.01
I0905 22:52:43.285980 90901 solver.cpp:228] Iteration 66130, loss = 0.0950142
I0905 22:52:43.286067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0950155 (* 1 = 0.0950155 loss)
I0905 22:52:43.286087 90901 sgd_solver.cpp:106] Iteration 66130, lr = 0.01
I0905 22:53:00.393488 90901 solver.cpp:228] Iteration 66140, loss = 0.0828214
I0905 22:53:00.393677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0828227 (* 1 = 0.0828227 loss)
I0905 22:53:00.393704 90901 sgd_solver.cpp:106] Iteration 66140, lr = 0.01
I0905 22:53:18.465968 90901 solver.cpp:228] Iteration 66150, loss = 0.140555
I0905 22:53:18.466048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140557 (* 1 = 0.140557 loss)
I0905 22:53:18.466068 90901 sgd_solver.cpp:106] Iteration 66150, lr = 0.01
I0905 22:53:34.041473 90901 solver.cpp:228] Iteration 66160, loss = 0.126289
I0905 22:53:34.041632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126291 (* 1 = 0.126291 loss)
I0905 22:53:34.041666 90901 sgd_solver.cpp:106] Iteration 66160, lr = 0.01
I0905 22:53:47.694453 90901 solver.cpp:228] Iteration 66170, loss = 0.339474
I0905 22:53:47.694541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339475 (* 1 = 0.339475 loss)
I0905 22:53:47.694561 90901 sgd_solver.cpp:106] Iteration 66170, lr = 0.01
I0905 22:53:59.626042 90901 solver.cpp:228] Iteration 66180, loss = 0.261559
I0905 22:53:59.626113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261561 (* 1 = 0.261561 loss)
I0905 22:53:59.626129 90901 sgd_solver.cpp:106] Iteration 66180, lr = 0.01
I0905 22:54:11.675493 90901 solver.cpp:228] Iteration 66190, loss = 0.154611
I0905 22:54:11.675720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154613 (* 1 = 0.154613 loss)
I0905 22:54:11.675743 90901 sgd_solver.cpp:106] Iteration 66190, lr = 0.01
I0905 22:54:24.355288 90901 solver.cpp:228] Iteration 66200, loss = 0.221096
I0905 22:54:24.355362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221097 (* 1 = 0.221097 loss)
I0905 22:54:24.355382 90901 sgd_solver.cpp:106] Iteration 66200, lr = 0.01
I0905 22:54:35.986605 90901 solver.cpp:228] Iteration 66210, loss = 0.189446
I0905 22:54:35.986693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189447 (* 1 = 0.189447 loss)
I0905 22:54:35.986711 90901 sgd_solver.cpp:106] Iteration 66210, lr = 0.01
I0905 22:54:49.240764 90901 solver.cpp:228] Iteration 66220, loss = 0.172802
I0905 22:54:49.240974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172803 (* 1 = 0.172803 loss)
I0905 22:54:49.240993 90901 sgd_solver.cpp:106] Iteration 66220, lr = 0.01
I0905 22:55:03.113363 90901 solver.cpp:228] Iteration 66230, loss = 0.441269
I0905 22:55:03.113448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.44127 (* 1 = 0.44127 loss)
I0905 22:55:03.113468 90901 sgd_solver.cpp:106] Iteration 66230, lr = 0.01
I0905 22:55:20.617375 90901 solver.cpp:228] Iteration 66240, loss = 0.117675
I0905 22:55:20.617561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117676 (* 1 = 0.117676 loss)
I0905 22:55:20.617594 90901 sgd_solver.cpp:106] Iteration 66240, lr = 0.01
I0905 22:55:36.859613 90901 solver.cpp:228] Iteration 66250, loss = 0.298669
I0905 22:55:36.859699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29867 (* 1 = 0.29867 loss)
I0905 22:55:36.859721 90901 sgd_solver.cpp:106] Iteration 66250, lr = 0.01
I0905 22:55:54.346467 90901 solver.cpp:228] Iteration 66260, loss = 0.43849
I0905 22:55:54.346750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438491 (* 1 = 0.438491 loss)
I0905 22:55:54.346781 90901 sgd_solver.cpp:106] Iteration 66260, lr = 0.01
I0905 22:56:14.111807 90901 solver.cpp:228] Iteration 66270, loss = 0.0360287
I0905 22:56:14.111987 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0360299 (* 1 = 0.0360299 loss)
I0905 22:56:14.112010 90901 sgd_solver.cpp:106] Iteration 66270, lr = 0.01
I0905 22:56:34.714814 90901 solver.cpp:228] Iteration 66280, loss = 0.418181
I0905 22:56:34.714969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418183 (* 1 = 0.418183 loss)
I0905 22:56:34.714989 90901 sgd_solver.cpp:106] Iteration 66280, lr = 0.01
I0905 22:56:55.567687 90901 solver.cpp:228] Iteration 66290, loss = 0.0956183
I0905 22:56:55.567775 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0956195 (* 1 = 0.0956195 loss)
I0905 22:56:55.567795 90901 sgd_solver.cpp:106] Iteration 66290, lr = 0.01
I0905 22:57:15.168099 90901 solver.cpp:228] Iteration 66300, loss = 0.371579
I0905 22:57:15.168314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.37158 (* 1 = 0.37158 loss)
I0905 22:57:15.168345 90901 sgd_solver.cpp:106] Iteration 66300, lr = 0.01
I0905 22:57:34.269644 90901 solver.cpp:228] Iteration 66310, loss = 0.0295766
I0905 22:57:34.269747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0295779 (* 1 = 0.0295779 loss)
I0905 22:57:34.269767 90901 sgd_solver.cpp:106] Iteration 66310, lr = 0.01
I0905 22:57:53.459349 90901 solver.cpp:228] Iteration 66320, loss = 0.526627
I0905 22:57:53.459553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.526628 (* 1 = 0.526628 loss)
I0905 22:57:53.459573 90901 sgd_solver.cpp:106] Iteration 66320, lr = 0.01
I0905 22:58:11.864668 90901 solver.cpp:228] Iteration 66330, loss = 0.216492
I0905 22:58:11.864749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216493 (* 1 = 0.216493 loss)
I0905 22:58:11.864771 90901 sgd_solver.cpp:106] Iteration 66330, lr = 0.01
I0905 22:58:29.991787 90901 solver.cpp:228] Iteration 66340, loss = 0.225241
I0905 22:58:29.991951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225243 (* 1 = 0.225243 loss)
I0905 22:58:29.991972 90901 sgd_solver.cpp:106] Iteration 66340, lr = 0.01
I0905 22:58:47.783488 90901 solver.cpp:228] Iteration 66350, loss = 0.140552
I0905 22:58:47.783586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140553 (* 1 = 0.140553 loss)
I0905 22:58:47.783607 90901 sgd_solver.cpp:106] Iteration 66350, lr = 0.01
I0905 22:59:08.062204 90901 solver.cpp:228] Iteration 66360, loss = 0.0726418
I0905 22:59:08.062526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0726431 (* 1 = 0.0726431 loss)
I0905 22:59:08.062551 90901 sgd_solver.cpp:106] Iteration 66360, lr = 0.01
I0905 22:59:26.267024 90901 solver.cpp:228] Iteration 66370, loss = 0.403772
I0905 22:59:26.267102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.403773 (* 1 = 0.403773 loss)
I0905 22:59:26.267122 90901 sgd_solver.cpp:106] Iteration 66370, lr = 0.01
I0905 22:59:41.929097 90901 solver.cpp:228] Iteration 66380, loss = 0.224837
I0905 22:59:41.929257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224839 (* 1 = 0.224839 loss)
I0905 22:59:41.929270 90901 sgd_solver.cpp:106] Iteration 66380, lr = 0.01
I0905 22:59:59.819456 90901 solver.cpp:228] Iteration 66390, loss = 0.262384
I0905 22:59:59.819540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262386 (* 1 = 0.262386 loss)
I0905 22:59:59.819561 90901 sgd_solver.cpp:106] Iteration 66390, lr = 0.01
I0905 23:00:19.570278 90901 solver.cpp:337] Iteration 66400, Testing net (#0)
I0905 23:02:20.338425 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.910625
I0905 23:02:20.338611 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.219293 (* 1 = 0.219293 loss)
I0905 23:02:20.910617 90901 solver.cpp:228] Iteration 66400, loss = 0.159081
I0905 23:02:20.910962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159082 (* 1 = 0.159082 loss)
I0905 23:02:20.911029 90901 sgd_solver.cpp:106] Iteration 66400, lr = 0.01
I0905 23:02:33.553860 90901 solver.cpp:228] Iteration 66410, loss = 0.082265
I0905 23:02:33.553952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0822664 (* 1 = 0.0822664 loss)
I0905 23:02:33.553977 90901 sgd_solver.cpp:106] Iteration 66410, lr = 0.01
I0905 23:02:46.214606 90901 solver.cpp:228] Iteration 66420, loss = 0.0778387
I0905 23:02:46.214720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0778401 (* 1 = 0.0778401 loss)
I0905 23:02:46.214738 90901 sgd_solver.cpp:106] Iteration 66420, lr = 0.01
I0905 23:02:58.913684 90901 solver.cpp:228] Iteration 66430, loss = 0.0838964
I0905 23:02:58.913874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0838977 (* 1 = 0.0838977 loss)
I0905 23:02:58.913904 90901 sgd_solver.cpp:106] Iteration 66430, lr = 0.01
I0905 23:03:11.582547 90901 solver.cpp:228] Iteration 66440, loss = 0.110731
I0905 23:03:11.582634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110733 (* 1 = 0.110733 loss)
I0905 23:03:11.582655 90901 sgd_solver.cpp:106] Iteration 66440, lr = 0.01
I0905 23:03:28.674701 90901 solver.cpp:228] Iteration 66450, loss = 0.173366
I0905 23:03:28.675056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173367 (* 1 = 0.173367 loss)
I0905 23:03:28.675108 90901 sgd_solver.cpp:106] Iteration 66450, lr = 0.01
I0905 23:03:47.500416 90901 solver.cpp:228] Iteration 66460, loss = 0.224762
I0905 23:03:47.500581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224764 (* 1 = 0.224764 loss)
I0905 23:03:47.500600 90901 sgd_solver.cpp:106] Iteration 66460, lr = 0.01
I0905 23:04:07.509157 90901 solver.cpp:228] Iteration 66470, loss = 0.20889
I0905 23:04:07.509248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208891 (* 1 = 0.208891 loss)
I0905 23:04:07.509269 90901 sgd_solver.cpp:106] Iteration 66470, lr = 0.01
I0905 23:04:26.879215 90901 solver.cpp:228] Iteration 66480, loss = 0.125655
I0905 23:04:26.879382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125657 (* 1 = 0.125657 loss)
I0905 23:04:26.879401 90901 sgd_solver.cpp:106] Iteration 66480, lr = 0.01
I0905 23:04:47.554847 90901 solver.cpp:228] Iteration 66490, loss = 0.352829
I0905 23:04:47.554914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35283 (* 1 = 0.35283 loss)
I0905 23:04:47.554934 90901 sgd_solver.cpp:106] Iteration 66490, lr = 0.01
I0905 23:05:07.182332 90901 solver.cpp:228] Iteration 66500, loss = 0.0765617
I0905 23:05:07.182540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.076563 (* 1 = 0.076563 loss)
I0905 23:05:07.182564 90901 sgd_solver.cpp:106] Iteration 66500, lr = 0.01
I0905 23:05:26.863898 90901 solver.cpp:228] Iteration 66510, loss = 0.0645404
I0905 23:05:26.863988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0645418 (* 1 = 0.0645418 loss)
I0905 23:05:26.864011 90901 sgd_solver.cpp:106] Iteration 66510, lr = 0.01
I0905 23:05:46.277091 90901 solver.cpp:228] Iteration 66520, loss = 0.0976876
I0905 23:05:46.277258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0976889 (* 1 = 0.0976889 loss)
I0905 23:05:46.277287 90901 sgd_solver.cpp:106] Iteration 66520, lr = 0.01
I0905 23:06:05.540181 90901 solver.cpp:228] Iteration 66530, loss = 0.0819209
I0905 23:06:05.540263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0819223 (* 1 = 0.0819223 loss)
I0905 23:06:05.540282 90901 sgd_solver.cpp:106] Iteration 66530, lr = 0.01
I0905 23:06:25.320780 90901 solver.cpp:228] Iteration 66540, loss = 0.133482
I0905 23:06:25.320966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133483 (* 1 = 0.133483 loss)
I0905 23:06:25.320998 90901 sgd_solver.cpp:106] Iteration 66540, lr = 0.01
I0905 23:06:44.890048 90901 solver.cpp:228] Iteration 66550, loss = 0.0455725
I0905 23:06:44.890120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0455739 (* 1 = 0.0455739 loss)
I0905 23:06:44.890141 90901 sgd_solver.cpp:106] Iteration 66550, lr = 0.01
I0905 23:07:03.591090 90901 solver.cpp:228] Iteration 66560, loss = 0.181446
I0905 23:07:03.591264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181448 (* 1 = 0.181448 loss)
I0905 23:07:03.591300 90901 sgd_solver.cpp:106] Iteration 66560, lr = 0.01
I0905 23:07:22.713863 90901 solver.cpp:228] Iteration 66570, loss = 0.0497767
I0905 23:07:22.713937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0497781 (* 1 = 0.0497781 loss)
I0905 23:07:22.713956 90901 sgd_solver.cpp:106] Iteration 66570, lr = 0.01
I0905 23:07:37.177613 90901 solver.cpp:228] Iteration 66580, loss = 0.208213
I0905 23:07:37.177798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208214 (* 1 = 0.208214 loss)
I0905 23:07:37.177816 90901 sgd_solver.cpp:106] Iteration 66580, lr = 0.01
I0905 23:07:49.149327 90901 solver.cpp:228] Iteration 66590, loss = 0.218368
I0905 23:07:49.149400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218369 (* 1 = 0.218369 loss)
I0905 23:07:49.149417 90901 sgd_solver.cpp:106] Iteration 66590, lr = 0.01
I0905 23:08:02.209718 90901 solver.cpp:228] Iteration 66600, loss = 0.0507192
I0905 23:08:02.209805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0507206 (* 1 = 0.0507206 loss)
I0905 23:08:02.209825 90901 sgd_solver.cpp:106] Iteration 66600, lr = 0.01
I0905 23:08:18.142921 90901 solver.cpp:228] Iteration 66610, loss = 0.157964
I0905 23:08:18.143123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157965 (* 1 = 0.157965 loss)
I0905 23:08:18.143152 90901 sgd_solver.cpp:106] Iteration 66610, lr = 0.01
I0905 23:08:36.967823 90901 solver.cpp:228] Iteration 66620, loss = 0.0750411
I0905 23:08:36.967886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0750424 (* 1 = 0.0750424 loss)
I0905 23:08:36.967902 90901 sgd_solver.cpp:106] Iteration 66620, lr = 0.01
I0905 23:08:56.755620 90901 solver.cpp:228] Iteration 66630, loss = 0.282857
I0905 23:08:56.755839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282859 (* 1 = 0.282859 loss)
I0905 23:08:56.755866 90901 sgd_solver.cpp:106] Iteration 66630, lr = 0.01
I0905 23:09:16.398279 90901 solver.cpp:228] Iteration 66640, loss = 0.0673544
I0905 23:09:16.398353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0673557 (* 1 = 0.0673557 loss)
I0905 23:09:16.398365 90901 sgd_solver.cpp:106] Iteration 66640, lr = 0.01
I0905 23:09:33.985951 90901 solver.cpp:228] Iteration 66650, loss = 0.356863
I0905 23:09:33.986160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356864 (* 1 = 0.356864 loss)
I0905 23:09:33.986179 90901 sgd_solver.cpp:106] Iteration 66650, lr = 0.01
I0905 23:09:53.022740 90901 solver.cpp:228] Iteration 66660, loss = 0.0942989
I0905 23:09:53.022831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0943003 (* 1 = 0.0943003 loss)
I0905 23:09:53.022853 90901 sgd_solver.cpp:106] Iteration 66660, lr = 0.01
I0905 23:10:12.250021 90901 solver.cpp:228] Iteration 66670, loss = 0.422885
I0905 23:10:12.250399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.422887 (* 1 = 0.422887 loss)
I0905 23:10:12.250421 90901 sgd_solver.cpp:106] Iteration 66670, lr = 0.01
I0905 23:10:31.577891 90901 solver.cpp:228] Iteration 66680, loss = 0.0350802
I0905 23:10:31.577970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350816 (* 1 = 0.0350816 loss)
I0905 23:10:31.577987 90901 sgd_solver.cpp:106] Iteration 66680, lr = 0.01
I0905 23:10:50.189169 90901 solver.cpp:228] Iteration 66690, loss = 0.234939
I0905 23:10:50.198783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23494 (* 1 = 0.23494 loss)
I0905 23:10:50.198804 90901 sgd_solver.cpp:106] Iteration 66690, lr = 0.01
I0905 23:11:08.640302 90901 solver.cpp:228] Iteration 66700, loss = 0.0801691
I0905 23:11:08.640377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0801705 (* 1 = 0.0801705 loss)
I0905 23:11:08.640398 90901 sgd_solver.cpp:106] Iteration 66700, lr = 0.01
I0905 23:11:22.371134 90901 solver.cpp:228] Iteration 66710, loss = 0.162774
I0905 23:11:22.371327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162776 (* 1 = 0.162776 loss)
I0905 23:11:22.371346 90901 sgd_solver.cpp:106] Iteration 66710, lr = 0.01
I0905 23:11:37.077096 90901 solver.cpp:228] Iteration 66720, loss = 0.318018
I0905 23:11:37.077160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31802 (* 1 = 0.31802 loss)
I0905 23:11:37.077183 90901 sgd_solver.cpp:106] Iteration 66720, lr = 0.01
I0905 23:11:51.895802 90901 solver.cpp:228] Iteration 66730, loss = 0.197019
I0905 23:11:51.895880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19702 (* 1 = 0.19702 loss)
I0905 23:11:51.895901 90901 sgd_solver.cpp:106] Iteration 66730, lr = 0.01
I0905 23:12:07.728010 90901 solver.cpp:228] Iteration 66740, loss = 0.204459
I0905 23:12:07.728271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204461 (* 1 = 0.204461 loss)
I0905 23:12:07.728298 90901 sgd_solver.cpp:106] Iteration 66740, lr = 0.01
I0905 23:12:24.586263 90901 solver.cpp:228] Iteration 66750, loss = 0.187862
I0905 23:12:24.586359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187864 (* 1 = 0.187864 loss)
I0905 23:12:24.586380 90901 sgd_solver.cpp:106] Iteration 66750, lr = 0.01
I0905 23:12:35.421260 90901 solver.cpp:228] Iteration 66760, loss = 0.13536
I0905 23:12:35.421334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135362 (* 1 = 0.135362 loss)
I0905 23:12:35.421350 90901 sgd_solver.cpp:106] Iteration 66760, lr = 0.01
I0905 23:12:45.356006 90901 solver.cpp:228] Iteration 66770, loss = 0.140811
I0905 23:12:45.356169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140813 (* 1 = 0.140813 loss)
I0905 23:12:45.356201 90901 sgd_solver.cpp:106] Iteration 66770, lr = 0.01
I0905 23:12:55.466809 90901 solver.cpp:228] Iteration 66780, loss = 0.145969
I0905 23:12:55.466892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145971 (* 1 = 0.145971 loss)
I0905 23:12:55.466910 90901 sgd_solver.cpp:106] Iteration 66780, lr = 0.01
I0905 23:13:10.767313 90901 solver.cpp:228] Iteration 66790, loss = 0.284391
I0905 23:13:10.767390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284393 (* 1 = 0.284393 loss)
I0905 23:13:10.767408 90901 sgd_solver.cpp:106] Iteration 66790, lr = 0.01
I0905 23:13:29.122903 90901 solver.cpp:228] Iteration 66800, loss = 0.119798
I0905 23:13:29.123050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119799 (* 1 = 0.119799 loss)
I0905 23:13:29.123071 90901 sgd_solver.cpp:106] Iteration 66800, lr = 0.01
I0905 23:13:47.586679 90901 solver.cpp:228] Iteration 66810, loss = 0.235188
I0905 23:13:47.586768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235189 (* 1 = 0.235189 loss)
I0905 23:13:47.586791 90901 sgd_solver.cpp:106] Iteration 66810, lr = 0.01
I0905 23:14:05.956749 90901 solver.cpp:228] Iteration 66820, loss = 0.228645
I0905 23:14:05.957002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228646 (* 1 = 0.228646 loss)
I0905 23:14:05.957022 90901 sgd_solver.cpp:106] Iteration 66820, lr = 0.01
I0905 23:14:24.527624 90901 solver.cpp:228] Iteration 66830, loss = 0.052654
I0905 23:14:24.527710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0526555 (* 1 = 0.0526555 loss)
I0905 23:14:24.527729 90901 sgd_solver.cpp:106] Iteration 66830, lr = 0.01
I0905 23:14:40.692282 90901 solver.cpp:228] Iteration 66840, loss = 0.0897214
I0905 23:14:40.692500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0897229 (* 1 = 0.0897229 loss)
I0905 23:14:40.692543 90901 sgd_solver.cpp:106] Iteration 66840, lr = 0.01
I0905 23:14:58.257299 90901 solver.cpp:228] Iteration 66850, loss = 0.1007
I0905 23:14:58.257375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100701 (* 1 = 0.100701 loss)
I0905 23:14:58.257395 90901 sgd_solver.cpp:106] Iteration 66850, lr = 0.01
I0905 23:15:14.711172 90901 solver.cpp:228] Iteration 66860, loss = 0.311643
I0905 23:15:14.711452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311645 (* 1 = 0.311645 loss)
I0905 23:15:14.711479 90901 sgd_solver.cpp:106] Iteration 66860, lr = 0.01
I0905 23:15:27.062204 90901 solver.cpp:228] Iteration 66870, loss = 0.131838
I0905 23:15:27.062283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13184 (* 1 = 0.13184 loss)
I0905 23:15:27.062300 90901 sgd_solver.cpp:106] Iteration 66870, lr = 0.01
I0905 23:15:41.504720 90901 solver.cpp:228] Iteration 66880, loss = 0.350717
I0905 23:15:41.504793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350719 (* 1 = 0.350719 loss)
I0905 23:15:41.504815 90901 sgd_solver.cpp:106] Iteration 66880, lr = 0.01
I0905 23:15:58.241427 90901 solver.cpp:228] Iteration 66890, loss = 0.111386
I0905 23:15:58.241598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111387 (* 1 = 0.111387 loss)
I0905 23:15:58.241629 90901 sgd_solver.cpp:106] Iteration 66890, lr = 0.01
I0905 23:16:11.459962 90901 solver.cpp:228] Iteration 66900, loss = 0.0489452
I0905 23:16:11.460060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0489467 (* 1 = 0.0489467 loss)
I0905 23:16:11.460088 90901 sgd_solver.cpp:106] Iteration 66900, lr = 0.01
I0905 23:16:23.906952 90901 solver.cpp:228] Iteration 66910, loss = 0.0417404
I0905 23:16:23.907028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0417419 (* 1 = 0.0417419 loss)
I0905 23:16:23.907044 90901 sgd_solver.cpp:106] Iteration 66910, lr = 0.01
I0905 23:16:36.133535 90901 solver.cpp:228] Iteration 66920, loss = 0.327662
I0905 23:16:36.133785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327664 (* 1 = 0.327664 loss)
I0905 23:16:36.133813 90901 sgd_solver.cpp:106] Iteration 66920, lr = 0.01
I0905 23:16:51.342972 90901 solver.cpp:228] Iteration 66930, loss = 0.108785
I0905 23:16:51.343062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108787 (* 1 = 0.108787 loss)
I0905 23:16:51.343082 90901 sgd_solver.cpp:106] Iteration 66930, lr = 0.01
I0905 23:17:06.196036 90901 solver.cpp:228] Iteration 66940, loss = 0.496312
I0905 23:17:06.196221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496313 (* 1 = 0.496313 loss)
I0905 23:17:06.196254 90901 sgd_solver.cpp:106] Iteration 66940, lr = 0.01
I0905 23:17:22.021195 90901 solver.cpp:228] Iteration 66950, loss = 0.136088
I0905 23:17:22.021280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13609 (* 1 = 0.13609 loss)
I0905 23:17:22.021302 90901 sgd_solver.cpp:106] Iteration 66950, lr = 0.01
I0905 23:17:39.846352 90901 solver.cpp:228] Iteration 66960, loss = 0.263953
I0905 23:17:39.846585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263955 (* 1 = 0.263955 loss)
I0905 23:17:39.846616 90901 sgd_solver.cpp:106] Iteration 66960, lr = 0.01
I0905 23:17:56.817894 90901 solver.cpp:228] Iteration 66970, loss = 0.0930668
I0905 23:17:56.817981 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0930684 (* 1 = 0.0930684 loss)
I0905 23:17:56.818001 90901 sgd_solver.cpp:106] Iteration 66970, lr = 0.01
I0905 23:18:14.791602 90901 solver.cpp:228] Iteration 66980, loss = 0.183377
I0905 23:18:14.800047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183379 (* 1 = 0.183379 loss)
I0905 23:18:14.800070 90901 sgd_solver.cpp:106] Iteration 66980, lr = 0.01
I0905 23:18:33.554152 90901 solver.cpp:228] Iteration 66990, loss = 0.145718
I0905 23:18:33.554283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145719 (* 1 = 0.145719 loss)
I0905 23:18:33.554314 90901 sgd_solver.cpp:106] Iteration 66990, lr = 0.01
I0905 23:18:52.962357 90901 solver.cpp:228] Iteration 67000, loss = 0.202708
I0905 23:18:52.962517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20271 (* 1 = 0.20271 loss)
I0905 23:18:52.962537 90901 sgd_solver.cpp:106] Iteration 67000, lr = 0.01
I0905 23:19:09.805749 90901 solver.cpp:228] Iteration 67010, loss = 0.178146
I0905 23:19:09.805829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178148 (* 1 = 0.178148 loss)
I0905 23:19:09.805847 90901 sgd_solver.cpp:106] Iteration 67010, lr = 0.01
I0905 23:19:27.853327 90901 solver.cpp:228] Iteration 67020, loss = 0.236125
I0905 23:19:27.853549 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236127 (* 1 = 0.236127 loss)
I0905 23:19:27.853569 90901 sgd_solver.cpp:106] Iteration 67020, lr = 0.01
I0905 23:19:45.841403 90901 solver.cpp:228] Iteration 67030, loss = 0.250731
I0905 23:19:45.841480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250733 (* 1 = 0.250733 loss)
I0905 23:19:45.841497 90901 sgd_solver.cpp:106] Iteration 67030, lr = 0.01
I0905 23:20:03.491735 90901 solver.cpp:228] Iteration 67040, loss = 0.0876891
I0905 23:20:03.491935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0876907 (* 1 = 0.0876907 loss)
I0905 23:20:03.491966 90901 sgd_solver.cpp:106] Iteration 67040, lr = 0.01
I0905 23:20:18.808521 90901 solver.cpp:228] Iteration 67050, loss = 0.146308
I0905 23:20:18.808585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146309 (* 1 = 0.146309 loss)
I0905 23:20:18.808598 90901 sgd_solver.cpp:106] Iteration 67050, lr = 0.01
I0905 23:20:30.810264 90901 solver.cpp:228] Iteration 67060, loss = 0.069331
I0905 23:20:30.810334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0693325 (* 1 = 0.0693325 loss)
I0905 23:20:30.810353 90901 sgd_solver.cpp:106] Iteration 67060, lr = 0.01
I0905 23:20:42.591817 90901 solver.cpp:228] Iteration 67070, loss = 0.194385
I0905 23:20:42.592043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194386 (* 1 = 0.194386 loss)
I0905 23:20:42.592067 90901 sgd_solver.cpp:106] Iteration 67070, lr = 0.01
I0905 23:20:57.387934 90901 solver.cpp:228] Iteration 67080, loss = 0.279623
I0905 23:20:57.388007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279625 (* 1 = 0.279625 loss)
I0905 23:20:57.388025 90901 sgd_solver.cpp:106] Iteration 67080, lr = 0.01
I0905 23:21:15.928361 90901 solver.cpp:228] Iteration 67090, loss = 0.151002
I0905 23:21:15.928575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151003 (* 1 = 0.151003 loss)
I0905 23:21:15.928594 90901 sgd_solver.cpp:106] Iteration 67090, lr = 0.01
I0905 23:21:32.641448 90901 solver.cpp:228] Iteration 67100, loss = 0.371798
I0905 23:21:32.641521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371799 (* 1 = 0.371799 loss)
I0905 23:21:32.641541 90901 sgd_solver.cpp:106] Iteration 67100, lr = 0.01
I0905 23:21:52.209537 90901 solver.cpp:228] Iteration 67110, loss = 0.0897738
I0905 23:21:52.209870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0897754 (* 1 = 0.0897754 loss)
I0905 23:21:52.209893 90901 sgd_solver.cpp:106] Iteration 67110, lr = 0.01
I0905 23:22:11.750434 90901 solver.cpp:228] Iteration 67120, loss = 0.280022
I0905 23:22:11.750524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280024 (* 1 = 0.280024 loss)
I0905 23:22:11.750553 90901 sgd_solver.cpp:106] Iteration 67120, lr = 0.01
I0905 23:22:28.287890 90901 solver.cpp:228] Iteration 67130, loss = 0.18078
I0905 23:22:28.288084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180781 (* 1 = 0.180781 loss)
I0905 23:22:28.288120 90901 sgd_solver.cpp:106] Iteration 67130, lr = 0.01
I0905 23:22:46.333384 90901 solver.cpp:228] Iteration 67140, loss = 0.160246
I0905 23:22:46.333456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160248 (* 1 = 0.160248 loss)
I0905 23:22:46.333474 90901 sgd_solver.cpp:106] Iteration 67140, lr = 0.01
I0905 23:23:03.860113 90901 solver.cpp:228] Iteration 67150, loss = 0.141171
I0905 23:23:03.860304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141173 (* 1 = 0.141173 loss)
I0905 23:23:03.860321 90901 sgd_solver.cpp:106] Iteration 67150, lr = 0.01
I0905 23:23:22.833773 90901 solver.cpp:228] Iteration 67160, loss = 0.0812555
I0905 23:23:22.833845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0812571 (* 1 = 0.0812571 loss)
I0905 23:23:22.833864 90901 sgd_solver.cpp:106] Iteration 67160, lr = 0.01
I0905 23:23:40.523175 90901 solver.cpp:228] Iteration 67170, loss = 0.0654222
I0905 23:23:40.523346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0654238 (* 1 = 0.0654238 loss)
I0905 23:23:40.523383 90901 sgd_solver.cpp:106] Iteration 67170, lr = 0.01
I0905 23:23:55.384886 90901 solver.cpp:228] Iteration 67180, loss = 0.149698
I0905 23:23:55.384966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1497 (* 1 = 0.1497 loss)
I0905 23:23:55.384984 90901 sgd_solver.cpp:106] Iteration 67180, lr = 0.01
I0905 23:24:13.582337 90901 solver.cpp:228] Iteration 67190, loss = 0.184341
I0905 23:24:13.582561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184343 (* 1 = 0.184343 loss)
I0905 23:24:13.582581 90901 sgd_solver.cpp:106] Iteration 67190, lr = 0.01
I0905 23:24:30.512794 90901 solver.cpp:337] Iteration 67200, Testing net (#0)
I0905 23:26:28.585865 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.895625
I0905 23:26:28.586040 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.250223 (* 1 = 0.250223 loss)
I0905 23:26:28.909713 90901 solver.cpp:228] Iteration 67200, loss = 0.12023
I0905 23:26:28.909783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120231 (* 1 = 0.120231 loss)
I0905 23:26:28.909806 90901 sgd_solver.cpp:106] Iteration 67200, lr = 0.01
I0905 23:26:43.318840 90901 solver.cpp:228] Iteration 67210, loss = 0.129307
I0905 23:26:43.318924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129308 (* 1 = 0.129308 loss)
I0905 23:26:43.318944 90901 sgd_solver.cpp:106] Iteration 67210, lr = 0.01
I0905 23:26:55.229112 90901 solver.cpp:228] Iteration 67220, loss = 0.598944
I0905 23:26:55.229207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.598946 (* 1 = 0.598946 loss)
I0905 23:26:55.229228 90901 sgd_solver.cpp:106] Iteration 67220, lr = 0.01
I0905 23:27:08.131062 90901 solver.cpp:228] Iteration 67230, loss = 0.196699
I0905 23:27:08.131228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196701 (* 1 = 0.196701 loss)
I0905 23:27:08.131248 90901 sgd_solver.cpp:106] Iteration 67230, lr = 0.01
I0905 23:27:19.249835 90901 solver.cpp:228] Iteration 67240, loss = 0.138139
I0905 23:27:19.249925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13814 (* 1 = 0.13814 loss)
I0905 23:27:19.249941 90901 sgd_solver.cpp:106] Iteration 67240, lr = 0.01
I0905 23:27:30.443744 90901 solver.cpp:228] Iteration 67250, loss = 0.355752
I0905 23:27:30.443828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355754 (* 1 = 0.355754 loss)
I0905 23:27:30.443845 90901 sgd_solver.cpp:106] Iteration 67250, lr = 0.01
I0905 23:27:39.825532 90901 solver.cpp:228] Iteration 67260, loss = 0.202594
I0905 23:27:39.825850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202596 (* 1 = 0.202596 loss)
I0905 23:27:39.825875 90901 sgd_solver.cpp:106] Iteration 67260, lr = 0.01
I0905 23:27:49.792271 90901 solver.cpp:228] Iteration 67270, loss = 0.0632214
I0905 23:27:49.792374 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.063223 (* 1 = 0.063223 loss)
I0905 23:27:49.792392 90901 sgd_solver.cpp:106] Iteration 67270, lr = 0.01
I0905 23:27:58.562281 90901 solver.cpp:228] Iteration 67280, loss = 0.24449
I0905 23:27:58.562366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244491 (* 1 = 0.244491 loss)
I0905 23:27:58.562383 90901 sgd_solver.cpp:106] Iteration 67280, lr = 0.01
I0905 23:28:04.868849 90901 solver.cpp:228] Iteration 67290, loss = 0.0417113
I0905 23:28:04.868922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0417129 (* 1 = 0.0417129 loss)
I0905 23:28:04.868939 90901 sgd_solver.cpp:106] Iteration 67290, lr = 0.01
I0905 23:28:10.096612 90901 solver.cpp:228] Iteration 67300, loss = 0.115339
I0905 23:28:10.096779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115341 (* 1 = 0.115341 loss)
I0905 23:28:10.096807 90901 sgd_solver.cpp:106] Iteration 67300, lr = 0.01
I0905 23:28:17.130913 90901 solver.cpp:228] Iteration 67310, loss = 0.181922
I0905 23:28:17.130977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181924 (* 1 = 0.181924 loss)
I0905 23:28:17.130993 90901 sgd_solver.cpp:106] Iteration 67310, lr = 0.01
I0905 23:28:24.925227 90901 solver.cpp:228] Iteration 67320, loss = 0.140577
I0905 23:28:24.925367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140579 (* 1 = 0.140579 loss)
I0905 23:28:24.925393 90901 sgd_solver.cpp:106] Iteration 67320, lr = 0.01
I0905 23:28:39.437412 90901 solver.cpp:228] Iteration 67330, loss = 0.0687524
I0905 23:28:39.437474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.068754 (* 1 = 0.068754 loss)
I0905 23:28:39.437490 90901 sgd_solver.cpp:106] Iteration 67330, lr = 0.01
I0905 23:28:51.071535 90901 solver.cpp:228] Iteration 67340, loss = 0.0804833
I0905 23:28:51.071709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0804849 (* 1 = 0.0804849 loss)
I0905 23:28:51.071750 90901 sgd_solver.cpp:106] Iteration 67340, lr = 0.01
I0905 23:29:03.499605 90901 solver.cpp:228] Iteration 67350, loss = 0.19349
I0905 23:29:03.499670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193491 (* 1 = 0.193491 loss)
I0905 23:29:03.499686 90901 sgd_solver.cpp:106] Iteration 67350, lr = 0.01
I0905 23:29:15.245040 90901 solver.cpp:228] Iteration 67360, loss = 0.150159
I0905 23:29:15.245126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15016 (* 1 = 0.15016 loss)
I0905 23:29:15.245143 90901 sgd_solver.cpp:106] Iteration 67360, lr = 0.01
I0905 23:29:27.881150 90901 solver.cpp:228] Iteration 67370, loss = 0.399494
I0905 23:29:27.881315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399495 (* 1 = 0.399495 loss)
I0905 23:29:27.881340 90901 sgd_solver.cpp:106] Iteration 67370, lr = 0.01
I0905 23:29:39.653627 90901 solver.cpp:228] Iteration 67380, loss = 0.139084
I0905 23:29:39.653723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139086 (* 1 = 0.139086 loss)
I0905 23:29:39.653745 90901 sgd_solver.cpp:106] Iteration 67380, lr = 0.01
I0905 23:29:56.604672 90901 solver.cpp:228] Iteration 67390, loss = 0.541344
I0905 23:29:56.604739 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541346 (* 1 = 0.541346 loss)
I0905 23:29:56.604755 90901 sgd_solver.cpp:106] Iteration 67390, lr = 0.01
I0905 23:30:13.303350 90901 solver.cpp:228] Iteration 67400, loss = 0.283878
I0905 23:30:13.303640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283879 (* 1 = 0.283879 loss)
I0905 23:30:13.303665 90901 sgd_solver.cpp:106] Iteration 67400, lr = 0.01
I0905 23:30:29.841780 90901 solver.cpp:228] Iteration 67410, loss = 0.196726
I0905 23:30:29.841858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196728 (* 1 = 0.196728 loss)
I0905 23:30:29.841876 90901 sgd_solver.cpp:106] Iteration 67410, lr = 0.01
I0905 23:30:47.673341 90901 solver.cpp:228] Iteration 67420, loss = 0.247544
I0905 23:30:47.673542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247546 (* 1 = 0.247546 loss)
I0905 23:30:47.673580 90901 sgd_solver.cpp:106] Iteration 67420, lr = 0.01
I0905 23:30:58.492604 90901 solver.cpp:228] Iteration 67430, loss = 0.153158
I0905 23:30:58.492687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153159 (* 1 = 0.153159 loss)
I0905 23:30:58.492708 90901 sgd_solver.cpp:106] Iteration 67430, lr = 0.01
I0905 23:31:15.287125 90901 solver.cpp:228] Iteration 67440, loss = 0.221751
I0905 23:31:15.287189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221753 (* 1 = 0.221753 loss)
I0905 23:31:15.287207 90901 sgd_solver.cpp:106] Iteration 67440, lr = 0.01
I0905 23:31:33.227509 90901 solver.cpp:228] Iteration 67450, loss = 0.0227431
I0905 23:31:33.227704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0227447 (* 1 = 0.0227447 loss)
I0905 23:31:33.227730 90901 sgd_solver.cpp:106] Iteration 67450, lr = 0.01
I0905 23:31:51.241047 90901 solver.cpp:228] Iteration 67460, loss = 0.0818652
I0905 23:31:51.241127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0818668 (* 1 = 0.0818668 loss)
I0905 23:31:51.241147 90901 sgd_solver.cpp:106] Iteration 67460, lr = 0.01
I0905 23:32:09.403211 90901 solver.cpp:228] Iteration 67470, loss = 0.194791
I0905 23:32:09.403349 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194793 (* 1 = 0.194793 loss)
I0905 23:32:09.403367 90901 sgd_solver.cpp:106] Iteration 67470, lr = 0.01
I0905 23:32:28.369168 90901 solver.cpp:228] Iteration 67480, loss = 0.211723
I0905 23:32:28.369242 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211725 (* 1 = 0.211725 loss)
I0905 23:32:28.369263 90901 sgd_solver.cpp:106] Iteration 67480, lr = 0.01
I0905 23:32:47.817122 90901 solver.cpp:228] Iteration 67490, loss = 0.0801513
I0905 23:32:47.817379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0801529 (* 1 = 0.0801529 loss)
I0905 23:32:47.817402 90901 sgd_solver.cpp:106] Iteration 67490, lr = 0.01
I0905 23:33:07.370640 90901 solver.cpp:228] Iteration 67500, loss = 0.235873
I0905 23:33:07.370772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235874 (* 1 = 0.235874 loss)
I0905 23:33:07.370800 90901 sgd_solver.cpp:106] Iteration 67500, lr = 0.01
I0905 23:33:24.772228 90901 solver.cpp:228] Iteration 67510, loss = 0.132158
I0905 23:33:24.772408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13216 (* 1 = 0.13216 loss)
I0905 23:33:24.772451 90901 sgd_solver.cpp:106] Iteration 67510, lr = 0.01
I0905 23:33:42.838982 90901 solver.cpp:228] Iteration 67520, loss = 0.0599802
I0905 23:33:42.839064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0599819 (* 1 = 0.0599819 loss)
I0905 23:33:42.839085 90901 sgd_solver.cpp:106] Iteration 67520, lr = 0.01
I0905 23:34:00.314229 90901 solver.cpp:228] Iteration 67530, loss = 0.487897
I0905 23:34:00.326740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.487898 (* 1 = 0.487898 loss)
I0905 23:34:00.326759 90901 sgd_solver.cpp:106] Iteration 67530, lr = 0.01
I0905 23:34:21.746938 90901 solver.cpp:228] Iteration 67540, loss = 0.151376
I0905 23:34:21.747005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151378 (* 1 = 0.151378 loss)
I0905 23:34:21.747025 90901 sgd_solver.cpp:106] Iteration 67540, lr = 0.01
I0905 23:34:41.785429 90901 solver.cpp:228] Iteration 67550, loss = 0.131181
I0905 23:34:41.785640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131183 (* 1 = 0.131183 loss)
I0905 23:34:41.785675 90901 sgd_solver.cpp:106] Iteration 67550, lr = 0.01
I0905 23:35:01.877135 90901 solver.cpp:228] Iteration 67560, loss = 0.173383
I0905 23:35:01.877210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173384 (* 1 = 0.173384 loss)
I0905 23:35:01.877228 90901 sgd_solver.cpp:106] Iteration 67560, lr = 0.01
I0905 23:35:15.720803 90901 solver.cpp:228] Iteration 67570, loss = 0.193893
I0905 23:35:15.720959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193895 (* 1 = 0.193895 loss)
I0905 23:35:15.720978 90901 sgd_solver.cpp:106] Iteration 67570, lr = 0.01
I0905 23:35:27.971326 90901 solver.cpp:228] Iteration 67580, loss = 0.0495556
I0905 23:35:27.971403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0495573 (* 1 = 0.0495573 loss)
I0905 23:35:27.971421 90901 sgd_solver.cpp:106] Iteration 67580, lr = 0.01
I0905 23:35:45.646920 90901 solver.cpp:228] Iteration 67590, loss = 0.143783
I0905 23:35:45.647003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143785 (* 1 = 0.143785 loss)
I0905 23:35:45.647025 90901 sgd_solver.cpp:106] Iteration 67590, lr = 0.01
I0905 23:36:04.326506 90901 solver.cpp:228] Iteration 67600, loss = 0.0692003
I0905 23:36:04.326704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0692019 (* 1 = 0.0692019 loss)
I0905 23:36:04.326728 90901 sgd_solver.cpp:106] Iteration 67600, lr = 0.01
I0905 23:36:22.278436 90901 solver.cpp:228] Iteration 67610, loss = 0.190035
I0905 23:36:22.278501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190037 (* 1 = 0.190037 loss)
I0905 23:36:22.278517 90901 sgd_solver.cpp:106] Iteration 67610, lr = 0.01
I0905 23:36:40.932754 90901 solver.cpp:228] Iteration 67620, loss = 0.491178
I0905 23:36:40.932930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.491179 (* 1 = 0.491179 loss)
I0905 23:36:40.932953 90901 sgd_solver.cpp:106] Iteration 67620, lr = 0.01
I0905 23:36:59.288059 90901 solver.cpp:228] Iteration 67630, loss = 0.345511
I0905 23:36:59.288159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345513 (* 1 = 0.345513 loss)
I0905 23:36:59.288177 90901 sgd_solver.cpp:106] Iteration 67630, lr = 0.01
I0905 23:37:18.500694 90901 solver.cpp:228] Iteration 67640, loss = 0.107086
I0905 23:37:18.501363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107087 (* 1 = 0.107087 loss)
I0905 23:37:18.501426 90901 sgd_solver.cpp:106] Iteration 67640, lr = 0.01
I0905 23:37:36.573668 90901 solver.cpp:228] Iteration 67650, loss = 0.167357
I0905 23:37:36.573774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167358 (* 1 = 0.167358 loss)
I0905 23:37:36.573796 90901 sgd_solver.cpp:106] Iteration 67650, lr = 0.01
I0905 23:37:53.107203 90901 solver.cpp:228] Iteration 67660, loss = 0.393054
I0905 23:37:53.107435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393056 (* 1 = 0.393056 loss)
I0905 23:37:53.107487 90901 sgd_solver.cpp:106] Iteration 67660, lr = 0.01
I0905 23:38:06.603211 90901 solver.cpp:228] Iteration 67670, loss = 0.259531
I0905 23:38:06.603298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259533 (* 1 = 0.259533 loss)
I0905 23:38:06.603317 90901 sgd_solver.cpp:106] Iteration 67670, lr = 0.01
I0905 23:38:18.221654 90901 solver.cpp:228] Iteration 67680, loss = 0.241311
I0905 23:38:18.221734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241312 (* 1 = 0.241312 loss)
I0905 23:38:18.221752 90901 sgd_solver.cpp:106] Iteration 67680, lr = 0.01
I0905 23:38:30.099515 90901 solver.cpp:228] Iteration 67690, loss = 0.343657
I0905 23:38:30.099706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343658 (* 1 = 0.343658 loss)
I0905 23:38:30.099736 90901 sgd_solver.cpp:106] Iteration 67690, lr = 0.01
I0905 23:38:46.388382 90901 solver.cpp:228] Iteration 67700, loss = 0.050411
I0905 23:38:46.388460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0504126 (* 1 = 0.0504126 loss)
I0905 23:38:46.388481 90901 sgd_solver.cpp:106] Iteration 67700, lr = 0.01
I0905 23:39:04.839642 90901 solver.cpp:228] Iteration 67710, loss = 0.189152
I0905 23:39:04.839928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189154 (* 1 = 0.189154 loss)
I0905 23:39:04.839951 90901 sgd_solver.cpp:106] Iteration 67710, lr = 0.01
I0905 23:39:23.319666 90901 solver.cpp:228] Iteration 67720, loss = 0.292756
I0905 23:39:23.319746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292758 (* 1 = 0.292758 loss)
I0905 23:39:23.319787 90901 sgd_solver.cpp:106] Iteration 67720, lr = 0.01
I0905 23:39:37.616550 90901 solver.cpp:228] Iteration 67730, loss = 0.198515
I0905 23:39:37.616716 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198516 (* 1 = 0.198516 loss)
I0905 23:39:37.616734 90901 sgd_solver.cpp:106] Iteration 67730, lr = 0.01
I0905 23:39:49.968451 90901 solver.cpp:228] Iteration 67740, loss = 0.101534
I0905 23:39:49.968526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101535 (* 1 = 0.101535 loss)
I0905 23:39:49.968544 90901 sgd_solver.cpp:106] Iteration 67740, lr = 0.01
I0905 23:40:06.581930 90901 solver.cpp:228] Iteration 67750, loss = 0.211992
I0905 23:40:06.582010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211993 (* 1 = 0.211993 loss)
I0905 23:40:06.582028 90901 sgd_solver.cpp:106] Iteration 67750, lr = 0.01
I0905 23:40:24.091035 90901 solver.cpp:228] Iteration 67760, loss = 0.11212
I0905 23:40:24.091240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112121 (* 1 = 0.112121 loss)
I0905 23:40:24.091276 90901 sgd_solver.cpp:106] Iteration 67760, lr = 0.01
I0905 23:40:41.119175 90901 solver.cpp:228] Iteration 67770, loss = 0.0629026
I0905 23:40:41.119266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0629042 (* 1 = 0.0629042 loss)
I0905 23:40:41.119283 90901 sgd_solver.cpp:106] Iteration 67770, lr = 0.01
I0905 23:40:59.204032 90901 solver.cpp:228] Iteration 67780, loss = 0.189505
I0905 23:40:59.204211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189507 (* 1 = 0.189507 loss)
I0905 23:40:59.204247 90901 sgd_solver.cpp:106] Iteration 67780, lr = 0.01
I0905 23:41:17.486440 90901 solver.cpp:228] Iteration 67790, loss = 0.432885
I0905 23:41:17.486521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.432886 (* 1 = 0.432886 loss)
I0905 23:41:17.486538 90901 sgd_solver.cpp:106] Iteration 67790, lr = 0.01
I0905 23:41:34.511258 90901 solver.cpp:228] Iteration 67800, loss = 0.115792
I0905 23:41:34.518743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115794 (* 1 = 0.115794 loss)
I0905 23:41:34.518759 90901 sgd_solver.cpp:106] Iteration 67800, lr = 0.01
I0905 23:41:53.395462 90901 solver.cpp:228] Iteration 67810, loss = 0.252439
I0905 23:41:53.395550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25244 (* 1 = 0.25244 loss)
I0905 23:41:53.395567 90901 sgd_solver.cpp:106] Iteration 67810, lr = 0.01
I0905 23:42:11.015874 90901 solver.cpp:228] Iteration 67820, loss = 0.0740625
I0905 23:42:11.016052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.074064 (* 1 = 0.074064 loss)
I0905 23:42:11.016086 90901 sgd_solver.cpp:106] Iteration 67820, lr = 0.01
I0905 23:42:27.807454 90901 solver.cpp:228] Iteration 67830, loss = 0.0998475
I0905 23:42:27.807528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.099849 (* 1 = 0.099849 loss)
I0905 23:42:27.807548 90901 sgd_solver.cpp:106] Iteration 67830, lr = 0.01
I0905 23:42:41.536449 90901 solver.cpp:228] Iteration 67840, loss = 0.044593
I0905 23:42:41.536600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0445944 (* 1 = 0.0445944 loss)
I0905 23:42:41.536633 90901 sgd_solver.cpp:106] Iteration 67840, lr = 0.01
I0905 23:42:52.704510 90901 solver.cpp:228] Iteration 67850, loss = 0.279061
I0905 23:42:52.704582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279063 (* 1 = 0.279063 loss)
I0905 23:42:52.704599 90901 sgd_solver.cpp:106] Iteration 67850, lr = 0.01
I0905 23:43:03.393520 90901 solver.cpp:228] Iteration 67860, loss = 0.255547
I0905 23:43:03.393612 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255549 (* 1 = 0.255549 loss)
I0905 23:43:03.393635 90901 sgd_solver.cpp:106] Iteration 67860, lr = 0.01
I0905 23:43:15.798332 90901 solver.cpp:228] Iteration 67870, loss = 0.210238
I0905 23:43:15.798614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21024 (* 1 = 0.21024 loss)
I0905 23:43:15.798668 90901 sgd_solver.cpp:106] Iteration 67870, lr = 0.01
I0905 23:43:32.137392 90901 solver.cpp:228] Iteration 67880, loss = 0.111201
I0905 23:43:32.137472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111202 (* 1 = 0.111202 loss)
I0905 23:43:32.137490 90901 sgd_solver.cpp:106] Iteration 67880, lr = 0.01
I0905 23:43:49.038720 90901 solver.cpp:228] Iteration 67890, loss = 0.641842
I0905 23:43:49.038897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.641843 (* 1 = 0.641843 loss)
I0905 23:43:49.038933 90901 sgd_solver.cpp:106] Iteration 67890, lr = 0.01
I0905 23:44:04.643442 90901 solver.cpp:228] Iteration 67900, loss = 0.093554
I0905 23:44:04.643517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0935555 (* 1 = 0.0935555 loss)
I0905 23:44:04.643538 90901 sgd_solver.cpp:106] Iteration 67900, lr = 0.01
I0905 23:44:14.459405 90901 solver.cpp:228] Iteration 67910, loss = 0.182461
I0905 23:44:14.459481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182463 (* 1 = 0.182463 loss)
I0905 23:44:14.459496 90901 sgd_solver.cpp:106] Iteration 67910, lr = 0.01
I0905 23:44:28.067523 90901 solver.cpp:228] Iteration 67920, loss = 0.17902
I0905 23:44:28.067678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179022 (* 1 = 0.179022 loss)
I0905 23:44:28.067723 90901 sgd_solver.cpp:106] Iteration 67920, lr = 0.01
I0905 23:44:38.883168 90901 solver.cpp:228] Iteration 67930, loss = 0.313479
I0905 23:44:38.883249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313481 (* 1 = 0.313481 loss)
I0905 23:44:38.883266 90901 sgd_solver.cpp:106] Iteration 67930, lr = 0.01
I0905 23:44:49.824710 90901 solver.cpp:228] Iteration 67940, loss = 0.266955
I0905 23:44:49.824790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266957 (* 1 = 0.266957 loss)
I0905 23:44:49.824808 90901 sgd_solver.cpp:106] Iteration 67940, lr = 0.01
I0905 23:44:58.358769 90901 solver.cpp:228] Iteration 67950, loss = 0.192103
I0905 23:44:58.358968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192104 (* 1 = 0.192104 loss)
I0905 23:44:58.358999 90901 sgd_solver.cpp:106] Iteration 67950, lr = 0.01
I0905 23:45:08.641307 90901 solver.cpp:228] Iteration 67960, loss = 0.0672602
I0905 23:45:08.641383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0672618 (* 1 = 0.0672618 loss)
I0905 23:45:08.641402 90901 sgd_solver.cpp:106] Iteration 67960, lr = 0.01
I0905 23:45:19.361548 90901 solver.cpp:228] Iteration 67970, loss = 0.0807372
I0905 23:45:19.361654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0807388 (* 1 = 0.0807388 loss)
I0905 23:45:19.361673 90901 sgd_solver.cpp:106] Iteration 67970, lr = 0.01
I0905 23:45:35.028301 90901 solver.cpp:228] Iteration 67980, loss = 0.125042
I0905 23:45:35.029220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125044 (* 1 = 0.125044 loss)
I0905 23:45:35.029254 90901 sgd_solver.cpp:106] Iteration 67980, lr = 0.01
I0905 23:45:52.280158 90901 solver.cpp:228] Iteration 67990, loss = 0.452729
I0905 23:45:52.280244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45273 (* 1 = 0.45273 loss)
I0905 23:45:52.280263 90901 sgd_solver.cpp:106] Iteration 67990, lr = 0.01
I0905 23:46:08.690999 90901 solver.cpp:337] Iteration 68000, Testing net (#0)
I0905 23:48:15.255204 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.929688
I0905 23:48:15.255384 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.189054 (* 1 = 0.189054 loss)
I0905 23:48:16.362728 90901 solver.cpp:228] Iteration 68000, loss = 0.0654561
I0905 23:48:16.362823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0654577 (* 1 = 0.0654577 loss)
I0905 23:48:16.362848 90901 sgd_solver.cpp:106] Iteration 68000, lr = 0.01
I0905 23:48:34.298426 90901 solver.cpp:228] Iteration 68010, loss = 0.177959
I0905 23:48:34.298513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17796 (* 1 = 0.17796 loss)
I0905 23:48:34.298533 90901 sgd_solver.cpp:106] Iteration 68010, lr = 0.01
I0905 23:48:45.145994 90901 solver.cpp:228] Iteration 68020, loss = 0.115957
I0905 23:48:45.146070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115958 (* 1 = 0.115958 loss)
I0905 23:48:45.146083 90901 sgd_solver.cpp:106] Iteration 68020, lr = 0.01
I0905 23:48:57.483319 90901 solver.cpp:228] Iteration 68030, loss = 0.125601
I0905 23:48:57.483522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125603 (* 1 = 0.125603 loss)
I0905 23:48:57.483539 90901 sgd_solver.cpp:106] Iteration 68030, lr = 0.01
I0905 23:49:05.788337 90901 solver.cpp:228] Iteration 68040, loss = 0.320671
I0905 23:49:05.788447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320673 (* 1 = 0.320673 loss)
I0905 23:49:05.788472 90901 sgd_solver.cpp:106] Iteration 68040, lr = 0.01
I0905 23:49:17.957551 90901 solver.cpp:228] Iteration 68050, loss = 0.288974
I0905 23:49:17.957634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288975 (* 1 = 0.288975 loss)
I0905 23:49:17.957651 90901 sgd_solver.cpp:106] Iteration 68050, lr = 0.01
I0905 23:49:30.123816 90901 solver.cpp:228] Iteration 68060, loss = 0.244082
I0905 23:49:30.123978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244084 (* 1 = 0.244084 loss)
I0905 23:49:30.123996 90901 sgd_solver.cpp:106] Iteration 68060, lr = 0.01
I0905 23:49:42.392930 90901 solver.cpp:228] Iteration 68070, loss = 0.170865
I0905 23:49:42.393000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170867 (* 1 = 0.170867 loss)
I0905 23:49:42.393016 90901 sgd_solver.cpp:106] Iteration 68070, lr = 0.01
I0905 23:49:56.731015 90901 solver.cpp:228] Iteration 68080, loss = 0.267097
I0905 23:49:56.731081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267099 (* 1 = 0.267099 loss)
I0905 23:49:56.731097 90901 sgd_solver.cpp:106] Iteration 68080, lr = 0.01
I0905 23:50:12.563412 90901 solver.cpp:228] Iteration 68090, loss = 0.30355
I0905 23:50:12.563644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303552 (* 1 = 0.303552 loss)
I0905 23:50:12.563670 90901 sgd_solver.cpp:106] Iteration 68090, lr = 0.01
I0905 23:50:24.501827 90901 solver.cpp:228] Iteration 68100, loss = 0.350853
I0905 23:50:24.501880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350855 (* 1 = 0.350855 loss)
I0905 23:50:24.501893 90901 sgd_solver.cpp:106] Iteration 68100, lr = 0.01
I0905 23:50:36.870765 90901 solver.cpp:228] Iteration 68110, loss = 0.209157
I0905 23:50:36.870847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209158 (* 1 = 0.209158 loss)
I0905 23:50:36.870864 90901 sgd_solver.cpp:106] Iteration 68110, lr = 0.01
I0905 23:50:52.303949 90901 solver.cpp:228] Iteration 68120, loss = 0.0900418
I0905 23:50:52.304136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0900433 (* 1 = 0.0900433 loss)
I0905 23:50:52.304157 90901 sgd_solver.cpp:106] Iteration 68120, lr = 0.01
I0905 23:51:03.541883 90901 solver.cpp:228] Iteration 68130, loss = 0.235301
I0905 23:51:03.541990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235302 (* 1 = 0.235302 loss)
I0905 23:51:03.542012 90901 sgd_solver.cpp:106] Iteration 68130, lr = 0.01
I0905 23:51:17.772922 90901 solver.cpp:228] Iteration 68140, loss = 0.192191
I0905 23:51:17.773048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192192 (* 1 = 0.192192 loss)
I0905 23:51:17.773069 90901 sgd_solver.cpp:106] Iteration 68140, lr = 0.01
I0905 23:51:35.487962 90901 solver.cpp:228] Iteration 68150, loss = 0.0980993
I0905 23:51:35.488351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0981008 (* 1 = 0.0981008 loss)
I0905 23:51:35.488379 90901 sgd_solver.cpp:106] Iteration 68150, lr = 0.01
I0905 23:51:54.109989 90901 solver.cpp:228] Iteration 68160, loss = 0.137377
I0905 23:51:54.110064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137379 (* 1 = 0.137379 loss)
I0905 23:51:54.110082 90901 sgd_solver.cpp:106] Iteration 68160, lr = 0.01
I0905 23:52:13.394120 90901 solver.cpp:228] Iteration 68170, loss = 0.263816
I0905 23:52:13.394301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263817 (* 1 = 0.263817 loss)
I0905 23:52:13.394330 90901 sgd_solver.cpp:106] Iteration 68170, lr = 0.01
I0905 23:52:32.086697 90901 solver.cpp:228] Iteration 68180, loss = 0.129929
I0905 23:52:32.086804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12993 (* 1 = 0.12993 loss)
I0905 23:52:32.086822 90901 sgd_solver.cpp:106] Iteration 68180, lr = 0.01
I0905 23:52:51.227370 90901 solver.cpp:228] Iteration 68190, loss = 0.0702454
I0905 23:52:51.227540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0702469 (* 1 = 0.0702469 loss)
I0905 23:52:51.227558 90901 sgd_solver.cpp:106] Iteration 68190, lr = 0.01
I0905 23:53:10.935571 90901 solver.cpp:228] Iteration 68200, loss = 0.24959
I0905 23:53:10.935648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249591 (* 1 = 0.249591 loss)
I0905 23:53:10.935669 90901 sgd_solver.cpp:106] Iteration 68200, lr = 0.01
I0905 23:53:27.788919 90901 solver.cpp:228] Iteration 68210, loss = 0.57883
I0905 23:53:27.789140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578831 (* 1 = 0.578831 loss)
I0905 23:53:27.789173 90901 sgd_solver.cpp:106] Iteration 68210, lr = 0.01
I0905 23:53:43.100786 90901 solver.cpp:228] Iteration 68220, loss = 0.10429
I0905 23:53:43.100898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104291 (* 1 = 0.104291 loss)
I0905 23:53:43.100922 90901 sgd_solver.cpp:106] Iteration 68220, lr = 0.01
I0905 23:53:59.621853 90901 solver.cpp:228] Iteration 68230, loss = 0.155138
I0905 23:53:59.622040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155139 (* 1 = 0.155139 loss)
I0905 23:53:59.622071 90901 sgd_solver.cpp:106] Iteration 68230, lr = 0.01
I0905 23:54:16.782472 90901 solver.cpp:228] Iteration 68240, loss = 0.261827
I0905 23:54:16.782563 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261829 (* 1 = 0.261829 loss)
I0905 23:54:16.782582 90901 sgd_solver.cpp:106] Iteration 68240, lr = 0.01
I0905 23:54:35.117605 90901 solver.cpp:228] Iteration 68250, loss = 0.107545
I0905 23:54:35.117801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107547 (* 1 = 0.107547 loss)
I0905 23:54:35.117843 90901 sgd_solver.cpp:106] Iteration 68250, lr = 0.01
I0905 23:54:51.783879 90901 solver.cpp:228] Iteration 68260, loss = 0.0837126
I0905 23:54:51.783980 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0837142 (* 1 = 0.0837142 loss)
I0905 23:54:51.784003 90901 sgd_solver.cpp:106] Iteration 68260, lr = 0.01
I0905 23:55:05.562991 90901 solver.cpp:228] Iteration 68270, loss = 0.4387
I0905 23:55:05.563243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438701 (* 1 = 0.438701 loss)
I0905 23:55:05.563273 90901 sgd_solver.cpp:106] Iteration 68270, lr = 0.01
I0905 23:55:21.205467 90901 solver.cpp:228] Iteration 68280, loss = 0.300658
I0905 23:55:21.205560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300659 (* 1 = 0.300659 loss)
I0905 23:55:21.205584 90901 sgd_solver.cpp:106] Iteration 68280, lr = 0.01
I0905 23:55:38.960557 90901 solver.cpp:228] Iteration 68290, loss = 0.119139
I0905 23:55:38.960819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119141 (* 1 = 0.119141 loss)
I0905 23:55:38.960853 90901 sgd_solver.cpp:106] Iteration 68290, lr = 0.01
I0905 23:55:55.897032 90901 solver.cpp:228] Iteration 68300, loss = 0.172819
I0905 23:55:55.897109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17282 (* 1 = 0.17282 loss)
I0905 23:55:55.897125 90901 sgd_solver.cpp:106] Iteration 68300, lr = 0.01
I0905 23:56:13.944116 90901 solver.cpp:228] Iteration 68310, loss = 0.169551
I0905 23:56:13.944330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169553 (* 1 = 0.169553 loss)
I0905 23:56:13.944355 90901 sgd_solver.cpp:106] Iteration 68310, lr = 0.01
I0905 23:56:31.186255 90901 solver.cpp:228] Iteration 68320, loss = 0.181605
I0905 23:56:31.186369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181606 (* 1 = 0.181606 loss)
I0905 23:56:31.186389 90901 sgd_solver.cpp:106] Iteration 68320, lr = 0.01
I0905 23:56:48.085083 90901 solver.cpp:228] Iteration 68330, loss = 0.1751
I0905 23:56:48.085253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175101 (* 1 = 0.175101 loss)
I0905 23:56:48.085292 90901 sgd_solver.cpp:106] Iteration 68330, lr = 0.01
I0905 23:57:01.078953 90901 solver.cpp:228] Iteration 68340, loss = 0.184706
I0905 23:57:01.079038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184708 (* 1 = 0.184708 loss)
I0905 23:57:01.079058 90901 sgd_solver.cpp:106] Iteration 68340, lr = 0.01
I0905 23:57:19.204602 90901 solver.cpp:228] Iteration 68350, loss = 0.237891
I0905 23:57:19.204784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237893 (* 1 = 0.237893 loss)
I0905 23:57:19.204833 90901 sgd_solver.cpp:106] Iteration 68350, lr = 0.01
I0905 23:57:37.549253 90901 solver.cpp:228] Iteration 68360, loss = 0.328928
I0905 23:57:37.549365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32893 (* 1 = 0.32893 loss)
I0905 23:57:37.549387 90901 sgd_solver.cpp:106] Iteration 68360, lr = 0.01
I0905 23:57:55.858741 90901 solver.cpp:228] Iteration 68370, loss = 0.182068
I0905 23:57:55.858899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18207 (* 1 = 0.18207 loss)
I0905 23:57:55.858914 90901 sgd_solver.cpp:106] Iteration 68370, lr = 0.01
I0905 23:58:16.139564 90901 solver.cpp:228] Iteration 68380, loss = 0.247884
I0905 23:58:16.139642 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247886 (* 1 = 0.247886 loss)
I0905 23:58:16.139659 90901 sgd_solver.cpp:106] Iteration 68380, lr = 0.01
I0905 23:58:34.934378 90901 solver.cpp:228] Iteration 68390, loss = 0.133849
I0905 23:58:34.934556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133851 (* 1 = 0.133851 loss)
I0905 23:58:34.934583 90901 sgd_solver.cpp:106] Iteration 68390, lr = 0.01
I0905 23:58:53.333982 90901 solver.cpp:228] Iteration 68400, loss = 0.327756
I0905 23:58:53.334058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327758 (* 1 = 0.327758 loss)
I0905 23:58:53.334081 90901 sgd_solver.cpp:106] Iteration 68400, lr = 0.01
I0905 23:59:11.626987 90901 solver.cpp:228] Iteration 68410, loss = 0.112001
I0905 23:59:11.627173 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112003 (* 1 = 0.112003 loss)
I0905 23:59:11.627197 90901 sgd_solver.cpp:106] Iteration 68410, lr = 0.01
I0905 23:59:30.202430 90901 solver.cpp:228] Iteration 68420, loss = 0.181523
I0905 23:59:30.202491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181525 (* 1 = 0.181525 loss)
I0905 23:59:30.202507 90901 sgd_solver.cpp:106] Iteration 68420, lr = 0.01
I0905 23:59:47.863862 90901 solver.cpp:228] Iteration 68430, loss = 0.166164
I0905 23:59:47.864042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166165 (* 1 = 0.166165 loss)
I0905 23:59:47.864071 90901 sgd_solver.cpp:106] Iteration 68430, lr = 0.01
I0906 00:00:05.506115 90901 solver.cpp:228] Iteration 68440, loss = 0.0967954
I0906 00:00:05.506199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0967971 (* 1 = 0.0967971 loss)
I0906 00:00:05.506217 90901 sgd_solver.cpp:106] Iteration 68440, lr = 0.01
I0906 00:00:21.970412 90901 solver.cpp:228] Iteration 68450, loss = 0.241974
I0906 00:00:21.970691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241976 (* 1 = 0.241976 loss)
I0906 00:00:21.970712 90901 sgd_solver.cpp:106] Iteration 68450, lr = 0.01
I0906 00:00:32.366113 90901 solver.cpp:228] Iteration 68460, loss = 0.419751
I0906 00:00:32.366183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.419753 (* 1 = 0.419753 loss)
I0906 00:00:32.366200 90901 sgd_solver.cpp:106] Iteration 68460, lr = 0.01
I0906 00:00:43.397452 90901 solver.cpp:228] Iteration 68470, loss = 0.108136
I0906 00:00:43.397521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108138 (* 1 = 0.108138 loss)
I0906 00:00:43.397536 90901 sgd_solver.cpp:106] Iteration 68470, lr = 0.01
I0906 00:00:56.270985 90901 solver.cpp:228] Iteration 68480, loss = 0.0323959
I0906 00:00:56.271196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0323975 (* 1 = 0.0323975 loss)
I0906 00:00:56.271224 90901 sgd_solver.cpp:106] Iteration 68480, lr = 0.01
I0906 00:01:07.459463 90901 solver.cpp:228] Iteration 68490, loss = 0.215006
I0906 00:01:07.459552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215008 (* 1 = 0.215008 loss)
I0906 00:01:07.459570 90901 sgd_solver.cpp:106] Iteration 68490, lr = 0.01
I0906 00:01:20.473631 90901 solver.cpp:228] Iteration 68500, loss = 0.114832
I0906 00:01:20.473726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114833 (* 1 = 0.114833 loss)
I0906 00:01:20.473747 90901 sgd_solver.cpp:106] Iteration 68500, lr = 0.01
I0906 00:01:31.662545 90901 solver.cpp:228] Iteration 68510, loss = 0.0792057
I0906 00:01:31.662758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0792074 (* 1 = 0.0792074 loss)
I0906 00:01:31.662786 90901 sgd_solver.cpp:106] Iteration 68510, lr = 0.01
I0906 00:01:44.956879 90901 solver.cpp:228] Iteration 68520, loss = 0.140436
I0906 00:01:44.956957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140437 (* 1 = 0.140437 loss)
I0906 00:01:44.956974 90901 sgd_solver.cpp:106] Iteration 68520, lr = 0.01
I0906 00:02:03.871639 90901 solver.cpp:228] Iteration 68530, loss = 0.274018
I0906 00:02:03.871852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27402 (* 1 = 0.27402 loss)
I0906 00:02:03.871877 90901 sgd_solver.cpp:106] Iteration 68530, lr = 0.01
I0906 00:02:22.833385 90901 solver.cpp:228] Iteration 68540, loss = 0.192155
I0906 00:02:22.833499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192157 (* 1 = 0.192157 loss)
I0906 00:02:22.833519 90901 sgd_solver.cpp:106] Iteration 68540, lr = 0.01
I0906 00:02:41.980615 90901 solver.cpp:228] Iteration 68550, loss = 0.0478373
I0906 00:02:41.984566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0478391 (* 1 = 0.0478391 loss)
I0906 00:02:41.984585 90901 sgd_solver.cpp:106] Iteration 68550, lr = 0.01
I0906 00:03:03.411720 90901 solver.cpp:228] Iteration 68560, loss = 0.221138
I0906 00:03:03.411798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22114 (* 1 = 0.22114 loss)
I0906 00:03:03.411820 90901 sgd_solver.cpp:106] Iteration 68560, lr = 0.01
I0906 00:03:22.763625 90901 solver.cpp:228] Iteration 68570, loss = 0.239803
I0906 00:03:22.763815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239805 (* 1 = 0.239805 loss)
I0906 00:03:22.763850 90901 sgd_solver.cpp:106] Iteration 68570, lr = 0.01
I0906 00:03:43.940594 90901 solver.cpp:228] Iteration 68580, loss = 0.16067
I0906 00:03:43.940699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160672 (* 1 = 0.160672 loss)
I0906 00:03:43.940724 90901 sgd_solver.cpp:106] Iteration 68580, lr = 0.01
I0906 00:04:02.596163 90901 solver.cpp:228] Iteration 68590, loss = 0.166768
I0906 00:04:02.596359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16677 (* 1 = 0.16677 loss)
I0906 00:04:02.596400 90901 sgd_solver.cpp:106] Iteration 68590, lr = 0.01
I0906 00:04:24.217171 90901 solver.cpp:228] Iteration 68600, loss = 0.374595
I0906 00:04:24.217298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374597 (* 1 = 0.374597 loss)
I0906 00:04:24.217324 90901 sgd_solver.cpp:106] Iteration 68600, lr = 0.01
I0906 00:04:44.207370 90901 solver.cpp:228] Iteration 68610, loss = 0.101675
I0906 00:04:44.207623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101677 (* 1 = 0.101677 loss)
I0906 00:04:44.207655 90901 sgd_solver.cpp:106] Iteration 68610, lr = 0.01
I0906 00:05:03.210121 90901 solver.cpp:228] Iteration 68620, loss = 0.0482273
I0906 00:05:03.210233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.048229 (* 1 = 0.048229 loss)
I0906 00:05:03.210261 90901 sgd_solver.cpp:106] Iteration 68620, lr = 0.01
I0906 00:05:21.823348 90901 solver.cpp:228] Iteration 68630, loss = 0.318358
I0906 00:05:21.823576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31836 (* 1 = 0.31836 loss)
I0906 00:05:21.823609 90901 sgd_solver.cpp:106] Iteration 68630, lr = 0.01
I0906 00:05:39.148013 90901 solver.cpp:228] Iteration 68640, loss = 0.305987
I0906 00:05:39.148092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305988 (* 1 = 0.305988 loss)
I0906 00:05:39.148114 90901 sgd_solver.cpp:106] Iteration 68640, lr = 0.01
I0906 00:05:55.803005 90901 solver.cpp:228] Iteration 68650, loss = 0.331901
I0906 00:05:55.803264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331903 (* 1 = 0.331903 loss)
I0906 00:05:55.803290 90901 sgd_solver.cpp:106] Iteration 68650, lr = 0.01
I0906 00:06:13.011083 90901 solver.cpp:228] Iteration 68660, loss = 0.360208
I0906 00:06:13.011178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36021 (* 1 = 0.36021 loss)
I0906 00:06:13.011198 90901 sgd_solver.cpp:106] Iteration 68660, lr = 0.01
I0906 00:06:30.599853 90901 solver.cpp:228] Iteration 68670, loss = 0.062309
I0906 00:06:30.600049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0623107 (* 1 = 0.0623107 loss)
I0906 00:06:30.600096 90901 sgd_solver.cpp:106] Iteration 68670, lr = 0.01
I0906 00:06:50.298748 90901 solver.cpp:228] Iteration 68680, loss = 0.154662
I0906 00:06:50.298833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154664 (* 1 = 0.154664 loss)
I0906 00:06:50.298856 90901 sgd_solver.cpp:106] Iteration 68680, lr = 0.01
I0906 00:07:10.574142 90901 solver.cpp:228] Iteration 68690, loss = 0.224531
I0906 00:07:10.574322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224532 (* 1 = 0.224532 loss)
I0906 00:07:10.574352 90901 sgd_solver.cpp:106] Iteration 68690, lr = 0.01
I0906 00:07:31.341284 90901 solver.cpp:228] Iteration 68700, loss = 0.0560608
I0906 00:07:31.341382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0560625 (* 1 = 0.0560625 loss)
I0906 00:07:31.341409 90901 sgd_solver.cpp:106] Iteration 68700, lr = 0.01
I0906 00:07:51.310910 90901 solver.cpp:228] Iteration 68710, loss = 0.152314
I0906 00:07:51.311074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152316 (* 1 = 0.152316 loss)
I0906 00:07:51.311102 90901 sgd_solver.cpp:106] Iteration 68710, lr = 0.01
I0906 00:08:09.657827 90901 solver.cpp:228] Iteration 68720, loss = 0.54088
I0906 00:08:09.657888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.540882 (* 1 = 0.540882 loss)
I0906 00:08:09.657907 90901 sgd_solver.cpp:106] Iteration 68720, lr = 0.01
I0906 00:08:27.164896 90901 solver.cpp:228] Iteration 68730, loss = 0.153522
I0906 00:08:27.165055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153524 (* 1 = 0.153524 loss)
I0906 00:08:27.165087 90901 sgd_solver.cpp:106] Iteration 68730, lr = 0.01
I0906 00:08:42.875952 90901 solver.cpp:228] Iteration 68740, loss = 0.240823
I0906 00:08:42.876029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240824 (* 1 = 0.240824 loss)
I0906 00:08:42.876047 90901 sgd_solver.cpp:106] Iteration 68740, lr = 0.01
I0906 00:09:00.898506 90901 solver.cpp:228] Iteration 68750, loss = 0.511493
I0906 00:09:00.898753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.511495 (* 1 = 0.511495 loss)
I0906 00:09:00.898774 90901 sgd_solver.cpp:106] Iteration 68750, lr = 0.01
I0906 00:09:10.278004 90901 solver.cpp:228] Iteration 68760, loss = 0.0413983
I0906 00:09:10.278095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0414001 (* 1 = 0.0414001 loss)
I0906 00:09:10.278117 90901 sgd_solver.cpp:106] Iteration 68760, lr = 0.01
I0906 00:09:18.434031 90901 solver.cpp:228] Iteration 68770, loss = 0.255304
I0906 00:09:18.434105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255305 (* 1 = 0.255305 loss)
I0906 00:09:18.434123 90901 sgd_solver.cpp:106] Iteration 68770, lr = 0.01
I0906 00:09:29.072465 90901 solver.cpp:228] Iteration 68780, loss = 0.317016
I0906 00:09:29.072535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317018 (* 1 = 0.317018 loss)
I0906 00:09:29.072549 90901 sgd_solver.cpp:106] Iteration 68780, lr = 0.01
I0906 00:09:42.638620 90901 solver.cpp:228] Iteration 68790, loss = 0.341559
I0906 00:09:42.638819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34156 (* 1 = 0.34156 loss)
I0906 00:09:42.638842 90901 sgd_solver.cpp:106] Iteration 68790, lr = 0.01
I0906 00:10:00.714670 90901 solver.cpp:337] Iteration 68800, Testing net (#0)
I0906 00:11:55.283176 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.930313
I0906 00:11:55.283390 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.173718 (* 1 = 0.173718 loss)
I0906 00:11:55.500208 90901 solver.cpp:228] Iteration 68800, loss = 0.161902
I0906 00:11:55.500296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161904 (* 1 = 0.161904 loss)
I0906 00:11:55.500326 90901 sgd_solver.cpp:106] Iteration 68800, lr = 0.01
I0906 00:12:12.959148 90901 solver.cpp:228] Iteration 68810, loss = 0.131042
I0906 00:12:12.959236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131044 (* 1 = 0.131044 loss)
I0906 00:12:12.959259 90901 sgd_solver.cpp:106] Iteration 68810, lr = 0.01
I0906 00:12:31.603447 90901 solver.cpp:228] Iteration 68820, loss = 0.0497808
I0906 00:12:31.603657 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0497825 (* 1 = 0.0497825 loss)
I0906 00:12:31.603685 90901 sgd_solver.cpp:106] Iteration 68820, lr = 0.01
I0906 00:12:51.258476 90901 solver.cpp:228] Iteration 68830, loss = 0.265344
I0906 00:12:51.258560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265345 (* 1 = 0.265345 loss)
I0906 00:12:51.258580 90901 sgd_solver.cpp:106] Iteration 68830, lr = 0.01
I0906 00:13:10.519322 90901 solver.cpp:228] Iteration 68840, loss = 0.196625
I0906 00:13:10.519496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196627 (* 1 = 0.196627 loss)
I0906 00:13:10.519518 90901 sgd_solver.cpp:106] Iteration 68840, lr = 0.01
I0906 00:13:30.026800 90901 solver.cpp:228] Iteration 68850, loss = 0.0596118
I0906 00:13:30.026875 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596135 (* 1 = 0.0596135 loss)
I0906 00:13:30.026891 90901 sgd_solver.cpp:106] Iteration 68850, lr = 0.01
I0906 00:13:48.158104 90901 solver.cpp:228] Iteration 68860, loss = 0.176779
I0906 00:13:48.158272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176781 (* 1 = 0.176781 loss)
I0906 00:13:48.158290 90901 sgd_solver.cpp:106] Iteration 68860, lr = 0.01
I0906 00:14:06.164443 90901 solver.cpp:228] Iteration 68870, loss = 0.0766753
I0906 00:14:06.164511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.076677 (* 1 = 0.076677 loss)
I0906 00:14:06.164528 90901 sgd_solver.cpp:106] Iteration 68870, lr = 0.01
I0906 00:14:23.765960 90901 solver.cpp:228] Iteration 68880, loss = 0.113114
I0906 00:14:23.766140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113116 (* 1 = 0.113116 loss)
I0906 00:14:23.766170 90901 sgd_solver.cpp:106] Iteration 68880, lr = 0.01
I0906 00:14:42.010413 90901 solver.cpp:228] Iteration 68890, loss = 0.121659
I0906 00:14:42.010488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121661 (* 1 = 0.121661 loss)
I0906 00:14:42.010507 90901 sgd_solver.cpp:106] Iteration 68890, lr = 0.01
I0906 00:14:59.313053 90901 solver.cpp:228] Iteration 68900, loss = 0.260268
I0906 00:14:59.313325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260269 (* 1 = 0.260269 loss)
I0906 00:14:59.313345 90901 sgd_solver.cpp:106] Iteration 68900, lr = 0.01
I0906 00:15:17.419004 90901 solver.cpp:228] Iteration 68910, loss = 0.232984
I0906 00:15:17.419085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232986 (* 1 = 0.232986 loss)
I0906 00:15:17.419102 90901 sgd_solver.cpp:106] Iteration 68910, lr = 0.01
I0906 00:15:35.793066 90901 solver.cpp:228] Iteration 68920, loss = 0.0715209
I0906 00:15:35.793344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0715226 (* 1 = 0.0715226 loss)
I0906 00:15:35.793370 90901 sgd_solver.cpp:106] Iteration 68920, lr = 0.01
I0906 00:15:54.737167 90901 solver.cpp:228] Iteration 68930, loss = 0.458269
I0906 00:15:54.737262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.458271 (* 1 = 0.458271 loss)
I0906 00:15:54.737282 90901 sgd_solver.cpp:106] Iteration 68930, lr = 0.01
I0906 00:16:13.347815 90901 solver.cpp:228] Iteration 68940, loss = 0.343208
I0906 00:16:13.348026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343209 (* 1 = 0.343209 loss)
I0906 00:16:13.348047 90901 sgd_solver.cpp:106] Iteration 68940, lr = 0.01
I0906 00:16:27.983845 90901 solver.cpp:228] Iteration 68950, loss = 0.135047
I0906 00:16:27.983933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135049 (* 1 = 0.135049 loss)
I0906 00:16:27.983950 90901 sgd_solver.cpp:106] Iteration 68950, lr = 0.01
I0906 00:16:37.576337 90901 solver.cpp:228] Iteration 68960, loss = 0.19153
I0906 00:16:37.576413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191532 (* 1 = 0.191532 loss)
I0906 00:16:37.576431 90901 sgd_solver.cpp:106] Iteration 68960, lr = 0.01
I0906 00:16:45.873945 90901 solver.cpp:228] Iteration 68970, loss = 0.440771
I0906 00:16:45.874140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.440773 (* 1 = 0.440773 loss)
I0906 00:16:45.874198 90901 sgd_solver.cpp:106] Iteration 68970, lr = 0.01
I0906 00:16:53.660770 90901 solver.cpp:228] Iteration 68980, loss = 0.37151
I0906 00:16:53.660852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.371512 (* 1 = 0.371512 loss)
I0906 00:16:53.660869 90901 sgd_solver.cpp:106] Iteration 68980, lr = 0.01
I0906 00:16:59.079649 90901 solver.cpp:228] Iteration 68990, loss = 0.182483
I0906 00:16:59.079721 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182485 (* 1 = 0.182485 loss)
I0906 00:16:59.079740 90901 sgd_solver.cpp:106] Iteration 68990, lr = 0.01
I0906 00:17:04.405906 90901 solver.cpp:228] Iteration 69000, loss = 0.183163
I0906 00:17:04.405978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183165 (* 1 = 0.183165 loss)
I0906 00:17:04.405997 90901 sgd_solver.cpp:106] Iteration 69000, lr = 0.01
I0906 00:17:11.856781 90901 solver.cpp:228] Iteration 69010, loss = 0.0786275
I0906 00:17:11.856926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0786292 (* 1 = 0.0786292 loss)
I0906 00:17:11.856950 90901 sgd_solver.cpp:106] Iteration 69010, lr = 0.01
I0906 00:17:26.288384 90901 solver.cpp:228] Iteration 69020, loss = 0.109027
I0906 00:17:26.288578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109029 (* 1 = 0.109029 loss)
I0906 00:17:26.288604 90901 sgd_solver.cpp:106] Iteration 69020, lr = 0.01
I0906 00:17:40.306942 90901 solver.cpp:228] Iteration 69030, loss = 0.351735
I0906 00:17:40.307013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351737 (* 1 = 0.351737 loss)
I0906 00:17:40.307031 90901 sgd_solver.cpp:106] Iteration 69030, lr = 0.01
I0906 00:17:56.124233 90901 solver.cpp:228] Iteration 69040, loss = 0.0684306
I0906 00:17:56.124318 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684322 (* 1 = 0.0684322 loss)
I0906 00:17:56.124341 90901 sgd_solver.cpp:106] Iteration 69040, lr = 0.01
I0906 00:18:13.208096 90901 solver.cpp:228] Iteration 69050, loss = 0.0415514
I0906 00:18:13.208963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0415531 (* 1 = 0.0415531 loss)
I0906 00:18:13.209010 90901 sgd_solver.cpp:106] Iteration 69050, lr = 0.01
I0906 00:18:31.663414 90901 solver.cpp:228] Iteration 69060, loss = 0.218511
I0906 00:18:31.663502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218512 (* 1 = 0.218512 loss)
I0906 00:18:31.663522 90901 sgd_solver.cpp:106] Iteration 69060, lr = 0.01
I0906 00:18:48.582273 90901 solver.cpp:228] Iteration 69070, loss = 0.395567
I0906 00:18:48.582532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395568 (* 1 = 0.395568 loss)
I0906 00:18:48.582561 90901 sgd_solver.cpp:106] Iteration 69070, lr = 0.01
I0906 00:19:06.974673 90901 solver.cpp:228] Iteration 69080, loss = 0.605358
I0906 00:19:06.974768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.60536 (* 1 = 0.60536 loss)
I0906 00:19:06.974786 90901 sgd_solver.cpp:106] Iteration 69080, lr = 0.01
I0906 00:19:22.628388 90901 solver.cpp:228] Iteration 69090, loss = 0.652445
I0906 00:19:22.628553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.652447 (* 1 = 0.652447 loss)
I0906 00:19:22.628577 90901 sgd_solver.cpp:106] Iteration 69090, lr = 0.01
I0906 00:19:40.059687 90901 solver.cpp:228] Iteration 69100, loss = 0.187165
I0906 00:19:40.059770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187167 (* 1 = 0.187167 loss)
I0906 00:19:40.059790 90901 sgd_solver.cpp:106] Iteration 69100, lr = 0.01
I0906 00:19:58.444320 90901 solver.cpp:228] Iteration 69110, loss = 0.0846207
I0906 00:19:58.444517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0846223 (* 1 = 0.0846223 loss)
I0906 00:19:58.444552 90901 sgd_solver.cpp:106] Iteration 69110, lr = 0.01
I0906 00:20:16.910588 90901 solver.cpp:228] Iteration 69120, loss = 0.0713224
I0906 00:20:16.910679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0713241 (* 1 = 0.0713241 loss)
I0906 00:20:16.910701 90901 sgd_solver.cpp:106] Iteration 69120, lr = 0.01
I0906 00:20:36.187193 90901 solver.cpp:228] Iteration 69130, loss = 0.0985753
I0906 00:20:36.187396 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0985769 (* 1 = 0.0985769 loss)
I0906 00:20:36.187413 90901 sgd_solver.cpp:106] Iteration 69130, lr = 0.01
I0906 00:20:55.932806 90901 solver.cpp:228] Iteration 69140, loss = 0.0913441
I0906 00:20:55.932893 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0913457 (* 1 = 0.0913457 loss)
I0906 00:20:55.932915 90901 sgd_solver.cpp:106] Iteration 69140, lr = 0.01
I0906 00:21:15.840534 90901 solver.cpp:228] Iteration 69150, loss = 0.245331
I0906 00:21:15.840750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245333 (* 1 = 0.245333 loss)
I0906 00:21:15.840770 90901 sgd_solver.cpp:106] Iteration 69150, lr = 0.01
I0906 00:21:34.113965 90901 solver.cpp:228] Iteration 69160, loss = 0.142795
I0906 00:21:34.114035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142796 (* 1 = 0.142796 loss)
I0906 00:21:34.114054 90901 sgd_solver.cpp:106] Iteration 69160, lr = 0.01
I0906 00:21:51.739933 90901 solver.cpp:228] Iteration 69170, loss = 0.245262
I0906 00:21:51.740139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245263 (* 1 = 0.245263 loss)
I0906 00:21:51.740182 90901 sgd_solver.cpp:106] Iteration 69170, lr = 0.01
I0906 00:22:11.137928 90901 solver.cpp:228] Iteration 69180, loss = 0.284055
I0906 00:22:11.138025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284057 (* 1 = 0.284057 loss)
I0906 00:22:11.138048 90901 sgd_solver.cpp:106] Iteration 69180, lr = 0.01
I0906 00:22:31.312693 90901 solver.cpp:228] Iteration 69190, loss = 0.0812547
I0906 00:22:31.312950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0812564 (* 1 = 0.0812564 loss)
I0906 00:22:31.312973 90901 sgd_solver.cpp:106] Iteration 69190, lr = 0.01
I0906 00:22:51.412140 90901 solver.cpp:228] Iteration 69200, loss = 0.378609
I0906 00:22:51.412230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378611 (* 1 = 0.378611 loss)
I0906 00:22:51.412250 90901 sgd_solver.cpp:106] Iteration 69200, lr = 0.01
I0906 00:23:10.506767 90901 solver.cpp:228] Iteration 69210, loss = 0.169364
I0906 00:23:10.506948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169365 (* 1 = 0.169365 loss)
I0906 00:23:10.506978 90901 sgd_solver.cpp:106] Iteration 69210, lr = 0.01
I0906 00:23:28.677289 90901 solver.cpp:228] Iteration 69220, loss = 0.068985
I0906 00:23:28.677414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0689866 (* 1 = 0.0689866 loss)
I0906 00:23:28.677449 90901 sgd_solver.cpp:106] Iteration 69220, lr = 0.01
I0906 00:23:48.085367 90901 solver.cpp:228] Iteration 69230, loss = 0.080678
I0906 00:23:48.085674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0806797 (* 1 = 0.0806797 loss)
I0906 00:23:48.085693 90901 sgd_solver.cpp:106] Iteration 69230, lr = 0.01
I0906 00:24:06.070443 90901 solver.cpp:228] Iteration 69240, loss = 0.0416183
I0906 00:24:06.070514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0416199 (* 1 = 0.0416199 loss)
I0906 00:24:06.070531 90901 sgd_solver.cpp:106] Iteration 69240, lr = 0.01
I0906 00:24:23.487828 90901 solver.cpp:228] Iteration 69250, loss = 0.219995
I0906 00:24:23.487996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219997 (* 1 = 0.219997 loss)
I0906 00:24:23.488029 90901 sgd_solver.cpp:106] Iteration 69250, lr = 0.01
I0906 00:24:41.949903 90901 solver.cpp:228] Iteration 69260, loss = 0.170688
I0906 00:24:41.949975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170689 (* 1 = 0.170689 loss)
I0906 00:24:41.949995 90901 sgd_solver.cpp:106] Iteration 69260, lr = 0.01
I0906 00:25:02.174046 90901 solver.cpp:228] Iteration 69270, loss = 0.314282
I0906 00:25:02.174386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314283 (* 1 = 0.314283 loss)
I0906 00:25:02.174408 90901 sgd_solver.cpp:106] Iteration 69270, lr = 0.01
I0906 00:25:19.813675 90901 solver.cpp:228] Iteration 69280, loss = 0.296104
I0906 00:25:19.813771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296105 (* 1 = 0.296105 loss)
I0906 00:25:19.813789 90901 sgd_solver.cpp:106] Iteration 69280, lr = 0.01
I0906 00:25:39.112169 90901 solver.cpp:228] Iteration 69290, loss = 0.169817
I0906 00:25:39.112380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169818 (* 1 = 0.169818 loss)
I0906 00:25:39.112406 90901 sgd_solver.cpp:106] Iteration 69290, lr = 0.01
I0906 00:25:56.719000 90901 solver.cpp:228] Iteration 69300, loss = 0.488687
I0906 00:25:56.719095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.488688 (* 1 = 0.488688 loss)
I0906 00:25:56.719130 90901 sgd_solver.cpp:106] Iteration 69300, lr = 0.01
I0906 00:26:16.012931 90901 solver.cpp:228] Iteration 69310, loss = 0.31043
I0906 00:26:16.013103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310431 (* 1 = 0.310431 loss)
I0906 00:26:16.013146 90901 sgd_solver.cpp:106] Iteration 69310, lr = 0.01
I0906 00:26:34.261780 90901 solver.cpp:228] Iteration 69320, loss = 0.195917
I0906 00:26:34.261860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195918 (* 1 = 0.195918 loss)
I0906 00:26:34.261883 90901 sgd_solver.cpp:106] Iteration 69320, lr = 0.01
I0906 00:26:53.972964 90901 solver.cpp:228] Iteration 69330, loss = 0.054579
I0906 00:26:53.973196 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545805 (* 1 = 0.0545805 loss)
I0906 00:26:53.973218 90901 sgd_solver.cpp:106] Iteration 69330, lr = 0.01
I0906 00:27:11.510941 90901 solver.cpp:228] Iteration 69340, loss = 0.238164
I0906 00:27:11.511015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238165 (* 1 = 0.238165 loss)
I0906 00:27:11.511039 90901 sgd_solver.cpp:106] Iteration 69340, lr = 0.01
I0906 00:27:30.289361 90901 solver.cpp:228] Iteration 69350, loss = 0.0926412
I0906 00:27:30.289696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0926427 (* 1 = 0.0926427 loss)
I0906 00:27:30.289718 90901 sgd_solver.cpp:106] Iteration 69350, lr = 0.01
I0906 00:27:47.123842 90901 solver.cpp:228] Iteration 69360, loss = 0.0309983
I0906 00:27:47.123929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0309998 (* 1 = 0.0309998 loss)
I0906 00:27:47.123950 90901 sgd_solver.cpp:106] Iteration 69360, lr = 0.01
I0906 00:28:07.075199 90901 solver.cpp:228] Iteration 69370, loss = 0.462351
I0906 00:28:07.075402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.462352 (* 1 = 0.462352 loss)
I0906 00:28:07.075430 90901 sgd_solver.cpp:106] Iteration 69370, lr = 0.01
I0906 00:28:24.771708 90901 solver.cpp:228] Iteration 69380, loss = 0.301279
I0906 00:28:24.771800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301281 (* 1 = 0.301281 loss)
I0906 00:28:24.771826 90901 sgd_solver.cpp:106] Iteration 69380, lr = 0.01
I0906 00:28:43.299307 90901 solver.cpp:228] Iteration 69390, loss = 0.0985823
I0906 00:28:43.299465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0985839 (* 1 = 0.0985839 loss)
I0906 00:28:43.299507 90901 sgd_solver.cpp:106] Iteration 69390, lr = 0.01
I0906 00:28:55.318194 90901 solver.cpp:228] Iteration 69400, loss = 0.601909
I0906 00:28:55.318286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.60191 (* 1 = 0.60191 loss)
I0906 00:28:55.318305 90901 sgd_solver.cpp:106] Iteration 69400, lr = 0.01
I0906 00:29:07.636616 90901 solver.cpp:228] Iteration 69410, loss = 0.0326065
I0906 00:29:07.636687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.032608 (* 1 = 0.032608 loss)
I0906 00:29:07.636705 90901 sgd_solver.cpp:106] Iteration 69410, lr = 0.01
I0906 00:29:25.474423 90901 solver.cpp:228] Iteration 69420, loss = 0.296176
I0906 00:29:25.474591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296177 (* 1 = 0.296177 loss)
I0906 00:29:25.474624 90901 sgd_solver.cpp:106] Iteration 69420, lr = 0.01
I0906 00:29:42.198803 90901 solver.cpp:228] Iteration 69430, loss = 0.0321696
I0906 00:29:42.198887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0321711 (* 1 = 0.0321711 loss)
I0906 00:29:42.198907 90901 sgd_solver.cpp:106] Iteration 69430, lr = 0.01
I0906 00:30:00.587529 90901 solver.cpp:228] Iteration 69440, loss = 0.0571757
I0906 00:30:00.587709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0571771 (* 1 = 0.0571771 loss)
I0906 00:30:00.587733 90901 sgd_solver.cpp:106] Iteration 69440, lr = 0.01
I0906 00:30:19.655192 90901 solver.cpp:228] Iteration 69450, loss = 0.0518822
I0906 00:30:19.655272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0518837 (* 1 = 0.0518837 loss)
I0906 00:30:19.655292 90901 sgd_solver.cpp:106] Iteration 69450, lr = 0.01
I0906 00:30:37.157286 90901 solver.cpp:228] Iteration 69460, loss = 0.478272
I0906 00:30:37.157573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.478273 (* 1 = 0.478273 loss)
I0906 00:30:37.157600 90901 sgd_solver.cpp:106] Iteration 69460, lr = 0.01
I0906 00:30:56.340037 90901 solver.cpp:228] Iteration 69470, loss = 0.342318
I0906 00:30:56.340140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342319 (* 1 = 0.342319 loss)
I0906 00:30:56.340159 90901 sgd_solver.cpp:106] Iteration 69470, lr = 0.01
I0906 00:31:14.990689 90901 solver.cpp:228] Iteration 69480, loss = 0.0298454
I0906 00:31:14.990882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0298468 (* 1 = 0.0298468 loss)
I0906 00:31:14.990901 90901 sgd_solver.cpp:106] Iteration 69480, lr = 0.01
I0906 00:31:34.619266 90901 solver.cpp:228] Iteration 69490, loss = 0.0710635
I0906 00:31:34.619354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0710649 (* 1 = 0.0710649 loss)
I0906 00:31:34.619374 90901 sgd_solver.cpp:106] Iteration 69490, lr = 0.01
I0906 00:31:53.488960 90901 solver.cpp:228] Iteration 69500, loss = 0.219377
I0906 00:31:53.489285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219378 (* 1 = 0.219378 loss)
I0906 00:31:53.489305 90901 sgd_solver.cpp:106] Iteration 69500, lr = 0.01
I0906 00:32:14.250272 90901 solver.cpp:228] Iteration 69510, loss = 0.288567
I0906 00:32:14.250355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288568 (* 1 = 0.288568 loss)
I0906 00:32:14.250376 90901 sgd_solver.cpp:106] Iteration 69510, lr = 0.01
I0906 00:32:33.916610 90901 solver.cpp:228] Iteration 69520, loss = 0.565194
I0906 00:32:33.916744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565195 (* 1 = 0.565195 loss)
I0906 00:32:33.916775 90901 sgd_solver.cpp:106] Iteration 69520, lr = 0.01
I0906 00:32:52.597445 90901 solver.cpp:228] Iteration 69530, loss = 0.0401653
I0906 00:32:52.597539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0401666 (* 1 = 0.0401666 loss)
I0906 00:32:52.597558 90901 sgd_solver.cpp:106] Iteration 69530, lr = 0.01
I0906 00:33:11.060958 90901 solver.cpp:228] Iteration 69540, loss = 0.35509
I0906 00:33:11.061260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355092 (* 1 = 0.355092 loss)
I0906 00:33:11.061290 90901 sgd_solver.cpp:106] Iteration 69540, lr = 0.01
I0906 00:33:27.566076 90901 solver.cpp:228] Iteration 69550, loss = 0.119293
I0906 00:33:27.566154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119295 (* 1 = 0.119295 loss)
I0906 00:33:27.566174 90901 sgd_solver.cpp:106] Iteration 69550, lr = 0.01
I0906 00:33:47.350220 90901 solver.cpp:228] Iteration 69560, loss = 0.150359
I0906 00:33:47.350394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15036 (* 1 = 0.15036 loss)
I0906 00:33:47.350435 90901 sgd_solver.cpp:106] Iteration 69560, lr = 0.01
I0906 00:34:05.463013 90901 solver.cpp:228] Iteration 69570, loss = 0.556986
I0906 00:34:05.463081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556987 (* 1 = 0.556987 loss)
I0906 00:34:05.463099 90901 sgd_solver.cpp:106] Iteration 69570, lr = 0.01
I0906 00:34:23.127223 90901 solver.cpp:228] Iteration 69580, loss = 0.107786
I0906 00:34:23.127398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107788 (* 1 = 0.107788 loss)
I0906 00:34:23.127434 90901 sgd_solver.cpp:106] Iteration 69580, lr = 0.01
I0906 00:34:43.388584 90901 solver.cpp:228] Iteration 69590, loss = 0.141064
I0906 00:34:43.388672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141066 (* 1 = 0.141066 loss)
I0906 00:34:43.388692 90901 sgd_solver.cpp:106] Iteration 69590, lr = 0.01
I0906 00:35:00.207032 90901 solver.cpp:337] Iteration 69600, Testing net (#0)
I0906 00:36:57.998541 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.921562
I0906 00:36:57.998733 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.199489 (* 1 = 0.199489 loss)
I0906 00:36:58.237135 90901 solver.cpp:228] Iteration 69600, loss = 0.645524
I0906 00:36:58.237213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.645525 (* 1 = 0.645525 loss)
I0906 00:36:58.237238 90901 sgd_solver.cpp:106] Iteration 69600, lr = 0.01
I0906 00:37:08.777588 90901 solver.cpp:228] Iteration 69610, loss = 0.145749
I0906 00:37:08.777662 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145751 (* 1 = 0.145751 loss)
I0906 00:37:08.777679 90901 sgd_solver.cpp:106] Iteration 69610, lr = 0.01
I0906 00:37:22.289839 90901 solver.cpp:228] Iteration 69620, loss = 0.0909152
I0906 00:37:22.289917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0909165 (* 1 = 0.0909165 loss)
I0906 00:37:22.289935 90901 sgd_solver.cpp:106] Iteration 69620, lr = 0.01
I0906 00:37:33.513758 90901 solver.cpp:228] Iteration 69630, loss = 0.335202
I0906 00:37:33.514036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335203 (* 1 = 0.335203 loss)
I0906 00:37:33.514057 90901 sgd_solver.cpp:106] Iteration 69630, lr = 0.01
I0906 00:37:46.145395 90901 solver.cpp:228] Iteration 69640, loss = 0.12972
I0906 00:37:46.145474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129722 (* 1 = 0.129722 loss)
I0906 00:37:46.145493 90901 sgd_solver.cpp:106] Iteration 69640, lr = 0.01
I0906 00:37:55.027932 90901 solver.cpp:228] Iteration 69650, loss = 0.248396
I0906 00:37:55.028014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248397 (* 1 = 0.248397 loss)
I0906 00:37:55.028033 90901 sgd_solver.cpp:106] Iteration 69650, lr = 0.01
I0906 00:38:06.626799 90901 solver.cpp:228] Iteration 69660, loss = 0.135015
I0906 00:38:06.627020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135016 (* 1 = 0.135016 loss)
I0906 00:38:06.627038 90901 sgd_solver.cpp:106] Iteration 69660, lr = 0.01
I0906 00:38:18.824086 90901 solver.cpp:228] Iteration 69670, loss = 0.148483
I0906 00:38:18.824182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148484 (* 1 = 0.148484 loss)
I0906 00:38:18.824203 90901 sgd_solver.cpp:106] Iteration 69670, lr = 0.01
I0906 00:38:29.785883 90901 solver.cpp:228] Iteration 69680, loss = 0.381288
I0906 00:38:29.785961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381289 (* 1 = 0.381289 loss)
I0906 00:38:29.785980 90901 sgd_solver.cpp:106] Iteration 69680, lr = 0.01
I0906 00:38:37.649806 90901 solver.cpp:228] Iteration 69690, loss = 0.0952216
I0906 00:38:37.650040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0952229 (* 1 = 0.0952229 loss)
I0906 00:38:37.650064 90901 sgd_solver.cpp:106] Iteration 69690, lr = 0.01
I0906 00:38:45.937651 90901 solver.cpp:228] Iteration 69700, loss = 0.0753747
I0906 00:38:45.937728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0753759 (* 1 = 0.0753759 loss)
I0906 00:38:45.937748 90901 sgd_solver.cpp:106] Iteration 69700, lr = 0.01
I0906 00:38:54.427753 90901 solver.cpp:228] Iteration 69710, loss = 0.170347
I0906 00:38:54.427850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170348 (* 1 = 0.170348 loss)
I0906 00:38:54.427866 90901 sgd_solver.cpp:106] Iteration 69710, lr = 0.01
I0906 00:39:02.601814 90901 solver.cpp:228] Iteration 69720, loss = 0.0451222
I0906 00:39:02.601904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0451234 (* 1 = 0.0451234 loss)
I0906 00:39:02.601923 90901 sgd_solver.cpp:106] Iteration 69720, lr = 0.01
I0906 00:39:12.487975 90901 solver.cpp:228] Iteration 69730, loss = 0.146196
I0906 00:39:12.488185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146198 (* 1 = 0.146198 loss)
I0906 00:39:12.488215 90901 sgd_solver.cpp:106] Iteration 69730, lr = 0.01
I0906 00:39:23.043347 90901 solver.cpp:228] Iteration 69740, loss = 0.294249
I0906 00:39:23.043426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29425 (* 1 = 0.29425 loss)
I0906 00:39:23.043448 90901 sgd_solver.cpp:106] Iteration 69740, lr = 0.01
I0906 00:39:36.829815 90901 solver.cpp:228] Iteration 69750, loss = 0.0765556
I0906 00:39:36.829927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0765569 (* 1 = 0.0765569 loss)
I0906 00:39:36.829952 90901 sgd_solver.cpp:106] Iteration 69750, lr = 0.01
I0906 00:39:55.061067 90901 solver.cpp:228] Iteration 69760, loss = 0.0826235
I0906 00:39:55.061424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0826247 (* 1 = 0.0826247 loss)
I0906 00:39:55.061453 90901 sgd_solver.cpp:106] Iteration 69760, lr = 0.01
I0906 00:40:13.356767 90901 solver.cpp:228] Iteration 69770, loss = 0.0426548
I0906 00:40:13.356863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.042656 (* 1 = 0.042656 loss)
I0906 00:40:13.356894 90901 sgd_solver.cpp:106] Iteration 69770, lr = 0.01
I0906 00:40:31.615784 90901 solver.cpp:228] Iteration 69780, loss = 0.202571
I0906 00:40:31.616199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202572 (* 1 = 0.202572 loss)
I0906 00:40:31.616225 90901 sgd_solver.cpp:106] Iteration 69780, lr = 0.01
I0906 00:40:47.418973 90901 solver.cpp:228] Iteration 69790, loss = 0.140011
I0906 00:40:47.419059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140012 (* 1 = 0.140012 loss)
I0906 00:40:47.419075 90901 sgd_solver.cpp:106] Iteration 69790, lr = 0.01
I0906 00:41:04.704676 90901 solver.cpp:228] Iteration 69800, loss = 0.0630533
I0906 00:41:04.704849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0630545 (* 1 = 0.0630545 loss)
I0906 00:41:04.704874 90901 sgd_solver.cpp:106] Iteration 69800, lr = 0.01
I0906 00:41:21.650806 90901 solver.cpp:228] Iteration 69810, loss = 0.267316
I0906 00:41:21.650888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267318 (* 1 = 0.267318 loss)
I0906 00:41:21.650907 90901 sgd_solver.cpp:106] Iteration 69810, lr = 0.01
I0906 00:41:35.029000 90901 solver.cpp:228] Iteration 69820, loss = 0.32934
I0906 00:41:35.029206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329341 (* 1 = 0.329341 loss)
I0906 00:41:35.029234 90901 sgd_solver.cpp:106] Iteration 69820, lr = 0.01
I0906 00:41:49.983054 90901 solver.cpp:228] Iteration 69830, loss = 0.351453
I0906 00:41:49.983125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351454 (* 1 = 0.351454 loss)
I0906 00:41:49.983141 90901 sgd_solver.cpp:106] Iteration 69830, lr = 0.01
I0906 00:42:01.603010 90901 solver.cpp:228] Iteration 69840, loss = 0.22456
I0906 00:42:01.603092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224561 (* 1 = 0.224561 loss)
I0906 00:42:01.603113 90901 sgd_solver.cpp:106] Iteration 69840, lr = 0.01
I0906 00:42:12.029336 90901 solver.cpp:228] Iteration 69850, loss = 0.0818771
I0906 00:42:12.029533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0818783 (* 1 = 0.0818783 loss)
I0906 00:42:12.029553 90901 sgd_solver.cpp:106] Iteration 69850, lr = 0.01
I0906 00:42:25.877557 90901 solver.cpp:228] Iteration 69860, loss = 0.282822
I0906 00:42:25.877642 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282824 (* 1 = 0.282824 loss)
I0906 00:42:25.877660 90901 sgd_solver.cpp:106] Iteration 69860, lr = 0.01
I0906 00:42:40.230425 90901 solver.cpp:228] Iteration 69870, loss = 0.0880905
I0906 00:42:40.230511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0880918 (* 1 = 0.0880918 loss)
I0906 00:42:40.230532 90901 sgd_solver.cpp:106] Iteration 69870, lr = 0.01
I0906 00:42:56.592689 90901 solver.cpp:228] Iteration 69880, loss = 0.0982775
I0906 00:42:56.592922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0982788 (* 1 = 0.0982788 loss)
I0906 00:42:56.592945 90901 sgd_solver.cpp:106] Iteration 69880, lr = 0.01
I0906 00:43:13.348589 90901 solver.cpp:228] Iteration 69890, loss = 0.151138
I0906 00:43:13.348676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151139 (* 1 = 0.151139 loss)
I0906 00:43:13.348696 90901 sgd_solver.cpp:106] Iteration 69890, lr = 0.01
I0906 00:43:31.384588 90901 solver.cpp:228] Iteration 69900, loss = 0.17934
I0906 00:43:31.384755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179341 (* 1 = 0.179341 loss)
I0906 00:43:31.384788 90901 sgd_solver.cpp:106] Iteration 69900, lr = 0.01
I0906 00:43:49.324257 90901 solver.cpp:228] Iteration 69910, loss = 0.286437
I0906 00:43:49.324348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286438 (* 1 = 0.286438 loss)
I0906 00:43:49.324371 90901 sgd_solver.cpp:106] Iteration 69910, lr = 0.01
I0906 00:44:07.529722 90901 solver.cpp:228] Iteration 69920, loss = 0.216689
I0906 00:44:07.529937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21669 (* 1 = 0.21669 loss)
I0906 00:44:07.529968 90901 sgd_solver.cpp:106] Iteration 69920, lr = 0.01
I0906 00:44:24.784345 90901 solver.cpp:228] Iteration 69930, loss = 0.141345
I0906 00:44:24.784425 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141346 (* 1 = 0.141346 loss)
I0906 00:44:24.784443 90901 sgd_solver.cpp:106] Iteration 69930, lr = 0.01
I0906 00:44:42.887243 90901 solver.cpp:228] Iteration 69940, loss = 0.452522
I0906 00:44:42.887483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.452524 (* 1 = 0.452524 loss)
I0906 00:44:42.887506 90901 sgd_solver.cpp:106] Iteration 69940, lr = 0.01
I0906 00:45:01.849639 90901 solver.cpp:228] Iteration 69950, loss = 0.136652
I0906 00:45:01.849750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136654 (* 1 = 0.136654 loss)
I0906 00:45:01.849772 90901 sgd_solver.cpp:106] Iteration 69950, lr = 0.01
I0906 00:45:18.923573 90901 solver.cpp:228] Iteration 69960, loss = 0.277335
I0906 00:45:18.923769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277336 (* 1 = 0.277336 loss)
I0906 00:45:18.923792 90901 sgd_solver.cpp:106] Iteration 69960, lr = 0.01
I0906 00:45:37.263643 90901 solver.cpp:228] Iteration 69970, loss = 0.309229
I0906 00:45:37.263728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30923 (* 1 = 0.30923 loss)
I0906 00:45:37.263749 90901 sgd_solver.cpp:106] Iteration 69970, lr = 0.01
I0906 00:45:53.758193 90901 solver.cpp:228] Iteration 69980, loss = 0.231121
I0906 00:45:53.758339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231122 (* 1 = 0.231122 loss)
I0906 00:45:53.758365 90901 sgd_solver.cpp:106] Iteration 69980, lr = 0.01
I0906 00:46:10.021347 90901 solver.cpp:228] Iteration 69990, loss = 0.206781
I0906 00:46:10.021421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206783 (* 1 = 0.206783 loss)
I0906 00:46:10.021440 90901 sgd_solver.cpp:106] Iteration 69990, lr = 0.01
I0906 00:46:27.908051 90901 solver.cpp:228] Iteration 70000, loss = 0.128373
I0906 00:46:27.908224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128374 (* 1 = 0.128374 loss)
I0906 00:46:27.908255 90901 sgd_solver.cpp:106] Iteration 70000, lr = 0.01
I0906 00:46:45.239500 90901 solver.cpp:228] Iteration 70010, loss = 0.250789
I0906 00:46:45.239575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250791 (* 1 = 0.250791 loss)
I0906 00:46:45.239593 90901 sgd_solver.cpp:106] Iteration 70010, lr = 0.01
I0906 00:47:03.178154 90901 solver.cpp:228] Iteration 70020, loss = 0.0559504
I0906 00:47:03.178346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0559517 (* 1 = 0.0559517 loss)
I0906 00:47:03.178365 90901 sgd_solver.cpp:106] Iteration 70020, lr = 0.01
I0906 00:47:18.218320 90901 solver.cpp:228] Iteration 70030, loss = 0.247392
I0906 00:47:18.218394 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247393 (* 1 = 0.247393 loss)
I0906 00:47:18.218411 90901 sgd_solver.cpp:106] Iteration 70030, lr = 0.01
I0906 00:47:35.531075 90901 solver.cpp:228] Iteration 70040, loss = 0.370403
I0906 00:47:35.531255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370404 (* 1 = 0.370404 loss)
I0906 00:47:35.531280 90901 sgd_solver.cpp:106] Iteration 70040, lr = 0.01
I0906 00:47:48.733891 90901 solver.cpp:228] Iteration 70050, loss = 0.162608
I0906 00:47:48.733966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162609 (* 1 = 0.162609 loss)
I0906 00:47:48.733983 90901 sgd_solver.cpp:106] Iteration 70050, lr = 0.01
I0906 00:48:01.819664 90901 solver.cpp:228] Iteration 70060, loss = 0.250427
I0906 00:48:01.819737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250428 (* 1 = 0.250428 loss)
I0906 00:48:01.819756 90901 sgd_solver.cpp:106] Iteration 70060, lr = 0.01
I0906 00:48:15.142513 90901 solver.cpp:228] Iteration 70070, loss = 0.574289
I0906 00:48:15.143934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.57429 (* 1 = 0.57429 loss)
I0906 00:48:15.143952 90901 sgd_solver.cpp:106] Iteration 70070, lr = 0.01
I0906 00:48:26.211369 90901 solver.cpp:228] Iteration 70080, loss = 0.158191
I0906 00:48:26.211441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158192 (* 1 = 0.158192 loss)
I0906 00:48:26.211459 90901 sgd_solver.cpp:106] Iteration 70080, lr = 0.01
I0906 00:48:33.229969 90901 solver.cpp:228] Iteration 70090, loss = 0.111697
I0906 00:48:33.230079 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111698 (* 1 = 0.111698 loss)
I0906 00:48:33.230108 90901 sgd_solver.cpp:106] Iteration 70090, lr = 0.01
I0906 00:48:41.565872 90901 solver.cpp:228] Iteration 70100, loss = 0.646043
I0906 00:48:41.565946 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.646044 (* 1 = 0.646044 loss)
I0906 00:48:41.565964 90901 sgd_solver.cpp:106] Iteration 70100, lr = 0.01
I0906 00:48:51.763075 90901 solver.cpp:228] Iteration 70110, loss = 0.685116
I0906 00:48:51.763312 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.685118 (* 1 = 0.685118 loss)
I0906 00:48:51.763344 90901 sgd_solver.cpp:106] Iteration 70110, lr = 0.01
I0906 00:49:02.413424 90901 solver.cpp:228] Iteration 70120, loss = 0.370847
I0906 00:49:02.413498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370849 (* 1 = 0.370849 loss)
I0906 00:49:02.413516 90901 sgd_solver.cpp:106] Iteration 70120, lr = 0.01
I0906 00:49:18.845659 90901 solver.cpp:228] Iteration 70130, loss = 0.207406
I0906 00:49:18.845731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207408 (* 1 = 0.207408 loss)
I0906 00:49:18.845749 90901 sgd_solver.cpp:106] Iteration 70130, lr = 0.01
I0906 00:49:35.980376 90901 solver.cpp:228] Iteration 70140, loss = 0.18222
I0906 00:49:35.980535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182221 (* 1 = 0.182221 loss)
I0906 00:49:35.980552 90901 sgd_solver.cpp:106] Iteration 70140, lr = 0.01
I0906 00:49:55.124161 90901 solver.cpp:228] Iteration 70150, loss = 0.0868576
I0906 00:49:55.124250 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0868589 (* 1 = 0.0868589 loss)
I0906 00:49:55.124275 90901 sgd_solver.cpp:106] Iteration 70150, lr = 0.01
I0906 00:50:13.760018 90901 solver.cpp:228] Iteration 70160, loss = 0.122929
I0906 00:50:13.760382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12293 (* 1 = 0.12293 loss)
I0906 00:50:13.760408 90901 sgd_solver.cpp:106] Iteration 70160, lr = 0.01
I0906 00:50:32.096287 90901 solver.cpp:228] Iteration 70170, loss = 0.504035
I0906 00:50:32.096351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504036 (* 1 = 0.504036 loss)
I0906 00:50:32.096372 90901 sgd_solver.cpp:106] Iteration 70170, lr = 0.01
I0906 00:50:51.116945 90901 solver.cpp:228] Iteration 70180, loss = 0.127706
I0906 00:50:51.117271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127707 (* 1 = 0.127707 loss)
I0906 00:50:51.117298 90901 sgd_solver.cpp:106] Iteration 70180, lr = 0.01
I0906 00:51:09.550359 90901 solver.cpp:228] Iteration 70190, loss = 0.401234
I0906 00:51:09.550444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.401235 (* 1 = 0.401235 loss)
I0906 00:51:09.550464 90901 sgd_solver.cpp:106] Iteration 70190, lr = 0.01
I0906 00:51:26.912061 90901 solver.cpp:228] Iteration 70200, loss = 0.13672
I0906 00:51:26.912230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136721 (* 1 = 0.136721 loss)
I0906 00:51:26.912257 90901 sgd_solver.cpp:106] Iteration 70200, lr = 0.01
I0906 00:51:46.351549 90901 solver.cpp:228] Iteration 70210, loss = 0.34992
I0906 00:51:46.351624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349921 (* 1 = 0.349921 loss)
I0906 00:51:46.351641 90901 sgd_solver.cpp:106] Iteration 70210, lr = 0.01
I0906 00:52:04.121853 90901 solver.cpp:228] Iteration 70220, loss = 0.320224
I0906 00:52:04.122057 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320225 (* 1 = 0.320225 loss)
I0906 00:52:04.122102 90901 sgd_solver.cpp:106] Iteration 70220, lr = 0.01
I0906 00:52:24.038161 90901 solver.cpp:228] Iteration 70230, loss = 0.117075
I0906 00:52:24.038308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117076 (* 1 = 0.117076 loss)
I0906 00:52:24.038331 90901 sgd_solver.cpp:106] Iteration 70230, lr = 0.01
I0906 00:52:42.064834 90901 solver.cpp:228] Iteration 70240, loss = 0.205155
I0906 00:52:42.065105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205156 (* 1 = 0.205156 loss)
I0906 00:52:42.065127 90901 sgd_solver.cpp:106] Iteration 70240, lr = 0.01
I0906 00:53:00.651152 90901 solver.cpp:228] Iteration 70250, loss = 0.0296578
I0906 00:53:00.651257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0296591 (* 1 = 0.0296591 loss)
I0906 00:53:00.651276 90901 sgd_solver.cpp:106] Iteration 70250, lr = 0.01
I0906 00:53:19.844254 90901 solver.cpp:228] Iteration 70260, loss = 0.507927
I0906 00:53:19.844431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.507928 (* 1 = 0.507928 loss)
I0906 00:53:19.844460 90901 sgd_solver.cpp:106] Iteration 70260, lr = 0.01
I0906 00:53:38.881475 90901 solver.cpp:228] Iteration 70270, loss = 0.227144
I0906 00:53:38.881568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227146 (* 1 = 0.227146 loss)
I0906 00:53:38.881585 90901 sgd_solver.cpp:106] Iteration 70270, lr = 0.01
I0906 00:53:59.353813 90901 solver.cpp:228] Iteration 70280, loss = 0.0706926
I0906 00:53:59.353971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.070694 (* 1 = 0.070694 loss)
I0906 00:53:59.354001 90901 sgd_solver.cpp:106] Iteration 70280, lr = 0.01
I0906 00:54:17.677278 90901 solver.cpp:228] Iteration 70290, loss = 0.165468
I0906 00:54:17.677386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16547 (* 1 = 0.16547 loss)
I0906 00:54:17.677405 90901 sgd_solver.cpp:106] Iteration 70290, lr = 0.01
I0906 00:54:36.360569 90901 solver.cpp:228] Iteration 70300, loss = 0.154003
I0906 00:54:36.360968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154004 (* 1 = 0.154004 loss)
I0906 00:54:36.361069 90901 sgd_solver.cpp:106] Iteration 70300, lr = 0.01
I0906 00:54:54.872900 90901 solver.cpp:228] Iteration 70310, loss = 0.0755274
I0906 00:54:54.872973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0755288 (* 1 = 0.0755288 loss)
I0906 00:54:54.872989 90901 sgd_solver.cpp:106] Iteration 70310, lr = 0.01
I0906 00:55:15.068045 90901 solver.cpp:228] Iteration 70320, loss = 0.0252455
I0906 00:55:15.068220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0252469 (* 1 = 0.0252469 loss)
I0906 00:55:15.068245 90901 sgd_solver.cpp:106] Iteration 70320, lr = 0.01
I0906 00:55:33.176581 90901 solver.cpp:228] Iteration 70330, loss = 0.202874
I0906 00:55:33.176654 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202876 (* 1 = 0.202876 loss)
I0906 00:55:33.176672 90901 sgd_solver.cpp:106] Iteration 70330, lr = 0.01
I0906 00:55:50.509135 90901 solver.cpp:228] Iteration 70340, loss = 0.0558487
I0906 00:55:50.509352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.05585 (* 1 = 0.05585 loss)
I0906 00:55:50.509368 90901 sgd_solver.cpp:106] Iteration 70340, lr = 0.01
I0906 00:56:03.758165 90901 solver.cpp:228] Iteration 70350, loss = 0.105848
I0906 00:56:03.758239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105849 (* 1 = 0.105849 loss)
I0906 00:56:03.758256 90901 sgd_solver.cpp:106] Iteration 70350, lr = 0.01
I0906 00:56:16.599902 90901 solver.cpp:228] Iteration 70360, loss = 0.0927697
I0906 00:56:16.600018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0927711 (* 1 = 0.0927711 loss)
I0906 00:56:16.600044 90901 sgd_solver.cpp:106] Iteration 70360, lr = 0.01
I0906 00:56:36.308377 90901 solver.cpp:228] Iteration 70370, loss = 0.0820156
I0906 00:56:36.310346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.082017 (* 1 = 0.082017 loss)
I0906 00:56:36.310364 90901 sgd_solver.cpp:106] Iteration 70370, lr = 0.01
I0906 00:56:54.282336 90901 solver.cpp:228] Iteration 70380, loss = 0.120765
I0906 00:56:54.282418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120766 (* 1 = 0.120766 loss)
I0906 00:56:54.282439 90901 sgd_solver.cpp:106] Iteration 70380, lr = 0.01
I0906 00:57:12.770443 90901 solver.cpp:228] Iteration 70390, loss = 0.602659
I0906 00:57:12.770730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.60266 (* 1 = 0.60266 loss)
I0906 00:57:12.770756 90901 sgd_solver.cpp:106] Iteration 70390, lr = 0.01
I0906 00:57:31.074013 90901 solver.cpp:337] Iteration 70400, Testing net (#0)
I0906 00:59:00.841939 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.904375
I0906 00:59:00.842103 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.241109 (* 1 = 0.241109 loss)
I0906 00:59:01.069463 90901 solver.cpp:228] Iteration 70400, loss = 0.185186
I0906 00:59:01.069557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185188 (* 1 = 0.185188 loss)
I0906 00:59:01.069581 90901 sgd_solver.cpp:106] Iteration 70400, lr = 0.01
I0906 00:59:11.271858 90901 solver.cpp:228] Iteration 70410, loss = 0.0886082
I0906 00:59:11.271982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0886095 (* 1 = 0.0886095 loss)
I0906 00:59:11.272001 90901 sgd_solver.cpp:106] Iteration 70410, lr = 0.01
I0906 00:59:20.226434 90901 solver.cpp:228] Iteration 70420, loss = 0.211627
I0906 00:59:20.226541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211628 (* 1 = 0.211628 loss)
I0906 00:59:20.226560 90901 sgd_solver.cpp:106] Iteration 70420, lr = 0.01
I0906 00:59:28.919098 90901 solver.cpp:228] Iteration 70430, loss = 0.112175
I0906 00:59:28.919167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112176 (* 1 = 0.112176 loss)
I0906 00:59:28.919185 90901 sgd_solver.cpp:106] Iteration 70430, lr = 0.01
I0906 00:59:39.855108 90901 solver.cpp:228] Iteration 70440, loss = 0.254875
I0906 00:59:39.855341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254876 (* 1 = 0.254876 loss)
I0906 00:59:39.855360 90901 sgd_solver.cpp:106] Iteration 70440, lr = 0.01
I0906 00:59:52.022483 90901 solver.cpp:228] Iteration 70450, loss = 0.199194
I0906 00:59:52.022585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199196 (* 1 = 0.199196 loss)
I0906 00:59:52.022608 90901 sgd_solver.cpp:106] Iteration 70450, lr = 0.01
I0906 01:00:07.053114 90901 solver.cpp:228] Iteration 70460, loss = 0.16743
I0906 01:00:07.053210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167431 (* 1 = 0.167431 loss)
I0906 01:00:07.053227 90901 sgd_solver.cpp:106] Iteration 70460, lr = 0.01
I0906 01:00:25.915825 90901 solver.cpp:228] Iteration 70470, loss = 0.469778
I0906 01:00:25.915974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46978 (* 1 = 0.46978 loss)
I0906 01:00:25.916007 90901 sgd_solver.cpp:106] Iteration 70470, lr = 0.01
I0906 01:00:44.500094 90901 solver.cpp:228] Iteration 70480, loss = 0.112088
I0906 01:00:44.500176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112089 (* 1 = 0.112089 loss)
I0906 01:00:44.500195 90901 sgd_solver.cpp:106] Iteration 70480, lr = 0.01
I0906 01:01:05.112558 90901 solver.cpp:228] Iteration 70490, loss = 0.167109
I0906 01:01:05.112771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16711 (* 1 = 0.16711 loss)
I0906 01:01:05.112803 90901 sgd_solver.cpp:106] Iteration 70490, lr = 0.01
I0906 01:01:25.356312 90901 solver.cpp:228] Iteration 70500, loss = 0.343957
I0906 01:01:25.356387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343958 (* 1 = 0.343958 loss)
I0906 01:01:25.356400 90901 sgd_solver.cpp:106] Iteration 70500, lr = 0.01
I0906 01:01:45.605885 90901 solver.cpp:228] Iteration 70510, loss = 0.568875
I0906 01:01:45.606097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.568877 (* 1 = 0.568877 loss)
I0906 01:01:45.606120 90901 sgd_solver.cpp:106] Iteration 70510, lr = 0.01
I0906 01:02:04.930106 90901 solver.cpp:228] Iteration 70520, loss = 0.0518689
I0906 01:02:04.930181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0518703 (* 1 = 0.0518703 loss)
I0906 01:02:04.930207 90901 sgd_solver.cpp:106] Iteration 70520, lr = 0.01
I0906 01:02:25.653805 90901 solver.cpp:228] Iteration 70530, loss = 0.116898
I0906 01:02:25.654106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1169 (* 1 = 0.1169 loss)
I0906 01:02:25.654127 90901 sgd_solver.cpp:106] Iteration 70530, lr = 0.01
I0906 01:02:45.511431 90901 solver.cpp:228] Iteration 70540, loss = 0.223178
I0906 01:02:45.511509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223179 (* 1 = 0.223179 loss)
I0906 01:02:45.511533 90901 sgd_solver.cpp:106] Iteration 70540, lr = 0.01
I0906 01:03:04.826987 90901 solver.cpp:228] Iteration 70550, loss = 0.10132
I0906 01:03:04.827157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101321 (* 1 = 0.101321 loss)
I0906 01:03:04.827185 90901 sgd_solver.cpp:106] Iteration 70550, lr = 0.01
I0906 01:03:25.295970 90901 solver.cpp:228] Iteration 70560, loss = 0.155462
I0906 01:03:25.296061 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155463 (* 1 = 0.155463 loss)
I0906 01:03:25.296085 90901 sgd_solver.cpp:106] Iteration 70560, lr = 0.01
I0906 01:03:45.938031 90901 solver.cpp:228] Iteration 70570, loss = 0.137429
I0906 01:03:45.938267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137431 (* 1 = 0.137431 loss)
I0906 01:03:45.938287 90901 sgd_solver.cpp:106] Iteration 70570, lr = 0.01
I0906 01:04:05.531332 90901 solver.cpp:228] Iteration 70580, loss = 0.163042
I0906 01:04:05.531450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163044 (* 1 = 0.163044 loss)
I0906 01:04:05.531471 90901 sgd_solver.cpp:106] Iteration 70580, lr = 0.01
I0906 01:04:25.412333 90901 solver.cpp:228] Iteration 70590, loss = 0.344902
I0906 01:04:25.412525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344903 (* 1 = 0.344903 loss)
I0906 01:04:25.412546 90901 sgd_solver.cpp:106] Iteration 70590, lr = 0.01
I0906 01:04:45.399611 90901 solver.cpp:228] Iteration 70600, loss = 0.256866
I0906 01:04:45.399665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256868 (* 1 = 0.256868 loss)
I0906 01:04:45.399687 90901 sgd_solver.cpp:106] Iteration 70600, lr = 0.01
I0906 01:05:05.727160 90901 solver.cpp:228] Iteration 70610, loss = 0.113295
I0906 01:05:05.727360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113296 (* 1 = 0.113296 loss)
I0906 01:05:05.727378 90901 sgd_solver.cpp:106] Iteration 70610, lr = 0.01
I0906 01:05:24.056697 90901 solver.cpp:228] Iteration 70620, loss = 0.288465
I0906 01:05:24.056802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288466 (* 1 = 0.288466 loss)
I0906 01:05:24.056831 90901 sgd_solver.cpp:106] Iteration 70620, lr = 0.01
I0906 01:05:43.118603 90901 solver.cpp:228] Iteration 70630, loss = 0.177358
I0906 01:05:43.118772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177359 (* 1 = 0.177359 loss)
I0906 01:05:43.118814 90901 sgd_solver.cpp:106] Iteration 70630, lr = 0.01
I0906 01:06:02.287634 90901 solver.cpp:228] Iteration 70640, loss = 0.35751
I0906 01:06:02.287709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357512 (* 1 = 0.357512 loss)
I0906 01:06:02.287727 90901 sgd_solver.cpp:106] Iteration 70640, lr = 0.01
I0906 01:06:22.289866 90901 solver.cpp:228] Iteration 70650, loss = 0.208
I0906 01:06:22.290097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208001 (* 1 = 0.208001 loss)
I0906 01:06:22.290129 90901 sgd_solver.cpp:106] Iteration 70650, lr = 0.01
I0906 01:06:39.834821 90901 solver.cpp:228] Iteration 70660, loss = 0.476421
I0906 01:06:39.834888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476423 (* 1 = 0.476423 loss)
I0906 01:06:39.834906 90901 sgd_solver.cpp:106] Iteration 70660, lr = 0.01
I0906 01:06:59.133286 90901 solver.cpp:228] Iteration 70670, loss = 0.201856
I0906 01:06:59.133519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201857 (* 1 = 0.201857 loss)
I0906 01:06:59.133540 90901 sgd_solver.cpp:106] Iteration 70670, lr = 0.01
I0906 01:07:13.433950 90901 solver.cpp:228] Iteration 70680, loss = 0.578182
I0906 01:07:13.434075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.578184 (* 1 = 0.578184 loss)
I0906 01:07:13.434101 90901 sgd_solver.cpp:106] Iteration 70680, lr = 0.01
I0906 01:07:29.161666 90901 solver.cpp:228] Iteration 70690, loss = 0.0417296
I0906 01:07:29.161896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.041731 (* 1 = 0.041731 loss)
I0906 01:07:29.161914 90901 sgd_solver.cpp:106] Iteration 70690, lr = 0.01
I0906 01:07:43.134937 90901 solver.cpp:228] Iteration 70700, loss = 0.223735
I0906 01:07:43.135017 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223736 (* 1 = 0.223736 loss)
I0906 01:07:43.135038 90901 sgd_solver.cpp:106] Iteration 70700, lr = 0.01
I0906 01:07:55.642040 90901 solver.cpp:228] Iteration 70710, loss = 0.145947
I0906 01:07:55.642119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145949 (* 1 = 0.145949 loss)
I0906 01:07:55.642138 90901 sgd_solver.cpp:106] Iteration 70710, lr = 0.01
I0906 01:08:09.850513 90901 solver.cpp:228] Iteration 70720, loss = 0.0927253
I0906 01:08:09.850778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0927267 (* 1 = 0.0927267 loss)
I0906 01:08:09.850798 90901 sgd_solver.cpp:106] Iteration 70720, lr = 0.01
I0906 01:08:27.872530 90901 solver.cpp:228] Iteration 70730, loss = 0.376794
I0906 01:08:27.872627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.376795 (* 1 = 0.376795 loss)
I0906 01:08:27.872644 90901 sgd_solver.cpp:106] Iteration 70730, lr = 0.01
I0906 01:08:48.443982 90901 solver.cpp:228] Iteration 70740, loss = 0.249103
I0906 01:08:48.444185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249104 (* 1 = 0.249104 loss)
I0906 01:08:48.444205 90901 sgd_solver.cpp:106] Iteration 70740, lr = 0.01
I0906 01:09:08.549927 90901 solver.cpp:228] Iteration 70750, loss = 0.0522036
I0906 01:09:08.550014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.052205 (* 1 = 0.052205 loss)
I0906 01:09:08.550031 90901 sgd_solver.cpp:106] Iteration 70750, lr = 0.01
I0906 01:09:27.547094 90901 solver.cpp:228] Iteration 70760, loss = 0.181597
I0906 01:09:27.558975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181599 (* 1 = 0.181599 loss)
I0906 01:09:27.559039 90901 sgd_solver.cpp:106] Iteration 70760, lr = 0.01
I0906 01:09:45.868631 90901 solver.cpp:228] Iteration 70770, loss = 0.0917551
I0906 01:09:45.868726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0917566 (* 1 = 0.0917566 loss)
I0906 01:09:45.868744 90901 sgd_solver.cpp:106] Iteration 70770, lr = 0.01
I0906 01:10:06.136813 90901 solver.cpp:228] Iteration 70780, loss = 0.158148
I0906 01:10:06.137030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158149 (* 1 = 0.158149 loss)
I0906 01:10:06.137073 90901 sgd_solver.cpp:106] Iteration 70780, lr = 0.01
I0906 01:10:25.127277 90901 solver.cpp:228] Iteration 70790, loss = 0.0685559
I0906 01:10:25.127359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0685574 (* 1 = 0.0685574 loss)
I0906 01:10:25.127377 90901 sgd_solver.cpp:106] Iteration 70790, lr = 0.01
I0906 01:10:43.154444 90901 solver.cpp:228] Iteration 70800, loss = 0.207421
I0906 01:10:43.154669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207423 (* 1 = 0.207423 loss)
I0906 01:10:43.154707 90901 sgd_solver.cpp:106] Iteration 70800, lr = 0.01
I0906 01:11:01.403378 90901 solver.cpp:228] Iteration 70810, loss = 0.138675
I0906 01:11:01.403470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138676 (* 1 = 0.138676 loss)
I0906 01:11:01.403489 90901 sgd_solver.cpp:106] Iteration 70810, lr = 0.01
I0906 01:11:22.387799 90901 solver.cpp:228] Iteration 70820, loss = 0.310324
I0906 01:11:22.387975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310325 (* 1 = 0.310325 loss)
I0906 01:11:22.388010 90901 sgd_solver.cpp:106] Iteration 70820, lr = 0.01
I0906 01:11:41.666599 90901 solver.cpp:228] Iteration 70830, loss = 0.455674
I0906 01:11:41.666705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.455676 (* 1 = 0.455676 loss)
I0906 01:11:41.666729 90901 sgd_solver.cpp:106] Iteration 70830, lr = 0.01
I0906 01:12:02.309600 90901 solver.cpp:228] Iteration 70840, loss = 0.748585
I0906 01:12:02.309866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.748586 (* 1 = 0.748586 loss)
I0906 01:12:02.309893 90901 sgd_solver.cpp:106] Iteration 70840, lr = 0.01
I0906 01:12:21.122545 90901 solver.cpp:228] Iteration 70850, loss = 0.149452
I0906 01:12:21.122622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149454 (* 1 = 0.149454 loss)
I0906 01:12:21.122654 90901 sgd_solver.cpp:106] Iteration 70850, lr = 0.01
I0906 01:12:40.525029 90901 solver.cpp:228] Iteration 70860, loss = 0.12084
I0906 01:12:40.525192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120841 (* 1 = 0.120841 loss)
I0906 01:12:40.525225 90901 sgd_solver.cpp:106] Iteration 70860, lr = 0.01
I0906 01:12:54.754277 90901 solver.cpp:228] Iteration 70870, loss = 0.219141
I0906 01:12:54.754353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219143 (* 1 = 0.219143 loss)
I0906 01:12:54.754364 90901 sgd_solver.cpp:106] Iteration 70870, lr = 0.01
I0906 01:13:07.599244 90901 solver.cpp:228] Iteration 70880, loss = 0.0241653
I0906 01:13:07.599328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0241668 (* 1 = 0.0241668 loss)
I0906 01:13:07.599349 90901 sgd_solver.cpp:106] Iteration 70880, lr = 0.01
I0906 01:13:22.717392 90901 solver.cpp:228] Iteration 70890, loss = 0.212559
I0906 01:13:22.717586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21256 (* 1 = 0.21256 loss)
I0906 01:13:22.717609 90901 sgd_solver.cpp:106] Iteration 70890, lr = 0.01
I0906 01:13:40.113739 90901 solver.cpp:228] Iteration 70900, loss = 0.0918733
I0906 01:13:40.113821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0918748 (* 1 = 0.0918748 loss)
I0906 01:13:40.113842 90901 sgd_solver.cpp:106] Iteration 70900, lr = 0.01
I0906 01:13:52.817725 90901 solver.cpp:228] Iteration 70910, loss = 0.232282
I0906 01:13:52.817880 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232284 (* 1 = 0.232284 loss)
I0906 01:13:52.817910 90901 sgd_solver.cpp:106] Iteration 70910, lr = 0.01
I0906 01:14:05.587362 90901 solver.cpp:228] Iteration 70920, loss = 0.106222
I0906 01:14:05.587452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106223 (* 1 = 0.106223 loss)
I0906 01:14:05.587471 90901 sgd_solver.cpp:106] Iteration 70920, lr = 0.01
I0906 01:14:17.340222 90901 solver.cpp:228] Iteration 70930, loss = 0.0773908
I0906 01:14:17.340361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0773923 (* 1 = 0.0773923 loss)
I0906 01:14:17.340389 90901 sgd_solver.cpp:106] Iteration 70930, lr = 0.01
I0906 01:14:29.206212 90901 solver.cpp:228] Iteration 70940, loss = 0.0933983
I0906 01:14:29.206418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0933998 (* 1 = 0.0933998 loss)
I0906 01:14:29.206436 90901 sgd_solver.cpp:106] Iteration 70940, lr = 0.01
I0906 01:14:44.612340 90901 solver.cpp:228] Iteration 70950, loss = 0.170883
I0906 01:14:44.612409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170884 (* 1 = 0.170884 loss)
I0906 01:14:44.612429 90901 sgd_solver.cpp:106] Iteration 70950, lr = 0.01
I0906 01:15:02.629310 90901 solver.cpp:228] Iteration 70960, loss = 0.205944
I0906 01:15:02.629487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205945 (* 1 = 0.205945 loss)
I0906 01:15:02.629510 90901 sgd_solver.cpp:106] Iteration 70960, lr = 0.01
I0906 01:15:20.566619 90901 solver.cpp:228] Iteration 70970, loss = 0.0518595
I0906 01:15:20.566720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.051861 (* 1 = 0.051861 loss)
I0906 01:15:20.566748 90901 sgd_solver.cpp:106] Iteration 70970, lr = 0.01
I0906 01:15:38.137676 90901 solver.cpp:228] Iteration 70980, loss = 0.238021
I0906 01:15:38.137955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238023 (* 1 = 0.238023 loss)
I0906 01:15:38.137982 90901 sgd_solver.cpp:106] Iteration 70980, lr = 0.01
I0906 01:15:53.965445 90901 solver.cpp:228] Iteration 70990, loss = 0.0733318
I0906 01:15:53.965574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0733333 (* 1 = 0.0733333 loss)
I0906 01:15:53.965593 90901 sgd_solver.cpp:106] Iteration 70990, lr = 0.01
I0906 01:16:11.063870 90901 solver.cpp:228] Iteration 71000, loss = 0.129948
I0906 01:16:11.064043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129949 (* 1 = 0.129949 loss)
I0906 01:16:11.064065 90901 sgd_solver.cpp:106] Iteration 71000, lr = 0.01
I0906 01:16:25.632060 90901 solver.cpp:228] Iteration 71010, loss = 0.0394202
I0906 01:16:25.632143 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0394217 (* 1 = 0.0394217 loss)
I0906 01:16:25.632164 90901 sgd_solver.cpp:106] Iteration 71010, lr = 0.01
I0906 01:16:42.793859 90901 solver.cpp:228] Iteration 71020, loss = 0.0838355
I0906 01:16:42.794008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.083837 (* 1 = 0.083837 loss)
I0906 01:16:42.794035 90901 sgd_solver.cpp:106] Iteration 71020, lr = 0.01
I0906 01:17:00.657955 90901 solver.cpp:228] Iteration 71030, loss = 0.31079
I0906 01:17:00.658041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310792 (* 1 = 0.310792 loss)
I0906 01:17:00.658058 90901 sgd_solver.cpp:106] Iteration 71030, lr = 0.01
I0906 01:17:19.322140 90901 solver.cpp:228] Iteration 71040, loss = 0.0871918
I0906 01:17:19.322430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0871932 (* 1 = 0.0871932 loss)
I0906 01:17:19.322458 90901 sgd_solver.cpp:106] Iteration 71040, lr = 0.01
I0906 01:17:37.176777 90901 solver.cpp:228] Iteration 71050, loss = 0.20226
I0906 01:17:37.176852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202262 (* 1 = 0.202262 loss)
I0906 01:17:37.176870 90901 sgd_solver.cpp:106] Iteration 71050, lr = 0.01
I0906 01:17:55.851701 90901 solver.cpp:228] Iteration 71060, loss = 0.424121
I0906 01:17:55.851860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424123 (* 1 = 0.424123 loss)
I0906 01:17:55.851888 90901 sgd_solver.cpp:106] Iteration 71060, lr = 0.01
I0906 01:18:14.789149 90901 solver.cpp:228] Iteration 71070, loss = 0.547696
I0906 01:18:14.789216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.547697 (* 1 = 0.547697 loss)
I0906 01:18:14.789237 90901 sgd_solver.cpp:106] Iteration 71070, lr = 0.01
I0906 01:18:32.482203 90901 solver.cpp:228] Iteration 71080, loss = 0.0717663
I0906 01:18:32.482820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0717677 (* 1 = 0.0717677 loss)
I0906 01:18:32.482862 90901 sgd_solver.cpp:106] Iteration 71080, lr = 0.01
I0906 01:18:47.269744 90901 solver.cpp:228] Iteration 71090, loss = 0.187827
I0906 01:18:47.269827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187829 (* 1 = 0.187829 loss)
I0906 01:18:47.269847 90901 sgd_solver.cpp:106] Iteration 71090, lr = 0.01
I0906 01:19:00.041263 90901 solver.cpp:228] Iteration 71100, loss = 0.564571
I0906 01:19:00.041332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.564572 (* 1 = 0.564572 loss)
I0906 01:19:00.041352 90901 sgd_solver.cpp:106] Iteration 71100, lr = 0.01
I0906 01:19:12.226984 90901 solver.cpp:228] Iteration 71110, loss = 0.23587
I0906 01:19:12.227205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235871 (* 1 = 0.235871 loss)
I0906 01:19:12.227242 90901 sgd_solver.cpp:106] Iteration 71110, lr = 0.01
I0906 01:19:27.274852 90901 solver.cpp:228] Iteration 71120, loss = 0.0580405
I0906 01:19:27.274930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0580419 (* 1 = 0.0580419 loss)
I0906 01:19:27.274951 90901 sgd_solver.cpp:106] Iteration 71120, lr = 0.01
I0906 01:19:46.197562 90901 solver.cpp:228] Iteration 71130, loss = 0.284971
I0906 01:19:46.197866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284972 (* 1 = 0.284972 loss)
I0906 01:19:46.197890 90901 sgd_solver.cpp:106] Iteration 71130, lr = 0.01
I0906 01:20:04.116092 90901 solver.cpp:228] Iteration 71140, loss = 0.270662
I0906 01:20:04.116159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270663 (* 1 = 0.270663 loss)
I0906 01:20:04.116185 90901 sgd_solver.cpp:106] Iteration 71140, lr = 0.01
I0906 01:20:23.223068 90901 solver.cpp:228] Iteration 71150, loss = 0.359743
I0906 01:20:23.223371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359745 (* 1 = 0.359745 loss)
I0906 01:20:23.223392 90901 sgd_solver.cpp:106] Iteration 71150, lr = 0.01
I0906 01:20:42.650558 90901 solver.cpp:228] Iteration 71160, loss = 0.15435
I0906 01:20:42.650660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154352 (* 1 = 0.154352 loss)
I0906 01:20:42.650681 90901 sgd_solver.cpp:106] Iteration 71160, lr = 0.01
I0906 01:21:01.321126 90901 solver.cpp:228] Iteration 71170, loss = 0.164256
I0906 01:21:01.321348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164257 (* 1 = 0.164257 loss)
I0906 01:21:01.321384 90901 sgd_solver.cpp:106] Iteration 71170, lr = 0.01
I0906 01:21:20.114007 90901 solver.cpp:228] Iteration 71180, loss = 0.0815044
I0906 01:21:20.114081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0815059 (* 1 = 0.0815059 loss)
I0906 01:21:20.114099 90901 sgd_solver.cpp:106] Iteration 71180, lr = 0.01
I0906 01:21:38.475036 90901 solver.cpp:228] Iteration 71190, loss = 0.132863
I0906 01:21:38.475193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132865 (* 1 = 0.132865 loss)
I0906 01:21:38.475213 90901 sgd_solver.cpp:106] Iteration 71190, lr = 0.01
I0906 01:21:56.424711 90901 solver.cpp:337] Iteration 71200, Testing net (#0)
I0906 01:24:09.524303 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.889375
I0906 01:24:09.524461 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277538 (* 1 = 0.277538 loss)
I0906 01:24:10.592255 90901 solver.cpp:228] Iteration 71200, loss = 0.231239
I0906 01:24:10.592327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23124 (* 1 = 0.23124 loss)
I0906 01:24:10.592350 90901 sgd_solver.cpp:106] Iteration 71200, lr = 0.01
I0906 01:24:29.013715 90901 solver.cpp:228] Iteration 71210, loss = 0.13126
I0906 01:24:29.013805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131262 (* 1 = 0.131262 loss)
I0906 01:24:29.013824 90901 sgd_solver.cpp:106] Iteration 71210, lr = 0.01
I0906 01:24:46.814240 90901 solver.cpp:228] Iteration 71220, loss = 0.335482
I0906 01:24:46.814474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335483 (* 1 = 0.335483 loss)
I0906 01:24:46.814494 90901 sgd_solver.cpp:106] Iteration 71220, lr = 0.01
I0906 01:25:06.422605 90901 solver.cpp:228] Iteration 71230, loss = 0.0909408
I0906 01:25:06.422708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0909422 (* 1 = 0.0909422 loss)
I0906 01:25:06.422729 90901 sgd_solver.cpp:106] Iteration 71230, lr = 0.01
I0906 01:25:21.858821 90901 solver.cpp:228] Iteration 71240, loss = 0.168957
I0906 01:25:21.859176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168958 (* 1 = 0.168958 loss)
I0906 01:25:21.859220 90901 sgd_solver.cpp:106] Iteration 71240, lr = 0.01
I0906 01:25:35.142544 90901 solver.cpp:228] Iteration 71250, loss = 0.0809628
I0906 01:25:35.142621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0809643 (* 1 = 0.0809643 loss)
I0906 01:25:35.142653 90901 sgd_solver.cpp:106] Iteration 71250, lr = 0.01
I0906 01:25:47.898016 90901 solver.cpp:228] Iteration 71260, loss = 0.0858904
I0906 01:25:47.898080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0858918 (* 1 = 0.0858918 loss)
I0906 01:25:47.898097 90901 sgd_solver.cpp:106] Iteration 71260, lr = 0.01
I0906 01:26:07.174712 90901 solver.cpp:228] Iteration 71270, loss = 0.145131
I0906 01:26:07.174931 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145133 (* 1 = 0.145133 loss)
I0906 01:26:07.174954 90901 sgd_solver.cpp:106] Iteration 71270, lr = 0.01
I0906 01:26:24.967805 90901 solver.cpp:228] Iteration 71280, loss = 0.321053
I0906 01:26:24.967895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321054 (* 1 = 0.321054 loss)
I0906 01:26:24.967913 90901 sgd_solver.cpp:106] Iteration 71280, lr = 0.01
I0906 01:26:45.021227 90901 solver.cpp:228] Iteration 71290, loss = 0.30166
I0906 01:26:45.021438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301662 (* 1 = 0.301662 loss)
I0906 01:26:45.021481 90901 sgd_solver.cpp:106] Iteration 71290, lr = 0.01
I0906 01:27:03.423322 90901 solver.cpp:228] Iteration 71300, loss = 0.0604421
I0906 01:27:03.423403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0604436 (* 1 = 0.0604436 loss)
I0906 01:27:03.423419 90901 sgd_solver.cpp:106] Iteration 71300, lr = 0.01
I0906 01:27:21.259191 90901 solver.cpp:228] Iteration 71310, loss = 0.159758
I0906 01:27:21.259366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15976 (* 1 = 0.15976 loss)
I0906 01:27:21.259384 90901 sgd_solver.cpp:106] Iteration 71310, lr = 0.01
I0906 01:27:38.790063 90901 solver.cpp:228] Iteration 71320, loss = 0.326858
I0906 01:27:38.790150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326859 (* 1 = 0.326859 loss)
I0906 01:27:38.790171 90901 sgd_solver.cpp:106] Iteration 71320, lr = 0.01
I0906 01:27:56.473866 90901 solver.cpp:228] Iteration 71330, loss = 0.0800787
I0906 01:27:56.474050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0800801 (* 1 = 0.0800801 loss)
I0906 01:27:56.474083 90901 sgd_solver.cpp:106] Iteration 71330, lr = 0.01
I0906 01:28:15.070724 90901 solver.cpp:228] Iteration 71340, loss = 0.203724
I0906 01:28:15.070791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203726 (* 1 = 0.203726 loss)
I0906 01:28:15.070814 90901 sgd_solver.cpp:106] Iteration 71340, lr = 0.01
I0906 01:28:33.192546 90901 solver.cpp:228] Iteration 71350, loss = 0.217784
I0906 01:28:33.192709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217785 (* 1 = 0.217785 loss)
I0906 01:28:33.192736 90901 sgd_solver.cpp:106] Iteration 71350, lr = 0.01
I0906 01:28:51.180187 90901 solver.cpp:228] Iteration 71360, loss = 0.241404
I0906 01:28:51.180321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241406 (* 1 = 0.241406 loss)
I0906 01:28:51.180354 90901 sgd_solver.cpp:106] Iteration 71360, lr = 0.01
I0906 01:29:08.476387 90901 solver.cpp:228] Iteration 71370, loss = 0.236511
I0906 01:29:08.476586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236512 (* 1 = 0.236512 loss)
I0906 01:29:08.476619 90901 sgd_solver.cpp:106] Iteration 71370, lr = 0.01
I0906 01:29:25.295265 90901 solver.cpp:228] Iteration 71380, loss = 0.222836
I0906 01:29:25.295341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222837 (* 1 = 0.222837 loss)
I0906 01:29:25.295357 90901 sgd_solver.cpp:106] Iteration 71380, lr = 0.01
I0906 01:29:39.704047 90901 solver.cpp:228] Iteration 71390, loss = 0.177845
I0906 01:29:39.704231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177846 (* 1 = 0.177846 loss)
I0906 01:29:39.704252 90901 sgd_solver.cpp:106] Iteration 71390, lr = 0.01
I0906 01:29:54.252696 90901 solver.cpp:228] Iteration 71400, loss = 0.192337
I0906 01:29:54.252774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192338 (* 1 = 0.192338 loss)
I0906 01:29:54.252794 90901 sgd_solver.cpp:106] Iteration 71400, lr = 0.01
I0906 01:30:07.003105 90901 solver.cpp:228] Iteration 71410, loss = 0.173441
I0906 01:30:07.003188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173442 (* 1 = 0.173442 loss)
I0906 01:30:07.003206 90901 sgd_solver.cpp:106] Iteration 71410, lr = 0.01
I0906 01:30:19.689512 90901 solver.cpp:228] Iteration 71420, loss = 0.491059
I0906 01:30:19.689858 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.49106 (* 1 = 0.49106 loss)
I0906 01:30:19.689891 90901 sgd_solver.cpp:106] Iteration 71420, lr = 0.01
I0906 01:30:31.985574 90901 solver.cpp:228] Iteration 71430, loss = 0.198041
I0906 01:30:31.985649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198042 (* 1 = 0.198042 loss)
I0906 01:30:31.985666 90901 sgd_solver.cpp:106] Iteration 71430, lr = 0.01
I0906 01:30:44.323837 90901 solver.cpp:228] Iteration 71440, loss = 0.533047
I0906 01:30:44.323902 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.533049 (* 1 = 0.533049 loss)
I0906 01:30:44.323920 90901 sgd_solver.cpp:106] Iteration 71440, lr = 0.01
I0906 01:30:57.469292 90901 solver.cpp:228] Iteration 71450, loss = 0.212638
I0906 01:30:57.469563 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212639 (* 1 = 0.212639 loss)
I0906 01:30:57.469584 90901 sgd_solver.cpp:106] Iteration 71450, lr = 0.01
I0906 01:31:14.512244 90901 solver.cpp:228] Iteration 71460, loss = 0.0348048
I0906 01:31:14.512332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0348063 (* 1 = 0.0348063 loss)
I0906 01:31:14.512356 90901 sgd_solver.cpp:106] Iteration 71460, lr = 0.01
I0906 01:31:32.880179 90901 solver.cpp:228] Iteration 71470, loss = 0.244159
I0906 01:31:32.880403 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24416 (* 1 = 0.24416 loss)
I0906 01:31:32.880436 90901 sgd_solver.cpp:106] Iteration 71470, lr = 0.01
I0906 01:31:52.751803 90901 solver.cpp:228] Iteration 71480, loss = 0.246781
I0906 01:31:52.751883 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246782 (* 1 = 0.246782 loss)
I0906 01:31:52.751902 90901 sgd_solver.cpp:106] Iteration 71480, lr = 0.01
I0906 01:32:12.171494 90901 solver.cpp:228] Iteration 71490, loss = 0.101718
I0906 01:32:12.171669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101719 (* 1 = 0.101719 loss)
I0906 01:32:12.171699 90901 sgd_solver.cpp:106] Iteration 71490, lr = 0.01
I0906 01:32:30.705118 90901 solver.cpp:228] Iteration 71500, loss = 0.0609185
I0906 01:32:30.705194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0609199 (* 1 = 0.0609199 loss)
I0906 01:32:30.705217 90901 sgd_solver.cpp:106] Iteration 71500, lr = 0.01
I0906 01:32:49.925320 90901 solver.cpp:228] Iteration 71510, loss = 0.127016
I0906 01:32:49.925506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127017 (* 1 = 0.127017 loss)
I0906 01:32:49.925529 90901 sgd_solver.cpp:106] Iteration 71510, lr = 0.01
I0906 01:33:08.259563 90901 solver.cpp:228] Iteration 71520, loss = 0.120086
I0906 01:33:08.259631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120088 (* 1 = 0.120088 loss)
I0906 01:33:08.259647 90901 sgd_solver.cpp:106] Iteration 71520, lr = 0.01
I0906 01:33:25.258095 90901 solver.cpp:228] Iteration 71530, loss = 0.0886677
I0906 01:33:25.258319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0886691 (* 1 = 0.0886691 loss)
I0906 01:33:25.258342 90901 sgd_solver.cpp:106] Iteration 71530, lr = 0.01
I0906 01:33:38.520241 90901 solver.cpp:228] Iteration 71540, loss = 0.157087
I0906 01:33:38.520328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157089 (* 1 = 0.157089 loss)
I0906 01:33:38.520345 90901 sgd_solver.cpp:106] Iteration 71540, lr = 0.01
I0906 01:33:51.439564 90901 solver.cpp:228] Iteration 71550, loss = 0.248452
I0906 01:33:51.439647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248454 (* 1 = 0.248454 loss)
I0906 01:33:51.439668 90901 sgd_solver.cpp:106] Iteration 71550, lr = 0.01
I0906 01:34:10.446950 90901 solver.cpp:228] Iteration 71560, loss = 0.550321
I0906 01:34:10.447167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.550322 (* 1 = 0.550322 loss)
I0906 01:34:10.447193 90901 sgd_solver.cpp:106] Iteration 71560, lr = 0.01
I0906 01:34:30.793365 90901 solver.cpp:228] Iteration 71570, loss = 0.288976
I0906 01:34:30.793442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288977 (* 1 = 0.288977 loss)
I0906 01:34:30.793460 90901 sgd_solver.cpp:106] Iteration 71570, lr = 0.01
I0906 01:34:51.820766 90901 solver.cpp:228] Iteration 71580, loss = 0.107793
I0906 01:34:51.821074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107794 (* 1 = 0.107794 loss)
I0906 01:34:51.821094 90901 sgd_solver.cpp:106] Iteration 71580, lr = 0.01
I0906 01:35:11.361861 90901 solver.cpp:228] Iteration 71590, loss = 0.0810665
I0906 01:35:11.361938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.081068 (* 1 = 0.081068 loss)
I0906 01:35:11.361956 90901 sgd_solver.cpp:106] Iteration 71590, lr = 0.01
I0906 01:35:29.885833 90901 solver.cpp:228] Iteration 71600, loss = 0.175474
I0906 01:35:29.886010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175475 (* 1 = 0.175475 loss)
I0906 01:35:29.886035 90901 sgd_solver.cpp:106] Iteration 71600, lr = 0.01
I0906 01:35:45.207623 90901 solver.cpp:228] Iteration 71610, loss = 0.246311
I0906 01:35:45.207718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246312 (* 1 = 0.246312 loss)
I0906 01:35:45.207741 90901 sgd_solver.cpp:106] Iteration 71610, lr = 0.01
I0906 01:35:59.381855 90901 solver.cpp:228] Iteration 71620, loss = 0.19473
I0906 01:35:59.381928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194731 (* 1 = 0.194731 loss)
I0906 01:35:59.381947 90901 sgd_solver.cpp:106] Iteration 71620, lr = 0.01
I0906 01:36:18.406855 90901 solver.cpp:228] Iteration 71630, loss = 0.121203
I0906 01:36:18.407066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121205 (* 1 = 0.121205 loss)
I0906 01:36:18.407088 90901 sgd_solver.cpp:106] Iteration 71630, lr = 0.01
I0906 01:36:37.833478 90901 solver.cpp:228] Iteration 71640, loss = 0.12883
I0906 01:36:37.833573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128832 (* 1 = 0.128832 loss)
I0906 01:36:37.833592 90901 sgd_solver.cpp:106] Iteration 71640, lr = 0.01
I0906 01:36:56.844020 90901 solver.cpp:228] Iteration 71650, loss = 0.14201
I0906 01:36:56.844166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142012 (* 1 = 0.142012 loss)
I0906 01:36:56.844187 90901 sgd_solver.cpp:106] Iteration 71650, lr = 0.01
I0906 01:37:14.936511 90901 solver.cpp:228] Iteration 71660, loss = 0.11025
I0906 01:37:14.936638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110252 (* 1 = 0.110252 loss)
I0906 01:37:14.936661 90901 sgd_solver.cpp:106] Iteration 71660, lr = 0.01
I0906 01:37:34.040668 90901 solver.cpp:228] Iteration 71670, loss = 0.128548
I0906 01:37:34.054708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12855 (* 1 = 0.12855 loss)
I0906 01:37:34.054726 90901 sgd_solver.cpp:106] Iteration 71670, lr = 0.01
I0906 01:37:52.525297 90901 solver.cpp:228] Iteration 71680, loss = 0.290558
I0906 01:37:52.525372 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290559 (* 1 = 0.290559 loss)
I0906 01:37:52.525391 90901 sgd_solver.cpp:106] Iteration 71680, lr = 0.01
I0906 01:38:10.377840 90901 solver.cpp:228] Iteration 71690, loss = 0.0921636
I0906 01:38:10.378005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.092165 (* 1 = 0.092165 loss)
I0906 01:38:10.378039 90901 sgd_solver.cpp:106] Iteration 71690, lr = 0.01
I0906 01:38:27.872933 90901 solver.cpp:228] Iteration 71700, loss = 0.0661494
I0906 01:38:27.873049 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0661509 (* 1 = 0.0661509 loss)
I0906 01:38:27.873069 90901 sgd_solver.cpp:106] Iteration 71700, lr = 0.01
I0906 01:38:47.411128 90901 solver.cpp:228] Iteration 71710, loss = 0.0824048
I0906 01:38:47.411360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0824063 (* 1 = 0.0824063 loss)
I0906 01:38:47.411381 90901 sgd_solver.cpp:106] Iteration 71710, lr = 0.01
I0906 01:39:05.681994 90901 solver.cpp:228] Iteration 71720, loss = 0.378286
I0906 01:39:05.682070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378288 (* 1 = 0.378288 loss)
I0906 01:39:05.682087 90901 sgd_solver.cpp:106] Iteration 71720, lr = 0.01
I0906 01:39:22.876821 90901 solver.cpp:228] Iteration 71730, loss = 0.234457
I0906 01:39:22.877074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234459 (* 1 = 0.234459 loss)
I0906 01:39:22.877092 90901 sgd_solver.cpp:106] Iteration 71730, lr = 0.01
I0906 01:39:41.785820 90901 solver.cpp:228] Iteration 71740, loss = 0.278622
I0906 01:39:41.785908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278624 (* 1 = 0.278624 loss)
I0906 01:39:41.785928 90901 sgd_solver.cpp:106] Iteration 71740, lr = 0.01
I0906 01:39:58.967217 90901 solver.cpp:228] Iteration 71750, loss = 0.0518315
I0906 01:39:58.967389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.051833 (* 1 = 0.051833 loss)
I0906 01:39:58.967430 90901 sgd_solver.cpp:106] Iteration 71750, lr = 0.01
I0906 01:40:17.156348 90901 solver.cpp:228] Iteration 71760, loss = 0.0209899
I0906 01:40:17.156432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0209914 (* 1 = 0.0209914 loss)
I0906 01:40:17.156461 90901 sgd_solver.cpp:106] Iteration 71760, lr = 0.01
I0906 01:40:33.468145 90901 solver.cpp:228] Iteration 71770, loss = 0.194629
I0906 01:40:33.468304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194631 (* 1 = 0.194631 loss)
I0906 01:40:33.468338 90901 sgd_solver.cpp:106] Iteration 71770, lr = 0.01
I0906 01:40:47.892230 90901 solver.cpp:228] Iteration 71780, loss = 0.209876
I0906 01:40:47.892304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209878 (* 1 = 0.209878 loss)
I0906 01:40:47.892323 90901 sgd_solver.cpp:106] Iteration 71780, lr = 0.01
I0906 01:41:02.509116 90901 solver.cpp:228] Iteration 71790, loss = 0.056068
I0906 01:41:02.509188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0560695 (* 1 = 0.0560695 loss)
I0906 01:41:02.509205 90901 sgd_solver.cpp:106] Iteration 71790, lr = 0.01
I0906 01:41:18.602959 90901 solver.cpp:228] Iteration 71800, loss = 0.167548
I0906 01:41:18.603148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16755 (* 1 = 0.16755 loss)
I0906 01:41:18.603179 90901 sgd_solver.cpp:106] Iteration 71800, lr = 0.01
I0906 01:41:31.278585 90901 solver.cpp:228] Iteration 71810, loss = 0.0812047
I0906 01:41:31.278702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0812062 (* 1 = 0.0812062 loss)
I0906 01:41:31.278723 90901 sgd_solver.cpp:106] Iteration 71810, lr = 0.01
I0906 01:41:45.303118 90901 solver.cpp:228] Iteration 71820, loss = 0.0900436
I0906 01:41:45.303202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0900452 (* 1 = 0.0900452 loss)
I0906 01:41:45.303226 90901 sgd_solver.cpp:106] Iteration 71820, lr = 0.01
I0906 01:41:58.026747 90901 solver.cpp:228] Iteration 71830, loss = 0.192062
I0906 01:41:58.026932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192064 (* 1 = 0.192064 loss)
I0906 01:41:58.026963 90901 sgd_solver.cpp:106] Iteration 71830, lr = 0.01
I0906 01:42:11.367108 90901 solver.cpp:228] Iteration 71840, loss = 0.234978
I0906 01:42:11.367182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23498 (* 1 = 0.23498 loss)
I0906 01:42:11.367219 90901 sgd_solver.cpp:106] Iteration 71840, lr = 0.01
I0906 01:42:28.422739 90901 solver.cpp:228] Iteration 71850, loss = 0.0586404
I0906 01:42:28.422956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.058642 (* 1 = 0.058642 loss)
I0906 01:42:28.422991 90901 sgd_solver.cpp:106] Iteration 71850, lr = 0.01
I0906 01:42:48.020478 90901 solver.cpp:228] Iteration 71860, loss = 0.144421
I0906 01:42:48.020571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144422 (* 1 = 0.144422 loss)
I0906 01:42:48.020589 90901 sgd_solver.cpp:106] Iteration 71860, lr = 0.01
I0906 01:43:07.505925 90901 solver.cpp:228] Iteration 71870, loss = 0.208651
I0906 01:43:07.506220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208652 (* 1 = 0.208652 loss)
I0906 01:43:07.506244 90901 sgd_solver.cpp:106] Iteration 71870, lr = 0.01
I0906 01:43:24.543414 90901 solver.cpp:228] Iteration 71880, loss = 0.104956
I0906 01:43:24.543479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104958 (* 1 = 0.104958 loss)
I0906 01:43:24.543495 90901 sgd_solver.cpp:106] Iteration 71880, lr = 0.01
I0906 01:43:37.171705 90901 solver.cpp:228] Iteration 71890, loss = 0.372642
I0906 01:43:37.171778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372644 (* 1 = 0.372644 loss)
I0906 01:43:37.171797 90901 sgd_solver.cpp:106] Iteration 71890, lr = 0.01
I0906 01:43:55.120574 90901 solver.cpp:228] Iteration 71900, loss = 0.103203
I0906 01:43:55.120786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103205 (* 1 = 0.103205 loss)
I0906 01:43:55.120808 90901 sgd_solver.cpp:106] Iteration 71900, lr = 0.01
I0906 01:44:15.480286 90901 solver.cpp:228] Iteration 71910, loss = 0.337525
I0906 01:44:15.480361 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337527 (* 1 = 0.337527 loss)
I0906 01:44:15.480383 90901 sgd_solver.cpp:106] Iteration 71910, lr = 0.01
I0906 01:44:34.954530 90901 solver.cpp:228] Iteration 71920, loss = 0.0987782
I0906 01:44:34.954736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0987798 (* 1 = 0.0987798 loss)
I0906 01:44:34.954771 90901 sgd_solver.cpp:106] Iteration 71920, lr = 0.01
I0906 01:44:50.263371 90901 solver.cpp:228] Iteration 71930, loss = 0.216059
I0906 01:44:50.263466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216061 (* 1 = 0.216061 loss)
I0906 01:44:50.263490 90901 sgd_solver.cpp:106] Iteration 71930, lr = 0.01
I0906 01:45:04.096011 90901 solver.cpp:228] Iteration 71940, loss = 0.254085
I0906 01:45:04.096084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254086 (* 1 = 0.254086 loss)
I0906 01:45:04.096101 90901 sgd_solver.cpp:106] Iteration 71940, lr = 0.01
I0906 01:45:22.518177 90901 solver.cpp:228] Iteration 71950, loss = 0.0618764
I0906 01:45:22.518358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.061878 (* 1 = 0.061878 loss)
I0906 01:45:22.518376 90901 sgd_solver.cpp:106] Iteration 71950, lr = 0.01
I0906 01:45:38.818725 90901 solver.cpp:228] Iteration 71960, loss = 0.0415472
I0906 01:45:38.818819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0415488 (* 1 = 0.0415488 loss)
I0906 01:45:38.818840 90901 sgd_solver.cpp:106] Iteration 71960, lr = 0.01
I0906 01:45:57.447430 90901 solver.cpp:228] Iteration 71970, loss = 0.150807
I0906 01:45:57.447600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150809 (* 1 = 0.150809 loss)
I0906 01:45:57.447633 90901 sgd_solver.cpp:106] Iteration 71970, lr = 0.01
I0906 01:46:12.850009 90901 solver.cpp:228] Iteration 71980, loss = 0.0786251
I0906 01:46:12.850085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0786267 (* 1 = 0.0786267 loss)
I0906 01:46:12.850106 90901 sgd_solver.cpp:106] Iteration 71980, lr = 0.01
I0906 01:46:25.816464 90901 solver.cpp:228] Iteration 71990, loss = 0.635029
I0906 01:46:25.816558 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.63503 (* 1 = 0.63503 loss)
I0906 01:46:25.816581 90901 sgd_solver.cpp:106] Iteration 71990, lr = 0.01
I0906 01:46:40.059715 90901 solver.cpp:337] Iteration 72000, Testing net (#0)
I0906 01:48:43.315948 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.917813
I0906 01:48:43.316118 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.203571 (* 1 = 0.203571 loss)
I0906 01:48:44.293871 90901 solver.cpp:228] Iteration 72000, loss = 0.140028
I0906 01:48:44.293968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140029 (* 1 = 0.140029 loss)
I0906 01:48:44.293997 90901 sgd_solver.cpp:106] Iteration 72000, lr = 0.01
I0906 01:49:01.784395 90901 solver.cpp:228] Iteration 72010, loss = 0.222344
I0906 01:49:01.784471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222346 (* 1 = 0.222346 loss)
I0906 01:49:01.784490 90901 sgd_solver.cpp:106] Iteration 72010, lr = 0.01
I0906 01:49:21.668284 90901 solver.cpp:228] Iteration 72020, loss = 0.240812
I0906 01:49:21.668519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240814 (* 1 = 0.240814 loss)
I0906 01:49:21.668552 90901 sgd_solver.cpp:106] Iteration 72020, lr = 0.01
I0906 01:49:39.946246 90901 solver.cpp:228] Iteration 72030, loss = 0.294998
I0906 01:49:39.946382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294999 (* 1 = 0.294999 loss)
I0906 01:49:39.946413 90901 sgd_solver.cpp:106] Iteration 72030, lr = 0.01
I0906 01:50:00.926554 90901 solver.cpp:228] Iteration 72040, loss = 0.406752
I0906 01:50:00.926806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406754 (* 1 = 0.406754 loss)
I0906 01:50:00.926828 90901 sgd_solver.cpp:106] Iteration 72040, lr = 0.01
I0906 01:50:18.754467 90901 solver.cpp:228] Iteration 72050, loss = 0.326319
I0906 01:50:18.754544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326321 (* 1 = 0.326321 loss)
I0906 01:50:18.754561 90901 sgd_solver.cpp:106] Iteration 72050, lr = 0.01
I0906 01:50:38.578419 90901 solver.cpp:228] Iteration 72060, loss = 0.249859
I0906 01:50:38.578616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24986 (* 1 = 0.24986 loss)
I0906 01:50:38.578661 90901 sgd_solver.cpp:106] Iteration 72060, lr = 0.01
I0906 01:51:00.010164 90901 solver.cpp:228] Iteration 72070, loss = 0.108006
I0906 01:51:00.010244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108008 (* 1 = 0.108008 loss)
I0906 01:51:00.010265 90901 sgd_solver.cpp:106] Iteration 72070, lr = 0.01
I0906 01:51:18.915779 90901 solver.cpp:228] Iteration 72080, loss = 0.149409
I0906 01:51:18.915985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14941 (* 1 = 0.14941 loss)
I0906 01:51:18.916021 90901 sgd_solver.cpp:106] Iteration 72080, lr = 0.01
I0906 01:51:39.250613 90901 solver.cpp:228] Iteration 72090, loss = 0.0640804
I0906 01:51:39.250738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.064082 (* 1 = 0.064082 loss)
I0906 01:51:39.250761 90901 sgd_solver.cpp:106] Iteration 72090, lr = 0.01
I0906 01:51:57.029530 90901 solver.cpp:228] Iteration 72100, loss = 0.158931
I0906 01:51:57.029685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158932 (* 1 = 0.158932 loss)
I0906 01:51:57.029703 90901 sgd_solver.cpp:106] Iteration 72100, lr = 0.01
I0906 01:52:13.335400 90901 solver.cpp:228] Iteration 72110, loss = 0.0527971
I0906 01:52:13.335481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0527986 (* 1 = 0.0527986 loss)
I0906 01:52:13.335501 90901 sgd_solver.cpp:106] Iteration 72110, lr = 0.01
I0906 01:52:30.798053 90901 solver.cpp:228] Iteration 72120, loss = 0.220513
I0906 01:52:30.798362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220515 (* 1 = 0.220515 loss)
I0906 01:52:30.798382 90901 sgd_solver.cpp:106] Iteration 72120, lr = 0.01
I0906 01:52:47.412395 90901 solver.cpp:228] Iteration 72130, loss = 0.143356
I0906 01:52:47.412498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143358 (* 1 = 0.143358 loss)
I0906 01:52:47.412518 90901 sgd_solver.cpp:106] Iteration 72130, lr = 0.01
I0906 01:53:08.066213 90901 solver.cpp:228] Iteration 72140, loss = 0.4445
I0906 01:53:08.066401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.444501 (* 1 = 0.444501 loss)
I0906 01:53:08.066421 90901 sgd_solver.cpp:106] Iteration 72140, lr = 0.01
I0906 01:53:26.132189 90901 solver.cpp:228] Iteration 72150, loss = 0.102615
I0906 01:53:26.132282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102616 (* 1 = 0.102616 loss)
I0906 01:53:26.132304 90901 sgd_solver.cpp:106] Iteration 72150, lr = 0.01
I0906 01:53:43.611183 90901 solver.cpp:228] Iteration 72160, loss = 0.0573871
I0906 01:53:43.611436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0573887 (* 1 = 0.0573887 loss)
I0906 01:53:43.611456 90901 sgd_solver.cpp:106] Iteration 72160, lr = 0.01
I0906 01:54:02.237121 90901 solver.cpp:228] Iteration 72170, loss = 0.221386
I0906 01:54:02.237202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221388 (* 1 = 0.221388 loss)
I0906 01:54:02.237223 90901 sgd_solver.cpp:106] Iteration 72170, lr = 0.01
I0906 01:54:19.808042 90901 solver.cpp:228] Iteration 72180, loss = 0.207491
I0906 01:54:19.808365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207492 (* 1 = 0.207492 loss)
I0906 01:54:19.808388 90901 sgd_solver.cpp:106] Iteration 72180, lr = 0.01
I0906 01:54:40.512224 90901 solver.cpp:228] Iteration 72190, loss = 0.0734241
I0906 01:54:40.512296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0734257 (* 1 = 0.0734257 loss)
I0906 01:54:40.512313 90901 sgd_solver.cpp:106] Iteration 72190, lr = 0.01
I0906 01:55:00.783922 90901 solver.cpp:228] Iteration 72200, loss = 0.137783
I0906 01:55:00.784104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137785 (* 1 = 0.137785 loss)
I0906 01:55:00.784147 90901 sgd_solver.cpp:106] Iteration 72200, lr = 0.01
I0906 01:55:19.875547 90901 solver.cpp:228] Iteration 72210, loss = 0.245651
I0906 01:55:19.875630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245652 (* 1 = 0.245652 loss)
I0906 01:55:19.875650 90901 sgd_solver.cpp:106] Iteration 72210, lr = 0.01
I0906 01:55:38.636363 90901 solver.cpp:228] Iteration 72220, loss = 0.363455
I0906 01:55:38.636610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363456 (* 1 = 0.363456 loss)
I0906 01:55:38.636631 90901 sgd_solver.cpp:106] Iteration 72220, lr = 0.01
I0906 01:55:58.346676 90901 solver.cpp:228] Iteration 72230, loss = 0.095079
I0906 01:55:58.346757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0950806 (* 1 = 0.0950806 loss)
I0906 01:55:58.346776 90901 sgd_solver.cpp:106] Iteration 72230, lr = 0.01
I0906 01:56:18.202620 90901 solver.cpp:228] Iteration 72240, loss = 0.059814
I0906 01:56:18.202805 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0598156 (* 1 = 0.0598156 loss)
I0906 01:56:18.202854 90901 sgd_solver.cpp:106] Iteration 72240, lr = 0.01
I0906 01:56:37.576882 90901 solver.cpp:228] Iteration 72250, loss = 0.469708
I0906 01:56:37.576957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.469709 (* 1 = 0.469709 loss)
I0906 01:56:37.576977 90901 sgd_solver.cpp:106] Iteration 72250, lr = 0.01
I0906 01:56:57.433945 90901 solver.cpp:228] Iteration 72260, loss = 0.310878
I0906 01:56:57.434231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31088 (* 1 = 0.31088 loss)
I0906 01:56:57.434255 90901 sgd_solver.cpp:106] Iteration 72260, lr = 0.01
I0906 01:57:14.269379 90901 solver.cpp:228] Iteration 72270, loss = 0.29811
I0906 01:57:14.269454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.298111 (* 1 = 0.298111 loss)
I0906 01:57:14.269472 90901 sgd_solver.cpp:106] Iteration 72270, lr = 0.01
I0906 01:57:33.249866 90901 solver.cpp:228] Iteration 72280, loss = 0.821832
I0906 01:57:33.250104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.821834 (* 1 = 0.821834 loss)
I0906 01:57:33.250134 90901 sgd_solver.cpp:106] Iteration 72280, lr = 0.01
I0906 01:57:52.886929 90901 solver.cpp:228] Iteration 72290, loss = 0.0690764
I0906 01:57:52.887012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.069078 (* 1 = 0.069078 loss)
I0906 01:57:52.887035 90901 sgd_solver.cpp:106] Iteration 72290, lr = 0.01
I0906 01:58:11.714315 90901 solver.cpp:228] Iteration 72300, loss = 0.104859
I0906 01:58:11.714560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10486 (* 1 = 0.10486 loss)
I0906 01:58:11.714591 90901 sgd_solver.cpp:106] Iteration 72300, lr = 0.01
I0906 01:58:28.937104 90901 solver.cpp:228] Iteration 72310, loss = 0.113641
I0906 01:58:28.937186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113643 (* 1 = 0.113643 loss)
I0906 01:58:28.937202 90901 sgd_solver.cpp:106] Iteration 72310, lr = 0.01
I0906 01:58:49.208778 90901 solver.cpp:228] Iteration 72320, loss = 0.232634
I0906 01:58:49.209002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232636 (* 1 = 0.232636 loss)
I0906 01:58:49.209040 90901 sgd_solver.cpp:106] Iteration 72320, lr = 0.01
I0906 01:59:02.995065 90901 solver.cpp:228] Iteration 72330, loss = 0.117537
I0906 01:59:02.995149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117538 (* 1 = 0.117538 loss)
I0906 01:59:02.995172 90901 sgd_solver.cpp:106] Iteration 72330, lr = 0.01
I0906 01:59:14.666172 90901 solver.cpp:228] Iteration 72340, loss = 0.0515679
I0906 01:59:14.666265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0515694 (* 1 = 0.0515694 loss)
I0906 01:59:14.666280 90901 sgd_solver.cpp:106] Iteration 72340, lr = 0.01
I0906 01:59:29.185325 90901 solver.cpp:228] Iteration 72350, loss = 0.241391
I0906 01:59:29.185489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241392 (* 1 = 0.241392 loss)
I0906 01:59:29.185518 90901 sgd_solver.cpp:106] Iteration 72350, lr = 0.01
I0906 01:59:49.379398 90901 solver.cpp:228] Iteration 72360, loss = 0.123179
I0906 01:59:49.379463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123181 (* 1 = 0.123181 loss)
I0906 01:59:49.379482 90901 sgd_solver.cpp:106] Iteration 72360, lr = 0.01
I0906 02:00:07.296442 90901 solver.cpp:228] Iteration 72370, loss = 0.0945229
I0906 02:00:07.296643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0945243 (* 1 = 0.0945243 loss)
I0906 02:00:07.296672 90901 sgd_solver.cpp:106] Iteration 72370, lr = 0.01
I0906 02:00:26.013319 90901 solver.cpp:228] Iteration 72380, loss = 0.237884
I0906 02:00:26.013391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237885 (* 1 = 0.237885 loss)
I0906 02:00:26.013411 90901 sgd_solver.cpp:106] Iteration 72380, lr = 0.01
I0906 02:00:44.944114 90901 solver.cpp:228] Iteration 72390, loss = 0.0750234
I0906 02:00:44.944669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0750248 (* 1 = 0.0750248 loss)
I0906 02:00:44.944694 90901 sgd_solver.cpp:106] Iteration 72390, lr = 0.01
I0906 02:01:04.303696 90901 solver.cpp:228] Iteration 72400, loss = 0.222263
I0906 02:01:04.303812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222264 (* 1 = 0.222264 loss)
I0906 02:01:04.303843 90901 sgd_solver.cpp:106] Iteration 72400, lr = 0.01
I0906 02:01:23.730670 90901 solver.cpp:228] Iteration 72410, loss = 0.372776
I0906 02:01:23.730924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372777 (* 1 = 0.372777 loss)
I0906 02:01:23.730943 90901 sgd_solver.cpp:106] Iteration 72410, lr = 0.01
I0906 02:01:44.052783 90901 solver.cpp:228] Iteration 72420, loss = 0.101294
I0906 02:01:44.052878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101296 (* 1 = 0.101296 loss)
I0906 02:01:44.052899 90901 sgd_solver.cpp:106] Iteration 72420, lr = 0.01
I0906 02:02:04.380714 90901 solver.cpp:228] Iteration 72430, loss = 0.184319
I0906 02:02:04.380951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18432 (* 1 = 0.18432 loss)
I0906 02:02:04.380985 90901 sgd_solver.cpp:106] Iteration 72430, lr = 0.01
I0906 02:02:24.002604 90901 solver.cpp:228] Iteration 72440, loss = 0.512367
I0906 02:02:24.002714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.512369 (* 1 = 0.512369 loss)
I0906 02:02:24.002734 90901 sgd_solver.cpp:106] Iteration 72440, lr = 0.01
I0906 02:02:42.567764 90901 solver.cpp:228] Iteration 72450, loss = 0.150607
I0906 02:02:42.567944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150608 (* 1 = 0.150608 loss)
I0906 02:02:42.567965 90901 sgd_solver.cpp:106] Iteration 72450, lr = 0.01
I0906 02:03:03.303962 90901 solver.cpp:228] Iteration 72460, loss = 0.151624
I0906 02:03:03.304044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151626 (* 1 = 0.151626 loss)
I0906 02:03:03.304064 90901 sgd_solver.cpp:106] Iteration 72460, lr = 0.01
I0906 02:03:23.441373 90901 solver.cpp:228] Iteration 72470, loss = 0.249218
I0906 02:03:23.441604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249219 (* 1 = 0.249219 loss)
I0906 02:03:23.441634 90901 sgd_solver.cpp:106] Iteration 72470, lr = 0.01
I0906 02:03:42.150396 90901 solver.cpp:228] Iteration 72480, loss = 0.0912162
I0906 02:03:42.150485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0912177 (* 1 = 0.0912177 loss)
I0906 02:03:42.150507 90901 sgd_solver.cpp:106] Iteration 72480, lr = 0.01
I0906 02:03:59.302134 90901 solver.cpp:228] Iteration 72490, loss = 0.178163
I0906 02:03:59.302355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178165 (* 1 = 0.178165 loss)
I0906 02:03:59.302378 90901 sgd_solver.cpp:106] Iteration 72490, lr = 0.01
I0906 02:04:19.053053 90901 solver.cpp:228] Iteration 72500, loss = 0.077178
I0906 02:04:19.053134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0771794 (* 1 = 0.0771794 loss)
I0906 02:04:19.053151 90901 sgd_solver.cpp:106] Iteration 72500, lr = 0.01
I0906 02:04:38.066624 90901 solver.cpp:228] Iteration 72510, loss = 0.218285
I0906 02:04:38.066828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218286 (* 1 = 0.218286 loss)
I0906 02:04:38.066871 90901 sgd_solver.cpp:106] Iteration 72510, lr = 0.01
I0906 02:04:56.704239 90901 solver.cpp:228] Iteration 72520, loss = 0.0541893
I0906 02:04:56.704339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0541907 (* 1 = 0.0541907 loss)
I0906 02:04:56.704367 90901 sgd_solver.cpp:106] Iteration 72520, lr = 0.01
I0906 02:05:16.011390 90901 solver.cpp:228] Iteration 72530, loss = 0.262591
I0906 02:05:16.012205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.262592 (* 1 = 0.262592 loss)
I0906 02:05:16.012223 90901 sgd_solver.cpp:106] Iteration 72530, lr = 0.01
I0906 02:05:36.125171 90901 solver.cpp:228] Iteration 72540, loss = 0.345941
I0906 02:05:36.125247 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345942 (* 1 = 0.345942 loss)
I0906 02:05:36.125270 90901 sgd_solver.cpp:106] Iteration 72540, lr = 0.01
I0906 02:05:50.469754 90901 solver.cpp:228] Iteration 72550, loss = 0.260342
I0906 02:05:50.469933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260344 (* 1 = 0.260344 loss)
I0906 02:05:50.469954 90901 sgd_solver.cpp:106] Iteration 72550, lr = 0.01
I0906 02:06:04.257037 90901 solver.cpp:228] Iteration 72560, loss = 0.13586
I0906 02:06:04.257104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135861 (* 1 = 0.135861 loss)
I0906 02:06:04.257122 90901 sgd_solver.cpp:106] Iteration 72560, lr = 0.01
I0906 02:06:16.626368 90901 solver.cpp:228] Iteration 72570, loss = 0.24066
I0906 02:06:16.626449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240662 (* 1 = 0.240662 loss)
I0906 02:06:16.626467 90901 sgd_solver.cpp:106] Iteration 72570, lr = 0.01
I0906 02:06:34.801098 90901 solver.cpp:228] Iteration 72580, loss = 0.349531
I0906 02:06:34.801301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349532 (* 1 = 0.349532 loss)
I0906 02:06:34.801323 90901 sgd_solver.cpp:106] Iteration 72580, lr = 0.01
I0906 02:06:52.293527 90901 solver.cpp:228] Iteration 72590, loss = 0.159678
I0906 02:06:52.293602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159679 (* 1 = 0.159679 loss)
I0906 02:06:52.293622 90901 sgd_solver.cpp:106] Iteration 72590, lr = 0.01
I0906 02:07:10.859737 90901 solver.cpp:228] Iteration 72600, loss = 0.282615
I0906 02:07:10.859917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282617 (* 1 = 0.282617 loss)
I0906 02:07:10.859941 90901 sgd_solver.cpp:106] Iteration 72600, lr = 0.01
I0906 02:07:28.457002 90901 solver.cpp:228] Iteration 72610, loss = 0.10596
I0906 02:07:28.457098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105961 (* 1 = 0.105961 loss)
I0906 02:07:28.457118 90901 sgd_solver.cpp:106] Iteration 72610, lr = 0.01
I0906 02:07:47.027232 90901 solver.cpp:228] Iteration 72620, loss = 0.319731
I0906 02:07:47.027513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319733 (* 1 = 0.319733 loss)
I0906 02:07:47.027537 90901 sgd_solver.cpp:106] Iteration 72620, lr = 0.01
I0906 02:08:04.117142 90901 solver.cpp:228] Iteration 72630, loss = 0.0955194
I0906 02:08:04.117219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0955209 (* 1 = 0.0955209 loss)
I0906 02:08:04.117238 90901 sgd_solver.cpp:106] Iteration 72630, lr = 0.01
I0906 02:08:22.555414 90901 solver.cpp:228] Iteration 72640, loss = 0.1642
I0906 02:08:22.555640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164202 (* 1 = 0.164202 loss)
I0906 02:08:22.555681 90901 sgd_solver.cpp:106] Iteration 72640, lr = 0.01
I0906 02:08:42.010419 90901 solver.cpp:228] Iteration 72650, loss = 0.223566
I0906 02:08:42.010475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223568 (* 1 = 0.223568 loss)
I0906 02:08:42.010488 90901 sgd_solver.cpp:106] Iteration 72650, lr = 0.01
I0906 02:09:01.120020 90901 solver.cpp:228] Iteration 72660, loss = 0.267912
I0906 02:09:01.120270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267914 (* 1 = 0.267914 loss)
I0906 02:09:01.120312 90901 sgd_solver.cpp:106] Iteration 72660, lr = 0.01
I0906 02:09:20.157536 90901 solver.cpp:228] Iteration 72670, loss = 0.111724
I0906 02:09:20.157626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111725 (* 1 = 0.111725 loss)
I0906 02:09:20.157647 90901 sgd_solver.cpp:106] Iteration 72670, lr = 0.01
I0906 02:09:39.281497 90901 solver.cpp:228] Iteration 72680, loss = 0.256438
I0906 02:09:39.281651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25644 (* 1 = 0.25644 loss)
I0906 02:09:39.281677 90901 sgd_solver.cpp:106] Iteration 72680, lr = 0.01
I0906 02:09:57.037096 90901 solver.cpp:228] Iteration 72690, loss = 0.435075
I0906 02:09:57.037174 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435076 (* 1 = 0.435076 loss)
I0906 02:09:57.037197 90901 sgd_solver.cpp:106] Iteration 72690, lr = 0.01
I0906 02:10:14.442776 90901 solver.cpp:228] Iteration 72700, loss = 0.209255
I0906 02:10:14.442956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209256 (* 1 = 0.209256 loss)
I0906 02:10:14.442997 90901 sgd_solver.cpp:106] Iteration 72700, lr = 0.01
I0906 02:10:27.137792 90901 solver.cpp:228] Iteration 72710, loss = 0.125735
I0906 02:10:27.137919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125737 (* 1 = 0.125737 loss)
I0906 02:10:27.137943 90901 sgd_solver.cpp:106] Iteration 72710, lr = 0.01
I0906 02:10:42.880534 90901 solver.cpp:228] Iteration 72720, loss = 0.118432
I0906 02:10:42.880611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118434 (* 1 = 0.118434 loss)
I0906 02:10:42.880630 90901 sgd_solver.cpp:106] Iteration 72720, lr = 0.01
I0906 02:10:57.863804 90901 solver.cpp:228] Iteration 72730, loss = 0.223081
I0906 02:10:57.863986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223083 (* 1 = 0.223083 loss)
I0906 02:10:57.864007 90901 sgd_solver.cpp:106] Iteration 72730, lr = 0.01
I0906 02:11:12.542712 90901 solver.cpp:228] Iteration 72740, loss = 0.05155
I0906 02:11:12.542807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0515515 (* 1 = 0.0515515 loss)
I0906 02:11:12.542829 90901 sgd_solver.cpp:106] Iteration 72740, lr = 0.01
I0906 02:11:29.373394 90901 solver.cpp:228] Iteration 72750, loss = 0.0731592
I0906 02:11:29.373584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0731607 (* 1 = 0.0731607 loss)
I0906 02:11:29.373626 90901 sgd_solver.cpp:106] Iteration 72750, lr = 0.01
I0906 02:11:44.640274 90901 solver.cpp:228] Iteration 72760, loss = 0.112219
I0906 02:11:44.640368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112221 (* 1 = 0.112221 loss)
I0906 02:11:44.640386 90901 sgd_solver.cpp:106] Iteration 72760, lr = 0.01
I0906 02:12:01.383517 90901 solver.cpp:228] Iteration 72770, loss = 0.396567
I0906 02:12:01.383755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.396568 (* 1 = 0.396568 loss)
I0906 02:12:01.383788 90901 sgd_solver.cpp:106] Iteration 72770, lr = 0.01
I0906 02:12:17.936584 90901 solver.cpp:228] Iteration 72780, loss = 0.231075
I0906 02:12:17.936673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231076 (* 1 = 0.231076 loss)
I0906 02:12:17.936697 90901 sgd_solver.cpp:106] Iteration 72780, lr = 0.01
I0906 02:12:36.091078 90901 solver.cpp:228] Iteration 72790, loss = 0.426371
I0906 02:12:36.091260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426373 (* 1 = 0.426373 loss)
I0906 02:12:36.091284 90901 sgd_solver.cpp:106] Iteration 72790, lr = 0.01
I0906 02:12:52.945292 90901 solver.cpp:337] Iteration 72800, Testing net (#0)
I0906 02:14:12.140125 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.923125
I0906 02:14:12.140368 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.197068 (* 1 = 0.197068 loss)
I0906 02:14:12.723014 90901 solver.cpp:228] Iteration 72800, loss = 0.230827
I0906 02:14:12.723129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230829 (* 1 = 0.230829 loss)
I0906 02:14:12.723186 90901 sgd_solver.cpp:106] Iteration 72800, lr = 0.01
I0906 02:14:24.956084 90901 solver.cpp:228] Iteration 72810, loss = 0.18665
I0906 02:14:24.956181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186651 (* 1 = 0.186651 loss)
I0906 02:14:24.956203 90901 sgd_solver.cpp:106] Iteration 72810, lr = 0.01
I0906 02:14:34.849722 90901 solver.cpp:228] Iteration 72820, loss = 0.255549
I0906 02:14:34.849812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255551 (* 1 = 0.255551 loss)
I0906 02:14:34.849831 90901 sgd_solver.cpp:106] Iteration 72820, lr = 0.01
I0906 02:14:43.936831 90901 solver.cpp:228] Iteration 72830, loss = 0.543727
I0906 02:14:43.937059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543729 (* 1 = 0.543729 loss)
I0906 02:14:43.937088 90901 sgd_solver.cpp:106] Iteration 72830, lr = 0.01
I0906 02:14:52.641579 90901 solver.cpp:228] Iteration 72840, loss = 0.14341
I0906 02:14:52.641685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143412 (* 1 = 0.143412 loss)
I0906 02:14:52.641712 90901 sgd_solver.cpp:106] Iteration 72840, lr = 0.01
I0906 02:15:01.502418 90901 solver.cpp:228] Iteration 72850, loss = 0.0390935
I0906 02:15:01.502495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0390951 (* 1 = 0.0390951 loss)
I0906 02:15:01.502522 90901 sgd_solver.cpp:106] Iteration 72850, lr = 0.01
I0906 02:15:09.828352 90901 solver.cpp:228] Iteration 72860, loss = 0.316393
I0906 02:15:09.828429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316394 (* 1 = 0.316394 loss)
I0906 02:15:09.828446 90901 sgd_solver.cpp:106] Iteration 72860, lr = 0.01
I0906 02:15:19.388546 90901 solver.cpp:228] Iteration 72870, loss = 0.140026
I0906 02:15:19.395488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140028 (* 1 = 0.140028 loss)
I0906 02:15:19.395534 90901 sgd_solver.cpp:106] Iteration 72870, lr = 0.01
I0906 02:15:27.204751 90901 solver.cpp:228] Iteration 72880, loss = 0.117853
I0906 02:15:27.204876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117855 (* 1 = 0.117855 loss)
I0906 02:15:27.204905 90901 sgd_solver.cpp:106] Iteration 72880, lr = 0.01
I0906 02:15:35.370720 90901 solver.cpp:228] Iteration 72890, loss = 0.052574
I0906 02:15:35.370795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0525756 (* 1 = 0.0525756 loss)
I0906 02:15:35.370815 90901 sgd_solver.cpp:106] Iteration 72890, lr = 0.01
I0906 02:15:44.022495 90901 solver.cpp:228] Iteration 72900, loss = 0.237908
I0906 02:15:44.022570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23791 (* 1 = 0.23791 loss)
I0906 02:15:44.022588 90901 sgd_solver.cpp:106] Iteration 72900, lr = 0.01
I0906 02:15:52.223738 90901 solver.cpp:228] Iteration 72910, loss = 0.142373
I0906 02:15:52.224066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142374 (* 1 = 0.142374 loss)
I0906 02:15:52.224097 90901 sgd_solver.cpp:106] Iteration 72910, lr = 0.01
I0906 02:16:00.986351 90901 solver.cpp:228] Iteration 72920, loss = 0.021602
I0906 02:16:00.986430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0216036 (* 1 = 0.0216036 loss)
I0906 02:16:00.986449 90901 sgd_solver.cpp:106] Iteration 72920, lr = 0.01
I0906 02:16:10.121625 90901 solver.cpp:228] Iteration 72930, loss = 0.0931652
I0906 02:16:10.121743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0931668 (* 1 = 0.0931668 loss)
I0906 02:16:10.121774 90901 sgd_solver.cpp:106] Iteration 72930, lr = 0.01
I0906 02:16:21.897380 90901 solver.cpp:228] Iteration 72940, loss = 0.0161309
I0906 02:16:21.897471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0161325 (* 1 = 0.0161325 loss)
I0906 02:16:21.897497 90901 sgd_solver.cpp:106] Iteration 72940, lr = 0.01
I0906 02:16:32.635740 90901 solver.cpp:228] Iteration 72950, loss = 0.0500977
I0906 02:16:32.636507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0500994 (* 1 = 0.0500994 loss)
I0906 02:16:32.636543 90901 sgd_solver.cpp:106] Iteration 72950, lr = 0.01
I0906 02:16:44.497035 90901 solver.cpp:228] Iteration 72960, loss = 0.241658
I0906 02:16:44.497124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241659 (* 1 = 0.241659 loss)
I0906 02:16:44.497149 90901 sgd_solver.cpp:106] Iteration 72960, lr = 0.01
I0906 02:16:54.939245 90901 solver.cpp:228] Iteration 72970, loss = 0.219171
I0906 02:16:54.939357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219173 (* 1 = 0.219173 loss)
I0906 02:16:54.939383 90901 sgd_solver.cpp:106] Iteration 72970, lr = 0.01
I0906 02:17:05.056818 90901 solver.cpp:228] Iteration 72980, loss = 0.139736
I0906 02:17:05.066704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139737 (* 1 = 0.139737 loss)
I0906 02:17:05.066725 90901 sgd_solver.cpp:106] Iteration 72980, lr = 0.01
I0906 02:17:16.096746 90901 solver.cpp:228] Iteration 72990, loss = 0.0221546
I0906 02:17:16.097007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0221562 (* 1 = 0.0221562 loss)
I0906 02:17:16.097040 90901 sgd_solver.cpp:106] Iteration 72990, lr = 0.01
I0906 02:17:27.046861 90901 solver.cpp:228] Iteration 73000, loss = 0.350447
I0906 02:17:27.046939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350448 (* 1 = 0.350448 loss)
I0906 02:17:27.046957 90901 sgd_solver.cpp:106] Iteration 73000, lr = 0.01
I0906 02:17:37.507846 90901 solver.cpp:228] Iteration 73010, loss = 0.213928
I0906 02:17:37.510743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21393 (* 1 = 0.21393 loss)
I0906 02:17:37.510772 90901 sgd_solver.cpp:106] Iteration 73010, lr = 0.01
I0906 02:17:49.743468 90901 solver.cpp:228] Iteration 73020, loss = 0.145332
I0906 02:17:49.743584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145334 (* 1 = 0.145334 loss)
I0906 02:17:49.743609 90901 sgd_solver.cpp:106] Iteration 73020, lr = 0.01
I0906 02:18:00.658300 90901 solver.cpp:228] Iteration 73030, loss = 0.192191
I0906 02:18:00.658435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192192 (* 1 = 0.192192 loss)
I0906 02:18:00.658465 90901 sgd_solver.cpp:106] Iteration 73030, lr = 0.01
I0906 02:18:11.542074 90901 solver.cpp:228] Iteration 73040, loss = 0.0773026
I0906 02:18:11.542325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0773043 (* 1 = 0.0773043 loss)
I0906 02:18:11.542349 90901 sgd_solver.cpp:106] Iteration 73040, lr = 0.01
I0906 02:18:22.232887 90901 solver.cpp:228] Iteration 73050, loss = 0.16499
I0906 02:18:22.233053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164992 (* 1 = 0.164992 loss)
I0906 02:18:22.233094 90901 sgd_solver.cpp:106] Iteration 73050, lr = 0.01
I0906 02:18:33.431970 90901 solver.cpp:228] Iteration 73060, loss = 0.0428442
I0906 02:18:33.432128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0428458 (* 1 = 0.0428458 loss)
I0906 02:18:33.432153 90901 sgd_solver.cpp:106] Iteration 73060, lr = 0.01
I0906 02:18:46.253978 90901 solver.cpp:228] Iteration 73070, loss = 0.140866
I0906 02:18:46.254266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140867 (* 1 = 0.140867 loss)
I0906 02:18:46.254307 90901 sgd_solver.cpp:106] Iteration 73070, lr = 0.01
I0906 02:18:56.991230 90901 solver.cpp:228] Iteration 73080, loss = 0.0987607
I0906 02:18:56.991328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0987623 (* 1 = 0.0987623 loss)
I0906 02:18:56.991353 90901 sgd_solver.cpp:106] Iteration 73080, lr = 0.01
I0906 02:19:08.221812 90901 solver.cpp:228] Iteration 73090, loss = 0.239343
I0906 02:19:08.221932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239345 (* 1 = 0.239345 loss)
I0906 02:19:08.221961 90901 sgd_solver.cpp:106] Iteration 73090, lr = 0.01
I0906 02:19:19.937185 90901 solver.cpp:228] Iteration 73100, loss = 0.435476
I0906 02:19:19.937434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435478 (* 1 = 0.435478 loss)
I0906 02:19:19.937455 90901 sgd_solver.cpp:106] Iteration 73100, lr = 0.01
I0906 02:19:28.648690 90901 solver.cpp:228] Iteration 73110, loss = 0.28565
I0906 02:19:28.648813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285652 (* 1 = 0.285652 loss)
I0906 02:19:28.648838 90901 sgd_solver.cpp:106] Iteration 73110, lr = 0.01
I0906 02:19:37.606081 90901 solver.cpp:228] Iteration 73120, loss = 0.209841
I0906 02:19:37.606192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209843 (* 1 = 0.209843 loss)
I0906 02:19:37.606226 90901 sgd_solver.cpp:106] Iteration 73120, lr = 0.01
I0906 02:19:49.170280 90901 solver.cpp:228] Iteration 73130, loss = 0.0811391
I0906 02:19:49.170449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0811408 (* 1 = 0.0811408 loss)
I0906 02:19:49.170487 90901 sgd_solver.cpp:106] Iteration 73130, lr = 0.01
I0906 02:20:00.642222 90901 solver.cpp:228] Iteration 73140, loss = 0.364445
I0906 02:20:00.642415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364446 (* 1 = 0.364446 loss)
I0906 02:20:00.642433 90901 sgd_solver.cpp:106] Iteration 73140, lr = 0.01
I0906 02:20:12.836249 90901 solver.cpp:228] Iteration 73150, loss = 0.21269
I0906 02:20:12.836405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212692 (* 1 = 0.212692 loss)
I0906 02:20:12.836433 90901 sgd_solver.cpp:106] Iteration 73150, lr = 0.01
I0906 02:20:22.887588 90901 solver.cpp:228] Iteration 73160, loss = 0.192203
I0906 02:20:22.887673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192205 (* 1 = 0.192205 loss)
I0906 02:20:22.887693 90901 sgd_solver.cpp:106] Iteration 73160, lr = 0.01
I0906 02:20:33.578454 90901 solver.cpp:228] Iteration 73170, loss = 0.0969067
I0906 02:20:33.578761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0969085 (* 1 = 0.0969085 loss)
I0906 02:20:33.578788 90901 sgd_solver.cpp:106] Iteration 73170, lr = 0.01
I0906 02:20:44.577911 90901 solver.cpp:228] Iteration 73180, loss = 0.101352
I0906 02:20:44.577996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101354 (* 1 = 0.101354 loss)
I0906 02:20:44.578014 90901 sgd_solver.cpp:106] Iteration 73180, lr = 0.01
I0906 02:20:54.903996 90901 solver.cpp:228] Iteration 73190, loss = 0.0453027
I0906 02:20:54.904109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0453045 (* 1 = 0.0453045 loss)
I0906 02:20:54.904135 90901 sgd_solver.cpp:106] Iteration 73190, lr = 0.01
I0906 02:21:05.562973 90901 solver.cpp:228] Iteration 73200, loss = 0.0885485
I0906 02:21:05.566740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0885503 (* 1 = 0.0885503 loss)
I0906 02:21:05.566792 90901 sgd_solver.cpp:106] Iteration 73200, lr = 0.01
I0906 02:21:13.383793 90901 solver.cpp:228] Iteration 73210, loss = 0.0250238
I0906 02:21:13.383913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0250256 (* 1 = 0.0250256 loss)
I0906 02:21:13.383936 90901 sgd_solver.cpp:106] Iteration 73210, lr = 0.01
I0906 02:21:21.737843 90901 solver.cpp:228] Iteration 73220, loss = 0.107586
I0906 02:21:21.737944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107588 (* 1 = 0.107588 loss)
I0906 02:21:21.737970 90901 sgd_solver.cpp:106] Iteration 73220, lr = 0.01
I0906 02:21:30.122313 90901 solver.cpp:228] Iteration 73230, loss = 0.176056
I0906 02:21:30.122437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176058 (* 1 = 0.176058 loss)
I0906 02:21:30.122473 90901 sgd_solver.cpp:106] Iteration 73230, lr = 0.01
I0906 02:21:40.043866 90901 solver.cpp:228] Iteration 73240, loss = 0.0853102
I0906 02:21:40.044198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853121 (* 1 = 0.0853121 loss)
I0906 02:21:40.044222 90901 sgd_solver.cpp:106] Iteration 73240, lr = 0.01
I0906 02:21:50.574990 90901 solver.cpp:228] Iteration 73250, loss = 0.840449
I0906 02:21:50.575103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.840451 (* 1 = 0.840451 loss)
I0906 02:21:50.575140 90901 sgd_solver.cpp:106] Iteration 73250, lr = 0.01
I0906 02:22:01.318505 90901 solver.cpp:228] Iteration 73260, loss = 0.308996
I0906 02:22:01.318706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308998 (* 1 = 0.308998 loss)
I0906 02:22:01.318737 90901 sgd_solver.cpp:106] Iteration 73260, lr = 0.01
I0906 02:22:12.059408 90901 solver.cpp:228] Iteration 73270, loss = 0.136856
I0906 02:22:12.059782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136858 (* 1 = 0.136858 loss)
I0906 02:22:12.059814 90901 sgd_solver.cpp:106] Iteration 73270, lr = 0.01
I0906 02:22:22.915740 90901 solver.cpp:228] Iteration 73280, loss = 0.33715
I0906 02:22:22.915810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337152 (* 1 = 0.337152 loss)
I0906 02:22:22.915832 90901 sgd_solver.cpp:106] Iteration 73280, lr = 0.01
I0906 02:22:33.980665 90901 solver.cpp:228] Iteration 73290, loss = 0.164133
I0906 02:22:33.980820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164135 (* 1 = 0.164135 loss)
I0906 02:22:33.980867 90901 sgd_solver.cpp:106] Iteration 73290, lr = 0.01
I0906 02:22:44.722398 90901 solver.cpp:228] Iteration 73300, loss = 0.114977
I0906 02:22:44.722621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114979 (* 1 = 0.114979 loss)
I0906 02:22:44.722654 90901 sgd_solver.cpp:106] Iteration 73300, lr = 0.01
I0906 02:22:55.335889 90901 solver.cpp:228] Iteration 73310, loss = 0.197426
I0906 02:22:55.336045 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197428 (* 1 = 0.197428 loss)
I0906 02:22:55.336076 90901 sgd_solver.cpp:106] Iteration 73310, lr = 0.01
I0906 02:23:07.443279 90901 solver.cpp:228] Iteration 73320, loss = 0.247625
I0906 02:23:07.443359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247626 (* 1 = 0.247626 loss)
I0906 02:23:07.443377 90901 sgd_solver.cpp:106] Iteration 73320, lr = 0.01
I0906 02:23:19.214812 90901 solver.cpp:228] Iteration 73330, loss = 0.0795102
I0906 02:23:19.218726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.079512 (* 1 = 0.079512 loss)
I0906 02:23:19.218775 90901 sgd_solver.cpp:106] Iteration 73330, lr = 0.01
I0906 02:23:32.489047 90901 solver.cpp:228] Iteration 73340, loss = 0.0930409
I0906 02:23:32.489128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0930426 (* 1 = 0.0930426 loss)
I0906 02:23:32.489147 90901 sgd_solver.cpp:106] Iteration 73340, lr = 0.01
I0906 02:23:41.982625 90901 solver.cpp:228] Iteration 73350, loss = 0.215994
I0906 02:23:41.982749 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215996 (* 1 = 0.215996 loss)
I0906 02:23:41.982782 90901 sgd_solver.cpp:106] Iteration 73350, lr = 0.01
I0906 02:23:52.608654 90901 solver.cpp:228] Iteration 73360, loss = 0.103189
I0906 02:23:52.608916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103191 (* 1 = 0.103191 loss)
I0906 02:23:52.608952 90901 sgd_solver.cpp:106] Iteration 73360, lr = 0.01
I0906 02:24:03.406720 90901 solver.cpp:228] Iteration 73370, loss = 0.077884
I0906 02:24:03.406810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0778857 (* 1 = 0.0778857 loss)
I0906 02:24:03.406833 90901 sgd_solver.cpp:106] Iteration 73370, lr = 0.01
I0906 02:24:14.521762 90901 solver.cpp:228] Iteration 73380, loss = 0.0950346
I0906 02:24:14.521837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0950363 (* 1 = 0.0950363 loss)
I0906 02:24:14.521862 90901 sgd_solver.cpp:106] Iteration 73380, lr = 0.01
I0906 02:24:26.657459 90901 solver.cpp:228] Iteration 73390, loss = 0.143587
I0906 02:24:26.657882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143588 (* 1 = 0.143588 loss)
I0906 02:24:26.657927 90901 sgd_solver.cpp:106] Iteration 73390, lr = 0.01
I0906 02:24:37.579551 90901 solver.cpp:228] Iteration 73400, loss = 0.13747
I0906 02:24:37.579675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137472 (* 1 = 0.137472 loss)
I0906 02:24:37.579702 90901 sgd_solver.cpp:106] Iteration 73400, lr = 0.01
I0906 02:24:48.758832 90901 solver.cpp:228] Iteration 73410, loss = 0.0401257
I0906 02:24:48.758955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0401273 (* 1 = 0.0401273 loss)
I0906 02:24:48.758980 90901 sgd_solver.cpp:106] Iteration 73410, lr = 0.01
I0906 02:24:59.714973 90901 solver.cpp:228] Iteration 73420, loss = 0.120848
I0906 02:24:59.715226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120849 (* 1 = 0.120849 loss)
I0906 02:24:59.715246 90901 sgd_solver.cpp:106] Iteration 73420, lr = 0.01
I0906 02:25:11.135792 90901 solver.cpp:228] Iteration 73430, loss = 0.0401537
I0906 02:25:11.135900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0401554 (* 1 = 0.0401554 loss)
I0906 02:25:11.135921 90901 sgd_solver.cpp:106] Iteration 73430, lr = 0.01
I0906 02:25:23.019364 90901 solver.cpp:228] Iteration 73440, loss = 0.124449
I0906 02:25:23.019456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124451 (* 1 = 0.124451 loss)
I0906 02:25:23.019482 90901 sgd_solver.cpp:106] Iteration 73440, lr = 0.01
I0906 02:25:33.831048 90901 solver.cpp:228] Iteration 73450, loss = 0.122446
I0906 02:25:33.831367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122447 (* 1 = 0.122447 loss)
I0906 02:25:33.831408 90901 sgd_solver.cpp:106] Iteration 73450, lr = 0.01
I0906 02:25:42.273073 90901 solver.cpp:228] Iteration 73460, loss = 0.15356
I0906 02:25:42.273165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153561 (* 1 = 0.153561 loss)
I0906 02:25:42.273197 90901 sgd_solver.cpp:106] Iteration 73460, lr = 0.01
I0906 02:25:52.637141 90901 solver.cpp:228] Iteration 73470, loss = 0.265019
I0906 02:25:52.637238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265021 (* 1 = 0.265021 loss)
I0906 02:25:52.637259 90901 sgd_solver.cpp:106] Iteration 73470, lr = 0.01
I0906 02:26:02.112738 90901 solver.cpp:228] Iteration 73480, loss = 0.0726585
I0906 02:26:02.112856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0726602 (* 1 = 0.0726602 loss)
I0906 02:26:02.112879 90901 sgd_solver.cpp:106] Iteration 73480, lr = 0.01
I0906 02:26:11.543756 90901 solver.cpp:228] Iteration 73490, loss = 0.0814893
I0906 02:26:11.543967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.081491 (* 1 = 0.081491 loss)
I0906 02:26:11.543984 90901 sgd_solver.cpp:106] Iteration 73490, lr = 0.01
I0906 02:26:21.458483 90901 solver.cpp:228] Iteration 73500, loss = 0.0231882
I0906 02:26:21.458581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0231899 (* 1 = 0.0231899 loss)
I0906 02:26:21.458601 90901 sgd_solver.cpp:106] Iteration 73500, lr = 0.01
I0906 02:26:31.764716 90901 solver.cpp:228] Iteration 73510, loss = 0.109156
I0906 02:26:31.764812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109158 (* 1 = 0.109158 loss)
I0906 02:26:31.764833 90901 sgd_solver.cpp:106] Iteration 73510, lr = 0.01
I0906 02:26:43.243907 90901 solver.cpp:228] Iteration 73520, loss = 0.0702004
I0906 02:26:43.244256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.070202 (* 1 = 0.070202 loss)
I0906 02:26:43.244277 90901 sgd_solver.cpp:106] Iteration 73520, lr = 0.01
I0906 02:26:54.555492 90901 solver.cpp:228] Iteration 73530, loss = 0.0885198
I0906 02:26:54.555569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0885215 (* 1 = 0.0885215 loss)
I0906 02:26:54.555591 90901 sgd_solver.cpp:106] Iteration 73530, lr = 0.01
I0906 02:27:05.988462 90901 solver.cpp:228] Iteration 73540, loss = 0.355096
I0906 02:27:05.988637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355097 (* 1 = 0.355097 loss)
I0906 02:27:05.988664 90901 sgd_solver.cpp:106] Iteration 73540, lr = 0.01
I0906 02:27:18.872905 90901 solver.cpp:228] Iteration 73550, loss = 0.0579846
I0906 02:27:18.873132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0579862 (* 1 = 0.0579862 loss)
I0906 02:27:18.873150 90901 sgd_solver.cpp:106] Iteration 73550, lr = 0.01
I0906 02:27:29.094583 90901 solver.cpp:228] Iteration 73560, loss = 0.133416
I0906 02:27:29.094722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133417 (* 1 = 0.133417 loss)
I0906 02:27:29.094748 90901 sgd_solver.cpp:106] Iteration 73560, lr = 0.01
I0906 02:27:41.174271 90901 solver.cpp:228] Iteration 73570, loss = 0.323303
I0906 02:27:41.174388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.323305 (* 1 = 0.323305 loss)
I0906 02:27:41.174415 90901 sgd_solver.cpp:106] Iteration 73570, lr = 0.01
I0906 02:27:52.675863 90901 solver.cpp:228] Iteration 73580, loss = 0.251899
I0906 02:27:52.676064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251901 (* 1 = 0.251901 loss)
I0906 02:27:52.676084 90901 sgd_solver.cpp:106] Iteration 73580, lr = 0.01
I0906 02:28:03.075176 90901 solver.cpp:228] Iteration 73590, loss = 0.15654
I0906 02:28:03.075330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156542 (* 1 = 0.156542 loss)
I0906 02:28:03.075361 90901 sgd_solver.cpp:106] Iteration 73590, lr = 0.01
I0906 02:28:14.300091 90901 solver.cpp:337] Iteration 73600, Testing net (#0)
I0906 02:29:28.810860 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.928125
I0906 02:29:28.813465 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.191948 (* 1 = 0.191948 loss)
I0906 02:29:29.020154 90901 solver.cpp:228] Iteration 73600, loss = 0.0826845
I0906 02:29:29.020244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0826861 (* 1 = 0.0826861 loss)
I0906 02:29:29.020267 90901 sgd_solver.cpp:106] Iteration 73600, lr = 0.01
I0906 02:29:38.107941 90901 solver.cpp:228] Iteration 73610, loss = 0.0758242
I0906 02:29:38.108036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0758258 (* 1 = 0.0758258 loss)
I0906 02:29:38.108053 90901 sgd_solver.cpp:106] Iteration 73610, lr = 0.01
I0906 02:29:46.936504 90901 solver.cpp:228] Iteration 73620, loss = 0.0744998
I0906 02:29:46.936630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0745013 (* 1 = 0.0745013 loss)
I0906 02:29:46.936664 90901 sgd_solver.cpp:106] Iteration 73620, lr = 0.01
I0906 02:29:56.494748 90901 solver.cpp:228] Iteration 73630, loss = 0.206157
I0906 02:29:56.494834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206159 (* 1 = 0.206159 loss)
I0906 02:29:56.494855 90901 sgd_solver.cpp:106] Iteration 73630, lr = 0.01
I0906 02:30:05.050302 90901 solver.cpp:228] Iteration 73640, loss = 0.0937784
I0906 02:30:05.050714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0937799 (* 1 = 0.0937799 loss)
I0906 02:30:05.050745 90901 sgd_solver.cpp:106] Iteration 73640, lr = 0.01
I0906 02:30:14.449731 90901 solver.cpp:228] Iteration 73650, loss = 0.41895
I0906 02:30:14.449857 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.418951 (* 1 = 0.418951 loss)
I0906 02:30:14.449887 90901 sgd_solver.cpp:106] Iteration 73650, lr = 0.01
I0906 02:30:23.895938 90901 solver.cpp:228] Iteration 73660, loss = 0.0177513
I0906 02:30:23.896023 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0177529 (* 1 = 0.0177529 loss)
I0906 02:30:23.896040 90901 sgd_solver.cpp:106] Iteration 73660, lr = 0.01
I0906 02:30:34.267531 90901 solver.cpp:228] Iteration 73670, loss = 0.0373706
I0906 02:30:34.267644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0373721 (* 1 = 0.0373721 loss)
I0906 02:30:34.267666 90901 sgd_solver.cpp:106] Iteration 73670, lr = 0.01
I0906 02:30:45.090802 90901 solver.cpp:228] Iteration 73680, loss = 0.0984996
I0906 02:30:45.091553 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0985012 (* 1 = 0.0985012 loss)
I0906 02:30:45.091621 90901 sgd_solver.cpp:106] Iteration 73680, lr = 0.01
I0906 02:30:57.098495 90901 solver.cpp:228] Iteration 73690, loss = 0.152904
I0906 02:30:57.098582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152906 (* 1 = 0.152906 loss)
I0906 02:30:57.098600 90901 sgd_solver.cpp:106] Iteration 73690, lr = 0.01
I0906 02:31:07.573804 90901 solver.cpp:228] Iteration 73700, loss = 0.634067
I0906 02:31:07.573956 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.634068 (* 1 = 0.634068 loss)
I0906 02:31:07.573992 90901 sgd_solver.cpp:106] Iteration 73700, lr = 0.01
I0906 02:31:17.896322 90901 solver.cpp:228] Iteration 73710, loss = 0.271239
I0906 02:31:17.896513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27124 (* 1 = 0.27124 loss)
I0906 02:31:17.896533 90901 sgd_solver.cpp:106] Iteration 73710, lr = 0.01
I0906 02:31:28.405783 90901 solver.cpp:228] Iteration 73720, loss = 0.182342
I0906 02:31:28.405901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182344 (* 1 = 0.182344 loss)
I0906 02:31:28.405931 90901 sgd_solver.cpp:106] Iteration 73720, lr = 0.01
I0906 02:31:37.737378 90901 solver.cpp:228] Iteration 73730, loss = 0.202433
I0906 02:31:37.737524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202435 (* 1 = 0.202435 loss)
I0906 02:31:37.737563 90901 sgd_solver.cpp:106] Iteration 73730, lr = 0.01
I0906 02:31:49.316543 90901 solver.cpp:228] Iteration 73740, loss = 0.187452
I0906 02:31:49.316870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187454 (* 1 = 0.187454 loss)
I0906 02:31:49.316893 90901 sgd_solver.cpp:106] Iteration 73740, lr = 0.01
I0906 02:31:59.797523 90901 solver.cpp:228] Iteration 73750, loss = 0.03517
I0906 02:31:59.797610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0351716 (* 1 = 0.0351716 loss)
I0906 02:31:59.797632 90901 sgd_solver.cpp:106] Iteration 73750, lr = 0.01
I0906 02:32:07.579723 90901 solver.cpp:228] Iteration 73760, loss = 0.202524
I0906 02:32:07.579864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202526 (* 1 = 0.202526 loss)
I0906 02:32:07.579898 90901 sgd_solver.cpp:106] Iteration 73760, lr = 0.01
I0906 02:32:16.387778 90901 solver.cpp:228] Iteration 73770, loss = 0.284438
I0906 02:32:16.387863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28444 (* 1 = 0.28444 loss)
I0906 02:32:16.387889 90901 sgd_solver.cpp:106] Iteration 73770, lr = 0.01
I0906 02:32:24.130175 90901 solver.cpp:228] Iteration 73780, loss = 0.0899279
I0906 02:32:24.140131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0899295 (* 1 = 0.0899295 loss)
I0906 02:32:24.140229 90901 sgd_solver.cpp:106] Iteration 73780, lr = 0.01
I0906 02:32:33.682726 90901 solver.cpp:228] Iteration 73790, loss = 0.165109
I0906 02:32:33.682862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165111 (* 1 = 0.165111 loss)
I0906 02:32:33.682885 90901 sgd_solver.cpp:106] Iteration 73790, lr = 0.01
I0906 02:32:43.794242 90901 solver.cpp:228] Iteration 73800, loss = 0.116893
I0906 02:32:43.794337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116894 (* 1 = 0.116894 loss)
I0906 02:32:43.794366 90901 sgd_solver.cpp:106] Iteration 73800, lr = 0.01
I0906 02:32:56.320788 90901 solver.cpp:228] Iteration 73810, loss = 0.122133
I0906 02:32:56.321203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122135 (* 1 = 0.122135 loss)
I0906 02:32:56.321224 90901 sgd_solver.cpp:106] Iteration 73810, lr = 0.01
I0906 02:33:07.437292 90901 solver.cpp:228] Iteration 73820, loss = 0.0673352
I0906 02:33:07.437413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0673367 (* 1 = 0.0673367 loss)
I0906 02:33:07.437439 90901 sgd_solver.cpp:106] Iteration 73820, lr = 0.01
I0906 02:33:19.170639 90901 solver.cpp:228] Iteration 73830, loss = 0.0668964
I0906 02:33:19.170742 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.066898 (* 1 = 0.066898 loss)
I0906 02:33:19.170764 90901 sgd_solver.cpp:106] Iteration 73830, lr = 0.01
I0906 02:33:29.737861 90901 solver.cpp:228] Iteration 73840, loss = 0.315246
I0906 02:33:29.738060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315247 (* 1 = 0.315247 loss)
I0906 02:33:29.738080 90901 sgd_solver.cpp:106] Iteration 73840, lr = 0.01
I0906 02:33:39.700661 90901 solver.cpp:228] Iteration 73850, loss = 0.118367
I0906 02:33:39.700754 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118369 (* 1 = 0.118369 loss)
I0906 02:33:39.700772 90901 sgd_solver.cpp:106] Iteration 73850, lr = 0.01
I0906 02:33:50.830456 90901 solver.cpp:228] Iteration 73860, loss = 0.0776811
I0906 02:33:50.830694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0776827 (* 1 = 0.0776827 loss)
I0906 02:33:50.830749 90901 sgd_solver.cpp:106] Iteration 73860, lr = 0.01
I0906 02:34:02.573552 90901 solver.cpp:228] Iteration 73870, loss = 0.0139095
I0906 02:34:02.574460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.013911 (* 1 = 0.013911 loss)
I0906 02:34:02.574491 90901 sgd_solver.cpp:106] Iteration 73870, lr = 0.01
I0906 02:34:11.285140 90901 solver.cpp:228] Iteration 73880, loss = 0.120284
I0906 02:34:11.285255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120286 (* 1 = 0.120286 loss)
I0906 02:34:11.285279 90901 sgd_solver.cpp:106] Iteration 73880, lr = 0.01
I0906 02:34:21.374406 90901 solver.cpp:228] Iteration 73890, loss = 0.277103
I0906 02:34:21.374541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277105 (* 1 = 0.277105 loss)
I0906 02:34:21.374567 90901 sgd_solver.cpp:106] Iteration 73890, lr = 0.01
I0906 02:34:32.533869 90901 solver.cpp:228] Iteration 73900, loss = 0.170689
I0906 02:34:32.533988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170691 (* 1 = 0.170691 loss)
I0906 02:34:32.534013 90901 sgd_solver.cpp:106] Iteration 73900, lr = 0.01
I0906 02:34:42.282714 90901 solver.cpp:228] Iteration 73910, loss = 0.230959
I0906 02:34:42.282918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230961 (* 1 = 0.230961 loss)
I0906 02:34:42.282944 90901 sgd_solver.cpp:106] Iteration 73910, lr = 0.01
I0906 02:34:51.875752 90901 solver.cpp:228] Iteration 73920, loss = 0.433992
I0906 02:34:51.875834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.433993 (* 1 = 0.433993 loss)
I0906 02:34:51.875852 90901 sgd_solver.cpp:106] Iteration 73920, lr = 0.01
I0906 02:35:02.530937 90901 solver.cpp:228] Iteration 73930, loss = 0.131121
I0906 02:35:02.531044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131123 (* 1 = 0.131123 loss)
I0906 02:35:02.531070 90901 sgd_solver.cpp:106] Iteration 73930, lr = 0.01
I0906 02:35:12.583042 90901 solver.cpp:228] Iteration 73940, loss = 0.189671
I0906 02:35:12.592751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189673 (* 1 = 0.189673 loss)
I0906 02:35:12.592798 90901 sgd_solver.cpp:106] Iteration 73940, lr = 0.01
I0906 02:35:24.232883 90901 solver.cpp:228] Iteration 73950, loss = 0.203106
I0906 02:35:24.233042 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203107 (* 1 = 0.203107 loss)
I0906 02:35:24.233067 90901 sgd_solver.cpp:106] Iteration 73950, lr = 0.01
I0906 02:35:34.089823 90901 solver.cpp:228] Iteration 73960, loss = 0.359554
I0906 02:35:34.089887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359556 (* 1 = 0.359556 loss)
I0906 02:35:34.089903 90901 sgd_solver.cpp:106] Iteration 73960, lr = 0.01
I0906 02:35:45.327913 90901 solver.cpp:228] Iteration 73970, loss = 0.131916
I0906 02:35:45.328351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131918 (* 1 = 0.131918 loss)
I0906 02:35:45.328378 90901 sgd_solver.cpp:106] Iteration 73970, lr = 0.01
I0906 02:35:56.359400 90901 solver.cpp:228] Iteration 73980, loss = 0.0850578
I0906 02:35:56.359503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0850593 (* 1 = 0.0850593 loss)
I0906 02:35:56.359524 90901 sgd_solver.cpp:106] Iteration 73980, lr = 0.01
I0906 02:36:06.629053 90901 solver.cpp:228] Iteration 73990, loss = 0.143947
I0906 02:36:06.629227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143948 (* 1 = 0.143948 loss)
I0906 02:36:06.629258 90901 sgd_solver.cpp:106] Iteration 73990, lr = 0.01
I0906 02:36:17.638718 90901 solver.cpp:228] Iteration 74000, loss = 0.0958435
I0906 02:36:17.639866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.095845 (* 1 = 0.095845 loss)
I0906 02:36:17.639907 90901 sgd_solver.cpp:106] Iteration 74000, lr = 0.01
I0906 02:36:26.612409 90901 solver.cpp:228] Iteration 74010, loss = 0.0576893
I0906 02:36:26.612484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0576908 (* 1 = 0.0576908 loss)
I0906 02:36:26.612505 90901 sgd_solver.cpp:106] Iteration 74010, lr = 0.01
I0906 02:36:35.287377 90901 solver.cpp:228] Iteration 74020, loss = 0.406084
I0906 02:36:35.287456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.406085 (* 1 = 0.406085 loss)
I0906 02:36:35.287473 90901 sgd_solver.cpp:106] Iteration 74020, lr = 0.01
I0906 02:36:43.610759 90901 solver.cpp:228] Iteration 74030, loss = 0.177722
I0906 02:36:43.610831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177723 (* 1 = 0.177723 loss)
I0906 02:36:43.610848 90901 sgd_solver.cpp:106] Iteration 74030, lr = 0.01
I0906 02:36:52.333096 90901 solver.cpp:228] Iteration 74040, loss = 0.189663
I0906 02:36:52.333307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189664 (* 1 = 0.189664 loss)
I0906 02:36:52.333333 90901 sgd_solver.cpp:106] Iteration 74040, lr = 0.01
I0906 02:37:00.496489 90901 solver.cpp:228] Iteration 74050, loss = 0.435697
I0906 02:37:00.496641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.435698 (* 1 = 0.435698 loss)
I0906 02:37:00.496676 90901 sgd_solver.cpp:106] Iteration 74050, lr = 0.01
I0906 02:37:08.495090 90901 solver.cpp:228] Iteration 74060, loss = 0.261555
I0906 02:37:08.495187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261557 (* 1 = 0.261557 loss)
I0906 02:37:08.495210 90901 sgd_solver.cpp:106] Iteration 74060, lr = 0.01
I0906 02:37:16.491518 90901 solver.cpp:228] Iteration 74070, loss = 0.0593614
I0906 02:37:16.491617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0593628 (* 1 = 0.0593628 loss)
I0906 02:37:16.491637 90901 sgd_solver.cpp:106] Iteration 74070, lr = 0.01
I0906 02:37:25.333158 90901 solver.cpp:228] Iteration 74080, loss = 0.053606
I0906 02:37:25.336319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0536074 (* 1 = 0.0536074 loss)
I0906 02:37:25.336343 90901 sgd_solver.cpp:106] Iteration 74080, lr = 0.01
I0906 02:37:36.267449 90901 solver.cpp:228] Iteration 74090, loss = 0.20419
I0906 02:37:36.267524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204192 (* 1 = 0.204192 loss)
I0906 02:37:36.267540 90901 sgd_solver.cpp:106] Iteration 74090, lr = 0.01
I0906 02:37:47.051314 90901 solver.cpp:228] Iteration 74100, loss = 0.288098
I0906 02:37:47.051398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2881 (* 1 = 0.2881 loss)
I0906 02:37:47.051419 90901 sgd_solver.cpp:106] Iteration 74100, lr = 0.01
I0906 02:37:58.123744 90901 solver.cpp:228] Iteration 74110, loss = 0.0878706
I0906 02:37:58.124110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0878721 (* 1 = 0.0878721 loss)
I0906 02:37:58.124130 90901 sgd_solver.cpp:106] Iteration 74110, lr = 0.01
I0906 02:38:09.082432 90901 solver.cpp:228] Iteration 74120, loss = 0.0433367
I0906 02:38:09.082547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0433382 (* 1 = 0.0433382 loss)
I0906 02:38:09.082578 90901 sgd_solver.cpp:106] Iteration 74120, lr = 0.01
I0906 02:38:19.462476 90901 solver.cpp:228] Iteration 74130, loss = 0.378806
I0906 02:38:19.462705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378808 (* 1 = 0.378808 loss)
I0906 02:38:19.462749 90901 sgd_solver.cpp:106] Iteration 74130, lr = 0.01
I0906 02:38:31.539594 90901 solver.cpp:228] Iteration 74140, loss = 0.0447457
I0906 02:38:31.540488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0447472 (* 1 = 0.0447472 loss)
I0906 02:38:31.540529 90901 sgd_solver.cpp:106] Iteration 74140, lr = 0.01
I0906 02:38:42.037077 90901 solver.cpp:228] Iteration 74150, loss = 0.138473
I0906 02:38:42.037168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138475 (* 1 = 0.138475 loss)
I0906 02:38:42.037186 90901 sgd_solver.cpp:106] Iteration 74150, lr = 0.01
I0906 02:38:51.788997 90901 solver.cpp:228] Iteration 74160, loss = 0.057251
I0906 02:38:51.789147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0572525 (* 1 = 0.0572525 loss)
I0906 02:38:51.789177 90901 sgd_solver.cpp:106] Iteration 74160, lr = 0.01
I0906 02:39:03.937799 90901 solver.cpp:228] Iteration 74170, loss = 0.170843
I0906 02:39:03.938159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170845 (* 1 = 0.170845 loss)
I0906 02:39:03.938194 90901 sgd_solver.cpp:106] Iteration 74170, lr = 0.01
I0906 02:39:13.180471 90901 solver.cpp:228] Iteration 74180, loss = 0.163712
I0906 02:39:13.180562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163714 (* 1 = 0.163714 loss)
I0906 02:39:13.180580 90901 sgd_solver.cpp:106] Iteration 74180, lr = 0.01
I0906 02:39:24.837458 90901 solver.cpp:228] Iteration 74190, loss = 0.161322
I0906 02:39:24.837589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161323 (* 1 = 0.161323 loss)
I0906 02:39:24.837615 90901 sgd_solver.cpp:106] Iteration 74190, lr = 0.01
I0906 02:39:37.120203 90901 solver.cpp:228] Iteration 74200, loss = 0.184482
I0906 02:39:37.121014 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184484 (* 1 = 0.184484 loss)
I0906 02:39:37.121039 90901 sgd_solver.cpp:106] Iteration 74200, lr = 0.01
I0906 02:39:48.304287 90901 solver.cpp:228] Iteration 74210, loss = 0.0767325
I0906 02:39:48.304517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.076734 (* 1 = 0.076734 loss)
I0906 02:39:48.304555 90901 sgd_solver.cpp:106] Iteration 74210, lr = 0.01
I0906 02:40:01.350550 90901 solver.cpp:228] Iteration 74220, loss = 0.0593633
I0906 02:40:01.350637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0593648 (* 1 = 0.0593648 loss)
I0906 02:40:01.350657 90901 sgd_solver.cpp:106] Iteration 74220, lr = 0.01
I0906 02:40:13.966668 90901 solver.cpp:228] Iteration 74230, loss = 0.155046
I0906 02:40:13.978807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155047 (* 1 = 0.155047 loss)
I0906 02:40:13.978844 90901 sgd_solver.cpp:106] Iteration 74230, lr = 0.01
I0906 02:40:25.869763 90901 solver.cpp:228] Iteration 74240, loss = 0.053124
I0906 02:40:25.869843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0531255 (* 1 = 0.0531255 loss)
I0906 02:40:25.869863 90901 sgd_solver.cpp:106] Iteration 74240, lr = 0.01
I0906 02:40:38.013630 90901 solver.cpp:228] Iteration 74250, loss = 0.0813815
I0906 02:40:38.013779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.081383 (* 1 = 0.081383 loss)
I0906 02:40:38.013799 90901 sgd_solver.cpp:106] Iteration 74250, lr = 0.01
I0906 02:40:50.439924 90901 solver.cpp:228] Iteration 74260, loss = 0.151114
I0906 02:40:50.440222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151115 (* 1 = 0.151115 loss)
I0906 02:40:50.440243 90901 sgd_solver.cpp:106] Iteration 74260, lr = 0.01
I0906 02:41:02.609521 90901 solver.cpp:228] Iteration 74270, loss = 0.270401
I0906 02:41:02.609604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270402 (* 1 = 0.270402 loss)
I0906 02:41:02.609622 90901 sgd_solver.cpp:106] Iteration 74270, lr = 0.01
I0906 02:41:15.328815 90901 solver.cpp:228] Iteration 74280, loss = 0.0978024
I0906 02:41:15.328905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0978038 (* 1 = 0.0978038 loss)
I0906 02:41:15.328927 90901 sgd_solver.cpp:106] Iteration 74280, lr = 0.01
I0906 02:41:27.129395 90901 solver.cpp:228] Iteration 74290, loss = 0.648315
I0906 02:41:27.130723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.648317 (* 1 = 0.648317 loss)
I0906 02:41:27.130772 90901 sgd_solver.cpp:106] Iteration 74290, lr = 0.01
I0906 02:41:38.671351 90901 solver.cpp:228] Iteration 74300, loss = 0.320186
I0906 02:41:38.671573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320187 (* 1 = 0.320187 loss)
I0906 02:41:38.671615 90901 sgd_solver.cpp:106] Iteration 74300, lr = 0.01
I0906 02:41:50.702455 90901 solver.cpp:228] Iteration 74310, loss = 0.497105
I0906 02:41:50.702625 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.497107 (* 1 = 0.497107 loss)
I0906 02:41:50.702678 90901 sgd_solver.cpp:106] Iteration 74310, lr = 0.01
I0906 02:42:03.025359 90901 solver.cpp:228] Iteration 74320, loss = 0.0851563
I0906 02:42:03.025570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0851576 (* 1 = 0.0851576 loss)
I0906 02:42:03.025595 90901 sgd_solver.cpp:106] Iteration 74320, lr = 0.01
I0906 02:42:13.371363 90901 solver.cpp:228] Iteration 74330, loss = 0.152947
I0906 02:42:13.371520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152949 (* 1 = 0.152949 loss)
I0906 02:42:13.371542 90901 sgd_solver.cpp:106] Iteration 74330, lr = 0.01
I0906 02:42:23.747860 90901 solver.cpp:228] Iteration 74340, loss = 0.0668479
I0906 02:42:23.747949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0668493 (* 1 = 0.0668493 loss)
I0906 02:42:23.747977 90901 sgd_solver.cpp:106] Iteration 74340, lr = 0.01
I0906 02:42:34.003574 90901 solver.cpp:228] Iteration 74350, loss = 0.139117
I0906 02:42:34.003836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139119 (* 1 = 0.139119 loss)
I0906 02:42:34.003873 90901 sgd_solver.cpp:106] Iteration 74350, lr = 0.01
I0906 02:42:43.552777 90901 solver.cpp:228] Iteration 74360, loss = 0.0328136
I0906 02:42:43.552907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0328151 (* 1 = 0.0328151 loss)
I0906 02:42:43.552938 90901 sgd_solver.cpp:106] Iteration 74360, lr = 0.01
I0906 02:42:52.233731 90901 solver.cpp:228] Iteration 74370, loss = 0.0907647
I0906 02:42:52.233814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0907661 (* 1 = 0.0907661 loss)
I0906 02:42:52.233832 90901 sgd_solver.cpp:106] Iteration 74370, lr = 0.01
I0906 02:43:01.179507 90901 solver.cpp:228] Iteration 74380, loss = 0.137122
I0906 02:43:01.179569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137124 (* 1 = 0.137124 loss)
I0906 02:43:01.179585 90901 sgd_solver.cpp:106] Iteration 74380, lr = 0.01
I0906 02:43:10.554287 90901 solver.cpp:228] Iteration 74390, loss = 0.464669
I0906 02:43:10.554502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.464671 (* 1 = 0.464671 loss)
I0906 02:43:10.554522 90901 sgd_solver.cpp:106] Iteration 74390, lr = 0.01
I0906 02:43:20.655786 90901 solver.cpp:337] Iteration 74400, Testing net (#0)
I0906 02:44:26.223036 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.920625
I0906 02:44:26.223314 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.219096 (* 1 = 0.219096 loss)
I0906 02:44:26.474138 90901 solver.cpp:228] Iteration 74400, loss = 0.243917
I0906 02:44:26.474220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243918 (* 1 = 0.243918 loss)
I0906 02:44:26.474246 90901 sgd_solver.cpp:106] Iteration 74400, lr = 0.01
I0906 02:44:38.372375 90901 solver.cpp:228] Iteration 74410, loss = 0.0797074
I0906 02:44:38.372556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0797089 (* 1 = 0.0797089 loss)
I0906 02:44:38.372589 90901 sgd_solver.cpp:106] Iteration 74410, lr = 0.01
I0906 02:44:57.722205 90901 solver.cpp:228] Iteration 74420, loss = 0.151677
I0906 02:44:57.722470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151678 (* 1 = 0.151678 loss)
I0906 02:44:57.722496 90901 sgd_solver.cpp:106] Iteration 74420, lr = 0.01
I0906 02:45:18.725605 90901 solver.cpp:228] Iteration 74430, loss = 0.453547
I0906 02:45:18.725685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453548 (* 1 = 0.453548 loss)
I0906 02:45:18.725703 90901 sgd_solver.cpp:106] Iteration 74430, lr = 0.01
I0906 02:45:40.752414 90901 solver.cpp:228] Iteration 74440, loss = 0.106665
I0906 02:45:40.752631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106666 (* 1 = 0.106666 loss)
I0906 02:45:40.752651 90901 sgd_solver.cpp:106] Iteration 74440, lr = 0.01
I0906 02:46:02.299764 90901 solver.cpp:228] Iteration 74450, loss = 0.11794
I0906 02:46:02.299834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117942 (* 1 = 0.117942 loss)
I0906 02:46:02.299851 90901 sgd_solver.cpp:106] Iteration 74450, lr = 0.01
I0906 02:46:17.668540 90901 solver.cpp:228] Iteration 74460, loss = 0.238561
I0906 02:46:17.668807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238562 (* 1 = 0.238562 loss)
I0906 02:46:17.668840 90901 sgd_solver.cpp:106] Iteration 74460, lr = 0.01
I0906 02:46:34.155293 90901 solver.cpp:228] Iteration 74470, loss = 0.057422
I0906 02:46:34.155376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0574234 (* 1 = 0.0574234 loss)
I0906 02:46:34.155393 90901 sgd_solver.cpp:106] Iteration 74470, lr = 0.01
I0906 02:46:54.945276 90901 solver.cpp:228] Iteration 74480, loss = 0.14801
I0906 02:46:54.945399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148012 (* 1 = 0.148012 loss)
I0906 02:46:54.945421 90901 sgd_solver.cpp:106] Iteration 74480, lr = 0.01
I0906 02:47:17.071946 90901 solver.cpp:228] Iteration 74490, loss = 0.0833303
I0906 02:47:17.072026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0833317 (* 1 = 0.0833317 loss)
I0906 02:47:17.072047 90901 sgd_solver.cpp:106] Iteration 74490, lr = 0.01
I0906 02:47:40.349673 90901 solver.cpp:228] Iteration 74500, loss = 0.210317
I0906 02:47:40.349824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210318 (* 1 = 0.210318 loss)
I0906 02:47:40.349858 90901 sgd_solver.cpp:106] Iteration 74500, lr = 0.01
I0906 02:48:03.646549 90901 solver.cpp:228] Iteration 74510, loss = 0.436173
I0906 02:48:03.646607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436174 (* 1 = 0.436174 loss)
I0906 02:48:03.646623 90901 sgd_solver.cpp:106] Iteration 74510, lr = 0.01
I0906 02:48:25.248744 90901 solver.cpp:228] Iteration 74520, loss = 0.296416
I0906 02:48:25.248885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296418 (* 1 = 0.296418 loss)
I0906 02:48:25.248901 90901 sgd_solver.cpp:106] Iteration 74520, lr = 0.01
I0906 02:48:46.276155 90901 solver.cpp:228] Iteration 74530, loss = 0.0940796
I0906 02:48:46.276239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0940809 (* 1 = 0.0940809 loss)
I0906 02:48:46.276262 90901 sgd_solver.cpp:106] Iteration 74530, lr = 0.01
I0906 02:49:08.431251 90901 solver.cpp:228] Iteration 74540, loss = 0.0800795
I0906 02:49:08.431504 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0800809 (* 1 = 0.0800809 loss)
I0906 02:49:08.431524 90901 sgd_solver.cpp:106] Iteration 74540, lr = 0.01
I0906 02:49:29.436566 90901 solver.cpp:228] Iteration 74550, loss = 0.252615
I0906 02:49:29.436624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252616 (* 1 = 0.252616 loss)
I0906 02:49:29.436642 90901 sgd_solver.cpp:106] Iteration 74550, lr = 0.01
I0906 02:49:52.215749 90901 solver.cpp:228] Iteration 74560, loss = 0.0666234
I0906 02:49:52.215983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0666247 (* 1 = 0.0666247 loss)
I0906 02:49:52.216001 90901 sgd_solver.cpp:106] Iteration 74560, lr = 0.01
I0906 02:50:13.640175 90901 solver.cpp:228] Iteration 74570, loss = 0.375582
I0906 02:50:13.640259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375583 (* 1 = 0.375583 loss)
I0906 02:50:13.640278 90901 sgd_solver.cpp:106] Iteration 74570, lr = 0.01
I0906 02:50:36.043630 90901 solver.cpp:228] Iteration 74580, loss = 0.20194
I0906 02:50:36.043900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201941 (* 1 = 0.201941 loss)
I0906 02:50:36.043925 90901 sgd_solver.cpp:106] Iteration 74580, lr = 0.01
I0906 02:50:51.863036 90901 solver.cpp:228] Iteration 74590, loss = 0.103937
I0906 02:50:51.863109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103938 (* 1 = 0.103938 loss)
I0906 02:50:51.863126 90901 sgd_solver.cpp:106] Iteration 74590, lr = 0.01
I0906 02:51:10.000248 90901 solver.cpp:228] Iteration 74600, loss = 0.303703
I0906 02:51:10.000414 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303704 (* 1 = 0.303704 loss)
I0906 02:51:10.000434 90901 sgd_solver.cpp:106] Iteration 74600, lr = 0.01
I0906 02:51:30.904748 90901 solver.cpp:228] Iteration 74610, loss = 0.113991
I0906 02:51:30.904830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113993 (* 1 = 0.113993 loss)
I0906 02:51:30.904852 90901 sgd_solver.cpp:106] Iteration 74610, lr = 0.01
I0906 02:51:53.223279 90901 solver.cpp:228] Iteration 74620, loss = 0.102889
I0906 02:51:53.223613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102891 (* 1 = 0.102891 loss)
I0906 02:51:53.223649 90901 sgd_solver.cpp:106] Iteration 74620, lr = 0.01
I0906 02:52:15.746143 90901 solver.cpp:228] Iteration 74630, loss = 0.125522
I0906 02:52:15.746227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125523 (* 1 = 0.125523 loss)
I0906 02:52:15.746245 90901 sgd_solver.cpp:106] Iteration 74630, lr = 0.01
I0906 02:52:37.759524 90901 solver.cpp:228] Iteration 74640, loss = 0.188509
I0906 02:52:37.759683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18851 (* 1 = 0.18851 loss)
I0906 02:52:37.759713 90901 sgd_solver.cpp:106] Iteration 74640, lr = 0.01
I0906 02:53:00.147645 90901 solver.cpp:228] Iteration 74650, loss = 0.272774
I0906 02:53:00.147718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272775 (* 1 = 0.272775 loss)
I0906 02:53:00.147735 90901 sgd_solver.cpp:106] Iteration 74650, lr = 0.01
I0906 02:53:23.022971 90901 solver.cpp:228] Iteration 74660, loss = 0.274449
I0906 02:53:23.023176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27445 (* 1 = 0.27445 loss)
I0906 02:53:23.023196 90901 sgd_solver.cpp:106] Iteration 74660, lr = 0.01
I0906 02:53:45.263221 90901 solver.cpp:228] Iteration 74670, loss = 0.17965
I0906 02:53:45.263299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179652 (* 1 = 0.179652 loss)
I0906 02:53:45.263316 90901 sgd_solver.cpp:106] Iteration 74670, lr = 0.01
I0906 02:54:05.919525 90901 solver.cpp:228] Iteration 74680, loss = 0.12385
I0906 02:54:05.919770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123851 (* 1 = 0.123851 loss)
I0906 02:54:05.919796 90901 sgd_solver.cpp:106] Iteration 74680, lr = 0.01
I0906 02:54:25.759151 90901 solver.cpp:228] Iteration 74690, loss = 0.0909892
I0906 02:54:25.759228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0909908 (* 1 = 0.0909908 loss)
I0906 02:54:25.759244 90901 sgd_solver.cpp:106] Iteration 74690, lr = 0.01
I0906 02:54:46.291896 90901 solver.cpp:228] Iteration 74700, loss = 0.0729987
I0906 02:54:46.292117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0730003 (* 1 = 0.0730003 loss)
I0906 02:54:46.292138 90901 sgd_solver.cpp:106] Iteration 74700, lr = 0.01
I0906 02:55:07.967200 90901 solver.cpp:228] Iteration 74710, loss = 0.0976701
I0906 02:55:07.967278 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0976717 (* 1 = 0.0976717 loss)
I0906 02:55:07.967295 90901 sgd_solver.cpp:106] Iteration 74710, lr = 0.01
I0906 02:55:29.561847 90901 solver.cpp:228] Iteration 74720, loss = 0.162117
I0906 02:55:29.562016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162118 (* 1 = 0.162118 loss)
I0906 02:55:29.562059 90901 sgd_solver.cpp:106] Iteration 74720, lr = 0.01
I0906 02:55:51.266383 90901 solver.cpp:228] Iteration 74730, loss = 0.177037
I0906 02:55:51.266476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177038 (* 1 = 0.177038 loss)
I0906 02:55:51.266494 90901 sgd_solver.cpp:106] Iteration 74730, lr = 0.01
I0906 02:56:14.522733 90901 solver.cpp:228] Iteration 74740, loss = 0.361134
I0906 02:56:14.522882 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.361136 (* 1 = 0.361136 loss)
I0906 02:56:14.522915 90901 sgd_solver.cpp:106] Iteration 74740, lr = 0.01
I0906 02:56:37.625396 90901 solver.cpp:228] Iteration 74750, loss = 0.366821
I0906 02:56:37.625469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366823 (* 1 = 0.366823 loss)
I0906 02:56:37.625488 90901 sgd_solver.cpp:106] Iteration 74750, lr = 0.01
I0906 02:57:01.247517 90901 solver.cpp:228] Iteration 74760, loss = 0.469738
I0906 02:57:01.247691 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46974 (* 1 = 0.46974 loss)
I0906 02:57:01.247710 90901 sgd_solver.cpp:106] Iteration 74760, lr = 0.01
I0906 02:57:24.484069 90901 solver.cpp:228] Iteration 74770, loss = 0.0827278
I0906 02:57:24.484149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0827294 (* 1 = 0.0827294 loss)
I0906 02:57:24.484167 90901 sgd_solver.cpp:106] Iteration 74770, lr = 0.01
I0906 02:57:46.550242 90901 solver.cpp:228] Iteration 74780, loss = 0.280288
I0906 02:57:46.550406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280289 (* 1 = 0.280289 loss)
I0906 02:57:46.550424 90901 sgd_solver.cpp:106] Iteration 74780, lr = 0.01
I0906 02:58:07.881021 90901 solver.cpp:228] Iteration 74790, loss = 0.199543
I0906 02:58:07.881103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199544 (* 1 = 0.199544 loss)
I0906 02:58:07.881120 90901 sgd_solver.cpp:106] Iteration 74790, lr = 0.01
I0906 02:58:30.805151 90901 solver.cpp:228] Iteration 74800, loss = 0.12179
I0906 02:58:30.805322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121792 (* 1 = 0.121792 loss)
I0906 02:58:30.805347 90901 sgd_solver.cpp:106] Iteration 74800, lr = 0.01
I0906 02:58:53.374550 90901 solver.cpp:228] Iteration 74810, loss = 0.215131
I0906 02:58:53.374666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215133 (* 1 = 0.215133 loss)
I0906 02:58:53.374689 90901 sgd_solver.cpp:106] Iteration 74810, lr = 0.01
I0906 02:59:14.900399 90901 solver.cpp:228] Iteration 74820, loss = 0.320413
I0906 02:59:14.900566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320415 (* 1 = 0.320415 loss)
I0906 02:59:14.900583 90901 sgd_solver.cpp:106] Iteration 74820, lr = 0.01
I0906 02:59:25.601413 90901 solver.cpp:228] Iteration 74830, loss = 0.228244
I0906 02:59:25.601485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228245 (* 1 = 0.228245 loss)
I0906 02:59:25.601505 90901 sgd_solver.cpp:106] Iteration 74830, lr = 0.01
I0906 02:59:34.436445 90901 solver.cpp:228] Iteration 74840, loss = 0.125508
I0906 02:59:34.436520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12551 (* 1 = 0.12551 loss)
I0906 02:59:34.436537 90901 sgd_solver.cpp:106] Iteration 74840, lr = 0.01
I0906 02:59:48.126083 90901 solver.cpp:228] Iteration 74850, loss = 0.0578956
I0906 02:59:48.126330 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0578973 (* 1 = 0.0578973 loss)
I0906 02:59:48.126360 90901 sgd_solver.cpp:106] Iteration 74850, lr = 0.01
I0906 03:00:08.542973 90901 solver.cpp:228] Iteration 74860, loss = 0.0920673
I0906 03:00:08.543047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.092069 (* 1 = 0.092069 loss)
I0906 03:00:08.543069 90901 sgd_solver.cpp:106] Iteration 74860, lr = 0.01
I0906 03:00:30.099349 90901 solver.cpp:228] Iteration 74870, loss = 0.0607178
I0906 03:00:30.099578 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0607194 (* 1 = 0.0607194 loss)
I0906 03:00:30.099596 90901 sgd_solver.cpp:106] Iteration 74870, lr = 0.01
I0906 03:00:52.122234 90901 solver.cpp:228] Iteration 74880, loss = 0.209942
I0906 03:00:52.122299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209944 (* 1 = 0.209944 loss)
I0906 03:00:52.122316 90901 sgd_solver.cpp:106] Iteration 74880, lr = 0.01
I0906 03:01:13.557660 90901 solver.cpp:228] Iteration 74890, loss = 0.214095
I0906 03:01:13.557827 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214096 (* 1 = 0.214096 loss)
I0906 03:01:13.557854 90901 sgd_solver.cpp:106] Iteration 74890, lr = 0.01
I0906 03:01:36.001147 90901 solver.cpp:228] Iteration 74900, loss = 0.255458
I0906 03:01:36.001207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25546 (* 1 = 0.25546 loss)
I0906 03:01:36.001224 90901 sgd_solver.cpp:106] Iteration 74900, lr = 0.01
I0906 03:01:56.514014 90901 solver.cpp:228] Iteration 74910, loss = 0.182603
I0906 03:01:56.514190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182605 (* 1 = 0.182605 loss)
I0906 03:01:56.514214 90901 sgd_solver.cpp:106] Iteration 74910, lr = 0.01
I0906 03:02:18.946915 90901 solver.cpp:228] Iteration 74920, loss = 0.336801
I0906 03:02:18.946981 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336803 (* 1 = 0.336803 loss)
I0906 03:02:18.947003 90901 sgd_solver.cpp:106] Iteration 74920, lr = 0.01
I0906 03:02:40.905486 90901 solver.cpp:228] Iteration 74930, loss = 0.248819
I0906 03:02:40.905648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248821 (* 1 = 0.248821 loss)
I0906 03:02:40.905663 90901 sgd_solver.cpp:106] Iteration 74930, lr = 0.01
I0906 03:03:01.694125 90901 solver.cpp:228] Iteration 74940, loss = 0.190518
I0906 03:03:01.694198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19052 (* 1 = 0.19052 loss)
I0906 03:03:01.694221 90901 sgd_solver.cpp:106] Iteration 74940, lr = 0.01
I0906 03:03:23.823678 90901 solver.cpp:228] Iteration 74950, loss = 0.347459
I0906 03:03:23.823843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347461 (* 1 = 0.347461 loss)
I0906 03:03:23.823871 90901 sgd_solver.cpp:106] Iteration 74950, lr = 0.01
I0906 03:03:46.017163 90901 solver.cpp:228] Iteration 74960, loss = 0.149022
I0906 03:03:46.017248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149024 (* 1 = 0.149024 loss)
I0906 03:03:46.017266 90901 sgd_solver.cpp:106] Iteration 74960, lr = 0.01
I0906 03:04:07.665132 90901 solver.cpp:228] Iteration 74970, loss = 0.400379
I0906 03:04:07.665362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40038 (* 1 = 0.40038 loss)
I0906 03:04:07.665381 90901 sgd_solver.cpp:106] Iteration 74970, lr = 0.01
I0906 03:04:29.291133 90901 solver.cpp:228] Iteration 74980, loss = 0.273703
I0906 03:04:29.291199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273705 (* 1 = 0.273705 loss)
I0906 03:04:29.291215 90901 sgd_solver.cpp:106] Iteration 74980, lr = 0.01
I0906 03:04:51.413432 90901 solver.cpp:228] Iteration 74990, loss = 0.03777
I0906 03:04:51.413605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0377717 (* 1 = 0.0377717 loss)
I0906 03:04:51.413635 90901 sgd_solver.cpp:106] Iteration 74990, lr = 0.01
I0906 03:05:12.307292 90901 solver.cpp:228] Iteration 75000, loss = 0.21451
I0906 03:05:12.307365 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214512 (* 1 = 0.214512 loss)
I0906 03:05:12.307380 90901 sgd_solver.cpp:46] MultiStep Status: Iteration 75000, step = 2
I0906 03:05:12.307390 90901 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I0906 03:05:34.627887 90901 solver.cpp:228] Iteration 75010, loss = 0.273464
I0906 03:05:34.628108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273466 (* 1 = 0.273466 loss)
I0906 03:05:34.628141 90901 sgd_solver.cpp:106] Iteration 75010, lr = 0.001
I0906 03:05:57.489431 90901 solver.cpp:228] Iteration 75020, loss = 0.321243
I0906 03:05:57.489521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321244 (* 1 = 0.321244 loss)
I0906 03:05:57.489538 90901 sgd_solver.cpp:106] Iteration 75020, lr = 0.001
I0906 03:06:19.725291 90901 solver.cpp:228] Iteration 75030, loss = 0.0847617
I0906 03:06:19.725458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0847634 (* 1 = 0.0847634 loss)
I0906 03:06:19.725495 90901 sgd_solver.cpp:106] Iteration 75030, lr = 0.001
I0906 03:06:41.271631 90901 solver.cpp:228] Iteration 75040, loss = 0.170871
I0906 03:06:41.271720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170873 (* 1 = 0.170873 loss)
I0906 03:06:41.271740 90901 sgd_solver.cpp:106] Iteration 75040, lr = 0.001
I0906 03:07:03.745589 90901 solver.cpp:228] Iteration 75050, loss = 0.0779102
I0906 03:07:03.745779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0779119 (* 1 = 0.0779119 loss)
I0906 03:07:03.745798 90901 sgd_solver.cpp:106] Iteration 75050, lr = 0.001
I0906 03:07:26.293117 90901 solver.cpp:228] Iteration 75060, loss = 0.442012
I0906 03:07:26.293187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442014 (* 1 = 0.442014 loss)
I0906 03:07:26.293203 90901 sgd_solver.cpp:106] Iteration 75060, lr = 0.001
I0906 03:07:47.886611 90901 solver.cpp:228] Iteration 75070, loss = 0.104721
I0906 03:07:47.886817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104723 (* 1 = 0.104723 loss)
I0906 03:07:47.886836 90901 sgd_solver.cpp:106] Iteration 75070, lr = 0.001
I0906 03:08:08.928079 90901 solver.cpp:228] Iteration 75080, loss = 0.16484
I0906 03:08:08.928155 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164841 (* 1 = 0.164841 loss)
I0906 03:08:08.928172 90901 sgd_solver.cpp:106] Iteration 75080, lr = 0.001
I0906 03:08:31.241201 90901 solver.cpp:228] Iteration 75090, loss = 0.618698
I0906 03:08:31.241335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.6187 (* 1 = 0.6187 loss)
I0906 03:08:31.241366 90901 sgd_solver.cpp:106] Iteration 75090, lr = 0.001
I0906 03:08:51.155838 90901 solver.cpp:228] Iteration 75100, loss = 0.262938
I0906 03:08:51.155938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26294 (* 1 = 0.26294 loss)
I0906 03:08:51.155958 90901 sgd_solver.cpp:106] Iteration 75100, lr = 0.001
I0906 03:09:12.706219 90901 solver.cpp:228] Iteration 75110, loss = 0.22143
I0906 03:09:12.706406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221432 (* 1 = 0.221432 loss)
I0906 03:09:12.706425 90901 sgd_solver.cpp:106] Iteration 75110, lr = 0.001
I0906 03:09:32.528635 90901 solver.cpp:228] Iteration 75120, loss = 0.081207
I0906 03:09:32.528714 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0812086 (* 1 = 0.0812086 loss)
I0906 03:09:32.528733 90901 sgd_solver.cpp:106] Iteration 75120, lr = 0.001
I0906 03:09:50.298130 90901 solver.cpp:228] Iteration 75130, loss = 0.363161
I0906 03:09:50.298326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363162 (* 1 = 0.363162 loss)
I0906 03:09:50.298370 90901 sgd_solver.cpp:106] Iteration 75130, lr = 0.001
I0906 03:10:03.699318 90901 solver.cpp:228] Iteration 75140, loss = 0.129734
I0906 03:10:03.699373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129736 (* 1 = 0.129736 loss)
I0906 03:10:03.699388 90901 sgd_solver.cpp:106] Iteration 75140, lr = 0.001
I0906 03:10:15.644284 90901 solver.cpp:228] Iteration 75150, loss = 0.0704411
I0906 03:10:15.644366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0704427 (* 1 = 0.0704427 loss)
I0906 03:10:15.644383 90901 sgd_solver.cpp:106] Iteration 75150, lr = 0.001
I0906 03:10:32.122319 90901 solver.cpp:228] Iteration 75160, loss = 0.197243
I0906 03:10:32.122493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197245 (* 1 = 0.197245 loss)
I0906 03:10:32.122520 90901 sgd_solver.cpp:106] Iteration 75160, lr = 0.001
I0906 03:10:50.798374 90901 solver.cpp:228] Iteration 75170, loss = 0.0432458
I0906 03:10:50.798472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0432474 (* 1 = 0.0432474 loss)
I0906 03:10:50.798496 90901 sgd_solver.cpp:106] Iteration 75170, lr = 0.001
I0906 03:11:05.130177 90901 solver.cpp:228] Iteration 75180, loss = 0.367188
I0906 03:11:05.130409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367189 (* 1 = 0.367189 loss)
I0906 03:11:05.130439 90901 sgd_solver.cpp:106] Iteration 75180, lr = 0.001
I0906 03:11:17.851598 90901 solver.cpp:228] Iteration 75190, loss = 0.186605
I0906 03:11:17.851686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186606 (* 1 = 0.186606 loss)
I0906 03:11:17.851704 90901 sgd_solver.cpp:106] Iteration 75190, lr = 0.001
I0906 03:11:31.969521 90901 solver.cpp:337] Iteration 75200, Testing net (#0)
I0906 03:13:55.143385 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.942187
I0906 03:13:55.143512 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.159015 (* 1 = 0.159015 loss)
I0906 03:13:56.010790 90901 solver.cpp:228] Iteration 75200, loss = 0.0566757
I0906 03:13:56.010862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0566773 (* 1 = 0.0566773 loss)
I0906 03:13:56.010881 90901 sgd_solver.cpp:106] Iteration 75200, lr = 0.001
I0906 03:14:17.242640 90901 solver.cpp:228] Iteration 75210, loss = 0.575561
I0906 03:14:17.242719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.575563 (* 1 = 0.575563 loss)
I0906 03:14:17.242740 90901 sgd_solver.cpp:106] Iteration 75210, lr = 0.001
I0906 03:14:39.498018 90901 solver.cpp:228] Iteration 75220, loss = 0.1132
I0906 03:14:39.498195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113202 (* 1 = 0.113202 loss)
I0906 03:14:39.498227 90901 sgd_solver.cpp:106] Iteration 75220, lr = 0.001
I0906 03:15:01.432477 90901 solver.cpp:228] Iteration 75230, loss = 0.278197
I0906 03:15:01.432560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278199 (* 1 = 0.278199 loss)
I0906 03:15:01.432579 90901 sgd_solver.cpp:106] Iteration 75230, lr = 0.001
I0906 03:15:22.393983 90901 solver.cpp:228] Iteration 75240, loss = 0.0833025
I0906 03:15:22.394135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0833042 (* 1 = 0.0833042 loss)
I0906 03:15:22.394166 90901 sgd_solver.cpp:106] Iteration 75240, lr = 0.001
I0906 03:15:43.774247 90901 solver.cpp:228] Iteration 75250, loss = 0.108954
I0906 03:15:43.774322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108956 (* 1 = 0.108956 loss)
I0906 03:15:43.774338 90901 sgd_solver.cpp:106] Iteration 75250, lr = 0.001
I0906 03:16:04.601564 90901 solver.cpp:228] Iteration 75260, loss = 0.374405
I0906 03:16:04.601752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.374407 (* 1 = 0.374407 loss)
I0906 03:16:04.601776 90901 sgd_solver.cpp:106] Iteration 75260, lr = 0.001
I0906 03:16:25.517853 90901 solver.cpp:228] Iteration 75270, loss = 0.0767281
I0906 03:16:25.517932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0767298 (* 1 = 0.0767298 loss)
I0906 03:16:25.517949 90901 sgd_solver.cpp:106] Iteration 75270, lr = 0.001
I0906 03:16:47.166416 90901 solver.cpp:228] Iteration 75280, loss = 0.129778
I0906 03:16:47.166573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12978 (* 1 = 0.12978 loss)
I0906 03:16:47.166604 90901 sgd_solver.cpp:106] Iteration 75280, lr = 0.001
I0906 03:17:08.947770 90901 solver.cpp:228] Iteration 75290, loss = 0.243314
I0906 03:17:08.947836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243316 (* 1 = 0.243316 loss)
I0906 03:17:08.947854 90901 sgd_solver.cpp:106] Iteration 75290, lr = 0.001
I0906 03:17:30.038405 90901 solver.cpp:228] Iteration 75300, loss = 0.0929281
I0906 03:17:30.038681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0929298 (* 1 = 0.0929298 loss)
I0906 03:17:30.038703 90901 sgd_solver.cpp:106] Iteration 75300, lr = 0.001
I0906 03:17:51.562005 90901 solver.cpp:228] Iteration 75310, loss = 0.0979866
I0906 03:17:51.562085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0979883 (* 1 = 0.0979883 loss)
I0906 03:17:51.562103 90901 sgd_solver.cpp:106] Iteration 75310, lr = 0.001
I0906 03:18:13.386411 90901 solver.cpp:228] Iteration 75320, loss = 0.112347
I0906 03:18:13.386574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112349 (* 1 = 0.112349 loss)
I0906 03:18:13.386608 90901 sgd_solver.cpp:106] Iteration 75320, lr = 0.001
I0906 03:18:29.573263 90901 solver.cpp:228] Iteration 75330, loss = 0.094645
I0906 03:18:29.573369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0946467 (* 1 = 0.0946467 loss)
I0906 03:18:29.573392 90901 sgd_solver.cpp:106] Iteration 75330, lr = 0.001
I0906 03:18:44.774711 90901 solver.cpp:228] Iteration 75340, loss = 0.0803781
I0906 03:18:44.774926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0803799 (* 1 = 0.0803799 loss)
I0906 03:18:44.774953 90901 sgd_solver.cpp:106] Iteration 75340, lr = 0.001
I0906 03:18:59.266544 90901 solver.cpp:228] Iteration 75350, loss = 0.277384
I0906 03:18:59.266638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277386 (* 1 = 0.277386 loss)
I0906 03:18:59.266661 90901 sgd_solver.cpp:106] Iteration 75350, lr = 0.001
I0906 03:19:17.761466 90901 solver.cpp:228] Iteration 75360, loss = 0.0365606
I0906 03:19:17.761631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0365623 (* 1 = 0.0365623 loss)
I0906 03:19:17.761654 90901 sgd_solver.cpp:106] Iteration 75360, lr = 0.001
I0906 03:19:40.948737 90901 solver.cpp:228] Iteration 75370, loss = 0.142145
I0906 03:19:40.948814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142147 (* 1 = 0.142147 loss)
I0906 03:19:40.948837 90901 sgd_solver.cpp:106] Iteration 75370, lr = 0.001
I0906 03:20:05.352372 90901 solver.cpp:228] Iteration 75380, loss = 0.315819
I0906 03:20:05.352540 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315821 (* 1 = 0.315821 loss)
I0906 03:20:05.352573 90901 sgd_solver.cpp:106] Iteration 75380, lr = 0.001
I0906 03:20:26.631865 90901 solver.cpp:228] Iteration 75390, loss = 0.266092
I0906 03:20:26.631950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266093 (* 1 = 0.266093 loss)
I0906 03:20:26.631969 90901 sgd_solver.cpp:106] Iteration 75390, lr = 0.001
I0906 03:20:50.159860 90901 solver.cpp:228] Iteration 75400, loss = 0.136413
I0906 03:20:50.160074 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136415 (* 1 = 0.136415 loss)
I0906 03:20:50.160092 90901 sgd_solver.cpp:106] Iteration 75400, lr = 0.001
I0906 03:21:12.401612 90901 solver.cpp:228] Iteration 75410, loss = 0.130551
I0906 03:21:12.401675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130553 (* 1 = 0.130553 loss)
I0906 03:21:12.401692 90901 sgd_solver.cpp:106] Iteration 75410, lr = 0.001
I0906 03:21:34.248442 90901 solver.cpp:228] Iteration 75420, loss = 0.0380222
I0906 03:21:34.248658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0380239 (* 1 = 0.0380239 loss)
I0906 03:21:34.248677 90901 sgd_solver.cpp:106] Iteration 75420, lr = 0.001
I0906 03:21:54.798140 90901 solver.cpp:228] Iteration 75430, loss = 0.0471439
I0906 03:21:54.798207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0471456 (* 1 = 0.0471456 loss)
I0906 03:21:54.798223 90901 sgd_solver.cpp:106] Iteration 75430, lr = 0.001
I0906 03:22:12.018687 90901 solver.cpp:228] Iteration 75440, loss = 0.0982901
I0906 03:22:12.018862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0982918 (* 1 = 0.0982918 loss)
I0906 03:22:12.018913 90901 sgd_solver.cpp:106] Iteration 75440, lr = 0.001
I0906 03:22:27.799249 90901 solver.cpp:228] Iteration 75450, loss = 0.275156
I0906 03:22:27.799332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275158 (* 1 = 0.275158 loss)
I0906 03:22:27.799350 90901 sgd_solver.cpp:106] Iteration 75450, lr = 0.001
I0906 03:22:42.475560 90901 solver.cpp:228] Iteration 75460, loss = 0.239793
I0906 03:22:42.475755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239794 (* 1 = 0.239794 loss)
I0906 03:22:42.475787 90901 sgd_solver.cpp:106] Iteration 75460, lr = 0.001
I0906 03:22:57.953438 90901 solver.cpp:228] Iteration 75470, loss = 0.0552188
I0906 03:22:57.953507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0552205 (* 1 = 0.0552205 loss)
I0906 03:22:57.953526 90901 sgd_solver.cpp:106] Iteration 75470, lr = 0.001
I0906 03:23:12.118190 90901 solver.cpp:228] Iteration 75480, loss = 0.0467633
I0906 03:23:12.118355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.046765 (* 1 = 0.046765 loss)
I0906 03:23:12.118378 90901 sgd_solver.cpp:106] Iteration 75480, lr = 0.001
I0906 03:23:27.482614 90901 solver.cpp:228] Iteration 75490, loss = 0.234582
I0906 03:23:27.482843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234584 (* 1 = 0.234584 loss)
I0906 03:23:27.482873 90901 sgd_solver.cpp:106] Iteration 75490, lr = 0.001
I0906 03:23:41.682903 90901 solver.cpp:228] Iteration 75500, loss = 0.164918
I0906 03:23:41.682978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16492 (* 1 = 0.16492 loss)
I0906 03:23:41.682996 90901 sgd_solver.cpp:106] Iteration 75500, lr = 0.001
I0906 03:23:55.267693 90901 solver.cpp:228] Iteration 75510, loss = 0.100227
I0906 03:23:55.267758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100228 (* 1 = 0.100228 loss)
I0906 03:23:55.267774 90901 sgd_solver.cpp:106] Iteration 75510, lr = 0.001
I0906 03:24:09.523141 90901 solver.cpp:228] Iteration 75520, loss = 0.183032
I0906 03:24:09.523299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183033 (* 1 = 0.183033 loss)
I0906 03:24:09.523326 90901 sgd_solver.cpp:106] Iteration 75520, lr = 0.001
I0906 03:24:24.708397 90901 solver.cpp:228] Iteration 75530, loss = 0.194055
I0906 03:24:24.708467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194056 (* 1 = 0.194056 loss)
I0906 03:24:24.708483 90901 sgd_solver.cpp:106] Iteration 75530, lr = 0.001
I0906 03:24:38.456415 90901 solver.cpp:228] Iteration 75540, loss = 0.0672561
I0906 03:24:38.456472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0672578 (* 1 = 0.0672578 loss)
I0906 03:24:38.456490 90901 sgd_solver.cpp:106] Iteration 75540, lr = 0.001
I0906 03:24:52.080863 90901 solver.cpp:228] Iteration 75550, loss = 0.093242
I0906 03:24:52.081010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0932437 (* 1 = 0.0932437 loss)
I0906 03:24:52.081032 90901 sgd_solver.cpp:106] Iteration 75550, lr = 0.001
I0906 03:25:05.545493 90901 solver.cpp:228] Iteration 75560, loss = 0.213804
I0906 03:25:05.545573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213805 (* 1 = 0.213805 loss)
I0906 03:25:05.545593 90901 sgd_solver.cpp:106] Iteration 75560, lr = 0.001
I0906 03:25:19.008280 90901 solver.cpp:228] Iteration 75570, loss = 0.142296
I0906 03:25:19.008352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142298 (* 1 = 0.142298 loss)
I0906 03:25:19.008369 90901 sgd_solver.cpp:106] Iteration 75570, lr = 0.001
I0906 03:25:27.238147 90901 solver.cpp:228] Iteration 75580, loss = 0.166719
I0906 03:25:27.238284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166721 (* 1 = 0.166721 loss)
I0906 03:25:27.238306 90901 sgd_solver.cpp:106] Iteration 75580, lr = 0.001
I0906 03:25:34.257772 90901 solver.cpp:228] Iteration 75590, loss = 0.160651
I0906 03:25:34.257844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160653 (* 1 = 0.160653 loss)
I0906 03:25:34.257858 90901 sgd_solver.cpp:106] Iteration 75590, lr = 0.001
I0906 03:25:40.210794 90901 solver.cpp:228] Iteration 75600, loss = 0.0551337
I0906 03:25:40.210870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0551353 (* 1 = 0.0551353 loss)
I0906 03:25:40.210891 90901 sgd_solver.cpp:106] Iteration 75600, lr = 0.001
I0906 03:25:45.416865 90901 solver.cpp:228] Iteration 75610, loss = 0.505119
I0906 03:25:45.416930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.505121 (* 1 = 0.505121 loss)
I0906 03:25:45.416949 90901 sgd_solver.cpp:106] Iteration 75610, lr = 0.001
I0906 03:25:50.607673 90901 solver.cpp:228] Iteration 75620, loss = 0.23281
I0906 03:25:50.607769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232812 (* 1 = 0.232812 loss)
I0906 03:25:50.607792 90901 sgd_solver.cpp:106] Iteration 75620, lr = 0.001
I0906 03:25:56.136572 90901 solver.cpp:228] Iteration 75630, loss = 0.165743
I0906 03:25:56.136636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165745 (* 1 = 0.165745 loss)
I0906 03:25:56.136651 90901 sgd_solver.cpp:106] Iteration 75630, lr = 0.001
I0906 03:26:03.340584 90901 solver.cpp:228] Iteration 75640, loss = 0.119003
I0906 03:26:03.340853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119005 (* 1 = 0.119005 loss)
I0906 03:26:03.340878 90901 sgd_solver.cpp:106] Iteration 75640, lr = 0.001
I0906 03:26:14.237032 90901 solver.cpp:228] Iteration 75650, loss = 0.281766
I0906 03:26:14.237118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281767 (* 1 = 0.281767 loss)
I0906 03:26:14.237138 90901 sgd_solver.cpp:106] Iteration 75650, lr = 0.001
I0906 03:26:25.480505 90901 solver.cpp:228] Iteration 75660, loss = 0.249168
I0906 03:26:25.480579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24917 (* 1 = 0.24917 loss)
I0906 03:26:25.480597 90901 sgd_solver.cpp:106] Iteration 75660, lr = 0.001
I0906 03:26:36.686173 90901 solver.cpp:228] Iteration 75670, loss = 0.134995
I0906 03:26:36.686345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134996 (* 1 = 0.134996 loss)
I0906 03:26:36.686374 90901 sgd_solver.cpp:106] Iteration 75670, lr = 0.001
I0906 03:26:48.888627 90901 solver.cpp:228] Iteration 75680, loss = 0.357209
I0906 03:26:48.888713 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35721 (* 1 = 0.35721 loss)
I0906 03:26:48.888731 90901 sgd_solver.cpp:106] Iteration 75680, lr = 0.001
I0906 03:27:01.050596 90901 solver.cpp:228] Iteration 75690, loss = 0.572505
I0906 03:27:01.050695 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.572507 (* 1 = 0.572507 loss)
I0906 03:27:01.050714 90901 sgd_solver.cpp:106] Iteration 75690, lr = 0.001
I0906 03:27:12.884344 90901 solver.cpp:228] Iteration 75700, loss = 0.22791
I0906 03:27:12.884500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227911 (* 1 = 0.227911 loss)
I0906 03:27:12.884531 90901 sgd_solver.cpp:106] Iteration 75700, lr = 0.001
I0906 03:27:24.954493 90901 solver.cpp:228] Iteration 75710, loss = 0.160443
I0906 03:27:24.954560 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160445 (* 1 = 0.160445 loss)
I0906 03:27:24.954577 90901 sgd_solver.cpp:106] Iteration 75710, lr = 0.001
I0906 03:27:36.326648 90901 solver.cpp:228] Iteration 75720, loss = 0.290501
I0906 03:27:36.326731 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290502 (* 1 = 0.290502 loss)
I0906 03:27:36.326753 90901 sgd_solver.cpp:106] Iteration 75720, lr = 0.001
I0906 03:27:49.603868 90901 solver.cpp:228] Iteration 75730, loss = 0.293733
I0906 03:27:49.604022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293735 (* 1 = 0.293735 loss)
I0906 03:27:49.604050 90901 sgd_solver.cpp:106] Iteration 75730, lr = 0.001
I0906 03:28:02.810154 90901 solver.cpp:228] Iteration 75740, loss = 0.12528
I0906 03:28:02.810230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125281 (* 1 = 0.125281 loss)
I0906 03:28:02.810246 90901 sgd_solver.cpp:106] Iteration 75740, lr = 0.001
I0906 03:28:16.204701 90901 solver.cpp:228] Iteration 75750, loss = 0.0977283
I0906 03:28:16.204767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0977298 (* 1 = 0.0977298 loss)
I0906 03:28:16.204783 90901 sgd_solver.cpp:106] Iteration 75750, lr = 0.001
I0906 03:28:29.552425 90901 solver.cpp:228] Iteration 75760, loss = 0.584023
I0906 03:28:29.552656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.584025 (* 1 = 0.584025 loss)
I0906 03:28:29.552675 90901 sgd_solver.cpp:106] Iteration 75760, lr = 0.001
I0906 03:28:42.510710 90901 solver.cpp:228] Iteration 75770, loss = 0.445254
I0906 03:28:42.510792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445255 (* 1 = 0.445255 loss)
I0906 03:28:42.510809 90901 sgd_solver.cpp:106] Iteration 75770, lr = 0.001
I0906 03:28:55.718621 90901 solver.cpp:228] Iteration 75780, loss = 0.118129
I0906 03:28:55.718718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118131 (* 1 = 0.118131 loss)
I0906 03:28:55.718745 90901 sgd_solver.cpp:106] Iteration 75780, lr = 0.001
I0906 03:29:08.832473 90901 solver.cpp:228] Iteration 75790, loss = 0.161733
I0906 03:29:08.832681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161735 (* 1 = 0.161735 loss)
I0906 03:29:08.832722 90901 sgd_solver.cpp:106] Iteration 75790, lr = 0.001
I0906 03:29:22.118584 90901 solver.cpp:228] Iteration 75800, loss = 0.275662
I0906 03:29:22.118643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275663 (* 1 = 0.275663 loss)
I0906 03:29:22.118661 90901 sgd_solver.cpp:106] Iteration 75800, lr = 0.001
I0906 03:29:35.286731 90901 solver.cpp:228] Iteration 75810, loss = 0.0689097
I0906 03:29:35.286918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0689112 (* 1 = 0.0689112 loss)
I0906 03:29:35.286981 90901 sgd_solver.cpp:106] Iteration 75810, lr = 0.001
I0906 03:29:49.637307 90901 solver.cpp:228] Iteration 75820, loss = 0.0350901
I0906 03:29:49.637552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350916 (* 1 = 0.0350916 loss)
I0906 03:29:49.637580 90901 sgd_solver.cpp:106] Iteration 75820, lr = 0.001
I0906 03:30:01.944229 90901 solver.cpp:228] Iteration 75830, loss = 0.0744452
I0906 03:30:01.944308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0744467 (* 1 = 0.0744467 loss)
I0906 03:30:01.944326 90901 sgd_solver.cpp:106] Iteration 75830, lr = 0.001
I0906 03:30:14.387256 90901 solver.cpp:228] Iteration 75840, loss = 0.191433
I0906 03:30:14.387320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191435 (* 1 = 0.191435 loss)
I0906 03:30:14.387336 90901 sgd_solver.cpp:106] Iteration 75840, lr = 0.001
I0906 03:30:25.829653 90901 solver.cpp:228] Iteration 75850, loss = 0.315554
I0906 03:30:25.829807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315556 (* 1 = 0.315556 loss)
I0906 03:30:25.829838 90901 sgd_solver.cpp:106] Iteration 75850, lr = 0.001
I0906 03:30:34.580742 90901 solver.cpp:228] Iteration 75860, loss = 0.267628
I0906 03:30:34.580818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267629 (* 1 = 0.267629 loss)
I0906 03:30:34.580835 90901 sgd_solver.cpp:106] Iteration 75860, lr = 0.001
I0906 03:30:42.008354 90901 solver.cpp:228] Iteration 75870, loss = 0.160937
I0906 03:30:42.008420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160939 (* 1 = 0.160939 loss)
I0906 03:30:42.008435 90901 sgd_solver.cpp:106] Iteration 75870, lr = 0.001
I0906 03:30:49.792476 90901 solver.cpp:228] Iteration 75880, loss = 0.140793
I0906 03:30:49.792567 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140795 (* 1 = 0.140795 loss)
I0906 03:30:49.792587 90901 sgd_solver.cpp:106] Iteration 75880, lr = 0.001
I0906 03:31:00.197630 90901 solver.cpp:228] Iteration 75890, loss = 0.0784296
I0906 03:31:00.197826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.078431 (* 1 = 0.078431 loss)
I0906 03:31:00.197851 90901 sgd_solver.cpp:106] Iteration 75890, lr = 0.001
I0906 03:31:12.305490 90901 solver.cpp:228] Iteration 75900, loss = 0.144273
I0906 03:31:12.305583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144275 (* 1 = 0.144275 loss)
I0906 03:31:12.305605 90901 sgd_solver.cpp:106] Iteration 75900, lr = 0.001
I0906 03:31:25.351083 90901 solver.cpp:228] Iteration 75910, loss = 0.0879487
I0906 03:31:25.351164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0879502 (* 1 = 0.0879502 loss)
I0906 03:31:25.351182 90901 sgd_solver.cpp:106] Iteration 75910, lr = 0.001
I0906 03:31:39.970640 90901 solver.cpp:228] Iteration 75920, loss = 0.17586
I0906 03:31:39.970795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175862 (* 1 = 0.175862 loss)
I0906 03:31:39.970827 90901 sgd_solver.cpp:106] Iteration 75920, lr = 0.001
I0906 03:31:54.389730 90901 solver.cpp:228] Iteration 75930, loss = 0.111735
I0906 03:31:54.389786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111736 (* 1 = 0.111736 loss)
I0906 03:31:54.389803 90901 sgd_solver.cpp:106] Iteration 75930, lr = 0.001
I0906 03:32:07.639681 90901 solver.cpp:228] Iteration 75940, loss = 0.283198
I0906 03:32:07.639746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283199 (* 1 = 0.283199 loss)
I0906 03:32:07.639761 90901 sgd_solver.cpp:106] Iteration 75940, lr = 0.001
I0906 03:32:19.897200 90901 solver.cpp:228] Iteration 75950, loss = 0.266752
I0906 03:32:19.897341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266753 (* 1 = 0.266753 loss)
I0906 03:32:19.897377 90901 sgd_solver.cpp:106] Iteration 75950, lr = 0.001
I0906 03:32:31.182624 90901 solver.cpp:228] Iteration 75960, loss = 0.108994
I0906 03:32:31.182762 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108995 (* 1 = 0.108995 loss)
I0906 03:32:31.182785 90901 sgd_solver.cpp:106] Iteration 75960, lr = 0.001
I0906 03:32:44.365178 90901 solver.cpp:228] Iteration 75970, loss = 0.353028
I0906 03:32:44.365267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353029 (* 1 = 0.353029 loss)
I0906 03:32:44.365284 90901 sgd_solver.cpp:106] Iteration 75970, lr = 0.001
I0906 03:32:57.924754 90901 solver.cpp:228] Iteration 75980, loss = 0.139246
I0906 03:32:57.924955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139248 (* 1 = 0.139248 loss)
I0906 03:32:57.924986 90901 sgd_solver.cpp:106] Iteration 75980, lr = 0.001
I0906 03:33:12.197603 90901 solver.cpp:228] Iteration 75990, loss = 0.0622524
I0906 03:33:12.197666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0622538 (* 1 = 0.0622538 loss)
I0906 03:33:12.197681 90901 sgd_solver.cpp:106] Iteration 75990, lr = 0.001
I0906 03:33:24.946097 90901 solver.cpp:337] Iteration 76000, Testing net (#0)
I0906 03:34:39.674162 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.939687
I0906 03:34:39.674305 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.16815 (* 1 = 0.16815 loss)
I0906 03:34:40.112110 90901 solver.cpp:228] Iteration 76000, loss = 0.273683
I0906 03:34:40.112164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273684 (* 1 = 0.273684 loss)
I0906 03:34:40.112182 90901 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I0906 03:34:49.413689 90901 solver.cpp:228] Iteration 76010, loss = 0.161926
I0906 03:34:49.413745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161927 (* 1 = 0.161927 loss)
I0906 03:34:49.413761 90901 sgd_solver.cpp:106] Iteration 76010, lr = 0.001
I0906 03:34:57.649417 90901 solver.cpp:228] Iteration 76020, loss = 0.0992402
I0906 03:34:57.649572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0992417 (* 1 = 0.0992417 loss)
I0906 03:34:57.649608 90901 sgd_solver.cpp:106] Iteration 76020, lr = 0.001
I0906 03:35:08.163715 90901 solver.cpp:228] Iteration 76030, loss = 0.489807
I0906 03:35:08.163789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489808 (* 1 = 0.489808 loss)
I0906 03:35:08.163806 90901 sgd_solver.cpp:106] Iteration 76030, lr = 0.001
I0906 03:35:21.554054 90901 solver.cpp:228] Iteration 76040, loss = 0.291715
I0906 03:35:21.554283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291716 (* 1 = 0.291716 loss)
I0906 03:35:21.554302 90901 sgd_solver.cpp:106] Iteration 76040, lr = 0.001
I0906 03:35:36.750919 90901 solver.cpp:228] Iteration 76050, loss = 0.429631
I0906 03:35:36.750993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.429633 (* 1 = 0.429633 loss)
I0906 03:35:36.751010 90901 sgd_solver.cpp:106] Iteration 76050, lr = 0.001
I0906 03:35:52.391674 90901 solver.cpp:228] Iteration 76060, loss = 0.0480316
I0906 03:35:52.391847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.048033 (* 1 = 0.048033 loss)
I0906 03:35:52.391865 90901 sgd_solver.cpp:106] Iteration 76060, lr = 0.001
I0906 03:36:07.553866 90901 solver.cpp:228] Iteration 76070, loss = 0.0925201
I0906 03:36:07.553971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0925215 (* 1 = 0.0925215 loss)
I0906 03:36:07.553989 90901 sgd_solver.cpp:106] Iteration 76070, lr = 0.001
I0906 03:36:22.431802 90901 solver.cpp:228] Iteration 76080, loss = 0.413753
I0906 03:36:22.431996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.413754 (* 1 = 0.413754 loss)
I0906 03:36:22.432013 90901 sgd_solver.cpp:106] Iteration 76080, lr = 0.001
I0906 03:36:38.112879 90901 solver.cpp:228] Iteration 76090, loss = 0.325271
I0906 03:36:38.112965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325272 (* 1 = 0.325272 loss)
I0906 03:36:38.112987 90901 sgd_solver.cpp:106] Iteration 76090, lr = 0.001
I0906 03:36:53.496884 90901 solver.cpp:228] Iteration 76100, loss = 0.2307
I0906 03:36:53.497041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230702 (* 1 = 0.230702 loss)
I0906 03:36:53.497059 90901 sgd_solver.cpp:106] Iteration 76100, lr = 0.001
I0906 03:37:09.202966 90901 solver.cpp:228] Iteration 76110, loss = 0.263728
I0906 03:37:09.203058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26373 (* 1 = 0.26373 loss)
I0906 03:37:09.203075 90901 sgd_solver.cpp:106] Iteration 76110, lr = 0.001
I0906 03:37:24.384804 90901 solver.cpp:228] Iteration 76120, loss = 0.337916
I0906 03:37:24.384971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337918 (* 1 = 0.337918 loss)
I0906 03:37:24.385000 90901 sgd_solver.cpp:106] Iteration 76120, lr = 0.001
I0906 03:37:38.906781 90901 solver.cpp:228] Iteration 76130, loss = 0.13129
I0906 03:37:38.906855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131291 (* 1 = 0.131291 loss)
I0906 03:37:38.906872 90901 sgd_solver.cpp:106] Iteration 76130, lr = 0.001
I0906 03:37:54.638425 90901 solver.cpp:228] Iteration 76140, loss = 0.32481
I0906 03:37:54.638588 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324812 (* 1 = 0.324812 loss)
I0906 03:37:54.638646 90901 sgd_solver.cpp:106] Iteration 76140, lr = 0.001
I0906 03:38:09.540452 90901 solver.cpp:228] Iteration 76150, loss = 0.213066
I0906 03:38:09.540516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213068 (* 1 = 0.213068 loss)
I0906 03:38:09.540531 90901 sgd_solver.cpp:106] Iteration 76150, lr = 0.001
I0906 03:38:24.890213 90901 solver.cpp:228] Iteration 76160, loss = 0.172984
I0906 03:38:24.890384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172985 (* 1 = 0.172985 loss)
I0906 03:38:24.890420 90901 sgd_solver.cpp:106] Iteration 76160, lr = 0.001
I0906 03:38:40.136824 90901 solver.cpp:228] Iteration 76170, loss = 0.247591
I0906 03:38:40.136912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247592 (* 1 = 0.247592 loss)
I0906 03:38:40.136930 90901 sgd_solver.cpp:106] Iteration 76170, lr = 0.001
I0906 03:38:54.596256 90901 solver.cpp:228] Iteration 76180, loss = 0.445931
I0906 03:38:54.596509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445933 (* 1 = 0.445933 loss)
I0906 03:38:54.596539 90901 sgd_solver.cpp:106] Iteration 76180, lr = 0.001
I0906 03:39:09.793644 90901 solver.cpp:228] Iteration 76190, loss = 0.24032
I0906 03:39:09.794003 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240322 (* 1 = 0.240322 loss)
I0906 03:39:09.794023 90901 sgd_solver.cpp:106] Iteration 76190, lr = 0.001
I0906 03:39:23.693652 90901 solver.cpp:228] Iteration 76200, loss = 0.197385
I0906 03:39:23.693729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197386 (* 1 = 0.197386 loss)
I0906 03:39:23.693750 90901 sgd_solver.cpp:106] Iteration 76200, lr = 0.001
I0906 03:39:38.905666 90901 solver.cpp:228] Iteration 76210, loss = 0.0910588
I0906 03:39:38.905735 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0910602 (* 1 = 0.0910602 loss)
I0906 03:39:38.905766 90901 sgd_solver.cpp:106] Iteration 76210, lr = 0.001
I0906 03:39:52.787084 90901 solver.cpp:228] Iteration 76220, loss = 0.0713693
I0906 03:39:52.787343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0713707 (* 1 = 0.0713707 loss)
I0906 03:39:52.787360 90901 sgd_solver.cpp:106] Iteration 76220, lr = 0.001
I0906 03:40:06.430660 90901 solver.cpp:228] Iteration 76230, loss = 0.228784
I0906 03:40:06.430738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228785 (* 1 = 0.228785 loss)
I0906 03:40:06.430757 90901 sgd_solver.cpp:106] Iteration 76230, lr = 0.001
I0906 03:40:20.288578 90901 solver.cpp:228] Iteration 76240, loss = 0.0920299
I0906 03:40:20.288662 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0920313 (* 1 = 0.0920313 loss)
I0906 03:40:20.288681 90901 sgd_solver.cpp:106] Iteration 76240, lr = 0.001
I0906 03:40:33.956780 90901 solver.cpp:228] Iteration 76250, loss = 0.101446
I0906 03:40:33.957095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101447 (* 1 = 0.101447 loss)
I0906 03:40:33.957116 90901 sgd_solver.cpp:106] Iteration 76250, lr = 0.001
I0906 03:40:49.015234 90901 solver.cpp:228] Iteration 76260, loss = 0.0260676
I0906 03:40:49.015297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.026069 (* 1 = 0.026069 loss)
I0906 03:40:49.015317 90901 sgd_solver.cpp:106] Iteration 76260, lr = 0.001
I0906 03:41:04.071799 90901 solver.cpp:228] Iteration 76270, loss = 0.220123
I0906 03:41:04.071961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220125 (* 1 = 0.220125 loss)
I0906 03:41:04.071979 90901 sgd_solver.cpp:106] Iteration 76270, lr = 0.001
I0906 03:41:17.182870 90901 solver.cpp:228] Iteration 76280, loss = 0.289156
I0906 03:41:17.182946 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289158 (* 1 = 0.289158 loss)
I0906 03:41:17.182965 90901 sgd_solver.cpp:106] Iteration 76280, lr = 0.001
I0906 03:41:25.962155 90901 solver.cpp:228] Iteration 76290, loss = 0.0554066
I0906 03:41:25.962220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0554079 (* 1 = 0.0554079 loss)
I0906 03:41:25.962237 90901 sgd_solver.cpp:106] Iteration 76290, lr = 0.001
I0906 03:41:34.934490 90901 solver.cpp:228] Iteration 76300, loss = 0.128122
I0906 03:41:34.934661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128124 (* 1 = 0.128124 loss)
I0906 03:41:34.934679 90901 sgd_solver.cpp:106] Iteration 76300, lr = 0.001
I0906 03:41:44.228440 90901 solver.cpp:228] Iteration 76310, loss = 0.169416
I0906 03:41:44.228508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169418 (* 1 = 0.169418 loss)
I0906 03:41:44.228528 90901 sgd_solver.cpp:106] Iteration 76310, lr = 0.001
I0906 03:41:53.364145 90901 solver.cpp:228] Iteration 76320, loss = 0.125327
I0906 03:41:53.364214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125329 (* 1 = 0.125329 loss)
I0906 03:41:53.364230 90901 sgd_solver.cpp:106] Iteration 76320, lr = 0.001
I0906 03:42:01.934787 90901 solver.cpp:228] Iteration 76330, loss = 0.238672
I0906 03:42:01.934859 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238674 (* 1 = 0.238674 loss)
I0906 03:42:01.934875 90901 sgd_solver.cpp:106] Iteration 76330, lr = 0.001
I0906 03:42:11.183197 90901 solver.cpp:228] Iteration 76340, loss = 0.165056
I0906 03:42:11.183408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165058 (* 1 = 0.165058 loss)
I0906 03:42:11.183425 90901 sgd_solver.cpp:106] Iteration 76340, lr = 0.001
I0906 03:42:19.864812 90901 solver.cpp:228] Iteration 76350, loss = 0.468894
I0906 03:42:19.864889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468895 (* 1 = 0.468895 loss)
I0906 03:42:19.864907 90901 sgd_solver.cpp:106] Iteration 76350, lr = 0.001
I0906 03:42:29.315141 90901 solver.cpp:228] Iteration 76360, loss = 0.24916
I0906 03:42:29.315210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249161 (* 1 = 0.249161 loss)
I0906 03:42:29.315227 90901 sgd_solver.cpp:106] Iteration 76360, lr = 0.001
I0906 03:42:38.014282 90901 solver.cpp:228] Iteration 76370, loss = 0.110398
I0906 03:42:38.014346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110399 (* 1 = 0.110399 loss)
I0906 03:42:38.014364 90901 sgd_solver.cpp:106] Iteration 76370, lr = 0.001
I0906 03:42:46.486723 90901 solver.cpp:228] Iteration 76380, loss = 0.0575547
I0906 03:42:46.486964 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0575561 (* 1 = 0.0575561 loss)
I0906 03:42:46.486984 90901 sgd_solver.cpp:106] Iteration 76380, lr = 0.001
I0906 03:42:55.363224 90901 solver.cpp:228] Iteration 76390, loss = 0.111509
I0906 03:42:55.363304 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111511 (* 1 = 0.111511 loss)
I0906 03:42:55.363320 90901 sgd_solver.cpp:106] Iteration 76390, lr = 0.001
I0906 03:43:00.574190 90901 solver.cpp:228] Iteration 76400, loss = 0.0812993
I0906 03:43:00.574254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0813007 (* 1 = 0.0813007 loss)
I0906 03:43:00.574277 90901 sgd_solver.cpp:106] Iteration 76400, lr = 0.001
I0906 03:43:05.754128 90901 solver.cpp:228] Iteration 76410, loss = 0.112055
I0906 03:43:05.754182 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112057 (* 1 = 0.112057 loss)
I0906 03:43:05.754199 90901 sgd_solver.cpp:106] Iteration 76410, lr = 0.001
I0906 03:43:10.947397 90901 solver.cpp:228] Iteration 76420, loss = 0.123946
I0906 03:43:10.947450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123947 (* 1 = 0.123947 loss)
I0906 03:43:10.947466 90901 sgd_solver.cpp:106] Iteration 76420, lr = 0.001
I0906 03:43:16.906105 90901 solver.cpp:228] Iteration 76430, loss = 0.199655
I0906 03:43:16.906289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199657 (* 1 = 0.199657 loss)
I0906 03:43:16.906318 90901 sgd_solver.cpp:106] Iteration 76430, lr = 0.001
I0906 03:43:25.468143 90901 solver.cpp:228] Iteration 76440, loss = 0.0754541
I0906 03:43:25.468231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0754555 (* 1 = 0.0754555 loss)
I0906 03:43:25.468253 90901 sgd_solver.cpp:106] Iteration 76440, lr = 0.001
I0906 03:43:34.610945 90901 solver.cpp:228] Iteration 76450, loss = 0.248121
I0906 03:43:34.611016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248123 (* 1 = 0.248123 loss)
I0906 03:43:34.611035 90901 sgd_solver.cpp:106] Iteration 76450, lr = 0.001
I0906 03:43:43.510428 90901 solver.cpp:228] Iteration 76460, loss = 0.14981
I0906 03:43:43.510524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149811 (* 1 = 0.149811 loss)
I0906 03:43:43.510541 90901 sgd_solver.cpp:106] Iteration 76460, lr = 0.001
I0906 03:43:52.601560 90901 solver.cpp:228] Iteration 76470, loss = 0.303139
I0906 03:43:52.601713 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30314 (* 1 = 0.30314 loss)
I0906 03:43:52.601729 90901 sgd_solver.cpp:106] Iteration 76470, lr = 0.001
I0906 03:44:01.552983 90901 solver.cpp:228] Iteration 76480, loss = 0.0445769
I0906 03:44:01.553117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0445783 (* 1 = 0.0445783 loss)
I0906 03:44:01.553140 90901 sgd_solver.cpp:106] Iteration 76480, lr = 0.001
I0906 03:44:10.448832 90901 solver.cpp:228] Iteration 76490, loss = 0.108911
I0906 03:44:10.448894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108912 (* 1 = 0.108912 loss)
I0906 03:44:10.448909 90901 sgd_solver.cpp:106] Iteration 76490, lr = 0.001
I0906 03:44:19.398355 90901 solver.cpp:228] Iteration 76500, loss = 0.284757
I0906 03:44:19.398411 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284758 (* 1 = 0.284758 loss)
I0906 03:44:19.398427 90901 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I0906 03:44:27.889967 90901 solver.cpp:228] Iteration 76510, loss = 0.114202
I0906 03:44:27.890188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114204 (* 1 = 0.114204 loss)
I0906 03:44:27.890213 90901 sgd_solver.cpp:106] Iteration 76510, lr = 0.001
I0906 03:44:36.755997 90901 solver.cpp:228] Iteration 76520, loss = 0.266092
I0906 03:44:36.756054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266094 (* 1 = 0.266094 loss)
I0906 03:44:36.756069 90901 sgd_solver.cpp:106] Iteration 76520, lr = 0.001
I0906 03:44:45.659605 90901 solver.cpp:228] Iteration 76530, loss = 0.150634
I0906 03:44:45.659704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150635 (* 1 = 0.150635 loss)
I0906 03:44:45.659723 90901 sgd_solver.cpp:106] Iteration 76530, lr = 0.001
I0906 03:44:54.241163 90901 solver.cpp:228] Iteration 76540, loss = 0.139008
I0906 03:44:54.241253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139009 (* 1 = 0.139009 loss)
I0906 03:44:54.241271 90901 sgd_solver.cpp:106] Iteration 76540, lr = 0.001
I0906 03:45:03.055109 90901 solver.cpp:228] Iteration 76550, loss = 0.160263
I0906 03:45:03.055306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160265 (* 1 = 0.160265 loss)
I0906 03:45:03.055336 90901 sgd_solver.cpp:106] Iteration 76550, lr = 0.001
I0906 03:45:11.374382 90901 solver.cpp:228] Iteration 76560, loss = 0.0277249
I0906 03:45:11.374446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0277264 (* 1 = 0.0277264 loss)
I0906 03:45:11.374465 90901 sgd_solver.cpp:106] Iteration 76560, lr = 0.001
I0906 03:45:20.245404 90901 solver.cpp:228] Iteration 76570, loss = 0.0315565
I0906 03:45:20.245468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0315579 (* 1 = 0.0315579 loss)
I0906 03:45:20.245484 90901 sgd_solver.cpp:106] Iteration 76570, lr = 0.001
I0906 03:45:28.980298 90901 solver.cpp:228] Iteration 76580, loss = 0.0597669
I0906 03:45:28.980360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0597683 (* 1 = 0.0597683 loss)
I0906 03:45:28.980376 90901 sgd_solver.cpp:106] Iteration 76580, lr = 0.001
I0906 03:45:37.410876 90901 solver.cpp:228] Iteration 76590, loss = 0.305876
I0906 03:45:37.411078 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305877 (* 1 = 0.305877 loss)
I0906 03:45:37.411118 90901 sgd_solver.cpp:106] Iteration 76590, lr = 0.001
I0906 03:45:45.976804 90901 solver.cpp:228] Iteration 76600, loss = 0.149503
I0906 03:45:45.976881 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149504 (* 1 = 0.149504 loss)
I0906 03:45:45.976898 90901 sgd_solver.cpp:106] Iteration 76600, lr = 0.001
I0906 03:45:54.926503 90901 solver.cpp:228] Iteration 76610, loss = 0.0300514
I0906 03:45:54.926565 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0300528 (* 1 = 0.0300528 loss)
I0906 03:45:54.926585 90901 sgd_solver.cpp:106] Iteration 76610, lr = 0.001
I0906 03:46:03.727982 90901 solver.cpp:228] Iteration 76620, loss = 0.255763
I0906 03:46:03.728083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255765 (* 1 = 0.255765 loss)
I0906 03:46:03.728107 90901 sgd_solver.cpp:106] Iteration 76620, lr = 0.001
I0906 03:46:12.691929 90901 solver.cpp:228] Iteration 76630, loss = 0.203036
I0906 03:46:12.692131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203037 (* 1 = 0.203037 loss)
I0906 03:46:12.692149 90901 sgd_solver.cpp:106] Iteration 76630, lr = 0.001
I0906 03:46:21.704649 90901 solver.cpp:228] Iteration 76640, loss = 0.359646
I0906 03:46:21.704718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359648 (* 1 = 0.359648 loss)
I0906 03:46:21.704737 90901 sgd_solver.cpp:106] Iteration 76640, lr = 0.001
I0906 03:46:30.319749 90901 solver.cpp:228] Iteration 76650, loss = 0.0888389
I0906 03:46:30.319833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0888403 (* 1 = 0.0888403 loss)
I0906 03:46:30.319851 90901 sgd_solver.cpp:106] Iteration 76650, lr = 0.001
I0906 03:46:38.949995 90901 solver.cpp:228] Iteration 76660, loss = 0.155685
I0906 03:46:38.950040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155687 (* 1 = 0.155687 loss)
I0906 03:46:38.950054 90901 sgd_solver.cpp:106] Iteration 76660, lr = 0.001
I0906 03:46:47.851235 90901 solver.cpp:228] Iteration 76670, loss = 0.364829
I0906 03:46:47.851373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36483 (* 1 = 0.36483 loss)
I0906 03:46:47.851403 90901 sgd_solver.cpp:106] Iteration 76670, lr = 0.001
I0906 03:46:56.732064 90901 solver.cpp:228] Iteration 76680, loss = 0.21672
I0906 03:46:56.732154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216722 (* 1 = 0.216722 loss)
I0906 03:46:56.732172 90901 sgd_solver.cpp:106] Iteration 76680, lr = 0.001
I0906 03:47:05.625656 90901 solver.cpp:228] Iteration 76690, loss = 0.101832
I0906 03:47:05.625795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101833 (* 1 = 0.101833 loss)
I0906 03:47:05.625811 90901 sgd_solver.cpp:106] Iteration 76690, lr = 0.001
I0906 03:47:14.370239 90901 solver.cpp:228] Iteration 76700, loss = 0.0570976
I0906 03:47:14.370282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.057099 (* 1 = 0.057099 loss)
I0906 03:47:14.370297 90901 sgd_solver.cpp:106] Iteration 76700, lr = 0.001
I0906 03:47:22.902621 90901 solver.cpp:228] Iteration 76710, loss = 0.0451313
I0906 03:47:22.902982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0451327 (* 1 = 0.0451327 loss)
I0906 03:47:22.903004 90901 sgd_solver.cpp:106] Iteration 76710, lr = 0.001
I0906 03:47:31.805253 90901 solver.cpp:228] Iteration 76720, loss = 0.143572
I0906 03:47:31.805325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143574 (* 1 = 0.143574 loss)
I0906 03:47:31.805341 90901 sgd_solver.cpp:106] Iteration 76720, lr = 0.001
I0906 03:47:40.120920 90901 solver.cpp:228] Iteration 76730, loss = 0.138815
I0906 03:47:40.120990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138817 (* 1 = 0.138817 loss)
I0906 03:47:40.121009 90901 sgd_solver.cpp:106] Iteration 76730, lr = 0.001
I0906 03:47:47.930183 90901 solver.cpp:228] Iteration 76740, loss = 0.260348
I0906 03:47:47.930243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260349 (* 1 = 0.260349 loss)
I0906 03:47:47.930259 90901 sgd_solver.cpp:106] Iteration 76740, lr = 0.001
I0906 03:47:53.110272 90901 solver.cpp:228] Iteration 76750, loss = 0.0519977
I0906 03:47:53.114699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0519991 (* 1 = 0.0519991 loss)
I0906 03:47:53.114717 90901 sgd_solver.cpp:106] Iteration 76750, lr = 0.001
I0906 03:47:58.322263 90901 solver.cpp:228] Iteration 76760, loss = 0.105392
I0906 03:47:58.322332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105393 (* 1 = 0.105393 loss)
I0906 03:47:58.322355 90901 sgd_solver.cpp:106] Iteration 76760, lr = 0.001
I0906 03:48:03.877018 90901 solver.cpp:228] Iteration 76770, loss = 0.50493
I0906 03:48:03.877071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504931 (* 1 = 0.504931 loss)
I0906 03:48:03.877086 90901 sgd_solver.cpp:106] Iteration 76770, lr = 0.001
I0906 03:48:12.543802 90901 solver.cpp:228] Iteration 76780, loss = 0.0580145
I0906 03:48:12.543855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.058016 (* 1 = 0.058016 loss)
I0906 03:48:12.543869 90901 sgd_solver.cpp:106] Iteration 76780, lr = 0.001
I0906 03:48:20.470417 90901 solver.cpp:228] Iteration 76790, loss = 0.19187
I0906 03:48:20.470489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191872 (* 1 = 0.191872 loss)
I0906 03:48:20.470505 90901 sgd_solver.cpp:106] Iteration 76790, lr = 0.001
I0906 03:48:28.691671 90901 solver.cpp:337] Iteration 76800, Testing net (#0)
I0906 03:49:30.983302 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.940625
I0906 03:49:30.983449 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.157669 (* 1 = 0.157669 loss)
I0906 03:49:31.374505 90901 solver.cpp:228] Iteration 76800, loss = 0.127588
I0906 03:49:31.374572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127589 (* 1 = 0.127589 loss)
I0906 03:49:31.374594 90901 sgd_solver.cpp:106] Iteration 76800, lr = 0.001
I0906 03:49:40.796627 90901 solver.cpp:228] Iteration 76810, loss = 0.285089
I0906 03:49:40.796689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285091 (* 1 = 0.285091 loss)
I0906 03:49:40.796705 90901 sgd_solver.cpp:106] Iteration 76810, lr = 0.001
I0906 03:49:49.660401 90901 solver.cpp:228] Iteration 76820, loss = 0.0993776
I0906 03:49:49.660478 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.099379 (* 1 = 0.099379 loss)
I0906 03:49:49.660495 90901 sgd_solver.cpp:106] Iteration 76820, lr = 0.001
I0906 03:49:59.352684 90901 solver.cpp:228] Iteration 76830, loss = 0.219576
I0906 03:49:59.352751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219577 (* 1 = 0.219577 loss)
I0906 03:49:59.352771 90901 sgd_solver.cpp:106] Iteration 76830, lr = 0.001
I0906 03:50:08.128592 90901 solver.cpp:228] Iteration 76840, loss = 0.136993
I0906 03:50:08.128795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136995 (* 1 = 0.136995 loss)
I0906 03:50:08.128819 90901 sgd_solver.cpp:106] Iteration 76840, lr = 0.001
I0906 03:50:17.582559 90901 solver.cpp:228] Iteration 76850, loss = 0.135576
I0906 03:50:17.582638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135578 (* 1 = 0.135578 loss)
I0906 03:50:17.582656 90901 sgd_solver.cpp:106] Iteration 76850, lr = 0.001
I0906 03:50:26.724851 90901 solver.cpp:228] Iteration 76860, loss = 0.0504261
I0906 03:50:26.724936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0504276 (* 1 = 0.0504276 loss)
I0906 03:50:26.724953 90901 sgd_solver.cpp:106] Iteration 76860, lr = 0.001
I0906 03:50:35.807961 90901 solver.cpp:228] Iteration 76870, loss = 0.107854
I0906 03:50:35.808028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107856 (* 1 = 0.107856 loss)
I0906 03:50:35.808048 90901 sgd_solver.cpp:106] Iteration 76870, lr = 0.001
I0906 03:50:44.929735 90901 solver.cpp:228] Iteration 76880, loss = 0.0743776
I0906 03:50:44.929909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.074379 (* 1 = 0.074379 loss)
I0906 03:50:44.929955 90901 sgd_solver.cpp:106] Iteration 76880, lr = 0.001
I0906 03:50:53.605558 90901 solver.cpp:228] Iteration 76890, loss = 0.0377678
I0906 03:50:53.605618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0377692 (* 1 = 0.0377692 loss)
I0906 03:50:53.605635 90901 sgd_solver.cpp:106] Iteration 76890, lr = 0.001
I0906 03:51:02.656775 90901 solver.cpp:228] Iteration 76900, loss = 0.0711384
I0906 03:51:02.656846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0711398 (* 1 = 0.0711398 loss)
I0906 03:51:02.656860 90901 sgd_solver.cpp:106] Iteration 76900, lr = 0.001
I0906 03:51:11.735923 90901 solver.cpp:228] Iteration 76910, loss = 0.255951
I0906 03:51:11.735985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255952 (* 1 = 0.255952 loss)
I0906 03:51:11.736001 90901 sgd_solver.cpp:106] Iteration 76910, lr = 0.001
I0906 03:51:20.597028 90901 solver.cpp:228] Iteration 76920, loss = 0.0724134
I0906 03:51:20.597376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0724148 (* 1 = 0.0724148 loss)
I0906 03:51:20.597396 90901 sgd_solver.cpp:106] Iteration 76920, lr = 0.001
I0906 03:51:29.874290 90901 solver.cpp:228] Iteration 76930, loss = 0.169019
I0906 03:51:29.874371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16902 (* 1 = 0.16902 loss)
I0906 03:51:29.874387 90901 sgd_solver.cpp:106] Iteration 76930, lr = 0.001
I0906 03:51:38.519100 90901 solver.cpp:228] Iteration 76940, loss = 0.0764052
I0906 03:51:38.519188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0764067 (* 1 = 0.0764067 loss)
I0906 03:51:38.519210 90901 sgd_solver.cpp:106] Iteration 76940, lr = 0.001
I0906 03:51:47.417872 90901 solver.cpp:228] Iteration 76950, loss = 0.119743
I0906 03:51:47.417948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119745 (* 1 = 0.119745 loss)
I0906 03:51:47.417964 90901 sgd_solver.cpp:106] Iteration 76950, lr = 0.001
I0906 03:51:56.566609 90901 solver.cpp:228] Iteration 76960, loss = 0.526426
I0906 03:51:56.566848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.526427 (* 1 = 0.526427 loss)
I0906 03:51:56.566884 90901 sgd_solver.cpp:106] Iteration 76960, lr = 0.001
I0906 03:52:05.116158 90901 solver.cpp:228] Iteration 76970, loss = 0.098708
I0906 03:52:05.116235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0987094 (* 1 = 0.0987094 loss)
I0906 03:52:05.116250 90901 sgd_solver.cpp:106] Iteration 76970, lr = 0.001
I0906 03:52:14.557008 90901 solver.cpp:228] Iteration 76980, loss = 0.450812
I0906 03:52:14.557066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.450814 (* 1 = 0.450814 loss)
I0906 03:52:14.557081 90901 sgd_solver.cpp:106] Iteration 76980, lr = 0.001
I0906 03:52:23.568559 90901 solver.cpp:228] Iteration 76990, loss = 0.115099
I0906 03:52:23.568641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1151 (* 1 = 0.1151 loss)
I0906 03:52:23.568660 90901 sgd_solver.cpp:106] Iteration 76990, lr = 0.001
I0906 03:52:32.421012 90901 solver.cpp:228] Iteration 77000, loss = 0.185221
I0906 03:52:32.421208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185222 (* 1 = 0.185222 loss)
I0906 03:52:32.421241 90901 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I0906 03:52:41.520777 90901 solver.cpp:228] Iteration 77010, loss = 0.0470502
I0906 03:52:41.520844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0470516 (* 1 = 0.0470516 loss)
I0906 03:52:41.520859 90901 sgd_solver.cpp:106] Iteration 77010, lr = 0.001
I0906 03:52:50.374866 90901 solver.cpp:228] Iteration 77020, loss = 0.127677
I0906 03:52:50.374934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127679 (* 1 = 0.127679 loss)
I0906 03:52:50.374950 90901 sgd_solver.cpp:106] Iteration 77020, lr = 0.001
I0906 03:52:59.500179 90901 solver.cpp:228] Iteration 77030, loss = 0.0402516
I0906 03:52:59.500244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.040253 (* 1 = 0.040253 loss)
I0906 03:52:59.500260 90901 sgd_solver.cpp:106] Iteration 77030, lr = 0.001
I0906 03:53:08.610110 90901 solver.cpp:228] Iteration 77040, loss = 0.0619937
I0906 03:53:08.610311 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0619952 (* 1 = 0.0619952 loss)
I0906 03:53:08.610343 90901 sgd_solver.cpp:106] Iteration 77040, lr = 0.001
I0906 03:53:18.007462 90901 solver.cpp:228] Iteration 77050, loss = 0.0816022
I0906 03:53:18.007530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0816037 (* 1 = 0.0816037 loss)
I0906 03:53:18.007546 90901 sgd_solver.cpp:106] Iteration 77050, lr = 0.001
I0906 03:53:26.939538 90901 solver.cpp:228] Iteration 77060, loss = 0.367514
I0906 03:53:26.939599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367516 (* 1 = 0.367516 loss)
I0906 03:53:26.939615 90901 sgd_solver.cpp:106] Iteration 77060, lr = 0.001
I0906 03:53:35.961638 90901 solver.cpp:228] Iteration 77070, loss = 0.0677999
I0906 03:53:35.961702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0678014 (* 1 = 0.0678014 loss)
I0906 03:53:35.961719 90901 sgd_solver.cpp:106] Iteration 77070, lr = 0.001
I0906 03:53:44.814532 90901 solver.cpp:228] Iteration 77080, loss = 0.0967318
I0906 03:53:44.814784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0967334 (* 1 = 0.0967334 loss)
I0906 03:53:44.814821 90901 sgd_solver.cpp:106] Iteration 77080, lr = 0.001
I0906 03:53:53.425576 90901 solver.cpp:228] Iteration 77090, loss = 0.0159827
I0906 03:53:53.425662 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0159842 (* 1 = 0.0159842 loss)
I0906 03:53:53.425679 90901 sgd_solver.cpp:106] Iteration 77090, lr = 0.001
I0906 03:54:02.530572 90901 solver.cpp:228] Iteration 77100, loss = 0.0690691
I0906 03:54:02.530674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0690706 (* 1 = 0.0690706 loss)
I0906 03:54:02.530702 90901 sgd_solver.cpp:106] Iteration 77100, lr = 0.001
I0906 03:54:11.172446 90901 solver.cpp:228] Iteration 77110, loss = 0.0351518
I0906 03:54:11.172511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0351533 (* 1 = 0.0351533 loss)
I0906 03:54:11.172531 90901 sgd_solver.cpp:106] Iteration 77110, lr = 0.001
I0906 03:54:20.232803 90901 solver.cpp:228] Iteration 77120, loss = 0.035256
I0906 03:54:20.232929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0352576 (* 1 = 0.0352576 loss)
I0906 03:54:20.232947 90901 sgd_solver.cpp:106] Iteration 77120, lr = 0.001
I0906 03:54:29.022992 90901 solver.cpp:228] Iteration 77130, loss = 0.145109
I0906 03:54:29.023041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145111 (* 1 = 0.145111 loss)
I0906 03:54:29.023056 90901 sgd_solver.cpp:106] Iteration 77130, lr = 0.001
I0906 03:54:38.087568 90901 solver.cpp:228] Iteration 77140, loss = 0.0951231
I0906 03:54:38.087627 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0951247 (* 1 = 0.0951247 loss)
I0906 03:54:38.087643 90901 sgd_solver.cpp:106] Iteration 77140, lr = 0.001
I0906 03:54:46.812907 90901 solver.cpp:228] Iteration 77150, loss = 0.0937074
I0906 03:54:46.812980 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0937089 (* 1 = 0.0937089 loss)
I0906 03:54:46.812999 90901 sgd_solver.cpp:106] Iteration 77150, lr = 0.001
I0906 03:54:55.797868 90901 solver.cpp:228] Iteration 77160, loss = 0.25676
I0906 03:54:55.798048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256761 (* 1 = 0.256761 loss)
I0906 03:54:55.798095 90901 sgd_solver.cpp:106] Iteration 77160, lr = 0.001
I0906 03:55:04.654528 90901 solver.cpp:228] Iteration 77170, loss = 0.226496
I0906 03:55:04.654595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226497 (* 1 = 0.226497 loss)
I0906 03:55:04.654610 90901 sgd_solver.cpp:106] Iteration 77170, lr = 0.001
I0906 03:55:13.539378 90901 solver.cpp:228] Iteration 77180, loss = 0.123524
I0906 03:55:13.539445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123525 (* 1 = 0.123525 loss)
I0906 03:55:13.539463 90901 sgd_solver.cpp:106] Iteration 77180, lr = 0.001
I0906 03:55:22.335475 90901 solver.cpp:228] Iteration 77190, loss = 0.465155
I0906 03:55:22.335530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465157 (* 1 = 0.465157 loss)
I0906 03:55:22.335543 90901 sgd_solver.cpp:106] Iteration 77190, lr = 0.001
I0906 03:55:31.232383 90901 solver.cpp:228] Iteration 77200, loss = 0.109607
I0906 03:55:31.232573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109609 (* 1 = 0.109609 loss)
I0906 03:55:31.232602 90901 sgd_solver.cpp:106] Iteration 77200, lr = 0.001
I0906 03:55:40.290792 90901 solver.cpp:228] Iteration 77210, loss = 0.069593
I0906 03:55:40.290868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0695946 (* 1 = 0.0695946 loss)
I0906 03:55:40.290884 90901 sgd_solver.cpp:106] Iteration 77210, lr = 0.001
I0906 03:55:49.435765 90901 solver.cpp:228] Iteration 77220, loss = 0.0891078
I0906 03:55:49.435832 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0891094 (* 1 = 0.0891094 loss)
I0906 03:55:49.435847 90901 sgd_solver.cpp:106] Iteration 77220, lr = 0.001
I0906 03:55:58.862072 90901 solver.cpp:228] Iteration 77230, loss = 0.0526282
I0906 03:55:58.862144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0526298 (* 1 = 0.0526298 loss)
I0906 03:55:58.862162 90901 sgd_solver.cpp:106] Iteration 77230, lr = 0.001
I0906 03:56:07.426180 90901 solver.cpp:228] Iteration 77240, loss = 0.210619
I0906 03:56:07.426898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21062 (* 1 = 0.21062 loss)
I0906 03:56:07.426925 90901 sgd_solver.cpp:106] Iteration 77240, lr = 0.001
I0906 03:56:16.865262 90901 solver.cpp:228] Iteration 77250, loss = 0.225691
I0906 03:56:16.865331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225692 (* 1 = 0.225692 loss)
I0906 03:56:16.865347 90901 sgd_solver.cpp:106] Iteration 77250, lr = 0.001
I0906 03:56:25.473722 90901 solver.cpp:228] Iteration 77260, loss = 0.182549
I0906 03:56:25.473824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182551 (* 1 = 0.182551 loss)
I0906 03:56:25.473841 90901 sgd_solver.cpp:106] Iteration 77260, lr = 0.001
I0906 03:56:34.324267 90901 solver.cpp:228] Iteration 77270, loss = 0.0472979
I0906 03:56:34.324358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0472995 (* 1 = 0.0472995 loss)
I0906 03:56:34.324374 90901 sgd_solver.cpp:106] Iteration 77270, lr = 0.001
I0906 03:56:42.971796 90901 solver.cpp:228] Iteration 77280, loss = 0.0463422
I0906 03:56:42.971923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0463437 (* 1 = 0.0463437 loss)
I0906 03:56:42.971954 90901 sgd_solver.cpp:106] Iteration 77280, lr = 0.001
I0906 03:56:52.086514 90901 solver.cpp:228] Iteration 77290, loss = 0.366046
I0906 03:56:52.086586 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366048 (* 1 = 0.366048 loss)
I0906 03:56:52.086603 90901 sgd_solver.cpp:106] Iteration 77290, lr = 0.001
I0906 03:57:00.993427 90901 solver.cpp:228] Iteration 77300, loss = 0.221746
I0906 03:57:00.993517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221747 (* 1 = 0.221747 loss)
I0906 03:57:00.993535 90901 sgd_solver.cpp:106] Iteration 77300, lr = 0.001
I0906 03:57:09.904625 90901 solver.cpp:228] Iteration 77310, loss = 0.171854
I0906 03:57:09.904688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171855 (* 1 = 0.171855 loss)
I0906 03:57:09.904705 90901 sgd_solver.cpp:106] Iteration 77310, lr = 0.001
I0906 03:57:18.912384 90901 solver.cpp:228] Iteration 77320, loss = 0.20874
I0906 03:57:18.912534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208742 (* 1 = 0.208742 loss)
I0906 03:57:18.912550 90901 sgd_solver.cpp:106] Iteration 77320, lr = 0.001
I0906 03:57:27.743480 90901 solver.cpp:228] Iteration 77330, loss = 0.0661984
I0906 03:57:27.743528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0661999 (* 1 = 0.0661999 loss)
I0906 03:57:27.743542 90901 sgd_solver.cpp:106] Iteration 77330, lr = 0.001
I0906 03:57:36.725925 90901 solver.cpp:228] Iteration 77340, loss = 0.110699
I0906 03:57:36.725999 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1107 (* 1 = 0.1107 loss)
I0906 03:57:36.726022 90901 sgd_solver.cpp:106] Iteration 77340, lr = 0.001
I0906 03:57:45.953986 90901 solver.cpp:228] Iteration 77350, loss = 0.0404617
I0906 03:57:45.954058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0404631 (* 1 = 0.0404631 loss)
I0906 03:57:45.954076 90901 sgd_solver.cpp:106] Iteration 77350, lr = 0.001
I0906 03:57:54.779484 90901 solver.cpp:228] Iteration 77360, loss = 0.250741
I0906 03:57:54.779655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250743 (* 1 = 0.250743 loss)
I0906 03:57:54.779696 90901 sgd_solver.cpp:106] Iteration 77360, lr = 0.001
I0906 03:58:03.329648 90901 solver.cpp:228] Iteration 77370, loss = 0.175334
I0906 03:58:03.329723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175335 (* 1 = 0.175335 loss)
I0906 03:58:03.329737 90901 sgd_solver.cpp:106] Iteration 77370, lr = 0.001
I0906 03:58:12.282076 90901 solver.cpp:228] Iteration 77380, loss = 0.0646797
I0906 03:58:12.282131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0646812 (* 1 = 0.0646812 loss)
I0906 03:58:12.282147 90901 sgd_solver.cpp:106] Iteration 77380, lr = 0.001
I0906 03:58:21.420348 90901 solver.cpp:228] Iteration 77390, loss = 0.384244
I0906 03:58:21.420424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.384245 (* 1 = 0.384245 loss)
I0906 03:58:21.420441 90901 sgd_solver.cpp:106] Iteration 77390, lr = 0.001
I0906 03:58:30.684581 90901 solver.cpp:228] Iteration 77400, loss = 0.255805
I0906 03:58:30.684824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255806 (* 1 = 0.255806 loss)
I0906 03:58:30.684842 90901 sgd_solver.cpp:106] Iteration 77400, lr = 0.001
I0906 03:58:39.905319 90901 solver.cpp:228] Iteration 77410, loss = 0.267489
I0906 03:58:39.905383 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267491 (* 1 = 0.267491 loss)
I0906 03:58:39.905401 90901 sgd_solver.cpp:106] Iteration 77410, lr = 0.001
I0906 03:58:48.255475 90901 solver.cpp:228] Iteration 77420, loss = 0.0813994
I0906 03:58:48.255551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0814009 (* 1 = 0.0814009 loss)
I0906 03:58:48.255568 90901 sgd_solver.cpp:106] Iteration 77420, lr = 0.001
I0906 03:58:57.315485 90901 solver.cpp:228] Iteration 77430, loss = 0.133799
I0906 03:58:57.315541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133801 (* 1 = 0.133801 loss)
I0906 03:58:57.315557 90901 sgd_solver.cpp:106] Iteration 77430, lr = 0.001
I0906 03:59:06.569478 90901 solver.cpp:228] Iteration 77440, loss = 0.288857
I0906 03:59:06.569694 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288858 (* 1 = 0.288858 loss)
I0906 03:59:06.569725 90901 sgd_solver.cpp:106] Iteration 77440, lr = 0.001
I0906 03:59:14.385016 90901 solver.cpp:228] Iteration 77450, loss = 0.0451299
I0906 03:59:14.385073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0451314 (* 1 = 0.0451314 loss)
I0906 03:59:14.385090 90901 sgd_solver.cpp:106] Iteration 77450, lr = 0.001
I0906 03:59:19.572952 90901 solver.cpp:228] Iteration 77460, loss = 0.0589078
I0906 03:59:19.573015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0589093 (* 1 = 0.0589093 loss)
I0906 03:59:19.573031 90901 sgd_solver.cpp:106] Iteration 77460, lr = 0.001
I0906 03:59:24.784126 90901 solver.cpp:228] Iteration 77470, loss = 0.11672
I0906 03:59:24.784183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116722 (* 1 = 0.116722 loss)
I0906 03:59:24.784198 90901 sgd_solver.cpp:106] Iteration 77470, lr = 0.001
I0906 03:59:30.289984 90901 solver.cpp:228] Iteration 77480, loss = 0.305905
I0906 03:59:30.290068 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305907 (* 1 = 0.305907 loss)
I0906 03:59:30.290086 90901 sgd_solver.cpp:106] Iteration 77480, lr = 0.001
I0906 03:59:35.485693 90901 solver.cpp:228] Iteration 77490, loss = 0.0350785
I0906 03:59:35.485767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.03508 (* 1 = 0.03508 loss)
I0906 03:59:35.485787 90901 sgd_solver.cpp:106] Iteration 77490, lr = 0.001
I0906 03:59:42.942243 90901 solver.cpp:228] Iteration 77500, loss = 0.0906123
I0906 03:59:42.942442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0906139 (* 1 = 0.0906139 loss)
I0906 03:59:42.942462 90901 sgd_solver.cpp:106] Iteration 77500, lr = 0.001
I0906 03:59:49.489691 90901 solver.cpp:228] Iteration 77510, loss = 0.0587762
I0906 03:59:49.489753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0587778 (* 1 = 0.0587778 loss)
I0906 03:59:49.489769 90901 sgd_solver.cpp:106] Iteration 77510, lr = 0.001
I0906 03:59:57.312997 90901 solver.cpp:228] Iteration 77520, loss = 0.219164
I0906 03:59:57.313060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219166 (* 1 = 0.219166 loss)
I0906 03:59:57.313076 90901 sgd_solver.cpp:106] Iteration 77520, lr = 0.001
I0906 04:00:05.339808 90901 solver.cpp:228] Iteration 77530, loss = 0.282976
I0906 04:00:05.339874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282977 (* 1 = 0.282977 loss)
I0906 04:00:05.339890 90901 sgd_solver.cpp:106] Iteration 77530, lr = 0.001
I0906 04:00:13.173933 90901 solver.cpp:228] Iteration 77540, loss = 0.0478454
I0906 04:00:13.174227 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0478469 (* 1 = 0.0478469 loss)
I0906 04:00:13.174247 90901 sgd_solver.cpp:106] Iteration 77540, lr = 0.001
I0906 04:00:20.696671 90901 solver.cpp:228] Iteration 77550, loss = 0.0461116
I0906 04:00:20.696750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0461132 (* 1 = 0.0461132 loss)
I0906 04:00:20.696766 90901 sgd_solver.cpp:106] Iteration 77550, lr = 0.001
I0906 04:00:28.773633 90901 solver.cpp:228] Iteration 77560, loss = 0.199383
I0906 04:00:28.773728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199384 (* 1 = 0.199384 loss)
I0906 04:00:28.773747 90901 sgd_solver.cpp:106] Iteration 77560, lr = 0.001
I0906 04:00:37.365453 90901 solver.cpp:228] Iteration 77570, loss = 0.289147
I0906 04:00:37.365519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289149 (* 1 = 0.289149 loss)
I0906 04:00:37.365535 90901 sgd_solver.cpp:106] Iteration 77570, lr = 0.001
I0906 04:00:46.037853 90901 solver.cpp:228] Iteration 77580, loss = 0.0330146
I0906 04:00:46.038013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0330161 (* 1 = 0.0330161 loss)
I0906 04:00:46.038043 90901 sgd_solver.cpp:106] Iteration 77580, lr = 0.001
I0906 04:00:54.311178 90901 solver.cpp:228] Iteration 77590, loss = 0.079832
I0906 04:00:54.311244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0798336 (* 1 = 0.0798336 loss)
I0906 04:00:54.311260 90901 sgd_solver.cpp:106] Iteration 77590, lr = 0.001
I0906 04:01:02.907114 90901 solver.cpp:337] Iteration 77600, Testing net (#0)
I0906 04:02:04.663122 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.937187
I0906 04:02:04.663316 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.150959 (* 1 = 0.150959 loss)
I0906 04:02:04.940310 90901 solver.cpp:228] Iteration 77600, loss = 0.0334789
I0906 04:02:04.940368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0334804 (* 1 = 0.0334804 loss)
I0906 04:02:04.940387 90901 sgd_solver.cpp:106] Iteration 77600, lr = 0.001
I0906 04:02:14.085041 90901 solver.cpp:228] Iteration 77610, loss = 0.0593186
I0906 04:02:14.085124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0593201 (* 1 = 0.0593201 loss)
I0906 04:02:14.085140 90901 sgd_solver.cpp:106] Iteration 77610, lr = 0.001
I0906 04:02:22.880908 90901 solver.cpp:228] Iteration 77620, loss = 0.277002
I0906 04:02:22.880966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277003 (* 1 = 0.277003 loss)
I0906 04:02:22.880985 90901 sgd_solver.cpp:106] Iteration 77620, lr = 0.001
I0906 04:02:32.446678 90901 solver.cpp:228] Iteration 77630, loss = 0.311121
I0906 04:02:32.446751 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311122 (* 1 = 0.311122 loss)
I0906 04:02:32.446768 90901 sgd_solver.cpp:106] Iteration 77630, lr = 0.001
I0906 04:02:41.466297 90901 solver.cpp:228] Iteration 77640, loss = 0.0934621
I0906 04:02:41.466480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0934637 (* 1 = 0.0934637 loss)
I0906 04:02:41.466511 90901 sgd_solver.cpp:106] Iteration 77640, lr = 0.001
I0906 04:02:50.314297 90901 solver.cpp:228] Iteration 77650, loss = 0.157881
I0906 04:02:50.314368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157882 (* 1 = 0.157882 loss)
I0906 04:02:50.314388 90901 sgd_solver.cpp:106] Iteration 77650, lr = 0.001
I0906 04:02:59.416824 90901 solver.cpp:228] Iteration 77660, loss = 0.131023
I0906 04:02:59.416889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131025 (* 1 = 0.131025 loss)
I0906 04:02:59.416905 90901 sgd_solver.cpp:106] Iteration 77660, lr = 0.001
I0906 04:03:08.544523 90901 solver.cpp:228] Iteration 77670, loss = 0.115265
I0906 04:03:08.544589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115267 (* 1 = 0.115267 loss)
I0906 04:03:08.544606 90901 sgd_solver.cpp:106] Iteration 77670, lr = 0.001
I0906 04:03:17.460407 90901 solver.cpp:228] Iteration 77680, loss = 0.354937
I0906 04:03:17.460682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.354939 (* 1 = 0.354939 loss)
I0906 04:03:17.460713 90901 sgd_solver.cpp:106] Iteration 77680, lr = 0.001
I0906 04:03:26.853924 90901 solver.cpp:228] Iteration 77690, loss = 0.0694958
I0906 04:03:26.853996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0694973 (* 1 = 0.0694973 loss)
I0906 04:03:26.854012 90901 sgd_solver.cpp:106] Iteration 77690, lr = 0.001
I0906 04:03:35.650843 90901 solver.cpp:228] Iteration 77700, loss = 0.0744456
I0906 04:03:35.650904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0744471 (* 1 = 0.0744471 loss)
I0906 04:03:35.650920 90901 sgd_solver.cpp:106] Iteration 77700, lr = 0.001
I0906 04:03:44.265967 90901 solver.cpp:228] Iteration 77710, loss = 0.236734
I0906 04:03:44.266031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236735 (* 1 = 0.236735 loss)
I0906 04:03:44.266048 90901 sgd_solver.cpp:106] Iteration 77710, lr = 0.001
I0906 04:03:53.220827 90901 solver.cpp:228] Iteration 77720, loss = 0.120929
I0906 04:03:53.221073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120931 (* 1 = 0.120931 loss)
I0906 04:03:53.221092 90901 sgd_solver.cpp:106] Iteration 77720, lr = 0.001
I0906 04:04:02.114433 90901 solver.cpp:228] Iteration 77730, loss = 0.372494
I0906 04:04:02.114493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372496 (* 1 = 0.372496 loss)
I0906 04:04:02.114511 90901 sgd_solver.cpp:106] Iteration 77730, lr = 0.001
I0906 04:04:10.432199 90901 solver.cpp:228] Iteration 77740, loss = 0.163903
I0906 04:04:10.432266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163905 (* 1 = 0.163905 loss)
I0906 04:04:10.432283 90901 sgd_solver.cpp:106] Iteration 77740, lr = 0.001
I0906 04:04:19.235991 90901 solver.cpp:228] Iteration 77750, loss = 0.129495
I0906 04:04:19.236090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129496 (* 1 = 0.129496 loss)
I0906 04:04:19.236106 90901 sgd_solver.cpp:106] Iteration 77750, lr = 0.001
I0906 04:04:28.175972 90901 solver.cpp:228] Iteration 77760, loss = 0.225896
I0906 04:04:28.176159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225897 (* 1 = 0.225897 loss)
I0906 04:04:28.176185 90901 sgd_solver.cpp:106] Iteration 77760, lr = 0.001
I0906 04:04:36.192848 90901 solver.cpp:228] Iteration 77770, loss = 0.151822
I0906 04:04:36.192915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151824 (* 1 = 0.151824 loss)
I0906 04:04:36.192931 90901 sgd_solver.cpp:106] Iteration 77770, lr = 0.001
I0906 04:04:44.450443 90901 solver.cpp:228] Iteration 77780, loss = 0.389756
I0906 04:04:44.450513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.389757 (* 1 = 0.389757 loss)
I0906 04:04:44.450531 90901 sgd_solver.cpp:106] Iteration 77780, lr = 0.001
I0906 04:04:52.868530 90901 solver.cpp:228] Iteration 77790, loss = 0.136226
I0906 04:04:52.868609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136228 (* 1 = 0.136228 loss)
I0906 04:04:52.868628 90901 sgd_solver.cpp:106] Iteration 77790, lr = 0.001
I0906 04:05:01.727843 90901 solver.cpp:228] Iteration 77800, loss = 0.236821
I0906 04:05:01.728032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236822 (* 1 = 0.236822 loss)
I0906 04:05:01.728055 90901 sgd_solver.cpp:106] Iteration 77800, lr = 0.001
I0906 04:05:10.324970 90901 solver.cpp:228] Iteration 77810, loss = 0.0991818
I0906 04:05:10.325044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0991834 (* 1 = 0.0991834 loss)
I0906 04:05:10.325062 90901 sgd_solver.cpp:106] Iteration 77810, lr = 0.001
I0906 04:05:19.526666 90901 solver.cpp:228] Iteration 77820, loss = 0.661463
I0906 04:05:19.526746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.661465 (* 1 = 0.661465 loss)
I0906 04:05:19.526767 90901 sgd_solver.cpp:106] Iteration 77820, lr = 0.001
I0906 04:05:27.636646 90901 solver.cpp:228] Iteration 77830, loss = 0.109702
I0906 04:05:27.636696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109704 (* 1 = 0.109704 loss)
I0906 04:05:27.636713 90901 sgd_solver.cpp:106] Iteration 77830, lr = 0.001
I0906 04:05:37.250315 90901 solver.cpp:228] Iteration 77840, loss = 0.188968
I0906 04:05:37.250538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18897 (* 1 = 0.18897 loss)
I0906 04:05:37.250558 90901 sgd_solver.cpp:106] Iteration 77840, lr = 0.001
I0906 04:05:45.846715 90901 solver.cpp:228] Iteration 77850, loss = 0.33586
I0906 04:05:45.846777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.335862 (* 1 = 0.335862 loss)
I0906 04:05:45.846794 90901 sgd_solver.cpp:106] Iteration 77850, lr = 0.001
I0906 04:05:55.033740 90901 solver.cpp:228] Iteration 77860, loss = 0.0916504
I0906 04:05:55.033838 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.091652 (* 1 = 0.091652 loss)
I0906 04:05:55.033855 90901 sgd_solver.cpp:106] Iteration 77860, lr = 0.001
I0906 04:06:03.601732 90901 solver.cpp:228] Iteration 77870, loss = 0.164625
I0906 04:06:03.601801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164627 (* 1 = 0.164627 loss)
I0906 04:06:03.601817 90901 sgd_solver.cpp:106] Iteration 77870, lr = 0.001
I0906 04:06:12.775692 90901 solver.cpp:228] Iteration 77880, loss = 0.0405866
I0906 04:06:12.775866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0405882 (* 1 = 0.0405882 loss)
I0906 04:06:12.775902 90901 sgd_solver.cpp:106] Iteration 77880, lr = 0.001
I0906 04:06:20.848335 90901 solver.cpp:228] Iteration 77890, loss = 0.118469
I0906 04:06:20.848408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11847 (* 1 = 0.11847 loss)
I0906 04:06:20.848429 90901 sgd_solver.cpp:106] Iteration 77890, lr = 0.001
I0906 04:06:30.086385 90901 solver.cpp:228] Iteration 77900, loss = 0.120086
I0906 04:06:30.086447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120088 (* 1 = 0.120088 loss)
I0906 04:06:30.086462 90901 sgd_solver.cpp:106] Iteration 77900, lr = 0.001
I0906 04:06:38.686797 90901 solver.cpp:228] Iteration 77910, loss = 0.0886969
I0906 04:06:38.686861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0886984 (* 1 = 0.0886984 loss)
I0906 04:06:38.686877 90901 sgd_solver.cpp:106] Iteration 77910, lr = 0.001
I0906 04:06:47.246992 90901 solver.cpp:228] Iteration 77920, loss = 0.271025
I0906 04:06:47.247159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271027 (* 1 = 0.271027 loss)
I0906 04:06:47.247179 90901 sgd_solver.cpp:106] Iteration 77920, lr = 0.001
I0906 04:06:54.592542 90901 solver.cpp:228] Iteration 77930, loss = 0.0783463
I0906 04:06:54.592619 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0783478 (* 1 = 0.0783478 loss)
I0906 04:06:54.592635 90901 sgd_solver.cpp:106] Iteration 77930, lr = 0.001
I0906 04:07:01.522979 90901 solver.cpp:228] Iteration 77940, loss = 0.0739319
I0906 04:07:01.523063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0739335 (* 1 = 0.0739335 loss)
I0906 04:07:01.523082 90901 sgd_solver.cpp:106] Iteration 77940, lr = 0.001
I0906 04:07:06.810155 90901 solver.cpp:228] Iteration 77950, loss = 0.20783
I0906 04:07:06.810228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207832 (* 1 = 0.207832 loss)
I0906 04:07:06.810245 90901 sgd_solver.cpp:106] Iteration 77950, lr = 0.001
I0906 04:07:11.775930 90901 solver.cpp:228] Iteration 77960, loss = 0.0640505
I0906 04:07:11.776005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.064052 (* 1 = 0.064052 loss)
I0906 04:07:11.776021 90901 sgd_solver.cpp:106] Iteration 77960, lr = 0.001
I0906 04:07:16.771576 90901 solver.cpp:228] Iteration 77970, loss = 0.172082
I0906 04:07:16.771636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172083 (* 1 = 0.172083 loss)
I0906 04:07:16.771653 90901 sgd_solver.cpp:106] Iteration 77970, lr = 0.001
I0906 04:07:21.679041 90901 solver.cpp:228] Iteration 77980, loss = 0.0431349
I0906 04:07:21.679265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0431364 (* 1 = 0.0431364 loss)
I0906 04:07:21.679293 90901 sgd_solver.cpp:106] Iteration 77980, lr = 0.001
I0906 04:07:26.333935 90901 solver.cpp:228] Iteration 77990, loss = 0.0838598
I0906 04:07:26.333993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0838614 (* 1 = 0.0838614 loss)
I0906 04:07:26.334008 90901 sgd_solver.cpp:106] Iteration 77990, lr = 0.001
I0906 04:07:30.995592 90901 solver.cpp:228] Iteration 78000, loss = 0.0826791
I0906 04:07:30.995673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0826806 (* 1 = 0.0826806 loss)
I0906 04:07:30.995692 90901 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I0906 04:07:36.124936 90901 solver.cpp:228] Iteration 78010, loss = 0.259353
I0906 04:07:36.125026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259355 (* 1 = 0.259355 loss)
I0906 04:07:36.125043 90901 sgd_solver.cpp:106] Iteration 78010, lr = 0.001
I0906 04:07:41.128345 90901 solver.cpp:228] Iteration 78020, loss = 0.184462
I0906 04:07:41.128418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184463 (* 1 = 0.184463 loss)
I0906 04:07:41.128434 90901 sgd_solver.cpp:106] Iteration 78020, lr = 0.001
I0906 04:07:46.108253 90901 solver.cpp:228] Iteration 78030, loss = 0.119208
I0906 04:07:46.108325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11921 (* 1 = 0.11921 loss)
I0906 04:07:46.108342 90901 sgd_solver.cpp:106] Iteration 78030, lr = 0.001
I0906 04:07:51.382310 90901 solver.cpp:228] Iteration 78040, loss = 0.0279499
I0906 04:07:51.382367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0279515 (* 1 = 0.0279515 loss)
I0906 04:07:51.382382 90901 sgd_solver.cpp:106] Iteration 78040, lr = 0.001
I0906 04:07:57.941239 90901 solver.cpp:228] Iteration 78050, loss = 0.29671
I0906 04:07:57.941417 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296711 (* 1 = 0.296711 loss)
I0906 04:07:57.941434 90901 sgd_solver.cpp:106] Iteration 78050, lr = 0.001
I0906 04:08:05.602429 90901 solver.cpp:228] Iteration 78060, loss = 0.114553
I0906 04:08:05.602505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114554 (* 1 = 0.114554 loss)
I0906 04:08:05.602521 90901 sgd_solver.cpp:106] Iteration 78060, lr = 0.001
I0906 04:08:13.879703 90901 solver.cpp:228] Iteration 78070, loss = 0.187194
I0906 04:08:13.879781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187195 (* 1 = 0.187195 loss)
I0906 04:08:13.879797 90901 sgd_solver.cpp:106] Iteration 78070, lr = 0.001
I0906 04:08:22.777282 90901 solver.cpp:228] Iteration 78080, loss = 0.0665876
I0906 04:08:22.777370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.066589 (* 1 = 0.066589 loss)
I0906 04:08:22.777387 90901 sgd_solver.cpp:106] Iteration 78080, lr = 0.001
I0906 04:08:31.769477 90901 solver.cpp:228] Iteration 78090, loss = 0.0863051
I0906 04:08:31.769640 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0863066 (* 1 = 0.0863066 loss)
I0906 04:08:31.769680 90901 sgd_solver.cpp:106] Iteration 78090, lr = 0.001
I0906 04:08:40.193307 90901 solver.cpp:228] Iteration 78100, loss = 0.118584
I0906 04:08:40.193392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118586 (* 1 = 0.118586 loss)
I0906 04:08:40.193411 90901 sgd_solver.cpp:106] Iteration 78100, lr = 0.001
I0906 04:08:48.639425 90901 solver.cpp:228] Iteration 78110, loss = 0.0963432
I0906 04:08:48.639495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0963446 (* 1 = 0.0963446 loss)
I0906 04:08:48.639511 90901 sgd_solver.cpp:106] Iteration 78110, lr = 0.001
I0906 04:08:57.794072 90901 solver.cpp:228] Iteration 78120, loss = 0.41471
I0906 04:08:57.794142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414711 (* 1 = 0.414711 loss)
I0906 04:08:57.794157 90901 sgd_solver.cpp:106] Iteration 78120, lr = 0.001
I0906 04:09:05.661926 90901 solver.cpp:228] Iteration 78130, loss = 0.0500973
I0906 04:09:05.662120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0500987 (* 1 = 0.0500987 loss)
I0906 04:09:05.662142 90901 sgd_solver.cpp:106] Iteration 78130, lr = 0.001
I0906 04:09:14.003541 90901 solver.cpp:228] Iteration 78140, loss = 0.100277
I0906 04:09:14.003636 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100278 (* 1 = 0.100278 loss)
I0906 04:09:14.003655 90901 sgd_solver.cpp:106] Iteration 78140, lr = 0.001
I0906 04:09:22.393214 90901 solver.cpp:228] Iteration 78150, loss = 0.0272347
I0906 04:09:22.393374 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0272362 (* 1 = 0.0272362 loss)
I0906 04:09:22.393415 90901 sgd_solver.cpp:106] Iteration 78150, lr = 0.001
I0906 04:09:29.398478 90901 solver.cpp:228] Iteration 78160, loss = 0.167766
I0906 04:09:29.398552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167767 (* 1 = 0.167767 loss)
I0906 04:09:29.398574 90901 sgd_solver.cpp:106] Iteration 78160, lr = 0.001
I0906 04:09:37.816273 90901 solver.cpp:228] Iteration 78170, loss = 0.309259
I0906 04:09:37.816493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30926 (* 1 = 0.30926 loss)
I0906 04:09:37.816537 90901 sgd_solver.cpp:106] Iteration 78170, lr = 0.001
I0906 04:09:45.559264 90901 solver.cpp:228] Iteration 78180, loss = 0.295032
I0906 04:09:45.559321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.295033 (* 1 = 0.295033 loss)
I0906 04:09:45.559336 90901 sgd_solver.cpp:106] Iteration 78180, lr = 0.001
I0906 04:09:53.563832 90901 solver.cpp:228] Iteration 78190, loss = 0.100697
I0906 04:09:53.563900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100698 (* 1 = 0.100698 loss)
I0906 04:09:53.563918 90901 sgd_solver.cpp:106] Iteration 78190, lr = 0.001
I0906 04:10:00.650804 90901 solver.cpp:228] Iteration 78200, loss = 0.0995784
I0906 04:10:00.650863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0995798 (* 1 = 0.0995798 loss)
I0906 04:10:00.650882 90901 sgd_solver.cpp:106] Iteration 78200, lr = 0.001
I0906 04:10:08.757336 90901 solver.cpp:228] Iteration 78210, loss = 0.131662
I0906 04:10:08.757535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131663 (* 1 = 0.131663 loss)
I0906 04:10:08.757570 90901 sgd_solver.cpp:106] Iteration 78210, lr = 0.001
I0906 04:10:17.380556 90901 solver.cpp:228] Iteration 78220, loss = 0.309903
I0906 04:10:17.380635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309904 (* 1 = 0.309904 loss)
I0906 04:10:17.380651 90901 sgd_solver.cpp:106] Iteration 78220, lr = 0.001
I0906 04:10:25.271849 90901 solver.cpp:228] Iteration 78230, loss = 0.0864328
I0906 04:10:25.271931 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0864343 (* 1 = 0.0864343 loss)
I0906 04:10:25.271947 90901 sgd_solver.cpp:106] Iteration 78230, lr = 0.001
I0906 04:10:34.088276 90901 solver.cpp:228] Iteration 78240, loss = 0.105405
I0906 04:10:34.088347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105406 (* 1 = 0.105406 loss)
I0906 04:10:34.088364 90901 sgd_solver.cpp:106] Iteration 78240, lr = 0.001
I0906 04:10:41.702981 90901 solver.cpp:228] Iteration 78250, loss = 0.0704502
I0906 04:10:41.703135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0704516 (* 1 = 0.0704516 loss)
I0906 04:10:41.703167 90901 sgd_solver.cpp:106] Iteration 78250, lr = 0.001
I0906 04:10:50.142688 90901 solver.cpp:228] Iteration 78260, loss = 0.253416
I0906 04:10:50.142761 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253418 (* 1 = 0.253418 loss)
I0906 04:10:50.142778 90901 sgd_solver.cpp:106] Iteration 78260, lr = 0.001
I0906 04:10:57.918452 90901 solver.cpp:228] Iteration 78270, loss = 0.319156
I0906 04:10:57.918514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.319157 (* 1 = 0.319157 loss)
I0906 04:10:57.918530 90901 sgd_solver.cpp:106] Iteration 78270, lr = 0.001
I0906 04:11:06.279566 90901 solver.cpp:228] Iteration 78280, loss = 0.12166
I0906 04:11:06.279635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121661 (* 1 = 0.121661 loss)
I0906 04:11:06.279654 90901 sgd_solver.cpp:106] Iteration 78280, lr = 0.001
I0906 04:11:13.864022 90901 solver.cpp:228] Iteration 78290, loss = 0.0426159
I0906 04:11:13.864229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0426174 (* 1 = 0.0426174 loss)
I0906 04:11:13.864248 90901 sgd_solver.cpp:106] Iteration 78290, lr = 0.001
I0906 04:11:22.419304 90901 solver.cpp:228] Iteration 78300, loss = 0.275668
I0906 04:11:22.419389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275669 (* 1 = 0.275669 loss)
I0906 04:11:22.419404 90901 sgd_solver.cpp:106] Iteration 78300, lr = 0.001
I0906 04:11:30.117663 90901 solver.cpp:228] Iteration 78310, loss = 0.120959
I0906 04:11:30.117727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120961 (* 1 = 0.120961 loss)
I0906 04:11:30.117743 90901 sgd_solver.cpp:106] Iteration 78310, lr = 0.001
I0906 04:11:38.438288 90901 solver.cpp:228] Iteration 78320, loss = 0.39839
I0906 04:11:38.438364 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398392 (* 1 = 0.398392 loss)
I0906 04:11:38.438381 90901 sgd_solver.cpp:106] Iteration 78320, lr = 0.001
I0906 04:11:47.420598 90901 solver.cpp:228] Iteration 78330, loss = 0.127343
I0906 04:11:47.420719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127344 (* 1 = 0.127344 loss)
I0906 04:11:47.420739 90901 sgd_solver.cpp:106] Iteration 78330, lr = 0.001
I0906 04:11:55.478238 90901 solver.cpp:228] Iteration 78340, loss = 0.477171
I0906 04:11:55.478299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.477172 (* 1 = 0.477172 loss)
I0906 04:11:55.478317 90901 sgd_solver.cpp:106] Iteration 78340, lr = 0.001
I0906 04:12:03.696686 90901 solver.cpp:228] Iteration 78350, loss = 0.250331
I0906 04:12:03.696760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250332 (* 1 = 0.250332 loss)
I0906 04:12:03.696777 90901 sgd_solver.cpp:106] Iteration 78350, lr = 0.001
I0906 04:12:11.391332 90901 solver.cpp:228] Iteration 78360, loss = 0.0458163
I0906 04:12:11.391402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0458178 (* 1 = 0.0458178 loss)
I0906 04:12:11.391417 90901 sgd_solver.cpp:106] Iteration 78360, lr = 0.001
I0906 04:12:19.735718 90901 solver.cpp:228] Iteration 78370, loss = 0.08291
I0906 04:12:19.735911 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0829115 (* 1 = 0.0829115 loss)
I0906 04:12:19.735954 90901 sgd_solver.cpp:106] Iteration 78370, lr = 0.001
I0906 04:12:28.408305 90901 solver.cpp:228] Iteration 78380, loss = 0.14837
I0906 04:12:28.408404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148371 (* 1 = 0.148371 loss)
I0906 04:12:28.408422 90901 sgd_solver.cpp:106] Iteration 78380, lr = 0.001
I0906 04:12:36.450103 90901 solver.cpp:228] Iteration 78390, loss = 0.296464
I0906 04:12:36.450178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296466 (* 1 = 0.296466 loss)
I0906 04:12:36.450194 90901 sgd_solver.cpp:106] Iteration 78390, lr = 0.001
I0906 04:12:44.612313 90901 solver.cpp:337] Iteration 78400, Testing net (#0)
I0906 04:13:42.585750 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.941562
I0906 04:13:42.585922 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.160634 (* 1 = 0.160634 loss)
I0906 04:13:42.868439 90901 solver.cpp:228] Iteration 78400, loss = 0.232562
I0906 04:13:42.868489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232564 (* 1 = 0.232564 loss)
I0906 04:13:42.868508 90901 sgd_solver.cpp:106] Iteration 78400, lr = 0.001
I0906 04:13:51.438247 90901 solver.cpp:228] Iteration 78410, loss = 0.270505
I0906 04:13:51.438333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270506 (* 1 = 0.270506 loss)
I0906 04:13:51.438359 90901 sgd_solver.cpp:106] Iteration 78410, lr = 0.001
I0906 04:13:59.542402 90901 solver.cpp:228] Iteration 78420, loss = 0.088938
I0906 04:13:59.542475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0889395 (* 1 = 0.0889395 loss)
I0906 04:13:59.542491 90901 sgd_solver.cpp:106] Iteration 78420, lr = 0.001
I0906 04:14:08.213809 90901 solver.cpp:228] Iteration 78430, loss = 0.269817
I0906 04:14:08.213876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269818 (* 1 = 0.269818 loss)
I0906 04:14:08.213894 90901 sgd_solver.cpp:106] Iteration 78430, lr = 0.001
I0906 04:14:17.216840 90901 solver.cpp:228] Iteration 78440, loss = 0.0858544
I0906 04:14:17.217028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0858559 (* 1 = 0.0858559 loss)
I0906 04:14:17.217046 90901 sgd_solver.cpp:106] Iteration 78440, lr = 0.001
I0906 04:14:25.114967 90901 solver.cpp:228] Iteration 78450, loss = 0.248488
I0906 04:14:25.115037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24849 (* 1 = 0.24849 loss)
I0906 04:14:25.115056 90901 sgd_solver.cpp:106] Iteration 78450, lr = 0.001
I0906 04:14:33.483588 90901 solver.cpp:228] Iteration 78460, loss = 0.0876941
I0906 04:14:33.483655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0876956 (* 1 = 0.0876956 loss)
I0906 04:14:33.483675 90901 sgd_solver.cpp:106] Iteration 78460, lr = 0.001
I0906 04:14:42.367825 90901 solver.cpp:228] Iteration 78470, loss = 0.142914
I0906 04:14:42.367887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142916 (* 1 = 0.142916 loss)
I0906 04:14:42.367907 90901 sgd_solver.cpp:106] Iteration 78470, lr = 0.001
I0906 04:14:49.424018 90901 solver.cpp:228] Iteration 78480, loss = 0.297584
I0906 04:14:49.424232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297586 (* 1 = 0.297586 loss)
I0906 04:14:49.424252 90901 sgd_solver.cpp:106] Iteration 78480, lr = 0.001
I0906 04:14:58.378609 90901 solver.cpp:228] Iteration 78490, loss = 0.276693
I0906 04:14:58.378671 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276694 (* 1 = 0.276694 loss)
I0906 04:14:58.378687 90901 sgd_solver.cpp:106] Iteration 78490, lr = 0.001
I0906 04:15:07.250751 90901 solver.cpp:228] Iteration 78500, loss = 0.0758031
I0906 04:15:07.250860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0758046 (* 1 = 0.0758046 loss)
I0906 04:15:07.250883 90901 sgd_solver.cpp:106] Iteration 78500, lr = 0.001
I0906 04:15:14.629163 90901 solver.cpp:228] Iteration 78510, loss = 0.158905
I0906 04:15:14.629218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158906 (* 1 = 0.158906 loss)
I0906 04:15:14.629235 90901 sgd_solver.cpp:106] Iteration 78510, lr = 0.001
I0906 04:15:23.416755 90901 solver.cpp:228] Iteration 78520, loss = 0.070264
I0906 04:15:23.416889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0702654 (* 1 = 0.0702654 loss)
I0906 04:15:23.416918 90901 sgd_solver.cpp:106] Iteration 78520, lr = 0.001
I0906 04:15:31.533505 90901 solver.cpp:228] Iteration 78530, loss = 0.194746
I0906 04:15:31.533571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194747 (* 1 = 0.194747 loss)
I0906 04:15:31.533586 90901 sgd_solver.cpp:106] Iteration 78530, lr = 0.001
I0906 04:15:39.133822 90901 solver.cpp:228] Iteration 78540, loss = 0.268113
I0906 04:15:39.133898 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268115 (* 1 = 0.268115 loss)
I0906 04:15:39.133913 90901 sgd_solver.cpp:106] Iteration 78540, lr = 0.001
I0906 04:15:47.880115 90901 solver.cpp:228] Iteration 78550, loss = 0.0852841
I0906 04:15:47.880169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0852856 (* 1 = 0.0852856 loss)
I0906 04:15:47.880185 90901 sgd_solver.cpp:106] Iteration 78550, lr = 0.001
I0906 04:15:55.901952 90901 solver.cpp:228] Iteration 78560, loss = 0.109839
I0906 04:15:55.902190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109841 (* 1 = 0.109841 loss)
I0906 04:15:55.902212 90901 sgd_solver.cpp:106] Iteration 78560, lr = 0.001
I0906 04:16:04.617840 90901 solver.cpp:228] Iteration 78570, loss = 0.164586
I0906 04:16:04.617904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164587 (* 1 = 0.164587 loss)
I0906 04:16:04.617920 90901 sgd_solver.cpp:106] Iteration 78570, lr = 0.001
I0906 04:16:13.320504 90901 solver.cpp:228] Iteration 78580, loss = 0.101144
I0906 04:16:13.320572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101146 (* 1 = 0.101146 loss)
I0906 04:16:13.320590 90901 sgd_solver.cpp:106] Iteration 78580, lr = 0.001
I0906 04:16:21.275620 90901 solver.cpp:228] Iteration 78590, loss = 0.0457712
I0906 04:16:21.275704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0457727 (* 1 = 0.0457727 loss)
I0906 04:16:21.275720 90901 sgd_solver.cpp:106] Iteration 78590, lr = 0.001
I0906 04:16:30.124061 90901 solver.cpp:228] Iteration 78600, loss = 0.191279
I0906 04:16:30.124203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19128 (* 1 = 0.19128 loss)
I0906 04:16:30.124233 90901 sgd_solver.cpp:106] Iteration 78600, lr = 0.001
I0906 04:16:38.421641 90901 solver.cpp:228] Iteration 78610, loss = 0.046156
I0906 04:16:38.421700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0461575 (* 1 = 0.0461575 loss)
I0906 04:16:38.421715 90901 sgd_solver.cpp:106] Iteration 78610, lr = 0.001
I0906 04:16:46.702865 90901 solver.cpp:228] Iteration 78620, loss = 0.18935
I0906 04:16:46.702919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189352 (* 1 = 0.189352 loss)
I0906 04:16:46.702935 90901 sgd_solver.cpp:106] Iteration 78620, lr = 0.001
I0906 04:16:55.314049 90901 solver.cpp:228] Iteration 78630, loss = 0.248243
I0906 04:16:55.314117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248245 (* 1 = 0.248245 loss)
I0906 04:16:55.314132 90901 sgd_solver.cpp:106] Iteration 78630, lr = 0.001
I0906 04:17:02.841961 90901 solver.cpp:228] Iteration 78640, loss = 0.541696
I0906 04:17:02.842118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.541698 (* 1 = 0.541698 loss)
I0906 04:17:02.842149 90901 sgd_solver.cpp:106] Iteration 78640, lr = 0.001
I0906 04:17:11.461892 90901 solver.cpp:228] Iteration 78650, loss = 0.73272
I0906 04:17:11.462036 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.732722 (* 1 = 0.732722 loss)
I0906 04:17:11.462062 90901 sgd_solver.cpp:106] Iteration 78650, lr = 0.001
I0906 04:17:20.143849 90901 solver.cpp:228] Iteration 78660, loss = 0.0612644
I0906 04:17:20.143923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0612659 (* 1 = 0.0612659 loss)
I0906 04:17:20.143941 90901 sgd_solver.cpp:106] Iteration 78660, lr = 0.001
I0906 04:17:27.878712 90901 solver.cpp:228] Iteration 78670, loss = 0.0488119
I0906 04:17:27.878801 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0488134 (* 1 = 0.0488134 loss)
I0906 04:17:27.878820 90901 sgd_solver.cpp:106] Iteration 78670, lr = 0.001
I0906 04:17:36.008558 90901 solver.cpp:228] Iteration 78680, loss = 0.10976
I0906 04:17:36.008728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109762 (* 1 = 0.109762 loss)
I0906 04:17:36.008745 90901 sgd_solver.cpp:106] Iteration 78680, lr = 0.001
I0906 04:17:42.986955 90901 solver.cpp:228] Iteration 78690, loss = 0.0900829
I0906 04:17:42.987015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0900845 (* 1 = 0.0900845 loss)
I0906 04:17:42.987030 90901 sgd_solver.cpp:106] Iteration 78690, lr = 0.001
I0906 04:17:50.754848 90901 solver.cpp:228] Iteration 78700, loss = 0.0765262
I0906 04:17:50.754923 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0765278 (* 1 = 0.0765278 loss)
I0906 04:17:50.754942 90901 sgd_solver.cpp:106] Iteration 78700, lr = 0.001
I0906 04:17:58.688486 90901 solver.cpp:228] Iteration 78710, loss = 0.331528
I0906 04:17:58.688575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33153 (* 1 = 0.33153 loss)
I0906 04:17:58.688592 90901 sgd_solver.cpp:106] Iteration 78710, lr = 0.001
I0906 04:18:05.757838 90901 solver.cpp:228] Iteration 78720, loss = 0.160025
I0906 04:18:05.757910 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160027 (* 1 = 0.160027 loss)
I0906 04:18:05.757931 90901 sgd_solver.cpp:106] Iteration 78720, lr = 0.001
I0906 04:18:12.239017 90901 solver.cpp:228] Iteration 78730, loss = 0.020954
I0906 04:18:12.239217 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0209556 (* 1 = 0.0209556 loss)
I0906 04:18:12.239269 90901 sgd_solver.cpp:106] Iteration 78730, lr = 0.001
I0906 04:18:18.743616 90901 solver.cpp:228] Iteration 78740, loss = 0.0236755
I0906 04:18:18.743677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0236771 (* 1 = 0.0236771 loss)
I0906 04:18:18.743693 90901 sgd_solver.cpp:106] Iteration 78740, lr = 0.001
I0906 04:18:23.940515 90901 solver.cpp:228] Iteration 78750, loss = 0.322467
I0906 04:18:23.940577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322469 (* 1 = 0.322469 loss)
I0906 04:18:23.940592 90901 sgd_solver.cpp:106] Iteration 78750, lr = 0.001
I0906 04:18:29.128374 90901 solver.cpp:228] Iteration 78760, loss = 0.15069
I0906 04:18:29.128438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150691 (* 1 = 0.150691 loss)
I0906 04:18:29.128454 90901 sgd_solver.cpp:106] Iteration 78760, lr = 0.001
I0906 04:18:35.164332 90901 solver.cpp:228] Iteration 78770, loss = 0.169517
I0906 04:18:35.164402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169519 (* 1 = 0.169519 loss)
I0906 04:18:35.164418 90901 sgd_solver.cpp:106] Iteration 78770, lr = 0.001
I0906 04:18:40.864550 90901 solver.cpp:228] Iteration 78780, loss = 0.197132
I0906 04:18:40.864603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197134 (* 1 = 0.197134 loss)
I0906 04:18:40.864622 90901 sgd_solver.cpp:106] Iteration 78780, lr = 0.001
I0906 04:18:46.468776 90901 solver.cpp:228] Iteration 78790, loss = 0.111239
I0906 04:18:46.468932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111241 (* 1 = 0.111241 loss)
I0906 04:18:46.468971 90901 sgd_solver.cpp:106] Iteration 78790, lr = 0.001
I0906 04:18:51.774343 90901 solver.cpp:228] Iteration 78800, loss = 0.096922
I0906 04:18:51.774406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0969235 (* 1 = 0.0969235 loss)
I0906 04:18:51.774425 90901 sgd_solver.cpp:106] Iteration 78800, lr = 0.001
I0906 04:18:57.362052 90901 solver.cpp:228] Iteration 78810, loss = 0.151622
I0906 04:18:57.362107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151623 (* 1 = 0.151623 loss)
I0906 04:18:57.362120 90901 sgd_solver.cpp:106] Iteration 78810, lr = 0.001
I0906 04:19:02.544225 90901 solver.cpp:228] Iteration 78820, loss = 0.20388
I0906 04:19:02.544282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203882 (* 1 = 0.203882 loss)
I0906 04:19:02.544301 90901 sgd_solver.cpp:106] Iteration 78820, lr = 0.001
I0906 04:19:07.919369 90901 solver.cpp:228] Iteration 78830, loss = 0.208767
I0906 04:19:07.919423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208769 (* 1 = 0.208769 loss)
I0906 04:19:07.919440 90901 sgd_solver.cpp:106] Iteration 78830, lr = 0.001
I0906 04:19:12.899333 90901 solver.cpp:228] Iteration 78840, loss = 0.0373917
I0906 04:19:12.899389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0373931 (* 1 = 0.0373931 loss)
I0906 04:19:12.899404 90901 sgd_solver.cpp:106] Iteration 78840, lr = 0.001
I0906 04:19:18.425626 90901 solver.cpp:228] Iteration 78850, loss = 0.102919
I0906 04:19:18.425837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10292 (* 1 = 0.10292 loss)
I0906 04:19:18.425853 90901 sgd_solver.cpp:106] Iteration 78850, lr = 0.001
I0906 04:19:23.616577 90901 solver.cpp:228] Iteration 78860, loss = 0.237233
I0906 04:19:23.616642 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237235 (* 1 = 0.237235 loss)
I0906 04:19:23.616655 90901 sgd_solver.cpp:106] Iteration 78860, lr = 0.001
I0906 04:19:28.830546 90901 solver.cpp:228] Iteration 78870, loss = 0.062968
I0906 04:19:28.830602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0629694 (* 1 = 0.0629694 loss)
I0906 04:19:28.830617 90901 sgd_solver.cpp:106] Iteration 78870, lr = 0.001
I0906 04:19:34.070729 90901 solver.cpp:228] Iteration 78880, loss = 0.135789
I0906 04:19:34.070791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135791 (* 1 = 0.135791 loss)
I0906 04:19:34.070804 90901 sgd_solver.cpp:106] Iteration 78880, lr = 0.001
I0906 04:19:39.557011 90901 solver.cpp:228] Iteration 78890, loss = 0.28114
I0906 04:19:39.557067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281141 (* 1 = 0.281141 loss)
I0906 04:19:39.557085 90901 sgd_solver.cpp:106] Iteration 78890, lr = 0.001
I0906 04:19:46.268321 90901 solver.cpp:228] Iteration 78900, loss = 0.15942
I0906 04:19:46.268404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159421 (* 1 = 0.159421 loss)
I0906 04:19:46.268420 90901 sgd_solver.cpp:106] Iteration 78900, lr = 0.001
I0906 04:19:54.754238 90901 solver.cpp:228] Iteration 78910, loss = 0.169312
I0906 04:19:54.754386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169313 (* 1 = 0.169313 loss)
I0906 04:19:54.754415 90901 sgd_solver.cpp:106] Iteration 78910, lr = 0.001
I0906 04:20:03.503423 90901 solver.cpp:228] Iteration 78920, loss = 0.0808169
I0906 04:20:03.503486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0808183 (* 1 = 0.0808183 loss)
I0906 04:20:03.503502 90901 sgd_solver.cpp:106] Iteration 78920, lr = 0.001
I0906 04:20:12.933933 90901 solver.cpp:228] Iteration 78930, loss = 0.209533
I0906 04:20:12.934000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209534 (* 1 = 0.209534 loss)
I0906 04:20:12.934015 90901 sgd_solver.cpp:106] Iteration 78930, lr = 0.001
I0906 04:20:21.747938 90901 solver.cpp:228] Iteration 78940, loss = 0.336956
I0906 04:20:21.748005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336957 (* 1 = 0.336957 loss)
I0906 04:20:21.748021 90901 sgd_solver.cpp:106] Iteration 78940, lr = 0.001
I0906 04:20:30.985071 90901 solver.cpp:228] Iteration 78950, loss = 0.0951809
I0906 04:20:30.985213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0951822 (* 1 = 0.0951822 loss)
I0906 04:20:30.985229 90901 sgd_solver.cpp:106] Iteration 78950, lr = 0.001
I0906 04:20:39.790280 90901 solver.cpp:228] Iteration 78960, loss = 0.0895512
I0906 04:20:39.790338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0895526 (* 1 = 0.0895526 loss)
I0906 04:20:39.790354 90901 sgd_solver.cpp:106] Iteration 78960, lr = 0.001
I0906 04:20:48.099941 90901 solver.cpp:228] Iteration 78970, loss = 0.0928807
I0906 04:20:48.100013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0928821 (* 1 = 0.0928821 loss)
I0906 04:20:48.100029 90901 sgd_solver.cpp:106] Iteration 78970, lr = 0.001
I0906 04:20:56.762007 90901 solver.cpp:228] Iteration 78980, loss = 0.0948827
I0906 04:20:56.762066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.094884 (* 1 = 0.094884 loss)
I0906 04:20:56.762084 90901 sgd_solver.cpp:106] Iteration 78980, lr = 0.001
I0906 04:21:05.776741 90901 solver.cpp:228] Iteration 78990, loss = 0.286898
I0906 04:21:05.776899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286899 (* 1 = 0.286899 loss)
I0906 04:21:05.776916 90901 sgd_solver.cpp:106] Iteration 78990, lr = 0.001
I0906 04:21:14.678074 90901 solver.cpp:228] Iteration 79000, loss = 0.183058
I0906 04:21:14.678153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183059 (* 1 = 0.183059 loss)
I0906 04:21:14.678169 90901 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I0906 04:21:21.539700 90901 solver.cpp:228] Iteration 79010, loss = 0.0945724
I0906 04:21:21.539757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0945737 (* 1 = 0.0945737 loss)
I0906 04:21:21.539770 90901 sgd_solver.cpp:106] Iteration 79010, lr = 0.001
I0906 04:21:27.916995 90901 solver.cpp:228] Iteration 79020, loss = 0.152872
I0906 04:21:27.917044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152874 (* 1 = 0.152874 loss)
I0906 04:21:27.917059 90901 sgd_solver.cpp:106] Iteration 79020, lr = 0.001
I0906 04:21:33.109863 90901 solver.cpp:228] Iteration 79030, loss = 0.645732
I0906 04:21:33.109936 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.645733 (* 1 = 0.645733 loss)
I0906 04:21:33.109954 90901 sgd_solver.cpp:106] Iteration 79030, lr = 0.001
I0906 04:21:38.623962 90901 solver.cpp:228] Iteration 79040, loss = 0.103024
I0906 04:21:38.624161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103026 (* 1 = 0.103026 loss)
I0906 04:21:38.624178 90901 sgd_solver.cpp:106] Iteration 79040, lr = 0.001
I0906 04:21:43.835010 90901 solver.cpp:228] Iteration 79050, loss = 0.149815
I0906 04:21:43.835079 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149817 (* 1 = 0.149817 loss)
I0906 04:21:43.835098 90901 sgd_solver.cpp:106] Iteration 79050, lr = 0.001
I0906 04:21:49.337694 90901 solver.cpp:228] Iteration 79060, loss = 0.0770501
I0906 04:21:49.337759 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0770514 (* 1 = 0.0770514 loss)
I0906 04:21:49.337775 90901 sgd_solver.cpp:106] Iteration 79060, lr = 0.001
I0906 04:21:54.712719 90901 solver.cpp:228] Iteration 79070, loss = 0.395884
I0906 04:21:54.712800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395885 (* 1 = 0.395885 loss)
I0906 04:21:54.712821 90901 sgd_solver.cpp:106] Iteration 79070, lr = 0.001
I0906 04:22:00.212656 90901 solver.cpp:228] Iteration 79080, loss = 0.107231
I0906 04:22:00.212728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107232 (* 1 = 0.107232 loss)
I0906 04:22:00.212744 90901 sgd_solver.cpp:106] Iteration 79080, lr = 0.001
I0906 04:22:05.652777 90901 solver.cpp:228] Iteration 79090, loss = 0.275379
I0906 04:22:05.652840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27538 (* 1 = 0.27538 loss)
I0906 04:22:05.652856 90901 sgd_solver.cpp:106] Iteration 79090, lr = 0.001
I0906 04:22:11.756927 90901 solver.cpp:228] Iteration 79100, loss = 0.100326
I0906 04:22:11.757093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100327 (* 1 = 0.100327 loss)
I0906 04:22:11.757133 90901 sgd_solver.cpp:106] Iteration 79100, lr = 0.001
I0906 04:22:18.941197 90901 solver.cpp:228] Iteration 79110, loss = 0.0952101
I0906 04:22:18.941273 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0952114 (* 1 = 0.0952114 loss)
I0906 04:22:18.941290 90901 sgd_solver.cpp:106] Iteration 79110, lr = 0.001
I0906 04:22:26.235270 90901 solver.cpp:228] Iteration 79120, loss = 0.284973
I0906 04:22:26.235340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284974 (* 1 = 0.284974 loss)
I0906 04:22:26.235357 90901 sgd_solver.cpp:106] Iteration 79120, lr = 0.001
I0906 04:22:33.758347 90901 solver.cpp:228] Iteration 79130, loss = 0.220799
I0906 04:22:33.758422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2208 (* 1 = 0.2208 loss)
I0906 04:22:33.758438 90901 sgd_solver.cpp:106] Iteration 79130, lr = 0.001
I0906 04:22:42.286730 90901 solver.cpp:228] Iteration 79140, loss = 0.338717
I0906 04:22:42.286978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338718 (* 1 = 0.338718 loss)
I0906 04:22:42.286999 90901 sgd_solver.cpp:106] Iteration 79140, lr = 0.001
I0906 04:22:50.736346 90901 solver.cpp:228] Iteration 79150, loss = 0.108402
I0906 04:22:50.736415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108403 (* 1 = 0.108403 loss)
I0906 04:22:50.736433 90901 sgd_solver.cpp:106] Iteration 79150, lr = 0.001
I0906 04:22:59.644974 90901 solver.cpp:228] Iteration 79160, loss = 0.320085
I0906 04:22:59.645058 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320086 (* 1 = 0.320086 loss)
I0906 04:22:59.645078 90901 sgd_solver.cpp:106] Iteration 79160, lr = 0.001
I0906 04:23:07.527637 90901 solver.cpp:228] Iteration 79170, loss = 0.0368872
I0906 04:23:07.527688 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0368885 (* 1 = 0.0368885 loss)
I0906 04:23:07.527704 90901 sgd_solver.cpp:106] Iteration 79170, lr = 0.001
I0906 04:23:16.515030 90901 solver.cpp:228] Iteration 79180, loss = 0.165976
I0906 04:23:16.516397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165977 (* 1 = 0.165977 loss)
I0906 04:23:16.516415 90901 sgd_solver.cpp:106] Iteration 79180, lr = 0.001
I0906 04:23:25.111598 90901 solver.cpp:228] Iteration 79190, loss = 0.0483392
I0906 04:23:25.111678 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0483406 (* 1 = 0.0483406 loss)
I0906 04:23:25.111695 90901 sgd_solver.cpp:106] Iteration 79190, lr = 0.001
I0906 04:23:32.639415 90901 solver.cpp:337] Iteration 79200, Testing net (#0)
I0906 04:24:29.955399 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.94625
I0906 04:24:29.955585 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.142901 (* 1 = 0.142901 loss)
I0906 04:24:30.236871 90901 solver.cpp:228] Iteration 79200, loss = 0.0994865
I0906 04:24:30.236933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0994879 (* 1 = 0.0994879 loss)
I0906 04:24:30.236953 90901 sgd_solver.cpp:106] Iteration 79200, lr = 0.001
I0906 04:24:38.076956 90901 solver.cpp:228] Iteration 79210, loss = 0.142197
I0906 04:24:38.077024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142198 (* 1 = 0.142198 loss)
I0906 04:24:38.077040 90901 sgd_solver.cpp:106] Iteration 79210, lr = 0.001
I0906 04:24:45.612704 90901 solver.cpp:228] Iteration 79220, loss = 0.111071
I0906 04:24:45.612763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111072 (* 1 = 0.111072 loss)
I0906 04:24:45.612779 90901 sgd_solver.cpp:106] Iteration 79220, lr = 0.001
I0906 04:24:53.198575 90901 solver.cpp:228] Iteration 79230, loss = 0.207925
I0906 04:24:53.198664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207927 (* 1 = 0.207927 loss)
I0906 04:24:53.198686 90901 sgd_solver.cpp:106] Iteration 79230, lr = 0.001
I0906 04:25:00.888494 90901 solver.cpp:228] Iteration 79240, loss = 0.0599872
I0906 04:25:00.888684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0599885 (* 1 = 0.0599885 loss)
I0906 04:25:00.888725 90901 sgd_solver.cpp:106] Iteration 79240, lr = 0.001
I0906 04:25:09.145010 90901 solver.cpp:228] Iteration 79250, loss = 0.147227
I0906 04:25:09.145093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147228 (* 1 = 0.147228 loss)
I0906 04:25:09.145109 90901 sgd_solver.cpp:106] Iteration 79250, lr = 0.001
I0906 04:25:16.398589 90901 solver.cpp:228] Iteration 79260, loss = 0.0371142
I0906 04:25:16.398686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0371155 (* 1 = 0.0371155 loss)
I0906 04:25:16.398705 90901 sgd_solver.cpp:106] Iteration 79260, lr = 0.001
I0906 04:25:24.048137 90901 solver.cpp:228] Iteration 79270, loss = 0.430373
I0906 04:25:24.048229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430374 (* 1 = 0.430374 loss)
I0906 04:25:24.048251 90901 sgd_solver.cpp:106] Iteration 79270, lr = 0.001
I0906 04:25:31.333802 90901 solver.cpp:228] Iteration 79280, loss = 0.0672154
I0906 04:25:31.333955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0672168 (* 1 = 0.0672168 loss)
I0906 04:25:31.333973 90901 sgd_solver.cpp:106] Iteration 79280, lr = 0.001
I0906 04:25:38.874368 90901 solver.cpp:228] Iteration 79290, loss = 0.0947986
I0906 04:25:38.874445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0948 (* 1 = 0.0948 loss)
I0906 04:25:38.874461 90901 sgd_solver.cpp:106] Iteration 79290, lr = 0.001
I0906 04:25:46.153709 90901 solver.cpp:228] Iteration 79300, loss = 0.199821
I0906 04:25:46.153781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199822 (* 1 = 0.199822 loss)
I0906 04:25:46.153800 90901 sgd_solver.cpp:106] Iteration 79300, lr = 0.001
I0906 04:25:53.609844 90901 solver.cpp:228] Iteration 79310, loss = 0.175618
I0906 04:25:53.609935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175619 (* 1 = 0.175619 loss)
I0906 04:25:53.609954 90901 sgd_solver.cpp:106] Iteration 79310, lr = 0.001
I0906 04:26:00.081367 90901 solver.cpp:228] Iteration 79320, loss = 0.0967329
I0906 04:26:00.081431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0967343 (* 1 = 0.0967343 loss)
I0906 04:26:00.081447 90901 sgd_solver.cpp:106] Iteration 79320, lr = 0.001
I0906 04:26:06.611683 90901 solver.cpp:228] Iteration 79330, loss = 0.193474
I0906 04:26:06.611866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193475 (* 1 = 0.193475 loss)
I0906 04:26:06.611891 90901 sgd_solver.cpp:106] Iteration 79330, lr = 0.001
I0906 04:26:12.324542 90901 solver.cpp:228] Iteration 79340, loss = 0.0682581
I0906 04:26:12.324621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0682595 (* 1 = 0.0682595 loss)
I0906 04:26:12.324637 90901 sgd_solver.cpp:106] Iteration 79340, lr = 0.001
I0906 04:26:18.344141 90901 solver.cpp:228] Iteration 79350, loss = 0.140122
I0906 04:26:18.344233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140123 (* 1 = 0.140123 loss)
I0906 04:26:18.344249 90901 sgd_solver.cpp:106] Iteration 79350, lr = 0.001
I0906 04:26:24.533308 90901 solver.cpp:228] Iteration 79360, loss = 0.412123
I0906 04:26:24.533399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.412124 (* 1 = 0.412124 loss)
I0906 04:26:24.533416 90901 sgd_solver.cpp:106] Iteration 79360, lr = 0.001
I0906 04:26:29.717881 90901 solver.cpp:228] Iteration 79370, loss = 0.0733781
I0906 04:26:29.717949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0733795 (* 1 = 0.0733795 loss)
I0906 04:26:29.717965 90901 sgd_solver.cpp:106] Iteration 79370, lr = 0.001
I0906 04:26:35.250025 90901 solver.cpp:228] Iteration 79380, loss = 0.0978308
I0906 04:26:35.250084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0978322 (* 1 = 0.0978322 loss)
I0906 04:26:35.250098 90901 sgd_solver.cpp:106] Iteration 79380, lr = 0.001
I0906 04:26:40.422943 90901 solver.cpp:228] Iteration 79390, loss = 0.0820191
I0906 04:26:40.423107 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0820205 (* 1 = 0.0820205 loss)
I0906 04:26:40.423132 90901 sgd_solver.cpp:106] Iteration 79390, lr = 0.001
I0906 04:26:45.628522 90901 solver.cpp:228] Iteration 79400, loss = 0.100311
I0906 04:26:45.628576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100312 (* 1 = 0.100312 loss)
I0906 04:26:45.628592 90901 sgd_solver.cpp:106] Iteration 79400, lr = 0.001
I0906 04:26:50.853900 90901 solver.cpp:228] Iteration 79410, loss = 0.0795568
I0906 04:26:50.853963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0795582 (* 1 = 0.0795582 loss)
I0906 04:26:50.853979 90901 sgd_solver.cpp:106] Iteration 79410, lr = 0.001
I0906 04:26:56.051172 90901 solver.cpp:228] Iteration 79420, loss = 0.387992
I0906 04:26:56.051224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387993 (* 1 = 0.387993 loss)
I0906 04:26:56.051239 90901 sgd_solver.cpp:106] Iteration 79420, lr = 0.001
I0906 04:27:01.574723 90901 solver.cpp:228] Iteration 79430, loss = 0.15588
I0906 04:27:01.574774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155882 (* 1 = 0.155882 loss)
I0906 04:27:01.574795 90901 sgd_solver.cpp:106] Iteration 79430, lr = 0.001
I0906 04:27:07.246045 90901 solver.cpp:228] Iteration 79440, loss = 0.101688
I0906 04:27:07.246125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10169 (* 1 = 0.10169 loss)
I0906 04:27:07.246142 90901 sgd_solver.cpp:106] Iteration 79440, lr = 0.001
I0906 04:27:13.758846 90901 solver.cpp:228] Iteration 79450, loss = 0.187103
I0906 04:27:13.758978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187104 (* 1 = 0.187104 loss)
I0906 04:27:13.759013 90901 sgd_solver.cpp:106] Iteration 79450, lr = 0.001
I0906 04:27:20.186327 90901 solver.cpp:228] Iteration 79460, loss = 0.101902
I0906 04:27:20.186401 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101904 (* 1 = 0.101904 loss)
I0906 04:27:20.186417 90901 sgd_solver.cpp:106] Iteration 79460, lr = 0.001
I0906 04:27:27.943861 90901 solver.cpp:228] Iteration 79470, loss = 0.193106
I0906 04:27:27.943925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193107 (* 1 = 0.193107 loss)
I0906 04:27:27.943941 90901 sgd_solver.cpp:106] Iteration 79470, lr = 0.001
I0906 04:27:36.569548 90901 solver.cpp:228] Iteration 79480, loss = 0.278985
I0906 04:27:36.569613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278986 (* 1 = 0.278986 loss)
I0906 04:27:36.569633 90901 sgd_solver.cpp:106] Iteration 79480, lr = 0.001
I0906 04:27:45.639353 90901 solver.cpp:228] Iteration 79490, loss = 0.316233
I0906 04:27:45.639510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316235 (* 1 = 0.316235 loss)
I0906 04:27:45.639529 90901 sgd_solver.cpp:106] Iteration 79490, lr = 0.001
I0906 04:27:53.136237 90901 solver.cpp:228] Iteration 79500, loss = 0.141638
I0906 04:27:53.136332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141639 (* 1 = 0.141639 loss)
I0906 04:27:53.136350 90901 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I0906 04:28:02.300892 90901 solver.cpp:228] Iteration 79510, loss = 0.326214
I0906 04:28:02.300947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326216 (* 1 = 0.326216 loss)
I0906 04:28:02.300959 90901 sgd_solver.cpp:106] Iteration 79510, lr = 0.001
I0906 04:28:10.834700 90901 solver.cpp:228] Iteration 79520, loss = 0.245123
I0906 04:28:10.834764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245125 (* 1 = 0.245125 loss)
I0906 04:28:10.834779 90901 sgd_solver.cpp:106] Iteration 79520, lr = 0.001
I0906 04:28:20.127305 90901 solver.cpp:228] Iteration 79530, loss = 0.257265
I0906 04:28:20.127459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257267 (* 1 = 0.257267 loss)
I0906 04:28:20.127485 90901 sgd_solver.cpp:106] Iteration 79530, lr = 0.001
I0906 04:28:28.666448 90901 solver.cpp:228] Iteration 79540, loss = 0.173627
I0906 04:28:28.666551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173628 (* 1 = 0.173628 loss)
I0906 04:28:28.666570 90901 sgd_solver.cpp:106] Iteration 79540, lr = 0.001
I0906 04:28:36.988034 90901 solver.cpp:228] Iteration 79550, loss = 0.225239
I0906 04:28:36.988145 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22524 (* 1 = 0.22524 loss)
I0906 04:28:36.988163 90901 sgd_solver.cpp:106] Iteration 79550, lr = 0.001
I0906 04:28:46.058532 90901 solver.cpp:228] Iteration 79560, loss = 0.0604026
I0906 04:28:46.058601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.060404 (* 1 = 0.060404 loss)
I0906 04:28:46.058619 90901 sgd_solver.cpp:106] Iteration 79560, lr = 0.001
I0906 04:28:55.065852 90901 solver.cpp:228] Iteration 79570, loss = 0.0699302
I0906 04:28:55.066020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0699315 (* 1 = 0.0699315 loss)
I0906 04:28:55.066052 90901 sgd_solver.cpp:106] Iteration 79570, lr = 0.001
I0906 04:29:03.965498 90901 solver.cpp:228] Iteration 79580, loss = 0.238765
I0906 04:29:03.965587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238766 (* 1 = 0.238766 loss)
I0906 04:29:03.965603 90901 sgd_solver.cpp:106] Iteration 79580, lr = 0.001
I0906 04:29:13.093813 90901 solver.cpp:228] Iteration 79590, loss = 0.115503
I0906 04:29:13.093868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115504 (* 1 = 0.115504 loss)
I0906 04:29:13.093885 90901 sgd_solver.cpp:106] Iteration 79590, lr = 0.001
I0906 04:29:21.680105 90901 solver.cpp:228] Iteration 79600, loss = 0.0591393
I0906 04:29:21.680186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0591406 (* 1 = 0.0591406 loss)
I0906 04:29:21.680202 90901 sgd_solver.cpp:106] Iteration 79600, lr = 0.001
I0906 04:29:31.092213 90901 solver.cpp:228] Iteration 79610, loss = 0.2068
I0906 04:29:31.092456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206801 (* 1 = 0.206801 loss)
I0906 04:29:31.092481 90901 sgd_solver.cpp:106] Iteration 79610, lr = 0.001
I0906 04:29:39.891010 90901 solver.cpp:228] Iteration 79620, loss = 0.357118
I0906 04:29:39.891085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35712 (* 1 = 0.35712 loss)
I0906 04:29:39.891103 90901 sgd_solver.cpp:106] Iteration 79620, lr = 0.001
I0906 04:29:49.177036 90901 solver.cpp:228] Iteration 79630, loss = 0.0462813
I0906 04:29:49.177111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0462827 (* 1 = 0.0462827 loss)
I0906 04:29:49.177127 90901 sgd_solver.cpp:106] Iteration 79630, lr = 0.001
I0906 04:29:57.914706 90901 solver.cpp:228] Iteration 79640, loss = 0.220576
I0906 04:29:57.914808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220577 (* 1 = 0.220577 loss)
I0906 04:29:57.914836 90901 sgd_solver.cpp:106] Iteration 79640, lr = 0.001
I0906 04:30:07.050123 90901 solver.cpp:228] Iteration 79650, loss = 0.121369
I0906 04:30:07.050328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12137 (* 1 = 0.12137 loss)
I0906 04:30:07.050364 90901 sgd_solver.cpp:106] Iteration 79650, lr = 0.001
I0906 04:30:15.714012 90901 solver.cpp:228] Iteration 79660, loss = 0.0960844
I0906 04:30:15.714087 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0960857 (* 1 = 0.0960857 loss)
I0906 04:30:15.714103 90901 sgd_solver.cpp:106] Iteration 79660, lr = 0.001
I0906 04:30:24.718444 90901 solver.cpp:228] Iteration 79670, loss = 0.302689
I0906 04:30:24.718509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30269 (* 1 = 0.30269 loss)
I0906 04:30:24.718525 90901 sgd_solver.cpp:106] Iteration 79670, lr = 0.001
I0906 04:30:33.581907 90901 solver.cpp:228] Iteration 79680, loss = 0.427597
I0906 04:30:33.581982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.427598 (* 1 = 0.427598 loss)
I0906 04:30:33.582000 90901 sgd_solver.cpp:106] Iteration 79680, lr = 0.001
I0906 04:30:42.569401 90901 solver.cpp:228] Iteration 79690, loss = 0.167029
I0906 04:30:42.569571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16703 (* 1 = 0.16703 loss)
I0906 04:30:42.569599 90901 sgd_solver.cpp:106] Iteration 79690, lr = 0.001
I0906 04:30:51.286972 90901 solver.cpp:228] Iteration 79700, loss = 0.0480514
I0906 04:30:51.287029 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0480528 (* 1 = 0.0480528 loss)
I0906 04:30:51.287047 90901 sgd_solver.cpp:106] Iteration 79700, lr = 0.001
I0906 04:31:00.602140 90901 solver.cpp:228] Iteration 79710, loss = 0.0692
I0906 04:31:00.602216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0692014 (* 1 = 0.0692014 loss)
I0906 04:31:00.602231 90901 sgd_solver.cpp:106] Iteration 79710, lr = 0.001
I0906 04:31:08.890367 90901 solver.cpp:228] Iteration 79720, loss = 0.0660614
I0906 04:31:08.890429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0660628 (* 1 = 0.0660628 loss)
I0906 04:31:08.890445 90901 sgd_solver.cpp:106] Iteration 79720, lr = 0.001
I0906 04:31:17.532784 90901 solver.cpp:228] Iteration 79730, loss = 0.0950526
I0906 04:31:17.532984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.095054 (* 1 = 0.095054 loss)
I0906 04:31:17.533004 90901 sgd_solver.cpp:106] Iteration 79730, lr = 0.001
I0906 04:31:25.861855 90901 solver.cpp:228] Iteration 79740, loss = 0.100038
I0906 04:31:25.861932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100039 (* 1 = 0.100039 loss)
I0906 04:31:25.861948 90901 sgd_solver.cpp:106] Iteration 79740, lr = 0.001
I0906 04:31:34.669378 90901 solver.cpp:228] Iteration 79750, loss = 0.201937
I0906 04:31:34.669473 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201939 (* 1 = 0.201939 loss)
I0906 04:31:34.669490 90901 sgd_solver.cpp:106] Iteration 79750, lr = 0.001
I0906 04:31:43.582439 90901 solver.cpp:228] Iteration 79760, loss = 0.161418
I0906 04:31:43.582499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16142 (* 1 = 0.16142 loss)
I0906 04:31:43.582515 90901 sgd_solver.cpp:106] Iteration 79760, lr = 0.001
I0906 04:31:52.349860 90901 solver.cpp:228] Iteration 79770, loss = 0.169985
I0906 04:31:52.350035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169986 (* 1 = 0.169986 loss)
I0906 04:31:52.350065 90901 sgd_solver.cpp:106] Iteration 79770, lr = 0.001
I0906 04:32:01.412171 90901 solver.cpp:228] Iteration 79780, loss = 0.268331
I0906 04:32:01.412256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268333 (* 1 = 0.268333 loss)
I0906 04:32:01.412276 90901 sgd_solver.cpp:106] Iteration 79780, lr = 0.001
I0906 04:32:09.988661 90901 solver.cpp:228] Iteration 79790, loss = 0.179962
I0906 04:32:09.988734 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179964 (* 1 = 0.179964 loss)
I0906 04:32:09.988752 90901 sgd_solver.cpp:106] Iteration 79790, lr = 0.001
I0906 04:32:19.085019 90901 solver.cpp:228] Iteration 79800, loss = 0.163384
I0906 04:32:19.085079 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163386 (* 1 = 0.163386 loss)
I0906 04:32:19.085095 90901 sgd_solver.cpp:106] Iteration 79800, lr = 0.001
I0906 04:32:27.721818 90901 solver.cpp:228] Iteration 79810, loss = 0.126622
I0906 04:32:27.721961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126624 (* 1 = 0.126624 loss)
I0906 04:32:27.721990 90901 sgd_solver.cpp:106] Iteration 79810, lr = 0.001
I0906 04:32:36.629065 90901 solver.cpp:228] Iteration 79820, loss = 0.0797414
I0906 04:32:36.629127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0797428 (* 1 = 0.0797428 loss)
I0906 04:32:36.629142 90901 sgd_solver.cpp:106] Iteration 79820, lr = 0.001
I0906 04:32:45.308562 90901 solver.cpp:228] Iteration 79830, loss = 0.0783691
I0906 04:32:45.308632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0783705 (* 1 = 0.0783705 loss)
I0906 04:32:45.308650 90901 sgd_solver.cpp:106] Iteration 79830, lr = 0.001
I0906 04:32:54.310384 90901 solver.cpp:228] Iteration 79840, loss = 0.158541
I0906 04:32:54.310474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158542 (* 1 = 0.158542 loss)
I0906 04:32:54.310492 90901 sgd_solver.cpp:106] Iteration 79840, lr = 0.001
I0906 04:33:02.462167 90901 solver.cpp:228] Iteration 79850, loss = 0.205308
I0906 04:33:02.462313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205309 (* 1 = 0.205309 loss)
I0906 04:33:02.462330 90901 sgd_solver.cpp:106] Iteration 79850, lr = 0.001
I0906 04:33:08.460129 90901 solver.cpp:228] Iteration 79860, loss = 0.0974719
I0906 04:33:08.460233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0974733 (* 1 = 0.0974733 loss)
I0906 04:33:08.460254 90901 sgd_solver.cpp:106] Iteration 79860, lr = 0.001
I0906 04:33:13.939059 90901 solver.cpp:228] Iteration 79870, loss = 0.109106
I0906 04:33:13.939133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109107 (* 1 = 0.109107 loss)
I0906 04:33:13.939153 90901 sgd_solver.cpp:106] Iteration 79870, lr = 0.001
I0906 04:33:20.187377 90901 solver.cpp:228] Iteration 79880, loss = 0.154311
I0906 04:33:20.187428 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154313 (* 1 = 0.154313 loss)
I0906 04:33:20.187444 90901 sgd_solver.cpp:106] Iteration 79880, lr = 0.001
I0906 04:33:25.375615 90901 solver.cpp:228] Iteration 79890, loss = 0.306024
I0906 04:33:25.375669 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306026 (* 1 = 0.306026 loss)
I0906 04:33:25.375684 90901 sgd_solver.cpp:106] Iteration 79890, lr = 0.001
I0906 04:33:30.551951 90901 solver.cpp:228] Iteration 79900, loss = 0.202125
I0906 04:33:30.552024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202127 (* 1 = 0.202127 loss)
I0906 04:33:30.552040 90901 sgd_solver.cpp:106] Iteration 79900, lr = 0.001
I0906 04:33:35.778033 90901 solver.cpp:228] Iteration 79910, loss = 0.451513
I0906 04:33:35.778211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.451515 (* 1 = 0.451515 loss)
I0906 04:33:35.778229 90901 sgd_solver.cpp:106] Iteration 79910, lr = 0.001
I0906 04:33:41.298854 90901 solver.cpp:228] Iteration 79920, loss = 0.0667408
I0906 04:33:41.298921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0667422 (* 1 = 0.0667422 loss)
I0906 04:33:41.298938 90901 sgd_solver.cpp:106] Iteration 79920, lr = 0.001
I0906 04:33:47.508775 90901 solver.cpp:228] Iteration 79930, loss = 0.15336
I0906 04:33:47.508862 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153362 (* 1 = 0.153362 loss)
I0906 04:33:47.508880 90901 sgd_solver.cpp:106] Iteration 79930, lr = 0.001
I0906 04:33:56.109185 90901 solver.cpp:228] Iteration 79940, loss = 0.136799
I0906 04:33:56.109256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1368 (* 1 = 0.1368 loss)
I0906 04:33:56.109272 90901 sgd_solver.cpp:106] Iteration 79940, lr = 0.001
I0906 04:34:05.077251 90901 solver.cpp:228] Iteration 79950, loss = 0.275011
I0906 04:34:05.077342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275013 (* 1 = 0.275013 loss)
I0906 04:34:05.077368 90901 sgd_solver.cpp:106] Iteration 79950, lr = 0.001
I0906 04:34:13.789736 90901 solver.cpp:228] Iteration 79960, loss = 0.190564
I0906 04:34:13.789896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190566 (* 1 = 0.190566 loss)
I0906 04:34:13.789914 90901 sgd_solver.cpp:106] Iteration 79960, lr = 0.001
I0906 04:34:22.873363 90901 solver.cpp:228] Iteration 79970, loss = 0.35516
I0906 04:34:22.873435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.355161 (* 1 = 0.355161 loss)
I0906 04:34:22.873452 90901 sgd_solver.cpp:106] Iteration 79970, lr = 0.001
I0906 04:34:31.844131 90901 solver.cpp:228] Iteration 79980, loss = 0.136203
I0906 04:34:31.844179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136204 (* 1 = 0.136204 loss)
I0906 04:34:31.844193 90901 sgd_solver.cpp:106] Iteration 79980, lr = 0.001
I0906 04:34:39.942893 90901 solver.cpp:228] Iteration 79990, loss = 0.0806061
I0906 04:34:39.942955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0806075 (* 1 = 0.0806075 loss)
I0906 04:34:39.942973 90901 sgd_solver.cpp:106] Iteration 79990, lr = 0.001
I0906 04:34:48.818207 90901 solver.cpp:337] Iteration 80000, Testing net (#0)
I0906 04:35:51.120918 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.938125
I0906 04:35:51.121073 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.157408 (* 1 = 0.157408 loss)
I0906 04:35:51.526464 90901 solver.cpp:228] Iteration 80000, loss = 0.0953187
I0906 04:35:51.526556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.09532 (* 1 = 0.09532 loss)
I0906 04:35:51.526581 90901 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I0906 04:36:00.256819 90901 solver.cpp:228] Iteration 80010, loss = 0.130464
I0906 04:36:00.256873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130465 (* 1 = 0.130465 loss)
I0906 04:36:00.256889 90901 sgd_solver.cpp:106] Iteration 80010, lr = 0.001
I0906 04:36:08.692723 90901 solver.cpp:228] Iteration 80020, loss = 0.34468
I0906 04:36:08.692803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344681 (* 1 = 0.344681 loss)
I0906 04:36:08.692819 90901 sgd_solver.cpp:106] Iteration 80020, lr = 0.001
I0906 04:36:17.762462 90901 solver.cpp:228] Iteration 80030, loss = 0.182715
I0906 04:36:17.762521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182717 (* 1 = 0.182717 loss)
I0906 04:36:17.762537 90901 sgd_solver.cpp:106] Iteration 80030, lr = 0.001
I0906 04:36:26.955898 90901 solver.cpp:228] Iteration 80040, loss = 0.169886
I0906 04:36:26.956307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169887 (* 1 = 0.169887 loss)
I0906 04:36:26.956336 90901 sgd_solver.cpp:106] Iteration 80040, lr = 0.001
I0906 04:36:35.810374 90901 solver.cpp:228] Iteration 80050, loss = 0.0603653
I0906 04:36:35.810498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0603667 (* 1 = 0.0603667 loss)
I0906 04:36:35.810528 90901 sgd_solver.cpp:106] Iteration 80050, lr = 0.001
I0906 04:36:44.471427 90901 solver.cpp:228] Iteration 80060, loss = 0.222893
I0906 04:36:44.471495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222895 (* 1 = 0.222895 loss)
I0906 04:36:44.471513 90901 sgd_solver.cpp:106] Iteration 80060, lr = 0.001
I0906 04:36:53.845765 90901 solver.cpp:228] Iteration 80070, loss = 0.117055
I0906 04:36:53.845831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117056 (* 1 = 0.117056 loss)
I0906 04:36:53.845849 90901 sgd_solver.cpp:106] Iteration 80070, lr = 0.001
I0906 04:37:02.498587 90901 solver.cpp:228] Iteration 80080, loss = 0.135034
I0906 04:37:02.499162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135035 (* 1 = 0.135035 loss)
I0906 04:37:02.499181 90901 sgd_solver.cpp:106] Iteration 80080, lr = 0.001
I0906 04:37:11.353802 90901 solver.cpp:228] Iteration 80090, loss = 0.125155
I0906 04:37:11.353874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125157 (* 1 = 0.125157 loss)
I0906 04:37:11.353890 90901 sgd_solver.cpp:106] Iteration 80090, lr = 0.001
I0906 04:37:19.958364 90901 solver.cpp:228] Iteration 80100, loss = 0.208578
I0906 04:37:19.958426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208579 (* 1 = 0.208579 loss)
I0906 04:37:19.958444 90901 sgd_solver.cpp:106] Iteration 80100, lr = 0.001
I0906 04:37:29.202280 90901 solver.cpp:228] Iteration 80110, loss = 0.0403081
I0906 04:37:29.202329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0403095 (* 1 = 0.0403095 loss)
I0906 04:37:29.202342 90901 sgd_solver.cpp:106] Iteration 80110, lr = 0.001
I0906 04:37:38.303233 90901 solver.cpp:228] Iteration 80120, loss = 0.0416908
I0906 04:37:38.306720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0416922 (* 1 = 0.0416922 loss)
I0906 04:37:38.306740 90901 sgd_solver.cpp:106] Iteration 80120, lr = 0.001
I0906 04:37:46.912353 90901 solver.cpp:228] Iteration 80130, loss = 0.0867939
I0906 04:37:46.912452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0867953 (* 1 = 0.0867953 loss)
I0906 04:37:46.912472 90901 sgd_solver.cpp:106] Iteration 80130, lr = 0.001
I0906 04:37:56.074379 90901 solver.cpp:228] Iteration 80140, loss = 0.122877
I0906 04:37:56.074452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122879 (* 1 = 0.122879 loss)
I0906 04:37:56.074470 90901 sgd_solver.cpp:106] Iteration 80140, lr = 0.001
I0906 04:38:04.708243 90901 solver.cpp:228] Iteration 80150, loss = 0.60358
I0906 04:38:04.708322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.603582 (* 1 = 0.603582 loss)
I0906 04:38:04.708338 90901 sgd_solver.cpp:106] Iteration 80150, lr = 0.001
I0906 04:38:13.567312 90901 solver.cpp:228] Iteration 80160, loss = 0.209413
I0906 04:38:13.567488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209414 (* 1 = 0.209414 loss)
I0906 04:38:13.567514 90901 sgd_solver.cpp:106] Iteration 80160, lr = 0.001
I0906 04:38:23.229442 90901 solver.cpp:228] Iteration 80170, loss = 0.0373917
I0906 04:38:23.229506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0373931 (* 1 = 0.0373931 loss)
I0906 04:38:23.229526 90901 sgd_solver.cpp:106] Iteration 80170, lr = 0.001
I0906 04:38:32.542031 90901 solver.cpp:228] Iteration 80180, loss = 0.0674262
I0906 04:38:32.542111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0674275 (* 1 = 0.0674275 loss)
I0906 04:38:32.542129 90901 sgd_solver.cpp:106] Iteration 80180, lr = 0.001
I0906 04:38:41.957106 90901 solver.cpp:228] Iteration 80190, loss = 0.117048
I0906 04:38:41.957166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117049 (* 1 = 0.117049 loss)
I0906 04:38:41.957183 90901 sgd_solver.cpp:106] Iteration 80190, lr = 0.001
I0906 04:38:51.215960 90901 solver.cpp:228] Iteration 80200, loss = 0.489274
I0906 04:38:51.216162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.489275 (* 1 = 0.489275 loss)
I0906 04:38:51.216181 90901 sgd_solver.cpp:106] Iteration 80200, lr = 0.001
I0906 04:38:59.740990 90901 solver.cpp:228] Iteration 80210, loss = 0.0751278
I0906 04:38:59.741071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0751291 (* 1 = 0.0751291 loss)
I0906 04:38:59.741087 90901 sgd_solver.cpp:106] Iteration 80210, lr = 0.001
I0906 04:39:09.196333 90901 solver.cpp:228] Iteration 80220, loss = 0.385911
I0906 04:39:09.196391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385912 (* 1 = 0.385912 loss)
I0906 04:39:09.196406 90901 sgd_solver.cpp:106] Iteration 80220, lr = 0.001
I0906 04:39:18.628897 90901 solver.cpp:228] Iteration 80230, loss = 0.513999
I0906 04:39:18.628971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.514001 (* 1 = 0.514001 loss)
I0906 04:39:18.628988 90901 sgd_solver.cpp:106] Iteration 80230, lr = 0.001
I0906 04:39:27.196676 90901 solver.cpp:228] Iteration 80240, loss = 0.193775
I0906 04:39:27.196808 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193776 (* 1 = 0.193776 loss)
I0906 04:39:27.196840 90901 sgd_solver.cpp:106] Iteration 80240, lr = 0.001
I0906 04:39:36.152518 90901 solver.cpp:228] Iteration 80250, loss = 0.0491454
I0906 04:39:36.152590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0491468 (* 1 = 0.0491468 loss)
I0906 04:39:36.152606 90901 sgd_solver.cpp:106] Iteration 80250, lr = 0.001
I0906 04:39:45.036892 90901 solver.cpp:228] Iteration 80260, loss = 0.132329
I0906 04:39:45.036949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13233 (* 1 = 0.13233 loss)
I0906 04:39:45.036964 90901 sgd_solver.cpp:106] Iteration 80260, lr = 0.001
I0906 04:39:54.423645 90901 solver.cpp:228] Iteration 80270, loss = 0.0739909
I0906 04:39:54.423720 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0739922 (* 1 = 0.0739922 loss)
I0906 04:39:54.423738 90901 sgd_solver.cpp:106] Iteration 80270, lr = 0.001
I0906 04:40:03.550616 90901 solver.cpp:228] Iteration 80280, loss = 0.0568167
I0906 04:40:03.550848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0568181 (* 1 = 0.0568181 loss)
I0906 04:40:03.550865 90901 sgd_solver.cpp:106] Iteration 80280, lr = 0.001
I0906 04:40:12.444515 90901 solver.cpp:228] Iteration 80290, loss = 0.047544
I0906 04:40:12.444583 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0475453 (* 1 = 0.0475453 loss)
I0906 04:40:12.444600 90901 sgd_solver.cpp:106] Iteration 80290, lr = 0.001
I0906 04:40:21.272008 90901 solver.cpp:228] Iteration 80300, loss = 0.237599
I0906 04:40:21.272083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2376 (* 1 = 0.2376 loss)
I0906 04:40:21.272104 90901 sgd_solver.cpp:106] Iteration 80300, lr = 0.001
I0906 04:40:30.095262 90901 solver.cpp:228] Iteration 80310, loss = 0.0690305
I0906 04:40:30.095348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0690318 (* 1 = 0.0690318 loss)
I0906 04:40:30.095366 90901 sgd_solver.cpp:106] Iteration 80310, lr = 0.001
I0906 04:40:39.400985 90901 solver.cpp:228] Iteration 80320, loss = 0.0284078
I0906 04:40:39.401124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0284091 (* 1 = 0.0284091 loss)
I0906 04:40:39.401141 90901 sgd_solver.cpp:106] Iteration 80320, lr = 0.001
I0906 04:40:48.061288 90901 solver.cpp:228] Iteration 80330, loss = 0.0508458
I0906 04:40:48.061367 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0508471 (* 1 = 0.0508471 loss)
I0906 04:40:48.061385 90901 sgd_solver.cpp:106] Iteration 80330, lr = 0.001
I0906 04:40:56.946177 90901 solver.cpp:228] Iteration 80340, loss = 0.134286
I0906 04:40:56.946241 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134288 (* 1 = 0.134288 loss)
I0906 04:40:56.946259 90901 sgd_solver.cpp:106] Iteration 80340, lr = 0.001
I0906 04:41:05.804498 90901 solver.cpp:228] Iteration 80350, loss = 0.0612722
I0906 04:41:05.804572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0612736 (* 1 = 0.0612736 loss)
I0906 04:41:05.804589 90901 sgd_solver.cpp:106] Iteration 80350, lr = 0.001
I0906 04:41:14.401100 90901 solver.cpp:228] Iteration 80360, loss = 0.0679313
I0906 04:41:14.401448 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0679327 (* 1 = 0.0679327 loss)
I0906 04:41:14.401471 90901 sgd_solver.cpp:106] Iteration 80360, lr = 0.001
I0906 04:41:23.084177 90901 solver.cpp:228] Iteration 80370, loss = 0.19088
I0906 04:41:23.084249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190881 (* 1 = 0.190881 loss)
I0906 04:41:23.084264 90901 sgd_solver.cpp:106] Iteration 80370, lr = 0.001
I0906 04:41:31.608768 90901 solver.cpp:228] Iteration 80380, loss = 0.0466812
I0906 04:41:31.608834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0466826 (* 1 = 0.0466826 loss)
I0906 04:41:31.608851 90901 sgd_solver.cpp:106] Iteration 80380, lr = 0.001
I0906 04:41:39.559701 90901 solver.cpp:228] Iteration 80390, loss = 0.0582406
I0906 04:41:39.559767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.058242 (* 1 = 0.058242 loss)
I0906 04:41:39.559787 90901 sgd_solver.cpp:106] Iteration 80390, lr = 0.001
I0906 04:41:45.045729 90901 solver.cpp:228] Iteration 80400, loss = 0.195039
I0906 04:41:45.045892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195041 (* 1 = 0.195041 loss)
I0906 04:41:45.045908 90901 sgd_solver.cpp:106] Iteration 80400, lr = 0.001
I0906 04:41:49.979173 90901 solver.cpp:228] Iteration 80410, loss = 0.317224
I0906 04:41:49.979254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317225 (* 1 = 0.317225 loss)
I0906 04:41:49.979274 90901 sgd_solver.cpp:106] Iteration 80410, lr = 0.001
I0906 04:41:54.904544 90901 solver.cpp:228] Iteration 80420, loss = 0.108787
I0906 04:41:54.904608 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108788 (* 1 = 0.108788 loss)
I0906 04:41:54.904625 90901 sgd_solver.cpp:106] Iteration 80420, lr = 0.001
I0906 04:41:59.867036 90901 solver.cpp:228] Iteration 80430, loss = 0.310365
I0906 04:41:59.867386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310366 (* 1 = 0.310366 loss)
I0906 04:41:59.867487 90901 sgd_solver.cpp:106] Iteration 80430, lr = 0.001
I0906 04:42:05.815346 90901 solver.cpp:228] Iteration 80440, loss = 0.103676
I0906 04:42:05.815418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103678 (* 1 = 0.103678 loss)
I0906 04:42:05.815434 90901 sgd_solver.cpp:106] Iteration 80440, lr = 0.001
I0906 04:42:13.568894 90901 solver.cpp:228] Iteration 80450, loss = 0.184534
I0906 04:42:13.568964 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184535 (* 1 = 0.184535 loss)
I0906 04:42:13.568984 90901 sgd_solver.cpp:106] Iteration 80450, lr = 0.001
I0906 04:42:20.838718 90901 solver.cpp:228] Iteration 80460, loss = 0.379036
I0906 04:42:20.838894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379037 (* 1 = 0.379037 loss)
I0906 04:42:20.838935 90901 sgd_solver.cpp:106] Iteration 80460, lr = 0.001
I0906 04:42:29.122649 90901 solver.cpp:228] Iteration 80470, loss = 0.203651
I0906 04:42:29.122725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203653 (* 1 = 0.203653 loss)
I0906 04:42:29.122751 90901 sgd_solver.cpp:106] Iteration 80470, lr = 0.001
I0906 04:42:37.332298 90901 solver.cpp:228] Iteration 80480, loss = 0.0907572
I0906 04:42:37.332360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0907585 (* 1 = 0.0907585 loss)
I0906 04:42:37.332376 90901 sgd_solver.cpp:106] Iteration 80480, lr = 0.001
I0906 04:42:45.887635 90901 solver.cpp:228] Iteration 80490, loss = 0.104695
I0906 04:42:45.887701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104696 (* 1 = 0.104696 loss)
I0906 04:42:45.887717 90901 sgd_solver.cpp:106] Iteration 80490, lr = 0.001
I0906 04:42:55.108603 90901 solver.cpp:228] Iteration 80500, loss = 0.204895
I0906 04:42:55.108873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204897 (* 1 = 0.204897 loss)
I0906 04:42:55.108904 90901 sgd_solver.cpp:106] Iteration 80500, lr = 0.001
I0906 04:43:04.241776 90901 solver.cpp:228] Iteration 80510, loss = 0.0777013
I0906 04:43:04.241837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0777026 (* 1 = 0.0777026 loss)
I0906 04:43:04.241852 90901 sgd_solver.cpp:106] Iteration 80510, lr = 0.001
I0906 04:43:12.754438 90901 solver.cpp:228] Iteration 80520, loss = 0.271455
I0906 04:43:12.754500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271456 (* 1 = 0.271456 loss)
I0906 04:43:12.754518 90901 sgd_solver.cpp:106] Iteration 80520, lr = 0.001
I0906 04:43:22.153406 90901 solver.cpp:228] Iteration 80530, loss = 0.187036
I0906 04:43:22.153493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187038 (* 1 = 0.187038 loss)
I0906 04:43:22.153512 90901 sgd_solver.cpp:106] Iteration 80530, lr = 0.001
I0906 04:43:30.794106 90901 solver.cpp:228] Iteration 80540, loss = 0.182574
I0906 04:43:30.794277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182575 (* 1 = 0.182575 loss)
I0906 04:43:30.794318 90901 sgd_solver.cpp:106] Iteration 80540, lr = 0.001
I0906 04:43:39.667716 90901 solver.cpp:228] Iteration 80550, loss = 0.283002
I0906 04:43:39.667788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283004 (* 1 = 0.283004 loss)
I0906 04:43:39.667805 90901 sgd_solver.cpp:106] Iteration 80550, lr = 0.001
I0906 04:43:48.146998 90901 solver.cpp:228] Iteration 80560, loss = 0.225539
I0906 04:43:48.147122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22554 (* 1 = 0.22554 loss)
I0906 04:43:48.147142 90901 sgd_solver.cpp:106] Iteration 80560, lr = 0.001
I0906 04:43:57.018158 90901 solver.cpp:228] Iteration 80570, loss = 0.200856
I0906 04:43:57.018220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200857 (* 1 = 0.200857 loss)
I0906 04:43:57.018237 90901 sgd_solver.cpp:106] Iteration 80570, lr = 0.001
I0906 04:44:05.816869 90901 solver.cpp:228] Iteration 80580, loss = 0.0427706
I0906 04:44:05.817006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0427719 (* 1 = 0.0427719 loss)
I0906 04:44:05.817024 90901 sgd_solver.cpp:106] Iteration 80580, lr = 0.001
I0906 04:44:13.743017 90901 solver.cpp:228] Iteration 80590, loss = 0.16646
I0906 04:44:13.743080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166461 (* 1 = 0.166461 loss)
I0906 04:44:13.743100 90901 sgd_solver.cpp:106] Iteration 80590, lr = 0.001
I0906 04:44:22.376997 90901 solver.cpp:228] Iteration 80600, loss = 0.395837
I0906 04:44:22.377084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395838 (* 1 = 0.395838 loss)
I0906 04:44:22.377102 90901 sgd_solver.cpp:106] Iteration 80600, lr = 0.001
I0906 04:44:30.409557 90901 solver.cpp:228] Iteration 80610, loss = 0.293849
I0906 04:44:30.409656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29385 (* 1 = 0.29385 loss)
I0906 04:44:30.409682 90901 sgd_solver.cpp:106] Iteration 80610, lr = 0.001
I0906 04:44:39.062672 90901 solver.cpp:228] Iteration 80620, loss = 0.565546
I0906 04:44:39.062846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.565547 (* 1 = 0.565547 loss)
I0906 04:44:39.062870 90901 sgd_solver.cpp:106] Iteration 80620, lr = 0.001
I0906 04:44:47.508518 90901 solver.cpp:228] Iteration 80630, loss = 0.0730355
I0906 04:44:47.508610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0730367 (* 1 = 0.0730367 loss)
I0906 04:44:47.508627 90901 sgd_solver.cpp:106] Iteration 80630, lr = 0.001
I0906 04:44:55.981385 90901 solver.cpp:228] Iteration 80640, loss = 0.343564
I0906 04:44:55.981492 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343566 (* 1 = 0.343566 loss)
I0906 04:44:55.981509 90901 sgd_solver.cpp:106] Iteration 80640, lr = 0.001
I0906 04:45:04.792657 90901 solver.cpp:228] Iteration 80650, loss = 0.379637
I0906 04:45:04.792723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379638 (* 1 = 0.379638 loss)
I0906 04:45:04.792742 90901 sgd_solver.cpp:106] Iteration 80650, lr = 0.001
I0906 04:45:13.410681 90901 solver.cpp:228] Iteration 80660, loss = 0.187897
I0906 04:45:13.410912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187898 (* 1 = 0.187898 loss)
I0906 04:45:13.410935 90901 sgd_solver.cpp:106] Iteration 80660, lr = 0.001
I0906 04:45:21.797180 90901 solver.cpp:228] Iteration 80670, loss = 0.0673088
I0906 04:45:21.797243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0673099 (* 1 = 0.0673099 loss)
I0906 04:45:21.797260 90901 sgd_solver.cpp:106] Iteration 80670, lr = 0.001
I0906 04:45:30.481655 90901 solver.cpp:228] Iteration 80680, loss = 0.255779
I0906 04:45:30.481722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255781 (* 1 = 0.255781 loss)
I0906 04:45:30.481739 90901 sgd_solver.cpp:106] Iteration 80680, lr = 0.001
I0906 04:45:39.203088 90901 solver.cpp:228] Iteration 80690, loss = 0.188227
I0906 04:45:39.203186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188228 (* 1 = 0.188228 loss)
I0906 04:45:39.203205 90901 sgd_solver.cpp:106] Iteration 80690, lr = 0.001
I0906 04:45:47.630966 90901 solver.cpp:228] Iteration 80700, loss = 0.0856807
I0906 04:45:47.631208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0856818 (* 1 = 0.0856818 loss)
I0906 04:45:47.631235 90901 sgd_solver.cpp:106] Iteration 80700, lr = 0.001
I0906 04:45:56.232910 90901 solver.cpp:228] Iteration 80710, loss = 0.208288
I0906 04:45:56.233026 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208289 (* 1 = 0.208289 loss)
I0906 04:45:56.233047 90901 sgd_solver.cpp:106] Iteration 80710, lr = 0.001
I0906 04:46:04.871116 90901 solver.cpp:228] Iteration 80720, loss = 0.328684
I0906 04:46:04.871181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.328685 (* 1 = 0.328685 loss)
I0906 04:46:04.871197 90901 sgd_solver.cpp:106] Iteration 80720, lr = 0.001
I0906 04:46:13.022106 90901 solver.cpp:228] Iteration 80730, loss = 0.176897
I0906 04:46:13.022248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176898 (* 1 = 0.176898 loss)
I0906 04:46:13.022267 90901 sgd_solver.cpp:106] Iteration 80730, lr = 0.001
I0906 04:46:21.533257 90901 solver.cpp:228] Iteration 80740, loss = 0.109525
I0906 04:46:21.533483 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109526 (* 1 = 0.109526 loss)
I0906 04:46:21.533511 90901 sgd_solver.cpp:106] Iteration 80740, lr = 0.001
I0906 04:46:30.096762 90901 solver.cpp:228] Iteration 80750, loss = 0.043285
I0906 04:46:30.096887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.043286 (* 1 = 0.043286 loss)
I0906 04:46:30.096915 90901 sgd_solver.cpp:106] Iteration 80750, lr = 0.001
I0906 04:46:38.802695 90901 solver.cpp:228] Iteration 80760, loss = 0.0992173
I0906 04:46:38.802753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0992184 (* 1 = 0.0992184 loss)
I0906 04:46:38.802772 90901 sgd_solver.cpp:106] Iteration 80760, lr = 0.001
I0906 04:46:47.453330 90901 solver.cpp:228] Iteration 80770, loss = 0.177272
I0906 04:46:47.453512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177273 (* 1 = 0.177273 loss)
I0906 04:46:47.453546 90901 sgd_solver.cpp:106] Iteration 80770, lr = 0.001
I0906 04:46:55.670810 90901 solver.cpp:228] Iteration 80780, loss = 0.0276886
I0906 04:46:55.671053 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0276897 (* 1 = 0.0276897 loss)
I0906 04:46:55.671073 90901 sgd_solver.cpp:106] Iteration 80780, lr = 0.001
I0906 04:47:04.099181 90901 solver.cpp:228] Iteration 80790, loss = 0.0255906
I0906 04:47:04.099259 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0255916 (* 1 = 0.0255916 loss)
I0906 04:47:04.099282 90901 sgd_solver.cpp:106] Iteration 80790, lr = 0.001
I0906 04:47:12.083216 90901 solver.cpp:337] Iteration 80800, Testing net (#0)
I0906 04:48:11.149984 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.950312
I0906 04:48:11.150137 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.130534 (* 1 = 0.130534 loss)
I0906 04:48:11.456584 90901 solver.cpp:228] Iteration 80800, loss = 0.358459
I0906 04:48:11.456702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35846 (* 1 = 0.35846 loss)
I0906 04:48:11.456730 90901 sgd_solver.cpp:106] Iteration 80800, lr = 0.001
I0906 04:48:20.034732 90901 solver.cpp:228] Iteration 80810, loss = 0.0507995
I0906 04:48:20.034842 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0508005 (* 1 = 0.0508005 loss)
I0906 04:48:20.034867 90901 sgd_solver.cpp:106] Iteration 80810, lr = 0.001
I0906 04:48:28.404954 90901 solver.cpp:228] Iteration 80820, loss = 0.17028
I0906 04:48:28.405015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170281 (* 1 = 0.170281 loss)
I0906 04:48:28.405031 90901 sgd_solver.cpp:106] Iteration 80820, lr = 0.001
I0906 04:48:37.748529 90901 solver.cpp:228] Iteration 80830, loss = 0.129184
I0906 04:48:37.748584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129185 (* 1 = 0.129185 loss)
I0906 04:48:37.748599 90901 sgd_solver.cpp:106] Iteration 80830, lr = 0.001
I0906 04:48:46.889340 90901 solver.cpp:228] Iteration 80840, loss = 0.0884347
I0906 04:48:46.889541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0884358 (* 1 = 0.0884358 loss)
I0906 04:48:46.889576 90901 sgd_solver.cpp:106] Iteration 80840, lr = 0.001
I0906 04:48:55.647481 90901 solver.cpp:228] Iteration 80850, loss = 0.0603357
I0906 04:48:55.647539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0603368 (* 1 = 0.0603368 loss)
I0906 04:48:55.647555 90901 sgd_solver.cpp:106] Iteration 80850, lr = 0.001
I0906 04:49:04.089366 90901 solver.cpp:228] Iteration 80860, loss = 0.0660131
I0906 04:49:04.089432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0660142 (* 1 = 0.0660142 loss)
I0906 04:49:04.089452 90901 sgd_solver.cpp:106] Iteration 80860, lr = 0.001
I0906 04:49:13.331174 90901 solver.cpp:228] Iteration 80870, loss = 0.0775268
I0906 04:49:13.331256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0775279 (* 1 = 0.0775279 loss)
I0906 04:49:13.331277 90901 sgd_solver.cpp:106] Iteration 80870, lr = 0.001
I0906 04:49:22.244789 90901 solver.cpp:228] Iteration 80880, loss = 0.11679
I0906 04:49:22.244962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116792 (* 1 = 0.116792 loss)
I0906 04:49:22.244989 90901 sgd_solver.cpp:106] Iteration 80880, lr = 0.001
I0906 04:49:30.995470 90901 solver.cpp:228] Iteration 80890, loss = 0.188636
I0906 04:49:30.995546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188637 (* 1 = 0.188637 loss)
I0906 04:49:30.995563 90901 sgd_solver.cpp:106] Iteration 80890, lr = 0.001
I0906 04:49:39.792541 90901 solver.cpp:228] Iteration 80900, loss = 0.173939
I0906 04:49:39.792634 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17394 (* 1 = 0.17394 loss)
I0906 04:49:39.792652 90901 sgd_solver.cpp:106] Iteration 80900, lr = 0.001
I0906 04:49:48.131860 90901 solver.cpp:228] Iteration 80910, loss = 0.0362723
I0906 04:49:48.131937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0362734 (* 1 = 0.0362734 loss)
I0906 04:49:48.131954 90901 sgd_solver.cpp:106] Iteration 80910, lr = 0.001
I0906 04:49:56.697505 90901 solver.cpp:228] Iteration 80920, loss = 0.272982
I0906 04:49:56.697834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272983 (* 1 = 0.272983 loss)
I0906 04:49:56.697859 90901 sgd_solver.cpp:106] Iteration 80920, lr = 0.001
I0906 04:50:04.492043 90901 solver.cpp:228] Iteration 80930, loss = 0.193667
I0906 04:50:04.492115 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193668 (* 1 = 0.193668 loss)
I0906 04:50:04.492131 90901 sgd_solver.cpp:106] Iteration 80930, lr = 0.001
I0906 04:50:12.630764 90901 solver.cpp:228] Iteration 80940, loss = 0.079357
I0906 04:50:12.630839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0793581 (* 1 = 0.0793581 loss)
I0906 04:50:12.630852 90901 sgd_solver.cpp:106] Iteration 80940, lr = 0.001
I0906 04:50:18.043658 90901 solver.cpp:228] Iteration 80950, loss = 0.0580131
I0906 04:50:18.043725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0580141 (* 1 = 0.0580141 loss)
I0906 04:50:18.043745 90901 sgd_solver.cpp:106] Iteration 80950, lr = 0.001
I0906 04:50:23.234494 90901 solver.cpp:228] Iteration 80960, loss = 0.0837733
I0906 04:50:23.234568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0837744 (* 1 = 0.0837744 loss)
I0906 04:50:23.234586 90901 sgd_solver.cpp:106] Iteration 80960, lr = 0.001
I0906 04:50:28.750316 90901 solver.cpp:228] Iteration 80970, loss = 0.231165
I0906 04:50:28.750515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231166 (* 1 = 0.231166 loss)
I0906 04:50:28.750535 90901 sgd_solver.cpp:106] Iteration 80970, lr = 0.001
I0906 04:50:34.064009 90901 solver.cpp:228] Iteration 80980, loss = 0.283211
I0906 04:50:34.064081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283212 (* 1 = 0.283212 loss)
I0906 04:50:34.064101 90901 sgd_solver.cpp:106] Iteration 80980, lr = 0.001
I0906 04:50:40.398717 90901 solver.cpp:228] Iteration 80990, loss = 0.167121
I0906 04:50:40.398795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167122 (* 1 = 0.167122 loss)
I0906 04:50:40.398813 90901 sgd_solver.cpp:106] Iteration 80990, lr = 0.001
I0906 04:50:45.627473 90901 solver.cpp:228] Iteration 81000, loss = 0.0336369
I0906 04:50:45.627575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0336379 (* 1 = 0.0336379 loss)
I0906 04:50:45.627594 90901 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I0906 04:50:52.091325 90901 solver.cpp:228] Iteration 81010, loss = 0.0961277
I0906 04:50:52.091382 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0961287 (* 1 = 0.0961287 loss)
I0906 04:50:52.091394 90901 sgd_solver.cpp:106] Iteration 81010, lr = 0.001
I0906 04:50:58.681617 90901 solver.cpp:228] Iteration 81020, loss = 0.0350534
I0906 04:50:58.681711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350544 (* 1 = 0.0350544 loss)
I0906 04:50:58.681730 90901 sgd_solver.cpp:106] Iteration 81020, lr = 0.001
I0906 04:51:07.124065 90901 solver.cpp:228] Iteration 81030, loss = 0.170369
I0906 04:51:07.124254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17037 (* 1 = 0.17037 loss)
I0906 04:51:07.124284 90901 sgd_solver.cpp:106] Iteration 81030, lr = 0.001
I0906 04:51:14.170439 90901 solver.cpp:228] Iteration 81040, loss = 0.0296613
I0906 04:51:14.170516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0296623 (* 1 = 0.0296623 loss)
I0906 04:51:14.170537 90901 sgd_solver.cpp:106] Iteration 81040, lr = 0.001
I0906 04:51:22.543642 90901 solver.cpp:228] Iteration 81050, loss = 0.230182
I0906 04:51:22.543715 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230183 (* 1 = 0.230183 loss)
I0906 04:51:22.543733 90901 sgd_solver.cpp:106] Iteration 81050, lr = 0.001
I0906 04:51:30.150423 90901 solver.cpp:228] Iteration 81060, loss = 0.616631
I0906 04:51:30.150516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.616632 (* 1 = 0.616632 loss)
I0906 04:51:30.150540 90901 sgd_solver.cpp:106] Iteration 81060, lr = 0.001
I0906 04:51:38.440397 90901 solver.cpp:228] Iteration 81070, loss = 0.0633166
I0906 04:51:38.440613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0633177 (* 1 = 0.0633177 loss)
I0906 04:51:38.440630 90901 sgd_solver.cpp:106] Iteration 81070, lr = 0.001
I0906 04:51:45.654750 90901 solver.cpp:228] Iteration 81080, loss = 0.256444
I0906 04:51:45.654837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256445 (* 1 = 0.256445 loss)
I0906 04:51:45.654856 90901 sgd_solver.cpp:106] Iteration 81080, lr = 0.001
I0906 04:51:53.498098 90901 solver.cpp:228] Iteration 81090, loss = 0.0480102
I0906 04:51:53.498188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0480112 (* 1 = 0.0480112 loss)
I0906 04:51:53.498214 90901 sgd_solver.cpp:106] Iteration 81090, lr = 0.001
I0906 04:52:01.554397 90901 solver.cpp:228] Iteration 81100, loss = 0.0411214
I0906 04:52:01.554497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0411224 (* 1 = 0.0411224 loss)
I0906 04:52:01.554517 90901 sgd_solver.cpp:106] Iteration 81100, lr = 0.001
I0906 04:52:09.680471 90901 solver.cpp:228] Iteration 81110, loss = 0.10009
I0906 04:52:09.680665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100091 (* 1 = 0.100091 loss)
I0906 04:52:09.680683 90901 sgd_solver.cpp:106] Iteration 81110, lr = 0.001
I0906 04:52:17.173846 90901 solver.cpp:228] Iteration 81120, loss = 0.0725843
I0906 04:52:17.173944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0725853 (* 1 = 0.0725853 loss)
I0906 04:52:17.173965 90901 sgd_solver.cpp:106] Iteration 81120, lr = 0.001
I0906 04:52:24.989924 90901 solver.cpp:228] Iteration 81130, loss = 0.232094
I0906 04:52:24.990011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232095 (* 1 = 0.232095 loss)
I0906 04:52:24.990031 90901 sgd_solver.cpp:106] Iteration 81130, lr = 0.001
I0906 04:52:32.841691 90901 solver.cpp:228] Iteration 81140, loss = 0.118323
I0906 04:52:32.841769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118324 (* 1 = 0.118324 loss)
I0906 04:52:32.841787 90901 sgd_solver.cpp:106] Iteration 81140, lr = 0.001
I0906 04:52:39.881783 90901 solver.cpp:228] Iteration 81150, loss = 0.0219345
I0906 04:52:39.881991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0219355 (* 1 = 0.0219355 loss)
I0906 04:52:39.882010 90901 sgd_solver.cpp:106] Iteration 81150, lr = 0.001
I0906 04:52:48.204289 90901 solver.cpp:228] Iteration 81160, loss = 0.397129
I0906 04:52:48.204366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.39713 (* 1 = 0.39713 loss)
I0906 04:52:48.204383 90901 sgd_solver.cpp:106] Iteration 81160, lr = 0.001
I0906 04:52:55.110065 90901 solver.cpp:228] Iteration 81170, loss = 0.181608
I0906 04:52:55.110147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181609 (* 1 = 0.181609 loss)
I0906 04:52:55.110164 90901 sgd_solver.cpp:106] Iteration 81170, lr = 0.001
I0906 04:53:03.890759 90901 solver.cpp:228] Iteration 81180, loss = 0.0289938
I0906 04:53:03.890835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0289949 (* 1 = 0.0289949 loss)
I0906 04:53:03.890852 90901 sgd_solver.cpp:106] Iteration 81180, lr = 0.001
I0906 04:53:10.353655 90901 solver.cpp:228] Iteration 81190, loss = 0.5013
I0906 04:53:10.353853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.501301 (* 1 = 0.501301 loss)
I0906 04:53:10.353873 90901 sgd_solver.cpp:106] Iteration 81190, lr = 0.001
I0906 04:53:19.029597 90901 solver.cpp:228] Iteration 81200, loss = 0.269872
I0906 04:53:19.029666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269873 (* 1 = 0.269873 loss)
I0906 04:53:19.029682 90901 sgd_solver.cpp:106] Iteration 81200, lr = 0.001
I0906 04:53:26.104322 90901 solver.cpp:228] Iteration 81210, loss = 0.325922
I0906 04:53:26.104490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325923 (* 1 = 0.325923 loss)
I0906 04:53:26.104514 90901 sgd_solver.cpp:106] Iteration 81210, lr = 0.001
I0906 04:53:34.492106 90901 solver.cpp:228] Iteration 81220, loss = 0.109666
I0906 04:53:34.492169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109667 (* 1 = 0.109667 loss)
I0906 04:53:34.492187 90901 sgd_solver.cpp:106] Iteration 81220, lr = 0.001
I0906 04:53:42.120535 90901 solver.cpp:228] Iteration 81230, loss = 0.207102
I0906 04:53:42.120784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207103 (* 1 = 0.207103 loss)
I0906 04:53:42.120803 90901 sgd_solver.cpp:106] Iteration 81230, lr = 0.001
I0906 04:53:50.126138 90901 solver.cpp:228] Iteration 81240, loss = 0.241312
I0906 04:53:50.126255 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241313 (* 1 = 0.241313 loss)
I0906 04:53:50.126289 90901 sgd_solver.cpp:106] Iteration 81240, lr = 0.001
I0906 04:53:56.559391 90901 solver.cpp:228] Iteration 81250, loss = 0.168559
I0906 04:53:56.559480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168561 (* 1 = 0.168561 loss)
I0906 04:53:56.559502 90901 sgd_solver.cpp:106] Iteration 81250, lr = 0.001
I0906 04:54:05.200747 90901 solver.cpp:228] Iteration 81260, loss = 0.111975
I0906 04:54:05.200815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111976 (* 1 = 0.111976 loss)
I0906 04:54:05.200835 90901 sgd_solver.cpp:106] Iteration 81260, lr = 0.001
I0906 04:54:12.481592 90901 solver.cpp:228] Iteration 81270, loss = 0.113604
I0906 04:54:12.481765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113605 (* 1 = 0.113605 loss)
I0906 04:54:12.481788 90901 sgd_solver.cpp:106] Iteration 81270, lr = 0.001
I0906 04:54:21.057355 90901 solver.cpp:228] Iteration 81280, loss = 0.316716
I0906 04:54:21.057468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316717 (* 1 = 0.316717 loss)
I0906 04:54:21.057493 90901 sgd_solver.cpp:106] Iteration 81280, lr = 0.001
I0906 04:54:28.040742 90901 solver.cpp:228] Iteration 81290, loss = 0.235219
I0906 04:54:28.040817 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23522 (* 1 = 0.23522 loss)
I0906 04:54:28.040840 90901 sgd_solver.cpp:106] Iteration 81290, lr = 0.001
I0906 04:54:36.749527 90901 solver.cpp:228] Iteration 81300, loss = 0.0295008
I0906 04:54:36.749611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0295019 (* 1 = 0.0295019 loss)
I0906 04:54:36.749629 90901 sgd_solver.cpp:106] Iteration 81300, lr = 0.001
I0906 04:54:44.179358 90901 solver.cpp:228] Iteration 81310, loss = 0.0574621
I0906 04:54:44.179491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0574632 (* 1 = 0.0574632 loss)
I0906 04:54:44.179510 90901 sgd_solver.cpp:106] Iteration 81310, lr = 0.001
I0906 04:54:52.687294 90901 solver.cpp:228] Iteration 81320, loss = 0.151217
I0906 04:54:52.687373 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151219 (* 1 = 0.151219 loss)
I0906 04:54:52.687391 90901 sgd_solver.cpp:106] Iteration 81320, lr = 0.001
I0906 04:55:00.028123 90901 solver.cpp:228] Iteration 81330, loss = 0.228031
I0906 04:55:00.028197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228032 (* 1 = 0.228032 loss)
I0906 04:55:00.028214 90901 sgd_solver.cpp:106] Iteration 81330, lr = 0.001
I0906 04:55:07.940348 90901 solver.cpp:228] Iteration 81340, loss = 0.453818
I0906 04:55:07.940421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453819 (* 1 = 0.453819 loss)
I0906 04:55:07.940439 90901 sgd_solver.cpp:106] Iteration 81340, lr = 0.001
I0906 04:55:16.643533 90901 solver.cpp:228] Iteration 81350, loss = 0.166173
I0906 04:55:16.643692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166174 (* 1 = 0.166174 loss)
I0906 04:55:16.643723 90901 sgd_solver.cpp:106] Iteration 81350, lr = 0.001
I0906 04:55:23.604626 90901 solver.cpp:228] Iteration 81360, loss = 0.245016
I0906 04:55:23.604684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245017 (* 1 = 0.245017 loss)
I0906 04:55:23.604706 90901 sgd_solver.cpp:106] Iteration 81360, lr = 0.001
I0906 04:55:32.204514 90901 solver.cpp:228] Iteration 81370, loss = 0.0289968
I0906 04:55:32.204574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0289979 (* 1 = 0.0289979 loss)
I0906 04:55:32.204594 90901 sgd_solver.cpp:106] Iteration 81370, lr = 0.001
I0906 04:55:39.744520 90901 solver.cpp:228] Iteration 81380, loss = 0.147332
I0906 04:55:39.744585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147334 (* 1 = 0.147334 loss)
I0906 04:55:39.744606 90901 sgd_solver.cpp:106] Iteration 81380, lr = 0.001
I0906 04:55:48.092950 90901 solver.cpp:228] Iteration 81390, loss = 0.198841
I0906 04:55:48.093210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198842 (* 1 = 0.198842 loss)
I0906 04:55:48.093230 90901 sgd_solver.cpp:106] Iteration 81390, lr = 0.001
I0906 04:55:55.601692 90901 solver.cpp:228] Iteration 81400, loss = 0.171862
I0906 04:55:55.601755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171864 (* 1 = 0.171864 loss)
I0906 04:55:55.601773 90901 sgd_solver.cpp:106] Iteration 81400, lr = 0.001
I0906 04:56:03.410289 90901 solver.cpp:228] Iteration 81410, loss = 0.0588072
I0906 04:56:03.410387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0588084 (* 1 = 0.0588084 loss)
I0906 04:56:03.410405 90901 sgd_solver.cpp:106] Iteration 81410, lr = 0.001
I0906 04:56:12.275734 90901 solver.cpp:228] Iteration 81420, loss = 0.306389
I0906 04:56:12.275820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30639 (* 1 = 0.30639 loss)
I0906 04:56:12.275841 90901 sgd_solver.cpp:106] Iteration 81420, lr = 0.001
I0906 04:56:19.840492 90901 solver.cpp:228] Iteration 81430, loss = 0.220838
I0906 04:56:19.840683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220839 (* 1 = 0.220839 loss)
I0906 04:56:19.840711 90901 sgd_solver.cpp:106] Iteration 81430, lr = 0.001
I0906 04:56:27.935714 90901 solver.cpp:228] Iteration 81440, loss = 0.0677654
I0906 04:56:27.935786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0677665 (* 1 = 0.0677665 loss)
I0906 04:56:27.935802 90901 sgd_solver.cpp:106] Iteration 81440, lr = 0.001
I0906 04:56:36.197005 90901 solver.cpp:228] Iteration 81450, loss = 0.113384
I0906 04:56:36.197090 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113385 (* 1 = 0.113385 loss)
I0906 04:56:36.197113 90901 sgd_solver.cpp:106] Iteration 81450, lr = 0.001
I0906 04:56:42.920994 90901 solver.cpp:228] Iteration 81460, loss = 0.144928
I0906 04:56:42.921097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144929 (* 1 = 0.144929 loss)
I0906 04:56:42.921116 90901 sgd_solver.cpp:106] Iteration 81460, lr = 0.001
I0906 04:56:51.926486 90901 solver.cpp:228] Iteration 81470, loss = 0.188659
I0906 04:56:51.926659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18866 (* 1 = 0.18866 loss)
I0906 04:56:51.926679 90901 sgd_solver.cpp:106] Iteration 81470, lr = 0.001
I0906 04:57:00.051030 90901 solver.cpp:228] Iteration 81480, loss = 0.331334
I0906 04:57:00.051106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331335 (* 1 = 0.331335 loss)
I0906 04:57:00.051127 90901 sgd_solver.cpp:106] Iteration 81480, lr = 0.001
I0906 04:57:08.091897 90901 solver.cpp:228] Iteration 81490, loss = 0.0665477
I0906 04:57:08.091984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0665488 (* 1 = 0.0665488 loss)
I0906 04:57:08.092001 90901 sgd_solver.cpp:106] Iteration 81490, lr = 0.001
I0906 04:57:16.701320 90901 solver.cpp:228] Iteration 81500, loss = 0.192388
I0906 04:57:16.701381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192389 (* 1 = 0.192389 loss)
I0906 04:57:16.701398 90901 sgd_solver.cpp:106] Iteration 81500, lr = 0.001
I0906 04:57:23.823217 90901 solver.cpp:228] Iteration 81510, loss = 0.0478881
I0906 04:57:23.823390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0478893 (* 1 = 0.0478893 loss)
I0906 04:57:23.823415 90901 sgd_solver.cpp:106] Iteration 81510, lr = 0.001
I0906 04:57:32.646802 90901 solver.cpp:228] Iteration 81520, loss = 0.320044
I0906 04:57:32.646873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.320045 (* 1 = 0.320045 loss)
I0906 04:57:32.646890 90901 sgd_solver.cpp:106] Iteration 81520, lr = 0.001
I0906 04:57:39.341714 90901 solver.cpp:228] Iteration 81530, loss = 0.264075
I0906 04:57:39.341837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264076 (* 1 = 0.264076 loss)
I0906 04:57:39.341857 90901 sgd_solver.cpp:106] Iteration 81530, lr = 0.001
I0906 04:57:48.181565 90901 solver.cpp:228] Iteration 81540, loss = 0.616438
I0906 04:57:48.181645 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.616439 (* 1 = 0.616439 loss)
I0906 04:57:48.181668 90901 sgd_solver.cpp:106] Iteration 81540, lr = 0.001
I0906 04:57:56.007367 90901 solver.cpp:228] Iteration 81550, loss = 0.103805
I0906 04:57:56.007545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103806 (* 1 = 0.103806 loss)
I0906 04:57:56.007566 90901 sgd_solver.cpp:106] Iteration 81550, lr = 0.001
I0906 04:58:03.862220 90901 solver.cpp:228] Iteration 81560, loss = 0.129615
I0906 04:58:03.862294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129616 (* 1 = 0.129616 loss)
I0906 04:58:03.862311 90901 sgd_solver.cpp:106] Iteration 81560, lr = 0.001
I0906 04:58:11.655313 90901 solver.cpp:228] Iteration 81570, loss = 0.157643
I0906 04:58:11.655405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157644 (* 1 = 0.157644 loss)
I0906 04:58:11.655422 90901 sgd_solver.cpp:106] Iteration 81570, lr = 0.001
I0906 04:58:19.727849 90901 solver.cpp:228] Iteration 81580, loss = 0.0614252
I0906 04:58:19.727928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0614263 (* 1 = 0.0614263 loss)
I0906 04:58:19.727947 90901 sgd_solver.cpp:106] Iteration 81580, lr = 0.001
I0906 04:58:28.111609 90901 solver.cpp:228] Iteration 81590, loss = 0.121694
I0906 04:58:28.111820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121695 (* 1 = 0.121695 loss)
I0906 04:58:28.111852 90901 sgd_solver.cpp:106] Iteration 81590, lr = 0.001
I0906 04:58:35.926184 90901 solver.cpp:337] Iteration 81600, Testing net (#0)
I0906 04:59:33.790585 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.941875
I0906 04:59:33.790762 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.15022 (* 1 = 0.15022 loss)
I0906 04:59:33.992096 90901 solver.cpp:228] Iteration 81600, loss = 0.0402082
I0906 04:59:33.992163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0402092 (* 1 = 0.0402092 loss)
I0906 04:59:33.992184 90901 sgd_solver.cpp:106] Iteration 81600, lr = 0.001
I0906 04:59:42.590422 90901 solver.cpp:228] Iteration 81610, loss = 0.076514
I0906 04:59:42.590490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.076515 (* 1 = 0.076515 loss)
I0906 04:59:42.590507 90901 sgd_solver.cpp:106] Iteration 81610, lr = 0.001
I0906 04:59:49.840879 90901 solver.cpp:228] Iteration 81620, loss = 0.253923
I0906 04:59:49.841011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253924 (* 1 = 0.253924 loss)
I0906 04:59:49.841039 90901 sgd_solver.cpp:106] Iteration 81620, lr = 0.001
I0906 04:59:58.615540 90901 solver.cpp:228] Iteration 81630, loss = 0.0895752
I0906 04:59:58.615800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0895763 (* 1 = 0.0895763 loss)
I0906 04:59:58.615854 90901 sgd_solver.cpp:106] Iteration 81630, lr = 0.001
I0906 05:00:06.520757 90901 solver.cpp:228] Iteration 81640, loss = 0.0573754
I0906 05:00:06.520927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0573764 (* 1 = 0.0573764 loss)
I0906 05:00:06.520961 90901 sgd_solver.cpp:106] Iteration 81640, lr = 0.001
I0906 05:00:14.898013 90901 solver.cpp:228] Iteration 81650, loss = 0.356171
I0906 05:00:14.898082 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356172 (* 1 = 0.356172 loss)
I0906 05:00:14.898098 90901 sgd_solver.cpp:106] Iteration 81650, lr = 0.001
I0906 05:00:23.528065 90901 solver.cpp:228] Iteration 81660, loss = 0.201529
I0906 05:00:23.528129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20153 (* 1 = 0.20153 loss)
I0906 05:00:23.528146 90901 sgd_solver.cpp:106] Iteration 81660, lr = 0.001
I0906 05:00:31.393869 90901 solver.cpp:228] Iteration 81670, loss = 0.134921
I0906 05:00:31.393930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134922 (* 1 = 0.134922 loss)
I0906 05:00:31.393947 90901 sgd_solver.cpp:106] Iteration 81670, lr = 0.001
I0906 05:00:39.986354 90901 solver.cpp:228] Iteration 81680, loss = 0.121568
I0906 05:00:39.986554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121569 (* 1 = 0.121569 loss)
I0906 05:00:39.986573 90901 sgd_solver.cpp:106] Iteration 81680, lr = 0.001
I0906 05:00:47.942409 90901 solver.cpp:228] Iteration 81690, loss = 0.0645735
I0906 05:00:47.942488 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0645745 (* 1 = 0.0645745 loss)
I0906 05:00:47.942507 90901 sgd_solver.cpp:106] Iteration 81690, lr = 0.001
I0906 05:00:57.025938 90901 solver.cpp:228] Iteration 81700, loss = 0.111888
I0906 05:00:57.026005 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111889 (* 1 = 0.111889 loss)
I0906 05:00:57.026021 90901 sgd_solver.cpp:106] Iteration 81700, lr = 0.001
I0906 05:01:05.585155 90901 solver.cpp:228] Iteration 81710, loss = 0.0775899
I0906 05:01:05.585245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0775909 (* 1 = 0.0775909 loss)
I0906 05:01:05.585268 90901 sgd_solver.cpp:106] Iteration 81710, lr = 0.001
I0906 05:01:13.309903 90901 solver.cpp:228] Iteration 81720, loss = 0.0501982
I0906 05:01:13.310056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0501993 (* 1 = 0.0501993 loss)
I0906 05:01:13.310075 90901 sgd_solver.cpp:106] Iteration 81720, lr = 0.001
I0906 05:01:21.710949 90901 solver.cpp:228] Iteration 81730, loss = 0.090986
I0906 05:01:21.711011 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.090987 (* 1 = 0.090987 loss)
I0906 05:01:21.711033 90901 sgd_solver.cpp:106] Iteration 81730, lr = 0.001
I0906 05:01:29.393198 90901 solver.cpp:228] Iteration 81740, loss = 0.155285
I0906 05:01:29.393266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155286 (* 1 = 0.155286 loss)
I0906 05:01:29.393283 90901 sgd_solver.cpp:106] Iteration 81740, lr = 0.001
I0906 05:01:37.777891 90901 solver.cpp:228] Iteration 81750, loss = 0.148208
I0906 05:01:37.777962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148209 (* 1 = 0.148209 loss)
I0906 05:01:37.777982 90901 sgd_solver.cpp:106] Iteration 81750, lr = 0.001
I0906 05:01:45.253638 90901 solver.cpp:228] Iteration 81760, loss = 0.012908
I0906 05:01:45.253821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.012909 (* 1 = 0.012909 loss)
I0906 05:01:45.253845 90901 sgd_solver.cpp:106] Iteration 81760, lr = 0.001
I0906 05:01:52.914157 90901 solver.cpp:228] Iteration 81770, loss = 0.106716
I0906 05:01:52.914222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106717 (* 1 = 0.106717 loss)
I0906 05:01:52.914237 90901 sgd_solver.cpp:106] Iteration 81770, lr = 0.001
I0906 05:02:00.667330 90901 solver.cpp:228] Iteration 81780, loss = 0.0586615
I0906 05:02:00.667393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0586625 (* 1 = 0.0586625 loss)
I0906 05:02:00.667408 90901 sgd_solver.cpp:106] Iteration 81780, lr = 0.001
I0906 05:02:07.922509 90901 solver.cpp:228] Iteration 81790, loss = 0.0853842
I0906 05:02:07.922587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853852 (* 1 = 0.0853852 loss)
I0906 05:02:07.922608 90901 sgd_solver.cpp:106] Iteration 81790, lr = 0.001
I0906 05:02:15.968816 90901 solver.cpp:228] Iteration 81800, loss = 0.343693
I0906 05:02:15.968993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343694 (* 1 = 0.343694 loss)
I0906 05:02:15.969014 90901 sgd_solver.cpp:106] Iteration 81800, lr = 0.001
I0906 05:02:23.572957 90901 solver.cpp:228] Iteration 81810, loss = 0.145407
I0906 05:02:23.573040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145408 (* 1 = 0.145408 loss)
I0906 05:02:23.573057 90901 sgd_solver.cpp:106] Iteration 81810, lr = 0.001
I0906 05:02:30.055704 90901 solver.cpp:228] Iteration 81820, loss = 0.0393068
I0906 05:02:30.055789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0393079 (* 1 = 0.0393079 loss)
I0906 05:02:30.055809 90901 sgd_solver.cpp:106] Iteration 81820, lr = 0.001
I0906 05:02:37.593117 90901 solver.cpp:228] Iteration 81830, loss = 0.523539
I0906 05:02:37.593188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.52354 (* 1 = 0.52354 loss)
I0906 05:02:37.593206 90901 sgd_solver.cpp:106] Iteration 81830, lr = 0.001
I0906 05:02:44.952687 90901 solver.cpp:228] Iteration 81840, loss = 0.0527377
I0906 05:02:44.952780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0527387 (* 1 = 0.0527387 loss)
I0906 05:02:44.952805 90901 sgd_solver.cpp:106] Iteration 81840, lr = 0.001
I0906 05:02:51.260161 90901 solver.cpp:228] Iteration 81850, loss = 0.0524065
I0906 05:02:51.260437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0524075 (* 1 = 0.0524075 loss)
I0906 05:02:51.260459 90901 sgd_solver.cpp:106] Iteration 81850, lr = 0.001
I0906 05:02:59.173282 90901 solver.cpp:228] Iteration 81860, loss = 0.249811
I0906 05:02:59.173347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249812 (* 1 = 0.249812 loss)
I0906 05:02:59.173364 90901 sgd_solver.cpp:106] Iteration 81860, lr = 0.001
I0906 05:03:06.474488 90901 solver.cpp:228] Iteration 81870, loss = 0.527486
I0906 05:03:06.474593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.527487 (* 1 = 0.527487 loss)
I0906 05:03:06.474618 90901 sgd_solver.cpp:106] Iteration 81870, lr = 0.001
I0906 05:03:11.674357 90901 solver.cpp:228] Iteration 81880, loss = 0.106606
I0906 05:03:11.674432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106607 (* 1 = 0.106607 loss)
I0906 05:03:11.674448 90901 sgd_solver.cpp:106] Iteration 81880, lr = 0.001
I0906 05:03:16.877689 90901 solver.cpp:228] Iteration 81890, loss = 0.0334903
I0906 05:03:16.877755 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0334914 (* 1 = 0.0334914 loss)
I0906 05:03:16.877771 90901 sgd_solver.cpp:106] Iteration 81890, lr = 0.001
I0906 05:03:22.084529 90901 solver.cpp:228] Iteration 81900, loss = 0.140448
I0906 05:03:22.084681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140449 (* 1 = 0.140449 loss)
I0906 05:03:22.084703 90901 sgd_solver.cpp:106] Iteration 81900, lr = 0.001
I0906 05:03:27.248148 90901 solver.cpp:228] Iteration 81910, loss = 0.138735
I0906 05:03:27.248209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138736 (* 1 = 0.138736 loss)
I0906 05:03:27.248229 90901 sgd_solver.cpp:106] Iteration 81910, lr = 0.001
I0906 05:03:32.747920 90901 solver.cpp:228] Iteration 81920, loss = 0.021268
I0906 05:03:32.747990 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0212691 (* 1 = 0.0212691 loss)
I0906 05:03:32.748010 90901 sgd_solver.cpp:106] Iteration 81920, lr = 0.001
I0906 05:03:37.939342 90901 solver.cpp:228] Iteration 81930, loss = 0.500284
I0906 05:03:37.939442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.500286 (* 1 = 0.500286 loss)
I0906 05:03:37.939473 90901 sgd_solver.cpp:106] Iteration 81930, lr = 0.001
I0906 05:03:43.208359 90901 solver.cpp:228] Iteration 81940, loss = 0.091268
I0906 05:03:43.208434 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0912691 (* 1 = 0.0912691 loss)
I0906 05:03:43.208453 90901 sgd_solver.cpp:106] Iteration 81940, lr = 0.001
I0906 05:03:48.628078 90901 solver.cpp:228] Iteration 81950, loss = 0.0566501
I0906 05:03:48.628159 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0566512 (* 1 = 0.0566512 loss)
I0906 05:03:48.628181 90901 sgd_solver.cpp:106] Iteration 81950, lr = 0.001
I0906 05:03:53.821589 90901 solver.cpp:228] Iteration 81960, loss = 0.0301439
I0906 05:03:53.821894 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.030145 (* 1 = 0.030145 loss)
I0906 05:03:53.821921 90901 sgd_solver.cpp:106] Iteration 81960, lr = 0.001
I0906 05:03:59.017552 90901 solver.cpp:228] Iteration 81970, loss = 0.028755
I0906 05:03:59.017621 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0287561 (* 1 = 0.0287561 loss)
I0906 05:03:59.017638 90901 sgd_solver.cpp:106] Iteration 81970, lr = 0.001
I0906 05:04:04.197485 90901 solver.cpp:228] Iteration 81980, loss = 0.0601197
I0906 05:04:04.197566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0601208 (* 1 = 0.0601208 loss)
I0906 05:04:04.197584 90901 sgd_solver.cpp:106] Iteration 81980, lr = 0.001
I0906 05:04:09.409991 90901 solver.cpp:228] Iteration 81990, loss = 0.123891
I0906 05:04:09.410076 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123892 (* 1 = 0.123892 loss)
I0906 05:04:09.410094 90901 sgd_solver.cpp:106] Iteration 81990, lr = 0.001
I0906 05:04:14.951040 90901 solver.cpp:228] Iteration 82000, loss = 0.340126
I0906 05:04:14.951122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340127 (* 1 = 0.340127 loss)
I0906 05:04:14.951144 90901 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I0906 05:04:20.143661 90901 solver.cpp:228] Iteration 82010, loss = 0.11711
I0906 05:04:20.143728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117111 (* 1 = 0.117111 loss)
I0906 05:04:20.143745 90901 sgd_solver.cpp:106] Iteration 82010, lr = 0.001
I0906 05:04:25.856009 90901 solver.cpp:228] Iteration 82020, loss = 0.128355
I0906 05:04:25.856176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128356 (* 1 = 0.128356 loss)
I0906 05:04:25.856195 90901 sgd_solver.cpp:106] Iteration 82020, lr = 0.001
I0906 05:04:31.064509 90901 solver.cpp:228] Iteration 82030, loss = 0.199576
I0906 05:04:31.064577 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199577 (* 1 = 0.199577 loss)
I0906 05:04:31.064594 90901 sgd_solver.cpp:106] Iteration 82030, lr = 0.001
I0906 05:04:36.604272 90901 solver.cpp:228] Iteration 82040, loss = 0.317743
I0906 05:04:36.604348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317744 (* 1 = 0.317744 loss)
I0906 05:04:36.604367 90901 sgd_solver.cpp:106] Iteration 82040, lr = 0.001
I0906 05:04:42.052094 90901 solver.cpp:228] Iteration 82050, loss = 0.214188
I0906 05:04:42.052167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214189 (* 1 = 0.214189 loss)
I0906 05:04:42.052188 90901 sgd_solver.cpp:106] Iteration 82050, lr = 0.001
I0906 05:04:48.729696 90901 solver.cpp:228] Iteration 82060, loss = 0.0449177
I0906 05:04:48.729760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0449188 (* 1 = 0.0449188 loss)
I0906 05:04:48.729782 90901 sgd_solver.cpp:106] Iteration 82060, lr = 0.001
I0906 05:04:56.732714 90901 solver.cpp:228] Iteration 82070, loss = 0.129744
I0906 05:04:56.732856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129745 (* 1 = 0.129745 loss)
I0906 05:04:56.732874 90901 sgd_solver.cpp:106] Iteration 82070, lr = 0.001
I0906 05:05:03.925534 90901 solver.cpp:228] Iteration 82080, loss = 0.545444
I0906 05:05:03.925631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.545445 (* 1 = 0.545445 loss)
I0906 05:05:03.925657 90901 sgd_solver.cpp:106] Iteration 82080, lr = 0.001
I0906 05:05:12.751219 90901 solver.cpp:228] Iteration 82090, loss = 0.210976
I0906 05:05:12.751299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210977 (* 1 = 0.210977 loss)
I0906 05:05:12.751315 90901 sgd_solver.cpp:106] Iteration 82090, lr = 0.001
I0906 05:05:19.699388 90901 solver.cpp:228] Iteration 82100, loss = 0.251262
I0906 05:05:19.699453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251263 (* 1 = 0.251263 loss)
I0906 05:05:19.699476 90901 sgd_solver.cpp:106] Iteration 82100, lr = 0.001
I0906 05:05:28.169575 90901 solver.cpp:228] Iteration 82110, loss = 0.468384
I0906 05:05:28.169780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.468385 (* 1 = 0.468385 loss)
I0906 05:05:28.169803 90901 sgd_solver.cpp:106] Iteration 82110, lr = 0.001
I0906 05:05:36.392254 90901 solver.cpp:228] Iteration 82120, loss = 0.0277103
I0906 05:05:36.392320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0277113 (* 1 = 0.0277113 loss)
I0906 05:05:36.392338 90901 sgd_solver.cpp:106] Iteration 82120, lr = 0.001
I0906 05:05:44.951025 90901 solver.cpp:228] Iteration 82130, loss = 0.0930024
I0906 05:05:44.951144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0930035 (* 1 = 0.0930035 loss)
I0906 05:05:44.951169 90901 sgd_solver.cpp:106] Iteration 82130, lr = 0.001
I0906 05:05:54.169422 90901 solver.cpp:228] Iteration 82140, loss = 0.220252
I0906 05:05:54.169515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220253 (* 1 = 0.220253 loss)
I0906 05:05:54.169540 90901 sgd_solver.cpp:106] Iteration 82140, lr = 0.001
I0906 05:06:02.686508 90901 solver.cpp:228] Iteration 82150, loss = 0.129341
I0906 05:06:02.686686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129342 (* 1 = 0.129342 loss)
I0906 05:06:02.686705 90901 sgd_solver.cpp:106] Iteration 82150, lr = 0.001
I0906 05:06:10.276684 90901 solver.cpp:228] Iteration 82160, loss = 0.214367
I0906 05:06:10.276763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214368 (* 1 = 0.214368 loss)
I0906 05:06:10.276782 90901 sgd_solver.cpp:106] Iteration 82160, lr = 0.001
I0906 05:06:19.609380 90901 solver.cpp:228] Iteration 82170, loss = 0.188184
I0906 05:06:19.609477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188185 (* 1 = 0.188185 loss)
I0906 05:06:19.609498 90901 sgd_solver.cpp:106] Iteration 82170, lr = 0.001
I0906 05:06:29.239004 90901 solver.cpp:228] Iteration 82180, loss = 0.140669
I0906 05:06:29.239071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14067 (* 1 = 0.14067 loss)
I0906 05:06:29.239089 90901 sgd_solver.cpp:106] Iteration 82180, lr = 0.001
I0906 05:06:37.591768 90901 solver.cpp:228] Iteration 82190, loss = 0.164908
I0906 05:06:37.591974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164909 (* 1 = 0.164909 loss)
I0906 05:06:37.591992 90901 sgd_solver.cpp:106] Iteration 82190, lr = 0.001
I0906 05:06:45.930852 90901 solver.cpp:228] Iteration 82200, loss = 0.0290021
I0906 05:06:45.930938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0290031 (* 1 = 0.0290031 loss)
I0906 05:06:45.930956 90901 sgd_solver.cpp:106] Iteration 82200, lr = 0.001
I0906 05:06:54.850122 90901 solver.cpp:228] Iteration 82210, loss = 0.15001
I0906 05:06:54.850198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150011 (* 1 = 0.150011 loss)
I0906 05:06:54.850217 90901 sgd_solver.cpp:106] Iteration 82210, lr = 0.001
I0906 05:07:03.650952 90901 solver.cpp:228] Iteration 82220, loss = 0.341127
I0906 05:07:03.651021 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.341128 (* 1 = 0.341128 loss)
I0906 05:07:03.651038 90901 sgd_solver.cpp:106] Iteration 82220, lr = 0.001
I0906 05:07:11.500723 90901 solver.cpp:228] Iteration 82230, loss = 0.0802512
I0906 05:07:11.500991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0802522 (* 1 = 0.0802522 loss)
I0906 05:07:11.501011 90901 sgd_solver.cpp:106] Iteration 82230, lr = 0.001
I0906 05:07:20.436173 90901 solver.cpp:228] Iteration 82240, loss = 0.0606258
I0906 05:07:20.436240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0606268 (* 1 = 0.0606268 loss)
I0906 05:07:20.436257 90901 sgd_solver.cpp:106] Iteration 82240, lr = 0.001
I0906 05:07:29.272853 90901 solver.cpp:228] Iteration 82250, loss = 0.32619
I0906 05:07:29.272939 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326191 (* 1 = 0.326191 loss)
I0906 05:07:29.272958 90901 sgd_solver.cpp:106] Iteration 82250, lr = 0.001
I0906 05:07:38.012321 90901 solver.cpp:228] Iteration 82260, loss = 0.105814
I0906 05:07:38.012415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105815 (* 1 = 0.105815 loss)
I0906 05:07:38.012435 90901 sgd_solver.cpp:106] Iteration 82260, lr = 0.001
I0906 05:07:45.545436 90901 solver.cpp:228] Iteration 82270, loss = 0.0720457
I0906 05:07:45.545675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0720467 (* 1 = 0.0720467 loss)
I0906 05:07:45.545697 90901 sgd_solver.cpp:106] Iteration 82270, lr = 0.001
I0906 05:07:53.844141 90901 solver.cpp:228] Iteration 82280, loss = 0.0263299
I0906 05:07:53.844213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.026331 (* 1 = 0.026331 loss)
I0906 05:07:53.844233 90901 sgd_solver.cpp:106] Iteration 82280, lr = 0.001
I0906 05:08:03.274646 90901 solver.cpp:228] Iteration 82290, loss = 0.0611957
I0906 05:08:03.274765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0611968 (* 1 = 0.0611968 loss)
I0906 05:08:03.274785 90901 sgd_solver.cpp:106] Iteration 82290, lr = 0.001
I0906 05:08:10.607270 90901 solver.cpp:228] Iteration 82300, loss = 0.166274
I0906 05:08:10.607362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166275 (* 1 = 0.166275 loss)
I0906 05:08:10.607380 90901 sgd_solver.cpp:106] Iteration 82300, lr = 0.001
I0906 05:08:19.667544 90901 solver.cpp:228] Iteration 82310, loss = 0.0280096
I0906 05:08:19.667696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0280106 (* 1 = 0.0280106 loss)
I0906 05:08:19.667726 90901 sgd_solver.cpp:106] Iteration 82310, lr = 0.001
I0906 05:08:28.445077 90901 solver.cpp:228] Iteration 82320, loss = 0.0606908
I0906 05:08:28.445157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0606918 (* 1 = 0.0606918 loss)
I0906 05:08:28.445175 90901 sgd_solver.cpp:106] Iteration 82320, lr = 0.001
I0906 05:08:37.477126 90901 solver.cpp:228] Iteration 82330, loss = 0.0977125
I0906 05:08:37.477191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0977136 (* 1 = 0.0977136 loss)
I0906 05:08:37.477208 90901 sgd_solver.cpp:106] Iteration 82330, lr = 0.001
I0906 05:08:45.338270 90901 solver.cpp:228] Iteration 82340, loss = 0.169718
I0906 05:08:45.338397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169719 (* 1 = 0.169719 loss)
I0906 05:08:45.338420 90901 sgd_solver.cpp:106] Iteration 82340, lr = 0.001
I0906 05:08:54.183969 90901 solver.cpp:228] Iteration 82350, loss = 0.424675
I0906 05:08:54.184119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.424676 (* 1 = 0.424676 loss)
I0906 05:08:54.184151 90901 sgd_solver.cpp:106] Iteration 82350, lr = 0.001
I0906 05:09:02.816189 90901 solver.cpp:228] Iteration 82360, loss = 0.118976
I0906 05:09:02.816252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118977 (* 1 = 0.118977 loss)
I0906 05:09:02.816270 90901 sgd_solver.cpp:106] Iteration 82360, lr = 0.001
I0906 05:09:10.303586 90901 solver.cpp:228] Iteration 82370, loss = 0.207962
I0906 05:09:10.303673 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207963 (* 1 = 0.207963 loss)
I0906 05:09:10.303691 90901 sgd_solver.cpp:106] Iteration 82370, lr = 0.001
I0906 05:09:17.957170 90901 solver.cpp:228] Iteration 82380, loss = 0.398897
I0906 05:09:17.957228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.398898 (* 1 = 0.398898 loss)
I0906 05:09:17.957245 90901 sgd_solver.cpp:106] Iteration 82380, lr = 0.001
I0906 05:09:26.823317 90901 solver.cpp:228] Iteration 82390, loss = 0.0696931
I0906 05:09:26.823487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0696942 (* 1 = 0.0696942 loss)
I0906 05:09:26.823505 90901 sgd_solver.cpp:106] Iteration 82390, lr = 0.001
I0906 05:09:34.877823 90901 solver.cpp:337] Iteration 82400, Testing net (#0)
I0906 05:10:33.727355 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.94625
I0906 05:10:33.727529 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.132613 (* 1 = 0.132613 loss)
I0906 05:10:34.188361 90901 solver.cpp:228] Iteration 82400, loss = 0.110305
I0906 05:10:34.188436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110306 (* 1 = 0.110306 loss)
I0906 05:10:34.188460 90901 sgd_solver.cpp:106] Iteration 82400, lr = 0.001
I0906 05:10:42.022296 90901 solver.cpp:228] Iteration 82410, loss = 0.0732955
I0906 05:10:42.022423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0732967 (* 1 = 0.0732967 loss)
I0906 05:10:42.022445 90901 sgd_solver.cpp:106] Iteration 82410, lr = 0.001
I0906 05:10:50.895869 90901 solver.cpp:228] Iteration 82420, loss = 0.190818
I0906 05:10:50.895944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190819 (* 1 = 0.190819 loss)
I0906 05:10:50.895963 90901 sgd_solver.cpp:106] Iteration 82420, lr = 0.001
I0906 05:10:59.745213 90901 solver.cpp:228] Iteration 82430, loss = 0.113697
I0906 05:10:59.745280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113698 (* 1 = 0.113698 loss)
I0906 05:10:59.745296 90901 sgd_solver.cpp:106] Iteration 82430, lr = 0.001
I0906 05:11:08.112807 90901 solver.cpp:228] Iteration 82440, loss = 0.551015
I0906 05:11:08.113150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.551016 (* 1 = 0.551016 loss)
I0906 05:11:08.113173 90901 sgd_solver.cpp:106] Iteration 82440, lr = 0.001
I0906 05:11:16.037878 90901 solver.cpp:228] Iteration 82450, loss = 0.202491
I0906 05:11:16.037955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202492 (* 1 = 0.202492 loss)
I0906 05:11:16.037971 90901 sgd_solver.cpp:106] Iteration 82450, lr = 0.001
I0906 05:11:24.818508 90901 solver.cpp:228] Iteration 82460, loss = 0.467792
I0906 05:11:24.818584 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467793 (* 1 = 0.467793 loss)
I0906 05:11:24.818605 90901 sgd_solver.cpp:106] Iteration 82460, lr = 0.001
I0906 05:11:33.698289 90901 solver.cpp:228] Iteration 82470, loss = 0.13772
I0906 05:11:33.698353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137721 (* 1 = 0.137721 loss)
I0906 05:11:33.698369 90901 sgd_solver.cpp:106] Iteration 82470, lr = 0.001
I0906 05:11:41.365533 90901 solver.cpp:228] Iteration 82480, loss = 0.127024
I0906 05:11:41.365687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127025 (* 1 = 0.127025 loss)
I0906 05:11:41.365706 90901 sgd_solver.cpp:106] Iteration 82480, lr = 0.001
I0906 05:11:50.165841 90901 solver.cpp:228] Iteration 82490, loss = 0.110415
I0906 05:11:50.165992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110416 (* 1 = 0.110416 loss)
I0906 05:11:50.166018 90901 sgd_solver.cpp:106] Iteration 82490, lr = 0.001
I0906 05:11:59.026314 90901 solver.cpp:228] Iteration 82500, loss = 0.232253
I0906 05:11:59.026377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232254 (* 1 = 0.232254 loss)
I0906 05:11:59.026394 90901 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I0906 05:12:07.626566 90901 solver.cpp:228] Iteration 82510, loss = 0.368088
I0906 05:12:07.626667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368089 (* 1 = 0.368089 loss)
I0906 05:12:07.626685 90901 sgd_solver.cpp:106] Iteration 82510, lr = 0.001
I0906 05:12:15.357931 90901 solver.cpp:228] Iteration 82520, loss = 0.131541
I0906 05:12:15.358131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131542 (* 1 = 0.131542 loss)
I0906 05:12:15.358165 90901 sgd_solver.cpp:106] Iteration 82520, lr = 0.001
I0906 05:12:23.668632 90901 solver.cpp:228] Iteration 82530, loss = 0.1005
I0906 05:12:23.668710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100501 (* 1 = 0.100501 loss)
I0906 05:12:23.668730 90901 sgd_solver.cpp:106] Iteration 82530, lr = 0.001
I0906 05:12:32.539048 90901 solver.cpp:228] Iteration 82540, loss = 0.0996462
I0906 05:12:32.539125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0996472 (* 1 = 0.0996472 loss)
I0906 05:12:32.539144 90901 sgd_solver.cpp:106] Iteration 82540, lr = 0.001
I0906 05:12:40.156322 90901 solver.cpp:228] Iteration 82550, loss = 0.237981
I0906 05:12:40.156436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237982 (* 1 = 0.237982 loss)
I0906 05:12:40.156457 90901 sgd_solver.cpp:106] Iteration 82550, lr = 0.001
I0906 05:12:48.714334 90901 solver.cpp:228] Iteration 82560, loss = 0.084168
I0906 05:12:48.714725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0841691 (* 1 = 0.0841691 loss)
I0906 05:12:48.714747 90901 sgd_solver.cpp:106] Iteration 82560, lr = 0.001
I0906 05:12:57.078862 90901 solver.cpp:228] Iteration 82570, loss = 0.0203836
I0906 05:12:57.078925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0203847 (* 1 = 0.0203847 loss)
I0906 05:12:57.078943 90901 sgd_solver.cpp:106] Iteration 82570, lr = 0.001
I0906 05:13:04.924926 90901 solver.cpp:228] Iteration 82580, loss = 0.022663
I0906 05:13:04.925004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.022664 (* 1 = 0.022664 loss)
I0906 05:13:04.925024 90901 sgd_solver.cpp:106] Iteration 82580, lr = 0.001
I0906 05:13:13.564179 90901 solver.cpp:228] Iteration 82590, loss = 0.368559
I0906 05:13:13.564337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36856 (* 1 = 0.36856 loss)
I0906 05:13:13.564369 90901 sgd_solver.cpp:106] Iteration 82590, lr = 0.001
I0906 05:13:22.148821 90901 solver.cpp:228] Iteration 82600, loss = 0.256534
I0906 05:13:22.149103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256535 (* 1 = 0.256535 loss)
I0906 05:13:22.149134 90901 sgd_solver.cpp:106] Iteration 82600, lr = 0.001
I0906 05:13:29.947540 90901 solver.cpp:228] Iteration 82610, loss = 0.0269906
I0906 05:13:29.947618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0269917 (* 1 = 0.0269917 loss)
I0906 05:13:29.947636 90901 sgd_solver.cpp:106] Iteration 82610, lr = 0.001
I0906 05:13:38.592198 90901 solver.cpp:228] Iteration 82620, loss = 0.391369
I0906 05:13:38.592296 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.391371 (* 1 = 0.391371 loss)
I0906 05:13:38.592319 90901 sgd_solver.cpp:106] Iteration 82620, lr = 0.001
I0906 05:13:47.305613 90901 solver.cpp:228] Iteration 82630, loss = 0.142728
I0906 05:13:47.305701 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142729 (* 1 = 0.142729 loss)
I0906 05:13:47.305717 90901 sgd_solver.cpp:106] Iteration 82630, lr = 0.001
I0906 05:13:55.057344 90901 solver.cpp:228] Iteration 82640, loss = 0.122199
I0906 05:13:55.057538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1222 (* 1 = 0.1222 loss)
I0906 05:13:55.057557 90901 sgd_solver.cpp:106] Iteration 82640, lr = 0.001
I0906 05:14:03.878803 90901 solver.cpp:228] Iteration 82650, loss = 0.0676955
I0906 05:14:03.878878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0676966 (* 1 = 0.0676966 loss)
I0906 05:14:03.878902 90901 sgd_solver.cpp:106] Iteration 82650, lr = 0.001
I0906 05:14:12.503247 90901 solver.cpp:228] Iteration 82660, loss = 0.0985494
I0906 05:14:12.503321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0985505 (* 1 = 0.0985505 loss)
I0906 05:14:12.503340 90901 sgd_solver.cpp:106] Iteration 82660, lr = 0.001
I0906 05:14:20.963466 90901 solver.cpp:228] Iteration 82670, loss = 0.136791
I0906 05:14:20.963630 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136793 (* 1 = 0.136793 loss)
I0906 05:14:20.963663 90901 sgd_solver.cpp:106] Iteration 82670, lr = 0.001
I0906 05:14:28.872169 90901 solver.cpp:228] Iteration 82680, loss = 0.233352
I0906 05:14:28.872432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233353 (* 1 = 0.233353 loss)
I0906 05:14:28.872452 90901 sgd_solver.cpp:106] Iteration 82680, lr = 0.001
I0906 05:14:37.541512 90901 solver.cpp:228] Iteration 82690, loss = 0.0847018
I0906 05:14:37.541599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0847029 (* 1 = 0.0847029 loss)
I0906 05:14:37.541616 90901 sgd_solver.cpp:106] Iteration 82690, lr = 0.001
I0906 05:14:46.866216 90901 solver.cpp:228] Iteration 82700, loss = 0.211166
I0906 05:14:46.866318 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211167 (* 1 = 0.211167 loss)
I0906 05:14:46.866338 90901 sgd_solver.cpp:106] Iteration 82700, lr = 0.001
I0906 05:14:54.322619 90901 solver.cpp:228] Iteration 82710, loss = 0.119096
I0906 05:14:54.322800 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119097 (* 1 = 0.119097 loss)
I0906 05:14:54.322826 90901 sgd_solver.cpp:106] Iteration 82710, lr = 0.001
I0906 05:15:02.902071 90901 solver.cpp:228] Iteration 82720, loss = 0.0918445
I0906 05:15:02.902287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0918456 (* 1 = 0.0918456 loss)
I0906 05:15:02.902305 90901 sgd_solver.cpp:106] Iteration 82720, lr = 0.001
I0906 05:15:12.290169 90901 solver.cpp:228] Iteration 82730, loss = 0.2029
I0906 05:15:12.290257 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202901 (* 1 = 0.202901 loss)
I0906 05:15:12.290274 90901 sgd_solver.cpp:106] Iteration 82730, lr = 0.001
I0906 05:15:19.804935 90901 solver.cpp:228] Iteration 82740, loss = 0.145558
I0906 05:15:19.805073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14556 (* 1 = 0.14556 loss)
I0906 05:15:19.805102 90901 sgd_solver.cpp:106] Iteration 82740, lr = 0.001
I0906 05:15:28.456385 90901 solver.cpp:228] Iteration 82750, loss = 0.242777
I0906 05:15:28.456460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242779 (* 1 = 0.242779 loss)
I0906 05:15:28.456477 90901 sgd_solver.cpp:106] Iteration 82750, lr = 0.001
I0906 05:15:37.245503 90901 solver.cpp:228] Iteration 82760, loss = 0.0580285
I0906 05:15:37.245760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0580296 (* 1 = 0.0580296 loss)
I0906 05:15:37.245782 90901 sgd_solver.cpp:106] Iteration 82760, lr = 0.001
I0906 05:15:45.882279 90901 solver.cpp:228] Iteration 82770, loss = 0.0486171
I0906 05:15:45.882386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0486182 (* 1 = 0.0486182 loss)
I0906 05:15:45.882411 90901 sgd_solver.cpp:106] Iteration 82770, lr = 0.001
I0906 05:15:53.784839 90901 solver.cpp:228] Iteration 82780, loss = 0.0849257
I0906 05:15:53.784919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0849269 (* 1 = 0.0849269 loss)
I0906 05:15:53.784940 90901 sgd_solver.cpp:106] Iteration 82780, lr = 0.001
I0906 05:16:02.499425 90901 solver.cpp:228] Iteration 82790, loss = 0.283032
I0906 05:16:02.499486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283033 (* 1 = 0.283033 loss)
I0906 05:16:02.499502 90901 sgd_solver.cpp:106] Iteration 82790, lr = 0.001
I0906 05:16:11.578987 90901 solver.cpp:228] Iteration 82800, loss = 0.228705
I0906 05:16:11.579172 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228706 (* 1 = 0.228706 loss)
I0906 05:16:11.579191 90901 sgd_solver.cpp:106] Iteration 82800, lr = 0.001
I0906 05:16:19.186120 90901 solver.cpp:228] Iteration 82810, loss = 0.107857
I0906 05:16:19.186194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107858 (* 1 = 0.107858 loss)
I0906 05:16:19.186214 90901 sgd_solver.cpp:106] Iteration 82810, lr = 0.001
I0906 05:16:27.783051 90901 solver.cpp:228] Iteration 82820, loss = 0.147445
I0906 05:16:27.783126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147446 (* 1 = 0.147446 loss)
I0906 05:16:27.783143 90901 sgd_solver.cpp:106] Iteration 82820, lr = 0.001
I0906 05:16:36.754379 90901 solver.cpp:228] Iteration 82830, loss = 0.283186
I0906 05:16:36.754474 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283187 (* 1 = 0.283187 loss)
I0906 05:16:36.754493 90901 sgd_solver.cpp:106] Iteration 82830, lr = 0.001
I0906 05:16:45.558151 90901 solver.cpp:228] Iteration 82840, loss = 0.127671
I0906 05:16:45.558331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127672 (* 1 = 0.127672 loss)
I0906 05:16:45.558357 90901 sgd_solver.cpp:106] Iteration 82840, lr = 0.001
I0906 05:16:53.797847 90901 solver.cpp:228] Iteration 82850, loss = 0.248896
I0906 05:16:53.797924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248897 (* 1 = 0.248897 loss)
I0906 05:16:53.797940 90901 sgd_solver.cpp:106] Iteration 82850, lr = 0.001
I0906 05:17:03.011193 90901 solver.cpp:228] Iteration 82860, loss = 0.0463852
I0906 05:17:03.011272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0463864 (* 1 = 0.0463864 loss)
I0906 05:17:03.011288 90901 sgd_solver.cpp:106] Iteration 82860, lr = 0.001
I0906 05:17:11.672384 90901 solver.cpp:228] Iteration 82870, loss = 0.268545
I0906 05:17:11.672469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268546 (* 1 = 0.268546 loss)
I0906 05:17:11.672487 90901 sgd_solver.cpp:106] Iteration 82870, lr = 0.001
I0906 05:17:19.224606 90901 solver.cpp:228] Iteration 82880, loss = 0.236078
I0906 05:17:19.225117 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23608 (* 1 = 0.23608 loss)
I0906 05:17:19.225153 90901 sgd_solver.cpp:106] Iteration 82880, lr = 0.001
I0906 05:17:27.347719 90901 solver.cpp:228] Iteration 82890, loss = 0.193905
I0906 05:17:27.347792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193906 (* 1 = 0.193906 loss)
I0906 05:17:27.347810 90901 sgd_solver.cpp:106] Iteration 82890, lr = 0.001
I0906 05:17:35.586321 90901 solver.cpp:228] Iteration 82900, loss = 0.0108369
I0906 05:17:35.586423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0108381 (* 1 = 0.0108381 loss)
I0906 05:17:35.586442 90901 sgd_solver.cpp:106] Iteration 82900, lr = 0.001
I0906 05:17:43.703305 90901 solver.cpp:228] Iteration 82910, loss = 0.613113
I0906 05:17:43.703415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.613114 (* 1 = 0.613114 loss)
I0906 05:17:43.703434 90901 sgd_solver.cpp:106] Iteration 82910, lr = 0.001
I0906 05:17:51.974354 90901 solver.cpp:228] Iteration 82920, loss = 0.105199
I0906 05:17:51.974510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1052 (* 1 = 0.1052 loss)
I0906 05:17:51.974529 90901 sgd_solver.cpp:106] Iteration 82920, lr = 0.001
I0906 05:17:59.598757 90901 solver.cpp:228] Iteration 82930, loss = 0.0241413
I0906 05:17:59.598816 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0241425 (* 1 = 0.0241425 loss)
I0906 05:17:59.598834 90901 sgd_solver.cpp:106] Iteration 82930, lr = 0.001
I0906 05:18:06.572628 90901 solver.cpp:228] Iteration 82940, loss = 0.0886238
I0906 05:18:06.572767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.088625 (* 1 = 0.088625 loss)
I0906 05:18:06.572796 90901 sgd_solver.cpp:106] Iteration 82940, lr = 0.001
I0906 05:18:12.022872 90901 solver.cpp:228] Iteration 82950, loss = 0.0876299
I0906 05:18:12.022951 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0876311 (* 1 = 0.0876311 loss)
I0906 05:18:12.022967 90901 sgd_solver.cpp:106] Iteration 82950, lr = 0.001
I0906 05:18:17.224087 90901 solver.cpp:228] Iteration 82960, loss = 0.100957
I0906 05:18:17.224156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100959 (* 1 = 0.100959 loss)
I0906 05:18:17.224174 90901 sgd_solver.cpp:106] Iteration 82960, lr = 0.001
I0906 05:18:22.149951 90901 solver.cpp:228] Iteration 82970, loss = 0.108533
I0906 05:18:22.150092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108534 (* 1 = 0.108534 loss)
I0906 05:18:22.150113 90901 sgd_solver.cpp:106] Iteration 82970, lr = 0.001
I0906 05:18:27.061471 90901 solver.cpp:228] Iteration 82980, loss = 0.147402
I0906 05:18:27.061556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147403 (* 1 = 0.147403 loss)
I0906 05:18:27.061576 90901 sgd_solver.cpp:106] Iteration 82980, lr = 0.001
I0906 05:18:32.377002 90901 solver.cpp:228] Iteration 82990, loss = 0.0979663
I0906 05:18:32.377084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0979676 (* 1 = 0.0979676 loss)
I0906 05:18:32.377109 90901 sgd_solver.cpp:106] Iteration 82990, lr = 0.001
I0906 05:18:37.299090 90901 solver.cpp:228] Iteration 83000, loss = 0.058527
I0906 05:18:37.299160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0585282 (* 1 = 0.0585282 loss)
I0906 05:18:37.299177 90901 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I0906 05:18:43.232348 90901 solver.cpp:228] Iteration 83010, loss = 0.249378
I0906 05:18:43.232424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.249379 (* 1 = 0.249379 loss)
I0906 05:18:43.232442 90901 sgd_solver.cpp:106] Iteration 83010, lr = 0.001
I0906 05:18:48.149718 90901 solver.cpp:228] Iteration 83020, loss = 0.194862
I0906 05:18:48.149787 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194863 (* 1 = 0.194863 loss)
I0906 05:18:48.149806 90901 sgd_solver.cpp:106] Iteration 83020, lr = 0.001
I0906 05:18:53.081903 90901 solver.cpp:228] Iteration 83030, loss = 0.454429
I0906 05:18:53.082165 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45443 (* 1 = 0.45443 loss)
I0906 05:18:53.082185 90901 sgd_solver.cpp:106] Iteration 83030, lr = 0.001
I0906 05:18:57.987782 90901 solver.cpp:228] Iteration 83040, loss = 0.201666
I0906 05:18:57.987854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201668 (* 1 = 0.201668 loss)
I0906 05:18:57.987869 90901 sgd_solver.cpp:106] Iteration 83040, lr = 0.001
I0906 05:19:02.939853 90901 solver.cpp:228] Iteration 83050, loss = 0.26671
I0906 05:19:02.939968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266711 (* 1 = 0.266711 loss)
I0906 05:19:02.939996 90901 sgd_solver.cpp:106] Iteration 83050, lr = 0.001
I0906 05:19:07.857038 90901 solver.cpp:228] Iteration 83060, loss = 0.278965
I0906 05:19:07.857105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278966 (* 1 = 0.278966 loss)
I0906 05:19:07.857123 90901 sgd_solver.cpp:106] Iteration 83060, lr = 0.001
I0906 05:19:12.778801 90901 solver.cpp:228] Iteration 83070, loss = 0.0828779
I0906 05:19:12.778885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0828792 (* 1 = 0.0828792 loss)
I0906 05:19:12.778903 90901 sgd_solver.cpp:106] Iteration 83070, lr = 0.001
I0906 05:19:17.718385 90901 solver.cpp:228] Iteration 83080, loss = 0.0883963
I0906 05:19:17.718571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0883976 (* 1 = 0.0883976 loss)
I0906 05:19:17.718600 90901 sgd_solver.cpp:106] Iteration 83080, lr = 0.001
I0906 05:19:22.682593 90901 solver.cpp:228] Iteration 83090, loss = 0.0978339
I0906 05:19:22.682729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0978351 (* 1 = 0.0978351 loss)
I0906 05:19:22.682749 90901 sgd_solver.cpp:106] Iteration 83090, lr = 0.001
I0906 05:19:27.930341 90901 solver.cpp:228] Iteration 83100, loss = 0.0392606
I0906 05:19:27.930502 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0392619 (* 1 = 0.0392619 loss)
I0906 05:19:27.930521 90901 sgd_solver.cpp:106] Iteration 83100, lr = 0.001
I0906 05:19:33.156677 90901 solver.cpp:228] Iteration 83110, loss = 0.268551
I0906 05:19:33.156744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268552 (* 1 = 0.268552 loss)
I0906 05:19:33.156760 90901 sgd_solver.cpp:106] Iteration 83110, lr = 0.001
I0906 05:19:38.368549 90901 solver.cpp:228] Iteration 83120, loss = 0.0458499
I0906 05:19:38.368620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0458512 (* 1 = 0.0458512 loss)
I0906 05:19:38.368638 90901 sgd_solver.cpp:106] Iteration 83120, lr = 0.001
I0906 05:19:45.704761 90901 solver.cpp:228] Iteration 83130, loss = 0.136292
I0906 05:19:45.704848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136294 (* 1 = 0.136294 loss)
I0906 05:19:45.704867 90901 sgd_solver.cpp:106] Iteration 83130, lr = 0.001
I0906 05:19:53.649608 90901 solver.cpp:228] Iteration 83140, loss = 0.0645447
I0906 05:19:53.649672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0645459 (* 1 = 0.0645459 loss)
I0906 05:19:53.649688 90901 sgd_solver.cpp:106] Iteration 83140, lr = 0.001
I0906 05:20:01.934185 90901 solver.cpp:228] Iteration 83150, loss = 0.114578
I0906 05:20:01.934386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114579 (* 1 = 0.114579 loss)
I0906 05:20:01.934408 90901 sgd_solver.cpp:106] Iteration 83150, lr = 0.001
I0906 05:20:09.855984 90901 solver.cpp:228] Iteration 83160, loss = 0.220711
I0906 05:20:09.856132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220712 (* 1 = 0.220712 loss)
I0906 05:20:09.856154 90901 sgd_solver.cpp:106] Iteration 83160, lr = 0.001
I0906 05:20:18.149122 90901 solver.cpp:228] Iteration 83170, loss = 0.0797357
I0906 05:20:18.149189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0797369 (* 1 = 0.0797369 loss)
I0906 05:20:18.149205 90901 sgd_solver.cpp:106] Iteration 83170, lr = 0.001
I0906 05:20:25.859421 90901 solver.cpp:228] Iteration 83180, loss = 0.881854
I0906 05:20:25.859593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.881855 (* 1 = 0.881855 loss)
I0906 05:20:25.859622 90901 sgd_solver.cpp:106] Iteration 83180, lr = 0.001
I0906 05:20:33.978255 90901 solver.cpp:228] Iteration 83190, loss = 0.0863823
I0906 05:20:33.978413 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0863835 (* 1 = 0.0863835 loss)
I0906 05:20:33.978433 90901 sgd_solver.cpp:106] Iteration 83190, lr = 0.001
I0906 05:20:41.878053 90901 solver.cpp:337] Iteration 83200, Testing net (#0)
I0906 05:21:40.448326 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9375
I0906 05:21:40.448462 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.164163 (* 1 = 0.164163 loss)
I0906 05:21:40.736995 90901 solver.cpp:228] Iteration 83200, loss = 0.0647027
I0906 05:21:40.737062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0647039 (* 1 = 0.0647039 loss)
I0906 05:21:40.737085 90901 sgd_solver.cpp:106] Iteration 83200, lr = 0.001
I0906 05:21:48.851392 90901 solver.cpp:228] Iteration 83210, loss = 0.0635937
I0906 05:21:48.851454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0635949 (* 1 = 0.0635949 loss)
I0906 05:21:48.851476 90901 sgd_solver.cpp:106] Iteration 83210, lr = 0.001
I0906 05:21:57.543737 90901 solver.cpp:228] Iteration 83220, loss = 0.255372
I0906 05:21:57.543881 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255374 (* 1 = 0.255374 loss)
I0906 05:21:57.543905 90901 sgd_solver.cpp:106] Iteration 83220, lr = 0.001
I0906 05:22:05.765581 90901 solver.cpp:228] Iteration 83230, loss = 0.16175
I0906 05:22:05.765707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161751 (* 1 = 0.161751 loss)
I0906 05:22:05.765727 90901 sgd_solver.cpp:106] Iteration 83230, lr = 0.001
I0906 05:22:14.621476 90901 solver.cpp:228] Iteration 83240, loss = 0.0855556
I0906 05:22:14.621745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0855568 (* 1 = 0.0855568 loss)
I0906 05:22:14.621778 90901 sgd_solver.cpp:106] Iteration 83240, lr = 0.001
I0906 05:22:23.307173 90901 solver.cpp:228] Iteration 83250, loss = 0.243507
I0906 05:22:23.307265 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243508 (* 1 = 0.243508 loss)
I0906 05:22:23.307286 90901 sgd_solver.cpp:106] Iteration 83250, lr = 0.001
I0906 05:22:31.940340 90901 solver.cpp:228] Iteration 83260, loss = 0.090856
I0906 05:22:31.940407 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0908572 (* 1 = 0.0908572 loss)
I0906 05:22:31.940424 90901 sgd_solver.cpp:106] Iteration 83260, lr = 0.001
I0906 05:22:40.638084 90901 solver.cpp:228] Iteration 83270, loss = 0.0486989
I0906 05:22:40.638170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0487001 (* 1 = 0.0487001 loss)
I0906 05:22:40.638191 90901 sgd_solver.cpp:106] Iteration 83270, lr = 0.001
I0906 05:22:49.487311 90901 solver.cpp:228] Iteration 83280, loss = 0.0920817
I0906 05:22:49.487486 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0920829 (* 1 = 0.0920829 loss)
I0906 05:22:49.487506 90901 sgd_solver.cpp:106] Iteration 83280, lr = 0.001
I0906 05:22:58.192090 90901 solver.cpp:228] Iteration 83290, loss = 0.19207
I0906 05:22:58.192163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192072 (* 1 = 0.192072 loss)
I0906 05:22:58.192186 90901 sgd_solver.cpp:106] Iteration 83290, lr = 0.001
I0906 05:23:07.086717 90901 solver.cpp:228] Iteration 83300, loss = 0.0457008
I0906 05:23:07.086781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.045702 (* 1 = 0.045702 loss)
I0906 05:23:07.086798 90901 sgd_solver.cpp:106] Iteration 83300, lr = 0.001
I0906 05:23:15.825158 90901 solver.cpp:228] Iteration 83310, loss = 0.0532739
I0906 05:23:15.825232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0532751 (* 1 = 0.0532751 loss)
I0906 05:23:15.825254 90901 sgd_solver.cpp:106] Iteration 83310, lr = 0.001
I0906 05:23:24.472167 90901 solver.cpp:228] Iteration 83320, loss = 0.0967776
I0906 05:23:24.472472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0967788 (* 1 = 0.0967788 loss)
I0906 05:23:24.472501 90901 sgd_solver.cpp:106] Iteration 83320, lr = 0.001
I0906 05:23:33.113445 90901 solver.cpp:228] Iteration 83330, loss = 0.172194
I0906 05:23:33.113620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172195 (* 1 = 0.172195 loss)
I0906 05:23:33.113673 90901 sgd_solver.cpp:106] Iteration 83330, lr = 0.001
I0906 05:23:41.805171 90901 solver.cpp:228] Iteration 83340, loss = 0.0344969
I0906 05:23:41.805275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0344981 (* 1 = 0.0344981 loss)
I0906 05:23:41.805294 90901 sgd_solver.cpp:106] Iteration 83340, lr = 0.001
I0906 05:23:50.714587 90901 solver.cpp:228] Iteration 83350, loss = 0.136915
I0906 05:23:50.714682 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136916 (* 1 = 0.136916 loss)
I0906 05:23:50.714706 90901 sgd_solver.cpp:106] Iteration 83350, lr = 0.001
I0906 05:23:59.393932 90901 solver.cpp:228] Iteration 83360, loss = 0.212602
I0906 05:23:59.394276 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.212603 (* 1 = 0.212603 loss)
I0906 05:23:59.394300 90901 sgd_solver.cpp:106] Iteration 83360, lr = 0.001
I0906 05:24:08.309880 90901 solver.cpp:228] Iteration 83370, loss = 0.0765066
I0906 05:24:08.309949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0765078 (* 1 = 0.0765078 loss)
I0906 05:24:08.309973 90901 sgd_solver.cpp:106] Iteration 83370, lr = 0.001
I0906 05:24:17.612875 90901 solver.cpp:228] Iteration 83380, loss = 0.293385
I0906 05:24:17.612959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293386 (* 1 = 0.293386 loss)
I0906 05:24:17.612982 90901 sgd_solver.cpp:106] Iteration 83380, lr = 0.001
I0906 05:24:26.948645 90901 solver.cpp:228] Iteration 83390, loss = 0.164315
I0906 05:24:26.948724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164317 (* 1 = 0.164317 loss)
I0906 05:24:26.948746 90901 sgd_solver.cpp:106] Iteration 83390, lr = 0.001
I0906 05:24:36.886319 90901 solver.cpp:228] Iteration 83400, loss = 0.168763
I0906 05:24:36.886476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168764 (* 1 = 0.168764 loss)
I0906 05:24:36.886498 90901 sgd_solver.cpp:106] Iteration 83400, lr = 0.001
I0906 05:24:45.966665 90901 solver.cpp:228] Iteration 83410, loss = 0.16864
I0906 05:24:45.966747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168641 (* 1 = 0.168641 loss)
I0906 05:24:45.966778 90901 sgd_solver.cpp:106] Iteration 83410, lr = 0.001
I0906 05:24:55.677114 90901 solver.cpp:228] Iteration 83420, loss = 0.148049
I0906 05:24:55.677192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148051 (* 1 = 0.148051 loss)
I0906 05:24:55.677214 90901 sgd_solver.cpp:106] Iteration 83420, lr = 0.001
I0906 05:25:04.630100 90901 solver.cpp:228] Iteration 83430, loss = 0.504282
I0906 05:25:04.630168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504284 (* 1 = 0.504284 loss)
I0906 05:25:04.630190 90901 sgd_solver.cpp:106] Iteration 83430, lr = 0.001
I0906 05:25:13.561399 90901 solver.cpp:228] Iteration 83440, loss = 0.0369333
I0906 05:25:13.561616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0369346 (* 1 = 0.0369346 loss)
I0906 05:25:13.561636 90901 sgd_solver.cpp:106] Iteration 83440, lr = 0.001
I0906 05:25:22.341697 90901 solver.cpp:228] Iteration 83450, loss = 0.271318
I0906 05:25:22.341764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271319 (* 1 = 0.271319 loss)
I0906 05:25:22.341781 90901 sgd_solver.cpp:106] Iteration 83450, lr = 0.001
I0906 05:25:31.464171 90901 solver.cpp:228] Iteration 83460, loss = 0.280484
I0906 05:25:31.464295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280486 (* 1 = 0.280486 loss)
I0906 05:25:31.464316 90901 sgd_solver.cpp:106] Iteration 83460, lr = 0.001
I0906 05:25:40.346504 90901 solver.cpp:228] Iteration 83470, loss = 0.19507
I0906 05:25:40.346590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195071 (* 1 = 0.195071 loss)
I0906 05:25:40.346607 90901 sgd_solver.cpp:106] Iteration 83470, lr = 0.001
I0906 05:25:49.289124 90901 solver.cpp:228] Iteration 83480, loss = 0.263151
I0906 05:25:49.289321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263152 (* 1 = 0.263152 loss)
I0906 05:25:49.289340 90901 sgd_solver.cpp:106] Iteration 83480, lr = 0.001
I0906 05:25:58.172173 90901 solver.cpp:228] Iteration 83490, loss = 0.139044
I0906 05:25:58.172237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139045 (* 1 = 0.139045 loss)
I0906 05:25:58.172255 90901 sgd_solver.cpp:106] Iteration 83490, lr = 0.001
I0906 05:26:07.072674 90901 solver.cpp:228] Iteration 83500, loss = 0.229258
I0906 05:26:07.072806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229259 (* 1 = 0.229259 loss)
I0906 05:26:07.072829 90901 sgd_solver.cpp:106] Iteration 83500, lr = 0.001
I0906 05:26:15.759970 90901 solver.cpp:228] Iteration 83510, loss = 0.194253
I0906 05:26:15.760038 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194255 (* 1 = 0.194255 loss)
I0906 05:26:15.760057 90901 sgd_solver.cpp:106] Iteration 83510, lr = 0.001
I0906 05:26:24.874624 90901 solver.cpp:228] Iteration 83520, loss = 0.0518992
I0906 05:26:24.874855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0519003 (* 1 = 0.0519003 loss)
I0906 05:26:24.874876 90901 sgd_solver.cpp:106] Iteration 83520, lr = 0.001
I0906 05:26:33.173920 90901 solver.cpp:228] Iteration 83530, loss = 0.0886437
I0906 05:26:33.173996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0886448 (* 1 = 0.0886448 loss)
I0906 05:26:33.174017 90901 sgd_solver.cpp:106] Iteration 83530, lr = 0.001
I0906 05:26:41.899757 90901 solver.cpp:228] Iteration 83540, loss = 0.0793732
I0906 05:26:41.899840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0793744 (* 1 = 0.0793744 loss)
I0906 05:26:41.899862 90901 sgd_solver.cpp:106] Iteration 83540, lr = 0.001
I0906 05:26:49.867063 90901 solver.cpp:228] Iteration 83550, loss = 0.0827812
I0906 05:26:49.867123 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0827824 (* 1 = 0.0827824 loss)
I0906 05:26:49.867141 90901 sgd_solver.cpp:106] Iteration 83550, lr = 0.001
I0906 05:26:57.112921 90901 solver.cpp:228] Iteration 83560, loss = 0.200415
I0906 05:26:57.113085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200416 (* 1 = 0.200416 loss)
I0906 05:26:57.113104 90901 sgd_solver.cpp:106] Iteration 83560, lr = 0.001
I0906 05:27:02.333089 90901 solver.cpp:228] Iteration 83570, loss = 0.240868
I0906 05:27:02.333200 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240869 (* 1 = 0.240869 loss)
I0906 05:27:02.333220 90901 sgd_solver.cpp:106] Iteration 83570, lr = 0.001
I0906 05:27:07.556977 90901 solver.cpp:228] Iteration 83580, loss = 0.114452
I0906 05:27:07.557054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114454 (* 1 = 0.114454 loss)
I0906 05:27:07.557072 90901 sgd_solver.cpp:106] Iteration 83580, lr = 0.001
I0906 05:27:12.794867 90901 solver.cpp:228] Iteration 83590, loss = 0.049328
I0906 05:27:12.795084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0493292 (* 1 = 0.0493292 loss)
I0906 05:27:12.795106 90901 sgd_solver.cpp:106] Iteration 83590, lr = 0.001
I0906 05:27:19.900619 90901 solver.cpp:228] Iteration 83600, loss = 0.059652
I0906 05:27:19.900718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596531 (* 1 = 0.0596531 loss)
I0906 05:27:19.900741 90901 sgd_solver.cpp:106] Iteration 83600, lr = 0.001
I0906 05:27:27.776736 90901 solver.cpp:228] Iteration 83610, loss = 0.146371
I0906 05:27:27.776962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146372 (* 1 = 0.146372 loss)
I0906 05:27:27.776980 90901 sgd_solver.cpp:106] Iteration 83610, lr = 0.001
I0906 05:27:36.176460 90901 solver.cpp:228] Iteration 83620, loss = 0.252842
I0906 05:27:36.176525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252843 (* 1 = 0.252843 loss)
I0906 05:27:36.176544 90901 sgd_solver.cpp:106] Iteration 83620, lr = 0.001
I0906 05:27:44.732127 90901 solver.cpp:228] Iteration 83630, loss = 0.101048
I0906 05:27:44.732203 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101049 (* 1 = 0.101049 loss)
I0906 05:27:44.732219 90901 sgd_solver.cpp:106] Iteration 83630, lr = 0.001
I0906 05:27:53.379015 90901 solver.cpp:228] Iteration 83640, loss = 0.163768
I0906 05:27:53.379099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163769 (* 1 = 0.163769 loss)
I0906 05:27:53.379127 90901 sgd_solver.cpp:106] Iteration 83640, lr = 0.001
I0906 05:28:02.044463 90901 solver.cpp:228] Iteration 83650, loss = 0.515881
I0906 05:28:02.044607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.515882 (* 1 = 0.515882 loss)
I0906 05:28:02.044636 90901 sgd_solver.cpp:106] Iteration 83650, lr = 0.001
I0906 05:28:10.658618 90901 solver.cpp:228] Iteration 83660, loss = 0.0934327
I0906 05:28:10.658704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0934338 (* 1 = 0.0934338 loss)
I0906 05:28:10.658723 90901 sgd_solver.cpp:106] Iteration 83660, lr = 0.001
I0906 05:28:19.270900 90901 solver.cpp:228] Iteration 83670, loss = 0.0566706
I0906 05:28:19.270977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0566717 (* 1 = 0.0566717 loss)
I0906 05:28:19.270995 90901 sgd_solver.cpp:106] Iteration 83670, lr = 0.001
I0906 05:28:27.336727 90901 solver.cpp:228] Iteration 83680, loss = 0.0915124
I0906 05:28:27.336818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0915135 (* 1 = 0.0915135 loss)
I0906 05:28:27.336838 90901 sgd_solver.cpp:106] Iteration 83680, lr = 0.001
I0906 05:28:35.960537 90901 solver.cpp:228] Iteration 83690, loss = 0.166778
I0906 05:28:35.960829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16678 (* 1 = 0.16678 loss)
I0906 05:28:35.960850 90901 sgd_solver.cpp:106] Iteration 83690, lr = 0.001
I0906 05:28:44.191730 90901 solver.cpp:228] Iteration 83700, loss = 0.324468
I0906 05:28:44.191788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324469 (* 1 = 0.324469 loss)
I0906 05:28:44.191803 90901 sgd_solver.cpp:106] Iteration 83700, lr = 0.001
I0906 05:28:52.572747 90901 solver.cpp:228] Iteration 83710, loss = 0.201221
I0906 05:28:52.572803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201222 (* 1 = 0.201222 loss)
I0906 05:28:52.572823 90901 sgd_solver.cpp:106] Iteration 83710, lr = 0.001
I0906 05:29:00.679256 90901 solver.cpp:228] Iteration 83720, loss = 0.147783
I0906 05:29:00.679316 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147784 (* 1 = 0.147784 loss)
I0906 05:29:00.679337 90901 sgd_solver.cpp:106] Iteration 83720, lr = 0.001
I0906 05:29:08.751934 90901 solver.cpp:228] Iteration 83730, loss = 0.582941
I0906 05:29:08.752142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.582942 (* 1 = 0.582942 loss)
I0906 05:29:08.752176 90901 sgd_solver.cpp:106] Iteration 83730, lr = 0.001
I0906 05:29:16.850201 90901 solver.cpp:228] Iteration 83740, loss = 0.0594639
I0906 05:29:16.850283 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0594649 (* 1 = 0.0594649 loss)
I0906 05:29:16.850304 90901 sgd_solver.cpp:106] Iteration 83740, lr = 0.001
I0906 05:29:25.194963 90901 solver.cpp:228] Iteration 83750, loss = 0.152089
I0906 05:29:25.195047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15209 (* 1 = 0.15209 loss)
I0906 05:29:25.195063 90901 sgd_solver.cpp:106] Iteration 83750, lr = 0.001
I0906 05:29:33.911674 90901 solver.cpp:228] Iteration 83760, loss = 0.346229
I0906 05:29:33.911743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346231 (* 1 = 0.346231 loss)
I0906 05:29:33.911763 90901 sgd_solver.cpp:106] Iteration 83760, lr = 0.001
I0906 05:29:41.889963 90901 solver.cpp:228] Iteration 83770, loss = 0.0942228
I0906 05:29:41.890398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0942239 (* 1 = 0.0942239 loss)
I0906 05:29:41.890422 90901 sgd_solver.cpp:106] Iteration 83770, lr = 0.001
I0906 05:29:50.513870 90901 solver.cpp:228] Iteration 83780, loss = 0.149732
I0906 05:29:50.513943 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149733 (* 1 = 0.149733 loss)
I0906 05:29:50.513960 90901 sgd_solver.cpp:106] Iteration 83780, lr = 0.001
I0906 05:29:59.657626 90901 solver.cpp:228] Iteration 83790, loss = 0.283217
I0906 05:29:59.657685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283218 (* 1 = 0.283218 loss)
I0906 05:29:59.657701 90901 sgd_solver.cpp:106] Iteration 83790, lr = 0.001
I0906 05:30:08.230533 90901 solver.cpp:228] Iteration 83800, loss = 0.0630473
I0906 05:30:08.230599 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0630484 (* 1 = 0.0630484 loss)
I0906 05:30:08.230618 90901 sgd_solver.cpp:106] Iteration 83800, lr = 0.001
I0906 05:30:16.917680 90901 solver.cpp:228] Iteration 83810, loss = 0.239978
I0906 05:30:16.926743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239979 (* 1 = 0.239979 loss)
I0906 05:30:16.926789 90901 sgd_solver.cpp:106] Iteration 83810, lr = 0.001
I0906 05:30:25.600236 90901 solver.cpp:228] Iteration 83820, loss = 0.0954288
I0906 05:30:25.600297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0954299 (* 1 = 0.0954299 loss)
I0906 05:30:25.600314 90901 sgd_solver.cpp:106] Iteration 83820, lr = 0.001
I0906 05:30:34.248124 90901 solver.cpp:228] Iteration 83830, loss = 0.0594634
I0906 05:30:34.248210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0594645 (* 1 = 0.0594645 loss)
I0906 05:30:34.248227 90901 sgd_solver.cpp:106] Iteration 83830, lr = 0.001
I0906 05:30:42.876091 90901 solver.cpp:228] Iteration 83840, loss = 0.211839
I0906 05:30:42.876211 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21184 (* 1 = 0.21184 loss)
I0906 05:30:42.876236 90901 sgd_solver.cpp:106] Iteration 83840, lr = 0.001
I0906 05:30:51.505306 90901 solver.cpp:228] Iteration 83850, loss = 0.110441
I0906 05:30:51.505470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110442 (* 1 = 0.110442 loss)
I0906 05:30:51.505499 90901 sgd_solver.cpp:106] Iteration 83850, lr = 0.001
I0906 05:30:59.957849 90901 solver.cpp:228] Iteration 83860, loss = 0.0293765
I0906 05:30:59.957959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0293776 (* 1 = 0.0293776 loss)
I0906 05:30:59.957984 90901 sgd_solver.cpp:106] Iteration 83860, lr = 0.001
I0906 05:31:08.418226 90901 solver.cpp:228] Iteration 83870, loss = 0.0651188
I0906 05:31:08.418303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0651199 (* 1 = 0.0651199 loss)
I0906 05:31:08.418318 90901 sgd_solver.cpp:106] Iteration 83870, lr = 0.001
I0906 05:31:17.092154 90901 solver.cpp:228] Iteration 83880, loss = 0.277511
I0906 05:31:17.092221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277513 (* 1 = 0.277513 loss)
I0906 05:31:17.092239 90901 sgd_solver.cpp:106] Iteration 83880, lr = 0.001
I0906 05:31:26.033289 90901 solver.cpp:228] Iteration 83890, loss = 0.0602591
I0906 05:31:26.033529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0602602 (* 1 = 0.0602602 loss)
I0906 05:31:26.033547 90901 sgd_solver.cpp:106] Iteration 83890, lr = 0.001
I0906 05:31:34.731030 90901 solver.cpp:228] Iteration 83900, loss = 0.362397
I0906 05:31:34.731137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362398 (* 1 = 0.362398 loss)
I0906 05:31:34.731156 90901 sgd_solver.cpp:106] Iteration 83900, lr = 0.001
I0906 05:31:43.414399 90901 solver.cpp:228] Iteration 83910, loss = 0.278434
I0906 05:31:43.414516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278435 (* 1 = 0.278435 loss)
I0906 05:31:43.414536 90901 sgd_solver.cpp:106] Iteration 83910, lr = 0.001
I0906 05:31:52.327270 90901 solver.cpp:228] Iteration 83920, loss = 0.110974
I0906 05:31:52.327355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110975 (* 1 = 0.110975 loss)
I0906 05:31:52.327374 90901 sgd_solver.cpp:106] Iteration 83920, lr = 0.001
I0906 05:32:00.960800 90901 solver.cpp:228] Iteration 83930, loss = 0.187705
I0906 05:32:00.961139 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187706 (* 1 = 0.187706 loss)
I0906 05:32:00.961159 90901 sgd_solver.cpp:106] Iteration 83930, lr = 0.001
I0906 05:32:09.866969 90901 solver.cpp:228] Iteration 83940, loss = 0.164012
I0906 05:32:09.867033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164013 (* 1 = 0.164013 loss)
I0906 05:32:09.867051 90901 sgd_solver.cpp:106] Iteration 83940, lr = 0.001
I0906 05:32:18.634110 90901 solver.cpp:228] Iteration 83950, loss = 0.338769
I0906 05:32:18.634181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.33877 (* 1 = 0.33877 loss)
I0906 05:32:18.634198 90901 sgd_solver.cpp:106] Iteration 83950, lr = 0.001
I0906 05:32:27.543632 90901 solver.cpp:228] Iteration 83960, loss = 0.147635
I0906 05:32:27.543699 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147636 (* 1 = 0.147636 loss)
I0906 05:32:27.543721 90901 sgd_solver.cpp:106] Iteration 83960, lr = 0.001
I0906 05:32:36.472034 90901 solver.cpp:228] Iteration 83970, loss = 0.0860512
I0906 05:32:36.472189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0860523 (* 1 = 0.0860523 loss)
I0906 05:32:36.472219 90901 sgd_solver.cpp:106] Iteration 83970, lr = 0.001
I0906 05:32:45.341825 90901 solver.cpp:228] Iteration 83980, loss = 0.0919185
I0906 05:32:45.341889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0919195 (* 1 = 0.0919195 loss)
I0906 05:32:45.341907 90901 sgd_solver.cpp:106] Iteration 83980, lr = 0.001
I0906 05:32:54.023578 90901 solver.cpp:228] Iteration 83990, loss = 0.0696037
I0906 05:32:54.023733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0696047 (* 1 = 0.0696047 loss)
I0906 05:32:54.023766 90901 sgd_solver.cpp:106] Iteration 83990, lr = 0.001
I0906 05:33:02.409020 90901 solver.cpp:337] Iteration 84000, Testing net (#0)
I0906 05:34:03.128058 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.950938
I0906 05:34:03.128567 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.149306 (* 1 = 0.149306 loss)
I0906 05:34:03.387114 90901 solver.cpp:228] Iteration 84000, loss = 0.326052
I0906 05:34:03.387181 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.326053 (* 1 = 0.326053 loss)
I0906 05:34:03.387203 90901 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I0906 05:34:11.618892 90901 solver.cpp:228] Iteration 84010, loss = 0.104512
I0906 05:34:11.619025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104514 (* 1 = 0.104514 loss)
I0906 05:34:11.619045 90901 sgd_solver.cpp:106] Iteration 84010, lr = 0.001
I0906 05:34:20.537273 90901 solver.cpp:228] Iteration 84020, loss = 0.0297168
I0906 05:34:20.537348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0297178 (* 1 = 0.0297178 loss)
I0906 05:34:20.537365 90901 sgd_solver.cpp:106] Iteration 84020, lr = 0.001
I0906 05:34:29.170285 90901 solver.cpp:228] Iteration 84030, loss = 0.0244662
I0906 05:34:29.170351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0244672 (* 1 = 0.0244672 loss)
I0906 05:34:29.170367 90901 sgd_solver.cpp:106] Iteration 84030, lr = 0.001
I0906 05:34:36.423101 90901 solver.cpp:228] Iteration 84040, loss = 0.016991
I0906 05:34:36.423315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.016992 (* 1 = 0.016992 loss)
I0906 05:34:36.423336 90901 sgd_solver.cpp:106] Iteration 84040, lr = 0.001
I0906 05:34:42.922394 90901 solver.cpp:228] Iteration 84050, loss = 0.0787888
I0906 05:34:42.922466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0787899 (* 1 = 0.0787899 loss)
I0906 05:34:42.922482 90901 sgd_solver.cpp:106] Iteration 84050, lr = 0.001
I0906 05:34:48.123934 90901 solver.cpp:228] Iteration 84060, loss = 0.033104
I0906 05:34:48.123998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.033105 (* 1 = 0.033105 loss)
I0906 05:34:48.124017 90901 sgd_solver.cpp:106] Iteration 84060, lr = 0.001
I0906 05:34:53.330601 90901 solver.cpp:228] Iteration 84070, loss = 0.106523
I0906 05:34:53.330677 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106524 (* 1 = 0.106524 loss)
I0906 05:34:53.330698 90901 sgd_solver.cpp:106] Iteration 84070, lr = 0.001
I0906 05:34:58.865175 90901 solver.cpp:228] Iteration 84080, loss = 0.0500754
I0906 05:34:58.865254 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0500764 (* 1 = 0.0500764 loss)
I0906 05:34:58.865272 90901 sgd_solver.cpp:106] Iteration 84080, lr = 0.001
I0906 05:35:04.590785 90901 solver.cpp:228] Iteration 84090, loss = 0.148021
I0906 05:35:04.590860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148022 (* 1 = 0.148022 loss)
I0906 05:35:04.590878 90901 sgd_solver.cpp:106] Iteration 84090, lr = 0.001
I0906 05:35:11.931861 90901 solver.cpp:228] Iteration 84100, loss = 0.123211
I0906 05:35:11.932129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123212 (* 1 = 0.123212 loss)
I0906 05:35:11.932152 90901 sgd_solver.cpp:106] Iteration 84100, lr = 0.001
I0906 05:35:19.740689 90901 solver.cpp:228] Iteration 84110, loss = 0.140167
I0906 05:35:19.740772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140168 (* 1 = 0.140168 loss)
I0906 05:35:19.740797 90901 sgd_solver.cpp:106] Iteration 84110, lr = 0.001
I0906 05:35:27.618958 90901 solver.cpp:228] Iteration 84120, loss = 0.199373
I0906 05:35:27.619022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199374 (* 1 = 0.199374 loss)
I0906 05:35:27.619040 90901 sgd_solver.cpp:106] Iteration 84120, lr = 0.001
I0906 05:35:36.041697 90901 solver.cpp:228] Iteration 84130, loss = 0.357781
I0906 05:35:36.041821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.357782 (* 1 = 0.357782 loss)
I0906 05:35:36.041849 90901 sgd_solver.cpp:106] Iteration 84130, lr = 0.001
I0906 05:35:44.271823 90901 solver.cpp:228] Iteration 84140, loss = 0.343353
I0906 05:35:44.272131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343354 (* 1 = 0.343354 loss)
I0906 05:35:44.272158 90901 sgd_solver.cpp:106] Iteration 84140, lr = 0.001
I0906 05:35:53.081769 90901 solver.cpp:228] Iteration 84150, loss = 0.109955
I0906 05:35:53.081835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109956 (* 1 = 0.109956 loss)
I0906 05:35:53.081856 90901 sgd_solver.cpp:106] Iteration 84150, lr = 0.001
I0906 05:36:01.197690 90901 solver.cpp:228] Iteration 84160, loss = 0.227242
I0906 05:36:01.197757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227243 (* 1 = 0.227243 loss)
I0906 05:36:01.197772 90901 sgd_solver.cpp:106] Iteration 84160, lr = 0.001
I0906 05:36:09.057811 90901 solver.cpp:228] Iteration 84170, loss = 0.0771222
I0906 05:36:09.057899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0771232 (* 1 = 0.0771232 loss)
I0906 05:36:09.057922 90901 sgd_solver.cpp:106] Iteration 84170, lr = 0.001
I0906 05:36:16.625989 90901 solver.cpp:228] Iteration 84180, loss = 0.0464947
I0906 05:36:16.626230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0464957 (* 1 = 0.0464957 loss)
I0906 05:36:16.626248 90901 sgd_solver.cpp:106] Iteration 84180, lr = 0.001
I0906 05:36:24.408529 90901 solver.cpp:228] Iteration 84190, loss = 0.314721
I0906 05:36:24.408601 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314722 (* 1 = 0.314722 loss)
I0906 05:36:24.408619 90901 sgd_solver.cpp:106] Iteration 84190, lr = 0.001
I0906 05:36:31.810567 90901 solver.cpp:228] Iteration 84200, loss = 0.19853
I0906 05:36:31.810624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.198531 (* 1 = 0.198531 loss)
I0906 05:36:31.810652 90901 sgd_solver.cpp:106] Iteration 84200, lr = 0.001
I0906 05:36:39.903730 90901 solver.cpp:228] Iteration 84210, loss = 0.0388963
I0906 05:36:39.903846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0388973 (* 1 = 0.0388973 loss)
I0906 05:36:39.903867 90901 sgd_solver.cpp:106] Iteration 84210, lr = 0.001
I0906 05:36:48.234910 90901 solver.cpp:228] Iteration 84220, loss = 0.215508
I0906 05:36:48.235137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215509 (* 1 = 0.215509 loss)
I0906 05:36:48.235159 90901 sgd_solver.cpp:106] Iteration 84220, lr = 0.001
I0906 05:36:56.106798 90901 solver.cpp:228] Iteration 84230, loss = 0.0462287
I0906 05:36:56.106870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0462297 (* 1 = 0.0462297 loss)
I0906 05:36:56.106887 90901 sgd_solver.cpp:106] Iteration 84230, lr = 0.001
I0906 05:37:03.988039 90901 solver.cpp:228] Iteration 84240, loss = 0.0562411
I0906 05:37:03.988102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0562421 (* 1 = 0.0562421 loss)
I0906 05:37:03.988121 90901 sgd_solver.cpp:106] Iteration 84240, lr = 0.001
I0906 05:37:12.274221 90901 solver.cpp:228] Iteration 84250, loss = 0.345909
I0906 05:37:12.274289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34591 (* 1 = 0.34591 loss)
I0906 05:37:12.274305 90901 sgd_solver.cpp:106] Iteration 84250, lr = 0.001
I0906 05:37:19.050029 90901 solver.cpp:228] Iteration 84260, loss = 0.195004
I0906 05:37:19.050282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195005 (* 1 = 0.195005 loss)
I0906 05:37:19.050307 90901 sgd_solver.cpp:106] Iteration 84260, lr = 0.001
I0906 05:37:27.362794 90901 solver.cpp:228] Iteration 84270, loss = 0.195869
I0906 05:37:27.362908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19587 (* 1 = 0.19587 loss)
I0906 05:37:27.362931 90901 sgd_solver.cpp:106] Iteration 84270, lr = 0.001
I0906 05:37:36.653188 90901 solver.cpp:228] Iteration 84280, loss = 0.216374
I0906 05:37:36.653275 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216375 (* 1 = 0.216375 loss)
I0906 05:37:36.653295 90901 sgd_solver.cpp:106] Iteration 84280, lr = 0.001
I0906 05:37:45.135392 90901 solver.cpp:228] Iteration 84290, loss = 0.301213
I0906 05:37:45.135462 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301214 (* 1 = 0.301214 loss)
I0906 05:37:45.135480 90901 sgd_solver.cpp:106] Iteration 84290, lr = 0.001
I0906 05:37:54.114297 90901 solver.cpp:228] Iteration 84300, loss = 0.13566
I0906 05:37:54.114527 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135661 (* 1 = 0.135661 loss)
I0906 05:37:54.114548 90901 sgd_solver.cpp:106] Iteration 84300, lr = 0.001
I0906 05:38:02.739202 90901 solver.cpp:228] Iteration 84310, loss = 0.0828077
I0906 05:38:02.739321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0828086 (* 1 = 0.0828086 loss)
I0906 05:38:02.739341 90901 sgd_solver.cpp:106] Iteration 84310, lr = 0.001
I0906 05:38:10.959599 90901 solver.cpp:228] Iteration 84320, loss = 0.117597
I0906 05:38:10.959702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117598 (* 1 = 0.117598 loss)
I0906 05:38:10.959723 90901 sgd_solver.cpp:106] Iteration 84320, lr = 0.001
I0906 05:38:19.308017 90901 solver.cpp:228] Iteration 84330, loss = 0.0634384
I0906 05:38:19.308156 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0634393 (* 1 = 0.0634393 loss)
I0906 05:38:19.308188 90901 sgd_solver.cpp:106] Iteration 84330, lr = 0.001
I0906 05:38:27.682045 90901 solver.cpp:228] Iteration 84340, loss = 0.0677883
I0906 05:38:27.682299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0677893 (* 1 = 0.0677893 loss)
I0906 05:38:27.682319 90901 sgd_solver.cpp:106] Iteration 84340, lr = 0.001
I0906 05:38:35.894866 90901 solver.cpp:228] Iteration 84350, loss = 0.0683577
I0906 05:38:35.895081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0683586 (* 1 = 0.0683586 loss)
I0906 05:38:35.895110 90901 sgd_solver.cpp:106] Iteration 84350, lr = 0.001
I0906 05:38:43.782444 90901 solver.cpp:228] Iteration 84360, loss = 0.210798
I0906 05:38:43.782516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.210799 (* 1 = 0.210799 loss)
I0906 05:38:43.782534 90901 sgd_solver.cpp:106] Iteration 84360, lr = 0.001
I0906 05:38:51.580797 90901 solver.cpp:228] Iteration 84370, loss = 0.126927
I0906 05:38:51.580889 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126928 (* 1 = 0.126928 loss)
I0906 05:38:51.580906 90901 sgd_solver.cpp:106] Iteration 84370, lr = 0.001
I0906 05:38:57.893892 90901 solver.cpp:228] Iteration 84380, loss = 0.382667
I0906 05:38:57.894052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.382668 (* 1 = 0.382668 loss)
I0906 05:38:57.894078 90901 sgd_solver.cpp:106] Iteration 84380, lr = 0.001
I0906 05:39:03.403993 90901 solver.cpp:228] Iteration 84390, loss = 0.0877136
I0906 05:39:03.404076 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0877146 (* 1 = 0.0877146 loss)
I0906 05:39:03.404093 90901 sgd_solver.cpp:106] Iteration 84390, lr = 0.001
I0906 05:39:08.638531 90901 solver.cpp:228] Iteration 84400, loss = 0.393501
I0906 05:39:08.638623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.393502 (* 1 = 0.393502 loss)
I0906 05:39:08.638660 90901 sgd_solver.cpp:106] Iteration 84400, lr = 0.001
I0906 05:39:13.856945 90901 solver.cpp:228] Iteration 84410, loss = 0.369082
I0906 05:39:13.857025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.369083 (* 1 = 0.369083 loss)
I0906 05:39:13.857045 90901 sgd_solver.cpp:106] Iteration 84410, lr = 0.001
I0906 05:39:19.079041 90901 solver.cpp:228] Iteration 84420, loss = 0.0906832
I0906 05:39:19.079120 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0906842 (* 1 = 0.0906842 loss)
I0906 05:39:19.079138 90901 sgd_solver.cpp:106] Iteration 84420, lr = 0.001
I0906 05:39:25.110049 90901 solver.cpp:228] Iteration 84430, loss = 0.299498
I0906 05:39:25.110231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299499 (* 1 = 0.299499 loss)
I0906 05:39:25.110260 90901 sgd_solver.cpp:106] Iteration 84430, lr = 0.001
I0906 05:39:32.997539 90901 solver.cpp:228] Iteration 84440, loss = 0.0851017
I0906 05:39:32.997685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0851026 (* 1 = 0.0851026 loss)
I0906 05:39:32.997709 90901 sgd_solver.cpp:106] Iteration 84440, lr = 0.001
I0906 05:39:40.810607 90901 solver.cpp:228] Iteration 84450, loss = 0.185918
I0906 05:39:40.810679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185919 (* 1 = 0.185919 loss)
I0906 05:39:40.810696 90901 sgd_solver.cpp:106] Iteration 84450, lr = 0.001
I0906 05:39:49.427577 90901 solver.cpp:228] Iteration 84460, loss = 0.231532
I0906 05:39:49.427664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231533 (* 1 = 0.231533 loss)
I0906 05:39:49.427685 90901 sgd_solver.cpp:106] Iteration 84460, lr = 0.001
I0906 05:39:57.882652 90901 solver.cpp:228] Iteration 84470, loss = 0.274422
I0906 05:39:57.882750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274423 (* 1 = 0.274423 loss)
I0906 05:39:57.882768 90901 sgd_solver.cpp:106] Iteration 84470, lr = 0.001
I0906 05:40:06.793627 90901 solver.cpp:228] Iteration 84480, loss = 0.30192
I0906 05:40:06.793886 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.301921 (* 1 = 0.301921 loss)
I0906 05:40:06.793916 90901 sgd_solver.cpp:106] Iteration 84480, lr = 0.001
I0906 05:40:15.177121 90901 solver.cpp:228] Iteration 84490, loss = 0.110111
I0906 05:40:15.177189 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110112 (* 1 = 0.110112 loss)
I0906 05:40:15.177209 90901 sgd_solver.cpp:106] Iteration 84490, lr = 0.001
I0906 05:40:23.488811 90901 solver.cpp:228] Iteration 84500, loss = 0.0645041
I0906 05:40:23.488925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.064505 (* 1 = 0.064505 loss)
I0906 05:40:23.488947 90901 sgd_solver.cpp:106] Iteration 84500, lr = 0.001
I0906 05:40:31.363752 90901 solver.cpp:228] Iteration 84510, loss = 0.280874
I0906 05:40:31.363904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280875 (* 1 = 0.280875 loss)
I0906 05:40:31.363926 90901 sgd_solver.cpp:106] Iteration 84510, lr = 0.001
I0906 05:40:40.290212 90901 solver.cpp:228] Iteration 84520, loss = 0.100548
I0906 05:40:40.290421 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100549 (* 1 = 0.100549 loss)
I0906 05:40:40.290453 90901 sgd_solver.cpp:106] Iteration 84520, lr = 0.001
I0906 05:40:48.450959 90901 solver.cpp:228] Iteration 84530, loss = 0.12259
I0906 05:40:48.451025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122591 (* 1 = 0.122591 loss)
I0906 05:40:48.451041 90901 sgd_solver.cpp:106] Iteration 84530, lr = 0.001
I0906 05:40:57.028420 90901 solver.cpp:228] Iteration 84540, loss = 0.0749441
I0906 05:40:57.028489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.074945 (* 1 = 0.074945 loss)
I0906 05:40:57.028512 90901 sgd_solver.cpp:106] Iteration 84540, lr = 0.001
I0906 05:41:05.420344 90901 solver.cpp:228] Iteration 84550, loss = 0.0132536
I0906 05:41:05.420423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0132545 (* 1 = 0.0132545 loss)
I0906 05:41:05.420442 90901 sgd_solver.cpp:106] Iteration 84550, lr = 0.001
I0906 05:41:14.151432 90901 solver.cpp:228] Iteration 84560, loss = 0.128849
I0906 05:41:14.151664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12885 (* 1 = 0.12885 loss)
I0906 05:41:14.151705 90901 sgd_solver.cpp:106] Iteration 84560, lr = 0.001
I0906 05:41:22.713785 90901 solver.cpp:228] Iteration 84570, loss = 0.100099
I0906 05:41:22.713850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1001 (* 1 = 0.1001 loss)
I0906 05:41:22.713870 90901 sgd_solver.cpp:106] Iteration 84570, lr = 0.001
I0906 05:41:31.114593 90901 solver.cpp:228] Iteration 84580, loss = 0.121799
I0906 05:41:31.114718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1218 (* 1 = 0.1218 loss)
I0906 05:41:31.114744 90901 sgd_solver.cpp:106] Iteration 84580, lr = 0.001
I0906 05:41:39.972952 90901 solver.cpp:228] Iteration 84590, loss = 0.28505
I0906 05:41:39.973028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285051 (* 1 = 0.285051 loss)
I0906 05:41:39.973044 90901 sgd_solver.cpp:106] Iteration 84590, lr = 0.001
I0906 05:41:48.869875 90901 solver.cpp:228] Iteration 84600, loss = 0.128681
I0906 05:41:48.870121 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128682 (* 1 = 0.128682 loss)
I0906 05:41:48.870141 90901 sgd_solver.cpp:106] Iteration 84600, lr = 0.001
I0906 05:41:57.526885 90901 solver.cpp:228] Iteration 84610, loss = 0.0179185
I0906 05:41:57.526947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0179194 (* 1 = 0.0179194 loss)
I0906 05:41:57.526967 90901 sgd_solver.cpp:106] Iteration 84610, lr = 0.001
I0906 05:42:05.617283 90901 solver.cpp:228] Iteration 84620, loss = 0.187776
I0906 05:42:05.617377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187777 (* 1 = 0.187777 loss)
I0906 05:42:05.617396 90901 sgd_solver.cpp:106] Iteration 84620, lr = 0.001
I0906 05:42:14.291251 90901 solver.cpp:228] Iteration 84630, loss = 0.271347
I0906 05:42:14.291327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271348 (* 1 = 0.271348 loss)
I0906 05:42:14.291344 90901 sgd_solver.cpp:106] Iteration 84630, lr = 0.001
I0906 05:42:22.404901 90901 solver.cpp:228] Iteration 84640, loss = 0.340854
I0906 05:42:22.405144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340854 (* 1 = 0.340854 loss)
I0906 05:42:22.405164 90901 sgd_solver.cpp:106] Iteration 84640, lr = 0.001
I0906 05:42:30.039408 90901 solver.cpp:228] Iteration 84650, loss = 0.267424
I0906 05:42:30.039536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267425 (* 1 = 0.267425 loss)
I0906 05:42:30.039559 90901 sgd_solver.cpp:106] Iteration 84650, lr = 0.001
I0906 05:42:38.168941 90901 solver.cpp:228] Iteration 84660, loss = 0.333542
I0906 05:42:38.169100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.333543 (* 1 = 0.333543 loss)
I0906 05:42:38.169122 90901 sgd_solver.cpp:106] Iteration 84660, lr = 0.001
I0906 05:42:46.575196 90901 solver.cpp:228] Iteration 84670, loss = 0.650546
I0906 05:42:46.575268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.650547 (* 1 = 0.650547 loss)
I0906 05:42:46.575286 90901 sgd_solver.cpp:106] Iteration 84670, lr = 0.001
I0906 05:42:55.185972 90901 solver.cpp:228] Iteration 84680, loss = 0.196688
I0906 05:42:55.186224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196688 (* 1 = 0.196688 loss)
I0906 05:42:55.186245 90901 sgd_solver.cpp:106] Iteration 84680, lr = 0.001
I0906 05:43:03.800580 90901 solver.cpp:228] Iteration 84690, loss = 0.0989766
I0906 05:43:03.800681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0989775 (* 1 = 0.0989775 loss)
I0906 05:43:03.800703 90901 sgd_solver.cpp:106] Iteration 84690, lr = 0.001
I0906 05:43:12.149790 90901 solver.cpp:228] Iteration 84700, loss = 0.0832104
I0906 05:43:12.149885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0832113 (* 1 = 0.0832113 loss)
I0906 05:43:12.149904 90901 sgd_solver.cpp:106] Iteration 84700, lr = 0.001
I0906 05:43:18.640799 90901 solver.cpp:228] Iteration 84710, loss = 0.107905
I0906 05:43:18.640884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107906 (* 1 = 0.107906 loss)
I0906 05:43:18.640902 90901 sgd_solver.cpp:106] Iteration 84710, lr = 0.001
I0906 05:43:23.619046 90901 solver.cpp:228] Iteration 84720, loss = 0.118379
I0906 05:43:23.619148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11838 (* 1 = 0.11838 loss)
I0906 05:43:23.619165 90901 sgd_solver.cpp:106] Iteration 84720, lr = 0.001
I0906 05:43:28.792676 90901 solver.cpp:228] Iteration 84730, loss = 0.0104876
I0906 05:43:28.792868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0104885 (* 1 = 0.0104885 loss)
I0906 05:43:28.792887 90901 sgd_solver.cpp:106] Iteration 84730, lr = 0.001
I0906 05:43:35.334141 90901 solver.cpp:228] Iteration 84740, loss = 0.0608573
I0906 05:43:35.334314 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0608581 (* 1 = 0.0608581 loss)
I0906 05:43:35.334336 90901 sgd_solver.cpp:106] Iteration 84740, lr = 0.001
I0906 05:43:42.725900 90901 solver.cpp:228] Iteration 84750, loss = 0.123073
I0906 05:43:42.725972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123074 (* 1 = 0.123074 loss)
I0906 05:43:42.725989 90901 sgd_solver.cpp:106] Iteration 84750, lr = 0.001
I0906 05:43:49.554183 90901 solver.cpp:228] Iteration 84760, loss = 0.21146
I0906 05:43:49.554244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211461 (* 1 = 0.211461 loss)
I0906 05:43:49.554260 90901 sgd_solver.cpp:106] Iteration 84760, lr = 0.001
I0906 05:43:56.635524 90901 solver.cpp:228] Iteration 84770, loss = 0.157173
I0906 05:43:56.635602 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157174 (* 1 = 0.157174 loss)
I0906 05:43:56.635622 90901 sgd_solver.cpp:106] Iteration 84770, lr = 0.001
I0906 05:44:04.277798 90901 solver.cpp:228] Iteration 84780, loss = 0.0838331
I0906 05:44:04.278064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0838339 (* 1 = 0.0838339 loss)
I0906 05:44:04.278085 90901 sgd_solver.cpp:106] Iteration 84780, lr = 0.001
I0906 05:44:11.808512 90901 solver.cpp:228] Iteration 84790, loss = 0.187799
I0906 05:44:11.808593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1878 (* 1 = 0.1878 loss)
I0906 05:44:11.808609 90901 sgd_solver.cpp:106] Iteration 84790, lr = 0.001
I0906 05:44:18.760359 90901 solver.cpp:337] Iteration 84800, Testing net (#0)
I0906 05:45:11.077909 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.942187
I0906 05:45:11.078085 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.142453 (* 1 = 0.142453 loss)
I0906 05:45:11.299155 90901 solver.cpp:228] Iteration 84800, loss = 0.150544
I0906 05:45:11.299216 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150545 (* 1 = 0.150545 loss)
I0906 05:45:11.299238 90901 sgd_solver.cpp:106] Iteration 84800, lr = 0.001
I0906 05:45:18.140866 90901 solver.cpp:228] Iteration 84810, loss = 0.0738297
I0906 05:45:18.140934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0738305 (* 1 = 0.0738305 loss)
I0906 05:45:18.140951 90901 sgd_solver.cpp:106] Iteration 84810, lr = 0.001
I0906 05:45:25.852236 90901 solver.cpp:228] Iteration 84820, loss = 0.0624528
I0906 05:45:25.852301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0624536 (* 1 = 0.0624536 loss)
I0906 05:45:25.852319 90901 sgd_solver.cpp:106] Iteration 84820, lr = 0.001
I0906 05:45:33.681301 90901 solver.cpp:228] Iteration 84830, loss = 0.0449708
I0906 05:45:33.681370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0449717 (* 1 = 0.0449717 loss)
I0906 05:45:33.681386 90901 sgd_solver.cpp:106] Iteration 84830, lr = 0.001
I0906 05:45:41.194285 90901 solver.cpp:228] Iteration 84840, loss = 0.258657
I0906 05:45:41.194447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258658 (* 1 = 0.258658 loss)
I0906 05:45:41.194466 90901 sgd_solver.cpp:106] Iteration 84840, lr = 0.001
I0906 05:45:49.055735 90901 solver.cpp:228] Iteration 84850, loss = 0.0434221
I0906 05:45:49.055804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.043423 (* 1 = 0.043423 loss)
I0906 05:45:49.055819 90901 sgd_solver.cpp:106] Iteration 84850, lr = 0.001
I0906 05:45:56.855139 90901 solver.cpp:228] Iteration 84860, loss = 0.0582021
I0906 05:45:56.855209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.058203 (* 1 = 0.058203 loss)
I0906 05:45:56.855227 90901 sgd_solver.cpp:106] Iteration 84860, lr = 0.001
I0906 05:46:03.742234 90901 solver.cpp:228] Iteration 84870, loss = 0.0104495
I0906 05:46:03.742311 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0104504 (* 1 = 0.0104504 loss)
I0906 05:46:03.742327 90901 sgd_solver.cpp:106] Iteration 84870, lr = 0.001
I0906 05:46:11.091701 90901 solver.cpp:228] Iteration 84880, loss = 0.27148
I0906 05:46:11.091845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271481 (* 1 = 0.271481 loss)
I0906 05:46:11.091868 90901 sgd_solver.cpp:106] Iteration 84880, lr = 0.001
I0906 05:46:18.511837 90901 solver.cpp:228] Iteration 84890, loss = 0.0447203
I0906 05:46:18.512151 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0447212 (* 1 = 0.0447212 loss)
I0906 05:46:18.512176 90901 sgd_solver.cpp:106] Iteration 84890, lr = 0.001
I0906 05:46:26.517501 90901 solver.cpp:228] Iteration 84900, loss = 0.151568
I0906 05:46:26.517566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151569 (* 1 = 0.151569 loss)
I0906 05:46:26.517585 90901 sgd_solver.cpp:106] Iteration 84900, lr = 0.001
I0906 05:46:33.501572 90901 solver.cpp:228] Iteration 84910, loss = 0.175731
I0906 05:46:33.501719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175732 (* 1 = 0.175732 loss)
I0906 05:46:33.501739 90901 sgd_solver.cpp:106] Iteration 84910, lr = 0.001
I0906 05:46:40.643812 90901 solver.cpp:228] Iteration 84920, loss = 0.282787
I0906 05:46:40.643954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282788 (* 1 = 0.282788 loss)
I0906 05:46:40.643975 90901 sgd_solver.cpp:106] Iteration 84920, lr = 0.001
I0906 05:46:47.507761 90901 solver.cpp:228] Iteration 84930, loss = 0.217028
I0906 05:46:47.507851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217029 (* 1 = 0.217029 loss)
I0906 05:46:47.507877 90901 sgd_solver.cpp:106] Iteration 84930, lr = 0.001
I0906 05:46:54.587028 90901 solver.cpp:228] Iteration 84940, loss = 0.216861
I0906 05:46:54.587303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216862 (* 1 = 0.216862 loss)
I0906 05:46:54.587321 90901 sgd_solver.cpp:106] Iteration 84940, lr = 0.001
I0906 05:47:00.159149 90901 solver.cpp:228] Iteration 84950, loss = 0.173358
I0906 05:47:00.159220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173359 (* 1 = 0.173359 loss)
I0906 05:47:00.159236 90901 sgd_solver.cpp:106] Iteration 84950, lr = 0.001
I0906 05:47:05.360795 90901 solver.cpp:228] Iteration 84960, loss = 0.265287
I0906 05:47:05.360863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265288 (* 1 = 0.265288 loss)
I0906 05:47:05.360880 90901 sgd_solver.cpp:106] Iteration 84960, lr = 0.001
I0906 05:47:10.627651 90901 solver.cpp:228] Iteration 84970, loss = 0.200319
I0906 05:47:10.627727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200319 (* 1 = 0.200319 loss)
I0906 05:47:10.627745 90901 sgd_solver.cpp:106] Iteration 84970, lr = 0.001
I0906 05:47:16.449007 90901 solver.cpp:228] Iteration 84980, loss = 0.102875
I0906 05:47:16.449214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102875 (* 1 = 0.102875 loss)
I0906 05:47:16.449239 90901 sgd_solver.cpp:106] Iteration 84980, lr = 0.001
I0906 05:47:22.953699 90901 solver.cpp:228] Iteration 84990, loss = 0.0791322
I0906 05:47:22.953908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0791331 (* 1 = 0.0791331 loss)
I0906 05:47:22.953946 90901 sgd_solver.cpp:106] Iteration 84990, lr = 0.001
I0906 05:47:30.596803 90901 solver.cpp:228] Iteration 85000, loss = 0.194177
I0906 05:47:30.597111 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194177 (* 1 = 0.194177 loss)
I0906 05:47:30.597136 90901 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I0906 05:47:38.556890 90901 solver.cpp:228] Iteration 85010, loss = 0.386863
I0906 05:47:38.556970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386864 (* 1 = 0.386864 loss)
I0906 05:47:38.556988 90901 sgd_solver.cpp:106] Iteration 85010, lr = 0.001
I0906 05:47:46.548643 90901 solver.cpp:228] Iteration 85020, loss = 0.0810781
I0906 05:47:46.548774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.081079 (* 1 = 0.081079 loss)
I0906 05:47:46.548797 90901 sgd_solver.cpp:106] Iteration 85020, lr = 0.001
I0906 05:47:54.065567 90901 solver.cpp:228] Iteration 85030, loss = 0.12895
I0906 05:47:54.065632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128951 (* 1 = 0.128951 loss)
I0906 05:47:54.065649 90901 sgd_solver.cpp:106] Iteration 85030, lr = 0.001
I0906 05:48:01.735488 90901 solver.cpp:228] Iteration 85040, loss = 0.12687
I0906 05:48:01.735652 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126871 (* 1 = 0.126871 loss)
I0906 05:48:01.735695 90901 sgd_solver.cpp:106] Iteration 85040, lr = 0.001
I0906 05:48:09.407507 90901 solver.cpp:228] Iteration 85050, loss = 0.0545944
I0906 05:48:09.407579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545953 (* 1 = 0.0545953 loss)
I0906 05:48:09.407598 90901 sgd_solver.cpp:106] Iteration 85050, lr = 0.001
I0906 05:48:16.728065 90901 solver.cpp:228] Iteration 85060, loss = 0.158445
I0906 05:48:16.728153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158446 (* 1 = 0.158446 loss)
I0906 05:48:16.728171 90901 sgd_solver.cpp:106] Iteration 85060, lr = 0.001
I0906 05:48:24.116714 90901 solver.cpp:228] Iteration 85070, loss = 0.385298
I0906 05:48:24.116781 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.385298 (* 1 = 0.385298 loss)
I0906 05:48:24.116799 90901 sgd_solver.cpp:106] Iteration 85070, lr = 0.001
I0906 05:48:31.217900 90901 solver.cpp:228] Iteration 85080, loss = 0.0573086
I0906 05:48:31.217977 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0573095 (* 1 = 0.0573095 loss)
I0906 05:48:31.217993 90901 sgd_solver.cpp:106] Iteration 85080, lr = 0.001
I0906 05:48:38.101385 90901 solver.cpp:228] Iteration 85090, loss = 0.0461321
I0906 05:48:38.101665 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.046133 (* 1 = 0.046133 loss)
I0906 05:48:38.101686 90901 sgd_solver.cpp:106] Iteration 85090, lr = 0.001
I0906 05:48:46.164047 90901 solver.cpp:228] Iteration 85100, loss = 0.238183
I0906 05:48:46.164142 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238184 (* 1 = 0.238184 loss)
I0906 05:48:46.164166 90901 sgd_solver.cpp:106] Iteration 85100, lr = 0.001
I0906 05:48:54.420877 90901 solver.cpp:228] Iteration 85110, loss = 0.048024
I0906 05:48:54.420954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0480249 (* 1 = 0.0480249 loss)
I0906 05:48:54.420972 90901 sgd_solver.cpp:106] Iteration 85110, lr = 0.001
I0906 05:49:02.243824 90901 solver.cpp:228] Iteration 85120, loss = 0.178755
I0906 05:49:02.243962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178756 (* 1 = 0.178756 loss)
I0906 05:49:02.243988 90901 sgd_solver.cpp:106] Iteration 85120, lr = 0.001
I0906 05:49:09.922298 90901 solver.cpp:228] Iteration 85130, loss = 0.0633465
I0906 05:49:09.922499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0633473 (* 1 = 0.0633473 loss)
I0906 05:49:09.922518 90901 sgd_solver.cpp:106] Iteration 85130, lr = 0.001
I0906 05:49:17.284703 90901 solver.cpp:228] Iteration 85140, loss = 0.0760155
I0906 05:49:17.284821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0760164 (* 1 = 0.0760164 loss)
I0906 05:49:17.284842 90901 sgd_solver.cpp:106] Iteration 85140, lr = 0.001
I0906 05:49:25.116940 90901 solver.cpp:228] Iteration 85150, loss = 0.0510415
I0906 05:49:25.117075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0510423 (* 1 = 0.0510423 loss)
I0906 05:49:25.117096 90901 sgd_solver.cpp:106] Iteration 85150, lr = 0.001
I0906 05:49:32.433933 90901 solver.cpp:228] Iteration 85160, loss = 0.344023
I0906 05:49:32.434171 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344023 (* 1 = 0.344023 loss)
I0906 05:49:32.434203 90901 sgd_solver.cpp:106] Iteration 85160, lr = 0.001
I0906 05:49:40.315508 90901 solver.cpp:228] Iteration 85170, loss = 0.0850548
I0906 05:49:40.315706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0850556 (* 1 = 0.0850556 loss)
I0906 05:49:40.315726 90901 sgd_solver.cpp:106] Iteration 85170, lr = 0.001
I0906 05:49:47.763394 90901 solver.cpp:228] Iteration 85180, loss = 0.0342637
I0906 05:49:47.763468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0342645 (* 1 = 0.0342645 loss)
I0906 05:49:47.763484 90901 sgd_solver.cpp:106] Iteration 85180, lr = 0.001
I0906 05:49:55.819108 90901 solver.cpp:228] Iteration 85190, loss = 0.19005
I0906 05:49:55.819175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190051 (* 1 = 0.190051 loss)
I0906 05:49:55.819195 90901 sgd_solver.cpp:106] Iteration 85190, lr = 0.001
I0906 05:50:03.136162 90901 solver.cpp:228] Iteration 85200, loss = 0.0625625
I0906 05:50:03.136303 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0625633 (* 1 = 0.0625633 loss)
I0906 05:50:03.136324 90901 sgd_solver.cpp:106] Iteration 85200, lr = 0.001
I0906 05:50:11.034744 90901 solver.cpp:228] Iteration 85210, loss = 0.148871
I0906 05:50:11.035018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148872 (* 1 = 0.148872 loss)
I0906 05:50:11.035042 90901 sgd_solver.cpp:106] Iteration 85210, lr = 0.001
I0906 05:50:18.348352 90901 solver.cpp:228] Iteration 85220, loss = 0.229969
I0906 05:50:18.348484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22997 (* 1 = 0.22997 loss)
I0906 05:50:18.348506 90901 sgd_solver.cpp:106] Iteration 85220, lr = 0.001
I0906 05:50:26.212713 90901 solver.cpp:228] Iteration 85230, loss = 0.152853
I0906 05:50:26.212888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152854 (* 1 = 0.152854 loss)
I0906 05:50:26.212915 90901 sgd_solver.cpp:106] Iteration 85230, lr = 0.001
I0906 05:50:34.077664 90901 solver.cpp:228] Iteration 85240, loss = 0.124987
I0906 05:50:34.077764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124988 (* 1 = 0.124988 loss)
I0906 05:50:34.077791 90901 sgd_solver.cpp:106] Iteration 85240, lr = 0.001
I0906 05:50:41.411018 90901 solver.cpp:228] Iteration 85250, loss = 0.0412871
I0906 05:50:41.411345 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0412879 (* 1 = 0.0412879 loss)
I0906 05:50:41.411363 90901 sgd_solver.cpp:106] Iteration 85250, lr = 0.001
I0906 05:50:48.454294 90901 solver.cpp:228] Iteration 85260, loss = 0.187738
I0906 05:50:48.454360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187739 (* 1 = 0.187739 loss)
I0906 05:50:48.454378 90901 sgd_solver.cpp:106] Iteration 85260, lr = 0.001
I0906 05:50:55.312497 90901 solver.cpp:228] Iteration 85270, loss = 0.0996157
I0906 05:50:55.312579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0996165 (* 1 = 0.0996165 loss)
I0906 05:50:55.312599 90901 sgd_solver.cpp:106] Iteration 85270, lr = 0.001
I0906 05:51:02.881379 90901 solver.cpp:228] Iteration 85280, loss = 0.276961
I0906 05:51:02.881453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276962 (* 1 = 0.276962 loss)
I0906 05:51:02.881474 90901 sgd_solver.cpp:106] Iteration 85280, lr = 0.001
I0906 05:51:10.786917 90901 solver.cpp:228] Iteration 85290, loss = 0.42853
I0906 05:51:10.786991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.428531 (* 1 = 0.428531 loss)
I0906 05:51:10.787010 90901 sgd_solver.cpp:106] Iteration 85290, lr = 0.001
I0906 05:51:19.023540 90901 solver.cpp:228] Iteration 85300, loss = 0.245865
I0906 05:51:19.023723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245866 (* 1 = 0.245866 loss)
I0906 05:51:19.023751 90901 sgd_solver.cpp:106] Iteration 85300, lr = 0.001
I0906 05:51:27.820611 90901 solver.cpp:228] Iteration 85310, loss = 0.1259
I0906 05:51:27.820689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125901 (* 1 = 0.125901 loss)
I0906 05:51:27.820710 90901 sgd_solver.cpp:106] Iteration 85310, lr = 0.001
I0906 05:51:36.603590 90901 solver.cpp:228] Iteration 85320, loss = 0.05348
I0906 05:51:36.603693 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0534808 (* 1 = 0.0534808 loss)
I0906 05:51:36.603713 90901 sgd_solver.cpp:106] Iteration 85320, lr = 0.001
I0906 05:51:44.966859 90901 solver.cpp:228] Iteration 85330, loss = 0.126145
I0906 05:51:44.966934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126146 (* 1 = 0.126146 loss)
I0906 05:51:44.966953 90901 sgd_solver.cpp:106] Iteration 85330, lr = 0.001
I0906 05:51:52.611440 90901 solver.cpp:228] Iteration 85340, loss = 0.351785
I0906 05:51:52.611795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351786 (* 1 = 0.351786 loss)
I0906 05:51:52.611819 90901 sgd_solver.cpp:106] Iteration 85340, lr = 0.001
I0906 05:52:00.262361 90901 solver.cpp:228] Iteration 85350, loss = 0.0445838
I0906 05:52:00.262445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0445846 (* 1 = 0.0445846 loss)
I0906 05:52:00.262462 90901 sgd_solver.cpp:106] Iteration 85350, lr = 0.001
I0906 05:52:08.145870 90901 solver.cpp:228] Iteration 85360, loss = 0.0965408
I0906 05:52:08.145965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0965417 (* 1 = 0.0965417 loss)
I0906 05:52:08.145987 90901 sgd_solver.cpp:106] Iteration 85360, lr = 0.001
I0906 05:52:15.528520 90901 solver.cpp:228] Iteration 85370, loss = 0.0921335
I0906 05:52:15.528651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0921344 (* 1 = 0.0921344 loss)
I0906 05:52:15.528676 90901 sgd_solver.cpp:106] Iteration 85370, lr = 0.001
I0906 05:52:23.044081 90901 solver.cpp:228] Iteration 85380, loss = 0.188
I0906 05:52:23.044381 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188 (* 1 = 0.188 loss)
I0906 05:52:23.044401 90901 sgd_solver.cpp:106] Iteration 85380, lr = 0.001
I0906 05:52:29.885201 90901 solver.cpp:228] Iteration 85390, loss = 0.128429
I0906 05:52:29.885272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12843 (* 1 = 0.12843 loss)
I0906 05:52:29.885289 90901 sgd_solver.cpp:106] Iteration 85390, lr = 0.001
I0906 05:52:37.207304 90901 solver.cpp:228] Iteration 85400, loss = 0.0414777
I0906 05:52:37.207484 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0414786 (* 1 = 0.0414786 loss)
I0906 05:52:37.207511 90901 sgd_solver.cpp:106] Iteration 85400, lr = 0.001
I0906 05:52:44.806805 90901 solver.cpp:228] Iteration 85410, loss = 0.15073
I0906 05:52:44.806985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150731 (* 1 = 0.150731 loss)
I0906 05:52:44.807016 90901 sgd_solver.cpp:106] Iteration 85410, lr = 0.001
I0906 05:52:52.122112 90901 solver.cpp:228] Iteration 85420, loss = 0.100703
I0906 05:52:52.122197 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100704 (* 1 = 0.100704 loss)
I0906 05:52:52.122215 90901 sgd_solver.cpp:106] Iteration 85420, lr = 0.001
I0906 05:52:59.452955 90901 solver.cpp:228] Iteration 85430, loss = 0.209866
I0906 05:52:59.453119 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209867 (* 1 = 0.209867 loss)
I0906 05:52:59.453140 90901 sgd_solver.cpp:106] Iteration 85430, lr = 0.001
I0906 05:53:06.824831 90901 solver.cpp:228] Iteration 85440, loss = 0.0668463
I0906 05:53:06.824928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0668473 (* 1 = 0.0668473 loss)
I0906 05:53:06.824952 90901 sgd_solver.cpp:106] Iteration 85440, lr = 0.001
I0906 05:53:13.924758 90901 solver.cpp:228] Iteration 85450, loss = 0.362721
I0906 05:53:13.924831 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.362722 (* 1 = 0.362722 loss)
I0906 05:53:13.924849 90901 sgd_solver.cpp:106] Iteration 85450, lr = 0.001
I0906 05:53:21.565439 90901 solver.cpp:228] Iteration 85460, loss = 0.199022
I0906 05:53:21.565510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199023 (* 1 = 0.199023 loss)
I0906 05:53:21.565529 90901 sgd_solver.cpp:106] Iteration 85460, lr = 0.001
I0906 05:53:28.186231 90901 solver.cpp:228] Iteration 85470, loss = 0.0970352
I0906 05:53:28.186298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0970362 (* 1 = 0.0970362 loss)
I0906 05:53:28.186316 90901 sgd_solver.cpp:106] Iteration 85470, lr = 0.001
I0906 05:53:35.978121 90901 solver.cpp:228] Iteration 85480, loss = 0.131905
I0906 05:53:35.978358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131906 (* 1 = 0.131906 loss)
I0906 05:53:35.978380 90901 sgd_solver.cpp:106] Iteration 85480, lr = 0.001
I0906 05:53:42.774451 90901 solver.cpp:228] Iteration 85490, loss = 0.0618863
I0906 05:53:42.774534 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0618872 (* 1 = 0.0618872 loss)
I0906 05:53:42.774556 90901 sgd_solver.cpp:106] Iteration 85490, lr = 0.001
I0906 05:53:49.319311 90901 solver.cpp:228] Iteration 85500, loss = 0.626846
I0906 05:53:49.319371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.626847 (* 1 = 0.626847 loss)
I0906 05:53:49.319391 90901 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I0906 05:53:56.160003 90901 solver.cpp:228] Iteration 85510, loss = 0.0418947
I0906 05:53:56.160290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0418957 (* 1 = 0.0418957 loss)
I0906 05:53:56.160353 90901 sgd_solver.cpp:106] Iteration 85510, lr = 0.001
I0906 05:54:01.857036 90901 solver.cpp:228] Iteration 85520, loss = 0.075113
I0906 05:54:01.857149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0751139 (* 1 = 0.0751139 loss)
I0906 05:54:01.857174 90901 sgd_solver.cpp:106] Iteration 85520, lr = 0.001
I0906 05:54:08.412852 90901 solver.cpp:228] Iteration 85530, loss = 0.0472854
I0906 05:54:08.413100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0472863 (* 1 = 0.0472863 loss)
I0906 05:54:08.413118 90901 sgd_solver.cpp:106] Iteration 85530, lr = 0.001
I0906 05:54:15.473088 90901 solver.cpp:228] Iteration 85540, loss = 0.287573
I0906 05:54:15.473166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287574 (* 1 = 0.287574 loss)
I0906 05:54:15.473184 90901 sgd_solver.cpp:106] Iteration 85540, lr = 0.001
I0906 05:54:22.269615 90901 solver.cpp:228] Iteration 85550, loss = 0.137904
I0906 05:54:22.269696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137905 (* 1 = 0.137905 loss)
I0906 05:54:22.269713 90901 sgd_solver.cpp:106] Iteration 85550, lr = 0.001
I0906 05:54:29.594713 90901 solver.cpp:228] Iteration 85560, loss = 0.204266
I0906 05:54:29.594802 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204267 (* 1 = 0.204267 loss)
I0906 05:54:29.594820 90901 sgd_solver.cpp:106] Iteration 85560, lr = 0.001
I0906 05:54:36.477277 90901 solver.cpp:228] Iteration 85570, loss = 0.27444
I0906 05:54:36.477344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274441 (* 1 = 0.274441 loss)
I0906 05:54:36.477362 90901 sgd_solver.cpp:106] Iteration 85570, lr = 0.001
I0906 05:54:43.515329 90901 solver.cpp:228] Iteration 85580, loss = 0.149071
I0906 05:54:43.515667 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149072 (* 1 = 0.149072 loss)
I0906 05:54:43.515691 90901 sgd_solver.cpp:106] Iteration 85580, lr = 0.001
I0906 05:54:51.147382 90901 solver.cpp:228] Iteration 85590, loss = 0.11933
I0906 05:54:51.147500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119331 (* 1 = 0.119331 loss)
I0906 05:54:51.147522 90901 sgd_solver.cpp:106] Iteration 85590, lr = 0.001
I0906 05:54:57.953857 90901 solver.cpp:337] Iteration 85600, Testing net (#0)
I0906 05:55:50.485968 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.944062
I0906 05:55:50.486173 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.152178 (* 1 = 0.152178 loss)
I0906 05:55:50.857348 90901 solver.cpp:228] Iteration 85600, loss = 0.171411
I0906 05:55:50.857429 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171412 (* 1 = 0.171412 loss)
I0906 05:55:50.857451 90901 sgd_solver.cpp:106] Iteration 85600, lr = 0.001
I0906 05:55:57.756335 90901 solver.cpp:228] Iteration 85610, loss = 0.058595
I0906 05:55:57.756412 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0585959 (* 1 = 0.0585959 loss)
I0906 05:55:57.756428 90901 sgd_solver.cpp:106] Iteration 85610, lr = 0.001
I0906 05:56:05.486243 90901 solver.cpp:228] Iteration 85620, loss = 0.0543182
I0906 05:56:05.486366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0543191 (* 1 = 0.0543191 loss)
I0906 05:56:05.486387 90901 sgd_solver.cpp:106] Iteration 85620, lr = 0.001
I0906 05:56:12.913486 90901 solver.cpp:228] Iteration 85630, loss = 0.167311
I0906 05:56:12.913585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167311 (* 1 = 0.167311 loss)
I0906 05:56:12.913602 90901 sgd_solver.cpp:106] Iteration 85630, lr = 0.001
I0906 05:56:19.884148 90901 solver.cpp:228] Iteration 85640, loss = 0.245613
I0906 05:56:19.884294 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245614 (* 1 = 0.245614 loss)
I0906 05:56:19.884317 90901 sgd_solver.cpp:106] Iteration 85640, lr = 0.001
I0906 05:56:28.001760 90901 solver.cpp:228] Iteration 85650, loss = 0.129537
I0906 05:56:28.001945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129538 (* 1 = 0.129538 loss)
I0906 05:56:28.001976 90901 sgd_solver.cpp:106] Iteration 85650, lr = 0.001
I0906 05:56:35.700410 90901 solver.cpp:228] Iteration 85660, loss = 0.0740999
I0906 05:56:35.700515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0741008 (* 1 = 0.0741008 loss)
I0906 05:56:35.700536 90901 sgd_solver.cpp:106] Iteration 85660, lr = 0.001
I0906 05:56:43.326536 90901 solver.cpp:228] Iteration 85670, loss = 0.360147
I0906 05:56:43.326609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.360148 (* 1 = 0.360148 loss)
I0906 05:56:43.326625 90901 sgd_solver.cpp:106] Iteration 85670, lr = 0.001
I0906 05:56:50.407965 90901 solver.cpp:228] Iteration 85680, loss = 0.157016
I0906 05:56:50.408037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157017 (* 1 = 0.157017 loss)
I0906 05:56:50.408054 90901 sgd_solver.cpp:106] Iteration 85680, lr = 0.001
I0906 05:56:57.810585 90901 solver.cpp:228] Iteration 85690, loss = 0.318165
I0906 05:56:57.810664 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.318166 (* 1 = 0.318166 loss)
I0906 05:56:57.810680 90901 sgd_solver.cpp:106] Iteration 85690, lr = 0.001
I0906 05:57:05.170259 90901 solver.cpp:228] Iteration 85700, loss = 0.154285
I0906 05:57:05.170675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154286 (* 1 = 0.154286 loss)
I0906 05:57:05.170703 90901 sgd_solver.cpp:106] Iteration 85700, lr = 0.001
I0906 05:57:13.037431 90901 solver.cpp:228] Iteration 85710, loss = 0.0899249
I0906 05:57:13.037518 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0899258 (* 1 = 0.0899258 loss)
I0906 05:57:13.037536 90901 sgd_solver.cpp:106] Iteration 85710, lr = 0.001
I0906 05:57:19.666016 90901 solver.cpp:228] Iteration 85720, loss = 0.058774
I0906 05:57:19.666113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0587749 (* 1 = 0.0587749 loss)
I0906 05:57:19.666137 90901 sgd_solver.cpp:106] Iteration 85720, lr = 0.001
I0906 05:57:24.912261 90901 solver.cpp:228] Iteration 85730, loss = 0.156172
I0906 05:57:24.912340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156173 (* 1 = 0.156173 loss)
I0906 05:57:24.912364 90901 sgd_solver.cpp:106] Iteration 85730, lr = 0.001
I0906 05:57:30.153631 90901 solver.cpp:228] Iteration 85740, loss = 0.165905
I0906 05:57:30.153712 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165906 (* 1 = 0.165906 loss)
I0906 05:57:30.153730 90901 sgd_solver.cpp:106] Iteration 85740, lr = 0.001
I0906 05:57:35.786197 90901 solver.cpp:228] Iteration 85750, loss = 0.0468191
I0906 05:57:35.786370 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.04682 (* 1 = 0.04682 loss)
I0906 05:57:35.786387 90901 sgd_solver.cpp:106] Iteration 85750, lr = 0.001
I0906 05:57:42.486989 90901 solver.cpp:228] Iteration 85760, loss = 0.1922
I0906 05:57:42.487081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192201 (* 1 = 0.192201 loss)
I0906 05:57:42.487099 90901 sgd_solver.cpp:106] Iteration 85760, lr = 0.001
I0906 05:57:48.974239 90901 solver.cpp:228] Iteration 85770, loss = 0.1177
I0906 05:57:48.974334 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117701 (* 1 = 0.117701 loss)
I0906 05:57:48.974352 90901 sgd_solver.cpp:106] Iteration 85770, lr = 0.001
I0906 05:57:55.961437 90901 solver.cpp:228] Iteration 85780, loss = 0.184956
I0906 05:57:55.961503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184957 (* 1 = 0.184957 loss)
I0906 05:57:55.961520 90901 sgd_solver.cpp:106] Iteration 85780, lr = 0.001
I0906 05:58:03.923616 90901 solver.cpp:228] Iteration 85790, loss = 0.0375378
I0906 05:58:03.923740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0375387 (* 1 = 0.0375387 loss)
I0906 05:58:03.923760 90901 sgd_solver.cpp:106] Iteration 85790, lr = 0.001
I0906 05:58:10.785765 90901 solver.cpp:228] Iteration 85800, loss = 0.18521
I0906 05:58:10.785969 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185211 (* 1 = 0.185211 loss)
I0906 05:58:10.785993 90901 sgd_solver.cpp:106] Iteration 85800, lr = 0.001
I0906 05:58:18.112967 90901 solver.cpp:228] Iteration 85810, loss = 0.320759
I0906 05:58:18.113035 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32076 (* 1 = 0.32076 loss)
I0906 05:58:18.113051 90901 sgd_solver.cpp:106] Iteration 85810, lr = 0.001
I0906 05:58:26.035540 90901 solver.cpp:228] Iteration 85820, loss = 0.079137
I0906 05:58:26.035610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0791379 (* 1 = 0.0791379 loss)
I0906 05:58:26.035627 90901 sgd_solver.cpp:106] Iteration 85820, lr = 0.001
I0906 05:58:33.094521 90901 solver.cpp:228] Iteration 85830, loss = 0.110767
I0906 05:58:33.094614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110767 (* 1 = 0.110767 loss)
I0906 05:58:33.094635 90901 sgd_solver.cpp:106] Iteration 85830, lr = 0.001
I0906 05:58:40.447264 90901 solver.cpp:228] Iteration 85840, loss = 0.242242
I0906 05:58:40.447346 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242242 (* 1 = 0.242242 loss)
I0906 05:58:40.447365 90901 sgd_solver.cpp:106] Iteration 85840, lr = 0.001
I0906 05:58:47.793993 90901 solver.cpp:228] Iteration 85850, loss = 0.321915
I0906 05:58:47.794215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321916 (* 1 = 0.321916 loss)
I0906 05:58:47.794240 90901 sgd_solver.cpp:106] Iteration 85850, lr = 0.001
I0906 05:58:55.154381 90901 solver.cpp:228] Iteration 85860, loss = 0.0434965
I0906 05:58:55.154487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0434974 (* 1 = 0.0434974 loss)
I0906 05:58:55.154507 90901 sgd_solver.cpp:106] Iteration 85860, lr = 0.001
I0906 05:59:01.723986 90901 solver.cpp:228] Iteration 85870, loss = 0.115884
I0906 05:59:01.724067 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115885 (* 1 = 0.115885 loss)
I0906 05:59:01.724084 90901 sgd_solver.cpp:106] Iteration 85870, lr = 0.001
I0906 05:59:09.060396 90901 solver.cpp:228] Iteration 85880, loss = 0.0596482
I0906 05:59:09.060467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596491 (* 1 = 0.0596491 loss)
I0906 05:59:09.060484 90901 sgd_solver.cpp:106] Iteration 85880, lr = 0.001
I0906 05:59:15.943492 90901 solver.cpp:228] Iteration 85890, loss = 0.160246
I0906 05:59:15.943572 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160247 (* 1 = 0.160247 loss)
I0906 05:59:15.943588 90901 sgd_solver.cpp:106] Iteration 85890, lr = 0.001
I0906 05:59:23.632943 90901 solver.cpp:228] Iteration 85900, loss = 0.156667
I0906 05:59:23.633357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156668 (* 1 = 0.156668 loss)
I0906 05:59:23.633388 90901 sgd_solver.cpp:106] Iteration 85900, lr = 0.001
I0906 05:59:31.107116 90901 solver.cpp:228] Iteration 85910, loss = 0.169173
I0906 05:59:31.107192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169174 (* 1 = 0.169174 loss)
I0906 05:59:31.107210 90901 sgd_solver.cpp:106] Iteration 85910, lr = 0.001
I0906 05:59:38.756922 90901 solver.cpp:228] Iteration 85920, loss = 0.181592
I0906 05:59:38.756978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181592 (* 1 = 0.181592 loss)
I0906 05:59:38.756999 90901 sgd_solver.cpp:106] Iteration 85920, lr = 0.001
I0906 05:59:45.696699 90901 solver.cpp:228] Iteration 85930, loss = 0.165808
I0906 05:59:45.697052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165808 (* 1 = 0.165808 loss)
I0906 05:59:45.697078 90901 sgd_solver.cpp:106] Iteration 85930, lr = 0.001
I0906 05:59:53.165365 90901 solver.cpp:228] Iteration 85940, loss = 0.048687
I0906 05:59:53.165431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0486879 (* 1 = 0.0486879 loss)
I0906 05:59:53.165448 90901 sgd_solver.cpp:106] Iteration 85940, lr = 0.001
I0906 06:00:00.925350 90901 solver.cpp:228] Iteration 85950, loss = 0.185388
I0906 06:00:00.925545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185388 (* 1 = 0.185388 loss)
I0906 06:00:00.925568 90901 sgd_solver.cpp:106] Iteration 85950, lr = 0.001
I0906 06:00:08.448773 90901 solver.cpp:228] Iteration 85960, loss = 0.175897
I0906 06:00:08.448840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175897 (* 1 = 0.175897 loss)
I0906 06:00:08.448858 90901 sgd_solver.cpp:106] Iteration 85960, lr = 0.001
I0906 06:00:15.854029 90901 solver.cpp:228] Iteration 85970, loss = 0.26194
I0906 06:00:15.854106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26194 (* 1 = 0.26194 loss)
I0906 06:00:15.854125 90901 sgd_solver.cpp:106] Iteration 85970, lr = 0.001
I0906 06:00:23.579479 90901 solver.cpp:228] Iteration 85980, loss = 0.244905
I0906 06:00:23.579542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.244906 (* 1 = 0.244906 loss)
I0906 06:00:23.579560 90901 sgd_solver.cpp:106] Iteration 85980, lr = 0.001
I0906 06:00:31.040225 90901 solver.cpp:228] Iteration 85990, loss = 0.150479
I0906 06:00:31.040444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15048 (* 1 = 0.15048 loss)
I0906 06:00:31.040463 90901 sgd_solver.cpp:106] Iteration 85990, lr = 0.001
I0906 06:00:38.642771 90901 solver.cpp:228] Iteration 86000, loss = 0.0687636
I0906 06:00:38.642853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0687645 (* 1 = 0.0687645 loss)
I0906 06:00:38.642869 90901 sgd_solver.cpp:106] Iteration 86000, lr = 0.001
I0906 06:00:45.727952 90901 solver.cpp:228] Iteration 86010, loss = 0.442833
I0906 06:00:45.728018 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.442834 (* 1 = 0.442834 loss)
I0906 06:00:45.728035 90901 sgd_solver.cpp:106] Iteration 86010, lr = 0.001
I0906 06:00:52.968361 90901 solver.cpp:228] Iteration 86020, loss = 0.336694
I0906 06:00:52.968456 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336695 (* 1 = 0.336695 loss)
I0906 06:00:52.968473 90901 sgd_solver.cpp:106] Iteration 86020, lr = 0.001
I0906 06:01:00.509865 90901 solver.cpp:228] Iteration 86030, loss = 0.169436
I0906 06:01:00.509944 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169437 (* 1 = 0.169437 loss)
I0906 06:01:00.509961 90901 sgd_solver.cpp:106] Iteration 86030, lr = 0.001
I0906 06:01:07.677363 90901 solver.cpp:228] Iteration 86040, loss = 0.0821461
I0906 06:01:07.677537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.082147 (* 1 = 0.082147 loss)
I0906 06:01:07.677557 90901 sgd_solver.cpp:106] Iteration 86040, lr = 0.001
I0906 06:01:14.539386 90901 solver.cpp:228] Iteration 86050, loss = 0.197442
I0906 06:01:14.539535 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197443 (* 1 = 0.197443 loss)
I0906 06:01:14.539561 90901 sgd_solver.cpp:106] Iteration 86050, lr = 0.001
I0906 06:01:21.881999 90901 solver.cpp:228] Iteration 86060, loss = 0.170738
I0906 06:01:21.882081 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170739 (* 1 = 0.170739 loss)
I0906 06:01:21.882099 90901 sgd_solver.cpp:106] Iteration 86060, lr = 0.001
I0906 06:01:28.779726 90901 solver.cpp:228] Iteration 86070, loss = 0.0367962
I0906 06:01:28.779806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0367971 (* 1 = 0.0367971 loss)
I0906 06:01:28.779822 90901 sgd_solver.cpp:106] Iteration 86070, lr = 0.001
I0906 06:01:36.057096 90901 solver.cpp:228] Iteration 86080, loss = 0.0851387
I0906 06:01:36.057180 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0851396 (* 1 = 0.0851396 loss)
I0906 06:01:36.057199 90901 sgd_solver.cpp:106] Iteration 86080, lr = 0.001
I0906 06:01:42.834561 90901 solver.cpp:228] Iteration 86090, loss = 0.0775148
I0906 06:01:42.834743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0775156 (* 1 = 0.0775156 loss)
I0906 06:01:42.834771 90901 sgd_solver.cpp:106] Iteration 86090, lr = 0.001
I0906 06:01:49.940361 90901 solver.cpp:228] Iteration 86100, loss = 0.340187
I0906 06:01:49.940436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.340188 (* 1 = 0.340188 loss)
I0906 06:01:49.940454 90901 sgd_solver.cpp:106] Iteration 86100, lr = 0.001
I0906 06:01:57.068466 90901 solver.cpp:228] Iteration 86110, loss = 0.0210052
I0906 06:01:57.068543 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0210059 (* 1 = 0.0210059 loss)
I0906 06:01:57.068562 90901 sgd_solver.cpp:106] Iteration 86110, lr = 0.001
I0906 06:02:03.309411 90901 solver.cpp:228] Iteration 86120, loss = 0.0339985
I0906 06:02:03.309521 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0339993 (* 1 = 0.0339993 loss)
I0906 06:02:03.309540 90901 sgd_solver.cpp:106] Iteration 86120, lr = 0.001
I0906 06:02:10.387166 90901 solver.cpp:228] Iteration 86130, loss = 0.0348979
I0906 06:02:10.387240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0348987 (* 1 = 0.0348987 loss)
I0906 06:02:10.387259 90901 sgd_solver.cpp:106] Iteration 86130, lr = 0.001
I0906 06:02:17.717080 90901 solver.cpp:228] Iteration 86140, loss = 0.252113
I0906 06:02:17.717299 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252114 (* 1 = 0.252114 loss)
I0906 06:02:17.717319 90901 sgd_solver.cpp:106] Iteration 86140, lr = 0.001
I0906 06:02:24.507722 90901 solver.cpp:228] Iteration 86150, loss = 0.0464335
I0906 06:02:24.507787 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0464343 (* 1 = 0.0464343 loss)
I0906 06:02:24.507804 90901 sgd_solver.cpp:106] Iteration 86150, lr = 0.001
I0906 06:02:31.672622 90901 solver.cpp:228] Iteration 86160, loss = 0.0422849
I0906 06:02:31.672705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0422857 (* 1 = 0.0422857 loss)
I0906 06:02:31.672722 90901 sgd_solver.cpp:106] Iteration 86160, lr = 0.001
I0906 06:02:39.801499 90901 solver.cpp:228] Iteration 86170, loss = 0.0324061
I0906 06:02:39.801558 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0324068 (* 1 = 0.0324068 loss)
I0906 06:02:39.801574 90901 sgd_solver.cpp:106] Iteration 86170, lr = 0.001
I0906 06:02:45.015892 90901 solver.cpp:228] Iteration 86180, loss = 0.240135
I0906 06:02:45.015965 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240136 (* 1 = 0.240136 loss)
I0906 06:02:45.015982 90901 sgd_solver.cpp:106] Iteration 86180, lr = 0.001
I0906 06:02:50.532009 90901 solver.cpp:228] Iteration 86190, loss = 0.195896
I0906 06:02:50.532177 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195896 (* 1 = 0.195896 loss)
I0906 06:02:50.532207 90901 sgd_solver.cpp:106] Iteration 86190, lr = 0.001
I0906 06:02:55.428242 90901 solver.cpp:228] Iteration 86200, loss = 0.0616737
I0906 06:02:55.428350 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0616744 (* 1 = 0.0616744 loss)
I0906 06:02:55.428371 90901 sgd_solver.cpp:106] Iteration 86200, lr = 0.001
I0906 06:03:00.974820 90901 solver.cpp:228] Iteration 86210, loss = 0.0999435
I0906 06:03:00.974887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0999442 (* 1 = 0.0999442 loss)
I0906 06:03:00.974903 90901 sgd_solver.cpp:106] Iteration 86210, lr = 0.001
I0906 06:03:06.194521 90901 solver.cpp:228] Iteration 86220, loss = 0.195463
I0906 06:03:06.194587 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195464 (* 1 = 0.195464 loss)
I0906 06:03:06.194603 90901 sgd_solver.cpp:106] Iteration 86220, lr = 0.001
I0906 06:03:12.216433 90901 solver.cpp:228] Iteration 86230, loss = 0.203878
I0906 06:03:12.216526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203879 (* 1 = 0.203879 loss)
I0906 06:03:12.216547 90901 sgd_solver.cpp:106] Iteration 86230, lr = 0.001
I0906 06:03:18.477149 90901 solver.cpp:228] Iteration 86240, loss = 0.189786
I0906 06:03:18.477319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189786 (* 1 = 0.189786 loss)
I0906 06:03:18.477345 90901 sgd_solver.cpp:106] Iteration 86240, lr = 0.001
I0906 06:03:25.326390 90901 solver.cpp:228] Iteration 86250, loss = 0.0611504
I0906 06:03:25.326614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0611511 (* 1 = 0.0611511 loss)
I0906 06:03:25.326647 90901 sgd_solver.cpp:106] Iteration 86250, lr = 0.001
I0906 06:03:32.432785 90901 solver.cpp:228] Iteration 86260, loss = 0.0905602
I0906 06:03:32.432868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0905609 (* 1 = 0.0905609 loss)
I0906 06:03:32.432886 90901 sgd_solver.cpp:106] Iteration 86260, lr = 0.001
I0906 06:03:38.977504 90901 solver.cpp:228] Iteration 86270, loss = 0.0217116
I0906 06:03:38.977596 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0217123 (* 1 = 0.0217123 loss)
I0906 06:03:38.977613 90901 sgd_solver.cpp:106] Iteration 86270, lr = 0.001
I0906 06:03:46.113986 90901 solver.cpp:228] Iteration 86280, loss = 0.0961736
I0906 06:03:46.114056 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0961743 (* 1 = 0.0961743 loss)
I0906 06:03:46.114074 90901 sgd_solver.cpp:106] Iteration 86280, lr = 0.001
I0906 06:03:53.210563 90901 solver.cpp:228] Iteration 86290, loss = 0.0779066
I0906 06:03:53.210707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0779073 (* 1 = 0.0779073 loss)
I0906 06:03:53.210731 90901 sgd_solver.cpp:106] Iteration 86290, lr = 0.001
I0906 06:04:00.584867 90901 solver.cpp:228] Iteration 86300, loss = 0.146519
I0906 06:04:00.585069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14652 (* 1 = 0.14652 loss)
I0906 06:04:00.585088 90901 sgd_solver.cpp:106] Iteration 86300, lr = 0.001
I0906 06:04:08.119313 90901 solver.cpp:228] Iteration 86310, loss = 0.16595
I0906 06:04:08.119395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165951 (* 1 = 0.165951 loss)
I0906 06:04:08.119416 90901 sgd_solver.cpp:106] Iteration 86310, lr = 0.001
I0906 06:04:14.948035 90901 solver.cpp:228] Iteration 86320, loss = 0.260441
I0906 06:04:14.948109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260442 (* 1 = 0.260442 loss)
I0906 06:04:14.948127 90901 sgd_solver.cpp:106] Iteration 86320, lr = 0.001
I0906 06:04:21.994329 90901 solver.cpp:228] Iteration 86330, loss = 0.165991
I0906 06:04:21.994405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165991 (* 1 = 0.165991 loss)
I0906 06:04:21.994423 90901 sgd_solver.cpp:106] Iteration 86330, lr = 0.001
I0906 06:04:28.595994 90901 solver.cpp:228] Iteration 86340, loss = 0.0653999
I0906 06:04:28.596062 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0654006 (* 1 = 0.0654006 loss)
I0906 06:04:28.596081 90901 sgd_solver.cpp:106] Iteration 86340, lr = 0.001
I0906 06:04:35.630795 90901 solver.cpp:228] Iteration 86350, loss = 0.0904692
I0906 06:04:35.631153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.09047 (* 1 = 0.09047 loss)
I0906 06:04:35.631175 90901 sgd_solver.cpp:106] Iteration 86350, lr = 0.001
I0906 06:04:43.039701 90901 solver.cpp:228] Iteration 86360, loss = 0.421611
I0906 06:04:43.039829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.421612 (* 1 = 0.421612 loss)
I0906 06:04:43.039857 90901 sgd_solver.cpp:106] Iteration 86360, lr = 0.001
I0906 06:04:50.936995 90901 solver.cpp:228] Iteration 86370, loss = 0.410798
I0906 06:04:50.937077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410798 (* 1 = 0.410798 loss)
I0906 06:04:50.937098 90901 sgd_solver.cpp:106] Iteration 86370, lr = 0.001
I0906 06:04:57.788779 90901 solver.cpp:228] Iteration 86380, loss = 0.164164
I0906 06:04:57.788929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164165 (* 1 = 0.164165 loss)
I0906 06:04:57.788959 90901 sgd_solver.cpp:106] Iteration 86380, lr = 0.001
I0906 06:05:04.960139 90901 solver.cpp:228] Iteration 86390, loss = 0.0464556
I0906 06:05:04.960222 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0464564 (* 1 = 0.0464564 loss)
I0906 06:05:04.960242 90901 sgd_solver.cpp:106] Iteration 86390, lr = 0.001
I0906 06:05:11.760478 90901 solver.cpp:337] Iteration 86400, Testing net (#0)
I0906 06:06:03.630617 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.95
I0906 06:06:03.630760 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.139585 (* 1 = 0.139585 loss)
I0906 06:06:04.102135 90901 solver.cpp:228] Iteration 86400, loss = 0.0754568
I0906 06:06:04.102242 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0754576 (* 1 = 0.0754576 loss)
I0906 06:06:04.102269 90901 sgd_solver.cpp:106] Iteration 86400, lr = 0.001
I0906 06:06:11.274433 90901 solver.cpp:228] Iteration 86410, loss = 0.113302
I0906 06:06:11.274528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113303 (* 1 = 0.113303 loss)
I0906 06:06:11.274547 90901 sgd_solver.cpp:106] Iteration 86410, lr = 0.001
I0906 06:06:18.863430 90901 solver.cpp:228] Iteration 86420, loss = 0.218964
I0906 06:06:18.863500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218965 (* 1 = 0.218965 loss)
I0906 06:06:18.863517 90901 sgd_solver.cpp:106] Iteration 86420, lr = 0.001
I0906 06:06:26.301913 90901 solver.cpp:228] Iteration 86430, loss = 0.182686
I0906 06:06:26.301992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182687 (* 1 = 0.182687 loss)
I0906 06:06:26.302011 90901 sgd_solver.cpp:106] Iteration 86430, lr = 0.001
I0906 06:06:33.764554 90901 solver.cpp:228] Iteration 86440, loss = 0.0223334
I0906 06:06:33.764760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0223341 (* 1 = 0.0223341 loss)
I0906 06:06:33.764786 90901 sgd_solver.cpp:106] Iteration 86440, lr = 0.001
I0906 06:06:41.208163 90901 solver.cpp:228] Iteration 86450, loss = 0.254449
I0906 06:06:41.208248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25445 (* 1 = 0.25445 loss)
I0906 06:06:41.208274 90901 sgd_solver.cpp:106] Iteration 86450, lr = 0.001
I0906 06:06:48.295704 90901 solver.cpp:228] Iteration 86460, loss = 0.127153
I0906 06:06:48.295796 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127154 (* 1 = 0.127154 loss)
I0906 06:06:48.295819 90901 sgd_solver.cpp:106] Iteration 86460, lr = 0.001
I0906 06:06:55.358090 90901 solver.cpp:228] Iteration 86470, loss = 0.142529
I0906 06:06:55.358199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142529 (* 1 = 0.142529 loss)
I0906 06:06:55.358223 90901 sgd_solver.cpp:106] Iteration 86470, lr = 0.001
I0906 06:07:02.429498 90901 solver.cpp:228] Iteration 86480, loss = 0.091146
I0906 06:07:02.429643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0911467 (* 1 = 0.0911467 loss)
I0906 06:07:02.429669 90901 sgd_solver.cpp:106] Iteration 86480, lr = 0.001
I0906 06:07:09.453052 90901 solver.cpp:228] Iteration 86490, loss = 0.056078
I0906 06:07:09.453205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0560787 (* 1 = 0.0560787 loss)
I0906 06:07:09.453236 90901 sgd_solver.cpp:106] Iteration 86490, lr = 0.001
I0906 06:07:17.082074 90901 solver.cpp:228] Iteration 86500, loss = 0.46794
I0906 06:07:17.082206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.46794 (* 1 = 0.46794 loss)
I0906 06:07:17.082229 90901 sgd_solver.cpp:106] Iteration 86500, lr = 0.001
I0906 06:07:24.456718 90901 solver.cpp:228] Iteration 86510, loss = 0.230984
I0906 06:07:24.456897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230985 (* 1 = 0.230985 loss)
I0906 06:07:24.456925 90901 sgd_solver.cpp:106] Iteration 86510, lr = 0.001
I0906 06:07:32.195971 90901 solver.cpp:228] Iteration 86520, loss = 0.0329462
I0906 06:07:32.196048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0329469 (* 1 = 0.0329469 loss)
I0906 06:07:32.196064 90901 sgd_solver.cpp:106] Iteration 86520, lr = 0.001
I0906 06:07:40.184203 90901 solver.cpp:228] Iteration 86530, loss = 0.0811304
I0906 06:07:40.184435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.081131 (* 1 = 0.081131 loss)
I0906 06:07:40.184456 90901 sgd_solver.cpp:106] Iteration 86530, lr = 0.001
I0906 06:07:48.160897 90901 solver.cpp:228] Iteration 86540, loss = 0.348075
I0906 06:07:48.160984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348076 (* 1 = 0.348076 loss)
I0906 06:07:48.161005 90901 sgd_solver.cpp:106] Iteration 86540, lr = 0.001
I0906 06:07:56.290261 90901 solver.cpp:228] Iteration 86550, loss = 0.119205
I0906 06:07:56.290356 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119206 (* 1 = 0.119206 loss)
I0906 06:07:56.290380 90901 sgd_solver.cpp:106] Iteration 86550, lr = 0.001
I0906 06:08:04.317832 90901 solver.cpp:228] Iteration 86560, loss = 0.0300875
I0906 06:08:04.317901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0300881 (* 1 = 0.0300881 loss)
I0906 06:08:04.317917 90901 sgd_solver.cpp:106] Iteration 86560, lr = 0.001
I0906 06:08:12.560629 90901 solver.cpp:228] Iteration 86570, loss = 0.0225646
I0906 06:08:12.560839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0225652 (* 1 = 0.0225652 loss)
I0906 06:08:12.560858 90901 sgd_solver.cpp:106] Iteration 86570, lr = 0.001
I0906 06:08:20.186022 90901 solver.cpp:228] Iteration 86580, loss = 0.168041
I0906 06:08:20.186089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168042 (* 1 = 0.168042 loss)
I0906 06:08:20.186107 90901 sgd_solver.cpp:106] Iteration 86580, lr = 0.001
I0906 06:08:27.269831 90901 solver.cpp:228] Iteration 86590, loss = 0.0982903
I0906 06:08:27.269913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0982909 (* 1 = 0.0982909 loss)
I0906 06:08:27.269935 90901 sgd_solver.cpp:106] Iteration 86590, lr = 0.001
I0906 06:08:34.900439 90901 solver.cpp:228] Iteration 86600, loss = 0.107879
I0906 06:08:34.900524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10788 (* 1 = 0.10788 loss)
I0906 06:08:34.900542 90901 sgd_solver.cpp:106] Iteration 86600, lr = 0.001
I0906 06:08:42.544495 90901 solver.cpp:228] Iteration 86610, loss = 0.135362
I0906 06:08:42.544570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135363 (* 1 = 0.135363 loss)
I0906 06:08:42.544592 90901 sgd_solver.cpp:106] Iteration 86610, lr = 0.001
I0906 06:08:50.493618 90901 solver.cpp:228] Iteration 86620, loss = 0.16428
I0906 06:08:50.493813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164281 (* 1 = 0.164281 loss)
I0906 06:08:50.493844 90901 sgd_solver.cpp:106] Iteration 86620, lr = 0.001
I0906 06:08:58.357296 90901 solver.cpp:228] Iteration 86630, loss = 0.482613
I0906 06:08:58.357437 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482613 (* 1 = 0.482613 loss)
I0906 06:08:58.357483 90901 sgd_solver.cpp:106] Iteration 86630, lr = 0.001
I0906 06:09:05.273838 90901 solver.cpp:228] Iteration 86640, loss = 0.11352
I0906 06:09:05.274015 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11352 (* 1 = 0.11352 loss)
I0906 06:09:05.274040 90901 sgd_solver.cpp:106] Iteration 86640, lr = 0.001
I0906 06:09:12.940412 90901 solver.cpp:228] Iteration 86650, loss = 0.108512
I0906 06:09:12.940477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108512 (* 1 = 0.108512 loss)
I0906 06:09:12.940496 90901 sgd_solver.cpp:106] Iteration 86650, lr = 0.001
I0906 06:09:20.790277 90901 solver.cpp:228] Iteration 86660, loss = 0.145684
I0906 06:09:20.790472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145685 (* 1 = 0.145685 loss)
I0906 06:09:20.790493 90901 sgd_solver.cpp:106] Iteration 86660, lr = 0.001
I0906 06:09:28.424427 90901 solver.cpp:228] Iteration 86670, loss = 0.367827
I0906 06:09:28.424554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367827 (* 1 = 0.367827 loss)
I0906 06:09:28.424576 90901 sgd_solver.cpp:106] Iteration 86670, lr = 0.001
I0906 06:09:35.758136 90901 solver.cpp:228] Iteration 86680, loss = 0.0238578
I0906 06:09:35.758260 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0238584 (* 1 = 0.0238584 loss)
I0906 06:09:35.758282 90901 sgd_solver.cpp:106] Iteration 86680, lr = 0.001
I0906 06:09:43.875484 90901 solver.cpp:228] Iteration 86690, loss = 0.287349
I0906 06:09:43.875644 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28735 (* 1 = 0.28735 loss)
I0906 06:09:43.875689 90901 sgd_solver.cpp:106] Iteration 86690, lr = 0.001
I0906 06:09:50.699926 90901 solver.cpp:228] Iteration 86700, loss = 0.463536
I0906 06:09:50.700008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463537 (* 1 = 0.463537 loss)
I0906 06:09:50.700031 90901 sgd_solver.cpp:106] Iteration 86700, lr = 0.001
I0906 06:09:58.362831 90901 solver.cpp:228] Iteration 86710, loss = 0.112171
I0906 06:09:58.363113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112171 (* 1 = 0.112171 loss)
I0906 06:09:58.363132 90901 sgd_solver.cpp:106] Iteration 86710, lr = 0.001
I0906 06:10:05.785568 90901 solver.cpp:228] Iteration 86720, loss = 0.202015
I0906 06:10:05.785648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202016 (* 1 = 0.202016 loss)
I0906 06:10:05.785666 90901 sgd_solver.cpp:106] Iteration 86720, lr = 0.001
I0906 06:10:12.528463 90901 solver.cpp:228] Iteration 86730, loss = 0.248353
I0906 06:10:12.528530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248354 (* 1 = 0.248354 loss)
I0906 06:10:12.528548 90901 sgd_solver.cpp:106] Iteration 86730, lr = 0.001
I0906 06:10:20.601302 90901 solver.cpp:228] Iteration 86740, loss = 0.0249267
I0906 06:10:20.601369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0249274 (* 1 = 0.0249274 loss)
I0906 06:10:20.601385 90901 sgd_solver.cpp:106] Iteration 86740, lr = 0.001
I0906 06:10:27.744467 90901 solver.cpp:228] Iteration 86750, loss = 0.102071
I0906 06:10:27.744552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102072 (* 1 = 0.102072 loss)
I0906 06:10:27.744570 90901 sgd_solver.cpp:106] Iteration 86750, lr = 0.001
I0906 06:10:35.194167 90901 solver.cpp:228] Iteration 86760, loss = 0.0517739
I0906 06:10:35.194351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0517745 (* 1 = 0.0517745 loss)
I0906 06:10:35.194382 90901 sgd_solver.cpp:106] Iteration 86760, lr = 0.001
I0906 06:10:42.629938 90901 solver.cpp:228] Iteration 86770, loss = 0.242339
I0906 06:10:42.630022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24234 (* 1 = 0.24234 loss)
I0906 06:10:42.630044 90901 sgd_solver.cpp:106] Iteration 86770, lr = 0.001
I0906 06:10:50.030268 90901 solver.cpp:228] Iteration 86780, loss = 0.108131
I0906 06:10:50.030350 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108132 (* 1 = 0.108132 loss)
I0906 06:10:50.030367 90901 sgd_solver.cpp:106] Iteration 86780, lr = 0.001
I0906 06:10:57.855430 90901 solver.cpp:228] Iteration 86790, loss = 0.0710529
I0906 06:10:57.855520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0710535 (* 1 = 0.0710535 loss)
I0906 06:10:57.855538 90901 sgd_solver.cpp:106] Iteration 86790, lr = 0.001
I0906 06:11:05.505511 90901 solver.cpp:228] Iteration 86800, loss = 0.0648208
I0906 06:11:05.505659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0648214 (* 1 = 0.0648214 loss)
I0906 06:11:05.505681 90901 sgd_solver.cpp:106] Iteration 86800, lr = 0.001
I0906 06:11:12.939432 90901 solver.cpp:228] Iteration 86810, loss = 0.059951
I0906 06:11:12.939510 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0599517 (* 1 = 0.0599517 loss)
I0906 06:11:12.939529 90901 sgd_solver.cpp:106] Iteration 86810, lr = 0.001
I0906 06:11:21.018082 90901 solver.cpp:228] Iteration 86820, loss = 0.0810419
I0906 06:11:21.018160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0810426 (* 1 = 0.0810426 loss)
I0906 06:11:21.018178 90901 sgd_solver.cpp:106] Iteration 86820, lr = 0.001
I0906 06:11:28.397379 90901 solver.cpp:228] Iteration 86830, loss = 0.0520355
I0906 06:11:28.397512 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0520362 (* 1 = 0.0520362 loss)
I0906 06:11:28.397534 90901 sgd_solver.cpp:106] Iteration 86830, lr = 0.001
I0906 06:11:36.017063 90901 solver.cpp:228] Iteration 86840, loss = 0.127186
I0906 06:11:36.017354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127187 (* 1 = 0.127187 loss)
I0906 06:11:36.017374 90901 sgd_solver.cpp:106] Iteration 86840, lr = 0.001
I0906 06:11:43.644093 90901 solver.cpp:228] Iteration 86850, loss = 0.0529186
I0906 06:11:43.644160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0529193 (* 1 = 0.0529193 loss)
I0906 06:11:43.644181 90901 sgd_solver.cpp:106] Iteration 86850, lr = 0.001
I0906 06:11:50.691256 90901 solver.cpp:228] Iteration 86860, loss = 0.0862533
I0906 06:11:50.691319 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0862541 (* 1 = 0.0862541 loss)
I0906 06:11:50.691336 90901 sgd_solver.cpp:106] Iteration 86860, lr = 0.001
I0906 06:11:58.328832 90901 solver.cpp:228] Iteration 86870, loss = 0.0639024
I0906 06:11:58.328922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0639032 (* 1 = 0.0639032 loss)
I0906 06:11:58.328944 90901 sgd_solver.cpp:106] Iteration 86870, lr = 0.001
I0906 06:12:06.453158 90901 solver.cpp:228] Iteration 86880, loss = 0.0973501
I0906 06:12:06.453814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0973509 (* 1 = 0.0973509 loss)
I0906 06:12:06.453852 90901 sgd_solver.cpp:106] Iteration 86880, lr = 0.001
I0906 06:12:14.396247 90901 solver.cpp:228] Iteration 86890, loss = 0.0218881
I0906 06:12:14.396400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0218889 (* 1 = 0.0218889 loss)
I0906 06:12:14.396427 90901 sgd_solver.cpp:106] Iteration 86890, lr = 0.001
I0906 06:12:21.680465 90901 solver.cpp:228] Iteration 86900, loss = 0.148898
I0906 06:12:21.680529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148899 (* 1 = 0.148899 loss)
I0906 06:12:21.680546 90901 sgd_solver.cpp:106] Iteration 86900, lr = 0.001
I0906 06:12:29.320979 90901 solver.cpp:228] Iteration 86910, loss = 0.155051
I0906 06:12:29.321059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155052 (* 1 = 0.155052 loss)
I0906 06:12:29.321084 90901 sgd_solver.cpp:106] Iteration 86910, lr = 0.001
I0906 06:12:36.339159 90901 solver.cpp:228] Iteration 86920, loss = 0.0969455
I0906 06:12:36.339246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0969463 (* 1 = 0.0969463 loss)
I0906 06:12:36.339262 90901 sgd_solver.cpp:106] Iteration 86920, lr = 0.001
I0906 06:12:43.962888 90901 solver.cpp:228] Iteration 86930, loss = 0.282743
I0906 06:12:43.963392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282744 (* 1 = 0.282744 loss)
I0906 06:12:43.963415 90901 sgd_solver.cpp:106] Iteration 86930, lr = 0.001
I0906 06:12:51.760399 90901 solver.cpp:228] Iteration 86940, loss = 0.110915
I0906 06:12:51.760475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110916 (* 1 = 0.110916 loss)
I0906 06:12:51.760493 90901 sgd_solver.cpp:106] Iteration 86940, lr = 0.001
I0906 06:12:58.929129 90901 solver.cpp:228] Iteration 86950, loss = 0.135262
I0906 06:12:58.929185 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135263 (* 1 = 0.135263 loss)
I0906 06:12:58.929203 90901 sgd_solver.cpp:106] Iteration 86950, lr = 0.001
I0906 06:13:06.755434 90901 solver.cpp:228] Iteration 86960, loss = 0.274015
I0906 06:13:06.755513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.274016 (* 1 = 0.274016 loss)
I0906 06:13:06.755537 90901 sgd_solver.cpp:106] Iteration 86960, lr = 0.001
I0906 06:13:14.916625 90901 solver.cpp:228] Iteration 86970, loss = 0.123998
I0906 06:13:14.916798 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123999 (* 1 = 0.123999 loss)
I0906 06:13:14.916824 90901 sgd_solver.cpp:106] Iteration 86970, lr = 0.001
I0906 06:13:22.509268 90901 solver.cpp:228] Iteration 86980, loss = 0.220577
I0906 06:13:22.509344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220577 (* 1 = 0.220577 loss)
I0906 06:13:22.509362 90901 sgd_solver.cpp:106] Iteration 86980, lr = 0.001
I0906 06:13:30.128119 90901 solver.cpp:228] Iteration 86990, loss = 0.240261
I0906 06:13:30.128195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.240262 (* 1 = 0.240262 loss)
I0906 06:13:30.128211 90901 sgd_solver.cpp:106] Iteration 86990, lr = 0.001
I0906 06:13:37.638716 90901 solver.cpp:228] Iteration 87000, loss = 0.0857886
I0906 06:13:37.638789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0857894 (* 1 = 0.0857894 loss)
I0906 06:13:37.638808 90901 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I0906 06:13:45.411298 90901 solver.cpp:228] Iteration 87010, loss = 0.0383071
I0906 06:13:45.411752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0383079 (* 1 = 0.0383079 loss)
I0906 06:13:45.411777 90901 sgd_solver.cpp:106] Iteration 87010, lr = 0.001
I0906 06:13:52.744894 90901 solver.cpp:228] Iteration 87020, loss = 0.0990913
I0906 06:13:52.744982 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0990921 (* 1 = 0.0990921 loss)
I0906 06:13:52.745000 90901 sgd_solver.cpp:106] Iteration 87020, lr = 0.001
I0906 06:14:00.402328 90901 solver.cpp:228] Iteration 87030, loss = 0.0711384
I0906 06:14:00.402389 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0711393 (* 1 = 0.0711393 loss)
I0906 06:14:00.402405 90901 sgd_solver.cpp:106] Iteration 87030, lr = 0.001
I0906 06:14:07.423660 90901 solver.cpp:228] Iteration 87040, loss = 0.179839
I0906 06:14:07.423727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17984 (* 1 = 0.17984 loss)
I0906 06:14:07.423743 90901 sgd_solver.cpp:106] Iteration 87040, lr = 0.001
I0906 06:14:14.773043 90901 solver.cpp:228] Iteration 87050, loss = 0.0949812
I0906 06:14:14.773126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.094982 (* 1 = 0.094982 loss)
I0906 06:14:14.773144 90901 sgd_solver.cpp:106] Iteration 87050, lr = 0.001
I0906 06:14:22.614570 90901 solver.cpp:228] Iteration 87060, loss = 0.05821
I0906 06:14:22.614820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0582108 (* 1 = 0.0582108 loss)
I0906 06:14:22.614840 90901 sgd_solver.cpp:106] Iteration 87060, lr = 0.001
I0906 06:14:29.717303 90901 solver.cpp:228] Iteration 87070, loss = 0.171933
I0906 06:14:29.717376 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171934 (* 1 = 0.171934 loss)
I0906 06:14:29.717391 90901 sgd_solver.cpp:106] Iteration 87070, lr = 0.001
I0906 06:14:36.963373 90901 solver.cpp:228] Iteration 87080, loss = 0.257899
I0906 06:14:36.963464 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2579 (* 1 = 0.2579 loss)
I0906 06:14:36.963486 90901 sgd_solver.cpp:106] Iteration 87080, lr = 0.001
I0906 06:14:44.363112 90901 solver.cpp:228] Iteration 87090, loss = 0.0490037
I0906 06:14:44.363186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0490044 (* 1 = 0.0490044 loss)
I0906 06:14:44.363204 90901 sgd_solver.cpp:106] Iteration 87090, lr = 0.001
I0906 06:14:50.729794 90901 solver.cpp:228] Iteration 87100, loss = 0.277568
I0906 06:14:50.729874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.277569 (* 1 = 0.277569 loss)
I0906 06:14:50.729892 90901 sgd_solver.cpp:106] Iteration 87100, lr = 0.001
I0906 06:14:58.389482 90901 solver.cpp:228] Iteration 87110, loss = 0.164789
I0906 06:14:58.389683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164789 (* 1 = 0.164789 loss)
I0906 06:14:58.389714 90901 sgd_solver.cpp:106] Iteration 87110, lr = 0.001
I0906 06:15:04.650136 90901 solver.cpp:228] Iteration 87120, loss = 0.0505941
I0906 06:15:04.650261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0505949 (* 1 = 0.0505949 loss)
I0906 06:15:04.650281 90901 sgd_solver.cpp:106] Iteration 87120, lr = 0.001
I0906 06:15:12.048271 90901 solver.cpp:228] Iteration 87130, loss = 0.0619901
I0906 06:15:12.048333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0619909 (* 1 = 0.0619909 loss)
I0906 06:15:12.048349 90901 sgd_solver.cpp:106] Iteration 87130, lr = 0.001
I0906 06:15:18.624156 90901 solver.cpp:228] Iteration 87140, loss = 0.0684774
I0906 06:15:18.624245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684781 (* 1 = 0.0684781 loss)
I0906 06:15:18.624264 90901 sgd_solver.cpp:106] Iteration 87140, lr = 0.001
I0906 06:15:24.412377 90901 solver.cpp:228] Iteration 87150, loss = 0.0427513
I0906 06:15:24.412477 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0427521 (* 1 = 0.0427521 loss)
I0906 06:15:24.412497 90901 sgd_solver.cpp:106] Iteration 87150, lr = 0.001
I0906 06:15:29.957309 90901 solver.cpp:228] Iteration 87160, loss = 0.0541246
I0906 06:15:29.957895 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0541254 (* 1 = 0.0541254 loss)
I0906 06:15:29.957926 90901 sgd_solver.cpp:106] Iteration 87160, lr = 0.001
I0906 06:15:35.190246 90901 solver.cpp:228] Iteration 87170, loss = 0.0938891
I0906 06:15:35.190317 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0938899 (* 1 = 0.0938899 loss)
I0906 06:15:35.190333 90901 sgd_solver.cpp:106] Iteration 87170, lr = 0.001
I0906 06:15:40.406373 90901 solver.cpp:228] Iteration 87180, loss = 0.174763
I0906 06:15:40.406461 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174763 (* 1 = 0.174763 loss)
I0906 06:15:40.406479 90901 sgd_solver.cpp:106] Iteration 87180, lr = 0.001
I0906 06:15:45.972297 90901 solver.cpp:228] Iteration 87190, loss = 0.0548827
I0906 06:15:45.972362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0548835 (* 1 = 0.0548835 loss)
I0906 06:15:45.972378 90901 sgd_solver.cpp:106] Iteration 87190, lr = 0.001
I0906 06:15:50.910096 90901 solver.cpp:337] Iteration 87200, Testing net (#0)
I0906 06:16:35.779259 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.936875
I0906 06:16:35.779399 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.171723 (* 1 = 0.171723 loss)
I0906 06:16:36.068222 90901 solver.cpp:228] Iteration 87200, loss = 0.0177512
I0906 06:16:36.068286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0177519 (* 1 = 0.0177519 loss)
I0906 06:16:36.068308 90901 sgd_solver.cpp:106] Iteration 87200, lr = 0.001
I0906 06:16:43.164757 90901 solver.cpp:228] Iteration 87210, loss = 0.115301
I0906 06:16:43.164814 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115302 (* 1 = 0.115302 loss)
I0906 06:16:43.164830 90901 sgd_solver.cpp:106] Iteration 87210, lr = 0.001
I0906 06:16:51.383095 90901 solver.cpp:228] Iteration 87220, loss = 0.199127
I0906 06:16:51.383175 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199128 (* 1 = 0.199128 loss)
I0906 06:16:51.383194 90901 sgd_solver.cpp:106] Iteration 87220, lr = 0.001
I0906 06:16:58.913239 90901 solver.cpp:228] Iteration 87230, loss = 0.305797
I0906 06:16:58.913313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.305797 (* 1 = 0.305797 loss)
I0906 06:16:58.913329 90901 sgd_solver.cpp:106] Iteration 87230, lr = 0.001
I0906 06:17:06.731494 90901 solver.cpp:228] Iteration 87240, loss = 0.0325115
I0906 06:17:06.731729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0325121 (* 1 = 0.0325121 loss)
I0906 06:17:06.731775 90901 sgd_solver.cpp:106] Iteration 87240, lr = 0.001
I0906 06:17:14.598845 90901 solver.cpp:228] Iteration 87250, loss = 0.0719436
I0906 06:17:14.598973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0719443 (* 1 = 0.0719443 loss)
I0906 06:17:14.598991 90901 sgd_solver.cpp:106] Iteration 87250, lr = 0.001
I0906 06:17:22.741853 90901 solver.cpp:228] Iteration 87260, loss = 0.208942
I0906 06:17:22.741925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208943 (* 1 = 0.208943 loss)
I0906 06:17:22.741956 90901 sgd_solver.cpp:106] Iteration 87260, lr = 0.001
I0906 06:17:30.580992 90901 solver.cpp:228] Iteration 87270, loss = 0.301559
I0906 06:17:30.581073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30156 (* 1 = 0.30156 loss)
I0906 06:17:30.581091 90901 sgd_solver.cpp:106] Iteration 87270, lr = 0.001
I0906 06:17:38.463351 90901 solver.cpp:228] Iteration 87280, loss = 0.0645102
I0906 06:17:38.463559 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0645109 (* 1 = 0.0645109 loss)
I0906 06:17:38.463590 90901 sgd_solver.cpp:106] Iteration 87280, lr = 0.001
I0906 06:17:46.040695 90901 solver.cpp:228] Iteration 87290, loss = 0.036928
I0906 06:17:46.040774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0369287 (* 1 = 0.0369287 loss)
I0906 06:17:46.040792 90901 sgd_solver.cpp:106] Iteration 87290, lr = 0.001
I0906 06:17:53.964016 90901 solver.cpp:228] Iteration 87300, loss = 0.0490865
I0906 06:17:53.964112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0490871 (* 1 = 0.0490871 loss)
I0906 06:17:53.964133 90901 sgd_solver.cpp:106] Iteration 87300, lr = 0.001
I0906 06:18:02.031527 90901 solver.cpp:228] Iteration 87310, loss = 0.103284
I0906 06:18:02.031596 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103285 (* 1 = 0.103285 loss)
I0906 06:18:02.031615 90901 sgd_solver.cpp:106] Iteration 87310, lr = 0.001
I0906 06:18:09.765856 90901 solver.cpp:228] Iteration 87320, loss = 0.0904661
I0906 06:18:09.766086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0904668 (* 1 = 0.0904668 loss)
I0906 06:18:09.766109 90901 sgd_solver.cpp:106] Iteration 87320, lr = 0.001
I0906 06:18:17.200896 90901 solver.cpp:228] Iteration 87330, loss = 0.0967633
I0906 06:18:17.200973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0967639 (* 1 = 0.0967639 loss)
I0906 06:18:17.200990 90901 sgd_solver.cpp:106] Iteration 87330, lr = 0.001
I0906 06:18:24.589823 90901 solver.cpp:228] Iteration 87340, loss = 0.325851
I0906 06:18:24.589884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325852 (* 1 = 0.325852 loss)
I0906 06:18:24.589901 90901 sgd_solver.cpp:106] Iteration 87340, lr = 0.001
I0906 06:18:32.672219 90901 solver.cpp:228] Iteration 87350, loss = 0.0406199
I0906 06:18:32.672315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0406206 (* 1 = 0.0406206 loss)
I0906 06:18:32.672334 90901 sgd_solver.cpp:106] Iteration 87350, lr = 0.001
I0906 06:18:40.799108 90901 solver.cpp:228] Iteration 87360, loss = 0.342716
I0906 06:18:40.799300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342716 (* 1 = 0.342716 loss)
I0906 06:18:40.799341 90901 sgd_solver.cpp:106] Iteration 87360, lr = 0.001
I0906 06:18:48.181762 90901 solver.cpp:228] Iteration 87370, loss = 0.232422
I0906 06:18:48.181890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232422 (* 1 = 0.232422 loss)
I0906 06:18:48.181911 90901 sgd_solver.cpp:106] Iteration 87370, lr = 0.001
I0906 06:18:56.124475 90901 solver.cpp:228] Iteration 87380, loss = 0.265026
I0906 06:18:56.124624 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265026 (* 1 = 0.265026 loss)
I0906 06:18:56.124644 90901 sgd_solver.cpp:106] Iteration 87380, lr = 0.001
I0906 06:19:03.741302 90901 solver.cpp:228] Iteration 87390, loss = 0.192319
I0906 06:19:03.741369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192319 (* 1 = 0.192319 loss)
I0906 06:19:03.741387 90901 sgd_solver.cpp:106] Iteration 87390, lr = 0.001
I0906 06:19:11.607326 90901 solver.cpp:228] Iteration 87400, loss = 0.0619383
I0906 06:19:11.607524 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0619389 (* 1 = 0.0619389 loss)
I0906 06:19:11.607544 90901 sgd_solver.cpp:106] Iteration 87400, lr = 0.001
I0906 06:19:19.467262 90901 solver.cpp:228] Iteration 87410, loss = 0.351225
I0906 06:19:19.467344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.351225 (* 1 = 0.351225 loss)
I0906 06:19:19.467360 90901 sgd_solver.cpp:106] Iteration 87410, lr = 0.001
I0906 06:19:27.322887 90901 solver.cpp:228] Iteration 87420, loss = 0.187188
I0906 06:19:27.322957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187188 (* 1 = 0.187188 loss)
I0906 06:19:27.322973 90901 sgd_solver.cpp:106] Iteration 87420, lr = 0.001
I0906 06:19:34.704007 90901 solver.cpp:228] Iteration 87430, loss = 0.051907
I0906 06:19:34.704113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0519077 (* 1 = 0.0519077 loss)
I0906 06:19:34.704133 90901 sgd_solver.cpp:106] Iteration 87430, lr = 0.001
I0906 06:19:42.873255 90901 solver.cpp:228] Iteration 87440, loss = 0.250326
I0906 06:19:42.873519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250326 (* 1 = 0.250326 loss)
I0906 06:19:42.873544 90901 sgd_solver.cpp:106] Iteration 87440, lr = 0.001
I0906 06:19:50.466675 90901 solver.cpp:228] Iteration 87450, loss = 0.161408
I0906 06:19:50.466752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161409 (* 1 = 0.161409 loss)
I0906 06:19:50.466769 90901 sgd_solver.cpp:106] Iteration 87450, lr = 0.001
I0906 06:19:58.809355 90901 solver.cpp:228] Iteration 87460, loss = 0.199828
I0906 06:19:58.809438 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199828 (* 1 = 0.199828 loss)
I0906 06:19:58.809456 90901 sgd_solver.cpp:106] Iteration 87460, lr = 0.001
I0906 06:20:06.430716 90901 solver.cpp:228] Iteration 87470, loss = 0.121678
I0906 06:20:06.430811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121678 (* 1 = 0.121678 loss)
I0906 06:20:06.430835 90901 sgd_solver.cpp:106] Iteration 87470, lr = 0.001
I0906 06:20:14.427355 90901 solver.cpp:228] Iteration 87480, loss = 0.25769
I0906 06:20:14.427536 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257691 (* 1 = 0.257691 loss)
I0906 06:20:14.427567 90901 sgd_solver.cpp:106] Iteration 87480, lr = 0.001
I0906 06:20:21.779335 90901 solver.cpp:228] Iteration 87490, loss = 0.122296
I0906 06:20:21.779392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122297 (* 1 = 0.122297 loss)
I0906 06:20:21.779409 90901 sgd_solver.cpp:106] Iteration 87490, lr = 0.001
I0906 06:20:29.903659 90901 solver.cpp:228] Iteration 87500, loss = 0.050575
I0906 06:20:29.903723 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0505757 (* 1 = 0.0505757 loss)
I0906 06:20:29.903740 90901 sgd_solver.cpp:106] Iteration 87500, lr = 0.001
I0906 06:20:37.525288 90901 solver.cpp:228] Iteration 87510, loss = 0.150847
I0906 06:20:37.525369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150847 (* 1 = 0.150847 loss)
I0906 06:20:37.525387 90901 sgd_solver.cpp:106] Iteration 87510, lr = 0.001
I0906 06:20:44.833784 90901 solver.cpp:228] Iteration 87520, loss = 0.0480208
I0906 06:20:44.833948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0480215 (* 1 = 0.0480215 loss)
I0906 06:20:44.833979 90901 sgd_solver.cpp:106] Iteration 87520, lr = 0.001
I0906 06:20:52.951792 90901 solver.cpp:228] Iteration 87530, loss = 0.196657
I0906 06:20:52.951866 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196658 (* 1 = 0.196658 loss)
I0906 06:20:52.951884 90901 sgd_solver.cpp:106] Iteration 87530, lr = 0.001
I0906 06:21:00.633334 90901 solver.cpp:228] Iteration 87540, loss = 0.196157
I0906 06:21:00.633424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196157 (* 1 = 0.196157 loss)
I0906 06:21:00.633448 90901 sgd_solver.cpp:106] Iteration 87540, lr = 0.001
I0906 06:21:08.397765 90901 solver.cpp:228] Iteration 87550, loss = 0.291269
I0906 06:21:08.397840 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29127 (* 1 = 0.29127 loss)
I0906 06:21:08.397858 90901 sgd_solver.cpp:106] Iteration 87550, lr = 0.001
I0906 06:21:16.057672 90901 solver.cpp:228] Iteration 87560, loss = 0.195739
I0906 06:21:16.057878 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19574 (* 1 = 0.19574 loss)
I0906 06:21:16.057896 90901 sgd_solver.cpp:106] Iteration 87560, lr = 0.001
I0906 06:21:24.321557 90901 solver.cpp:228] Iteration 87570, loss = 0.0280549
I0906 06:21:24.321629 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0280557 (* 1 = 0.0280557 loss)
I0906 06:21:24.321645 90901 sgd_solver.cpp:106] Iteration 87570, lr = 0.001
I0906 06:21:31.834475 90901 solver.cpp:228] Iteration 87580, loss = 0.0896327
I0906 06:21:31.834620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0896335 (* 1 = 0.0896335 loss)
I0906 06:21:31.834717 90901 sgd_solver.cpp:106] Iteration 87580, lr = 0.001
I0906 06:21:41.020004 90901 solver.cpp:228] Iteration 87590, loss = 0.135204
I0906 06:21:41.020072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135205 (* 1 = 0.135205 loss)
I0906 06:21:41.020090 90901 sgd_solver.cpp:106] Iteration 87590, lr = 0.001
I0906 06:21:49.085084 90901 solver.cpp:228] Iteration 87600, loss = 0.0960946
I0906 06:21:49.085544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0960954 (* 1 = 0.0960954 loss)
I0906 06:21:49.085574 90901 sgd_solver.cpp:106] Iteration 87600, lr = 0.001
I0906 06:21:57.233103 90901 solver.cpp:228] Iteration 87610, loss = 0.0343167
I0906 06:21:57.233225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0343174 (* 1 = 0.0343174 loss)
I0906 06:21:57.233248 90901 sgd_solver.cpp:106] Iteration 87610, lr = 0.001
I0906 06:22:02.566309 90901 solver.cpp:228] Iteration 87620, loss = 0.0505392
I0906 06:22:02.566408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.05054 (* 1 = 0.05054 loss)
I0906 06:22:02.566432 90901 sgd_solver.cpp:106] Iteration 87620, lr = 0.001
I0906 06:22:08.190726 90901 solver.cpp:228] Iteration 87630, loss = 0.225117
I0906 06:22:08.190820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225118 (* 1 = 0.225118 loss)
I0906 06:22:08.190843 90901 sgd_solver.cpp:106] Iteration 87630, lr = 0.001
I0906 06:22:14.351676 90901 solver.cpp:228] Iteration 87640, loss = 0.155629
I0906 06:22:14.351773 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15563 (* 1 = 0.15563 loss)
I0906 06:22:14.351796 90901 sgd_solver.cpp:106] Iteration 87640, lr = 0.001
I0906 06:22:22.539072 90901 solver.cpp:228] Iteration 87650, loss = 0.0706231
I0906 06:22:22.539270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0706239 (* 1 = 0.0706239 loss)
I0906 06:22:22.539299 90901 sgd_solver.cpp:106] Iteration 87650, lr = 0.001
I0906 06:22:30.511495 90901 solver.cpp:228] Iteration 87660, loss = 0.0460263
I0906 06:22:30.511569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0460271 (* 1 = 0.0460271 loss)
I0906 06:22:30.511584 90901 sgd_solver.cpp:106] Iteration 87660, lr = 0.001
I0906 06:22:39.155745 90901 solver.cpp:228] Iteration 87670, loss = 0.0607704
I0906 06:22:39.155819 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0607712 (* 1 = 0.0607712 loss)
I0906 06:22:39.155838 90901 sgd_solver.cpp:106] Iteration 87670, lr = 0.001
I0906 06:22:47.353277 90901 solver.cpp:228] Iteration 87680, loss = 0.119891
I0906 06:22:47.353355 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119892 (* 1 = 0.119892 loss)
I0906 06:22:47.353373 90901 sgd_solver.cpp:106] Iteration 87680, lr = 0.001
I0906 06:22:56.435719 90901 solver.cpp:228] Iteration 87690, loss = 0.0855842
I0906 06:22:56.435966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.085585 (* 1 = 0.085585 loss)
I0906 06:22:56.435986 90901 sgd_solver.cpp:106] Iteration 87690, lr = 0.001
I0906 06:23:04.948463 90901 solver.cpp:228] Iteration 87700, loss = 0.0664323
I0906 06:23:04.948554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0664331 (* 1 = 0.0664331 loss)
I0906 06:23:04.948572 90901 sgd_solver.cpp:106] Iteration 87700, lr = 0.001
I0906 06:23:13.316943 90901 solver.cpp:228] Iteration 87710, loss = 0.185938
I0906 06:23:13.317010 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185939 (* 1 = 0.185939 loss)
I0906 06:23:13.317026 90901 sgd_solver.cpp:106] Iteration 87710, lr = 0.001
I0906 06:23:21.590167 90901 solver.cpp:228] Iteration 87720, loss = 0.188884
I0906 06:23:21.590252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.188884 (* 1 = 0.188884 loss)
I0906 06:23:21.590270 90901 sgd_solver.cpp:106] Iteration 87720, lr = 0.001
I0906 06:23:30.154594 90901 solver.cpp:228] Iteration 87730, loss = 0.0705684
I0906 06:23:30.154966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0705692 (* 1 = 0.0705692 loss)
I0906 06:23:30.154988 90901 sgd_solver.cpp:106] Iteration 87730, lr = 0.001
I0906 06:23:38.322090 90901 solver.cpp:228] Iteration 87740, loss = 0.141413
I0906 06:23:38.322223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141414 (* 1 = 0.141414 loss)
I0906 06:23:38.322244 90901 sgd_solver.cpp:106] Iteration 87740, lr = 0.001
I0906 06:23:46.691321 90901 solver.cpp:228] Iteration 87750, loss = 0.0664817
I0906 06:23:46.691392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0664826 (* 1 = 0.0664826 loss)
I0906 06:23:46.691409 90901 sgd_solver.cpp:106] Iteration 87750, lr = 0.001
I0906 06:23:54.807502 90901 solver.cpp:228] Iteration 87760, loss = 0.134926
I0906 06:23:54.807585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134927 (* 1 = 0.134927 loss)
I0906 06:23:54.807603 90901 sgd_solver.cpp:106] Iteration 87760, lr = 0.001
I0906 06:24:02.960108 90901 solver.cpp:228] Iteration 87770, loss = 0.0684968
I0906 06:24:02.960326 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684977 (* 1 = 0.0684977 loss)
I0906 06:24:02.960356 90901 sgd_solver.cpp:106] Iteration 87770, lr = 0.001
I0906 06:24:10.869833 90901 solver.cpp:228] Iteration 87780, loss = 0.363021
I0906 06:24:10.869899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363022 (* 1 = 0.363022 loss)
I0906 06:24:10.869915 90901 sgd_solver.cpp:106] Iteration 87780, lr = 0.001
I0906 06:24:18.825122 90901 solver.cpp:228] Iteration 87790, loss = 0.286723
I0906 06:24:18.825191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.286723 (* 1 = 0.286723 loss)
I0906 06:24:18.825209 90901 sgd_solver.cpp:106] Iteration 87790, lr = 0.001
I0906 06:24:26.888459 90901 solver.cpp:228] Iteration 87800, loss = 0.167104
I0906 06:24:26.888526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167105 (* 1 = 0.167105 loss)
I0906 06:24:26.888545 90901 sgd_solver.cpp:106] Iteration 87800, lr = 0.001
I0906 06:24:34.631289 90901 solver.cpp:228] Iteration 87810, loss = 0.0863176
I0906 06:24:34.631436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0863185 (* 1 = 0.0863185 loss)
I0906 06:24:34.631455 90901 sgd_solver.cpp:106] Iteration 87810, lr = 0.001
I0906 06:24:42.938381 90901 solver.cpp:228] Iteration 87820, loss = 0.184009
I0906 06:24:42.938459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.184009 (* 1 = 0.184009 loss)
I0906 06:24:42.938477 90901 sgd_solver.cpp:106] Iteration 87820, lr = 0.001
I0906 06:24:50.728126 90901 solver.cpp:228] Iteration 87830, loss = 0.13511
I0906 06:24:50.728232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135111 (* 1 = 0.135111 loss)
I0906 06:24:50.728268 90901 sgd_solver.cpp:106] Iteration 87830, lr = 0.001
I0906 06:24:58.394738 90901 solver.cpp:228] Iteration 87840, loss = 0.0794793
I0906 06:24:58.394845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0794801 (* 1 = 0.0794801 loss)
I0906 06:24:58.394863 90901 sgd_solver.cpp:106] Iteration 87840, lr = 0.001
I0906 06:25:06.196472 90901 solver.cpp:228] Iteration 87850, loss = 0.261768
I0906 06:25:06.196766 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261769 (* 1 = 0.261769 loss)
I0906 06:25:06.196796 90901 sgd_solver.cpp:106] Iteration 87850, lr = 0.001
I0906 06:25:13.821866 90901 solver.cpp:228] Iteration 87860, loss = 0.0568553
I0906 06:25:13.821959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0568561 (* 1 = 0.0568561 loss)
I0906 06:25:13.821977 90901 sgd_solver.cpp:106] Iteration 87860, lr = 0.001
I0906 06:25:21.724558 90901 solver.cpp:228] Iteration 87870, loss = 0.0432801
I0906 06:25:21.724639 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0432809 (* 1 = 0.0432809 loss)
I0906 06:25:21.724658 90901 sgd_solver.cpp:106] Iteration 87870, lr = 0.001
I0906 06:25:29.828294 90901 solver.cpp:228] Iteration 87880, loss = 0.0716125
I0906 06:25:29.828404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0716134 (* 1 = 0.0716134 loss)
I0906 06:25:29.828423 90901 sgd_solver.cpp:106] Iteration 87880, lr = 0.001
I0906 06:25:37.721423 90901 solver.cpp:228] Iteration 87890, loss = 0.206905
I0906 06:25:37.721750 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206906 (* 1 = 0.206906 loss)
I0906 06:25:37.721776 90901 sgd_solver.cpp:106] Iteration 87890, lr = 0.001
I0906 06:25:45.124367 90901 solver.cpp:228] Iteration 87900, loss = 0.261867
I0906 06:25:45.124444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.261868 (* 1 = 0.261868 loss)
I0906 06:25:45.124461 90901 sgd_solver.cpp:106] Iteration 87900, lr = 0.001
I0906 06:25:53.138957 90901 solver.cpp:228] Iteration 87910, loss = 0.248693
I0906 06:25:53.139071 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248694 (* 1 = 0.248694 loss)
I0906 06:25:53.139099 90901 sgd_solver.cpp:106] Iteration 87910, lr = 0.001
I0906 06:26:01.262989 90901 solver.cpp:228] Iteration 87920, loss = 0.201752
I0906 06:26:01.263072 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201753 (* 1 = 0.201753 loss)
I0906 06:26:01.263093 90901 sgd_solver.cpp:106] Iteration 87920, lr = 0.001
I0906 06:26:09.129732 90901 solver.cpp:228] Iteration 87930, loss = 0.195701
I0906 06:26:09.129884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195702 (* 1 = 0.195702 loss)
I0906 06:26:09.129901 90901 sgd_solver.cpp:106] Iteration 87930, lr = 0.001
I0906 06:26:17.238167 90901 solver.cpp:228] Iteration 87940, loss = 0.0758992
I0906 06:26:17.238231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0759001 (* 1 = 0.0759001 loss)
I0906 06:26:17.238248 90901 sgd_solver.cpp:106] Iteration 87940, lr = 0.001
I0906 06:26:25.323176 90901 solver.cpp:228] Iteration 87950, loss = 0.449664
I0906 06:26:25.323238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.449665 (* 1 = 0.449665 loss)
I0906 06:26:25.323256 90901 sgd_solver.cpp:106] Iteration 87950, lr = 0.001
I0906 06:26:32.850697 90901 solver.cpp:228] Iteration 87960, loss = 0.133194
I0906 06:26:32.851032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133195 (* 1 = 0.133195 loss)
I0906 06:26:32.851066 90901 sgd_solver.cpp:106] Iteration 87960, lr = 0.001
I0906 06:26:41.274684 90901 solver.cpp:228] Iteration 87970, loss = 0.141005
I0906 06:26:41.274863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141006 (* 1 = 0.141006 loss)
I0906 06:26:41.274881 90901 sgd_solver.cpp:106] Iteration 87970, lr = 0.001
I0906 06:26:50.405514 90901 solver.cpp:228] Iteration 87980, loss = 0.263991
I0906 06:26:50.405576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263992 (* 1 = 0.263992 loss)
I0906 06:26:50.405594 90901 sgd_solver.cpp:106] Iteration 87980, lr = 0.001
I0906 06:26:57.596204 90901 solver.cpp:228] Iteration 87990, loss = 0.556867
I0906 06:26:57.596297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.556868 (* 1 = 0.556868 loss)
I0906 06:26:57.596314 90901 sgd_solver.cpp:106] Iteration 87990, lr = 0.001
I0906 06:27:05.036609 90901 solver.cpp:337] Iteration 88000, Testing net (#0)
I0906 06:27:55.635592 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.947187
I0906 06:27:55.635828 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.144958 (* 1 = 0.144958 loss)
I0906 06:27:56.069653 90901 solver.cpp:228] Iteration 88000, loss = 0.0370146
I0906 06:27:56.069710 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0370156 (* 1 = 0.0370156 loss)
I0906 06:27:56.069731 90901 sgd_solver.cpp:106] Iteration 88000, lr = 0.001
I0906 06:28:03.383174 90901 solver.cpp:228] Iteration 88010, loss = 0.368588
I0906 06:28:03.383242 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.368589 (* 1 = 0.368589 loss)
I0906 06:28:03.383261 90901 sgd_solver.cpp:106] Iteration 88010, lr = 0.001
I0906 06:28:11.539813 90901 solver.cpp:228] Iteration 88020, loss = 0.0478027
I0906 06:28:11.539942 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0478036 (* 1 = 0.0478036 loss)
I0906 06:28:11.539964 90901 sgd_solver.cpp:106] Iteration 88020, lr = 0.001
I0906 06:28:19.437836 90901 solver.cpp:228] Iteration 88030, loss = 0.136155
I0906 06:28:19.437921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136156 (* 1 = 0.136156 loss)
I0906 06:28:19.437942 90901 sgd_solver.cpp:106] Iteration 88030, lr = 0.001
I0906 06:28:27.588904 90901 solver.cpp:228] Iteration 88040, loss = 0.0402893
I0906 06:28:27.589134 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0402903 (* 1 = 0.0402903 loss)
I0906 06:28:27.589153 90901 sgd_solver.cpp:106] Iteration 88040, lr = 0.001
I0906 06:28:35.693106 90901 solver.cpp:228] Iteration 88050, loss = 0.0291195
I0906 06:28:35.693183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0291204 (* 1 = 0.0291204 loss)
I0906 06:28:35.693204 90901 sgd_solver.cpp:106] Iteration 88050, lr = 0.001
I0906 06:28:43.377043 90901 solver.cpp:228] Iteration 88060, loss = 0.2543
I0906 06:28:43.377122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254301 (* 1 = 0.254301 loss)
I0906 06:28:43.377138 90901 sgd_solver.cpp:106] Iteration 88060, lr = 0.001
I0906 06:28:51.276876 90901 solver.cpp:228] Iteration 88070, loss = 0.139823
I0906 06:28:51.276935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139824 (* 1 = 0.139824 loss)
I0906 06:28:51.276952 90901 sgd_solver.cpp:106] Iteration 88070, lr = 0.001
I0906 06:28:59.086272 90901 solver.cpp:228] Iteration 88080, loss = 0.163146
I0906 06:28:59.086480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163147 (* 1 = 0.163147 loss)
I0906 06:28:59.086511 90901 sgd_solver.cpp:106] Iteration 88080, lr = 0.001
I0906 06:29:06.471694 90901 solver.cpp:228] Iteration 88090, loss = 0.105427
I0906 06:29:06.471815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105428 (* 1 = 0.105428 loss)
I0906 06:29:06.471839 90901 sgd_solver.cpp:106] Iteration 88090, lr = 0.001
I0906 06:29:14.446565 90901 solver.cpp:228] Iteration 88100, loss = 0.186138
I0906 06:29:14.446651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186139 (* 1 = 0.186139 loss)
I0906 06:29:14.446682 90901 sgd_solver.cpp:106] Iteration 88100, lr = 0.001
I0906 06:29:22.305632 90901 solver.cpp:228] Iteration 88110, loss = 0.08307
I0906 06:29:22.305712 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.083071 (* 1 = 0.083071 loss)
I0906 06:29:22.305732 90901 sgd_solver.cpp:106] Iteration 88110, lr = 0.001
I0906 06:29:30.527884 90901 solver.cpp:228] Iteration 88120, loss = 0.169774
I0906 06:29:30.528206 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169775 (* 1 = 0.169775 loss)
I0906 06:29:30.528234 90901 sgd_solver.cpp:106] Iteration 88120, lr = 0.001
I0906 06:29:38.804615 90901 solver.cpp:228] Iteration 88130, loss = 0.0529264
I0906 06:29:38.804697 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0529274 (* 1 = 0.0529274 loss)
I0906 06:29:38.804723 90901 sgd_solver.cpp:106] Iteration 88130, lr = 0.001
I0906 06:29:47.654884 90901 solver.cpp:228] Iteration 88140, loss = 0.0750981
I0906 06:29:47.654938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0750991 (* 1 = 0.0750991 loss)
I0906 06:29:47.654956 90901 sgd_solver.cpp:106] Iteration 88140, lr = 0.001
I0906 06:29:55.784772 90901 solver.cpp:228] Iteration 88150, loss = 0.259332
I0906 06:29:55.784843 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259332 (* 1 = 0.259332 loss)
I0906 06:29:55.784862 90901 sgd_solver.cpp:106] Iteration 88150, lr = 0.001
I0906 06:30:03.484453 90901 solver.cpp:228] Iteration 88160, loss = 0.0261187
I0906 06:30:03.484616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0261197 (* 1 = 0.0261197 loss)
I0906 06:30:03.484634 90901 sgd_solver.cpp:106] Iteration 88160, lr = 0.001
I0906 06:30:11.072553 90901 solver.cpp:228] Iteration 88170, loss = 0.289416
I0906 06:30:11.072620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289417 (* 1 = 0.289417 loss)
I0906 06:30:11.072638 90901 sgd_solver.cpp:106] Iteration 88170, lr = 0.001
I0906 06:30:19.374364 90901 solver.cpp:228] Iteration 88180, loss = 0.178714
I0906 06:30:19.374449 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178715 (* 1 = 0.178715 loss)
I0906 06:30:19.374466 90901 sgd_solver.cpp:106] Iteration 88180, lr = 0.001
I0906 06:30:27.958925 90901 solver.cpp:228] Iteration 88190, loss = 0.0998313
I0906 06:30:27.959030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0998323 (* 1 = 0.0998323 loss)
I0906 06:30:27.959048 90901 sgd_solver.cpp:106] Iteration 88190, lr = 0.001
I0906 06:30:36.127257 90901 solver.cpp:228] Iteration 88200, loss = 0.0236921
I0906 06:30:36.127506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.023693 (* 1 = 0.023693 loss)
I0906 06:30:36.127537 90901 sgd_solver.cpp:106] Iteration 88200, lr = 0.001
I0906 06:30:44.504770 90901 solver.cpp:228] Iteration 88210, loss = 0.517792
I0906 06:30:44.504855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.517793 (* 1 = 0.517793 loss)
I0906 06:30:44.504873 90901 sgd_solver.cpp:106] Iteration 88210, lr = 0.001
I0906 06:30:52.382865 90901 solver.cpp:228] Iteration 88220, loss = 0.254659
I0906 06:30:52.382953 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25466 (* 1 = 0.25466 loss)
I0906 06:30:52.382971 90901 sgd_solver.cpp:106] Iteration 88220, lr = 0.001
I0906 06:31:00.482326 90901 solver.cpp:228] Iteration 88230, loss = 0.102714
I0906 06:31:00.482395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102715 (* 1 = 0.102715 loss)
I0906 06:31:00.482414 90901 sgd_solver.cpp:106] Iteration 88230, lr = 0.001
I0906 06:31:08.876516 90901 solver.cpp:228] Iteration 88240, loss = 0.232014
I0906 06:31:08.876793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232015 (* 1 = 0.232015 loss)
I0906 06:31:08.876816 90901 sgd_solver.cpp:106] Iteration 88240, lr = 0.001
I0906 06:31:17.255111 90901 solver.cpp:228] Iteration 88250, loss = 0.476627
I0906 06:31:17.255187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.476628 (* 1 = 0.476628 loss)
I0906 06:31:17.255203 90901 sgd_solver.cpp:106] Iteration 88250, lr = 0.001
I0906 06:31:26.193909 90901 solver.cpp:228] Iteration 88260, loss = 0.134371
I0906 06:31:26.193976 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134372 (* 1 = 0.134372 loss)
I0906 06:31:26.193994 90901 sgd_solver.cpp:106] Iteration 88260, lr = 0.001
I0906 06:31:33.903964 90901 solver.cpp:228] Iteration 88270, loss = 0.647383
I0906 06:31:33.904028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.647384 (* 1 = 0.647384 loss)
I0906 06:31:33.904050 90901 sgd_solver.cpp:106] Iteration 88270, lr = 0.001
I0906 06:31:41.969871 90901 solver.cpp:228] Iteration 88280, loss = 0.0741289
I0906 06:31:41.970028 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0741299 (* 1 = 0.0741299 loss)
I0906 06:31:41.970047 90901 sgd_solver.cpp:106] Iteration 88280, lr = 0.001
I0906 06:31:50.534626 90901 solver.cpp:228] Iteration 88290, loss = 0.213248
I0906 06:31:50.534708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.213249 (* 1 = 0.213249 loss)
I0906 06:31:50.534728 90901 sgd_solver.cpp:106] Iteration 88290, lr = 0.001
I0906 06:31:58.851491 90901 solver.cpp:228] Iteration 88300, loss = 0.0911452
I0906 06:31:58.851569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0911461 (* 1 = 0.0911461 loss)
I0906 06:31:58.851593 90901 sgd_solver.cpp:106] Iteration 88300, lr = 0.001
I0906 06:32:06.439277 90901 solver.cpp:228] Iteration 88310, loss = 0.202858
I0906 06:32:06.439375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202859 (* 1 = 0.202859 loss)
I0906 06:32:06.439395 90901 sgd_solver.cpp:106] Iteration 88310, lr = 0.001
I0906 06:32:14.312407 90901 solver.cpp:228] Iteration 88320, loss = 0.0308203
I0906 06:32:14.312571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0308213 (* 1 = 0.0308213 loss)
I0906 06:32:14.312588 90901 sgd_solver.cpp:106] Iteration 88320, lr = 0.001
I0906 06:32:22.294474 90901 solver.cpp:228] Iteration 88330, loss = 0.0644505
I0906 06:32:22.294544 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0644515 (* 1 = 0.0644515 loss)
I0906 06:32:22.294562 90901 sgd_solver.cpp:106] Iteration 88330, lr = 0.001
I0906 06:32:30.409349 90901 solver.cpp:228] Iteration 88340, loss = 0.165781
I0906 06:32:30.409422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165781 (* 1 = 0.165781 loss)
I0906 06:32:30.409440 90901 sgd_solver.cpp:106] Iteration 88340, lr = 0.001
I0906 06:32:38.282439 90901 solver.cpp:228] Iteration 88350, loss = 0.155128
I0906 06:32:38.282500 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155129 (* 1 = 0.155129 loss)
I0906 06:32:38.282518 90901 sgd_solver.cpp:106] Iteration 88350, lr = 0.001
I0906 06:32:46.376965 90901 solver.cpp:228] Iteration 88360, loss = 0.119518
I0906 06:32:46.377202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119519 (* 1 = 0.119519 loss)
I0906 06:32:46.377221 90901 sgd_solver.cpp:106] Iteration 88360, lr = 0.001
I0906 06:32:54.743957 90901 solver.cpp:228] Iteration 88370, loss = 0.0828883
I0906 06:32:54.744041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0828893 (* 1 = 0.0828893 loss)
I0906 06:32:54.744058 90901 sgd_solver.cpp:106] Iteration 88370, lr = 0.001
I0906 06:33:02.899185 90901 solver.cpp:228] Iteration 88380, loss = 0.0684307
I0906 06:33:02.899359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684317 (* 1 = 0.0684317 loss)
I0906 06:33:02.899384 90901 sgd_solver.cpp:106] Iteration 88380, lr = 0.001
I0906 06:33:11.130332 90901 solver.cpp:228] Iteration 88390, loss = 0.0384718
I0906 06:33:11.130416 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0384727 (* 1 = 0.0384727 loss)
I0906 06:33:11.130434 90901 sgd_solver.cpp:106] Iteration 88390, lr = 0.001
I0906 06:33:19.423113 90901 solver.cpp:228] Iteration 88400, loss = 0.34592
I0906 06:33:19.423344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345921 (* 1 = 0.345921 loss)
I0906 06:33:19.423365 90901 sgd_solver.cpp:106] Iteration 88400, lr = 0.001
I0906 06:33:27.158231 90901 solver.cpp:228] Iteration 88410, loss = 0.125042
I0906 06:33:27.158320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125043 (* 1 = 0.125043 loss)
I0906 06:33:27.158339 90901 sgd_solver.cpp:106] Iteration 88410, lr = 0.001
I0906 06:33:35.293193 90901 solver.cpp:228] Iteration 88420, loss = 0.100636
I0906 06:33:35.293287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100637 (* 1 = 0.100637 loss)
I0906 06:33:35.293305 90901 sgd_solver.cpp:106] Iteration 88420, lr = 0.001
I0906 06:33:42.720424 90901 solver.cpp:228] Iteration 88430, loss = 0.260023
I0906 06:33:42.720507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.260024 (* 1 = 0.260024 loss)
I0906 06:33:42.720525 90901 sgd_solver.cpp:106] Iteration 88430, lr = 0.001
I0906 06:33:51.353610 90901 solver.cpp:228] Iteration 88440, loss = 0.0781832
I0906 06:33:51.353790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0781842 (* 1 = 0.0781842 loss)
I0906 06:33:51.353832 90901 sgd_solver.cpp:106] Iteration 88440, lr = 0.001
I0906 06:33:59.476645 90901 solver.cpp:228] Iteration 88450, loss = 0.110719
I0906 06:33:59.476729 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11072 (* 1 = 0.11072 loss)
I0906 06:33:59.476750 90901 sgd_solver.cpp:106] Iteration 88450, lr = 0.001
I0906 06:34:07.306704 90901 solver.cpp:228] Iteration 88460, loss = 0.199447
I0906 06:34:07.306787 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199448 (* 1 = 0.199448 loss)
I0906 06:34:07.306805 90901 sgd_solver.cpp:106] Iteration 88460, lr = 0.001
I0906 06:34:15.178050 90901 solver.cpp:228] Iteration 88470, loss = 0.285952
I0906 06:34:15.178127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285953 (* 1 = 0.285953 loss)
I0906 06:34:15.178145 90901 sgd_solver.cpp:106] Iteration 88470, lr = 0.001
I0906 06:34:23.232455 90901 solver.cpp:228] Iteration 88480, loss = 0.171161
I0906 06:34:23.232707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171162 (* 1 = 0.171162 loss)
I0906 06:34:23.232748 90901 sgd_solver.cpp:106] Iteration 88480, lr = 0.001
I0906 06:34:30.771673 90901 solver.cpp:228] Iteration 88490, loss = 0.100407
I0906 06:34:30.771739 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100408 (* 1 = 0.100408 loss)
I0906 06:34:30.771752 90901 sgd_solver.cpp:106] Iteration 88490, lr = 0.001
I0906 06:34:35.973786 90901 solver.cpp:228] Iteration 88500, loss = 0.10101
I0906 06:34:35.973867 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101011 (* 1 = 0.101011 loss)
I0906 06:34:35.973886 90901 sgd_solver.cpp:106] Iteration 88500, lr = 0.001
I0906 06:34:41.202716 90901 solver.cpp:228] Iteration 88510, loss = 0.162558
I0906 06:34:41.202793 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162559 (* 1 = 0.162559 loss)
I0906 06:34:41.202810 90901 sgd_solver.cpp:106] Iteration 88510, lr = 0.001
I0906 06:34:46.719463 90901 solver.cpp:228] Iteration 88520, loss = 0.138175
I0906 06:34:46.719557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138176 (* 1 = 0.138176 loss)
I0906 06:34:46.719574 90901 sgd_solver.cpp:106] Iteration 88520, lr = 0.001
I0906 06:34:52.214881 90901 solver.cpp:228] Iteration 88530, loss = 0.0736744
I0906 06:34:52.214967 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0736754 (* 1 = 0.0736754 loss)
I0906 06:34:52.214984 90901 sgd_solver.cpp:106] Iteration 88530, lr = 0.001
I0906 06:34:59.971406 90901 solver.cpp:228] Iteration 88540, loss = 0.105298
I0906 06:34:59.971626 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105299 (* 1 = 0.105299 loss)
I0906 06:34:59.971642 90901 sgd_solver.cpp:106] Iteration 88540, lr = 0.001
I0906 06:35:07.460228 90901 solver.cpp:228] Iteration 88550, loss = 0.253981
I0906 06:35:07.460297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253982 (* 1 = 0.253982 loss)
I0906 06:35:07.460315 90901 sgd_solver.cpp:106] Iteration 88550, lr = 0.001
I0906 06:35:15.976873 90901 solver.cpp:228] Iteration 88560, loss = 0.242373
I0906 06:35:15.976968 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242374 (* 1 = 0.242374 loss)
I0906 06:35:15.976990 90901 sgd_solver.cpp:106] Iteration 88560, lr = 0.001
I0906 06:35:23.362460 90901 solver.cpp:228] Iteration 88570, loss = 0.332228
I0906 06:35:23.362551 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.332229 (* 1 = 0.332229 loss)
I0906 06:35:23.362577 90901 sgd_solver.cpp:106] Iteration 88570, lr = 0.001
I0906 06:35:31.255339 90901 solver.cpp:228] Iteration 88580, loss = 0.372632
I0906 06:35:31.255527 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372633 (* 1 = 0.372633 loss)
I0906 06:35:31.255551 90901 sgd_solver.cpp:106] Iteration 88580, lr = 0.001
I0906 06:35:39.584229 90901 solver.cpp:228] Iteration 88590, loss = 0.169899
I0906 06:35:39.584327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1699 (* 1 = 0.1699 loss)
I0906 06:35:39.584348 90901 sgd_solver.cpp:106] Iteration 88590, lr = 0.001
I0906 06:35:47.956194 90901 solver.cpp:228] Iteration 88600, loss = 0.0572243
I0906 06:35:47.956300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0572253 (* 1 = 0.0572253 loss)
I0906 06:35:47.956317 90901 sgd_solver.cpp:106] Iteration 88600, lr = 0.001
I0906 06:35:55.634069 90901 solver.cpp:228] Iteration 88610, loss = 0.226015
I0906 06:35:55.634212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226016 (* 1 = 0.226016 loss)
I0906 06:35:55.634232 90901 sgd_solver.cpp:106] Iteration 88610, lr = 0.001
I0906 06:36:03.494369 90901 solver.cpp:228] Iteration 88620, loss = 0.306557
I0906 06:36:03.494575 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306558 (* 1 = 0.306558 loss)
I0906 06:36:03.494606 90901 sgd_solver.cpp:106] Iteration 88620, lr = 0.001
I0906 06:36:11.922766 90901 solver.cpp:228] Iteration 88630, loss = 0.154554
I0906 06:36:11.922876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154555 (* 1 = 0.154555 loss)
I0906 06:36:11.922896 90901 sgd_solver.cpp:106] Iteration 88630, lr = 0.001
I0906 06:36:19.589699 90901 solver.cpp:228] Iteration 88640, loss = 0.0621225
I0906 06:36:19.589766 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0621236 (* 1 = 0.0621236 loss)
I0906 06:36:19.589784 90901 sgd_solver.cpp:106] Iteration 88640, lr = 0.001
I0906 06:36:27.015777 90901 solver.cpp:228] Iteration 88650, loss = 0.0279917
I0906 06:36:27.015853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0279928 (* 1 = 0.0279928 loss)
I0906 06:36:27.015871 90901 sgd_solver.cpp:106] Iteration 88650, lr = 0.001
I0906 06:36:34.636091 90901 solver.cpp:228] Iteration 88660, loss = 0.123804
I0906 06:36:34.636298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123806 (* 1 = 0.123806 loss)
I0906 06:36:34.636328 90901 sgd_solver.cpp:106] Iteration 88660, lr = 0.001
I0906 06:36:42.518159 90901 solver.cpp:228] Iteration 88670, loss = 0.179064
I0906 06:36:42.518225 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179065 (* 1 = 0.179065 loss)
I0906 06:36:42.518244 90901 sgd_solver.cpp:106] Iteration 88670, lr = 0.001
I0906 06:36:49.338222 90901 solver.cpp:228] Iteration 88680, loss = 0.0642274
I0906 06:36:49.338289 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0642284 (* 1 = 0.0642284 loss)
I0906 06:36:49.338310 90901 sgd_solver.cpp:106] Iteration 88680, lr = 0.001
I0906 06:36:54.541270 90901 solver.cpp:228] Iteration 88690, loss = 0.0692356
I0906 06:36:54.541335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0692367 (* 1 = 0.0692367 loss)
I0906 06:36:54.541352 90901 sgd_solver.cpp:106] Iteration 88690, lr = 0.001
I0906 06:36:59.769178 90901 solver.cpp:228] Iteration 88700, loss = 0.0562479
I0906 06:36:59.769268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0562489 (* 1 = 0.0562489 loss)
I0906 06:36:59.769286 90901 sgd_solver.cpp:106] Iteration 88700, lr = 0.001
I0906 06:37:06.820152 90901 solver.cpp:228] Iteration 88710, loss = 0.123141
I0906 06:37:06.820360 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123142 (* 1 = 0.123142 loss)
I0906 06:37:06.820379 90901 sgd_solver.cpp:106] Iteration 88710, lr = 0.001
I0906 06:37:14.706271 90901 solver.cpp:228] Iteration 88720, loss = 0.0458176
I0906 06:37:14.706337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0458186 (* 1 = 0.0458186 loss)
I0906 06:37:14.706357 90901 sgd_solver.cpp:106] Iteration 88720, lr = 0.001
I0906 06:37:22.735708 90901 solver.cpp:228] Iteration 88730, loss = 0.496254
I0906 06:37:22.735795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.496255 (* 1 = 0.496255 loss)
I0906 06:37:22.735815 90901 sgd_solver.cpp:106] Iteration 88730, lr = 0.001
I0906 06:37:30.945253 90901 solver.cpp:228] Iteration 88740, loss = 0.244949
I0906 06:37:30.945327 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24495 (* 1 = 0.24495 loss)
I0906 06:37:30.945343 90901 sgd_solver.cpp:106] Iteration 88740, lr = 0.001
I0906 06:37:39.097139 90901 solver.cpp:228] Iteration 88750, loss = 0.127686
I0906 06:37:39.097390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127687 (* 1 = 0.127687 loss)
I0906 06:37:39.097410 90901 sgd_solver.cpp:106] Iteration 88750, lr = 0.001
I0906 06:37:47.521759 90901 solver.cpp:228] Iteration 88760, loss = 0.214437
I0906 06:37:47.521818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214438 (* 1 = 0.214438 loss)
I0906 06:37:47.521834 90901 sgd_solver.cpp:106] Iteration 88760, lr = 0.001
I0906 06:37:55.560601 90901 solver.cpp:228] Iteration 88770, loss = 0.134172
I0906 06:37:55.560698 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134173 (* 1 = 0.134173 loss)
I0906 06:37:55.560720 90901 sgd_solver.cpp:106] Iteration 88770, lr = 0.001
I0906 06:38:03.976366 90901 solver.cpp:228] Iteration 88780, loss = 0.129292
I0906 06:38:03.976469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129293 (* 1 = 0.129293 loss)
I0906 06:38:03.976498 90901 sgd_solver.cpp:106] Iteration 88780, lr = 0.001
I0906 06:38:12.118825 90901 solver.cpp:228] Iteration 88790, loss = 0.0925525
I0906 06:38:12.119104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0925535 (* 1 = 0.0925535 loss)
I0906 06:38:12.119125 90901 sgd_solver.cpp:106] Iteration 88790, lr = 0.001
I0906 06:38:20.048337 90901 solver.cpp:337] Iteration 88800, Testing net (#0)
I0906 06:39:17.210901 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.947812
I0906 06:39:17.211068 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.13497 (* 1 = 0.13497 loss)
I0906 06:39:17.428891 90901 solver.cpp:228] Iteration 88800, loss = 0.0450929
I0906 06:39:17.428971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0450939 (* 1 = 0.0450939 loss)
I0906 06:39:17.428993 90901 sgd_solver.cpp:106] Iteration 88800, lr = 0.001
I0906 06:39:25.314132 90901 solver.cpp:228] Iteration 88810, loss = 0.133028
I0906 06:39:25.314213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133029 (* 1 = 0.133029 loss)
I0906 06:39:25.314234 90901 sgd_solver.cpp:106] Iteration 88810, lr = 0.001
I0906 06:39:33.983209 90901 solver.cpp:228] Iteration 88820, loss = 0.0733029
I0906 06:39:33.983286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0733039 (* 1 = 0.0733039 loss)
I0906 06:39:33.983305 90901 sgd_solver.cpp:106] Iteration 88820, lr = 0.001
I0906 06:39:42.188918 90901 solver.cpp:228] Iteration 88830, loss = 0.095407
I0906 06:39:42.188998 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.095408 (* 1 = 0.095408 loss)
I0906 06:39:42.189016 90901 sgd_solver.cpp:106] Iteration 88830, lr = 0.001
I0906 06:39:50.582973 90901 solver.cpp:228] Iteration 88840, loss = 0.721726
I0906 06:39:50.583173 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.721727 (* 1 = 0.721727 loss)
I0906 06:39:50.583204 90901 sgd_solver.cpp:106] Iteration 88840, lr = 0.001
I0906 06:39:58.940032 90901 solver.cpp:228] Iteration 88850, loss = 0.0426908
I0906 06:39:58.940098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0426918 (* 1 = 0.0426918 loss)
I0906 06:39:58.940114 90901 sgd_solver.cpp:106] Iteration 88850, lr = 0.001
I0906 06:40:06.802271 90901 solver.cpp:228] Iteration 88860, loss = 0.065368
I0906 06:40:06.802338 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.065369 (* 1 = 0.065369 loss)
I0906 06:40:06.802361 90901 sgd_solver.cpp:106] Iteration 88860, lr = 0.001
I0906 06:40:14.772924 90901 solver.cpp:228] Iteration 88870, loss = 0.287827
I0906 06:40:14.772999 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287828 (* 1 = 0.287828 loss)
I0906 06:40:14.773015 90901 sgd_solver.cpp:106] Iteration 88870, lr = 0.001
I0906 06:40:22.977840 90901 solver.cpp:228] Iteration 88880, loss = 0.103685
I0906 06:40:22.978031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103686 (* 1 = 0.103686 loss)
I0906 06:40:22.978072 90901 sgd_solver.cpp:106] Iteration 88880, lr = 0.001
I0906 06:40:31.010406 90901 solver.cpp:228] Iteration 88890, loss = 0.133767
I0906 06:40:31.010467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133768 (* 1 = 0.133768 loss)
I0906 06:40:31.010484 90901 sgd_solver.cpp:106] Iteration 88890, lr = 0.001
I0906 06:40:38.977756 90901 solver.cpp:228] Iteration 88900, loss = 0.252409
I0906 06:40:38.977854 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25241 (* 1 = 0.25241 loss)
I0906 06:40:38.977874 90901 sgd_solver.cpp:106] Iteration 88900, lr = 0.001
I0906 06:40:46.863706 90901 solver.cpp:228] Iteration 88910, loss = 0.0207144
I0906 06:40:46.863770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0207153 (* 1 = 0.0207153 loss)
I0906 06:40:46.863786 90901 sgd_solver.cpp:106] Iteration 88910, lr = 0.001
I0906 06:40:54.815246 90901 solver.cpp:228] Iteration 88920, loss = 0.112243
I0906 06:40:54.815497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112244 (* 1 = 0.112244 loss)
I0906 06:40:54.815516 90901 sgd_solver.cpp:106] Iteration 88920, lr = 0.001
I0906 06:41:02.455867 90901 solver.cpp:228] Iteration 88930, loss = 0.111199
I0906 06:41:02.455962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1112 (* 1 = 0.1112 loss)
I0906 06:41:02.455981 90901 sgd_solver.cpp:106] Iteration 88930, lr = 0.001
I0906 06:41:10.638162 90901 solver.cpp:228] Iteration 88940, loss = 0.0162739
I0906 06:41:10.638249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0162749 (* 1 = 0.0162749 loss)
I0906 06:41:10.638267 90901 sgd_solver.cpp:106] Iteration 88940, lr = 0.001
I0906 06:41:18.495965 90901 solver.cpp:228] Iteration 88950, loss = 0.0538353
I0906 06:41:18.496050 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0538364 (* 1 = 0.0538364 loss)
I0906 06:41:18.496068 90901 sgd_solver.cpp:106] Iteration 88950, lr = 0.001
I0906 06:41:26.130442 90901 solver.cpp:228] Iteration 88960, loss = 0.134748
I0906 06:41:26.130643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134749 (* 1 = 0.134749 loss)
I0906 06:41:26.130672 90901 sgd_solver.cpp:106] Iteration 88960, lr = 0.001
I0906 06:41:34.221349 90901 solver.cpp:228] Iteration 88970, loss = 0.225344
I0906 06:41:34.221436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225345 (* 1 = 0.225345 loss)
I0906 06:41:34.221453 90901 sgd_solver.cpp:106] Iteration 88970, lr = 0.001
I0906 06:41:42.333088 90901 solver.cpp:228] Iteration 88980, loss = 0.1187
I0906 06:41:42.333163 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118701 (* 1 = 0.118701 loss)
I0906 06:41:42.333181 90901 sgd_solver.cpp:106] Iteration 88980, lr = 0.001
I0906 06:41:50.876086 90901 solver.cpp:228] Iteration 88990, loss = 0.0287521
I0906 06:41:50.876149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0287531 (* 1 = 0.0287531 loss)
I0906 06:41:50.876168 90901 sgd_solver.cpp:106] Iteration 88990, lr = 0.001
I0906 06:41:58.601958 90901 solver.cpp:228] Iteration 89000, loss = 0.152907
I0906 06:41:58.602246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152908 (* 1 = 0.152908 loss)
I0906 06:41:58.602269 90901 sgd_solver.cpp:106] Iteration 89000, lr = 0.001
I0906 06:42:07.300300 90901 solver.cpp:228] Iteration 89010, loss = 0.157175
I0906 06:42:07.300372 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157176 (* 1 = 0.157176 loss)
I0906 06:42:07.300390 90901 sgd_solver.cpp:106] Iteration 89010, lr = 0.001
I0906 06:42:15.569428 90901 solver.cpp:228] Iteration 89020, loss = 0.46515
I0906 06:42:15.569480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.465151 (* 1 = 0.465151 loss)
I0906 06:42:15.569502 90901 sgd_solver.cpp:106] Iteration 89020, lr = 0.001
I0906 06:42:23.233002 90901 solver.cpp:228] Iteration 89030, loss = 0.147523
I0906 06:42:23.233101 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.147524 (* 1 = 0.147524 loss)
I0906 06:42:23.233126 90901 sgd_solver.cpp:106] Iteration 89030, lr = 0.001
I0906 06:42:31.617568 90901 solver.cpp:228] Iteration 89040, loss = 0.097902
I0906 06:42:31.617745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.097903 (* 1 = 0.097903 loss)
I0906 06:42:31.617763 90901 sgd_solver.cpp:106] Iteration 89040, lr = 0.001
I0906 06:42:39.965440 90901 solver.cpp:228] Iteration 89050, loss = 0.151275
I0906 06:42:39.965523 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151276 (* 1 = 0.151276 loss)
I0906 06:42:39.965544 90901 sgd_solver.cpp:106] Iteration 89050, lr = 0.001
I0906 06:42:47.801533 90901 solver.cpp:228] Iteration 89060, loss = 0.272686
I0906 06:42:47.801625 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272687 (* 1 = 0.272687 loss)
I0906 06:42:47.801643 90901 sgd_solver.cpp:106] Iteration 89060, lr = 0.001
I0906 06:42:56.146399 90901 solver.cpp:228] Iteration 89070, loss = 0.075355
I0906 06:42:56.146459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.075356 (* 1 = 0.075356 loss)
I0906 06:42:56.146476 90901 sgd_solver.cpp:106] Iteration 89070, lr = 0.001
I0906 06:43:04.125809 90901 solver.cpp:228] Iteration 89080, loss = 0.134089
I0906 06:43:04.126272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13409 (* 1 = 0.13409 loss)
I0906 06:43:04.126296 90901 sgd_solver.cpp:106] Iteration 89080, lr = 0.001
I0906 06:43:12.754425 90901 solver.cpp:228] Iteration 89090, loss = 0.157311
I0906 06:43:12.754480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157312 (* 1 = 0.157312 loss)
I0906 06:43:12.754499 90901 sgd_solver.cpp:106] Iteration 89090, lr = 0.001
I0906 06:43:21.018379 90901 solver.cpp:228] Iteration 89100, loss = 0.0323463
I0906 06:43:21.018443 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0323472 (* 1 = 0.0323472 loss)
I0906 06:43:21.018460 90901 sgd_solver.cpp:106] Iteration 89100, lr = 0.001
I0906 06:43:29.101032 90901 solver.cpp:228] Iteration 89110, loss = 0.0438851
I0906 06:43:29.101131 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0438861 (* 1 = 0.0438861 loss)
I0906 06:43:29.101152 90901 sgd_solver.cpp:106] Iteration 89110, lr = 0.001
I0906 06:43:37.201985 90901 solver.cpp:228] Iteration 89120, loss = 0.154238
I0906 06:43:37.202220 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154239 (* 1 = 0.154239 loss)
I0906 06:43:37.202239 90901 sgd_solver.cpp:106] Iteration 89120, lr = 0.001
I0906 06:43:45.347383 90901 solver.cpp:228] Iteration 89130, loss = 0.290449
I0906 06:43:45.347460 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29045 (* 1 = 0.29045 loss)
I0906 06:43:45.347476 90901 sgd_solver.cpp:106] Iteration 89130, lr = 0.001
I0906 06:43:53.214419 90901 solver.cpp:228] Iteration 89140, loss = 0.258867
I0906 06:43:53.214498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258868 (* 1 = 0.258868 loss)
I0906 06:43:53.214514 90901 sgd_solver.cpp:106] Iteration 89140, lr = 0.001
I0906 06:44:01.456326 90901 solver.cpp:228] Iteration 89150, loss = 0.281734
I0906 06:44:01.456405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281735 (* 1 = 0.281735 loss)
I0906 06:44:01.456423 90901 sgd_solver.cpp:106] Iteration 89150, lr = 0.001
I0906 06:44:09.762861 90901 solver.cpp:228] Iteration 89160, loss = 0.0456313
I0906 06:44:09.762996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0456323 (* 1 = 0.0456323 loss)
I0906 06:44:09.763016 90901 sgd_solver.cpp:106] Iteration 89160, lr = 0.001
I0906 06:44:17.356936 90901 solver.cpp:228] Iteration 89170, loss = 0.0447651
I0906 06:44:17.357007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.044766 (* 1 = 0.044766 loss)
I0906 06:44:17.357023 90901 sgd_solver.cpp:106] Iteration 89170, lr = 0.001
I0906 06:44:25.557428 90901 solver.cpp:228] Iteration 89180, loss = 0.242915
I0906 06:44:25.557495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.242916 (* 1 = 0.242916 loss)
I0906 06:44:25.557512 90901 sgd_solver.cpp:106] Iteration 89180, lr = 0.001
I0906 06:44:33.631120 90901 solver.cpp:228] Iteration 89190, loss = 0.0789362
I0906 06:44:33.631207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0789372 (* 1 = 0.0789372 loss)
I0906 06:44:33.631227 90901 sgd_solver.cpp:106] Iteration 89190, lr = 0.001
I0906 06:44:41.769045 90901 solver.cpp:228] Iteration 89200, loss = 0.0384004
I0906 06:44:41.769249 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0384014 (* 1 = 0.0384014 loss)
I0906 06:44:41.769292 90901 sgd_solver.cpp:106] Iteration 89200, lr = 0.001
I0906 06:44:49.210348 90901 solver.cpp:228] Iteration 89210, loss = 0.236191
I0906 06:44:49.210417 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236192 (* 1 = 0.236192 loss)
I0906 06:44:49.210433 90901 sgd_solver.cpp:106] Iteration 89210, lr = 0.001
I0906 06:44:57.217751 90901 solver.cpp:228] Iteration 89220, loss = 0.108824
I0906 06:44:57.217823 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108825 (* 1 = 0.108825 loss)
I0906 06:44:57.217839 90901 sgd_solver.cpp:106] Iteration 89220, lr = 0.001
I0906 06:45:04.607558 90901 solver.cpp:228] Iteration 89230, loss = 0.283553
I0906 06:45:04.607656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283554 (* 1 = 0.283554 loss)
I0906 06:45:04.607674 90901 sgd_solver.cpp:106] Iteration 89230, lr = 0.001
I0906 06:45:12.505426 90901 solver.cpp:228] Iteration 89240, loss = 0.373607
I0906 06:45:12.505681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373608 (* 1 = 0.373608 loss)
I0906 06:45:12.505700 90901 sgd_solver.cpp:106] Iteration 89240, lr = 0.001
I0906 06:45:19.858019 90901 solver.cpp:228] Iteration 89250, loss = 0.0674017
I0906 06:45:19.858115 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0674027 (* 1 = 0.0674027 loss)
I0906 06:45:19.858134 90901 sgd_solver.cpp:106] Iteration 89250, lr = 0.001
I0906 06:45:27.266779 90901 solver.cpp:228] Iteration 89260, loss = 0.28884
I0906 06:45:27.266850 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.288841 (* 1 = 0.288841 loss)
I0906 06:45:27.266868 90901 sgd_solver.cpp:106] Iteration 89260, lr = 0.001
I0906 06:45:34.911692 90901 solver.cpp:228] Iteration 89270, loss = 0.239634
I0906 06:45:34.911764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239635 (* 1 = 0.239635 loss)
I0906 06:45:34.911782 90901 sgd_solver.cpp:106] Iteration 89270, lr = 0.001
I0906 06:45:40.294703 90901 solver.cpp:228] Iteration 89280, loss = 0.314131
I0906 06:45:40.294783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.314131 (* 1 = 0.314131 loss)
I0906 06:45:40.294801 90901 sgd_solver.cpp:106] Iteration 89280, lr = 0.001
I0906 06:45:45.315613 90901 solver.cpp:228] Iteration 89290, loss = 0.0940869
I0906 06:45:45.315767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0940878 (* 1 = 0.0940878 loss)
I0906 06:45:45.315798 90901 sgd_solver.cpp:106] Iteration 89290, lr = 0.001
I0906 06:45:50.855856 90901 solver.cpp:228] Iteration 89300, loss = 0.0913243
I0906 06:45:50.855931 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0913252 (* 1 = 0.0913252 loss)
I0906 06:45:50.855953 90901 sgd_solver.cpp:106] Iteration 89300, lr = 0.001
I0906 06:45:57.876510 90901 solver.cpp:228] Iteration 89310, loss = 0.0247967
I0906 06:45:57.876579 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0247976 (* 1 = 0.0247976 loss)
I0906 06:45:57.876597 90901 sgd_solver.cpp:106] Iteration 89310, lr = 0.001
I0906 06:46:05.808334 90901 solver.cpp:228] Iteration 89320, loss = 0.271587
I0906 06:46:05.808405 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271588 (* 1 = 0.271588 loss)
I0906 06:46:05.808421 90901 sgd_solver.cpp:106] Iteration 89320, lr = 0.001
I0906 06:46:13.905030 90901 solver.cpp:228] Iteration 89330, loss = 0.0197955
I0906 06:46:13.905108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0197964 (* 1 = 0.0197964 loss)
I0906 06:46:13.905129 90901 sgd_solver.cpp:106] Iteration 89330, lr = 0.001
I0906 06:46:21.490998 90901 solver.cpp:228] Iteration 89340, loss = 0.308917
I0906 06:46:21.491183 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.308918 (* 1 = 0.308918 loss)
I0906 06:46:21.491206 90901 sgd_solver.cpp:106] Iteration 89340, lr = 0.001
I0906 06:46:29.732166 90901 solver.cpp:228] Iteration 89350, loss = 0.0717921
I0906 06:46:29.732233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.071793 (* 1 = 0.071793 loss)
I0906 06:46:29.732249 90901 sgd_solver.cpp:106] Iteration 89350, lr = 0.001
I0906 06:46:38.023005 90901 solver.cpp:228] Iteration 89360, loss = 0.366585
I0906 06:46:38.023085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366586 (* 1 = 0.366586 loss)
I0906 06:46:38.023107 90901 sgd_solver.cpp:106] Iteration 89360, lr = 0.001
I0906 06:46:45.634445 90901 solver.cpp:228] Iteration 89370, loss = 0.128162
I0906 06:46:45.634614 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128163 (* 1 = 0.128163 loss)
I0906 06:46:45.634660 90901 sgd_solver.cpp:106] Iteration 89370, lr = 0.001
I0906 06:46:51.856426 90901 solver.cpp:228] Iteration 89380, loss = 0.111441
I0906 06:46:51.856689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111442 (* 1 = 0.111442 loss)
I0906 06:46:51.856709 90901 sgd_solver.cpp:106] Iteration 89380, lr = 0.001
I0906 06:46:58.933775 90901 solver.cpp:228] Iteration 89390, loss = 0.181601
I0906 06:46:58.933851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181602 (* 1 = 0.181602 loss)
I0906 06:46:58.933868 90901 sgd_solver.cpp:106] Iteration 89390, lr = 0.001
I0906 06:47:06.557298 90901 solver.cpp:228] Iteration 89400, loss = 0.302278
I0906 06:47:06.557458 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.302279 (* 1 = 0.302279 loss)
I0906 06:47:06.557499 90901 sgd_solver.cpp:106] Iteration 89400, lr = 0.001
I0906 06:47:14.096441 90901 solver.cpp:228] Iteration 89410, loss = 0.0333087
I0906 06:47:14.096520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0333096 (* 1 = 0.0333096 loss)
I0906 06:47:14.096537 90901 sgd_solver.cpp:106] Iteration 89410, lr = 0.001
I0906 06:47:21.719867 90901 solver.cpp:228] Iteration 89420, loss = 0.287896
I0906 06:47:21.719930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.287896 (* 1 = 0.287896 loss)
I0906 06:47:21.719946 90901 sgd_solver.cpp:106] Iteration 89420, lr = 0.001
I0906 06:47:29.379631 90901 solver.cpp:228] Iteration 89430, loss = 0.0488278
I0906 06:47:29.379853 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0488287 (* 1 = 0.0488287 loss)
I0906 06:47:29.379873 90901 sgd_solver.cpp:106] Iteration 89430, lr = 0.001
I0906 06:47:36.977797 90901 solver.cpp:228] Iteration 89440, loss = 0.035589
I0906 06:47:36.977861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0355899 (* 1 = 0.0355899 loss)
I0906 06:47:36.977877 90901 sgd_solver.cpp:106] Iteration 89440, lr = 0.001
I0906 06:47:44.823200 90901 solver.cpp:228] Iteration 89450, loss = 0.110109
I0906 06:47:44.823297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11011 (* 1 = 0.11011 loss)
I0906 06:47:44.823320 90901 sgd_solver.cpp:106] Iteration 89450, lr = 0.001
I0906 06:47:52.419194 90901 solver.cpp:228] Iteration 89460, loss = 0.040728
I0906 06:47:52.419268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0407289 (* 1 = 0.0407289 loss)
I0906 06:47:52.419287 90901 sgd_solver.cpp:106] Iteration 89460, lr = 0.001
I0906 06:47:59.990869 90901 solver.cpp:228] Iteration 89470, loss = 0.126707
I0906 06:47:59.991874 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126708 (* 1 = 0.126708 loss)
I0906 06:47:59.991897 90901 sgd_solver.cpp:106] Iteration 89470, lr = 0.001
I0906 06:48:07.541992 90901 solver.cpp:228] Iteration 89480, loss = 0.0417772
I0906 06:48:07.542064 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0417782 (* 1 = 0.0417782 loss)
I0906 06:48:07.542083 90901 sgd_solver.cpp:106] Iteration 89480, lr = 0.001
I0906 06:48:15.215657 90901 solver.cpp:228] Iteration 89490, loss = 0.204144
I0906 06:48:15.215759 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204145 (* 1 = 0.204145 loss)
I0906 06:48:15.215790 90901 sgd_solver.cpp:106] Iteration 89490, lr = 0.001
I0906 06:48:23.049226 90901 solver.cpp:228] Iteration 89500, loss = 0.187986
I0906 06:48:23.049306 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187987 (* 1 = 0.187987 loss)
I0906 06:48:23.049324 90901 sgd_solver.cpp:106] Iteration 89500, lr = 0.001
I0906 06:48:30.182154 90901 solver.cpp:228] Iteration 89510, loss = 0.6581
I0906 06:48:30.182384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.658101 (* 1 = 0.658101 loss)
I0906 06:48:30.182418 90901 sgd_solver.cpp:106] Iteration 89510, lr = 0.001
I0906 06:48:37.650136 90901 solver.cpp:228] Iteration 89520, loss = 0.0449864
I0906 06:48:37.650208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0449873 (* 1 = 0.0449873 loss)
I0906 06:48:37.650225 90901 sgd_solver.cpp:106] Iteration 89520, lr = 0.001
I0906 06:48:45.549398 90901 solver.cpp:228] Iteration 89530, loss = 0.192066
I0906 06:48:45.549525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192067 (* 1 = 0.192067 loss)
I0906 06:48:45.549548 90901 sgd_solver.cpp:106] Iteration 89530, lr = 0.001
I0906 06:48:54.168424 90901 solver.cpp:228] Iteration 89540, loss = 0.0406633
I0906 06:48:54.168506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0406642 (* 1 = 0.0406642 loss)
I0906 06:48:54.168524 90901 sgd_solver.cpp:106] Iteration 89540, lr = 0.001
I0906 06:49:02.356415 90901 solver.cpp:228] Iteration 89550, loss = 0.189564
I0906 06:49:02.356674 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189565 (* 1 = 0.189565 loss)
I0906 06:49:02.356696 90901 sgd_solver.cpp:106] Iteration 89550, lr = 0.001
I0906 06:49:09.917385 90901 solver.cpp:228] Iteration 89560, loss = 0.370625
I0906 06:49:09.917450 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.370626 (* 1 = 0.370626 loss)
I0906 06:49:09.917469 90901 sgd_solver.cpp:106] Iteration 89560, lr = 0.001
I0906 06:49:17.478626 90901 solver.cpp:228] Iteration 89570, loss = 0.315384
I0906 06:49:17.478711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315385 (* 1 = 0.315385 loss)
I0906 06:49:17.478732 90901 sgd_solver.cpp:106] Iteration 89570, lr = 0.001
I0906 06:49:25.329743 90901 solver.cpp:228] Iteration 89580, loss = 0.079399
I0906 06:49:25.329834 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0794 (* 1 = 0.0794 loss)
I0906 06:49:25.329852 90901 sgd_solver.cpp:106] Iteration 89580, lr = 0.001
I0906 06:49:33.706102 90901 solver.cpp:228] Iteration 89590, loss = 0.233082
I0906 06:49:33.706248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233083 (* 1 = 0.233083 loss)
I0906 06:49:33.706266 90901 sgd_solver.cpp:106] Iteration 89590, lr = 0.001
I0906 06:49:41.346210 90901 solver.cpp:337] Iteration 89600, Testing net (#0)
I0906 06:50:37.195497 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.946563
I0906 06:50:37.195669 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.149272 (* 1 = 0.149272 loss)
I0906 06:50:37.441740 90901 solver.cpp:228] Iteration 89600, loss = 0.316346
I0906 06:50:37.441804 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316347 (* 1 = 0.316347 loss)
I0906 06:50:37.441823 90901 sgd_solver.cpp:106] Iteration 89600, lr = 0.001
I0906 06:50:45.063407 90901 solver.cpp:228] Iteration 89610, loss = 0.34427
I0906 06:50:45.063470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344271 (* 1 = 0.344271 loss)
I0906 06:50:45.063486 90901 sgd_solver.cpp:106] Iteration 89610, lr = 0.001
I0906 06:50:50.759821 90901 solver.cpp:228] Iteration 89620, loss = 0.102416
I0906 06:50:50.759887 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102417 (* 1 = 0.102417 loss)
I0906 06:50:50.759905 90901 sgd_solver.cpp:106] Iteration 89620, lr = 0.001
I0906 06:50:55.975602 90901 solver.cpp:228] Iteration 89630, loss = 0.221986
I0906 06:50:55.975663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221986 (* 1 = 0.221986 loss)
I0906 06:50:55.975682 90901 sgd_solver.cpp:106] Iteration 89630, lr = 0.001
I0906 06:51:01.477064 90901 solver.cpp:228] Iteration 89640, loss = 0.616898
I0906 06:51:01.477150 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.616899 (* 1 = 0.616899 loss)
I0906 06:51:01.477169 90901 sgd_solver.cpp:106] Iteration 89640, lr = 0.001
I0906 06:51:07.231557 90901 solver.cpp:228] Iteration 89650, loss = 0.272513
I0906 06:51:07.231778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272514 (* 1 = 0.272514 loss)
I0906 06:51:07.231809 90901 sgd_solver.cpp:106] Iteration 89650, lr = 0.001
I0906 06:51:12.468672 90901 solver.cpp:228] Iteration 89660, loss = 0.137082
I0906 06:51:12.468730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137083 (* 1 = 0.137083 loss)
I0906 06:51:12.468747 90901 sgd_solver.cpp:106] Iteration 89660, lr = 0.001
I0906 06:51:18.000416 90901 solver.cpp:228] Iteration 89670, loss = 0.108158
I0906 06:51:18.000497 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108159 (* 1 = 0.108159 loss)
I0906 06:51:18.000514 90901 sgd_solver.cpp:106] Iteration 89670, lr = 0.001
I0906 06:51:24.219777 90901 solver.cpp:228] Iteration 89680, loss = 0.0205158
I0906 06:51:24.219849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0205167 (* 1 = 0.0205167 loss)
I0906 06:51:24.219869 90901 sgd_solver.cpp:106] Iteration 89680, lr = 0.001
I0906 06:51:29.782790 90901 solver.cpp:228] Iteration 89690, loss = 0.146783
I0906 06:51:29.782848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146784 (* 1 = 0.146784 loss)
I0906 06:51:29.782866 90901 sgd_solver.cpp:106] Iteration 89690, lr = 0.001
I0906 06:51:35.801069 90901 solver.cpp:228] Iteration 89700, loss = 0.581941
I0906 06:51:35.801146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.581942 (* 1 = 0.581942 loss)
I0906 06:51:35.801164 90901 sgd_solver.cpp:106] Iteration 89700, lr = 0.001
I0906 06:51:42.737361 90901 solver.cpp:228] Iteration 89710, loss = 0.337667
I0906 06:51:42.737615 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.337668 (* 1 = 0.337668 loss)
I0906 06:51:42.737637 90901 sgd_solver.cpp:106] Iteration 89710, lr = 0.001
I0906 06:51:49.578655 90901 solver.cpp:228] Iteration 89720, loss = 0.45761
I0906 06:51:49.578809 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.457611 (* 1 = 0.457611 loss)
I0906 06:51:49.578830 90901 sgd_solver.cpp:106] Iteration 89720, lr = 0.001
I0906 06:51:56.970034 90901 solver.cpp:228] Iteration 89730, loss = 0.0931323
I0906 06:51:56.970106 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0931332 (* 1 = 0.0931332 loss)
I0906 06:51:56.970124 90901 sgd_solver.cpp:106] Iteration 89730, lr = 0.001
I0906 06:52:03.818246 90901 solver.cpp:228] Iteration 89740, loss = 0.168348
I0906 06:52:03.818320 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168349 (* 1 = 0.168349 loss)
I0906 06:52:03.818338 90901 sgd_solver.cpp:106] Iteration 89740, lr = 0.001
I0906 06:52:11.095495 90901 solver.cpp:228] Iteration 89750, loss = 0.190271
I0906 06:52:11.095566 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190272 (* 1 = 0.190272 loss)
I0906 06:52:11.095584 90901 sgd_solver.cpp:106] Iteration 89750, lr = 0.001
I0906 06:52:18.199508 90901 solver.cpp:228] Iteration 89760, loss = 0.134604
I0906 06:52:18.199784 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134605 (* 1 = 0.134605 loss)
I0906 06:52:18.199805 90901 sgd_solver.cpp:106] Iteration 89760, lr = 0.001
I0906 06:52:25.850008 90901 solver.cpp:228] Iteration 89770, loss = 0.203865
I0906 06:52:25.850075 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203866 (* 1 = 0.203866 loss)
I0906 06:52:25.850092 90901 sgd_solver.cpp:106] Iteration 89770, lr = 0.001
I0906 06:52:32.990743 90901 solver.cpp:228] Iteration 89780, loss = 0.236769
I0906 06:52:32.990810 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23677 (* 1 = 0.23677 loss)
I0906 06:52:32.990828 90901 sgd_solver.cpp:106] Iteration 89780, lr = 0.001
I0906 06:52:40.635315 90901 solver.cpp:228] Iteration 89790, loss = 0.0441814
I0906 06:52:40.635432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0441824 (* 1 = 0.0441824 loss)
I0906 06:52:40.635454 90901 sgd_solver.cpp:106] Iteration 89790, lr = 0.001
I0906 06:52:48.312990 90901 solver.cpp:228] Iteration 89800, loss = 0.0243431
I0906 06:52:48.313186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0243441 (* 1 = 0.0243441 loss)
I0906 06:52:48.313206 90901 sgd_solver.cpp:106] Iteration 89800, lr = 0.001
I0906 06:52:55.283484 90901 solver.cpp:228] Iteration 89810, loss = 0.023402
I0906 06:52:55.283591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0234029 (* 1 = 0.0234029 loss)
I0906 06:52:55.283610 90901 sgd_solver.cpp:106] Iteration 89810, lr = 0.001
I0906 06:53:03.177569 90901 solver.cpp:228] Iteration 89820, loss = 0.143836
I0906 06:53:03.177649 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143837 (* 1 = 0.143837 loss)
I0906 06:53:03.177670 90901 sgd_solver.cpp:106] Iteration 89820, lr = 0.001
I0906 06:53:11.048668 90901 solver.cpp:228] Iteration 89830, loss = 0.0475784
I0906 06:53:11.048738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0475794 (* 1 = 0.0475794 loss)
I0906 06:53:11.048754 90901 sgd_solver.cpp:106] Iteration 89830, lr = 0.001
I0906 06:53:18.422206 90901 solver.cpp:228] Iteration 89840, loss = 0.206636
I0906 06:53:18.422415 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206637 (* 1 = 0.206637 loss)
I0906 06:53:18.422433 90901 sgd_solver.cpp:106] Iteration 89840, lr = 0.001
I0906 06:53:26.081377 90901 solver.cpp:228] Iteration 89850, loss = 0.065421
I0906 06:53:26.081485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0654221 (* 1 = 0.0654221 loss)
I0906 06:53:26.081504 90901 sgd_solver.cpp:106] Iteration 89850, lr = 0.001
I0906 06:53:33.956934 90901 solver.cpp:228] Iteration 89860, loss = 0.102988
I0906 06:53:33.957013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102989 (* 1 = 0.102989 loss)
I0906 06:53:33.957032 90901 sgd_solver.cpp:106] Iteration 89860, lr = 0.001
I0906 06:53:41.650256 90901 solver.cpp:228] Iteration 89870, loss = 0.504477
I0906 06:53:41.650331 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504478 (* 1 = 0.504478 loss)
I0906 06:53:41.650347 90901 sgd_solver.cpp:106] Iteration 89870, lr = 0.001
I0906 06:53:49.142851 90901 solver.cpp:228] Iteration 89880, loss = 0.0661967
I0906 06:53:49.143069 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0661978 (* 1 = 0.0661978 loss)
I0906 06:53:49.143093 90901 sgd_solver.cpp:106] Iteration 89880, lr = 0.001
I0906 06:53:56.537103 90901 solver.cpp:228] Iteration 89890, loss = 0.102974
I0906 06:53:56.537170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102975 (* 1 = 0.102975 loss)
I0906 06:53:56.537187 90901 sgd_solver.cpp:106] Iteration 89890, lr = 0.001
I0906 06:54:03.849259 90901 solver.cpp:228] Iteration 89900, loss = 0.151814
I0906 06:54:03.849339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151815 (* 1 = 0.151815 loss)
I0906 06:54:03.849356 90901 sgd_solver.cpp:106] Iteration 89900, lr = 0.001
I0906 06:54:11.875910 90901 solver.cpp:228] Iteration 89910, loss = 0.0537226
I0906 06:54:11.875978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0537236 (* 1 = 0.0537236 loss)
I0906 06:54:11.875995 90901 sgd_solver.cpp:106] Iteration 89910, lr = 0.001
I0906 06:54:19.400825 90901 solver.cpp:228] Iteration 89920, loss = 0.170613
I0906 06:54:19.400979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170614 (* 1 = 0.170614 loss)
I0906 06:54:19.400995 90901 sgd_solver.cpp:106] Iteration 89920, lr = 0.001
I0906 06:54:26.780621 90901 solver.cpp:228] Iteration 89930, loss = 0.171966
I0906 06:54:26.780689 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171967 (* 1 = 0.171967 loss)
I0906 06:54:26.780706 90901 sgd_solver.cpp:106] Iteration 89930, lr = 0.001
I0906 06:54:34.487025 90901 solver.cpp:228] Iteration 89940, loss = 0.0737381
I0906 06:54:34.487099 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0737391 (* 1 = 0.0737391 loss)
I0906 06:54:34.487117 90901 sgd_solver.cpp:106] Iteration 89940, lr = 0.001
I0906 06:54:42.408069 90901 solver.cpp:228] Iteration 89950, loss = 0.206043
I0906 06:54:42.408141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206044 (* 1 = 0.206044 loss)
I0906 06:54:42.408159 90901 sgd_solver.cpp:106] Iteration 89950, lr = 0.001
I0906 06:54:50.306524 90901 solver.cpp:228] Iteration 89960, loss = 0.173678
I0906 06:54:50.306828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173679 (* 1 = 0.173679 loss)
I0906 06:54:50.306851 90901 sgd_solver.cpp:106] Iteration 89960, lr = 0.001
I0906 06:54:57.411473 90901 solver.cpp:228] Iteration 89970, loss = 0.110262
I0906 06:54:57.411538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110263 (* 1 = 0.110263 loss)
I0906 06:54:57.411558 90901 sgd_solver.cpp:106] Iteration 89970, lr = 0.001
I0906 06:55:05.201416 90901 solver.cpp:228] Iteration 89980, loss = 0.426628
I0906 06:55:05.201495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.426629 (* 1 = 0.426629 loss)
I0906 06:55:05.201513 90901 sgd_solver.cpp:106] Iteration 89980, lr = 0.001
I0906 06:55:13.051086 90901 solver.cpp:228] Iteration 89990, loss = 0.123272
I0906 06:55:13.051229 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123273 (* 1 = 0.123273 loss)
I0906 06:55:13.051249 90901 sgd_solver.cpp:106] Iteration 89990, lr = 0.001
I0906 06:55:20.938341 90901 solver.cpp:228] Iteration 90000, loss = 0.122412
I0906 06:55:20.938679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122413 (* 1 = 0.122413 loss)
I0906 06:55:20.938710 90901 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I0906 06:55:28.855815 90901 solver.cpp:228] Iteration 90010, loss = 0.049412
I0906 06:55:28.855916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.049413 (* 1 = 0.049413 loss)
I0906 06:55:28.855933 90901 sgd_solver.cpp:106] Iteration 90010, lr = 0.001
I0906 06:55:36.292700 90901 solver.cpp:228] Iteration 90020, loss = 0.23593
I0906 06:55:36.292771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235931 (* 1 = 0.235931 loss)
I0906 06:55:36.292788 90901 sgd_solver.cpp:106] Iteration 90020, lr = 0.001
I0906 06:55:43.889935 90901 solver.cpp:228] Iteration 90030, loss = 0.260779
I0906 06:55:43.890044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.26078 (* 1 = 0.26078 loss)
I0906 06:55:43.890064 90901 sgd_solver.cpp:106] Iteration 90030, lr = 0.001
I0906 06:55:51.824275 90901 solver.cpp:228] Iteration 90040, loss = 0.170648
I0906 06:55:51.824455 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170649 (* 1 = 0.170649 loss)
I0906 06:55:51.824472 90901 sgd_solver.cpp:106] Iteration 90040, lr = 0.001
I0906 06:55:59.448398 90901 solver.cpp:228] Iteration 90050, loss = 0.0195591
I0906 06:55:59.448470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0195602 (* 1 = 0.0195602 loss)
I0906 06:55:59.448487 90901 sgd_solver.cpp:106] Iteration 90050, lr = 0.001
I0906 06:56:07.657646 90901 solver.cpp:228] Iteration 90060, loss = 0.0441719
I0906 06:56:07.657770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.044173 (* 1 = 0.044173 loss)
I0906 06:56:07.657793 90901 sgd_solver.cpp:106] Iteration 90060, lr = 0.001
I0906 06:56:15.175006 90901 solver.cpp:228] Iteration 90070, loss = 0.0756678
I0906 06:56:15.175110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0756689 (* 1 = 0.0756689 loss)
I0906 06:56:15.175132 90901 sgd_solver.cpp:106] Iteration 90070, lr = 0.001
I0906 06:56:23.536571 90901 solver.cpp:228] Iteration 90080, loss = 0.246317
I0906 06:56:23.536766 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246318 (* 1 = 0.246318 loss)
I0906 06:56:23.536793 90901 sgd_solver.cpp:106] Iteration 90080, lr = 0.001
I0906 06:56:31.275207 90901 solver.cpp:228] Iteration 90090, loss = 0.359679
I0906 06:56:31.275282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.35968 (* 1 = 0.35968 loss)
I0906 06:56:31.275300 90901 sgd_solver.cpp:106] Iteration 90090, lr = 0.001
I0906 06:56:39.686822 90901 solver.cpp:228] Iteration 90100, loss = 0.0843474
I0906 06:56:39.686914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0843485 (* 1 = 0.0843485 loss)
I0906 06:56:39.686938 90901 sgd_solver.cpp:106] Iteration 90100, lr = 0.001
I0906 06:56:48.025809 90901 solver.cpp:228] Iteration 90110, loss = 0.316134
I0906 06:56:48.025897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316135 (* 1 = 0.316135 loss)
I0906 06:56:48.025915 90901 sgd_solver.cpp:106] Iteration 90110, lr = 0.001
I0906 06:56:56.603613 90901 solver.cpp:228] Iteration 90120, loss = 0.101082
I0906 06:56:56.603829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101083 (* 1 = 0.101083 loss)
I0906 06:56:56.603857 90901 sgd_solver.cpp:106] Iteration 90120, lr = 0.001
I0906 06:57:04.219748 90901 solver.cpp:228] Iteration 90130, loss = 0.11014
I0906 06:57:04.219818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110141 (* 1 = 0.110141 loss)
I0906 06:57:04.219835 90901 sgd_solver.cpp:106] Iteration 90130, lr = 0.001
I0906 06:57:12.236378 90901 solver.cpp:228] Iteration 90140, loss = 0.0408362
I0906 06:57:12.236452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0408373 (* 1 = 0.0408373 loss)
I0906 06:57:12.236474 90901 sgd_solver.cpp:106] Iteration 90140, lr = 0.001
I0906 06:57:20.276525 90901 solver.cpp:228] Iteration 90150, loss = 0.0758319
I0906 06:57:20.276590 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.075833 (* 1 = 0.075833 loss)
I0906 06:57:20.276607 90901 sgd_solver.cpp:106] Iteration 90150, lr = 0.001
I0906 06:57:27.963476 90901 solver.cpp:228] Iteration 90160, loss = 0.02765
I0906 06:57:27.963692 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0276511 (* 1 = 0.0276511 loss)
I0906 06:57:27.963726 90901 sgd_solver.cpp:106] Iteration 90160, lr = 0.001
I0906 06:57:36.148097 90901 solver.cpp:228] Iteration 90170, loss = 0.20435
I0906 06:57:36.148161 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204351 (* 1 = 0.204351 loss)
I0906 06:57:36.148180 90901 sgd_solver.cpp:106] Iteration 90170, lr = 0.001
I0906 06:57:43.305708 90901 solver.cpp:228] Iteration 90180, loss = 0.387487
I0906 06:57:43.305815 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.387488 (* 1 = 0.387488 loss)
I0906 06:57:43.305836 90901 sgd_solver.cpp:106] Iteration 90180, lr = 0.001
I0906 06:57:51.867383 90901 solver.cpp:228] Iteration 90190, loss = 0.0458014
I0906 06:57:51.867441 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0458025 (* 1 = 0.0458025 loss)
I0906 06:57:51.867456 90901 sgd_solver.cpp:106] Iteration 90190, lr = 0.001
I0906 06:57:59.712502 90901 solver.cpp:228] Iteration 90200, loss = 0.0588419
I0906 06:57:59.712705 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0588431 (* 1 = 0.0588431 loss)
I0906 06:57:59.712741 90901 sgd_solver.cpp:106] Iteration 90200, lr = 0.001
I0906 06:58:08.015980 90901 solver.cpp:228] Iteration 90210, loss = 0.0931795
I0906 06:58:08.016084 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0931807 (* 1 = 0.0931807 loss)
I0906 06:58:08.016105 90901 sgd_solver.cpp:106] Iteration 90210, lr = 0.001
I0906 06:58:15.311012 90901 solver.cpp:228] Iteration 90220, loss = 0.231133
I0906 06:58:15.311086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231134 (* 1 = 0.231134 loss)
I0906 06:58:15.311103 90901 sgd_solver.cpp:106] Iteration 90220, lr = 0.001
I0906 06:58:23.192251 90901 solver.cpp:228] Iteration 90230, loss = 0.215525
I0906 06:58:23.192322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215526 (* 1 = 0.215526 loss)
I0906 06:58:23.192344 90901 sgd_solver.cpp:106] Iteration 90230, lr = 0.001
I0906 06:58:31.057664 90901 solver.cpp:228] Iteration 90240, loss = 0.343428
I0906 06:58:31.057821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343429 (* 1 = 0.343429 loss)
I0906 06:58:31.057842 90901 sgd_solver.cpp:106] Iteration 90240, lr = 0.001
I0906 06:58:39.217079 90901 solver.cpp:228] Iteration 90250, loss = 0.0933088
I0906 06:58:39.217144 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.09331 (* 1 = 0.09331 loss)
I0906 06:58:39.217161 90901 sgd_solver.cpp:106] Iteration 90250, lr = 0.001
I0906 06:58:47.358906 90901 solver.cpp:228] Iteration 90260, loss = 0.154476
I0906 06:58:47.358970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154477 (* 1 = 0.154477 loss)
I0906 06:58:47.358991 90901 sgd_solver.cpp:106] Iteration 90260, lr = 0.001
I0906 06:58:54.988065 90901 solver.cpp:228] Iteration 90270, loss = 0.0336804
I0906 06:58:54.988147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0336816 (* 1 = 0.0336816 loss)
I0906 06:58:54.988165 90901 sgd_solver.cpp:106] Iteration 90270, lr = 0.001
I0906 06:59:02.856066 90901 solver.cpp:228] Iteration 90280, loss = 0.243393
I0906 06:59:02.856358 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243395 (* 1 = 0.243395 loss)
I0906 06:59:02.856376 90901 sgd_solver.cpp:106] Iteration 90280, lr = 0.001
I0906 06:59:10.757050 90901 solver.cpp:228] Iteration 90290, loss = 0.133958
I0906 06:59:10.757127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133959 (* 1 = 0.133959 loss)
I0906 06:59:10.757143 90901 sgd_solver.cpp:106] Iteration 90290, lr = 0.001
I0906 06:59:18.127873 90901 solver.cpp:228] Iteration 90300, loss = 0.052071
I0906 06:59:18.127959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0520721 (* 1 = 0.0520721 loss)
I0906 06:59:18.127976 90901 sgd_solver.cpp:106] Iteration 90300, lr = 0.001
I0906 06:59:26.349817 90901 solver.cpp:228] Iteration 90310, loss = 0.107131
I0906 06:59:26.349890 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107133 (* 1 = 0.107133 loss)
I0906 06:59:26.349913 90901 sgd_solver.cpp:106] Iteration 90310, lr = 0.001
I0906 06:59:33.919977 90901 solver.cpp:228] Iteration 90320, loss = 0.169275
I0906 06:59:33.920137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169276 (* 1 = 0.169276 loss)
I0906 06:59:33.920157 90901 sgd_solver.cpp:106] Iteration 90320, lr = 0.001
I0906 06:59:41.026831 90901 solver.cpp:228] Iteration 90330, loss = 0.117422
I0906 06:59:41.026907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117423 (* 1 = 0.117423 loss)
I0906 06:59:41.026924 90901 sgd_solver.cpp:106] Iteration 90330, lr = 0.001
I0906 06:59:48.684933 90901 solver.cpp:228] Iteration 90340, loss = 0.0849911
I0906 06:59:48.685009 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0849923 (* 1 = 0.0849923 loss)
I0906 06:59:48.685025 90901 sgd_solver.cpp:106] Iteration 90340, lr = 0.001
I0906 06:59:56.584445 90901 solver.cpp:228] Iteration 90350, loss = 0.0688259
I0906 06:59:56.584522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.068827 (* 1 = 0.068827 loss)
I0906 06:59:56.584539 90901 sgd_solver.cpp:106] Iteration 90350, lr = 0.001
I0906 07:00:04.447796 90901 solver.cpp:228] Iteration 90360, loss = 0.283747
I0906 07:00:04.448000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283749 (* 1 = 0.283749 loss)
I0906 07:00:04.448024 90901 sgd_solver.cpp:106] Iteration 90360, lr = 0.001
I0906 07:00:12.325309 90901 solver.cpp:228] Iteration 90370, loss = 0.167893
I0906 07:00:12.325392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167894 (* 1 = 0.167894 loss)
I0906 07:00:12.325409 90901 sgd_solver.cpp:106] Iteration 90370, lr = 0.001
I0906 07:00:20.456373 90901 solver.cpp:228] Iteration 90380, loss = 0.0188543
I0906 07:00:20.456454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0188554 (* 1 = 0.0188554 loss)
I0906 07:00:20.456473 90901 sgd_solver.cpp:106] Iteration 90380, lr = 0.001
I0906 07:00:28.097928 90901 solver.cpp:228] Iteration 90390, loss = 0.0417562
I0906 07:00:28.098224 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0417573 (* 1 = 0.0417573 loss)
I0906 07:00:28.098266 90901 sgd_solver.cpp:106] Iteration 90390, lr = 0.001
I0906 07:00:35.651145 90901 solver.cpp:337] Iteration 90400, Testing net (#0)
I0906 07:01:29.290506 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.944062
I0906 07:01:29.290685 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.144958 (* 1 = 0.144958 loss)
I0906 07:01:29.524929 90901 solver.cpp:228] Iteration 90400, loss = 0.41562
I0906 07:01:29.525013 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.415621 (* 1 = 0.415621 loss)
I0906 07:01:29.525038 90901 sgd_solver.cpp:106] Iteration 90400, lr = 0.001
I0906 07:01:36.872050 90901 solver.cpp:228] Iteration 90410, loss = 0.289496
I0906 07:01:36.872122 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.289497 (* 1 = 0.289497 loss)
I0906 07:01:36.872139 90901 sgd_solver.cpp:106] Iteration 90410, lr = 0.001
I0906 07:01:44.194962 90901 solver.cpp:228] Iteration 90420, loss = 0.214376
I0906 07:01:44.195041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214377 (* 1 = 0.214377 loss)
I0906 07:01:44.195060 90901 sgd_solver.cpp:106] Iteration 90420, lr = 0.001
I0906 07:01:51.249637 90901 solver.cpp:228] Iteration 90430, loss = 0.220895
I0906 07:01:51.249785 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220896 (* 1 = 0.220896 loss)
I0906 07:01:51.249817 90901 sgd_solver.cpp:106] Iteration 90430, lr = 0.001
I0906 07:01:58.321892 90901 solver.cpp:228] Iteration 90440, loss = 0.0682121
I0906 07:01:58.321995 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0682133 (* 1 = 0.0682133 loss)
I0906 07:01:58.322013 90901 sgd_solver.cpp:106] Iteration 90440, lr = 0.001
I0906 07:02:05.643826 90901 solver.cpp:228] Iteration 90450, loss = 0.243661
I0906 07:02:05.644032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243662 (* 1 = 0.243662 loss)
I0906 07:02:05.644049 90901 sgd_solver.cpp:106] Iteration 90450, lr = 0.001
I0906 07:02:12.710933 90901 solver.cpp:228] Iteration 90460, loss = 0.113143
I0906 07:02:12.711030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113144 (* 1 = 0.113144 loss)
I0906 07:02:12.711048 90901 sgd_solver.cpp:106] Iteration 90460, lr = 0.001
I0906 07:02:20.052134 90901 solver.cpp:228] Iteration 90470, loss = 0.0568041
I0906 07:02:20.052217 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0568052 (* 1 = 0.0568052 loss)
I0906 07:02:20.052235 90901 sgd_solver.cpp:106] Iteration 90470, lr = 0.001
I0906 07:02:27.447199 90901 solver.cpp:228] Iteration 90480, loss = 0.0154122
I0906 07:02:27.447288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0154133 (* 1 = 0.0154133 loss)
I0906 07:02:27.447306 90901 sgd_solver.cpp:106] Iteration 90480, lr = 0.001
I0906 07:02:35.342717 90901 solver.cpp:228] Iteration 90490, loss = 0.118399
I0906 07:02:35.342820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118401 (* 1 = 0.118401 loss)
I0906 07:02:35.342841 90901 sgd_solver.cpp:106] Iteration 90490, lr = 0.001
I0906 07:02:42.736222 90901 solver.cpp:228] Iteration 90500, loss = 0.073322
I0906 07:02:42.736418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0733231 (* 1 = 0.0733231 loss)
I0906 07:02:42.736450 90901 sgd_solver.cpp:106] Iteration 90500, lr = 0.001
I0906 07:02:50.510675 90901 solver.cpp:228] Iteration 90510, loss = 0.157305
I0906 07:02:50.510757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157306 (* 1 = 0.157306 loss)
I0906 07:02:50.510773 90901 sgd_solver.cpp:106] Iteration 90510, lr = 0.001
I0906 07:02:58.335194 90901 solver.cpp:228] Iteration 90520, loss = 0.114189
I0906 07:02:58.335270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11419 (* 1 = 0.11419 loss)
I0906 07:02:58.335288 90901 sgd_solver.cpp:106] Iteration 90520, lr = 0.001
I0906 07:03:05.715100 90901 solver.cpp:228] Iteration 90530, loss = 0.161374
I0906 07:03:05.715204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161375 (* 1 = 0.161375 loss)
I0906 07:03:05.715229 90901 sgd_solver.cpp:106] Iteration 90530, lr = 0.001
I0906 07:03:13.882257 90901 solver.cpp:228] Iteration 90540, loss = 0.0748615
I0906 07:03:13.882463 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0748626 (* 1 = 0.0748626 loss)
I0906 07:03:13.882491 90901 sgd_solver.cpp:106] Iteration 90540, lr = 0.001
I0906 07:03:20.910593 90901 solver.cpp:228] Iteration 90550, loss = 0.535012
I0906 07:03:20.910753 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.535013 (* 1 = 0.535013 loss)
I0906 07:03:20.910773 90901 sgd_solver.cpp:106] Iteration 90550, lr = 0.001
I0906 07:03:29.307551 90901 solver.cpp:228] Iteration 90560, loss = 0.148726
I0906 07:03:29.307622 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148727 (* 1 = 0.148727 loss)
I0906 07:03:29.307641 90901 sgd_solver.cpp:106] Iteration 90560, lr = 0.001
I0906 07:03:36.680238 90901 solver.cpp:228] Iteration 90570, loss = 0.0699234
I0906 07:03:36.680313 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0699246 (* 1 = 0.0699246 loss)
I0906 07:03:36.680331 90901 sgd_solver.cpp:106] Iteration 90570, lr = 0.001
I0906 07:03:44.802485 90901 solver.cpp:228] Iteration 90580, loss = 0.220588
I0906 07:03:44.802733 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220589 (* 1 = 0.220589 loss)
I0906 07:03:44.802767 90901 sgd_solver.cpp:106] Iteration 90580, lr = 0.001
I0906 07:03:52.003993 90901 solver.cpp:228] Iteration 90590, loss = 0.0502741
I0906 07:03:52.004055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0502753 (* 1 = 0.0502753 loss)
I0906 07:03:52.004070 90901 sgd_solver.cpp:106] Iteration 90590, lr = 0.001
I0906 07:03:59.795480 90901 solver.cpp:228] Iteration 90600, loss = 0.176188
I0906 07:03:59.795569 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176189 (* 1 = 0.176189 loss)
I0906 07:03:59.795593 90901 sgd_solver.cpp:106] Iteration 90600, lr = 0.001
I0906 07:04:07.454437 90901 solver.cpp:228] Iteration 90610, loss = 0.119373
I0906 07:04:07.454511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119374 (* 1 = 0.119374 loss)
I0906 07:04:07.454529 90901 sgd_solver.cpp:106] Iteration 90610, lr = 0.001
I0906 07:04:15.355290 90901 solver.cpp:228] Iteration 90620, loss = 0.0285633
I0906 07:04:15.355489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0285645 (* 1 = 0.0285645 loss)
I0906 07:04:15.355512 90901 sgd_solver.cpp:106] Iteration 90620, lr = 0.001
I0906 07:04:23.014742 90901 solver.cpp:228] Iteration 90630, loss = 0.13675
I0906 07:04:23.014806 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136751 (* 1 = 0.136751 loss)
I0906 07:04:23.014823 90901 sgd_solver.cpp:106] Iteration 90630, lr = 0.001
I0906 07:04:31.153743 90901 solver.cpp:228] Iteration 90640, loss = 0.659675
I0906 07:04:31.153836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.659676 (* 1 = 0.659676 loss)
I0906 07:04:31.153853 90901 sgd_solver.cpp:106] Iteration 90640, lr = 0.001
I0906 07:04:39.122571 90901 solver.cpp:228] Iteration 90650, loss = 0.0875459
I0906 07:04:39.122661 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0875471 (* 1 = 0.0875471 loss)
I0906 07:04:39.122680 90901 sgd_solver.cpp:106] Iteration 90650, lr = 0.001
I0906 07:04:47.159572 90901 solver.cpp:228] Iteration 90660, loss = 0.184289
I0906 07:04:47.159791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18429 (* 1 = 0.18429 loss)
I0906 07:04:47.159811 90901 sgd_solver.cpp:106] Iteration 90660, lr = 0.001
I0906 07:04:55.121049 90901 solver.cpp:228] Iteration 90670, loss = 0.283383
I0906 07:04:55.121129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283384 (* 1 = 0.283384 loss)
I0906 07:04:55.121148 90901 sgd_solver.cpp:106] Iteration 90670, lr = 0.001
I0906 07:05:02.939188 90901 solver.cpp:228] Iteration 90680, loss = 0.0614174
I0906 07:05:02.939262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0614186 (* 1 = 0.0614186 loss)
I0906 07:05:02.939280 90901 sgd_solver.cpp:106] Iteration 90680, lr = 0.001
I0906 07:05:10.597892 90901 solver.cpp:228] Iteration 90690, loss = 0.164364
I0906 07:05:10.597975 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164365 (* 1 = 0.164365 loss)
I0906 07:05:10.597991 90901 sgd_solver.cpp:106] Iteration 90690, lr = 0.001
I0906 07:05:17.973701 90901 solver.cpp:228] Iteration 90700, loss = 0.504994
I0906 07:05:17.973839 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.504995 (* 1 = 0.504995 loss)
I0906 07:05:17.973861 90901 sgd_solver.cpp:106] Iteration 90700, lr = 0.001
I0906 07:05:25.536067 90901 solver.cpp:228] Iteration 90710, loss = 0.0768502
I0906 07:05:25.536146 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0768514 (* 1 = 0.0768514 loss)
I0906 07:05:25.536169 90901 sgd_solver.cpp:106] Iteration 90710, lr = 0.001
I0906 07:05:32.888556 90901 solver.cpp:228] Iteration 90720, loss = 0.0228698
I0906 07:05:32.888638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.022871 (* 1 = 0.022871 loss)
I0906 07:05:32.888654 90901 sgd_solver.cpp:106] Iteration 90720, lr = 0.001
I0906 07:05:38.845263 90901 solver.cpp:228] Iteration 90730, loss = 0.0357179
I0906 07:05:38.845343 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0357191 (* 1 = 0.0357191 loss)
I0906 07:05:38.845361 90901 sgd_solver.cpp:106] Iteration 90730, lr = 0.001
I0906 07:05:44.869585 90901 solver.cpp:228] Iteration 90740, loss = 0.0209539
I0906 07:05:44.869655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0209551 (* 1 = 0.0209551 loss)
I0906 07:05:44.869673 90901 sgd_solver.cpp:106] Iteration 90740, lr = 0.001
I0906 07:05:50.596779 90901 solver.cpp:228] Iteration 90750, loss = 0.0211329
I0906 07:05:50.597105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0211341 (* 1 = 0.0211341 loss)
I0906 07:05:50.597122 90901 sgd_solver.cpp:106] Iteration 90750, lr = 0.001
I0906 07:05:56.356134 90901 solver.cpp:228] Iteration 90760, loss = 0.458719
I0906 07:05:56.356210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.45872 (* 1 = 0.45872 loss)
I0906 07:05:56.356228 90901 sgd_solver.cpp:106] Iteration 90760, lr = 0.001
I0906 07:06:01.661376 90901 solver.cpp:228] Iteration 90770, loss = 0.197233
I0906 07:06:01.661468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197235 (* 1 = 0.197235 loss)
I0906 07:06:01.661489 90901 sgd_solver.cpp:106] Iteration 90770, lr = 0.001
I0906 07:06:07.093713 90901 solver.cpp:228] Iteration 90780, loss = 0.209462
I0906 07:06:07.093777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209463 (* 1 = 0.209463 loss)
I0906 07:06:07.093794 90901 sgd_solver.cpp:106] Iteration 90780, lr = 0.001
I0906 07:06:12.332834 90901 solver.cpp:228] Iteration 90790, loss = 0.31132
I0906 07:06:12.332919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.311321 (* 1 = 0.311321 loss)
I0906 07:06:12.332938 90901 sgd_solver.cpp:106] Iteration 90790, lr = 0.001
I0906 07:06:17.510042 90901 solver.cpp:228] Iteration 90800, loss = 0.0446709
I0906 07:06:17.510113 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0446721 (* 1 = 0.0446721 loss)
I0906 07:06:17.510130 90901 sgd_solver.cpp:106] Iteration 90800, lr = 0.001
I0906 07:06:22.809869 90901 solver.cpp:228] Iteration 90810, loss = 0.115291
I0906 07:06:22.810020 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115292 (* 1 = 0.115292 loss)
I0906 07:06:22.810040 90901 sgd_solver.cpp:106] Iteration 90810, lr = 0.001
I0906 07:06:27.951577 90901 solver.cpp:228] Iteration 90820, loss = 0.0359027
I0906 07:06:27.951660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0359039 (* 1 = 0.0359039 loss)
I0906 07:06:27.951678 90901 sgd_solver.cpp:106] Iteration 90820, lr = 0.001
I0906 07:06:33.523339 90901 solver.cpp:228] Iteration 90830, loss = 0.0798416
I0906 07:06:33.523428 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0798428 (* 1 = 0.0798428 loss)
I0906 07:06:33.523447 90901 sgd_solver.cpp:106] Iteration 90830, lr = 0.001
I0906 07:06:38.728832 90901 solver.cpp:228] Iteration 90840, loss = 0.113111
I0906 07:06:38.728905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113113 (* 1 = 0.113113 loss)
I0906 07:06:38.728930 90901 sgd_solver.cpp:106] Iteration 90840, lr = 0.001
I0906 07:06:43.972192 90901 solver.cpp:228] Iteration 90850, loss = 0.149336
I0906 07:06:43.972301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149337 (* 1 = 0.149337 loss)
I0906 07:06:43.972318 90901 sgd_solver.cpp:106] Iteration 90850, lr = 0.001
I0906 07:06:49.595031 90901 solver.cpp:228] Iteration 90860, loss = 0.0793004
I0906 07:06:49.595115 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0793017 (* 1 = 0.0793017 loss)
I0906 07:06:49.595132 90901 sgd_solver.cpp:106] Iteration 90860, lr = 0.001
I0906 07:06:56.956766 90901 solver.cpp:228] Iteration 90870, loss = 0.0661059
I0906 07:06:56.957135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0661072 (* 1 = 0.0661072 loss)
I0906 07:06:56.957156 90901 sgd_solver.cpp:106] Iteration 90870, lr = 0.001
I0906 07:07:04.053730 90901 solver.cpp:228] Iteration 90880, loss = 0.171085
I0906 07:07:04.053818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171086 (* 1 = 0.171086 loss)
I0906 07:07:04.053838 90901 sgd_solver.cpp:106] Iteration 90880, lr = 0.001
I0906 07:07:10.829453 90901 solver.cpp:228] Iteration 90890, loss = 0.139211
I0906 07:07:10.829589 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139212 (* 1 = 0.139212 loss)
I0906 07:07:10.829623 90901 sgd_solver.cpp:106] Iteration 90890, lr = 0.001
I0906 07:07:18.681138 90901 solver.cpp:228] Iteration 90900, loss = 0.0562614
I0906 07:07:18.681210 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0562627 (* 1 = 0.0562627 loss)
I0906 07:07:18.681227 90901 sgd_solver.cpp:106] Iteration 90900, lr = 0.001
I0906 07:07:26.758162 90901 solver.cpp:228] Iteration 90910, loss = 0.10217
I0906 07:07:26.758246 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102171 (* 1 = 0.102171 loss)
I0906 07:07:26.758265 90901 sgd_solver.cpp:106] Iteration 90910, lr = 0.001
I0906 07:07:34.949551 90901 solver.cpp:228] Iteration 90920, loss = 0.0918066
I0906 07:07:34.949724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0918078 (* 1 = 0.0918078 loss)
I0906 07:07:34.949756 90901 sgd_solver.cpp:106] Iteration 90920, lr = 0.001
I0906 07:07:43.237555 90901 solver.cpp:228] Iteration 90930, loss = 0.238207
I0906 07:07:43.237623 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238208 (* 1 = 0.238208 loss)
I0906 07:07:43.237639 90901 sgd_solver.cpp:106] Iteration 90930, lr = 0.001
I0906 07:07:51.580535 90901 solver.cpp:228] Iteration 90940, loss = 0.383211
I0906 07:07:51.580632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383213 (* 1 = 0.383213 loss)
I0906 07:07:51.580654 90901 sgd_solver.cpp:106] Iteration 90940, lr = 0.001
I0906 07:07:59.720249 90901 solver.cpp:228] Iteration 90950, loss = 0.20993
I0906 07:07:59.720340 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209931 (* 1 = 0.209931 loss)
I0906 07:07:59.720376 90901 sgd_solver.cpp:106] Iteration 90950, lr = 0.001
I0906 07:08:07.907946 90901 solver.cpp:228] Iteration 90960, loss = 0.2532
I0906 07:08:07.908157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253201 (* 1 = 0.253201 loss)
I0906 07:08:07.908177 90901 sgd_solver.cpp:106] Iteration 90960, lr = 0.001
I0906 07:08:16.099548 90901 solver.cpp:228] Iteration 90970, loss = 0.132834
I0906 07:08:16.099658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132836 (* 1 = 0.132836 loss)
I0906 07:08:16.099678 90901 sgd_solver.cpp:106] Iteration 90970, lr = 0.001
I0906 07:08:23.711104 90901 solver.cpp:228] Iteration 90980, loss = 0.128192
I0906 07:08:23.711204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128193 (* 1 = 0.128193 loss)
I0906 07:08:23.711226 90901 sgd_solver.cpp:106] Iteration 90980, lr = 0.001
I0906 07:08:31.382194 90901 solver.cpp:228] Iteration 90990, loss = 0.0677036
I0906 07:08:31.382264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0677048 (* 1 = 0.0677048 loss)
I0906 07:08:31.382282 90901 sgd_solver.cpp:106] Iteration 90990, lr = 0.001
I0906 07:08:39.349145 90901 solver.cpp:228] Iteration 91000, loss = 0.367786
I0906 07:08:39.349329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.367787 (* 1 = 0.367787 loss)
I0906 07:08:39.349355 90901 sgd_solver.cpp:106] Iteration 91000, lr = 0.001
I0906 07:08:46.781785 90901 solver.cpp:228] Iteration 91010, loss = 0.566627
I0906 07:08:46.781873 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566628 (* 1 = 0.566628 loss)
I0906 07:08:46.781893 90901 sgd_solver.cpp:106] Iteration 91010, lr = 0.001
I0906 07:08:54.594856 90901 solver.cpp:228] Iteration 91020, loss = 0.116641
I0906 07:08:54.594933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116643 (* 1 = 0.116643 loss)
I0906 07:08:54.594949 90901 sgd_solver.cpp:106] Iteration 91020, lr = 0.001
I0906 07:09:01.928397 90901 solver.cpp:228] Iteration 91030, loss = 0.0822826
I0906 07:09:01.928465 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0822838 (* 1 = 0.0822838 loss)
I0906 07:09:01.928483 90901 sgd_solver.cpp:106] Iteration 91030, lr = 0.001
I0906 07:09:08.406563 90901 solver.cpp:228] Iteration 91040, loss = 0.0963091
I0906 07:09:08.406647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0963102 (* 1 = 0.0963102 loss)
I0906 07:09:08.406674 90901 sgd_solver.cpp:106] Iteration 91040, lr = 0.001
I0906 07:09:16.772034 90901 solver.cpp:228] Iteration 91050, loss = 0.0682861
I0906 07:09:16.772315 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0682873 (* 1 = 0.0682873 loss)
I0906 07:09:16.772335 90901 sgd_solver.cpp:106] Iteration 91050, lr = 0.001
I0906 07:09:25.054605 90901 solver.cpp:228] Iteration 91060, loss = 0.195697
I0906 07:09:25.054719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195698 (* 1 = 0.195698 loss)
I0906 07:09:25.054745 90901 sgd_solver.cpp:106] Iteration 91060, lr = 0.001
I0906 07:09:33.193136 90901 solver.cpp:228] Iteration 91070, loss = 0.175042
I0906 07:09:33.193215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175043 (* 1 = 0.175043 loss)
I0906 07:09:33.193233 90901 sgd_solver.cpp:106] Iteration 91070, lr = 0.001
I0906 07:09:41.832988 90901 solver.cpp:228] Iteration 91080, loss = 0.0628692
I0906 07:09:41.833073 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0628704 (* 1 = 0.0628704 loss)
I0906 07:09:41.833092 90901 sgd_solver.cpp:106] Iteration 91080, lr = 0.001
I0906 07:09:49.988797 90901 solver.cpp:228] Iteration 91090, loss = 0.0853694
I0906 07:09:49.988978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853706 (* 1 = 0.0853706 loss)
I0906 07:09:49.988998 90901 sgd_solver.cpp:106] Iteration 91090, lr = 0.001
I0906 07:09:58.449069 90901 solver.cpp:228] Iteration 91100, loss = 0.251679
I0906 07:09:58.449136 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.25168 (* 1 = 0.25168 loss)
I0906 07:09:58.449154 90901 sgd_solver.cpp:106] Iteration 91100, lr = 0.001
I0906 07:10:06.512784 90901 solver.cpp:228] Iteration 91110, loss = 0.149867
I0906 07:10:06.512848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149868 (* 1 = 0.149868 loss)
I0906 07:10:06.512866 90901 sgd_solver.cpp:106] Iteration 91110, lr = 0.001
I0906 07:10:15.291728 90901 solver.cpp:228] Iteration 91120, loss = 0.0628719
I0906 07:10:15.291790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.062873 (* 1 = 0.062873 loss)
I0906 07:10:15.291806 90901 sgd_solver.cpp:106] Iteration 91120, lr = 0.001
I0906 07:10:23.802990 90901 solver.cpp:228] Iteration 91130, loss = 0.167659
I0906 07:10:23.803138 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16766 (* 1 = 0.16766 loss)
I0906 07:10:23.803176 90901 sgd_solver.cpp:106] Iteration 91130, lr = 0.001
I0906 07:10:32.424077 90901 solver.cpp:228] Iteration 91140, loss = 0.0403768
I0906 07:10:32.424209 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0403779 (* 1 = 0.0403779 loss)
I0906 07:10:32.424234 90901 sgd_solver.cpp:106] Iteration 91140, lr = 0.001
I0906 07:10:40.275219 90901 solver.cpp:228] Iteration 91150, loss = 0.0237747
I0906 07:10:40.275281 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0237758 (* 1 = 0.0237758 loss)
I0906 07:10:40.275298 90901 sgd_solver.cpp:106] Iteration 91150, lr = 0.001
I0906 07:10:47.006371 90901 solver.cpp:228] Iteration 91160, loss = 0.0983919
I0906 07:10:47.006476 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0983931 (* 1 = 0.0983931 loss)
I0906 07:10:47.006494 90901 sgd_solver.cpp:106] Iteration 91160, lr = 0.001
I0906 07:10:54.897972 90901 solver.cpp:228] Iteration 91170, loss = 0.197271
I0906 07:10:54.898270 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197273 (* 1 = 0.197273 loss)
I0906 07:10:54.898289 90901 sgd_solver.cpp:106] Iteration 91170, lr = 0.001
I0906 07:11:03.178258 90901 solver.cpp:228] Iteration 91180, loss = 0.0563024
I0906 07:11:03.178329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0563035 (* 1 = 0.0563035 loss)
I0906 07:11:03.178346 90901 sgd_solver.cpp:106] Iteration 91180, lr = 0.001
I0906 07:11:12.036640 90901 solver.cpp:228] Iteration 91190, loss = 0.330024
I0906 07:11:12.036708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.330025 (* 1 = 0.330025 loss)
I0906 07:11:12.036726 90901 sgd_solver.cpp:106] Iteration 91190, lr = 0.001
I0906 07:11:19.760634 90901 solver.cpp:337] Iteration 91200, Testing net (#0)
I0906 07:12:15.277458 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9525
I0906 07:12:15.277649 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.130901 (* 1 = 0.130901 loss)
I0906 07:12:15.683912 90901 solver.cpp:228] Iteration 91200, loss = 0.19721
I0906 07:12:15.683991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.197211 (* 1 = 0.197211 loss)
I0906 07:12:15.684015 90901 sgd_solver.cpp:106] Iteration 91200, lr = 0.001
I0906 07:12:23.336467 90901 solver.cpp:228] Iteration 91210, loss = 0.0258167
I0906 07:12:23.336529 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0258178 (* 1 = 0.0258178 loss)
I0906 07:12:23.336542 90901 sgd_solver.cpp:106] Iteration 91210, lr = 0.001
I0906 07:12:30.830919 90901 solver.cpp:228] Iteration 91220, loss = 0.0978851
I0906 07:12:30.830991 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0978862 (* 1 = 0.0978862 loss)
I0906 07:12:30.831009 90901 sgd_solver.cpp:106] Iteration 91220, lr = 0.001
I0906 07:12:37.116878 90901 solver.cpp:228] Iteration 91230, loss = 0.107942
I0906 07:12:37.117008 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107943 (* 1 = 0.107943 loss)
I0906 07:12:37.117028 90901 sgd_solver.cpp:106] Iteration 91230, lr = 0.001
I0906 07:12:42.011415 90901 solver.cpp:228] Iteration 91240, loss = 0.390356
I0906 07:12:42.011556 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.390357 (* 1 = 0.390357 loss)
I0906 07:12:42.011585 90901 sgd_solver.cpp:106] Iteration 91240, lr = 0.001
I0906 07:12:47.571888 90901 solver.cpp:228] Iteration 91250, loss = 0.038349
I0906 07:12:47.572055 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.03835 (* 1 = 0.03835 loss)
I0906 07:12:47.572072 90901 sgd_solver.cpp:106] Iteration 91250, lr = 0.001
I0906 07:12:52.789768 90901 solver.cpp:228] Iteration 91260, loss = 0.0643385
I0906 07:12:52.789842 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0643396 (* 1 = 0.0643396 loss)
I0906 07:12:52.789860 90901 sgd_solver.cpp:106] Iteration 91260, lr = 0.001
I0906 07:12:58.551187 90901 solver.cpp:228] Iteration 91270, loss = 0.119821
I0906 07:12:58.551285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119822 (* 1 = 0.119822 loss)
I0906 07:12:58.551304 90901 sgd_solver.cpp:106] Iteration 91270, lr = 0.001
I0906 07:13:04.353163 90901 solver.cpp:228] Iteration 91280, loss = 0.0623206
I0906 07:13:04.353256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0623216 (* 1 = 0.0623216 loss)
I0906 07:13:04.353278 90901 sgd_solver.cpp:106] Iteration 91280, lr = 0.001
I0906 07:13:10.017031 90901 solver.cpp:228] Iteration 91290, loss = 0.217388
I0906 07:13:10.017108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.217389 (* 1 = 0.217389 loss)
I0906 07:13:10.017125 90901 sgd_solver.cpp:106] Iteration 91290, lr = 0.001
I0906 07:13:16.600803 90901 solver.cpp:228] Iteration 91300, loss = 0.102381
I0906 07:13:16.600867 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102382 (* 1 = 0.102382 loss)
I0906 07:13:16.600884 90901 sgd_solver.cpp:106] Iteration 91300, lr = 0.001
I0906 07:13:22.869789 90901 solver.cpp:228] Iteration 91310, loss = 0.0289092
I0906 07:13:22.870000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0289103 (* 1 = 0.0289103 loss)
I0906 07:13:22.870020 90901 sgd_solver.cpp:106] Iteration 91310, lr = 0.001
I0906 07:13:29.175285 90901 solver.cpp:228] Iteration 91320, loss = 0.221015
I0906 07:13:29.175397 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221016 (* 1 = 0.221016 loss)
I0906 07:13:29.175421 90901 sgd_solver.cpp:106] Iteration 91320, lr = 0.001
I0906 07:13:34.986438 90901 solver.cpp:228] Iteration 91330, loss = 0.199096
I0906 07:13:34.986508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199097 (* 1 = 0.199097 loss)
I0906 07:13:34.986524 90901 sgd_solver.cpp:106] Iteration 91330, lr = 0.001
I0906 07:13:41.727113 90901 solver.cpp:228] Iteration 91340, loss = 0.0300806
I0906 07:13:41.727187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0300818 (* 1 = 0.0300818 loss)
I0906 07:13:41.727205 90901 sgd_solver.cpp:106] Iteration 91340, lr = 0.001
I0906 07:13:48.812752 90901 solver.cpp:228] Iteration 91350, loss = 0.195502
I0906 07:13:48.812824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195503 (* 1 = 0.195503 loss)
I0906 07:13:48.812840 90901 sgd_solver.cpp:106] Iteration 91350, lr = 0.001
I0906 07:13:55.290057 90901 solver.cpp:228] Iteration 91360, loss = 0.108896
I0906 07:13:55.290252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108898 (* 1 = 0.108898 loss)
I0906 07:13:55.290285 90901 sgd_solver.cpp:106] Iteration 91360, lr = 0.001
I0906 07:14:01.776131 90901 solver.cpp:228] Iteration 91370, loss = 0.0543666
I0906 07:14:01.776219 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0543677 (* 1 = 0.0543677 loss)
I0906 07:14:01.776237 90901 sgd_solver.cpp:106] Iteration 91370, lr = 0.001
I0906 07:14:08.077733 90901 solver.cpp:228] Iteration 91380, loss = 0.300598
I0906 07:14:08.077807 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.300599 (* 1 = 0.300599 loss)
I0906 07:14:08.077831 90901 sgd_solver.cpp:106] Iteration 91380, lr = 0.001
I0906 07:14:15.447834 90901 solver.cpp:228] Iteration 91390, loss = 0.0775006
I0906 07:14:15.447926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0775017 (* 1 = 0.0775017 loss)
I0906 07:14:15.447942 90901 sgd_solver.cpp:106] Iteration 91390, lr = 0.001
I0906 07:14:22.555341 90901 solver.cpp:228] Iteration 91400, loss = 0.116256
I0906 07:14:22.555423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116257 (* 1 = 0.116257 loss)
I0906 07:14:22.555446 90901 sgd_solver.cpp:106] Iteration 91400, lr = 0.001
I0906 07:14:29.333068 90901 solver.cpp:228] Iteration 91410, loss = 0.181871
I0906 07:14:29.333235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181872 (* 1 = 0.181872 loss)
I0906 07:14:29.333253 90901 sgd_solver.cpp:106] Iteration 91410, lr = 0.001
I0906 07:14:36.695286 90901 solver.cpp:228] Iteration 91420, loss = 0.07744
I0906 07:14:36.695386 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0774411 (* 1 = 0.0774411 loss)
I0906 07:14:36.695407 90901 sgd_solver.cpp:106] Iteration 91420, lr = 0.001
I0906 07:14:44.540091 90901 solver.cpp:228] Iteration 91430, loss = 0.0539961
I0906 07:14:44.540199 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0539972 (* 1 = 0.0539972 loss)
I0906 07:14:44.540217 90901 sgd_solver.cpp:106] Iteration 91430, lr = 0.001
I0906 07:14:51.148581 90901 solver.cpp:228] Iteration 91440, loss = 0.135003
I0906 07:14:51.148663 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135004 (* 1 = 0.135004 loss)
I0906 07:14:51.148684 90901 sgd_solver.cpp:106] Iteration 91440, lr = 0.001
I0906 07:14:59.585489 90901 solver.cpp:228] Iteration 91450, loss = 0.365638
I0906 07:14:59.585728 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.36564 (* 1 = 0.36564 loss)
I0906 07:14:59.585748 90901 sgd_solver.cpp:106] Iteration 91450, lr = 0.001
I0906 07:15:06.530586 90901 solver.cpp:228] Iteration 91460, loss = 0.13763
I0906 07:15:06.530690 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137632 (* 1 = 0.137632 loss)
I0906 07:15:06.530709 90901 sgd_solver.cpp:106] Iteration 91460, lr = 0.001
I0906 07:15:14.050761 90901 solver.cpp:228] Iteration 91470, loss = 0.189815
I0906 07:15:14.050845 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189816 (* 1 = 0.189816 loss)
I0906 07:15:14.050863 90901 sgd_solver.cpp:106] Iteration 91470, lr = 0.001
I0906 07:15:20.643044 90901 solver.cpp:228] Iteration 91480, loss = 0.270081
I0906 07:15:20.643141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270082 (* 1 = 0.270082 loss)
I0906 07:15:20.643159 90901 sgd_solver.cpp:106] Iteration 91480, lr = 0.001
I0906 07:15:28.559275 90901 solver.cpp:228] Iteration 91490, loss = 0.148537
I0906 07:15:28.559391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148538 (* 1 = 0.148538 loss)
I0906 07:15:28.559409 90901 sgd_solver.cpp:106] Iteration 91490, lr = 0.001
I0906 07:15:35.474619 90901 solver.cpp:228] Iteration 91500, loss = 0.14937
I0906 07:15:35.474884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149372 (* 1 = 0.149372 loss)
I0906 07:15:35.474905 90901 sgd_solver.cpp:106] Iteration 91500, lr = 0.001
I0906 07:15:42.995019 90901 solver.cpp:228] Iteration 91510, loss = 0.0309718
I0906 07:15:42.995095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0309729 (* 1 = 0.0309729 loss)
I0906 07:15:42.995112 90901 sgd_solver.cpp:106] Iteration 91510, lr = 0.001
I0906 07:15:50.776034 90901 solver.cpp:228] Iteration 91520, loss = 0.265514
I0906 07:15:50.776244 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265515 (* 1 = 0.265515 loss)
I0906 07:15:50.776268 90901 sgd_solver.cpp:106] Iteration 91520, lr = 0.001
I0906 07:15:57.890696 90901 solver.cpp:228] Iteration 91530, loss = 0.114824
I0906 07:15:57.890771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114825 (* 1 = 0.114825 loss)
I0906 07:15:57.890792 90901 sgd_solver.cpp:106] Iteration 91530, lr = 0.001
I0906 07:16:05.718142 90901 solver.cpp:228] Iteration 91540, loss = 0.14909
I0906 07:16:05.718363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149091 (* 1 = 0.149091 loss)
I0906 07:16:05.718382 90901 sgd_solver.cpp:106] Iteration 91540, lr = 0.001
I0906 07:16:12.548629 90901 solver.cpp:228] Iteration 91550, loss = 0.109074
I0906 07:16:12.548722 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109075 (* 1 = 0.109075 loss)
I0906 07:16:12.548740 90901 sgd_solver.cpp:106] Iteration 91550, lr = 0.001
I0906 07:16:20.653610 90901 solver.cpp:228] Iteration 91560, loss = 0.0829698
I0906 07:16:20.653676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0829708 (* 1 = 0.0829708 loss)
I0906 07:16:20.653693 90901 sgd_solver.cpp:106] Iteration 91560, lr = 0.001
I0906 07:16:27.202950 90901 solver.cpp:228] Iteration 91570, loss = 0.0445447
I0906 07:16:27.203044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0445457 (* 1 = 0.0445457 loss)
I0906 07:16:27.203063 90901 sgd_solver.cpp:106] Iteration 91570, lr = 0.001
I0906 07:16:35.137940 90901 solver.cpp:228] Iteration 91580, loss = 0.118096
I0906 07:16:35.138100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118097 (* 1 = 0.118097 loss)
I0906 07:16:35.138139 90901 sgd_solver.cpp:106] Iteration 91580, lr = 0.001
I0906 07:16:41.828124 90901 solver.cpp:228] Iteration 91590, loss = 0.677366
I0906 07:16:41.828311 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.677367 (* 1 = 0.677367 loss)
I0906 07:16:41.828343 90901 sgd_solver.cpp:106] Iteration 91590, lr = 0.001
I0906 07:16:50.766433 90901 solver.cpp:228] Iteration 91600, loss = 0.0969826
I0906 07:16:50.766507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0969837 (* 1 = 0.0969837 loss)
I0906 07:16:50.766525 90901 sgd_solver.cpp:106] Iteration 91600, lr = 0.001
I0906 07:16:57.455154 90901 solver.cpp:228] Iteration 91610, loss = 0.207572
I0906 07:16:57.455243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207573 (* 1 = 0.207573 loss)
I0906 07:16:57.455260 90901 sgd_solver.cpp:106] Iteration 91610, lr = 0.001
I0906 07:17:05.166362 90901 solver.cpp:228] Iteration 91620, loss = 0.0435688
I0906 07:17:05.166513 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0435699 (* 1 = 0.0435699 loss)
I0906 07:17:05.166545 90901 sgd_solver.cpp:106] Iteration 91620, lr = 0.001
I0906 07:17:12.218343 90901 solver.cpp:228] Iteration 91630, loss = 0.0773249
I0906 07:17:12.218698 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.077326 (* 1 = 0.077326 loss)
I0906 07:17:12.218735 90901 sgd_solver.cpp:106] Iteration 91630, lr = 0.001
I0906 07:17:19.500699 90901 solver.cpp:228] Iteration 91640, loss = 0.142129
I0906 07:17:19.500777 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.14213 (* 1 = 0.14213 loss)
I0906 07:17:19.500800 90901 sgd_solver.cpp:106] Iteration 91640, lr = 0.001
I0906 07:17:26.427832 90901 solver.cpp:228] Iteration 91650, loss = 0.0762914
I0906 07:17:26.427899 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0762925 (* 1 = 0.0762925 loss)
I0906 07:17:26.427917 90901 sgd_solver.cpp:106] Iteration 91650, lr = 0.001
I0906 07:17:34.527051 90901 solver.cpp:228] Iteration 91660, loss = 0.21508
I0906 07:17:34.527133 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215081 (* 1 = 0.215081 loss)
I0906 07:17:34.527150 90901 sgd_solver.cpp:106] Iteration 91660, lr = 0.001
I0906 07:17:41.433095 90901 solver.cpp:228] Iteration 91670, loss = 0.0766933
I0906 07:17:41.433187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0766944 (* 1 = 0.0766944 loss)
I0906 07:17:41.433208 90901 sgd_solver.cpp:106] Iteration 91670, lr = 0.001
I0906 07:17:49.380339 90901 solver.cpp:228] Iteration 91680, loss = 0.171141
I0906 07:17:49.380532 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171142 (* 1 = 0.171142 loss)
I0906 07:17:49.380561 90901 sgd_solver.cpp:106] Iteration 91680, lr = 0.001
I0906 07:17:56.158488 90901 solver.cpp:228] Iteration 91690, loss = 0.190145
I0906 07:17:56.158547 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190146 (* 1 = 0.190146 loss)
I0906 07:17:56.158562 90901 sgd_solver.cpp:106] Iteration 91690, lr = 0.001
I0906 07:18:03.984968 90901 solver.cpp:228] Iteration 91700, loss = 0.108277
I0906 07:18:03.985043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108278 (* 1 = 0.108278 loss)
I0906 07:18:03.985059 90901 sgd_solver.cpp:106] Iteration 91700, lr = 0.001
I0906 07:18:10.452921 90901 solver.cpp:228] Iteration 91710, loss = 0.123653
I0906 07:18:10.452993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123654 (* 1 = 0.123654 loss)
I0906 07:18:10.453011 90901 sgd_solver.cpp:106] Iteration 91710, lr = 0.001
I0906 07:18:18.402799 90901 solver.cpp:228] Iteration 91720, loss = 0.0264117
I0906 07:18:18.402863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0264128 (* 1 = 0.0264128 loss)
I0906 07:18:18.402884 90901 sgd_solver.cpp:106] Iteration 91720, lr = 0.001
I0906 07:18:25.284373 90901 solver.cpp:228] Iteration 91730, loss = 0.106827
I0906 07:18:25.284533 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106828 (* 1 = 0.106828 loss)
I0906 07:18:25.284566 90901 sgd_solver.cpp:106] Iteration 91730, lr = 0.001
I0906 07:18:33.206876 90901 solver.cpp:228] Iteration 91740, loss = 0.0771469
I0906 07:18:33.206957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0771479 (* 1 = 0.0771479 loss)
I0906 07:18:33.206977 90901 sgd_solver.cpp:106] Iteration 91740, lr = 0.001
I0906 07:18:41.086832 90901 solver.cpp:228] Iteration 91750, loss = 0.0583625
I0906 07:18:41.086917 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0583635 (* 1 = 0.0583635 loss)
I0906 07:18:41.086935 90901 sgd_solver.cpp:106] Iteration 91750, lr = 0.001
I0906 07:18:47.626235 90901 solver.cpp:228] Iteration 91760, loss = 0.114648
I0906 07:18:47.626351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114649 (* 1 = 0.114649 loss)
I0906 07:18:47.626380 90901 sgd_solver.cpp:106] Iteration 91760, lr = 0.001
I0906 07:18:55.647624 90901 solver.cpp:228] Iteration 91770, loss = 0.0836074
I0906 07:18:55.647824 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0836084 (* 1 = 0.0836084 loss)
I0906 07:18:55.647840 90901 sgd_solver.cpp:106] Iteration 91770, lr = 0.001
I0906 07:19:02.655814 90901 solver.cpp:228] Iteration 91780, loss = 0.0738617
I0906 07:19:02.655954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0738627 (* 1 = 0.0738627 loss)
I0906 07:19:02.656011 90901 sgd_solver.cpp:106] Iteration 91780, lr = 0.001
I0906 07:19:10.894439 90901 solver.cpp:228] Iteration 91790, loss = 0.0896725
I0906 07:19:10.894508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0896735 (* 1 = 0.0896735 loss)
I0906 07:19:10.894526 90901 sgd_solver.cpp:106] Iteration 91790, lr = 0.001
I0906 07:19:18.933444 90901 solver.cpp:228] Iteration 91800, loss = 0.272622
I0906 07:19:18.933526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272623 (* 1 = 0.272623 loss)
I0906 07:19:18.933543 90901 sgd_solver.cpp:106] Iteration 91800, lr = 0.001
I0906 07:19:25.778954 90901 solver.cpp:228] Iteration 91810, loss = 0.463248
I0906 07:19:25.779127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463249 (* 1 = 0.463249 loss)
I0906 07:19:25.779150 90901 sgd_solver.cpp:106] Iteration 91810, lr = 0.001
I0906 07:19:33.928324 90901 solver.cpp:228] Iteration 91820, loss = 0.143894
I0906 07:19:33.928395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143895 (* 1 = 0.143895 loss)
I0906 07:19:33.928413 90901 sgd_solver.cpp:106] Iteration 91820, lr = 0.001
I0906 07:19:40.195725 90901 solver.cpp:228] Iteration 91830, loss = 0.0423812
I0906 07:19:40.195811 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0423822 (* 1 = 0.0423822 loss)
I0906 07:19:40.195827 90901 sgd_solver.cpp:106] Iteration 91830, lr = 0.001
I0906 07:19:48.452383 90901 solver.cpp:228] Iteration 91840, loss = 0.153494
I0906 07:19:48.452472 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153495 (* 1 = 0.153495 loss)
I0906 07:19:48.452491 90901 sgd_solver.cpp:106] Iteration 91840, lr = 0.001
I0906 07:19:54.580525 90901 solver.cpp:228] Iteration 91850, loss = 0.157491
I0906 07:19:54.580597 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157492 (* 1 = 0.157492 loss)
I0906 07:19:54.580618 90901 sgd_solver.cpp:106] Iteration 91850, lr = 0.001
I0906 07:20:03.000459 90901 solver.cpp:228] Iteration 91860, loss = 0.372755
I0906 07:20:03.000672 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.372756 (* 1 = 0.372756 loss)
I0906 07:20:03.000691 90901 sgd_solver.cpp:106] Iteration 91860, lr = 0.001
I0906 07:20:09.222070 90901 solver.cpp:228] Iteration 91870, loss = 0.0389579
I0906 07:20:09.222162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.038959 (* 1 = 0.038959 loss)
I0906 07:20:09.222184 90901 sgd_solver.cpp:106] Iteration 91870, lr = 0.001
I0906 07:20:17.315027 90901 solver.cpp:228] Iteration 91880, loss = 0.142093
I0906 07:20:17.315147 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142094 (* 1 = 0.142094 loss)
I0906 07:20:17.315170 90901 sgd_solver.cpp:106] Iteration 91880, lr = 0.001
I0906 07:20:23.969563 90901 solver.cpp:228] Iteration 91890, loss = 0.436826
I0906 07:20:23.969655 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.436827 (* 1 = 0.436827 loss)
I0906 07:20:23.969676 90901 sgd_solver.cpp:106] Iteration 91890, lr = 0.001
I0906 07:20:31.833669 90901 solver.cpp:228] Iteration 91900, loss = 0.187521
I0906 07:20:31.833747 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187522 (* 1 = 0.187522 loss)
I0906 07:20:31.833765 90901 sgd_solver.cpp:106] Iteration 91900, lr = 0.001
I0906 07:20:39.446650 90901 solver.cpp:228] Iteration 91910, loss = 0.0348704
I0906 07:20:39.446892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0348715 (* 1 = 0.0348715 loss)
I0906 07:20:39.446910 90901 sgd_solver.cpp:106] Iteration 91910, lr = 0.001
I0906 07:20:46.204836 90901 solver.cpp:228] Iteration 91920, loss = 0.0275962
I0906 07:20:46.204921 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0275973 (* 1 = 0.0275973 loss)
I0906 07:20:46.204938 90901 sgd_solver.cpp:106] Iteration 91920, lr = 0.001
I0906 07:20:53.318488 90901 solver.cpp:228] Iteration 91930, loss = 0.224858
I0906 07:20:53.318552 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.224859 (* 1 = 0.224859 loss)
I0906 07:20:53.318568 90901 sgd_solver.cpp:106] Iteration 91930, lr = 0.001
I0906 07:21:00.421468 90901 solver.cpp:228] Iteration 91940, loss = 0.0433333
I0906 07:21:00.421530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0433344 (* 1 = 0.0433344 loss)
I0906 07:21:00.421550 90901 sgd_solver.cpp:106] Iteration 91940, lr = 0.001
I0906 07:21:07.028858 90901 solver.cpp:228] Iteration 91950, loss = 0.104233
I0906 07:21:07.028959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104234 (* 1 = 0.104234 loss)
I0906 07:21:07.028980 90901 sgd_solver.cpp:106] Iteration 91950, lr = 0.001
I0906 07:21:13.778158 90901 solver.cpp:228] Iteration 91960, loss = 0.20127
I0906 07:21:13.778295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201272 (* 1 = 0.201272 loss)
I0906 07:21:13.778324 90901 sgd_solver.cpp:106] Iteration 91960, lr = 0.001
I0906 07:21:20.584794 90901 solver.cpp:228] Iteration 91970, loss = 0.191374
I0906 07:21:20.584863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191375 (* 1 = 0.191375 loss)
I0906 07:21:20.584887 90901 sgd_solver.cpp:106] Iteration 91970, lr = 0.001
I0906 07:21:27.157903 90901 solver.cpp:228] Iteration 91980, loss = 0.096849
I0906 07:21:27.158004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0968501 (* 1 = 0.0968501 loss)
I0906 07:21:27.158022 90901 sgd_solver.cpp:106] Iteration 91980, lr = 0.001
I0906 07:21:33.127670 90901 solver.cpp:228] Iteration 91990, loss = 0.0551986
I0906 07:21:33.127737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0551997 (* 1 = 0.0551997 loss)
I0906 07:21:33.127755 90901 sgd_solver.cpp:106] Iteration 91990, lr = 0.001
I0906 07:21:39.253134 90901 solver.cpp:337] Iteration 92000, Testing net (#0)
I0906 07:22:20.079304 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.943125
I0906 07:22:20.079485 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.160105 (* 1 = 0.160105 loss)
I0906 07:22:20.295833 90901 solver.cpp:228] Iteration 92000, loss = 0.329371
I0906 07:22:20.295927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329372 (* 1 = 0.329372 loss)
I0906 07:22:20.295958 90901 sgd_solver.cpp:106] Iteration 92000, lr = 0.001
I0906 07:22:25.819344 90901 solver.cpp:228] Iteration 92010, loss = 0.0899315
I0906 07:22:25.819407 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0899326 (* 1 = 0.0899326 loss)
I0906 07:22:25.819424 90901 sgd_solver.cpp:106] Iteration 92010, lr = 0.001
I0906 07:22:31.008435 90901 solver.cpp:228] Iteration 92020, loss = 0.0442455
I0906 07:22:31.008499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0442465 (* 1 = 0.0442465 loss)
I0906 07:22:31.008517 90901 sgd_solver.cpp:106] Iteration 92020, lr = 0.001
I0906 07:22:36.226266 90901 solver.cpp:228] Iteration 92030, loss = 0.086097
I0906 07:22:36.226335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0860981 (* 1 = 0.0860981 loss)
I0906 07:22:36.226351 90901 sgd_solver.cpp:106] Iteration 92030, lr = 0.001
I0906 07:22:41.433831 90901 solver.cpp:228] Iteration 92040, loss = 0.0723791
I0906 07:22:41.433900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0723802 (* 1 = 0.0723802 loss)
I0906 07:22:41.433917 90901 sgd_solver.cpp:106] Iteration 92040, lr = 0.001
I0906 07:22:46.975471 90901 solver.cpp:228] Iteration 92050, loss = 0.182673
I0906 07:22:46.975550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182674 (* 1 = 0.182674 loss)
I0906 07:22:46.975566 90901 sgd_solver.cpp:106] Iteration 92050, lr = 0.001
I0906 07:22:52.207653 90901 solver.cpp:228] Iteration 92060, loss = 0.054952
I0906 07:22:52.208037 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.054953 (* 1 = 0.054953 loss)
I0906 07:22:52.208063 90901 sgd_solver.cpp:106] Iteration 92060, lr = 0.001
I0906 07:22:57.430878 90901 solver.cpp:228] Iteration 92070, loss = 0.293986
I0906 07:22:57.430959 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.293987 (* 1 = 0.293987 loss)
I0906 07:22:57.430977 90901 sgd_solver.cpp:106] Iteration 92070, lr = 0.001
I0906 07:23:02.668509 90901 solver.cpp:228] Iteration 92080, loss = 0.0260931
I0906 07:23:02.668571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0260941 (* 1 = 0.0260941 loss)
I0906 07:23:02.668588 90901 sgd_solver.cpp:106] Iteration 92080, lr = 0.001
I0906 07:23:08.243911 90901 solver.cpp:228] Iteration 92090, loss = 0.0310459
I0906 07:23:08.243986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0310469 (* 1 = 0.0310469 loss)
I0906 07:23:08.244004 90901 sgd_solver.cpp:106] Iteration 92090, lr = 0.001
I0906 07:23:13.957789 90901 solver.cpp:228] Iteration 92100, loss = 0.247083
I0906 07:23:13.957871 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247084 (* 1 = 0.247084 loss)
I0906 07:23:13.957890 90901 sgd_solver.cpp:106] Iteration 92100, lr = 0.001
I0906 07:23:21.027693 90901 solver.cpp:228] Iteration 92110, loss = 0.016362
I0906 07:23:21.027757 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.016363 (* 1 = 0.016363 loss)
I0906 07:23:21.027775 90901 sgd_solver.cpp:106] Iteration 92110, lr = 0.001
I0906 07:23:28.274070 90901 solver.cpp:228] Iteration 92120, loss = 0.132029
I0906 07:23:28.274267 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13203 (* 1 = 0.13203 loss)
I0906 07:23:28.274312 90901 sgd_solver.cpp:106] Iteration 92120, lr = 0.001
I0906 07:23:35.325513 90901 solver.cpp:228] Iteration 92130, loss = 0.0819649
I0906 07:23:35.325610 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0819659 (* 1 = 0.0819659 loss)
I0906 07:23:35.325629 90901 sgd_solver.cpp:106] Iteration 92130, lr = 0.001
I0906 07:23:42.733460 90901 solver.cpp:228] Iteration 92140, loss = 0.0201605
I0906 07:23:42.733542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0201615 (* 1 = 0.0201615 loss)
I0906 07:23:42.733559 90901 sgd_solver.cpp:106] Iteration 92140, lr = 0.001
I0906 07:23:50.495501 90901 solver.cpp:228] Iteration 92150, loss = 0.20817
I0906 07:23:50.495568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208171 (* 1 = 0.208171 loss)
I0906 07:23:50.495584 90901 sgd_solver.cpp:106] Iteration 92150, lr = 0.001
I0906 07:23:58.125195 90901 solver.cpp:228] Iteration 92160, loss = 0.111746
I0906 07:23:58.125263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111747 (* 1 = 0.111747 loss)
I0906 07:23:58.125279 90901 sgd_solver.cpp:106] Iteration 92160, lr = 0.001
I0906 07:24:05.739034 90901 solver.cpp:228] Iteration 92170, loss = 0.338133
I0906 07:24:05.739395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338134 (* 1 = 0.338134 loss)
I0906 07:24:05.739418 90901 sgd_solver.cpp:106] Iteration 92170, lr = 0.001
I0906 07:24:13.811044 90901 solver.cpp:228] Iteration 92180, loss = 0.095461
I0906 07:24:13.811116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.095462 (* 1 = 0.095462 loss)
I0906 07:24:13.811134 90901 sgd_solver.cpp:106] Iteration 92180, lr = 0.001
I0906 07:24:21.671607 90901 solver.cpp:228] Iteration 92190, loss = 0.755839
I0906 07:24:21.671666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.75584 (* 1 = 0.75584 loss)
I0906 07:24:21.671684 90901 sgd_solver.cpp:106] Iteration 92190, lr = 0.001
I0906 07:24:29.718132 90901 solver.cpp:228] Iteration 92200, loss = 0.170631
I0906 07:24:29.718205 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170632 (* 1 = 0.170632 loss)
I0906 07:24:29.718222 90901 sgd_solver.cpp:106] Iteration 92200, lr = 0.001
I0906 07:24:37.235709 90901 solver.cpp:228] Iteration 92210, loss = 0.0672613
I0906 07:24:37.235924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0672623 (* 1 = 0.0672623 loss)
I0906 07:24:37.235942 90901 sgd_solver.cpp:106] Iteration 92210, lr = 0.001
I0906 07:24:45.465013 90901 solver.cpp:228] Iteration 92220, loss = 0.174452
I0906 07:24:45.465080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174453 (* 1 = 0.174453 loss)
I0906 07:24:45.465098 90901 sgd_solver.cpp:106] Iteration 92220, lr = 0.001
I0906 07:24:53.077442 90901 solver.cpp:228] Iteration 92230, loss = 0.0339553
I0906 07:24:53.077539 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0339563 (* 1 = 0.0339563 loss)
I0906 07:24:53.077561 90901 sgd_solver.cpp:106] Iteration 92230, lr = 0.001
I0906 07:25:00.522649 90901 solver.cpp:228] Iteration 92240, loss = 0.0474931
I0906 07:25:00.522727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.047494 (* 1 = 0.047494 loss)
I0906 07:25:00.522754 90901 sgd_solver.cpp:106] Iteration 92240, lr = 0.001
I0906 07:25:08.737406 90901 solver.cpp:228] Iteration 92250, loss = 0.0833425
I0906 07:25:08.737568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0833434 (* 1 = 0.0833434 loss)
I0906 07:25:08.737598 90901 sgd_solver.cpp:106] Iteration 92250, lr = 0.001
I0906 07:25:17.699928 90901 solver.cpp:228] Iteration 92260, loss = 0.356022
I0906 07:25:17.700040 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.356023 (* 1 = 0.356023 loss)
I0906 07:25:17.700062 90901 sgd_solver.cpp:106] Iteration 92260, lr = 0.001
I0906 07:25:25.833267 90901 solver.cpp:228] Iteration 92270, loss = 0.0537246
I0906 07:25:25.833395 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0537255 (* 1 = 0.0537255 loss)
I0906 07:25:25.833416 90901 sgd_solver.cpp:106] Iteration 92270, lr = 0.001
I0906 07:25:34.026579 90901 solver.cpp:228] Iteration 92280, loss = 0.2189
I0906 07:25:34.026732 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218901 (* 1 = 0.218901 loss)
I0906 07:25:34.026770 90901 sgd_solver.cpp:106] Iteration 92280, lr = 0.001
I0906 07:25:42.147693 90901 solver.cpp:228] Iteration 92290, loss = 0.0396507
I0906 07:25:42.147914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0396516 (* 1 = 0.0396516 loss)
I0906 07:25:42.147939 90901 sgd_solver.cpp:106] Iteration 92290, lr = 0.001
I0906 07:25:50.467764 90901 solver.cpp:228] Iteration 92300, loss = 0.151188
I0906 07:25:50.467828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151189 (* 1 = 0.151189 loss)
I0906 07:25:50.467846 90901 sgd_solver.cpp:106] Iteration 92300, lr = 0.001
I0906 07:25:58.145889 90901 solver.cpp:228] Iteration 92310, loss = 0.0711594
I0906 07:25:58.145963 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0711604 (* 1 = 0.0711604 loss)
I0906 07:25:58.145983 90901 sgd_solver.cpp:106] Iteration 92310, lr = 0.001
I0906 07:26:06.502482 90901 solver.cpp:228] Iteration 92320, loss = 0.0235394
I0906 07:26:06.502557 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0235404 (* 1 = 0.0235404 loss)
I0906 07:26:06.502573 90901 sgd_solver.cpp:106] Iteration 92320, lr = 0.001
I0906 07:26:14.605950 90901 solver.cpp:228] Iteration 92330, loss = 0.0535647
I0906 07:26:14.606118 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0535657 (* 1 = 0.0535657 loss)
I0906 07:26:14.606139 90901 sgd_solver.cpp:106] Iteration 92330, lr = 0.001
I0906 07:26:22.430815 90901 solver.cpp:228] Iteration 92340, loss = 0.408589
I0906 07:26:22.430884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.40859 (* 1 = 0.40859 loss)
I0906 07:26:22.430901 90901 sgd_solver.cpp:106] Iteration 92340, lr = 0.001
I0906 07:26:30.621984 90901 solver.cpp:228] Iteration 92350, loss = 0.179023
I0906 07:26:30.622052 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.179024 (* 1 = 0.179024 loss)
I0906 07:26:30.622071 90901 sgd_solver.cpp:106] Iteration 92350, lr = 0.001
I0906 07:26:38.717037 90901 solver.cpp:228] Iteration 92360, loss = 0.223334
I0906 07:26:38.717124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.223335 (* 1 = 0.223335 loss)
I0906 07:26:38.717150 90901 sgd_solver.cpp:106] Iteration 92360, lr = 0.001
I0906 07:26:46.805436 90901 solver.cpp:228] Iteration 92370, loss = 0.169904
I0906 07:26:46.805666 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169905 (* 1 = 0.169905 loss)
I0906 07:26:46.805688 90901 sgd_solver.cpp:106] Iteration 92370, lr = 0.001
I0906 07:26:54.491047 90901 solver.cpp:228] Iteration 92380, loss = 0.285963
I0906 07:26:54.491116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285964 (* 1 = 0.285964 loss)
I0906 07:26:54.491135 90901 sgd_solver.cpp:106] Iteration 92380, lr = 0.001
I0906 07:27:02.383334 90901 solver.cpp:228] Iteration 92390, loss = 0.164018
I0906 07:27:02.383409 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164019 (* 1 = 0.164019 loss)
I0906 07:27:02.383430 90901 sgd_solver.cpp:106] Iteration 92390, lr = 0.001
I0906 07:27:10.154134 90901 solver.cpp:228] Iteration 92400, loss = 0.0872379
I0906 07:27:10.154207 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0872389 (* 1 = 0.0872389 loss)
I0906 07:27:10.154224 90901 sgd_solver.cpp:106] Iteration 92400, lr = 0.001
I0906 07:27:17.826272 90901 solver.cpp:228] Iteration 92410, loss = 0.236537
I0906 07:27:17.826489 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236538 (* 1 = 0.236538 loss)
I0906 07:27:17.826508 90901 sgd_solver.cpp:106] Iteration 92410, lr = 0.001
I0906 07:27:24.929952 90901 solver.cpp:228] Iteration 92420, loss = 0.0217555
I0906 07:27:24.930030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0217565 (* 1 = 0.0217565 loss)
I0906 07:27:24.930047 90901 sgd_solver.cpp:106] Iteration 92420, lr = 0.001
I0906 07:27:33.067306 90901 solver.cpp:228] Iteration 92430, loss = 0.041939
I0906 07:27:33.067392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.04194 (* 1 = 0.04194 loss)
I0906 07:27:33.067414 90901 sgd_solver.cpp:106] Iteration 92430, lr = 0.001
I0906 07:27:41.173341 90901 solver.cpp:228] Iteration 92440, loss = 0.0489853
I0906 07:27:41.173435 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0489862 (* 1 = 0.0489862 loss)
I0906 07:27:41.173456 90901 sgd_solver.cpp:106] Iteration 92440, lr = 0.001
I0906 07:27:48.786224 90901 solver.cpp:228] Iteration 92450, loss = 0.29227
I0906 07:27:48.786408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292271 (* 1 = 0.292271 loss)
I0906 07:27:48.786428 90901 sgd_solver.cpp:106] Iteration 92450, lr = 0.001
I0906 07:27:56.941596 90901 solver.cpp:228] Iteration 92460, loss = 0.119988
I0906 07:27:56.941679 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119989 (* 1 = 0.119989 loss)
I0906 07:27:56.941695 90901 sgd_solver.cpp:106] Iteration 92460, lr = 0.001
I0906 07:28:05.024883 90901 solver.cpp:228] Iteration 92470, loss = 0.349536
I0906 07:28:05.024962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349537 (* 1 = 0.349537 loss)
I0906 07:28:05.024981 90901 sgd_solver.cpp:106] Iteration 92470, lr = 0.001
I0906 07:28:12.796691 90901 solver.cpp:228] Iteration 92480, loss = 0.097213
I0906 07:28:12.796774 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0972139 (* 1 = 0.0972139 loss)
I0906 07:28:12.796790 90901 sgd_solver.cpp:106] Iteration 92480, lr = 0.001
I0906 07:28:21.018862 90901 solver.cpp:228] Iteration 92490, loss = 0.061199
I0906 07:28:21.021214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0612 (* 1 = 0.0612 loss)
I0906 07:28:21.021255 90901 sgd_solver.cpp:106] Iteration 92490, lr = 0.001
I0906 07:28:28.360106 90901 solver.cpp:228] Iteration 92500, loss = 0.0712682
I0906 07:28:28.360193 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0712691 (* 1 = 0.0712691 loss)
I0906 07:28:28.360210 90901 sgd_solver.cpp:106] Iteration 92500, lr = 0.001
I0906 07:28:36.865304 90901 solver.cpp:228] Iteration 92510, loss = 0.115674
I0906 07:28:36.865368 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115675 (* 1 = 0.115675 loss)
I0906 07:28:36.865386 90901 sgd_solver.cpp:106] Iteration 92510, lr = 0.001
I0906 07:28:45.138828 90901 solver.cpp:228] Iteration 92520, loss = 0.121284
I0906 07:28:45.138932 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121285 (* 1 = 0.121285 loss)
I0906 07:28:45.138953 90901 sgd_solver.cpp:106] Iteration 92520, lr = 0.001
I0906 07:28:53.026414 90901 solver.cpp:228] Iteration 92530, loss = 0.183986
I0906 07:28:53.026639 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183987 (* 1 = 0.183987 loss)
I0906 07:28:53.026690 90901 sgd_solver.cpp:106] Iteration 92530, lr = 0.001
I0906 07:29:00.408418 90901 solver.cpp:228] Iteration 92540, loss = 0.0648831
I0906 07:29:00.408522 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.064884 (* 1 = 0.064884 loss)
I0906 07:29:00.408547 90901 sgd_solver.cpp:106] Iteration 92540, lr = 0.001
I0906 07:29:07.893851 90901 solver.cpp:228] Iteration 92550, loss = 0.227901
I0906 07:29:07.893934 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227902 (* 1 = 0.227902 loss)
I0906 07:29:07.893952 90901 sgd_solver.cpp:106] Iteration 92550, lr = 0.001
I0906 07:29:15.213774 90901 solver.cpp:228] Iteration 92560, loss = 0.3034
I0906 07:29:15.213852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.303401 (* 1 = 0.303401 loss)
I0906 07:29:15.213871 90901 sgd_solver.cpp:106] Iteration 92560, lr = 0.001
I0906 07:29:21.750542 90901 solver.cpp:228] Iteration 92570, loss = 0.235605
I0906 07:29:21.750656 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235606 (* 1 = 0.235606 loss)
I0906 07:29:21.750674 90901 sgd_solver.cpp:106] Iteration 92570, lr = 0.001
I0906 07:29:29.819931 90901 solver.cpp:228] Iteration 92580, loss = 0.119765
I0906 07:29:29.820277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119766 (* 1 = 0.119766 loss)
I0906 07:29:29.820300 90901 sgd_solver.cpp:106] Iteration 92580, lr = 0.001
I0906 07:29:37.426782 90901 solver.cpp:228] Iteration 92590, loss = 0.176598
I0906 07:29:37.426844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176599 (* 1 = 0.176599 loss)
I0906 07:29:37.426861 90901 sgd_solver.cpp:106] Iteration 92590, lr = 0.001
I0906 07:29:45.370532 90901 solver.cpp:228] Iteration 92600, loss = 0.161109
I0906 07:29:45.370609 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16111 (* 1 = 0.16111 loss)
I0906 07:29:45.370625 90901 sgd_solver.cpp:106] Iteration 92600, lr = 0.001
I0906 07:29:53.195691 90901 solver.cpp:228] Iteration 92610, loss = 0.0444182
I0906 07:29:53.195767 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0444191 (* 1 = 0.0444191 loss)
I0906 07:29:53.195785 90901 sgd_solver.cpp:106] Iteration 92610, lr = 0.001
I0906 07:30:01.281081 90901 solver.cpp:228] Iteration 92620, loss = 0.0306908
I0906 07:30:01.281240 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0306918 (* 1 = 0.0306918 loss)
I0906 07:30:01.281261 90901 sgd_solver.cpp:106] Iteration 92620, lr = 0.001
I0906 07:30:09.459038 90901 solver.cpp:228] Iteration 92630, loss = 0.0855156
I0906 07:30:09.459115 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0855166 (* 1 = 0.0855166 loss)
I0906 07:30:09.459132 90901 sgd_solver.cpp:106] Iteration 92630, lr = 0.001
I0906 07:30:17.187971 90901 solver.cpp:228] Iteration 92640, loss = 0.0993316
I0906 07:30:17.188076 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0993326 (* 1 = 0.0993326 loss)
I0906 07:30:17.188098 90901 sgd_solver.cpp:106] Iteration 92640, lr = 0.001
I0906 07:30:24.787003 90901 solver.cpp:228] Iteration 92650, loss = 0.0475915
I0906 07:30:24.787086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0475925 (* 1 = 0.0475925 loss)
I0906 07:30:24.787109 90901 sgd_solver.cpp:106] Iteration 92650, lr = 0.001
I0906 07:30:33.177057 90901 solver.cpp:228] Iteration 92660, loss = 0.082885
I0906 07:30:33.177256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.082886 (* 1 = 0.082886 loss)
I0906 07:30:33.177275 90901 sgd_solver.cpp:106] Iteration 92660, lr = 0.001
I0906 07:30:41.298887 90901 solver.cpp:228] Iteration 92670, loss = 0.0900469
I0906 07:30:41.298961 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0900479 (* 1 = 0.0900479 loss)
I0906 07:30:41.298980 90901 sgd_solver.cpp:106] Iteration 92670, lr = 0.001
I0906 07:30:49.667970 90901 solver.cpp:228] Iteration 92680, loss = 0.121422
I0906 07:30:49.668077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121423 (* 1 = 0.121423 loss)
I0906 07:30:49.668097 90901 sgd_solver.cpp:106] Iteration 92680, lr = 0.001
I0906 07:30:57.852233 90901 solver.cpp:228] Iteration 92690, loss = 0.0534982
I0906 07:30:57.852300 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0534993 (* 1 = 0.0534993 loss)
I0906 07:30:57.852319 90901 sgd_solver.cpp:106] Iteration 92690, lr = 0.001
I0906 07:31:05.930013 90901 solver.cpp:228] Iteration 92700, loss = 0.20729
I0906 07:31:05.930160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207291 (* 1 = 0.207291 loss)
I0906 07:31:05.930207 90901 sgd_solver.cpp:106] Iteration 92700, lr = 0.001
I0906 07:31:14.542567 90901 solver.cpp:228] Iteration 92710, loss = 0.2857
I0906 07:31:14.542659 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285701 (* 1 = 0.285701 loss)
I0906 07:31:14.542678 90901 sgd_solver.cpp:106] Iteration 92710, lr = 0.001
I0906 07:31:22.917903 90901 solver.cpp:228] Iteration 92720, loss = 0.633055
I0906 07:31:22.917979 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.633056 (* 1 = 0.633056 loss)
I0906 07:31:22.918000 90901 sgd_solver.cpp:106] Iteration 92720, lr = 0.001
I0906 07:31:30.537533 90901 solver.cpp:228] Iteration 92730, loss = 0.136923
I0906 07:31:30.537600 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136924 (* 1 = 0.136924 loss)
I0906 07:31:30.537619 90901 sgd_solver.cpp:106] Iteration 92730, lr = 0.001
I0906 07:31:38.857590 90901 solver.cpp:228] Iteration 92740, loss = 0.343654
I0906 07:31:38.857795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343655 (* 1 = 0.343655 loss)
I0906 07:31:38.857825 90901 sgd_solver.cpp:106] Iteration 92740, lr = 0.001
I0906 07:31:46.984182 90901 solver.cpp:228] Iteration 92750, loss = 0.0914754
I0906 07:31:46.984252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0914764 (* 1 = 0.0914764 loss)
I0906 07:31:46.984269 90901 sgd_solver.cpp:106] Iteration 92750, lr = 0.001
I0906 07:31:54.414012 90901 solver.cpp:228] Iteration 92760, loss = 0.0500835
I0906 07:31:54.414098 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0500845 (* 1 = 0.0500845 loss)
I0906 07:31:54.414124 90901 sgd_solver.cpp:106] Iteration 92760, lr = 0.001
I0906 07:32:02.743599 90901 solver.cpp:228] Iteration 92770, loss = 0.136921
I0906 07:32:02.743711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136922 (* 1 = 0.136922 loss)
I0906 07:32:02.743737 90901 sgd_solver.cpp:106] Iteration 92770, lr = 0.001
I0906 07:32:10.537405 90901 solver.cpp:228] Iteration 92780, loss = 0.0408951
I0906 07:32:10.537554 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.040896 (* 1 = 0.040896 loss)
I0906 07:32:10.537571 90901 sgd_solver.cpp:106] Iteration 92780, lr = 0.001
I0906 07:32:18.800848 90901 solver.cpp:228] Iteration 92790, loss = 0.043782
I0906 07:32:18.800925 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0437829 (* 1 = 0.0437829 loss)
I0906 07:32:18.800943 90901 sgd_solver.cpp:106] Iteration 92790, lr = 0.001
I0906 07:32:25.778194 90901 solver.cpp:337] Iteration 92800, Testing net (#0)
I0906 07:33:17.452216 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.937813
I0906 07:33:17.452428 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.16598 (* 1 = 0.16598 loss)
I0906 07:33:17.669847 90901 solver.cpp:228] Iteration 92800, loss = 0.187555
I0906 07:33:17.669903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187556 (* 1 = 0.187556 loss)
I0906 07:33:17.669921 90901 sgd_solver.cpp:106] Iteration 92800, lr = 0.001
I0906 07:33:22.890010 90901 solver.cpp:228] Iteration 92810, loss = 0.0413829
I0906 07:33:22.890089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0413838 (* 1 = 0.0413838 loss)
I0906 07:33:22.890106 90901 sgd_solver.cpp:106] Iteration 92810, lr = 0.001
I0906 07:33:28.435719 90901 solver.cpp:228] Iteration 92820, loss = 0.120302
I0906 07:33:28.435783 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120303 (* 1 = 0.120303 loss)
I0906 07:33:28.435801 90901 sgd_solver.cpp:106] Iteration 92820, lr = 0.001
I0906 07:33:33.665726 90901 solver.cpp:228] Iteration 92830, loss = 0.272445
I0906 07:33:33.665791 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272446 (* 1 = 0.272446 loss)
I0906 07:33:33.665808 90901 sgd_solver.cpp:106] Iteration 92830, lr = 0.001
I0906 07:33:38.893618 90901 solver.cpp:228] Iteration 92840, loss = 0.0282656
I0906 07:33:38.893685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0282666 (* 1 = 0.0282666 loss)
I0906 07:33:38.893702 90901 sgd_solver.cpp:106] Iteration 92840, lr = 0.001
I0906 07:33:45.189251 90901 solver.cpp:228] Iteration 92850, loss = 0.232947
I0906 07:33:45.189337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.232948 (* 1 = 0.232948 loss)
I0906 07:33:45.189357 90901 sgd_solver.cpp:106] Iteration 92850, lr = 0.001
I0906 07:33:52.025708 90901 solver.cpp:228] Iteration 92860, loss = 0.0131644
I0906 07:33:52.025897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0131653 (* 1 = 0.0131653 loss)
I0906 07:33:52.025933 90901 sgd_solver.cpp:106] Iteration 92860, lr = 0.001
I0906 07:33:59.878517 90901 solver.cpp:228] Iteration 92870, loss = 0.115463
I0906 07:33:59.878595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115464 (* 1 = 0.115464 loss)
I0906 07:33:59.878613 90901 sgd_solver.cpp:106] Iteration 92870, lr = 0.001
I0906 07:34:07.634766 90901 solver.cpp:228] Iteration 92880, loss = 0.0271234
I0906 07:34:07.634851 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0271244 (* 1 = 0.0271244 loss)
I0906 07:34:07.634871 90901 sgd_solver.cpp:106] Iteration 92880, lr = 0.001
I0906 07:34:15.009963 90901 solver.cpp:228] Iteration 92890, loss = 0.394398
I0906 07:34:15.010046 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.394399 (* 1 = 0.394399 loss)
I0906 07:34:15.010064 90901 sgd_solver.cpp:106] Iteration 92890, lr = 0.001
I0906 07:34:23.396093 90901 solver.cpp:228] Iteration 92900, loss = 0.0749506
I0906 07:34:23.396292 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0749516 (* 1 = 0.0749516 loss)
I0906 07:34:23.396323 90901 sgd_solver.cpp:106] Iteration 92900, lr = 0.001
I0906 07:34:31.600899 90901 solver.cpp:228] Iteration 92910, loss = 0.0615027
I0906 07:34:31.600962 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0615036 (* 1 = 0.0615036 loss)
I0906 07:34:31.600980 90901 sgd_solver.cpp:106] Iteration 92910, lr = 0.001
I0906 07:34:40.180366 90901 solver.cpp:228] Iteration 92920, loss = 0.108916
I0906 07:34:40.180433 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108917 (* 1 = 0.108917 loss)
I0906 07:34:40.180449 90901 sgd_solver.cpp:106] Iteration 92920, lr = 0.001
I0906 07:34:48.086365 90901 solver.cpp:228] Iteration 92930, loss = 0.0893351
I0906 07:34:48.086436 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0893361 (* 1 = 0.0893361 loss)
I0906 07:34:48.086452 90901 sgd_solver.cpp:106] Iteration 92930, lr = 0.001
I0906 07:34:55.975368 90901 solver.cpp:228] Iteration 92940, loss = 0.238939
I0906 07:34:55.975646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23894 (* 1 = 0.23894 loss)
I0906 07:34:55.975666 90901 sgd_solver.cpp:106] Iteration 92940, lr = 0.001
I0906 07:35:03.770131 90901 solver.cpp:228] Iteration 92950, loss = 0.221502
I0906 07:35:03.770195 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.221503 (* 1 = 0.221503 loss)
I0906 07:35:03.770212 90901 sgd_solver.cpp:106] Iteration 92950, lr = 0.001
I0906 07:35:12.158149 90901 solver.cpp:228] Iteration 92960, loss = 0.119757
I0906 07:35:12.158231 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119758 (* 1 = 0.119758 loss)
I0906 07:35:12.158254 90901 sgd_solver.cpp:106] Iteration 92960, lr = 0.001
I0906 07:35:20.125210 90901 solver.cpp:228] Iteration 92970, loss = 0.38042
I0906 07:35:20.125264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.380421 (* 1 = 0.380421 loss)
I0906 07:35:20.125280 90901 sgd_solver.cpp:106] Iteration 92970, lr = 0.001
I0906 07:35:27.373062 90901 solver.cpp:228] Iteration 92980, loss = 0.0834082
I0906 07:35:27.373333 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0834091 (* 1 = 0.0834091 loss)
I0906 07:35:27.373354 90901 sgd_solver.cpp:106] Iteration 92980, lr = 0.001
I0906 07:35:34.457041 90901 solver.cpp:228] Iteration 92990, loss = 0.0287023
I0906 07:35:34.457157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0287031 (* 1 = 0.0287031 loss)
I0906 07:35:34.457180 90901 sgd_solver.cpp:106] Iteration 92990, lr = 0.001
I0906 07:35:41.497194 90901 solver.cpp:228] Iteration 93000, loss = 0.27091
I0906 07:35:41.497272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270911 (* 1 = 0.270911 loss)
I0906 07:35:41.497292 90901 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I0906 07:35:48.847733 90901 solver.cpp:228] Iteration 93010, loss = 0.161293
I0906 07:35:48.847797 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161294 (* 1 = 0.161294 loss)
I0906 07:35:48.847816 90901 sgd_solver.cpp:106] Iteration 93010, lr = 0.001
I0906 07:35:56.210026 90901 solver.cpp:228] Iteration 93020, loss = 0.0697608
I0906 07:35:56.210093 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0697617 (* 1 = 0.0697617 loss)
I0906 07:35:56.210109 90901 sgd_solver.cpp:106] Iteration 93020, lr = 0.001
I0906 07:36:03.397845 90901 solver.cpp:228] Iteration 93030, loss = 0.173153
I0906 07:36:03.398097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173153 (* 1 = 0.173153 loss)
I0906 07:36:03.398124 90901 sgd_solver.cpp:106] Iteration 93030, lr = 0.001
I0906 07:36:10.671874 90901 solver.cpp:228] Iteration 93040, loss = 0.173398
I0906 07:36:10.671989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173399 (* 1 = 0.173399 loss)
I0906 07:36:10.672010 90901 sgd_solver.cpp:106] Iteration 93040, lr = 0.001
I0906 07:36:18.269286 90901 solver.cpp:228] Iteration 93050, loss = 0.0832861
I0906 07:36:18.269363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.083287 (* 1 = 0.083287 loss)
I0906 07:36:18.269382 90901 sgd_solver.cpp:106] Iteration 93050, lr = 0.001
I0906 07:36:25.625005 90901 solver.cpp:228] Iteration 93060, loss = 0.059674
I0906 07:36:25.625110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596749 (* 1 = 0.0596749 loss)
I0906 07:36:25.625129 90901 sgd_solver.cpp:106] Iteration 93060, lr = 0.001
I0906 07:36:33.502145 90901 solver.cpp:228] Iteration 93070, loss = 0.0545624
I0906 07:36:33.502964 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545633 (* 1 = 0.0545633 loss)
I0906 07:36:33.502980 90901 sgd_solver.cpp:106] Iteration 93070, lr = 0.001
I0906 07:36:40.997349 90901 solver.cpp:228] Iteration 93080, loss = 0.233338
I0906 07:36:40.997440 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233338 (* 1 = 0.233338 loss)
I0906 07:36:40.997460 90901 sgd_solver.cpp:106] Iteration 93080, lr = 0.001
I0906 07:36:49.117161 90901 solver.cpp:228] Iteration 93090, loss = 0.0701429
I0906 07:36:49.117233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0701437 (* 1 = 0.0701437 loss)
I0906 07:36:49.117250 90901 sgd_solver.cpp:106] Iteration 93090, lr = 0.001
I0906 07:36:56.885504 90901 solver.cpp:228] Iteration 93100, loss = 0.0778219
I0906 07:36:56.885571 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0778227 (* 1 = 0.0778227 loss)
I0906 07:36:56.885589 90901 sgd_solver.cpp:106] Iteration 93100, lr = 0.001
I0906 07:37:05.307440 90901 solver.cpp:228] Iteration 93110, loss = 0.14944
I0906 07:37:05.307709 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149441 (* 1 = 0.149441 loss)
I0906 07:37:05.307729 90901 sgd_solver.cpp:106] Iteration 93110, lr = 0.001
I0906 07:37:12.933966 90901 solver.cpp:228] Iteration 93120, loss = 0.122894
I0906 07:37:12.934059 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122895 (* 1 = 0.122895 loss)
I0906 07:37:12.934078 90901 sgd_solver.cpp:106] Iteration 93120, lr = 0.001
I0906 07:37:21.371194 90901 solver.cpp:228] Iteration 93130, loss = 0.161971
I0906 07:37:21.371286 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161972 (* 1 = 0.161972 loss)
I0906 07:37:21.371310 90901 sgd_solver.cpp:106] Iteration 93130, lr = 0.001
I0906 07:37:29.587209 90901 solver.cpp:228] Iteration 93140, loss = 0.350664
I0906 07:37:29.587280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350664 (* 1 = 0.350664 loss)
I0906 07:37:29.587297 90901 sgd_solver.cpp:106] Iteration 93140, lr = 0.001
I0906 07:37:37.425256 90901 solver.cpp:228] Iteration 93150, loss = 0.259137
I0906 07:37:37.425402 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259137 (* 1 = 0.259137 loss)
I0906 07:37:37.425431 90901 sgd_solver.cpp:106] Iteration 93150, lr = 0.001
I0906 07:37:45.423288 90901 solver.cpp:228] Iteration 93160, loss = 0.109586
I0906 07:37:45.423352 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109587 (* 1 = 0.109587 loss)
I0906 07:37:45.423368 90901 sgd_solver.cpp:106] Iteration 93160, lr = 0.001
I0906 07:37:53.247750 90901 solver.cpp:228] Iteration 93170, loss = 0.0471998
I0906 07:37:53.247818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0472006 (* 1 = 0.0472006 loss)
I0906 07:37:53.247833 90901 sgd_solver.cpp:106] Iteration 93170, lr = 0.001
I0906 07:38:01.368978 90901 solver.cpp:228] Iteration 93180, loss = 0.127266
I0906 07:38:01.369066 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127266 (* 1 = 0.127266 loss)
I0906 07:38:01.369086 90901 sgd_solver.cpp:106] Iteration 93180, lr = 0.001
I0906 07:38:10.181709 90901 solver.cpp:228] Iteration 93190, loss = 0.180815
I0906 07:38:10.182000 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180815 (* 1 = 0.180815 loss)
I0906 07:38:10.182024 90901 sgd_solver.cpp:106] Iteration 93190, lr = 0.001
I0906 07:38:18.663687 90901 solver.cpp:228] Iteration 93200, loss = 0.18022
I0906 07:38:18.663758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180221 (* 1 = 0.180221 loss)
I0906 07:38:18.663780 90901 sgd_solver.cpp:106] Iteration 93200, lr = 0.001
I0906 07:38:26.989923 90901 solver.cpp:228] Iteration 93210, loss = 0.106971
I0906 07:38:26.989986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106972 (* 1 = 0.106972 loss)
I0906 07:38:26.990002 90901 sgd_solver.cpp:106] Iteration 93210, lr = 0.001
I0906 07:38:35.256178 90901 solver.cpp:228] Iteration 93220, loss = 0.0751274
I0906 07:38:35.256261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0751282 (* 1 = 0.0751282 loss)
I0906 07:38:35.256283 90901 sgd_solver.cpp:106] Iteration 93220, lr = 0.001
I0906 07:38:44.045922 90901 solver.cpp:228] Iteration 93230, loss = 0.306611
I0906 07:38:44.046140 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.306612 (* 1 = 0.306612 loss)
I0906 07:38:44.046160 90901 sgd_solver.cpp:106] Iteration 93230, lr = 0.001
I0906 07:38:52.421149 90901 solver.cpp:228] Iteration 93240, loss = 0.0834223
I0906 07:38:52.421212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0834231 (* 1 = 0.0834231 loss)
I0906 07:38:52.421228 90901 sgd_solver.cpp:106] Iteration 93240, lr = 0.001
I0906 07:39:00.200830 90901 solver.cpp:228] Iteration 93250, loss = 0.275158
I0906 07:39:00.200978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275159 (* 1 = 0.275159 loss)
I0906 07:39:00.201000 90901 sgd_solver.cpp:106] Iteration 93250, lr = 0.001
I0906 07:39:08.904608 90901 solver.cpp:228] Iteration 93260, loss = 0.229754
I0906 07:39:08.904676 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229755 (* 1 = 0.229755 loss)
I0906 07:39:08.904696 90901 sgd_solver.cpp:106] Iteration 93260, lr = 0.001
I0906 07:39:17.581370 90901 solver.cpp:228] Iteration 93270, loss = 0.0326112
I0906 07:39:17.581538 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0326119 (* 1 = 0.0326119 loss)
I0906 07:39:17.581568 90901 sgd_solver.cpp:106] Iteration 93270, lr = 0.001
I0906 07:39:25.694661 90901 solver.cpp:228] Iteration 93280, loss = 0.0560792
I0906 07:39:25.694738 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.05608 (* 1 = 0.05608 loss)
I0906 07:39:25.694756 90901 sgd_solver.cpp:106] Iteration 93280, lr = 0.001
I0906 07:39:34.502581 90901 solver.cpp:228] Iteration 93290, loss = 0.118342
I0906 07:39:34.502684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118343 (* 1 = 0.118343 loss)
I0906 07:39:34.502708 90901 sgd_solver.cpp:106] Iteration 93290, lr = 0.001
I0906 07:39:42.533134 90901 solver.cpp:228] Iteration 93300, loss = 0.135777
I0906 07:39:42.533226 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135778 (* 1 = 0.135778 loss)
I0906 07:39:42.533247 90901 sgd_solver.cpp:106] Iteration 93300, lr = 0.001
I0906 07:39:51.412215 90901 solver.cpp:228] Iteration 93310, loss = 0.381542
I0906 07:39:51.412410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.381543 (* 1 = 0.381543 loss)
I0906 07:39:51.412433 90901 sgd_solver.cpp:106] Iteration 93310, lr = 0.001
I0906 07:40:00.158970 90901 solver.cpp:228] Iteration 93320, loss = 0.130661
I0906 07:40:00.159054 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130662 (* 1 = 0.130662 loss)
I0906 07:40:00.159071 90901 sgd_solver.cpp:106] Iteration 93320, lr = 0.001
I0906 07:40:08.223592 90901 solver.cpp:228] Iteration 93330, loss = 0.0718999
I0906 07:40:08.223670 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0719006 (* 1 = 0.0719006 loss)
I0906 07:40:08.223687 90901 sgd_solver.cpp:106] Iteration 93330, lr = 0.001
I0906 07:40:15.843132 90901 solver.cpp:228] Iteration 93340, loss = 0.43868
I0906 07:40:15.843201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.438681 (* 1 = 0.438681 loss)
I0906 07:40:15.843219 90901 sgd_solver.cpp:106] Iteration 93340, lr = 0.001
I0906 07:40:24.677274 90901 solver.cpp:228] Iteration 93350, loss = 0.410544
I0906 07:40:24.677469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410545 (* 1 = 0.410545 loss)
I0906 07:40:24.677489 90901 sgd_solver.cpp:106] Iteration 93350, lr = 0.001
I0906 07:40:32.686096 90901 solver.cpp:228] Iteration 93360, loss = 0.343729
I0906 07:40:32.686154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.34373 (* 1 = 0.34373 loss)
I0906 07:40:32.686169 90901 sgd_solver.cpp:106] Iteration 93360, lr = 0.001
I0906 07:40:40.731091 90901 solver.cpp:228] Iteration 93370, loss = 0.0705116
I0906 07:40:40.731194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0705123 (* 1 = 0.0705123 loss)
I0906 07:40:40.731220 90901 sgd_solver.cpp:106] Iteration 93370, lr = 0.001
I0906 07:40:48.306797 90901 solver.cpp:228] Iteration 93380, loss = 0.055574
I0906 07:40:48.306879 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0555748 (* 1 = 0.0555748 loss)
I0906 07:40:48.306901 90901 sgd_solver.cpp:106] Iteration 93380, lr = 0.001
I0906 07:40:56.351398 90901 solver.cpp:228] Iteration 93390, loss = 0.0399205
I0906 07:40:56.351641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0399212 (* 1 = 0.0399212 loss)
I0906 07:40:56.351660 90901 sgd_solver.cpp:106] Iteration 93390, lr = 0.001
I0906 07:41:04.287533 90901 solver.cpp:228] Iteration 93400, loss = 0.364425
I0906 07:41:04.287616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364425 (* 1 = 0.364425 loss)
I0906 07:41:04.287633 90901 sgd_solver.cpp:106] Iteration 93400, lr = 0.001
I0906 07:41:12.651041 90901 solver.cpp:228] Iteration 93410, loss = 0.209867
I0906 07:41:12.651154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209868 (* 1 = 0.209868 loss)
I0906 07:41:12.651178 90901 sgd_solver.cpp:106] Iteration 93410, lr = 0.001
I0906 07:41:20.777323 90901 solver.cpp:228] Iteration 93420, loss = 0.051014
I0906 07:41:20.777398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0510148 (* 1 = 0.0510148 loss)
I0906 07:41:20.777415 90901 sgd_solver.cpp:106] Iteration 93420, lr = 0.001
I0906 07:41:28.509575 90901 solver.cpp:228] Iteration 93430, loss = 0.10576
I0906 07:41:28.509765 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105761 (* 1 = 0.105761 loss)
I0906 07:41:28.509786 90901 sgd_solver.cpp:106] Iteration 93430, lr = 0.001
I0906 07:41:36.324301 90901 solver.cpp:228] Iteration 93440, loss = 0.0673455
I0906 07:41:36.324398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0673462 (* 1 = 0.0673462 loss)
I0906 07:41:36.324420 90901 sgd_solver.cpp:106] Iteration 93440, lr = 0.001
I0906 07:41:44.675689 90901 solver.cpp:228] Iteration 93450, loss = 0.0678966
I0906 07:41:44.675768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0678973 (* 1 = 0.0678973 loss)
I0906 07:41:44.675794 90901 sgd_solver.cpp:106] Iteration 93450, lr = 0.001
I0906 07:41:53.244681 90901 solver.cpp:228] Iteration 93460, loss = 0.134397
I0906 07:41:53.244799 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134398 (* 1 = 0.134398 loss)
I0906 07:41:53.244825 90901 sgd_solver.cpp:106] Iteration 93460, lr = 0.001
I0906 07:42:01.456240 90901 solver.cpp:228] Iteration 93470, loss = 0.190924
I0906 07:42:01.456392 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190925 (* 1 = 0.190925 loss)
I0906 07:42:01.456410 90901 sgd_solver.cpp:106] Iteration 93470, lr = 0.001
I0906 07:42:09.232681 90901 solver.cpp:228] Iteration 93480, loss = 0.064737
I0906 07:42:09.232769 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0647378 (* 1 = 0.0647378 loss)
I0906 07:42:09.232786 90901 sgd_solver.cpp:106] Iteration 93480, lr = 0.001
I0906 07:42:16.853335 90901 solver.cpp:228] Iteration 93490, loss = 0.113596
I0906 07:42:16.853466 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113597 (* 1 = 0.113597 loss)
I0906 07:42:16.853487 90901 sgd_solver.cpp:106] Iteration 93490, lr = 0.001
I0906 07:42:22.345398 90901 solver.cpp:228] Iteration 93500, loss = 0.264198
I0906 07:42:22.345480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264199 (* 1 = 0.264199 loss)
I0906 07:42:22.345502 90901 sgd_solver.cpp:106] Iteration 93500, lr = 0.001
I0906 07:42:27.689834 90901 solver.cpp:228] Iteration 93510, loss = 0.425588
I0906 07:42:27.689913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.425589 (* 1 = 0.425589 loss)
I0906 07:42:27.689931 90901 sgd_solver.cpp:106] Iteration 93510, lr = 0.001
I0906 07:42:33.124603 90901 solver.cpp:228] Iteration 93520, loss = 0.071263
I0906 07:42:33.124768 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0712637 (* 1 = 0.0712637 loss)
I0906 07:42:33.124799 90901 sgd_solver.cpp:106] Iteration 93520, lr = 0.001
I0906 07:42:38.339135 90901 solver.cpp:228] Iteration 93530, loss = 0.102033
I0906 07:42:38.339200 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102033 (* 1 = 0.102033 loss)
I0906 07:42:38.339216 90901 sgd_solver.cpp:106] Iteration 93530, lr = 0.001
I0906 07:42:44.204097 90901 solver.cpp:228] Iteration 93540, loss = 0.0463374
I0906 07:42:44.204186 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0463381 (* 1 = 0.0463381 loss)
I0906 07:42:44.204211 90901 sgd_solver.cpp:106] Iteration 93540, lr = 0.001
I0906 07:42:50.602412 90901 solver.cpp:228] Iteration 93550, loss = 0.0776192
I0906 07:42:50.602479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0776199 (* 1 = 0.0776199 loss)
I0906 07:42:50.602496 90901 sgd_solver.cpp:106] Iteration 93550, lr = 0.001
I0906 07:42:56.651437 90901 solver.cpp:228] Iteration 93560, loss = 0.093805
I0906 07:42:56.651526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0938057 (* 1 = 0.0938057 loss)
I0906 07:42:56.651543 90901 sgd_solver.cpp:106] Iteration 93560, lr = 0.001
I0906 07:43:02.404244 90901 solver.cpp:228] Iteration 93570, loss = 0.0227874
I0906 07:43:02.404328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0227881 (* 1 = 0.0227881 loss)
I0906 07:43:02.404347 90901 sgd_solver.cpp:106] Iteration 93570, lr = 0.001
I0906 07:43:08.434444 90901 solver.cpp:228] Iteration 93580, loss = 0.0533762
I0906 07:43:08.434681 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0533769 (* 1 = 0.0533769 loss)
I0906 07:43:08.434705 90901 sgd_solver.cpp:106] Iteration 93580, lr = 0.001
I0906 07:43:13.646080 90901 solver.cpp:228] Iteration 93590, loss = 0.0639875
I0906 07:43:13.646188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0639882 (* 1 = 0.0639882 loss)
I0906 07:43:13.646210 90901 sgd_solver.cpp:106] Iteration 93590, lr = 0.001
I0906 07:43:18.959328 90901 solver.cpp:337] Iteration 93600, Testing net (#0)
I0906 07:44:11.528964 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.935
I0906 07:44:11.529137 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.183473 (* 1 = 0.183473 loss)
I0906 07:44:11.811203 90901 solver.cpp:228] Iteration 93600, loss = 0.0826231
I0906 07:44:11.811271 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0826238 (* 1 = 0.0826238 loss)
I0906 07:44:11.811293 90901 sgd_solver.cpp:106] Iteration 93600, lr = 0.001
I0906 07:44:20.117496 90901 solver.cpp:228] Iteration 93610, loss = 0.0472036
I0906 07:44:20.117574 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0472043 (* 1 = 0.0472043 loss)
I0906 07:44:20.117594 90901 sgd_solver.cpp:106] Iteration 93610, lr = 0.001
I0906 07:44:28.877380 90901 solver.cpp:228] Iteration 93620, loss = 0.20035
I0906 07:44:28.877468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200351 (* 1 = 0.200351 loss)
I0906 07:44:28.877485 90901 sgd_solver.cpp:106] Iteration 93620, lr = 0.001
I0906 07:44:37.046347 90901 solver.cpp:228] Iteration 93630, loss = 0.0636091
I0906 07:44:37.046469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0636098 (* 1 = 0.0636098 loss)
I0906 07:44:37.046494 90901 sgd_solver.cpp:106] Iteration 93630, lr = 0.001
I0906 07:44:45.164775 90901 solver.cpp:228] Iteration 93640, loss = 0.0337712
I0906 07:44:45.165048 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0337719 (* 1 = 0.0337719 loss)
I0906 07:44:45.165072 90901 sgd_solver.cpp:106] Iteration 93640, lr = 0.001
I0906 07:44:53.143432 90901 solver.cpp:228] Iteration 93650, loss = 0.0485364
I0906 07:44:53.143508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.048537 (* 1 = 0.048537 loss)
I0906 07:44:53.143527 90901 sgd_solver.cpp:106] Iteration 93650, lr = 0.001
I0906 07:45:01.233172 90901 solver.cpp:228] Iteration 93660, loss = 0.518612
I0906 07:45:01.233245 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.518613 (* 1 = 0.518613 loss)
I0906 07:45:01.233265 90901 sgd_solver.cpp:106] Iteration 93660, lr = 0.001
I0906 07:45:09.347956 90901 solver.cpp:228] Iteration 93670, loss = 0.315397
I0906 07:45:09.348039 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315397 (* 1 = 0.315397 loss)
I0906 07:45:09.348057 90901 sgd_solver.cpp:106] Iteration 93670, lr = 0.001
I0906 07:45:17.079156 90901 solver.cpp:228] Iteration 93680, loss = 0.0656343
I0906 07:45:17.079452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0656349 (* 1 = 0.0656349 loss)
I0906 07:45:17.079474 90901 sgd_solver.cpp:106] Iteration 93680, lr = 0.001
I0906 07:45:25.330654 90901 solver.cpp:228] Iteration 93690, loss = 0.0491264
I0906 07:45:25.330719 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0491271 (* 1 = 0.0491271 loss)
I0906 07:45:25.330749 90901 sgd_solver.cpp:106] Iteration 93690, lr = 0.001
I0906 07:45:33.749768 90901 solver.cpp:228] Iteration 93700, loss = 0.121825
I0906 07:45:33.749855 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121826 (* 1 = 0.121826 loss)
I0906 07:45:33.749876 90901 sgd_solver.cpp:106] Iteration 93700, lr = 0.001
I0906 07:45:41.445792 90901 solver.cpp:228] Iteration 93710, loss = 0.24375
I0906 07:45:41.445876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243751 (* 1 = 0.243751 loss)
I0906 07:45:41.445899 90901 sgd_solver.cpp:106] Iteration 93710, lr = 0.001
I0906 07:45:49.493521 90901 solver.cpp:228] Iteration 93720, loss = 0.292296
I0906 07:45:49.495218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.292297 (* 1 = 0.292297 loss)
I0906 07:45:49.495240 90901 sgd_solver.cpp:106] Iteration 93720, lr = 0.001
I0906 07:45:57.928608 90901 solver.cpp:228] Iteration 93730, loss = 0.0793301
I0906 07:45:57.928704 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0793308 (* 1 = 0.0793308 loss)
I0906 07:45:57.928725 90901 sgd_solver.cpp:106] Iteration 93730, lr = 0.001
I0906 07:46:06.033546 90901 solver.cpp:228] Iteration 93740, loss = 0.0754358
I0906 07:46:06.033648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0754366 (* 1 = 0.0754366 loss)
I0906 07:46:06.033666 90901 sgd_solver.cpp:106] Iteration 93740, lr = 0.001
I0906 07:46:14.811014 90901 solver.cpp:228] Iteration 93750, loss = 0.119635
I0906 07:46:14.811095 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119636 (* 1 = 0.119636 loss)
I0906 07:46:14.811118 90901 sgd_solver.cpp:106] Iteration 93750, lr = 0.001
I0906 07:46:23.226435 90901 solver.cpp:228] Iteration 93760, loss = 0.0804183
I0906 07:46:23.226613 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0804191 (* 1 = 0.0804191 loss)
I0906 07:46:23.226653 90901 sgd_solver.cpp:106] Iteration 93760, lr = 0.001
I0906 07:46:31.189684 90901 solver.cpp:228] Iteration 93770, loss = 0.207886
I0906 07:46:31.189764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207887 (* 1 = 0.207887 loss)
I0906 07:46:31.189782 90901 sgd_solver.cpp:106] Iteration 93770, lr = 0.001
I0906 07:46:39.257571 90901 solver.cpp:228] Iteration 93780, loss = 0.0396178
I0906 07:46:39.257653 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0396186 (* 1 = 0.0396186 loss)
I0906 07:46:39.257671 90901 sgd_solver.cpp:106] Iteration 93780, lr = 0.001
I0906 07:46:47.445281 90901 solver.cpp:228] Iteration 93790, loss = 0.094008
I0906 07:46:47.445379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0940088 (* 1 = 0.0940088 loss)
I0906 07:46:47.445399 90901 sgd_solver.cpp:106] Iteration 93790, lr = 0.001
I0906 07:46:55.593523 90901 solver.cpp:228] Iteration 93800, loss = 0.1675
I0906 07:46:55.593684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167501 (* 1 = 0.167501 loss)
I0906 07:46:55.593708 90901 sgd_solver.cpp:106] Iteration 93800, lr = 0.001
I0906 07:47:03.730072 90901 solver.cpp:228] Iteration 93810, loss = 0.247037
I0906 07:47:03.730160 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247037 (* 1 = 0.247037 loss)
I0906 07:47:03.730178 90901 sgd_solver.cpp:106] Iteration 93810, lr = 0.001
I0906 07:47:11.477301 90901 solver.cpp:228] Iteration 93820, loss = 0.708455
I0906 07:47:11.477388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.708456 (* 1 = 0.708456 loss)
I0906 07:47:11.477406 90901 sgd_solver.cpp:106] Iteration 93820, lr = 0.001
I0906 07:47:19.412091 90901 solver.cpp:228] Iteration 93830, loss = 0.0928831
I0906 07:47:19.412170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0928839 (* 1 = 0.0928839 loss)
I0906 07:47:19.412187 90901 sgd_solver.cpp:106] Iteration 93830, lr = 0.001
I0906 07:47:27.335971 90901 solver.cpp:228] Iteration 93840, loss = 0.0362902
I0906 07:47:27.336212 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.036291 (* 1 = 0.036291 loss)
I0906 07:47:27.336231 90901 sgd_solver.cpp:106] Iteration 93840, lr = 0.001
I0906 07:47:35.925638 90901 solver.cpp:228] Iteration 93850, loss = 0.0750092
I0906 07:47:35.925745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.07501 (* 1 = 0.07501 loss)
I0906 07:47:35.925763 90901 sgd_solver.cpp:106] Iteration 93850, lr = 0.001
I0906 07:47:43.436074 90901 solver.cpp:228] Iteration 93860, loss = 0.0611837
I0906 07:47:43.436152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0611845 (* 1 = 0.0611845 loss)
I0906 07:47:43.436175 90901 sgd_solver.cpp:106] Iteration 93860, lr = 0.001
I0906 07:47:50.593046 90901 solver.cpp:228] Iteration 93870, loss = 0.120793
I0906 07:47:50.593178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120794 (* 1 = 0.120794 loss)
I0906 07:47:50.593200 90901 sgd_solver.cpp:106] Iteration 93870, lr = 0.001
I0906 07:47:58.545219 90901 solver.cpp:228] Iteration 93880, loss = 0.121794
I0906 07:47:58.545445 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121795 (* 1 = 0.121795 loss)
I0906 07:47:58.545467 90901 sgd_solver.cpp:106] Iteration 93880, lr = 0.001
I0906 07:48:06.761454 90901 solver.cpp:228] Iteration 93890, loss = 0.642512
I0906 07:48:06.761528 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.642513 (* 1 = 0.642513 loss)
I0906 07:48:06.761549 90901 sgd_solver.cpp:106] Iteration 93890, lr = 0.001
I0906 07:48:14.871116 90901 solver.cpp:228] Iteration 93900, loss = 0.0293663
I0906 07:48:14.871218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0293671 (* 1 = 0.0293671 loss)
I0906 07:48:14.871240 90901 sgd_solver.cpp:106] Iteration 93900, lr = 0.001
I0906 07:48:23.198758 90901 solver.cpp:228] Iteration 93910, loss = 0.0731183
I0906 07:48:23.198846 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0731191 (* 1 = 0.0731191 loss)
I0906 07:48:23.198863 90901 sgd_solver.cpp:106] Iteration 93910, lr = 0.001
I0906 07:48:31.309680 90901 solver.cpp:228] Iteration 93920, loss = 0.266388
I0906 07:48:31.309833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266389 (* 1 = 0.266389 loss)
I0906 07:48:31.309854 90901 sgd_solver.cpp:106] Iteration 93920, lr = 0.001
I0906 07:48:38.970785 90901 solver.cpp:228] Iteration 93930, loss = 0.0117358
I0906 07:48:38.970849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0117365 (* 1 = 0.0117365 loss)
I0906 07:48:38.970866 90901 sgd_solver.cpp:106] Iteration 93930, lr = 0.001
I0906 07:48:47.156517 90901 solver.cpp:228] Iteration 93940, loss = 0.0350851
I0906 07:48:47.156591 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350859 (* 1 = 0.0350859 loss)
I0906 07:48:47.156610 90901 sgd_solver.cpp:106] Iteration 93940, lr = 0.001
I0906 07:48:55.207326 90901 solver.cpp:228] Iteration 93950, loss = 0.0237095
I0906 07:48:55.207399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0237103 (* 1 = 0.0237103 loss)
I0906 07:48:55.207417 90901 sgd_solver.cpp:106] Iteration 93950, lr = 0.001
I0906 07:49:03.578930 90901 solver.cpp:228] Iteration 93960, loss = 0.27385
I0906 07:49:03.579100 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.273851 (* 1 = 0.273851 loss)
I0906 07:49:03.579129 90901 sgd_solver.cpp:106] Iteration 93960, lr = 0.001
I0906 07:49:11.493049 90901 solver.cpp:228] Iteration 93970, loss = 0.202183
I0906 07:49:11.493124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.202183 (* 1 = 0.202183 loss)
I0906 07:49:11.493139 90901 sgd_solver.cpp:106] Iteration 93970, lr = 0.001
I0906 07:49:19.280962 90901 solver.cpp:228] Iteration 93980, loss = 0.315062
I0906 07:49:19.281025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315063 (* 1 = 0.315063 loss)
I0906 07:49:19.281042 90901 sgd_solver.cpp:106] Iteration 93980, lr = 0.001
I0906 07:49:27.258456 90901 solver.cpp:228] Iteration 93990, loss = 0.100643
I0906 07:49:27.258520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100644 (* 1 = 0.100644 loss)
I0906 07:49:27.258536 90901 sgd_solver.cpp:106] Iteration 93990, lr = 0.001
I0906 07:49:34.826601 90901 solver.cpp:228] Iteration 94000, loss = 0.188819
I0906 07:49:34.826795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18882 (* 1 = 0.18882 loss)
I0906 07:49:34.826812 90901 sgd_solver.cpp:106] Iteration 94000, lr = 0.001
I0906 07:49:43.455153 90901 solver.cpp:228] Iteration 94010, loss = 0.10344
I0906 07:49:43.455221 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103441 (* 1 = 0.103441 loss)
I0906 07:49:43.455238 90901 sgd_solver.cpp:106] Iteration 94010, lr = 0.001
I0906 07:49:51.669760 90901 solver.cpp:228] Iteration 94020, loss = 0.0846976
I0906 07:49:51.669821 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0846985 (* 1 = 0.0846985 loss)
I0906 07:49:51.669838 90901 sgd_solver.cpp:106] Iteration 94020, lr = 0.001
I0906 07:49:59.720975 90901 solver.cpp:228] Iteration 94030, loss = 0.182115
I0906 07:49:59.721043 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182115 (* 1 = 0.182115 loss)
I0906 07:49:59.721061 90901 sgd_solver.cpp:106] Iteration 94030, lr = 0.001
I0906 07:50:07.462949 90901 solver.cpp:228] Iteration 94040, loss = 0.0615515
I0906 07:50:07.463202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0615523 (* 1 = 0.0615523 loss)
I0906 07:50:07.463227 90901 sgd_solver.cpp:106] Iteration 94040, lr = 0.001
I0906 07:50:14.897722 90901 solver.cpp:228] Iteration 94050, loss = 0.266778
I0906 07:50:14.898063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266779 (* 1 = 0.266779 loss)
I0906 07:50:14.898120 90901 sgd_solver.cpp:106] Iteration 94050, lr = 0.001
I0906 07:50:22.489339 90901 solver.cpp:228] Iteration 94060, loss = 0.0243583
I0906 07:50:22.489503 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0243592 (* 1 = 0.0243592 loss)
I0906 07:50:22.489527 90901 sgd_solver.cpp:106] Iteration 94060, lr = 0.001
I0906 07:50:30.558447 90901 solver.cpp:228] Iteration 94070, loss = 0.100042
I0906 07:50:30.558537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100043 (* 1 = 0.100043 loss)
I0906 07:50:30.558554 90901 sgd_solver.cpp:106] Iteration 94070, lr = 0.001
I0906 07:50:37.960217 90901 solver.cpp:228] Iteration 94080, loss = 0.193385
I0906 07:50:37.960371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193386 (* 1 = 0.193386 loss)
I0906 07:50:37.960400 90901 sgd_solver.cpp:106] Iteration 94080, lr = 0.001
I0906 07:50:46.061036 90901 solver.cpp:228] Iteration 94090, loss = 0.0303738
I0906 07:50:46.061105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0303747 (* 1 = 0.0303747 loss)
I0906 07:50:46.061122 90901 sgd_solver.cpp:106] Iteration 94090, lr = 0.001
I0906 07:50:53.953141 90901 solver.cpp:228] Iteration 94100, loss = 0.0647747
I0906 07:50:53.953214 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0647756 (* 1 = 0.0647756 loss)
I0906 07:50:53.953234 90901 sgd_solver.cpp:106] Iteration 94100, lr = 0.001
I0906 07:51:01.811059 90901 solver.cpp:228] Iteration 94110, loss = 0.296073
I0906 07:51:01.811132 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296074 (* 1 = 0.296074 loss)
I0906 07:51:01.811153 90901 sgd_solver.cpp:106] Iteration 94110, lr = 0.001
I0906 07:51:09.754741 90901 solver.cpp:228] Iteration 94120, loss = 0.0745836
I0906 07:51:09.754952 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0745845 (* 1 = 0.0745845 loss)
I0906 07:51:09.754971 90901 sgd_solver.cpp:106] Iteration 94120, lr = 0.001
I0906 07:51:17.677137 90901 solver.cpp:228] Iteration 94130, loss = 0.0684106
I0906 07:51:17.677243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684115 (* 1 = 0.0684115 loss)
I0906 07:51:17.677263 90901 sgd_solver.cpp:106] Iteration 94130, lr = 0.001
I0906 07:51:25.323343 90901 solver.cpp:228] Iteration 94140, loss = 0.0666295
I0906 07:51:25.323408 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0666304 (* 1 = 0.0666304 loss)
I0906 07:51:25.323424 90901 sgd_solver.cpp:106] Iteration 94140, lr = 0.001
I0906 07:51:32.727278 90901 solver.cpp:228] Iteration 94150, loss = 0.148662
I0906 07:51:32.727380 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148663 (* 1 = 0.148663 loss)
I0906 07:51:32.727399 90901 sgd_solver.cpp:106] Iteration 94150, lr = 0.001
I0906 07:51:40.420346 90901 solver.cpp:228] Iteration 94160, loss = 0.0549883
I0906 07:51:40.420516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0549893 (* 1 = 0.0549893 loss)
I0906 07:51:40.420536 90901 sgd_solver.cpp:106] Iteration 94160, lr = 0.001
I0906 07:51:48.262869 90901 solver.cpp:228] Iteration 94170, loss = 0.017664
I0906 07:51:48.262938 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0176649 (* 1 = 0.0176649 loss)
I0906 07:51:48.262956 90901 sgd_solver.cpp:106] Iteration 94170, lr = 0.001
I0906 07:51:56.616111 90901 solver.cpp:228] Iteration 94180, loss = 0.130726
I0906 07:51:56.616379 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130727 (* 1 = 0.130727 loss)
I0906 07:51:56.616420 90901 sgd_solver.cpp:106] Iteration 94180, lr = 0.001
I0906 07:52:04.277066 90901 solver.cpp:228] Iteration 94190, loss = 0.0280622
I0906 07:52:04.277153 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0280631 (* 1 = 0.0280631 loss)
I0906 07:52:04.277171 90901 sgd_solver.cpp:106] Iteration 94190, lr = 0.001
I0906 07:52:12.872478 90901 solver.cpp:228] Iteration 94200, loss = 0.239433
I0906 07:52:12.872675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239434 (* 1 = 0.239434 loss)
I0906 07:52:12.872694 90901 sgd_solver.cpp:106] Iteration 94200, lr = 0.001
I0906 07:52:21.138298 90901 solver.cpp:228] Iteration 94210, loss = 0.118431
I0906 07:52:21.138371 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118432 (* 1 = 0.118432 loss)
I0906 07:52:21.138387 90901 sgd_solver.cpp:106] Iteration 94210, lr = 0.001
I0906 07:52:29.113930 90901 solver.cpp:228] Iteration 94220, loss = 0.0288471
I0906 07:52:29.114004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.028848 (* 1 = 0.028848 loss)
I0906 07:52:29.114022 90901 sgd_solver.cpp:106] Iteration 94220, lr = 0.001
I0906 07:52:36.356040 90901 solver.cpp:228] Iteration 94230, loss = 0.13733
I0906 07:52:36.356125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137331 (* 1 = 0.137331 loss)
I0906 07:52:36.356143 90901 sgd_solver.cpp:106] Iteration 94230, lr = 0.001
I0906 07:52:44.529145 90901 solver.cpp:228] Iteration 94240, loss = 0.111742
I0906 07:52:44.529332 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111743 (* 1 = 0.111743 loss)
I0906 07:52:44.529352 90901 sgd_solver.cpp:106] Iteration 94240, lr = 0.001
I0906 07:52:52.378012 90901 solver.cpp:228] Iteration 94250, loss = 0.0479892
I0906 07:52:52.378080 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0479901 (* 1 = 0.0479901 loss)
I0906 07:52:52.378098 90901 sgd_solver.cpp:106] Iteration 94250, lr = 0.001
I0906 07:53:00.344404 90901 solver.cpp:228] Iteration 94260, loss = 0.0630627
I0906 07:53:00.344470 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0630636 (* 1 = 0.0630636 loss)
I0906 07:53:00.344485 90901 sgd_solver.cpp:106] Iteration 94260, lr = 0.001
I0906 07:53:08.180337 90901 solver.cpp:228] Iteration 94270, loss = 0.126466
I0906 07:53:08.180393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126466 (* 1 = 0.126466 loss)
I0906 07:53:08.180415 90901 sgd_solver.cpp:106] Iteration 94270, lr = 0.001
I0906 07:53:16.090991 90901 solver.cpp:228] Iteration 94280, loss = 0.150226
I0906 07:53:16.091168 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.150227 (* 1 = 0.150227 loss)
I0906 07:53:16.091187 90901 sgd_solver.cpp:106] Iteration 94280, lr = 0.001
I0906 07:53:23.879354 90901 solver.cpp:228] Iteration 94290, loss = 0.0719183
I0906 07:53:23.879420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0719192 (* 1 = 0.0719192 loss)
I0906 07:53:23.879436 90901 sgd_solver.cpp:106] Iteration 94290, lr = 0.001
I0906 07:53:32.047319 90901 solver.cpp:228] Iteration 94300, loss = 0.339406
I0906 07:53:32.047406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.339406 (* 1 = 0.339406 loss)
I0906 07:53:32.047425 90901 sgd_solver.cpp:106] Iteration 94300, lr = 0.001
I0906 07:53:40.378702 90901 solver.cpp:228] Iteration 94310, loss = 0.0247183
I0906 07:53:40.378772 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0247192 (* 1 = 0.0247192 loss)
I0906 07:53:40.378789 90901 sgd_solver.cpp:106] Iteration 94310, lr = 0.001
I0906 07:53:47.504835 90901 solver.cpp:228] Iteration 94320, loss = 0.11892
I0906 07:53:47.505033 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118921 (* 1 = 0.118921 loss)
I0906 07:53:47.505061 90901 sgd_solver.cpp:106] Iteration 94320, lr = 0.001
I0906 07:53:55.670490 90901 solver.cpp:228] Iteration 94330, loss = 0.093615
I0906 07:53:55.670550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0936159 (* 1 = 0.0936159 loss)
I0906 07:53:55.670567 90901 sgd_solver.cpp:106] Iteration 94330, lr = 0.001
I0906 07:54:02.932116 90901 solver.cpp:228] Iteration 94340, loss = 0.0381593
I0906 07:54:02.932188 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0381602 (* 1 = 0.0381602 loss)
I0906 07:54:02.932210 90901 sgd_solver.cpp:106] Iteration 94340, lr = 0.001
I0906 07:54:10.680698 90901 solver.cpp:228] Iteration 94350, loss = 0.119786
I0906 07:54:10.680771 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119787 (* 1 = 0.119787 loss)
I0906 07:54:10.680793 90901 sgd_solver.cpp:106] Iteration 94350, lr = 0.001
I0906 07:54:19.271862 90901 solver.cpp:228] Iteration 94360, loss = 0.183522
I0906 07:54:19.272019 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183523 (* 1 = 0.183523 loss)
I0906 07:54:19.272049 90901 sgd_solver.cpp:106] Iteration 94360, lr = 0.001
I0906 07:54:27.082106 90901 solver.cpp:228] Iteration 94370, loss = 0.0601772
I0906 07:54:27.082180 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0601781 (* 1 = 0.0601781 loss)
I0906 07:54:27.082197 90901 sgd_solver.cpp:106] Iteration 94370, lr = 0.001
I0906 07:54:35.399673 90901 solver.cpp:228] Iteration 94380, loss = 0.104889
I0906 07:54:35.399760 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10489 (* 1 = 0.10489 loss)
I0906 07:54:35.399776 90901 sgd_solver.cpp:106] Iteration 94380, lr = 0.001
I0906 07:54:43.557432 90901 solver.cpp:228] Iteration 94390, loss = 0.216849
I0906 07:54:43.557519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21685 (* 1 = 0.21685 loss)
I0906 07:54:43.557536 90901 sgd_solver.cpp:106] Iteration 94390, lr = 0.001
I0906 07:54:51.885957 90901 solver.cpp:337] Iteration 94400, Testing net (#0)
I0906 07:55:47.640331 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.950312
I0906 07:55:47.640517 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.133434 (* 1 = 0.133434 loss)
I0906 07:55:48.122607 90901 solver.cpp:228] Iteration 94400, loss = 0.195482
I0906 07:55:48.122687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195483 (* 1 = 0.195483 loss)
I0906 07:55:48.122710 90901 sgd_solver.cpp:106] Iteration 94400, lr = 0.001
I0906 07:55:55.239099 90901 solver.cpp:228] Iteration 94410, loss = 0.119381
I0906 07:55:55.239166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119382 (* 1 = 0.119382 loss)
I0906 07:55:55.239182 90901 sgd_solver.cpp:106] Iteration 94410, lr = 0.001
I0906 07:56:02.524912 90901 solver.cpp:228] Iteration 94420, loss = 0.236035
I0906 07:56:02.524994 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.236036 (* 1 = 0.236036 loss)
I0906 07:56:02.525015 90901 sgd_solver.cpp:106] Iteration 94420, lr = 0.001
I0906 07:56:09.913342 90901 solver.cpp:228] Iteration 94430, loss = 0.0881987
I0906 07:56:09.913422 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0881996 (* 1 = 0.0881996 loss)
I0906 07:56:09.913439 90901 sgd_solver.cpp:106] Iteration 94430, lr = 0.001
I0906 07:56:17.296028 90901 solver.cpp:228] Iteration 94440, loss = 0.196212
I0906 07:56:17.296110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196213 (* 1 = 0.196213 loss)
I0906 07:56:17.296128 90901 sgd_solver.cpp:106] Iteration 94440, lr = 0.001
I0906 07:56:23.330934 90901 solver.cpp:228] Iteration 94450, loss = 0.463603
I0906 07:56:23.331148 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.463604 (* 1 = 0.463604 loss)
I0906 07:56:23.331176 90901 sgd_solver.cpp:106] Iteration 94450, lr = 0.001
I0906 07:56:30.137132 90901 solver.cpp:228] Iteration 94460, loss = 0.204363
I0906 07:56:30.137238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204364 (* 1 = 0.204364 loss)
I0906 07:56:30.137264 90901 sgd_solver.cpp:106] Iteration 94460, lr = 0.001
I0906 07:56:36.459890 90901 solver.cpp:228] Iteration 94470, loss = 0.0822509
I0906 07:56:36.459974 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0822517 (* 1 = 0.0822517 loss)
I0906 07:56:36.459991 90901 sgd_solver.cpp:106] Iteration 94470, lr = 0.001
I0906 07:56:41.643818 90901 solver.cpp:228] Iteration 94480, loss = 0.109739
I0906 07:56:41.643904 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10974 (* 1 = 0.10974 loss)
I0906 07:56:41.643923 90901 sgd_solver.cpp:106] Iteration 94480, lr = 0.001
I0906 07:56:46.882028 90901 solver.cpp:228] Iteration 94490, loss = 0.245924
I0906 07:56:46.882105 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245925 (* 1 = 0.245925 loss)
I0906 07:56:46.882128 90901 sgd_solver.cpp:106] Iteration 94490, lr = 0.001
I0906 07:56:53.013151 90901 solver.cpp:228] Iteration 94500, loss = 0.0793391
I0906 07:56:53.013228 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0793399 (* 1 = 0.0793399 loss)
I0906 07:56:53.013254 90901 sgd_solver.cpp:106] Iteration 94500, lr = 0.001
I0906 07:56:59.535712 90901 solver.cpp:228] Iteration 94510, loss = 0.0590213
I0906 07:56:59.535918 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0590222 (* 1 = 0.0590222 loss)
I0906 07:56:59.535951 90901 sgd_solver.cpp:106] Iteration 94510, lr = 0.001
I0906 07:57:05.260766 90901 solver.cpp:228] Iteration 94520, loss = 0.127618
I0906 07:57:05.260870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127619 (* 1 = 0.127619 loss)
I0906 07:57:05.260895 90901 sgd_solver.cpp:106] Iteration 94520, lr = 0.001
I0906 07:57:10.462082 90901 solver.cpp:228] Iteration 94530, loss = 0.0376387
I0906 07:57:10.462157 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0376396 (* 1 = 0.0376396 loss)
I0906 07:57:10.462174 90901 sgd_solver.cpp:106] Iteration 94530, lr = 0.001
I0906 07:57:16.193002 90901 solver.cpp:228] Iteration 94540, loss = 0.321679
I0906 07:57:16.193092 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.32168 (* 1 = 0.32168 loss)
I0906 07:57:16.193109 90901 sgd_solver.cpp:106] Iteration 94540, lr = 0.001
I0906 07:57:21.602350 90901 solver.cpp:228] Iteration 94550, loss = 0.0909503
I0906 07:57:21.602442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0909511 (* 1 = 0.0909511 loss)
I0906 07:57:21.602466 90901 sgd_solver.cpp:106] Iteration 94550, lr = 0.001
I0906 07:57:26.828901 90901 solver.cpp:228] Iteration 94560, loss = 0.0350773
I0906 07:57:26.828994 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350782 (* 1 = 0.0350782 loss)
I0906 07:57:26.829020 90901 sgd_solver.cpp:106] Iteration 94560, lr = 0.001
I0906 07:57:32.054774 90901 solver.cpp:228] Iteration 94570, loss = 0.132732
I0906 07:57:32.055001 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132732 (* 1 = 0.132732 loss)
I0906 07:57:32.055019 90901 sgd_solver.cpp:106] Iteration 94570, lr = 0.001
I0906 07:57:37.605444 90901 solver.cpp:228] Iteration 94580, loss = 0.0384677
I0906 07:57:37.605526 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0384686 (* 1 = 0.0384686 loss)
I0906 07:57:37.605545 90901 sgd_solver.cpp:106] Iteration 94580, lr = 0.001
I0906 07:57:42.822404 90901 solver.cpp:228] Iteration 94590, loss = 0.0182225
I0906 07:57:42.822491 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0182234 (* 1 = 0.0182234 loss)
I0906 07:57:42.822515 90901 sgd_solver.cpp:106] Iteration 94590, lr = 0.001
I0906 07:57:48.072080 90901 solver.cpp:228] Iteration 94600, loss = 0.0540326
I0906 07:57:48.072166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0540335 (* 1 = 0.0540335 loss)
I0906 07:57:48.072190 90901 sgd_solver.cpp:106] Iteration 94600, lr = 0.001
I0906 07:57:53.631778 90901 solver.cpp:228] Iteration 94610, loss = 0.0848198
I0906 07:57:53.631913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0848207 (* 1 = 0.0848207 loss)
I0906 07:57:53.631940 90901 sgd_solver.cpp:106] Iteration 94610, lr = 0.001
I0906 07:57:58.839169 90901 solver.cpp:228] Iteration 94620, loss = 0.18687
I0906 07:57:58.839233 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186871 (* 1 = 0.186871 loss)
I0906 07:57:58.839249 90901 sgd_solver.cpp:106] Iteration 94620, lr = 0.001
I0906 07:58:04.062773 90901 solver.cpp:228] Iteration 94630, loss = 0.16125
I0906 07:58:04.062971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161251 (* 1 = 0.161251 loss)
I0906 07:58:04.062990 90901 sgd_solver.cpp:106] Iteration 94630, lr = 0.001
I0906 07:58:10.109035 90901 solver.cpp:228] Iteration 94640, loss = 0.215743
I0906 07:58:10.109096 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.215744 (* 1 = 0.215744 loss)
I0906 07:58:10.109113 90901 sgd_solver.cpp:106] Iteration 94640, lr = 0.001
I0906 07:58:17.738106 90901 solver.cpp:228] Iteration 94650, loss = 0.211011
I0906 07:58:17.738198 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211012 (* 1 = 0.211012 loss)
I0906 07:58:17.738219 90901 sgd_solver.cpp:106] Iteration 94650, lr = 0.001
I0906 07:58:25.416766 90901 solver.cpp:228] Iteration 94660, loss = 0.107696
I0906 07:58:25.416847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107697 (* 1 = 0.107697 loss)
I0906 07:58:25.416867 90901 sgd_solver.cpp:106] Iteration 94660, lr = 0.001
I0906 07:58:33.696045 90901 solver.cpp:228] Iteration 94670, loss = 0.0404622
I0906 07:58:33.696152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0404632 (* 1 = 0.0404632 loss)
I0906 07:58:33.696177 90901 sgd_solver.cpp:106] Iteration 94670, lr = 0.001
I0906 07:58:41.328311 90901 solver.cpp:228] Iteration 94680, loss = 0.0433991
I0906 07:58:41.328680 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0434 (* 1 = 0.0434 loss)
I0906 07:58:41.328723 90901 sgd_solver.cpp:106] Iteration 94680, lr = 0.001
I0906 07:58:48.865841 90901 solver.cpp:228] Iteration 94690, loss = 0.0474179
I0906 07:58:48.865926 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0474189 (* 1 = 0.0474189 loss)
I0906 07:58:48.865944 90901 sgd_solver.cpp:106] Iteration 94690, lr = 0.001
I0906 07:58:56.592550 90901 solver.cpp:228] Iteration 94700, loss = 0.222863
I0906 07:58:56.592638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.222864 (* 1 = 0.222864 loss)
I0906 07:58:56.592655 90901 sgd_solver.cpp:106] Iteration 94700, lr = 0.001
I0906 07:59:04.964349 90901 solver.cpp:228] Iteration 94710, loss = 0.176301
I0906 07:59:04.964447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176302 (* 1 = 0.176302 loss)
I0906 07:59:04.964465 90901 sgd_solver.cpp:106] Iteration 94710, lr = 0.001
I0906 07:59:12.903249 90901 solver.cpp:228] Iteration 94720, loss = 0.0977008
I0906 07:59:12.903471 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0977018 (* 1 = 0.0977018 loss)
I0906 07:59:12.903493 90901 sgd_solver.cpp:106] Iteration 94720, lr = 0.001
I0906 07:59:20.529289 90901 solver.cpp:228] Iteration 94730, loss = 0.123132
I0906 07:59:20.529351 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123133 (* 1 = 0.123133 loss)
I0906 07:59:20.529371 90901 sgd_solver.cpp:106] Iteration 94730, lr = 0.001
I0906 07:59:28.408987 90901 solver.cpp:228] Iteration 94740, loss = 0.0484233
I0906 07:59:28.409060 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0484243 (* 1 = 0.0484243 loss)
I0906 07:59:28.409078 90901 sgd_solver.cpp:106] Iteration 94740, lr = 0.001
I0906 07:59:36.539402 90901 solver.cpp:228] Iteration 94750, loss = 0.195773
I0906 07:59:36.539490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195774 (* 1 = 0.195774 loss)
I0906 07:59:36.539511 90901 sgd_solver.cpp:106] Iteration 94750, lr = 0.001
I0906 07:59:43.909312 90901 solver.cpp:228] Iteration 94760, loss = 0.0497556
I0906 07:59:43.909487 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0497567 (* 1 = 0.0497567 loss)
I0906 07:59:43.909507 90901 sgd_solver.cpp:106] Iteration 94760, lr = 0.001
I0906 07:59:51.919216 90901 solver.cpp:228] Iteration 94770, loss = 0.0588234
I0906 07:59:51.919288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0588244 (* 1 = 0.0588244 loss)
I0906 07:59:51.919307 90901 sgd_solver.cpp:106] Iteration 94770, lr = 0.001
I0906 08:00:00.062517 90901 solver.cpp:228] Iteration 94780, loss = 0.0884686
I0906 08:00:00.062593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0884696 (* 1 = 0.0884696 loss)
I0906 08:00:00.062611 90901 sgd_solver.cpp:106] Iteration 94780, lr = 0.001
I0906 08:00:07.641405 90901 solver.cpp:228] Iteration 94790, loss = 0.239485
I0906 08:00:07.641505 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.239486 (* 1 = 0.239486 loss)
I0906 08:00:07.641522 90901 sgd_solver.cpp:106] Iteration 94790, lr = 0.001
I0906 08:00:15.927492 90901 solver.cpp:228] Iteration 94800, loss = 0.321937
I0906 08:00:15.927727 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.321938 (* 1 = 0.321938 loss)
I0906 08:00:15.927753 90901 sgd_solver.cpp:106] Iteration 94800, lr = 0.001
I0906 08:00:24.150244 90901 solver.cpp:228] Iteration 94810, loss = 0.0773319
I0906 08:00:24.150357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0773329 (* 1 = 0.0773329 loss)
I0906 08:00:24.150382 90901 sgd_solver.cpp:106] Iteration 94810, lr = 0.001
I0906 08:00:31.498956 90901 solver.cpp:228] Iteration 94820, loss = 0.0338907
I0906 08:00:31.499044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0338917 (* 1 = 0.0338917 loss)
I0906 08:00:31.499065 90901 sgd_solver.cpp:106] Iteration 94820, lr = 0.001
I0906 08:00:39.945523 90901 solver.cpp:228] Iteration 94830, loss = 0.0981405
I0906 08:00:39.945618 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0981415 (* 1 = 0.0981415 loss)
I0906 08:00:39.945636 90901 sgd_solver.cpp:106] Iteration 94830, lr = 0.001
I0906 08:00:47.625069 90901 solver.cpp:228] Iteration 94840, loss = 0.185845
I0906 08:00:47.625280 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185846 (* 1 = 0.185846 loss)
I0906 08:00:47.625313 90901 sgd_solver.cpp:106] Iteration 94840, lr = 0.001
I0906 08:00:54.935292 90901 solver.cpp:228] Iteration 94850, loss = 0.0795479
I0906 08:00:54.935385 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0795488 (* 1 = 0.0795488 loss)
I0906 08:00:54.935410 90901 sgd_solver.cpp:106] Iteration 94850, lr = 0.001
I0906 08:01:02.216104 90901 solver.cpp:228] Iteration 94860, loss = 0.16227
I0906 08:01:02.216164 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.162271 (* 1 = 0.162271 loss)
I0906 08:01:02.216183 90901 sgd_solver.cpp:106] Iteration 94860, lr = 0.001
I0906 08:01:10.322176 90901 solver.cpp:228] Iteration 94870, loss = 0.0338254
I0906 08:01:10.322242 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0338264 (* 1 = 0.0338264 loss)
I0906 08:01:10.322258 90901 sgd_solver.cpp:106] Iteration 94870, lr = 0.001
I0906 08:01:18.261620 90901 solver.cpp:228] Iteration 94880, loss = 0.0337829
I0906 08:01:18.261863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0337838 (* 1 = 0.0337838 loss)
I0906 08:01:18.261893 90901 sgd_solver.cpp:106] Iteration 94880, lr = 0.001
I0906 08:01:26.389636 90901 solver.cpp:228] Iteration 94890, loss = 0.722107
I0906 08:01:26.389706 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.722108 (* 1 = 0.722108 loss)
I0906 08:01:26.389724 90901 sgd_solver.cpp:106] Iteration 94890, lr = 0.001
I0906 08:01:34.435868 90901 solver.cpp:228] Iteration 94900, loss = 0.445405
I0906 08:01:34.435945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.445406 (* 1 = 0.445406 loss)
I0906 08:01:34.435962 90901 sgd_solver.cpp:106] Iteration 94900, lr = 0.001
I0906 08:01:42.487706 90901 solver.cpp:228] Iteration 94910, loss = 0.10964
I0906 08:01:42.487782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109641 (* 1 = 0.109641 loss)
I0906 08:01:42.487799 90901 sgd_solver.cpp:106] Iteration 94910, lr = 0.001
I0906 08:01:50.553247 90901 solver.cpp:228] Iteration 94920, loss = 0.0129389
I0906 08:01:50.553447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0129398 (* 1 = 0.0129398 loss)
I0906 08:01:50.553469 90901 sgd_solver.cpp:106] Iteration 94920, lr = 0.001
I0906 08:01:58.737625 90901 solver.cpp:228] Iteration 94930, loss = 0.163698
I0906 08:01:58.737687 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163699 (* 1 = 0.163699 loss)
I0906 08:01:58.737704 90901 sgd_solver.cpp:106] Iteration 94930, lr = 0.001
I0906 08:02:07.177750 90901 solver.cpp:228] Iteration 94940, loss = 0.225616
I0906 08:02:07.177826 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225617 (* 1 = 0.225617 loss)
I0906 08:02:07.177845 90901 sgd_solver.cpp:106] Iteration 94940, lr = 0.001
I0906 08:02:15.626528 90901 solver.cpp:228] Iteration 94950, loss = 0.113
I0906 08:02:15.626646 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113001 (* 1 = 0.113001 loss)
I0906 08:02:15.626674 90901 sgd_solver.cpp:106] Iteration 94950, lr = 0.001
I0906 08:02:23.722905 90901 solver.cpp:228] Iteration 94960, loss = 0.104638
I0906 08:02:23.723152 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104639 (* 1 = 0.104639 loss)
I0906 08:02:23.723171 90901 sgd_solver.cpp:106] Iteration 94960, lr = 0.001
I0906 08:02:32.048617 90901 solver.cpp:228] Iteration 94970, loss = 0.0943468
I0906 08:02:32.048686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0943477 (* 1 = 0.0943477 loss)
I0906 08:02:32.048703 90901 sgd_solver.cpp:106] Iteration 94970, lr = 0.001
I0906 08:02:40.879294 90901 solver.cpp:228] Iteration 94980, loss = 0.0657884
I0906 08:02:40.879384 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0657893 (* 1 = 0.0657893 loss)
I0906 08:02:40.879402 90901 sgd_solver.cpp:106] Iteration 94980, lr = 0.001
I0906 08:02:48.717150 90901 solver.cpp:228] Iteration 94990, loss = 0.102774
I0906 08:02:48.717239 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102775 (* 1 = 0.102775 loss)
I0906 08:02:48.717259 90901 sgd_solver.cpp:106] Iteration 94990, lr = 0.001
I0906 08:02:56.923779 90901 solver.cpp:228] Iteration 95000, loss = 0.422599
I0906 08:02:56.923996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.4226 (* 1 = 0.4226 loss)
I0906 08:02:56.924021 90901 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0906 08:03:04.659991 90901 solver.cpp:228] Iteration 95010, loss = 0.0747325
I0906 08:03:04.660116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0747335 (* 1 = 0.0747335 loss)
I0906 08:03:04.660147 90901 sgd_solver.cpp:106] Iteration 95010, lr = 0.001
I0906 08:03:13.092814 90901 solver.cpp:228] Iteration 95020, loss = 0.0728081
I0906 08:03:13.092885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0728091 (* 1 = 0.0728091 loss)
I0906 08:03:13.092901 90901 sgd_solver.cpp:106] Iteration 95020, lr = 0.001
I0906 08:03:20.676890 90901 solver.cpp:228] Iteration 95030, loss = 0.0596477
I0906 08:03:20.676980 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596487 (* 1 = 0.0596487 loss)
I0906 08:03:20.677003 90901 sgd_solver.cpp:106] Iteration 95030, lr = 0.001
I0906 08:03:28.745244 90901 solver.cpp:228] Iteration 95040, loss = 0.130179
I0906 08:03:28.745443 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13018 (* 1 = 0.13018 loss)
I0906 08:03:28.745473 90901 sgd_solver.cpp:106] Iteration 95040, lr = 0.001
I0906 08:03:36.599306 90901 solver.cpp:228] Iteration 95050, loss = 0.0959889
I0906 08:03:36.599378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0959899 (* 1 = 0.0959899 loss)
I0906 08:03:36.599398 90901 sgd_solver.cpp:106] Iteration 95050, lr = 0.001
I0906 08:03:44.174521 90901 solver.cpp:228] Iteration 95060, loss = 0.0405674
I0906 08:03:44.174648 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0405684 (* 1 = 0.0405684 loss)
I0906 08:03:44.174671 90901 sgd_solver.cpp:106] Iteration 95060, lr = 0.001
I0906 08:03:52.543378 90901 solver.cpp:228] Iteration 95070, loss = 0.0899391
I0906 08:03:52.543453 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.08994 (* 1 = 0.08994 loss)
I0906 08:03:52.543473 90901 sgd_solver.cpp:106] Iteration 95070, lr = 0.001
I0906 08:04:00.640997 90901 solver.cpp:228] Iteration 95080, loss = 0.0772327
I0906 08:04:00.641176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0772336 (* 1 = 0.0772336 loss)
I0906 08:04:00.641201 90901 sgd_solver.cpp:106] Iteration 95080, lr = 0.001
I0906 08:04:08.547113 90901 solver.cpp:228] Iteration 95090, loss = 0.112697
I0906 08:04:08.547194 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112698 (* 1 = 0.112698 loss)
I0906 08:04:08.547214 90901 sgd_solver.cpp:106] Iteration 95090, lr = 0.001
I0906 08:04:16.629782 90901 solver.cpp:228] Iteration 95100, loss = 0.165957
I0906 08:04:16.629847 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165958 (* 1 = 0.165958 loss)
I0906 08:04:16.629863 90901 sgd_solver.cpp:106] Iteration 95100, lr = 0.001
I0906 08:04:24.511116 90901 solver.cpp:228] Iteration 95110, loss = 0.168338
I0906 08:04:24.511204 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168338 (* 1 = 0.168338 loss)
I0906 08:04:24.511221 90901 sgd_solver.cpp:106] Iteration 95110, lr = 0.001
I0906 08:04:32.364513 90901 solver.cpp:228] Iteration 95120, loss = 0.117448
I0906 08:04:32.364707 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117449 (* 1 = 0.117449 loss)
I0906 08:04:32.364737 90901 sgd_solver.cpp:106] Iteration 95120, lr = 0.001
I0906 08:04:39.926779 90901 solver.cpp:228] Iteration 95130, loss = 0.0462805
I0906 08:04:39.926861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0462814 (* 1 = 0.0462814 loss)
I0906 08:04:39.926877 90901 sgd_solver.cpp:106] Iteration 95130, lr = 0.001
I0906 08:04:47.785643 90901 solver.cpp:228] Iteration 95140, loss = 0.275498
I0906 08:04:47.785740 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.275499 (* 1 = 0.275499 loss)
I0906 08:04:47.785766 90901 sgd_solver.cpp:106] Iteration 95140, lr = 0.001
I0906 08:04:56.509992 90901 solver.cpp:228] Iteration 95150, loss = 0.0292504
I0906 08:04:56.510077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0292513 (* 1 = 0.0292513 loss)
I0906 08:04:56.510095 90901 sgd_solver.cpp:106] Iteration 95150, lr = 0.001
I0906 08:05:05.353592 90901 solver.cpp:228] Iteration 95160, loss = 0.15664
I0906 08:05:05.353837 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156641 (* 1 = 0.156641 loss)
I0906 08:05:05.353866 90901 sgd_solver.cpp:106] Iteration 95160, lr = 0.001
I0906 08:05:13.981807 90901 solver.cpp:228] Iteration 95170, loss = 0.161558
I0906 08:05:13.981919 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161559 (* 1 = 0.161559 loss)
I0906 08:05:13.981936 90901 sgd_solver.cpp:106] Iteration 95170, lr = 0.001
I0906 08:05:22.950960 90901 solver.cpp:228] Iteration 95180, loss = 0.128908
I0906 08:05:22.951045 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128909 (* 1 = 0.128909 loss)
I0906 08:05:22.951064 90901 sgd_solver.cpp:106] Iteration 95180, lr = 0.001
I0906 08:05:30.893934 90901 solver.cpp:228] Iteration 95190, loss = 0.0829878
I0906 08:05:30.894016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0829887 (* 1 = 0.0829887 loss)
I0906 08:05:30.894033 90901 sgd_solver.cpp:106] Iteration 95190, lr = 0.001
I0906 08:05:38.575978 90901 solver.cpp:337] Iteration 95200, Testing net (#0)
I0906 08:06:34.442505 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.950312
I0906 08:06:34.442687 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.141937 (* 1 = 0.141937 loss)
I0906 08:06:34.761831 90901 solver.cpp:228] Iteration 95200, loss = 0.0546807
I0906 08:06:34.761914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0546816 (* 1 = 0.0546816 loss)
I0906 08:06:34.761943 90901 sgd_solver.cpp:106] Iteration 95200, lr = 0.001
I0906 08:06:42.792568 90901 solver.cpp:228] Iteration 95210, loss = 0.331233
I0906 08:06:42.792637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.331234 (* 1 = 0.331234 loss)
I0906 08:06:42.792654 90901 sgd_solver.cpp:106] Iteration 95210, lr = 0.001
I0906 08:06:50.677947 90901 solver.cpp:228] Iteration 95220, loss = 0.248705
I0906 08:06:50.678022 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248706 (* 1 = 0.248706 loss)
I0906 08:06:50.678041 90901 sgd_solver.cpp:106] Iteration 95220, lr = 0.001
I0906 08:06:58.358325 90901 solver.cpp:228] Iteration 95230, loss = 0.112879
I0906 08:06:58.358398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11288 (* 1 = 0.11288 loss)
I0906 08:06:58.358415 90901 sgd_solver.cpp:106] Iteration 95230, lr = 0.001
I0906 08:07:06.549698 90901 solver.cpp:228] Iteration 95240, loss = 0.033852
I0906 08:07:06.549937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0338529 (* 1 = 0.0338529 loss)
I0906 08:07:06.549965 90901 sgd_solver.cpp:106] Iteration 95240, lr = 0.001
I0906 08:07:14.672371 90901 solver.cpp:228] Iteration 95250, loss = 0.19368
I0906 08:07:14.672452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.193681 (* 1 = 0.193681 loss)
I0906 08:07:14.672472 90901 sgd_solver.cpp:106] Iteration 95250, lr = 0.001
I0906 08:07:22.997062 90901 solver.cpp:228] Iteration 95260, loss = 0.666518
I0906 08:07:22.997125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.666519 (* 1 = 0.666519 loss)
I0906 08:07:22.997143 90901 sgd_solver.cpp:106] Iteration 95260, lr = 0.001
I0906 08:07:30.351025 90901 solver.cpp:228] Iteration 95270, loss = 0.134346
I0906 08:07:30.351125 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134347 (* 1 = 0.134347 loss)
I0906 08:07:30.351145 90901 sgd_solver.cpp:106] Iteration 95270, lr = 0.001
I0906 08:07:38.879333 90901 solver.cpp:228] Iteration 95280, loss = 0.123549
I0906 08:07:38.879570 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.123549 (* 1 = 0.123549 loss)
I0906 08:07:38.879601 90901 sgd_solver.cpp:106] Iteration 95280, lr = 0.001
I0906 08:07:47.099750 90901 solver.cpp:228] Iteration 95290, loss = 0.219877
I0906 08:07:47.099835 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.219878 (* 1 = 0.219878 loss)
I0906 08:07:47.099858 90901 sgd_solver.cpp:106] Iteration 95290, lr = 0.001
I0906 08:07:55.462678 90901 solver.cpp:228] Iteration 95300, loss = 0.0893562
I0906 08:07:55.462780 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.089357 (* 1 = 0.089357 loss)
I0906 08:07:55.462800 90901 sgd_solver.cpp:106] Iteration 95300, lr = 0.001
I0906 08:08:02.741194 90901 solver.cpp:228] Iteration 95310, loss = 0.452513
I0906 08:08:02.741282 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.452514 (* 1 = 0.452514 loss)
I0906 08:08:02.741300 90901 sgd_solver.cpp:106] Iteration 95310, lr = 0.001
I0906 08:08:10.128425 90901 solver.cpp:228] Iteration 95320, loss = 0.0538764
I0906 08:08:10.128685 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0538772 (* 1 = 0.0538772 loss)
I0906 08:08:10.128708 90901 sgd_solver.cpp:106] Iteration 95320, lr = 0.001
I0906 08:08:17.183528 90901 solver.cpp:228] Iteration 95330, loss = 0.314599
I0906 08:08:17.183620 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3146 (* 1 = 0.3146 loss)
I0906 08:08:17.183639 90901 sgd_solver.cpp:106] Iteration 95330, lr = 0.001
I0906 08:08:24.710183 90901 solver.cpp:228] Iteration 95340, loss = 0.192592
I0906 08:08:24.710258 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192593 (* 1 = 0.192593 loss)
I0906 08:08:24.710274 90901 sgd_solver.cpp:106] Iteration 95340, lr = 0.001
I0906 08:08:31.799408 90901 solver.cpp:228] Iteration 95350, loss = 0.0619621
I0906 08:08:31.799490 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0619629 (* 1 = 0.0619629 loss)
I0906 08:08:31.799507 90901 sgd_solver.cpp:106] Iteration 95350, lr = 0.001
I0906 08:08:39.064165 90901 solver.cpp:228] Iteration 95360, loss = 0.18625
I0906 08:08:39.064236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.18625 (* 1 = 0.18625 loss)
I0906 08:08:39.064254 90901 sgd_solver.cpp:106] Iteration 95360, lr = 0.001
I0906 08:08:46.132127 90901 solver.cpp:228] Iteration 95370, loss = 0.448743
I0906 08:08:46.132342 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.448744 (* 1 = 0.448744 loss)
I0906 08:08:46.132360 90901 sgd_solver.cpp:106] Iteration 95370, lr = 0.001
I0906 08:08:53.415591 90901 solver.cpp:228] Iteration 95380, loss = 0.0769234
I0906 08:08:53.415660 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0769242 (* 1 = 0.0769242 loss)
I0906 08:08:53.415679 90901 sgd_solver.cpp:106] Iteration 95380, lr = 0.001
I0906 08:08:59.404243 90901 solver.cpp:228] Iteration 95390, loss = 0.329584
I0906 08:08:59.404353 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329585 (* 1 = 0.329585 loss)
I0906 08:08:59.404378 90901 sgd_solver.cpp:106] Iteration 95390, lr = 0.001
I0906 08:09:04.344283 90901 solver.cpp:228] Iteration 95400, loss = 0.103446
I0906 08:09:04.344362 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103447 (* 1 = 0.103447 loss)
I0906 08:09:04.344379 90901 sgd_solver.cpp:106] Iteration 95400, lr = 0.001
I0906 08:09:09.931392 90901 solver.cpp:228] Iteration 95410, loss = 0.10816
I0906 08:09:09.931475 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108161 (* 1 = 0.108161 loss)
I0906 08:09:09.931493 90901 sgd_solver.cpp:106] Iteration 95410, lr = 0.001
I0906 08:09:15.122277 90901 solver.cpp:228] Iteration 95420, loss = 0.128169
I0906 08:09:15.122359 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12817 (* 1 = 0.12817 loss)
I0906 08:09:15.122378 90901 sgd_solver.cpp:106] Iteration 95420, lr = 0.001
I0906 08:09:20.337683 90901 solver.cpp:228] Iteration 95430, loss = 0.132607
I0906 08:09:20.337954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132607 (* 1 = 0.132607 loss)
I0906 08:09:20.337973 90901 sgd_solver.cpp:106] Iteration 95430, lr = 0.001
I0906 08:09:26.957841 90901 solver.cpp:228] Iteration 95440, loss = 0.0952701
I0906 08:09:26.957914 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0952709 (* 1 = 0.0952709 loss)
I0906 08:09:26.957936 90901 sgd_solver.cpp:106] Iteration 95440, lr = 0.001
I0906 08:09:34.228610 90901 solver.cpp:228] Iteration 95450, loss = 0.238632
I0906 08:09:34.228708 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238633 (* 1 = 0.238633 loss)
I0906 08:09:34.228727 90901 sgd_solver.cpp:106] Iteration 95450, lr = 0.001
I0906 08:09:40.187316 90901 solver.cpp:228] Iteration 95460, loss = 0.57105
I0906 08:09:40.187496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.571051 (* 1 = 0.571051 loss)
I0906 08:09:40.187530 90901 sgd_solver.cpp:106] Iteration 95460, lr = 0.001
I0906 08:09:45.743424 90901 solver.cpp:228] Iteration 95470, loss = 0.302559
I0906 08:09:45.743515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30256 (* 1 = 0.30256 loss)
I0906 08:09:45.743533 90901 sgd_solver.cpp:106] Iteration 95470, lr = 0.001
I0906 08:09:52.281579 90901 solver.cpp:228] Iteration 95480, loss = 0.216165
I0906 08:09:52.281795 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216166 (* 1 = 0.216166 loss)
I0906 08:09:52.281816 90901 sgd_solver.cpp:106] Iteration 95480, lr = 0.001
I0906 08:09:58.694118 90901 solver.cpp:228] Iteration 95490, loss = 0.0847467
I0906 08:09:58.694176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0847475 (* 1 = 0.0847475 loss)
I0906 08:09:58.694195 90901 sgd_solver.cpp:106] Iteration 95490, lr = 0.001
I0906 08:10:04.671676 90901 solver.cpp:228] Iteration 95500, loss = 0.185175
I0906 08:10:04.671744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.185176 (* 1 = 0.185176 loss)
I0906 08:10:04.671762 90901 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I0906 08:10:12.005795 90901 solver.cpp:228] Iteration 95510, loss = 0.0218498
I0906 08:10:12.005863 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0218505 (* 1 = 0.0218505 loss)
I0906 08:10:12.005882 90901 sgd_solver.cpp:106] Iteration 95510, lr = 0.001
I0906 08:10:18.397115 90901 solver.cpp:228] Iteration 95520, loss = 0.161165
I0906 08:10:18.397202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161165 (* 1 = 0.161165 loss)
I0906 08:10:18.397219 90901 sgd_solver.cpp:106] Iteration 95520, lr = 0.001
I0906 08:10:25.771214 90901 solver.cpp:228] Iteration 95530, loss = 0.346255
I0906 08:10:25.771410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.346256 (* 1 = 0.346256 loss)
I0906 08:10:25.771428 90901 sgd_solver.cpp:106] Iteration 95530, lr = 0.001
I0906 08:10:32.606771 90901 solver.cpp:228] Iteration 95540, loss = 0.158745
I0906 08:10:32.606861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.158745 (* 1 = 0.158745 loss)
I0906 08:10:32.606885 90901 sgd_solver.cpp:106] Iteration 95540, lr = 0.001
I0906 08:10:40.021777 90901 solver.cpp:228] Iteration 95550, loss = 0.144708
I0906 08:10:40.021877 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144709 (* 1 = 0.144709 loss)
I0906 08:10:40.021894 90901 sgd_solver.cpp:106] Iteration 95550, lr = 0.001
I0906 08:10:48.091717 90901 solver.cpp:228] Iteration 95560, loss = 0.245302
I0906 08:10:48.091792 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.245303 (* 1 = 0.245303 loss)
I0906 08:10:48.091812 90901 sgd_solver.cpp:106] Iteration 95560, lr = 0.001
I0906 08:10:56.168931 90901 solver.cpp:228] Iteration 95570, loss = 0.43436
I0906 08:10:56.169116 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.434361 (* 1 = 0.434361 loss)
I0906 08:10:56.169134 90901 sgd_solver.cpp:106] Iteration 95570, lr = 0.001
I0906 08:11:04.191695 90901 solver.cpp:228] Iteration 95580, loss = 0.0349918
I0906 08:11:04.191763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0349926 (* 1 = 0.0349926 loss)
I0906 08:11:04.191781 90901 sgd_solver.cpp:106] Iteration 95580, lr = 0.001
I0906 08:11:12.216055 90901 solver.cpp:228] Iteration 95590, loss = 0.13328
I0906 08:11:12.216208 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133281 (* 1 = 0.133281 loss)
I0906 08:11:12.216233 90901 sgd_solver.cpp:106] Iteration 95590, lr = 0.001
I0906 08:11:20.214258 90901 solver.cpp:228] Iteration 95600, loss = 0.244839
I0906 08:11:20.214344 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24484 (* 1 = 0.24484 loss)
I0906 08:11:20.214360 90901 sgd_solver.cpp:106] Iteration 95600, lr = 0.001
I0906 08:11:27.604316 90901 solver.cpp:228] Iteration 95610, loss = 0.205006
I0906 08:11:27.604568 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.205007 (* 1 = 0.205007 loss)
I0906 08:11:27.604586 90901 sgd_solver.cpp:106] Iteration 95610, lr = 0.001
I0906 08:11:34.959857 90901 solver.cpp:228] Iteration 95620, loss = 0.22935
I0906 08:11:34.959924 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229351 (* 1 = 0.229351 loss)
I0906 08:11:34.959942 90901 sgd_solver.cpp:106] Iteration 95620, lr = 0.001
I0906 08:11:42.580257 90901 solver.cpp:228] Iteration 95630, loss = 0.0658359
I0906 08:11:42.580369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0658368 (* 1 = 0.0658368 loss)
I0906 08:11:42.580399 90901 sgd_solver.cpp:106] Iteration 95630, lr = 0.001
I0906 08:11:50.731453 90901 solver.cpp:228] Iteration 95640, loss = 0.0380265
I0906 08:11:50.731542 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0380274 (* 1 = 0.0380274 loss)
I0906 08:11:50.731564 90901 sgd_solver.cpp:106] Iteration 95640, lr = 0.001
I0906 08:11:58.347566 90901 solver.cpp:228] Iteration 95650, loss = 0.0357469
I0906 08:11:58.347786 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0357478 (* 1 = 0.0357478 loss)
I0906 08:11:58.347805 90901 sgd_solver.cpp:106] Iteration 95650, lr = 0.001
I0906 08:12:05.812228 90901 solver.cpp:228] Iteration 95660, loss = 0.0213882
I0906 08:12:05.812325 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0213891 (* 1 = 0.0213891 loss)
I0906 08:12:05.812343 90901 sgd_solver.cpp:106] Iteration 95660, lr = 0.001
I0906 08:12:13.610728 90901 solver.cpp:228] Iteration 95670, loss = 0.170068
I0906 08:12:13.610813 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170068 (* 1 = 0.170068 loss)
I0906 08:12:13.610831 90901 sgd_solver.cpp:106] Iteration 95670, lr = 0.001
I0906 08:12:21.251086 90901 solver.cpp:228] Iteration 95680, loss = 0.110268
I0906 08:12:21.251173 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110269 (* 1 = 0.110269 loss)
I0906 08:12:21.251193 90901 sgd_solver.cpp:106] Iteration 95680, lr = 0.001
I0906 08:12:29.411852 90901 solver.cpp:228] Iteration 95690, loss = 0.116269
I0906 08:12:29.412044 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11627 (* 1 = 0.11627 loss)
I0906 08:12:29.412066 90901 sgd_solver.cpp:106] Iteration 95690, lr = 0.001
I0906 08:12:36.787700 90901 solver.cpp:228] Iteration 95700, loss = 0.130442
I0906 08:12:36.787756 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130443 (* 1 = 0.130443 loss)
I0906 08:12:36.787775 90901 sgd_solver.cpp:106] Iteration 95700, lr = 0.001
I0906 08:12:44.625911 90901 solver.cpp:228] Iteration 95710, loss = 0.0462266
I0906 08:12:44.626039 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0462275 (* 1 = 0.0462275 loss)
I0906 08:12:44.626060 90901 sgd_solver.cpp:106] Iteration 95710, lr = 0.001
I0906 08:12:52.489419 90901 solver.cpp:228] Iteration 95720, loss = 0.0549075
I0906 08:12:52.489501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0549084 (* 1 = 0.0549084 loss)
I0906 08:12:52.489521 90901 sgd_solver.cpp:106] Iteration 95720, lr = 0.001
I0906 08:12:59.987665 90901 solver.cpp:228] Iteration 95730, loss = 0.159384
I0906 08:12:59.987818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159385 (* 1 = 0.159385 loss)
I0906 08:12:59.987838 90901 sgd_solver.cpp:106] Iteration 95730, lr = 0.001
I0906 08:13:07.559824 90901 solver.cpp:228] Iteration 95740, loss = 0.0281713
I0906 08:13:07.559901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0281722 (* 1 = 0.0281722 loss)
I0906 08:13:07.559923 90901 sgd_solver.cpp:106] Iteration 95740, lr = 0.001
I0906 08:13:15.152575 90901 solver.cpp:228] Iteration 95750, loss = 0.0924962
I0906 08:13:15.152647 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.092497 (* 1 = 0.092497 loss)
I0906 08:13:15.152664 90901 sgd_solver.cpp:106] Iteration 95750, lr = 0.001
I0906 08:13:23.001788 90901 solver.cpp:228] Iteration 95760, loss = 0.0959722
I0906 08:13:23.001888 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0959731 (* 1 = 0.0959731 loss)
I0906 08:13:23.001911 90901 sgd_solver.cpp:106] Iteration 95760, lr = 0.001
I0906 08:13:30.302700 90901 solver.cpp:228] Iteration 95770, loss = 0.0789459
I0906 08:13:30.302927 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0789468 (* 1 = 0.0789468 loss)
I0906 08:13:30.302959 90901 sgd_solver.cpp:106] Iteration 95770, lr = 0.001
I0906 08:13:38.157841 90901 solver.cpp:228] Iteration 95780, loss = 0.257112
I0906 08:13:38.157907 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257113 (* 1 = 0.257113 loss)
I0906 08:13:38.157927 90901 sgd_solver.cpp:106] Iteration 95780, lr = 0.001
I0906 08:13:45.966321 90901 solver.cpp:228] Iteration 95790, loss = 0.112423
I0906 08:13:45.966400 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112424 (* 1 = 0.112424 loss)
I0906 08:13:45.966418 90901 sgd_solver.cpp:106] Iteration 95790, lr = 0.001
I0906 08:13:53.343070 90901 solver.cpp:228] Iteration 95800, loss = 0.146862
I0906 08:13:53.343129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146863 (* 1 = 0.146863 loss)
I0906 08:13:53.343147 90901 sgd_solver.cpp:106] Iteration 95800, lr = 0.001
I0906 08:14:00.996682 90901 solver.cpp:228] Iteration 95810, loss = 0.414115
I0906 08:14:00.996852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.414116 (* 1 = 0.414116 loss)
I0906 08:14:00.996886 90901 sgd_solver.cpp:106] Iteration 95810, lr = 0.001
I0906 08:14:08.582633 90901 solver.cpp:228] Iteration 95820, loss = 0.140466
I0906 08:14:08.582703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140467 (* 1 = 0.140467 loss)
I0906 08:14:08.582721 90901 sgd_solver.cpp:106] Iteration 95820, lr = 0.001
I0906 08:14:15.865489 90901 solver.cpp:228] Iteration 95830, loss = 0.151007
I0906 08:14:15.865625 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151008 (* 1 = 0.151008 loss)
I0906 08:14:15.865648 90901 sgd_solver.cpp:106] Iteration 95830, lr = 0.001
I0906 08:14:23.289525 90901 solver.cpp:228] Iteration 95840, loss = 0.110407
I0906 08:14:23.289633 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110408 (* 1 = 0.110408 loss)
I0906 08:14:23.289651 90901 sgd_solver.cpp:106] Iteration 95840, lr = 0.001
I0906 08:14:30.826922 90901 solver.cpp:228] Iteration 95850, loss = 0.0128036
I0906 08:14:30.826985 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0128045 (* 1 = 0.0128045 loss)
I0906 08:14:30.827002 90901 sgd_solver.cpp:106] Iteration 95850, lr = 0.001
I0906 08:14:38.690717 90901 solver.cpp:228] Iteration 95860, loss = 0.100935
I0906 08:14:38.690930 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100935 (* 1 = 0.100935 loss)
I0906 08:14:38.690971 90901 sgd_solver.cpp:106] Iteration 95860, lr = 0.001
I0906 08:14:46.541298 90901 solver.cpp:228] Iteration 95870, loss = 0.109573
I0906 08:14:46.541391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109574 (* 1 = 0.109574 loss)
I0906 08:14:46.541417 90901 sgd_solver.cpp:106] Iteration 95870, lr = 0.001
I0906 08:14:53.362274 90901 solver.cpp:228] Iteration 95880, loss = 0.0632255
I0906 08:14:53.362366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0632264 (* 1 = 0.0632264 loss)
I0906 08:14:53.362390 90901 sgd_solver.cpp:106] Iteration 95880, lr = 0.001
I0906 08:15:01.294525 90901 solver.cpp:228] Iteration 95890, loss = 0.024405
I0906 08:15:01.294603 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0244058 (* 1 = 0.0244058 loss)
I0906 08:15:01.294625 90901 sgd_solver.cpp:106] Iteration 95890, lr = 0.001
I0906 08:15:08.523670 90901 solver.cpp:228] Iteration 95900, loss = 0.133035
I0906 08:15:08.523739 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133035 (* 1 = 0.133035 loss)
I0906 08:15:08.523757 90901 sgd_solver.cpp:106] Iteration 95900, lr = 0.001
I0906 08:15:16.192703 90901 solver.cpp:228] Iteration 95910, loss = 0.153339
I0906 08:15:16.192931 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.15334 (* 1 = 0.15334 loss)
I0906 08:15:16.192961 90901 sgd_solver.cpp:106] Iteration 95910, lr = 0.001
I0906 08:15:24.192657 90901 solver.cpp:228] Iteration 95920, loss = 0.114503
I0906 08:15:24.192736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114504 (* 1 = 0.114504 loss)
I0906 08:15:24.192755 90901 sgd_solver.cpp:106] Iteration 95920, lr = 0.001
I0906 08:15:31.929924 90901 solver.cpp:228] Iteration 95930, loss = 0.12181
I0906 08:15:31.930007 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121811 (* 1 = 0.121811 loss)
I0906 08:15:31.930029 90901 sgd_solver.cpp:106] Iteration 95930, lr = 0.001
I0906 08:15:39.792161 90901 solver.cpp:228] Iteration 95940, loss = 0.181442
I0906 08:15:39.792230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181443 (* 1 = 0.181443 loss)
I0906 08:15:39.792248 90901 sgd_solver.cpp:106] Iteration 95940, lr = 0.001
I0906 08:15:47.688478 90901 solver.cpp:228] Iteration 95950, loss = 0.115426
I0906 08:15:47.688683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115427 (* 1 = 0.115427 loss)
I0906 08:15:47.688705 90901 sgd_solver.cpp:106] Iteration 95950, lr = 0.001
I0906 08:15:56.076253 90901 solver.cpp:228] Iteration 95960, loss = 0.0283318
I0906 08:15:56.076347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0283327 (* 1 = 0.0283327 loss)
I0906 08:15:56.076370 90901 sgd_solver.cpp:106] Iteration 95960, lr = 0.001
I0906 08:16:03.640480 90901 solver.cpp:228] Iteration 95970, loss = 0.383653
I0906 08:16:03.640558 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.383654 (* 1 = 0.383654 loss)
I0906 08:16:03.640579 90901 sgd_solver.cpp:106] Iteration 95970, lr = 0.001
I0906 08:16:11.255404 90901 solver.cpp:228] Iteration 95980, loss = 0.0581874
I0906 08:16:11.255482 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0581883 (* 1 = 0.0581883 loss)
I0906 08:16:11.255502 90901 sgd_solver.cpp:106] Iteration 95980, lr = 0.001
I0906 08:16:18.851227 90901 solver.cpp:228] Iteration 95990, loss = 0.386965
I0906 08:16:18.851426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.386966 (* 1 = 0.386966 loss)
I0906 08:16:18.851462 90901 sgd_solver.cpp:106] Iteration 95990, lr = 0.001
I0906 08:16:26.385435 90901 solver.cpp:337] Iteration 96000, Testing net (#0)
I0906 08:17:22.213655 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.938438
I0906 08:17:22.215162 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.161823 (* 1 = 0.161823 loss)
I0906 08:17:22.585887 90901 solver.cpp:228] Iteration 96000, loss = 0.200842
I0906 08:17:22.585976 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200843 (* 1 = 0.200843 loss)
I0906 08:17:22.586000 90901 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0906 08:17:30.680441 90901 solver.cpp:228] Iteration 96010, loss = 0.156866
I0906 08:17:30.680519 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156866 (* 1 = 0.156866 loss)
I0906 08:17:30.680538 90901 sgd_solver.cpp:106] Iteration 96010, lr = 0.001
I0906 08:17:37.463932 90901 solver.cpp:228] Iteration 96020, loss = 0.133079
I0906 08:17:37.464046 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13308 (* 1 = 0.13308 loss)
I0906 08:17:37.464063 90901 sgd_solver.cpp:106] Iteration 96020, lr = 0.001
I0906 08:17:45.625241 90901 solver.cpp:228] Iteration 96030, loss = 0.0303083
I0906 08:17:45.625322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0303092 (* 1 = 0.0303092 loss)
I0906 08:17:45.625341 90901 sgd_solver.cpp:106] Iteration 96030, lr = 0.001
I0906 08:17:53.116160 90901 solver.cpp:228] Iteration 96040, loss = 0.280469
I0906 08:17:53.116469 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28047 (* 1 = 0.28047 loss)
I0906 08:17:53.116490 90901 sgd_solver.cpp:106] Iteration 96040, lr = 0.001
I0906 08:18:00.993309 90901 solver.cpp:228] Iteration 96050, loss = 0.0419557
I0906 08:18:00.993363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0419566 (* 1 = 0.0419566 loss)
I0906 08:18:00.993381 90901 sgd_solver.cpp:106] Iteration 96050, lr = 0.001
I0906 08:18:08.671129 90901 solver.cpp:228] Iteration 96060, loss = 0.0720621
I0906 08:18:08.671201 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.072063 (* 1 = 0.072063 loss)
I0906 08:18:08.671217 90901 sgd_solver.cpp:106] Iteration 96060, lr = 0.001
I0906 08:18:16.438371 90901 solver.cpp:228] Iteration 96070, loss = 0.0295933
I0906 08:18:16.438459 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0295943 (* 1 = 0.0295943 loss)
I0906 08:18:16.438483 90901 sgd_solver.cpp:106] Iteration 96070, lr = 0.001
I0906 08:18:24.657177 90901 solver.cpp:228] Iteration 96080, loss = 0.0540046
I0906 08:18:24.657419 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0540056 (* 1 = 0.0540056 loss)
I0906 08:18:24.657440 90901 sgd_solver.cpp:106] Iteration 96080, lr = 0.001
I0906 08:18:32.688168 90901 solver.cpp:228] Iteration 96090, loss = 0.411971
I0906 08:18:32.688235 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.411972 (* 1 = 0.411972 loss)
I0906 08:18:32.688252 90901 sgd_solver.cpp:106] Iteration 96090, lr = 0.001
I0906 08:18:39.492367 90901 solver.cpp:228] Iteration 96100, loss = 0.157743
I0906 08:18:39.492446 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157744 (* 1 = 0.157744 loss)
I0906 08:18:39.492465 90901 sgd_solver.cpp:106] Iteration 96100, lr = 0.001
I0906 08:18:47.795380 90901 solver.cpp:228] Iteration 96110, loss = 0.126788
I0906 08:18:47.795452 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126789 (* 1 = 0.126789 loss)
I0906 08:18:47.795470 90901 sgd_solver.cpp:106] Iteration 96110, lr = 0.001
I0906 08:18:55.659380 90901 solver.cpp:228] Iteration 96120, loss = 0.231662
I0906 08:18:55.659585 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.231663 (* 1 = 0.231663 loss)
I0906 08:18:55.659615 90901 sgd_solver.cpp:106] Iteration 96120, lr = 0.001
I0906 08:19:03.744333 90901 solver.cpp:228] Iteration 96130, loss = 0.160746
I0906 08:19:03.744393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160747 (* 1 = 0.160747 loss)
I0906 08:19:03.744410 90901 sgd_solver.cpp:106] Iteration 96130, lr = 0.001
I0906 08:19:11.445930 90901 solver.cpp:228] Iteration 96140, loss = 0.0433642
I0906 08:19:11.445996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0433652 (* 1 = 0.0433652 loss)
I0906 08:19:11.446012 90901 sgd_solver.cpp:106] Iteration 96140, lr = 0.001
I0906 08:19:19.514400 90901 solver.cpp:228] Iteration 96150, loss = 0.294351
I0906 08:19:19.514480 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.294352 (* 1 = 0.294352 loss)
I0906 08:19:19.514497 90901 sgd_solver.cpp:106] Iteration 96150, lr = 0.001
I0906 08:19:26.785935 90901 solver.cpp:228] Iteration 96160, loss = 0.276357
I0906 08:19:26.786129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276358 (* 1 = 0.276358 loss)
I0906 08:19:26.786162 90901 sgd_solver.cpp:106] Iteration 96160, lr = 0.001
I0906 08:19:35.201184 90901 solver.cpp:228] Iteration 96170, loss = 0.281777
I0906 08:19:35.201256 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281778 (* 1 = 0.281778 loss)
I0906 08:19:35.201275 90901 sgd_solver.cpp:106] Iteration 96170, lr = 0.001
I0906 08:19:42.738858 90901 solver.cpp:228] Iteration 96180, loss = 0.0964808
I0906 08:19:42.738916 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0964818 (* 1 = 0.0964818 loss)
I0906 08:19:42.738932 90901 sgd_solver.cpp:106] Iteration 96180, lr = 0.001
I0906 08:19:50.067816 90901 solver.cpp:228] Iteration 96190, loss = 0.0528855
I0906 08:19:50.067896 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0528865 (* 1 = 0.0528865 loss)
I0906 08:19:50.067916 90901 sgd_solver.cpp:106] Iteration 96190, lr = 0.001
I0906 08:19:57.899754 90901 solver.cpp:228] Iteration 96200, loss = 0.0537822
I0906 08:19:57.899960 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0537832 (* 1 = 0.0537832 loss)
I0906 08:19:57.899978 90901 sgd_solver.cpp:106] Iteration 96200, lr = 0.001
I0906 08:20:05.384361 90901 solver.cpp:228] Iteration 96210, loss = 0.154404
I0906 08:20:05.384430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154405 (* 1 = 0.154405 loss)
I0906 08:20:05.384449 90901 sgd_solver.cpp:106] Iteration 96210, lr = 0.001
I0906 08:20:13.344840 90901 solver.cpp:228] Iteration 96220, loss = 0.135203
I0906 08:20:13.344950 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135204 (* 1 = 0.135204 loss)
I0906 08:20:13.344980 90901 sgd_solver.cpp:106] Iteration 96220, lr = 0.001
I0906 08:20:20.985086 90901 solver.cpp:228] Iteration 96230, loss = 0.119045
I0906 08:20:20.985162 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119046 (* 1 = 0.119046 loss)
I0906 08:20:20.985180 90901 sgd_solver.cpp:106] Iteration 96230, lr = 0.001
I0906 08:20:28.676681 90901 solver.cpp:228] Iteration 96240, loss = 0.0243204
I0906 08:20:28.676848 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0243214 (* 1 = 0.0243214 loss)
I0906 08:20:28.676867 90901 sgd_solver.cpp:106] Iteration 96240, lr = 0.001
I0906 08:20:36.114612 90901 solver.cpp:228] Iteration 96250, loss = 0.102711
I0906 08:20:36.114703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102712 (* 1 = 0.102712 loss)
I0906 08:20:36.114733 90901 sgd_solver.cpp:106] Iteration 96250, lr = 0.001
I0906 08:20:43.850788 90901 solver.cpp:228] Iteration 96260, loss = 0.454182
I0906 08:20:43.850870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454183 (* 1 = 0.454183 loss)
I0906 08:20:43.850888 90901 sgd_solver.cpp:106] Iteration 96260, lr = 0.001
I0906 08:20:51.432651 90901 solver.cpp:228] Iteration 96270, loss = 0.0840791
I0906 08:20:51.432744 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0840801 (* 1 = 0.0840801 loss)
I0906 08:20:51.432760 90901 sgd_solver.cpp:106] Iteration 96270, lr = 0.001
I0906 08:20:59.326697 90901 solver.cpp:228] Iteration 96280, loss = 0.103843
I0906 08:20:59.326884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103844 (* 1 = 0.103844 loss)
I0906 08:20:59.326908 90901 sgd_solver.cpp:106] Iteration 96280, lr = 0.001
I0906 08:21:06.290976 90901 solver.cpp:228] Iteration 96290, loss = 0.213349
I0906 08:21:06.291041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21335 (* 1 = 0.21335 loss)
I0906 08:21:06.291059 90901 sgd_solver.cpp:106] Iteration 96290, lr = 0.001
I0906 08:21:14.168032 90901 solver.cpp:228] Iteration 96300, loss = 0.173917
I0906 08:21:14.168112 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173918 (* 1 = 0.173918 loss)
I0906 08:21:14.168136 90901 sgd_solver.cpp:106] Iteration 96300, lr = 0.001
I0906 08:21:21.720974 90901 solver.cpp:228] Iteration 96310, loss = 0.111089
I0906 08:21:21.721077 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11109 (* 1 = 0.11109 loss)
I0906 08:21:21.721096 90901 sgd_solver.cpp:106] Iteration 96310, lr = 0.001
I0906 08:21:29.413682 90901 solver.cpp:228] Iteration 96320, loss = 0.0393898
I0906 08:21:29.413885 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0393908 (* 1 = 0.0393908 loss)
I0906 08:21:29.413911 90901 sgd_solver.cpp:106] Iteration 96320, lr = 0.001
I0906 08:21:36.560370 90901 solver.cpp:228] Iteration 96330, loss = 0.053878
I0906 08:21:36.560442 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0538791 (* 1 = 0.0538791 loss)
I0906 08:21:36.560459 90901 sgd_solver.cpp:106] Iteration 96330, lr = 0.001
I0906 08:21:44.328922 90901 solver.cpp:228] Iteration 96340, loss = 0.291781
I0906 08:21:44.328996 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.291782 (* 1 = 0.291782 loss)
I0906 08:21:44.329016 90901 sgd_solver.cpp:106] Iteration 96340, lr = 0.001
I0906 08:21:52.436138 90901 solver.cpp:228] Iteration 96350, loss = 0.0318067
I0906 08:21:52.436213 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0318078 (* 1 = 0.0318078 loss)
I0906 08:21:52.436228 90901 sgd_solver.cpp:106] Iteration 96350, lr = 0.001
I0906 08:21:59.508910 90901 solver.cpp:228] Iteration 96360, loss = 0.106417
I0906 08:21:59.509130 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106418 (* 1 = 0.106418 loss)
I0906 08:21:59.509148 90901 sgd_solver.cpp:106] Iteration 96360, lr = 0.001
I0906 08:22:07.849546 90901 solver.cpp:228] Iteration 96370, loss = 0.12899
I0906 08:22:07.849632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128991 (* 1 = 0.128991 loss)
I0906 08:22:07.849649 90901 sgd_solver.cpp:106] Iteration 96370, lr = 0.001
I0906 08:22:14.615080 90901 solver.cpp:228] Iteration 96380, loss = 0.0689913
I0906 08:22:14.615154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0689923 (* 1 = 0.0689923 loss)
I0906 08:22:14.615171 90901 sgd_solver.cpp:106] Iteration 96380, lr = 0.001
I0906 08:22:22.221946 90901 solver.cpp:228] Iteration 96390, loss = 0.114569
I0906 08:22:22.222070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.11457 (* 1 = 0.11457 loss)
I0906 08:22:22.222090 90901 sgd_solver.cpp:106] Iteration 96390, lr = 0.001
I0906 08:22:29.098920 90901 solver.cpp:228] Iteration 96400, loss = 0.0622078
I0906 08:22:29.099009 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0622088 (* 1 = 0.0622088 loss)
I0906 08:22:29.099027 90901 sgd_solver.cpp:106] Iteration 96400, lr = 0.001
I0906 08:22:36.677151 90901 solver.cpp:228] Iteration 96410, loss = 0.127337
I0906 08:22:36.677323 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127338 (* 1 = 0.127338 loss)
I0906 08:22:36.677366 90901 sgd_solver.cpp:106] Iteration 96410, lr = 0.001
I0906 08:22:44.013685 90901 solver.cpp:228] Iteration 96420, loss = 0.247408
I0906 08:22:44.013748 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.247409 (* 1 = 0.247409 loss)
I0906 08:22:44.013766 90901 sgd_solver.cpp:106] Iteration 96420, lr = 0.001
I0906 08:22:51.024448 90901 solver.cpp:228] Iteration 96430, loss = 0.557981
I0906 08:22:51.024516 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.557982 (* 1 = 0.557982 loss)
I0906 08:22:51.024533 90901 sgd_solver.cpp:106] Iteration 96430, lr = 0.001
I0906 08:22:57.835455 90901 solver.cpp:228] Iteration 96440, loss = 0.0757194
I0906 08:22:57.835530 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0757204 (* 1 = 0.0757204 loss)
I0906 08:22:57.835548 90901 sgd_solver.cpp:106] Iteration 96440, lr = 0.001
I0906 08:23:05.414580 90901 solver.cpp:228] Iteration 96450, loss = 0.153306
I0906 08:23:05.414697 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153307 (* 1 = 0.153307 loss)
I0906 08:23:05.414716 90901 sgd_solver.cpp:106] Iteration 96450, lr = 0.001
I0906 08:23:12.275928 90901 solver.cpp:228] Iteration 96460, loss = 0.0446804
I0906 08:23:12.276124 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0446814 (* 1 = 0.0446814 loss)
I0906 08:23:12.276162 90901 sgd_solver.cpp:106] Iteration 96460, lr = 0.001
I0906 08:23:19.698879 90901 solver.cpp:228] Iteration 96470, loss = 0.264756
I0906 08:23:19.698947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.264757 (* 1 = 0.264757 loss)
I0906 08:23:19.698966 90901 sgd_solver.cpp:106] Iteration 96470, lr = 0.001
I0906 08:23:26.585768 90901 solver.cpp:228] Iteration 96480, loss = 0.107639
I0906 08:23:26.585841 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10764 (* 1 = 0.10764 loss)
I0906 08:23:26.585857 90901 sgd_solver.cpp:106] Iteration 96480, lr = 0.001
I0906 08:23:32.295274 90901 solver.cpp:228] Iteration 96490, loss = 0.172537
I0906 08:23:32.295339 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172538 (* 1 = 0.172538 loss)
I0906 08:23:32.295357 90901 sgd_solver.cpp:106] Iteration 96490, lr = 0.001
I0906 08:23:38.540618 90901 solver.cpp:228] Iteration 96500, loss = 0.13001
I0906 08:23:38.540698 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130011 (* 1 = 0.130011 loss)
I0906 08:23:38.540714 90901 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I0906 08:23:44.297732 90901 solver.cpp:228] Iteration 96510, loss = 0.177852
I0906 08:23:44.297929 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177853 (* 1 = 0.177853 loss)
I0906 08:23:44.297946 90901 sgd_solver.cpp:106] Iteration 96510, lr = 0.001
I0906 08:23:50.337929 90901 solver.cpp:228] Iteration 96520, loss = 0.276465
I0906 08:23:50.338016 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276466 (* 1 = 0.276466 loss)
I0906 08:23:50.338035 90901 sgd_solver.cpp:106] Iteration 96520, lr = 0.001
I0906 08:23:55.541820 90901 solver.cpp:228] Iteration 96530, loss = 0.0916236
I0906 08:23:55.541906 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0916246 (* 1 = 0.0916246 loss)
I0906 08:23:55.541923 90901 sgd_solver.cpp:106] Iteration 96530, lr = 0.001
I0906 08:24:00.743616 90901 solver.cpp:228] Iteration 96540, loss = 0.0700568
I0906 08:24:00.743683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0700578 (* 1 = 0.0700578 loss)
I0906 08:24:00.743700 90901 sgd_solver.cpp:106] Iteration 96540, lr = 0.001
I0906 08:24:05.947415 90901 solver.cpp:228] Iteration 96550, loss = 0.400773
I0906 08:24:05.947485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.400774 (* 1 = 0.400774 loss)
I0906 08:24:05.947502 90901 sgd_solver.cpp:106] Iteration 96550, lr = 0.001
I0906 08:24:11.448791 90901 solver.cpp:228] Iteration 96560, loss = 0.220634
I0906 08:24:11.448915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220635 (* 1 = 0.220635 loss)
I0906 08:24:11.448936 90901 sgd_solver.cpp:106] Iteration 96560, lr = 0.001
I0906 08:24:16.636464 90901 solver.cpp:228] Iteration 96570, loss = 0.147399
I0906 08:24:16.636651 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1474 (* 1 = 0.1474 loss)
I0906 08:24:16.636669 90901 sgd_solver.cpp:106] Iteration 96570, lr = 0.001
I0906 08:24:21.839828 90901 solver.cpp:228] Iteration 96580, loss = 0.482057
I0906 08:24:21.839897 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.482058 (* 1 = 0.482058 loss)
I0906 08:24:21.839915 90901 sgd_solver.cpp:106] Iteration 96580, lr = 0.001
I0906 08:24:27.032042 90901 solver.cpp:228] Iteration 96590, loss = 0.0287905
I0906 08:24:27.032109 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0287915 (* 1 = 0.0287915 loss)
I0906 08:24:27.032125 90901 sgd_solver.cpp:106] Iteration 96590, lr = 0.001
I0906 08:24:32.567293 90901 solver.cpp:228] Iteration 96600, loss = 0.272595
I0906 08:24:32.567363 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272596 (* 1 = 0.272596 loss)
I0906 08:24:32.567379 90901 sgd_solver.cpp:106] Iteration 96600, lr = 0.001
I0906 08:24:37.744774 90901 solver.cpp:228] Iteration 96610, loss = 0.20973
I0906 08:24:37.744820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209731 (* 1 = 0.209731 loss)
I0906 08:24:37.744835 90901 sgd_solver.cpp:106] Iteration 96610, lr = 0.001
I0906 08:24:42.866217 90901 solver.cpp:228] Iteration 96620, loss = 0.0673272
I0906 08:24:42.866277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0673282 (* 1 = 0.0673282 loss)
I0906 08:24:42.866295 90901 sgd_solver.cpp:106] Iteration 96620, lr = 0.001
I0906 08:24:48.110702 90901 solver.cpp:228] Iteration 96630, loss = 0.142336
I0906 08:24:48.110954 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142337 (* 1 = 0.142337 loss)
I0906 08:24:48.110978 90901 sgd_solver.cpp:106] Iteration 96630, lr = 0.001
I0906 08:24:53.322449 90901 solver.cpp:228] Iteration 96640, loss = 0.283346
I0906 08:24:53.322525 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283347 (* 1 = 0.283347 loss)
I0906 08:24:53.322545 90901 sgd_solver.cpp:106] Iteration 96640, lr = 0.001
I0906 08:24:59.596151 90901 solver.cpp:228] Iteration 96650, loss = 0.0465369
I0906 08:24:59.596215 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.046538 (* 1 = 0.046538 loss)
I0906 08:24:59.596230 90901 sgd_solver.cpp:106] Iteration 96650, lr = 0.001
I0906 08:25:04.795253 90901 solver.cpp:228] Iteration 96660, loss = 0.0724756
I0906 08:25:04.795321 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0724767 (* 1 = 0.0724767 loss)
I0906 08:25:04.795339 90901 sgd_solver.cpp:106] Iteration 96660, lr = 0.001
I0906 08:25:09.997452 90901 solver.cpp:228] Iteration 96670, loss = 0.0226173
I0906 08:25:09.997550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0226184 (* 1 = 0.0226184 loss)
I0906 08:25:09.997568 90901 sgd_solver.cpp:106] Iteration 96670, lr = 0.001
I0906 08:25:15.729568 90901 solver.cpp:228] Iteration 96680, loss = 0.141432
I0906 08:25:15.729643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141433 (* 1 = 0.141433 loss)
I0906 08:25:15.729660 90901 sgd_solver.cpp:106] Iteration 96680, lr = 0.001
I0906 08:25:20.959007 90901 solver.cpp:228] Iteration 96690, loss = 0.164943
I0906 08:25:20.959261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164945 (* 1 = 0.164945 loss)
I0906 08:25:20.959291 90901 sgd_solver.cpp:106] Iteration 96690, lr = 0.001
I0906 08:25:26.922559 90901 solver.cpp:228] Iteration 96700, loss = 0.0795273
I0906 08:25:26.922632 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0795284 (* 1 = 0.0795284 loss)
I0906 08:25:26.922662 90901 sgd_solver.cpp:106] Iteration 96700, lr = 0.001
I0906 08:25:33.993412 90901 solver.cpp:228] Iteration 96710, loss = 0.164041
I0906 08:25:33.993468 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.164042 (* 1 = 0.164042 loss)
I0906 08:25:33.993486 90901 sgd_solver.cpp:106] Iteration 96710, lr = 0.001
I0906 08:25:40.801908 90901 solver.cpp:228] Iteration 96720, loss = 0.0971289
I0906 08:25:40.801983 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.09713 (* 1 = 0.09713 loss)
I0906 08:25:40.802001 90901 sgd_solver.cpp:106] Iteration 96720, lr = 0.001
I0906 08:25:48.552877 90901 solver.cpp:228] Iteration 96730, loss = 0.373505
I0906 08:25:48.552947 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.373507 (* 1 = 0.373507 loss)
I0906 08:25:48.552968 90901 sgd_solver.cpp:106] Iteration 96730, lr = 0.001
I0906 08:25:56.038877 90901 solver.cpp:228] Iteration 96740, loss = 0.163639
I0906 08:25:56.039088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16364 (* 1 = 0.16364 loss)
I0906 08:25:56.039108 90901 sgd_solver.cpp:106] Iteration 96740, lr = 0.001
I0906 08:26:03.896585 90901 solver.cpp:228] Iteration 96750, loss = 0.177208
I0906 08:26:03.896637 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177209 (* 1 = 0.177209 loss)
I0906 08:26:03.896657 90901 sgd_solver.cpp:106] Iteration 96750, lr = 0.001
I0906 08:26:11.096810 90901 solver.cpp:228] Iteration 96760, loss = 0.0683123
I0906 08:26:11.096884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0683133 (* 1 = 0.0683133 loss)
I0906 08:26:11.096901 90901 sgd_solver.cpp:106] Iteration 96760, lr = 0.001
I0906 08:26:19.249313 90901 solver.cpp:228] Iteration 96770, loss = 0.0137344
I0906 08:26:19.249410 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0137355 (* 1 = 0.0137355 loss)
I0906 08:26:19.249431 90901 sgd_solver.cpp:106] Iteration 96770, lr = 0.001
I0906 08:26:27.146822 90901 solver.cpp:228] Iteration 96780, loss = 0.135636
I0906 08:26:27.147004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.135637 (* 1 = 0.135637 loss)
I0906 08:26:27.147023 90901 sgd_solver.cpp:106] Iteration 96780, lr = 0.001
I0906 08:26:34.794682 90901 solver.cpp:228] Iteration 96790, loss = 0.0446401
I0906 08:26:34.794764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0446412 (* 1 = 0.0446412 loss)
I0906 08:26:34.794782 90901 sgd_solver.cpp:106] Iteration 96790, lr = 0.001
I0906 08:26:41.880993 90901 solver.cpp:337] Iteration 96800, Testing net (#0)
I0906 08:27:36.895249 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.952187
I0906 08:27:36.895508 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.131438 (* 1 = 0.131438 loss)
I0906 08:27:37.348964 90901 solver.cpp:228] Iteration 96800, loss = 0.209326
I0906 08:27:37.349041 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209327 (* 1 = 0.209327 loss)
I0906 08:27:37.349071 90901 sgd_solver.cpp:106] Iteration 96800, lr = 0.001
I0906 08:27:44.674523 90901 solver.cpp:228] Iteration 96810, loss = 0.0980675
I0906 08:27:44.674595 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0980686 (* 1 = 0.0980686 loss)
I0906 08:27:44.674612 90901 sgd_solver.cpp:106] Iteration 96810, lr = 0.001
I0906 08:27:52.389283 90901 solver.cpp:228] Iteration 96820, loss = 0.0624284
I0906 08:27:52.389348 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0624295 (* 1 = 0.0624295 loss)
I0906 08:27:52.389364 90901 sgd_solver.cpp:106] Iteration 96820, lr = 0.001
I0906 08:28:00.047103 90901 solver.cpp:228] Iteration 96830, loss = 0.0853775
I0906 08:28:00.047166 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853786 (* 1 = 0.0853786 loss)
I0906 08:28:00.047185 90901 sgd_solver.cpp:106] Iteration 96830, lr = 0.001
I0906 08:28:07.681571 90901 solver.cpp:228] Iteration 96840, loss = 0.0545741
I0906 08:28:07.681726 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545751 (* 1 = 0.0545751 loss)
I0906 08:28:07.681757 90901 sgd_solver.cpp:106] Iteration 96840, lr = 0.001
I0906 08:28:16.018620 90901 solver.cpp:228] Iteration 96850, loss = 0.416483
I0906 08:28:16.018712 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.416484 (* 1 = 0.416484 loss)
I0906 08:28:16.018728 90901 sgd_solver.cpp:106] Iteration 96850, lr = 0.001
I0906 08:28:23.674512 90901 solver.cpp:228] Iteration 96860, loss = 0.0243567
I0906 08:28:23.674582 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0243578 (* 1 = 0.0243578 loss)
I0906 08:28:23.674598 90901 sgd_solver.cpp:106] Iteration 96860, lr = 0.001
I0906 08:28:31.753556 90901 solver.cpp:228] Iteration 96870, loss = 0.0761733
I0906 08:28:31.753638 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0761744 (* 1 = 0.0761744 loss)
I0906 08:28:31.753655 90901 sgd_solver.cpp:106] Iteration 96870, lr = 0.001
I0906 08:28:39.807618 90901 solver.cpp:228] Iteration 96880, loss = 0.281843
I0906 08:28:39.807778 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281844 (* 1 = 0.281844 loss)
I0906 08:28:39.807801 90901 sgd_solver.cpp:106] Iteration 96880, lr = 0.001
I0906 08:28:46.970769 90901 solver.cpp:228] Iteration 96890, loss = 0.0899063
I0906 08:28:46.970861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0899075 (* 1 = 0.0899075 loss)
I0906 08:28:46.970878 90901 sgd_solver.cpp:106] Iteration 96890, lr = 0.001
I0906 08:28:54.848181 90901 solver.cpp:228] Iteration 96900, loss = 0.270162
I0906 08:28:54.848253 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.270164 (* 1 = 0.270164 loss)
I0906 08:28:54.848273 90901 sgd_solver.cpp:106] Iteration 96900, lr = 0.001
I0906 08:29:02.456826 90901 solver.cpp:228] Iteration 96910, loss = 0.0613787
I0906 08:29:02.456892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0613798 (* 1 = 0.0613798 loss)
I0906 08:29:02.456913 90901 sgd_solver.cpp:106] Iteration 96910, lr = 0.001
I0906 08:29:10.357368 90901 solver.cpp:228] Iteration 96920, loss = 0.0942216
I0906 08:29:10.357745 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0942227 (* 1 = 0.0942227 loss)
I0906 08:29:10.357765 90901 sgd_solver.cpp:106] Iteration 96920, lr = 0.001
I0906 08:29:18.480190 90901 solver.cpp:228] Iteration 96930, loss = 0.203735
I0906 08:29:18.480252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203736 (* 1 = 0.203736 loss)
I0906 08:29:18.480273 90901 sgd_solver.cpp:106] Iteration 96930, lr = 0.001
I0906 08:29:25.540165 90901 solver.cpp:228] Iteration 96940, loss = 0.234972
I0906 08:29:25.540230 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234973 (* 1 = 0.234973 loss)
I0906 08:29:25.540246 90901 sgd_solver.cpp:106] Iteration 96940, lr = 0.001
I0906 08:29:33.130597 90901 solver.cpp:228] Iteration 96950, loss = 0.0309579
I0906 08:29:33.130702 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.030959 (* 1 = 0.030959 loss)
I0906 08:29:33.130720 90901 sgd_solver.cpp:106] Iteration 96950, lr = 0.001
I0906 08:29:41.291427 90901 solver.cpp:228] Iteration 96960, loss = 0.100434
I0906 08:29:41.291631 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100435 (* 1 = 0.100435 loss)
I0906 08:29:41.291651 90901 sgd_solver.cpp:106] Iteration 96960, lr = 0.001
I0906 08:29:48.631465 90901 solver.cpp:228] Iteration 96970, loss = 0.0558143
I0906 08:29:48.631537 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0558154 (* 1 = 0.0558154 loss)
I0906 08:29:48.631556 90901 sgd_solver.cpp:106] Iteration 96970, lr = 0.001
I0906 08:29:56.729178 90901 solver.cpp:228] Iteration 96980, loss = 0.250613
I0906 08:29:56.729264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250614 (* 1 = 0.250614 loss)
I0906 08:29:56.729287 90901 sgd_solver.cpp:106] Iteration 96980, lr = 0.001
I0906 08:30:04.760447 90901 solver.cpp:228] Iteration 96990, loss = 0.312309
I0906 08:30:04.760509 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.31231 (* 1 = 0.31231 loss)
I0906 08:30:04.760525 90901 sgd_solver.cpp:106] Iteration 96990, lr = 0.001
I0906 08:30:11.951894 90901 solver.cpp:228] Iteration 97000, loss = 0.282183
I0906 08:30:11.952085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.282184 (* 1 = 0.282184 loss)
I0906 08:30:11.952124 90901 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0906 08:30:20.380523 90901 solver.cpp:228] Iteration 97010, loss = 0.0157424
I0906 08:30:20.380611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0157434 (* 1 = 0.0157434 loss)
I0906 08:30:20.380630 90901 sgd_solver.cpp:106] Iteration 97010, lr = 0.001
I0906 08:30:27.390496 90901 solver.cpp:228] Iteration 97020, loss = 0.214691
I0906 08:30:27.390607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.214692 (* 1 = 0.214692 loss)
I0906 08:30:27.390625 90901 sgd_solver.cpp:106] Iteration 97020, lr = 0.001
I0906 08:30:35.238288 90901 solver.cpp:228] Iteration 97030, loss = 0.059376
I0906 08:30:35.238369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0593771 (* 1 = 0.0593771 loss)
I0906 08:30:35.238389 90901 sgd_solver.cpp:106] Iteration 97030, lr = 0.001
I0906 08:30:42.328990 90901 solver.cpp:228] Iteration 97040, loss = 0.137912
I0906 08:30:42.329180 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137913 (* 1 = 0.137913 loss)
I0906 08:30:42.329224 90901 sgd_solver.cpp:106] Iteration 97040, lr = 0.001
I0906 08:30:50.175438 90901 solver.cpp:228] Iteration 97050, loss = 0.0981365
I0906 08:30:50.175523 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0981376 (* 1 = 0.0981376 loss)
I0906 08:30:50.175541 90901 sgd_solver.cpp:106] Iteration 97050, lr = 0.001
I0906 08:30:56.535425 90901 solver.cpp:228] Iteration 97060, loss = 0.117141
I0906 08:30:56.535506 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117142 (* 1 = 0.117142 loss)
I0906 08:30:56.535526 90901 sgd_solver.cpp:106] Iteration 97060, lr = 0.001
I0906 08:31:01.794425 90901 solver.cpp:228] Iteration 97070, loss = 0.065968
I0906 08:31:01.794531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0659691 (* 1 = 0.0659691 loss)
I0906 08:31:01.794553 90901 sgd_solver.cpp:106] Iteration 97070, lr = 0.001
I0906 08:31:07.558601 90901 solver.cpp:228] Iteration 97080, loss = 0.203456
I0906 08:31:07.558703 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.203457 (* 1 = 0.203457 loss)
I0906 08:31:07.558722 90901 sgd_solver.cpp:106] Iteration 97080, lr = 0.001
I0906 08:31:12.989701 90901 solver.cpp:228] Iteration 97090, loss = 0.0883483
I0906 08:31:12.989920 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0883493 (* 1 = 0.0883493 loss)
I0906 08:31:12.989940 90901 sgd_solver.cpp:106] Iteration 97090, lr = 0.001
I0906 08:31:18.715097 90901 solver.cpp:228] Iteration 97100, loss = 0.122112
I0906 08:31:18.715178 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122113 (* 1 = 0.122113 loss)
I0906 08:31:18.715194 90901 sgd_solver.cpp:106] Iteration 97100, lr = 0.001
I0906 08:31:24.432307 90901 solver.cpp:228] Iteration 97110, loss = 0.166295
I0906 08:31:24.432377 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.166296 (* 1 = 0.166296 loss)
I0906 08:31:24.432394 90901 sgd_solver.cpp:106] Iteration 97110, lr = 0.001
I0906 08:31:30.449435 90901 solver.cpp:228] Iteration 97120, loss = 0.0614953
I0906 08:31:30.449508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0614964 (* 1 = 0.0614964 loss)
I0906 08:31:30.449525 90901 sgd_solver.cpp:106] Iteration 97120, lr = 0.001
I0906 08:31:35.923758 90901 solver.cpp:228] Iteration 97130, loss = 0.0472847
I0906 08:31:35.923818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0472858 (* 1 = 0.0472858 loss)
I0906 08:31:35.923835 90901 sgd_solver.cpp:106] Iteration 97130, lr = 0.001
I0906 08:31:41.139257 90901 solver.cpp:228] Iteration 97140, loss = 0.0777362
I0906 08:31:41.139336 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0777373 (* 1 = 0.0777373 loss)
I0906 08:31:41.139358 90901 sgd_solver.cpp:106] Iteration 97140, lr = 0.001
I0906 08:31:47.451259 90901 solver.cpp:228] Iteration 97150, loss = 0.174969
I0906 08:31:47.451635 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17497 (* 1 = 0.17497 loss)
I0906 08:31:47.451665 90901 sgd_solver.cpp:106] Iteration 97150, lr = 0.001
I0906 08:31:52.938460 90901 solver.cpp:228] Iteration 97160, loss = 0.138686
I0906 08:31:52.938541 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138687 (* 1 = 0.138687 loss)
I0906 08:31:52.938561 90901 sgd_solver.cpp:106] Iteration 97160, lr = 0.001
I0906 08:31:58.749792 90901 solver.cpp:228] Iteration 97170, loss = 0.108381
I0906 08:31:58.749861 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108382 (* 1 = 0.108382 loss)
I0906 08:31:58.749877 90901 sgd_solver.cpp:106] Iteration 97170, lr = 0.001
I0906 08:32:04.189079 90901 solver.cpp:228] Iteration 97180, loss = 0.210059
I0906 08:32:04.189158 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.21006 (* 1 = 0.21006 loss)
I0906 08:32:04.189174 90901 sgd_solver.cpp:106] Iteration 97180, lr = 0.001
I0906 08:32:09.595669 90901 solver.cpp:228] Iteration 97190, loss = 0.324571
I0906 08:32:09.595746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324572 (* 1 = 0.324572 loss)
I0906 08:32:09.595762 90901 sgd_solver.cpp:106] Iteration 97190, lr = 0.001
I0906 08:32:15.689471 90901 solver.cpp:228] Iteration 97200, loss = 0.0634719
I0906 08:32:15.689546 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.063473 (* 1 = 0.063473 loss)
I0906 08:32:15.689564 90901 sgd_solver.cpp:106] Iteration 97200, lr = 0.001
I0906 08:32:21.155212 90901 solver.cpp:228] Iteration 97210, loss = 0.00755732
I0906 08:32:21.155424 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00755839 (* 1 = 0.00755839 loss)
I0906 08:32:21.155447 90901 sgd_solver.cpp:106] Iteration 97210, lr = 0.001
I0906 08:32:26.358417 90901 solver.cpp:228] Iteration 97220, loss = 0.0764161
I0906 08:32:26.358479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0764171 (* 1 = 0.0764171 loss)
I0906 08:32:26.358499 90901 sgd_solver.cpp:106] Iteration 97220, lr = 0.001
I0906 08:32:31.593030 90901 solver.cpp:228] Iteration 97230, loss = 0.0837733
I0906 08:32:31.593097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0837743 (* 1 = 0.0837743 loss)
I0906 08:32:31.593117 90901 sgd_solver.cpp:106] Iteration 97230, lr = 0.001
I0906 08:32:37.122436 90901 solver.cpp:228] Iteration 97240, loss = 0.0993932
I0906 08:32:37.122499 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0993943 (* 1 = 0.0993943 loss)
I0906 08:32:37.122516 90901 sgd_solver.cpp:106] Iteration 97240, lr = 0.001
I0906 08:32:42.341575 90901 solver.cpp:228] Iteration 97250, loss = 0.102112
I0906 08:32:42.341641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102113 (* 1 = 0.102113 loss)
I0906 08:32:42.341658 90901 sgd_solver.cpp:106] Iteration 97250, lr = 0.001
I0906 08:32:47.538528 90901 solver.cpp:228] Iteration 97260, loss = 0.022981
I0906 08:32:47.538611 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0229821 (* 1 = 0.0229821 loss)
I0906 08:32:47.538635 90901 sgd_solver.cpp:106] Iteration 97260, lr = 0.001
I0906 08:32:52.755890 90901 solver.cpp:228] Iteration 97270, loss = 0.543161
I0906 08:32:52.756103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.543162 (* 1 = 0.543162 loss)
I0906 08:32:52.756119 90901 sgd_solver.cpp:106] Iteration 97270, lr = 0.001
I0906 08:32:58.286449 90901 solver.cpp:228] Iteration 97280, loss = 0.145705
I0906 08:32:58.286520 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145706 (* 1 = 0.145706 loss)
I0906 08:32:58.286537 90901 sgd_solver.cpp:106] Iteration 97280, lr = 0.001
I0906 08:33:03.473549 90901 solver.cpp:228] Iteration 97290, loss = 0.27262
I0906 08:33:03.473604 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.272621 (* 1 = 0.272621 loss)
I0906 08:33:03.473618 90901 sgd_solver.cpp:106] Iteration 97290, lr = 0.001
I0906 08:33:08.712154 90901 solver.cpp:228] Iteration 97300, loss = 0.410226
I0906 08:33:08.712218 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410227 (* 1 = 0.410227 loss)
I0906 08:33:08.712234 90901 sgd_solver.cpp:106] Iteration 97300, lr = 0.001
I0906 08:33:14.242410 90901 solver.cpp:228] Iteration 97310, loss = 0.0933376
I0906 08:33:14.242493 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0933387 (* 1 = 0.0933387 loss)
I0906 08:33:14.242511 90901 sgd_solver.cpp:106] Iteration 97310, lr = 0.001
I0906 08:33:19.438786 90901 solver.cpp:228] Iteration 97320, loss = 0.0435057
I0906 08:33:19.438856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0435068 (* 1 = 0.0435068 loss)
I0906 08:33:19.438874 90901 sgd_solver.cpp:106] Iteration 97320, lr = 0.001
I0906 08:33:26.231281 90901 solver.cpp:228] Iteration 97330, loss = 0.0782434
I0906 08:33:26.233508 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0782445 (* 1 = 0.0782445 loss)
I0906 08:33:26.233527 90901 sgd_solver.cpp:106] Iteration 97330, lr = 0.001
I0906 08:33:34.307919 90901 solver.cpp:228] Iteration 97340, loss = 0.228448
I0906 08:33:34.307984 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228449 (* 1 = 0.228449 loss)
I0906 08:33:34.308002 90901 sgd_solver.cpp:106] Iteration 97340, lr = 0.001
I0906 08:33:42.769532 90901 solver.cpp:228] Iteration 97350, loss = 0.0647489
I0906 08:33:42.769605 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.06475 (* 1 = 0.06475 loss)
I0906 08:33:42.769624 90901 sgd_solver.cpp:106] Iteration 97350, lr = 0.001
I0906 08:33:50.439610 90901 solver.cpp:228] Iteration 97360, loss = 0.454619
I0906 08:33:50.439684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454621 (* 1 = 0.454621 loss)
I0906 08:33:50.439702 90901 sgd_solver.cpp:106] Iteration 97360, lr = 0.001
I0906 08:33:58.518291 90901 solver.cpp:228] Iteration 97370, loss = 0.313355
I0906 08:33:58.518457 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313356 (* 1 = 0.313356 loss)
I0906 08:33:58.518488 90901 sgd_solver.cpp:106] Iteration 97370, lr = 0.001
I0906 08:34:07.039892 90901 solver.cpp:228] Iteration 97380, loss = 0.324567
I0906 08:34:07.039971 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.324568 (* 1 = 0.324568 loss)
I0906 08:34:07.039991 90901 sgd_solver.cpp:106] Iteration 97380, lr = 0.001
I0906 08:34:15.690459 90901 solver.cpp:228] Iteration 97390, loss = 0.263463
I0906 08:34:15.690517 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.263464 (* 1 = 0.263464 loss)
I0906 08:34:15.690537 90901 sgd_solver.cpp:106] Iteration 97390, lr = 0.001
I0906 08:34:23.979038 90901 solver.cpp:228] Iteration 97400, loss = 0.57156
I0906 08:34:23.979110 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.571561 (* 1 = 0.571561 loss)
I0906 08:34:23.979128 90901 sgd_solver.cpp:106] Iteration 97400, lr = 0.001
I0906 08:34:32.459094 90901 solver.cpp:228] Iteration 97410, loss = 0.266566
I0906 08:34:32.459298 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.266567 (* 1 = 0.266567 loss)
I0906 08:34:32.459317 90901 sgd_solver.cpp:106] Iteration 97410, lr = 0.001
I0906 08:34:41.208027 90901 solver.cpp:228] Iteration 97420, loss = 0.06775
I0906 08:34:41.208149 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0677511 (* 1 = 0.0677511 loss)
I0906 08:34:41.208178 90901 sgd_solver.cpp:106] Iteration 97420, lr = 0.001
I0906 08:34:49.077461 90901 solver.cpp:228] Iteration 97430, loss = 0.255164
I0906 08:34:49.077561 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255165 (* 1 = 0.255165 loss)
I0906 08:34:49.077580 90901 sgd_solver.cpp:106] Iteration 97430, lr = 0.001
I0906 08:34:57.444336 90901 solver.cpp:228] Iteration 97440, loss = 0.134871
I0906 08:34:57.444418 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134872 (* 1 = 0.134872 loss)
I0906 08:34:57.444435 90901 sgd_solver.cpp:106] Iteration 97440, lr = 0.001
I0906 08:35:05.844719 90901 solver.cpp:228] Iteration 97450, loss = 0.0852376
I0906 08:35:05.844908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0852387 (* 1 = 0.0852387 loss)
I0906 08:35:05.844929 90901 sgd_solver.cpp:106] Iteration 97450, lr = 0.001
I0906 08:35:13.973953 90901 solver.cpp:228] Iteration 97460, loss = 0.208015
I0906 08:35:13.974012 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.208016 (* 1 = 0.208016 loss)
I0906 08:35:13.974028 90901 sgd_solver.cpp:106] Iteration 97460, lr = 0.001
I0906 08:35:22.534734 90901 solver.cpp:228] Iteration 97470, loss = 0.0994626
I0906 08:35:22.534828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0994637 (* 1 = 0.0994637 loss)
I0906 08:35:22.534845 90901 sgd_solver.cpp:106] Iteration 97470, lr = 0.001
I0906 08:35:30.858198 90901 solver.cpp:228] Iteration 97480, loss = 0.14481
I0906 08:35:30.858263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144811 (* 1 = 0.144811 loss)
I0906 08:35:30.858279 90901 sgd_solver.cpp:106] Iteration 97480, lr = 0.001
I0906 08:35:39.307235 90901 solver.cpp:228] Iteration 97490, loss = 0.148834
I0906 08:35:39.307420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148836 (* 1 = 0.148836 loss)
I0906 08:35:39.307451 90901 sgd_solver.cpp:106] Iteration 97490, lr = 0.001
I0906 08:35:47.348000 90901 solver.cpp:228] Iteration 97500, loss = 0.0885685
I0906 08:35:47.348086 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0885696 (* 1 = 0.0885696 loss)
I0906 08:35:47.348104 90901 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0906 08:35:55.692814 90901 solver.cpp:228] Iteration 97510, loss = 0.350012
I0906 08:35:55.692900 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.350013 (* 1 = 0.350013 loss)
I0906 08:35:55.692921 90901 sgd_solver.cpp:106] Iteration 97510, lr = 0.001
I0906 08:36:03.837416 90901 solver.cpp:228] Iteration 97520, loss = 0.347496
I0906 08:36:03.837496 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347498 (* 1 = 0.347498 loss)
I0906 08:36:03.837513 90901 sgd_solver.cpp:106] Iteration 97520, lr = 0.001
I0906 08:36:12.044008 90901 solver.cpp:228] Iteration 97530, loss = 0.186987
I0906 08:36:12.044236 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186988 (* 1 = 0.186988 loss)
I0906 08:36:12.044270 90901 sgd_solver.cpp:106] Iteration 97530, lr = 0.001
I0906 08:36:20.558161 90901 solver.cpp:228] Iteration 97540, loss = 0.0834796
I0906 08:36:20.558238 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0834807 (* 1 = 0.0834807 loss)
I0906 08:36:20.558254 90901 sgd_solver.cpp:106] Iteration 97540, lr = 0.001
I0906 08:36:28.499619 90901 solver.cpp:228] Iteration 97550, loss = 0.0772227
I0906 08:36:28.499686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0772238 (* 1 = 0.0772238 loss)
I0906 08:36:28.499703 90901 sgd_solver.cpp:106] Iteration 97550, lr = 0.001
I0906 08:36:37.078271 90901 solver.cpp:228] Iteration 97560, loss = 0.0441079
I0906 08:36:37.078341 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.044109 (* 1 = 0.044109 loss)
I0906 08:36:37.078358 90901 sgd_solver.cpp:106] Iteration 97560, lr = 0.001
I0906 08:36:45.415599 90901 solver.cpp:228] Iteration 97570, loss = 0.0410994
I0906 08:36:45.415782 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0411004 (* 1 = 0.0411004 loss)
I0906 08:36:45.415812 90901 sgd_solver.cpp:106] Iteration 97570, lr = 0.001
I0906 08:36:53.777726 90901 solver.cpp:228] Iteration 97580, loss = 0.161421
I0906 08:36:53.777788 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161422 (* 1 = 0.161422 loss)
I0906 08:36:53.777803 90901 sgd_solver.cpp:106] Iteration 97580, lr = 0.001
I0906 08:37:02.231029 90901 solver.cpp:228] Iteration 97590, loss = 0.0982209
I0906 08:37:02.231089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.098222 (* 1 = 0.098222 loss)
I0906 08:37:02.231106 90901 sgd_solver.cpp:106] Iteration 97590, lr = 0.001
I0906 08:37:10.123368 90901 solver.cpp:337] Iteration 97600, Testing net (#0)
I0906 08:38:08.159009 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9475
I0906 08:38:08.159261 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.14298 (* 1 = 0.14298 loss)
I0906 08:38:08.619362 90901 solver.cpp:228] Iteration 97600, loss = 0.0332465
I0906 08:38:08.619428 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0332475 (* 1 = 0.0332475 loss)
I0906 08:38:08.619451 90901 sgd_solver.cpp:106] Iteration 97600, lr = 0.001
I0906 08:38:16.574388 90901 solver.cpp:228] Iteration 97610, loss = 0.108253
I0906 08:38:16.574447 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108254 (* 1 = 0.108254 loss)
I0906 08:38:16.574465 90901 sgd_solver.cpp:106] Iteration 97610, lr = 0.001
I0906 08:38:24.599833 90901 solver.cpp:228] Iteration 97620, loss = 0.290046
I0906 08:38:24.599915 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.290047 (* 1 = 0.290047 loss)
I0906 08:38:24.599936 90901 sgd_solver.cpp:106] Iteration 97620, lr = 0.001
I0906 08:38:32.737396 90901 solver.cpp:228] Iteration 97630, loss = 0.0564455
I0906 08:38:32.737444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0564465 (* 1 = 0.0564465 loss)
I0906 08:38:32.737460 90901 sgd_solver.cpp:106] Iteration 97630, lr = 0.001
I0906 08:38:41.087071 90901 solver.cpp:228] Iteration 97640, loss = 0.100682
I0906 08:38:41.087328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.100683 (* 1 = 0.100683 loss)
I0906 08:38:41.087348 90901 sgd_solver.cpp:106] Iteration 97640, lr = 0.001
I0906 08:38:50.053670 90901 solver.cpp:228] Iteration 97650, loss = 0.551498
I0906 08:38:50.053730 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.551499 (* 1 = 0.551499 loss)
I0906 08:38:50.053746 90901 sgd_solver.cpp:106] Iteration 97650, lr = 0.001
I0906 08:38:56.623844 90901 solver.cpp:228] Iteration 97660, loss = 0.142256
I0906 08:38:56.623903 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142257 (* 1 = 0.142257 loss)
I0906 08:38:56.623919 90901 sgd_solver.cpp:106] Iteration 97660, lr = 0.001
I0906 08:39:01.827320 90901 solver.cpp:228] Iteration 97670, loss = 0.083395
I0906 08:39:01.827388 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.083396 (* 1 = 0.083396 loss)
I0906 08:39:01.827404 90901 sgd_solver.cpp:106] Iteration 97670, lr = 0.001
I0906 08:39:07.066428 90901 solver.cpp:228] Iteration 97680, loss = 0.0126075
I0906 08:39:07.066495 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0126085 (* 1 = 0.0126085 loss)
I0906 08:39:07.066512 90901 sgd_solver.cpp:106] Iteration 97680, lr = 0.001
I0906 08:39:13.763886 90901 solver.cpp:228] Iteration 97690, loss = 0.299431
I0906 08:39:13.764169 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.299432 (* 1 = 0.299432 loss)
I0906 08:39:13.764190 90901 sgd_solver.cpp:106] Iteration 97690, lr = 0.001
I0906 08:39:21.612476 90901 solver.cpp:228] Iteration 97700, loss = 0.087544
I0906 08:39:21.612562 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0875451 (* 1 = 0.0875451 loss)
I0906 08:39:21.612582 90901 sgd_solver.cpp:106] Iteration 97700, lr = 0.001
I0906 08:39:29.695289 90901 solver.cpp:228] Iteration 97710, loss = 0.0330536
I0906 08:39:29.695354 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0330547 (* 1 = 0.0330547 loss)
I0906 08:39:29.695374 90901 sgd_solver.cpp:106] Iteration 97710, lr = 0.001
I0906 08:39:37.729230 90901 solver.cpp:228] Iteration 97720, loss = 0.163558
I0906 08:39:37.729305 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16356 (* 1 = 0.16356 loss)
I0906 08:39:37.729321 90901 sgd_solver.cpp:106] Iteration 97720, lr = 0.001
I0906 08:39:46.308348 90901 solver.cpp:228] Iteration 97730, loss = 0.0485418
I0906 08:39:46.308501 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0485429 (* 1 = 0.0485429 loss)
I0906 08:39:46.308529 90901 sgd_solver.cpp:106] Iteration 97730, lr = 0.001
I0906 08:39:54.756032 90901 solver.cpp:228] Iteration 97740, loss = 0.268664
I0906 08:39:54.756103 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.268665 (* 1 = 0.268665 loss)
I0906 08:39:54.756121 90901 sgd_solver.cpp:106] Iteration 97740, lr = 0.001
I0906 08:40:02.248353 90901 solver.cpp:228] Iteration 97750, loss = 0.0605053
I0906 08:40:02.248420 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0605064 (* 1 = 0.0605064 loss)
I0906 08:40:02.248436 90901 sgd_solver.cpp:106] Iteration 97750, lr = 0.001
I0906 08:40:10.219056 90901 solver.cpp:228] Iteration 97760, loss = 0.071667
I0906 08:40:10.219128 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0716681 (* 1 = 0.0716681 loss)
I0906 08:40:10.219144 90901 sgd_solver.cpp:106] Iteration 97760, lr = 0.001
I0906 08:40:18.484143 90901 solver.cpp:228] Iteration 97770, loss = 0.172614
I0906 08:40:18.484329 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172615 (* 1 = 0.172615 loss)
I0906 08:40:18.484361 90901 sgd_solver.cpp:106] Iteration 97770, lr = 0.001
I0906 08:40:26.839982 90901 solver.cpp:228] Iteration 97780, loss = 0.204097
I0906 08:40:26.840057 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204098 (* 1 = 0.204098 loss)
I0906 08:40:26.840075 90901 sgd_solver.cpp:106] Iteration 97780, lr = 0.001
I0906 08:40:35.216593 90901 solver.cpp:228] Iteration 97790, loss = 0.0955307
I0906 08:40:35.216652 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0955318 (* 1 = 0.0955318 loss)
I0906 08:40:35.216670 90901 sgd_solver.cpp:106] Iteration 97790, lr = 0.001
I0906 08:40:43.618683 90901 solver.cpp:228] Iteration 97800, loss = 0.152193
I0906 08:40:43.618758 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.152194 (* 1 = 0.152194 loss)
I0906 08:40:43.618775 90901 sgd_solver.cpp:106] Iteration 97800, lr = 0.001
I0906 08:40:51.915346 90901 solver.cpp:228] Iteration 97810, loss = 0.138461
I0906 08:40:51.915511 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138462 (* 1 = 0.138462 loss)
I0906 08:40:51.915558 90901 sgd_solver.cpp:106] Iteration 97810, lr = 0.001
I0906 08:41:00.240975 90901 solver.cpp:228] Iteration 97820, loss = 0.0266667
I0906 08:41:00.241083 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0266678 (* 1 = 0.0266678 loss)
I0906 08:41:00.241103 90901 sgd_solver.cpp:106] Iteration 97820, lr = 0.001
I0906 08:41:08.101266 90901 solver.cpp:228] Iteration 97830, loss = 0.0474428
I0906 08:41:08.101347 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0474439 (* 1 = 0.0474439 loss)
I0906 08:41:08.101364 90901 sgd_solver.cpp:106] Iteration 97830, lr = 0.001
I0906 08:41:16.405741 90901 solver.cpp:228] Iteration 97840, loss = 0.0709646
I0906 08:41:16.405812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0709657 (* 1 = 0.0709657 loss)
I0906 08:41:16.405828 90901 sgd_solver.cpp:106] Iteration 97840, lr = 0.001
I0906 08:41:24.523212 90901 solver.cpp:228] Iteration 97850, loss = 0.0837183
I0906 08:41:24.523444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0837194 (* 1 = 0.0837194 loss)
I0906 08:41:24.523461 90901 sgd_solver.cpp:106] Iteration 97850, lr = 0.001
I0906 08:41:32.850399 90901 solver.cpp:228] Iteration 97860, loss = 0.256153
I0906 08:41:32.850481 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.256154 (* 1 = 0.256154 loss)
I0906 08:41:32.850499 90901 sgd_solver.cpp:106] Iteration 97860, lr = 0.001
I0906 08:41:41.190220 90901 solver.cpp:228] Iteration 97870, loss = 0.0548171
I0906 08:41:41.190297 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0548182 (* 1 = 0.0548182 loss)
I0906 08:41:41.190315 90901 sgd_solver.cpp:106] Iteration 97870, lr = 0.001
I0906 08:41:49.481729 90901 solver.cpp:228] Iteration 97880, loss = 0.316674
I0906 08:41:49.481789 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.316675 (* 1 = 0.316675 loss)
I0906 08:41:49.481806 90901 sgd_solver.cpp:106] Iteration 97880, lr = 0.001
I0906 08:41:57.325580 90901 solver.cpp:228] Iteration 97890, loss = 0.0841714
I0906 08:41:57.325736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0841725 (* 1 = 0.0841725 loss)
I0906 08:41:57.325752 90901 sgd_solver.cpp:106] Iteration 97890, lr = 0.001
I0906 08:42:05.184960 90901 solver.cpp:228] Iteration 97900, loss = 0.0387088
I0906 08:42:05.185024 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0387098 (* 1 = 0.0387098 loss)
I0906 08:42:05.185041 90901 sgd_solver.cpp:106] Iteration 97900, lr = 0.001
I0906 08:42:12.580713 90901 solver.cpp:228] Iteration 97910, loss = 0.284932
I0906 08:42:12.580773 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284933 (* 1 = 0.284933 loss)
I0906 08:42:12.580790 90901 sgd_solver.cpp:106] Iteration 97910, lr = 0.001
I0906 08:42:19.447305 90901 solver.cpp:228] Iteration 97920, loss = 0.0987388
I0906 08:42:19.447378 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0987399 (* 1 = 0.0987399 loss)
I0906 08:42:19.447394 90901 sgd_solver.cpp:106] Iteration 97920, lr = 0.001
I0906 08:42:26.170220 90901 solver.cpp:228] Iteration 97930, loss = 0.0620817
I0906 08:42:26.170301 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0620827 (* 1 = 0.0620827 loss)
I0906 08:42:26.170318 90901 sgd_solver.cpp:106] Iteration 97930, lr = 0.001
I0906 08:42:31.108127 90901 solver.cpp:228] Iteration 97940, loss = 0.089531
I0906 08:42:31.108264 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.089532 (* 1 = 0.089532 loss)
I0906 08:42:31.108292 90901 sgd_solver.cpp:106] Iteration 97940, lr = 0.001
I0906 08:42:36.041570 90901 solver.cpp:228] Iteration 97950, loss = 0.243568
I0906 08:42:36.041641 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243569 (* 1 = 0.243569 loss)
I0906 08:42:36.041657 90901 sgd_solver.cpp:106] Iteration 97950, lr = 0.001
I0906 08:42:43.036378 90901 solver.cpp:228] Iteration 97960, loss = 0.148121
I0906 08:42:43.036439 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148122 (* 1 = 0.148122 loss)
I0906 08:42:43.036455 90901 sgd_solver.cpp:106] Iteration 97960, lr = 0.001
I0906 08:42:50.287727 90901 solver.cpp:228] Iteration 97970, loss = 0.342898
I0906 08:42:50.287803 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.342899 (* 1 = 0.342899 loss)
I0906 08:42:50.287827 90901 sgd_solver.cpp:106] Iteration 97970, lr = 0.001
I0906 08:42:57.596603 90901 solver.cpp:228] Iteration 97980, loss = 0.119992
I0906 08:42:57.596683 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119993 (* 1 = 0.119993 loss)
I0906 08:42:57.596700 90901 sgd_solver.cpp:106] Iteration 97980, lr = 0.001
I0906 08:43:04.281258 90901 solver.cpp:228] Iteration 97990, loss = 0.03933
I0906 08:43:04.281494 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.039331 (* 1 = 0.039331 loss)
I0906 08:43:04.281513 90901 sgd_solver.cpp:106] Iteration 97990, lr = 0.001
I0906 08:43:11.396929 90901 solver.cpp:228] Iteration 98000, loss = 0.144187
I0906 08:43:11.396992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144188 (* 1 = 0.144188 loss)
I0906 08:43:11.397011 90901 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0906 08:43:18.827034 90901 solver.cpp:228] Iteration 98010, loss = 0.181591
I0906 08:43:18.827127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181592 (* 1 = 0.181592 loss)
I0906 08:43:18.827147 90901 sgd_solver.cpp:106] Iteration 98010, lr = 0.001
I0906 08:43:27.116899 90901 solver.cpp:228] Iteration 98020, loss = 0.0467468
I0906 08:43:27.116966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0467478 (* 1 = 0.0467478 loss)
I0906 08:43:27.116982 90901 sgd_solver.cpp:106] Iteration 98020, lr = 0.001
I0906 08:43:35.218610 90901 solver.cpp:228] Iteration 98030, loss = 0.0921126
I0906 08:43:35.218852 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0921136 (* 1 = 0.0921136 loss)
I0906 08:43:35.218871 90901 sgd_solver.cpp:106] Iteration 98030, lr = 0.001
I0906 08:43:43.413060 90901 solver.cpp:228] Iteration 98040, loss = 0.363348
I0906 08:43:43.413135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.363349 (* 1 = 0.363349 loss)
I0906 08:43:43.413156 90901 sgd_solver.cpp:106] Iteration 98040, lr = 0.001
I0906 08:43:51.954200 90901 solver.cpp:228] Iteration 98050, loss = 0.155299
I0906 08:43:51.954252 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1553 (* 1 = 0.1553 loss)
I0906 08:43:51.954268 90901 sgd_solver.cpp:106] Iteration 98050, lr = 0.001
I0906 08:44:00.287116 90901 solver.cpp:228] Iteration 98060, loss = 0.0577338
I0906 08:44:00.287268 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0577348 (* 1 = 0.0577348 loss)
I0906 08:44:00.287303 90901 sgd_solver.cpp:106] Iteration 98060, lr = 0.001
I0906 08:44:08.451479 90901 solver.cpp:228] Iteration 98070, loss = 0.0609216
I0906 08:44:08.451686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0609226 (* 1 = 0.0609226 loss)
I0906 08:44:08.451705 90901 sgd_solver.cpp:106] Iteration 98070, lr = 0.001
I0906 08:44:16.783100 90901 solver.cpp:228] Iteration 98080, loss = 0.0968676
I0906 08:44:16.783167 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0968686 (* 1 = 0.0968686 loss)
I0906 08:44:16.783188 90901 sgd_solver.cpp:106] Iteration 98080, lr = 0.001
I0906 08:44:25.088225 90901 solver.cpp:228] Iteration 98090, loss = 0.115502
I0906 08:44:25.088309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115503 (* 1 = 0.115503 loss)
I0906 08:44:25.088325 90901 sgd_solver.cpp:106] Iteration 98090, lr = 0.001
I0906 08:44:33.242199 90901 solver.cpp:228] Iteration 98100, loss = 0.0487497
I0906 08:44:33.242266 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0487507 (* 1 = 0.0487507 loss)
I0906 08:44:33.242283 90901 sgd_solver.cpp:106] Iteration 98100, lr = 0.001
I0906 08:44:41.146733 90901 solver.cpp:228] Iteration 98110, loss = 0.148395
I0906 08:44:41.146945 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148396 (* 1 = 0.148396 loss)
I0906 08:44:41.146966 90901 sgd_solver.cpp:106] Iteration 98110, lr = 0.001
I0906 08:44:49.395139 90901 solver.cpp:228] Iteration 98120, loss = 0.0559087
I0906 08:44:49.395223 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0559097 (* 1 = 0.0559097 loss)
I0906 08:44:49.395242 90901 sgd_solver.cpp:106] Iteration 98120, lr = 0.001
I0906 08:44:57.846649 90901 solver.cpp:228] Iteration 98130, loss = 0.453552
I0906 08:44:57.846752 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.453553 (* 1 = 0.453553 loss)
I0906 08:44:57.846777 90901 sgd_solver.cpp:106] Iteration 98130, lr = 0.001
I0906 08:45:06.230211 90901 solver.cpp:228] Iteration 98140, loss = 0.0222867
I0906 08:45:06.230285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0222877 (* 1 = 0.0222877 loss)
I0906 08:45:06.230303 90901 sgd_solver.cpp:106] Iteration 98140, lr = 0.001
I0906 08:45:14.074681 90901 solver.cpp:228] Iteration 98150, loss = 0.122571
I0906 08:45:14.074928 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.122572 (* 1 = 0.122572 loss)
I0906 08:45:14.074950 90901 sgd_solver.cpp:106] Iteration 98150, lr = 0.001
I0906 08:45:22.429805 90901 solver.cpp:228] Iteration 98160, loss = 0.133146
I0906 08:45:22.429884 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133147 (* 1 = 0.133147 loss)
I0906 08:45:22.429901 90901 sgd_solver.cpp:106] Iteration 98160, lr = 0.001
I0906 08:45:31.071702 90901 solver.cpp:228] Iteration 98170, loss = 0.202289
I0906 08:45:31.071770 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.20229 (* 1 = 0.20229 loss)
I0906 08:45:31.071789 90901 sgd_solver.cpp:106] Iteration 98170, lr = 0.001
I0906 08:45:39.106326 90901 solver.cpp:228] Iteration 98180, loss = 0.143726
I0906 08:45:39.106396 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143727 (* 1 = 0.143727 loss)
I0906 08:45:39.106412 90901 sgd_solver.cpp:106] Iteration 98180, lr = 0.001
I0906 08:45:47.801260 90901 solver.cpp:228] Iteration 98190, loss = 0.0563881
I0906 08:45:47.801406 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0563891 (* 1 = 0.0563891 loss)
I0906 08:45:47.801436 90901 sgd_solver.cpp:106] Iteration 98190, lr = 0.001
I0906 08:45:55.991199 90901 solver.cpp:228] Iteration 98200, loss = 0.271722
I0906 08:45:55.991261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271723 (* 1 = 0.271723 loss)
I0906 08:45:55.991277 90901 sgd_solver.cpp:106] Iteration 98200, lr = 0.001
I0906 08:46:04.235025 90901 solver.cpp:228] Iteration 98210, loss = 0.267148
I0906 08:46:04.235088 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.267149 (* 1 = 0.267149 loss)
I0906 08:46:04.235105 90901 sgd_solver.cpp:106] Iteration 98210, lr = 0.001
I0906 08:46:12.362676 90901 solver.cpp:228] Iteration 98220, loss = 0.0603376
I0906 08:46:12.362764 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0603386 (* 1 = 0.0603386 loss)
I0906 08:46:12.362782 90901 sgd_solver.cpp:106] Iteration 98220, lr = 0.001
I0906 08:46:20.299468 90901 solver.cpp:228] Iteration 98230, loss = 0.0567016
I0906 08:46:20.299711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0567026 (* 1 = 0.0567026 loss)
I0906 08:46:20.299734 90901 sgd_solver.cpp:106] Iteration 98230, lr = 0.001
I0906 08:46:28.631958 90901 solver.cpp:228] Iteration 98240, loss = 0.103391
I0906 08:46:28.632025 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103392 (* 1 = 0.103392 loss)
I0906 08:46:28.632041 90901 sgd_solver.cpp:106] Iteration 98240, lr = 0.001
I0906 08:46:36.901880 90901 solver.cpp:228] Iteration 98250, loss = 0.0389147
I0906 08:46:36.901948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0389156 (* 1 = 0.0389156 loss)
I0906 08:46:36.901965 90901 sgd_solver.cpp:106] Iteration 98250, lr = 0.001
I0906 08:46:45.229198 90901 solver.cpp:228] Iteration 98260, loss = 0.233362
I0906 08:46:45.229274 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.233363 (* 1 = 0.233363 loss)
I0906 08:46:45.229290 90901 sgd_solver.cpp:106] Iteration 98260, lr = 0.001
I0906 08:46:52.837136 90901 solver.cpp:228] Iteration 98270, loss = 0.0966448
I0906 08:46:52.837357 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0966457 (* 1 = 0.0966457 loss)
I0906 08:46:52.837374 90901 sgd_solver.cpp:106] Iteration 98270, lr = 0.001
I0906 08:47:01.139299 90901 solver.cpp:228] Iteration 98280, loss = 0.0759369
I0906 08:47:01.139369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0759379 (* 1 = 0.0759379 loss)
I0906 08:47:01.139386 90901 sgd_solver.cpp:106] Iteration 98280, lr = 0.001
I0906 08:47:09.311800 90901 solver.cpp:228] Iteration 98290, loss = 0.255334
I0906 08:47:09.311868 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255335 (* 1 = 0.255335 loss)
I0906 08:47:09.311887 90901 sgd_solver.cpp:106] Iteration 98290, lr = 0.001
I0906 08:47:17.581367 90901 solver.cpp:228] Iteration 98300, loss = 0.041027
I0906 08:47:17.581431 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0410279 (* 1 = 0.0410279 loss)
I0906 08:47:17.581446 90901 sgd_solver.cpp:106] Iteration 98300, lr = 0.001
I0906 08:47:26.056720 90901 solver.cpp:228] Iteration 98310, loss = 0.177064
I0906 08:47:26.056836 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177065 (* 1 = 0.177065 loss)
I0906 08:47:26.056854 90901 sgd_solver.cpp:106] Iteration 98310, lr = 0.001
I0906 08:47:34.236644 90901 solver.cpp:228] Iteration 98320, loss = 0.112514
I0906 08:47:34.236718 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112515 (* 1 = 0.112515 loss)
I0906 08:47:34.236735 90901 sgd_solver.cpp:106] Iteration 98320, lr = 0.001
I0906 08:47:42.639344 90901 solver.cpp:228] Iteration 98330, loss = 0.11088
I0906 08:47:42.639423 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.110881 (* 1 = 0.110881 loss)
I0906 08:47:42.639441 90901 sgd_solver.cpp:106] Iteration 98330, lr = 0.001
I0906 08:47:51.273799 90901 solver.cpp:228] Iteration 98340, loss = 0.111521
I0906 08:47:51.273870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111522 (* 1 = 0.111522 loss)
I0906 08:47:51.273887 90901 sgd_solver.cpp:106] Iteration 98340, lr = 0.001
I0906 08:47:59.483683 90901 solver.cpp:228] Iteration 98350, loss = 0.0302701
I0906 08:47:59.483849 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.030271 (* 1 = 0.030271 loss)
I0906 08:47:59.483872 90901 sgd_solver.cpp:106] Iteration 98350, lr = 0.001
I0906 08:48:07.696421 90901 solver.cpp:228] Iteration 98360, loss = 0.099547
I0906 08:48:07.696485 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0995479 (* 1 = 0.0995479 loss)
I0906 08:48:07.696501 90901 sgd_solver.cpp:106] Iteration 98360, lr = 0.001
I0906 08:48:15.869362 90901 solver.cpp:228] Iteration 98370, loss = 0.0837032
I0906 08:48:15.869432 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0837041 (* 1 = 0.0837041 loss)
I0906 08:48:15.869451 90901 sgd_solver.cpp:106] Iteration 98370, lr = 0.001
I0906 08:48:24.168803 90901 solver.cpp:228] Iteration 98380, loss = 0.102548
I0906 08:48:24.168869 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102549 (* 1 = 0.102549 loss)
I0906 08:48:24.168886 90901 sgd_solver.cpp:106] Iteration 98380, lr = 0.001
I0906 08:48:32.508261 90901 solver.cpp:228] Iteration 98390, loss = 0.173027
I0906 08:48:32.508390 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173028 (* 1 = 0.173028 loss)
I0906 08:48:32.508409 90901 sgd_solver.cpp:106] Iteration 98390, lr = 0.001
I0906 08:48:40.878849 90901 solver.cpp:337] Iteration 98400, Testing net (#0)
I0906 08:49:41.472537 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.950312
I0906 08:49:41.472764 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.131276 (* 1 = 0.131276 loss)
I0906 08:49:41.895234 90901 solver.cpp:228] Iteration 98400, loss = 0.353715
I0906 08:49:41.895287 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.353716 (* 1 = 0.353716 loss)
I0906 08:49:41.895306 90901 sgd_solver.cpp:106] Iteration 98400, lr = 0.001
I0906 08:49:50.213297 90901 solver.cpp:228] Iteration 98410, loss = 0.28567
I0906 08:49:50.213369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.285671 (* 1 = 0.285671 loss)
I0906 08:49:50.213388 90901 sgd_solver.cpp:106] Iteration 98410, lr = 0.001
I0906 08:49:58.985781 90901 solver.cpp:228] Iteration 98420, loss = 0.168657
I0906 08:49:58.985860 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168659 (* 1 = 0.168659 loss)
I0906 08:49:58.985879 90901 sgd_solver.cpp:106] Iteration 98420, lr = 0.001
I0906 08:50:07.711498 90901 solver.cpp:228] Iteration 98430, loss = 0.0460403
I0906 08:50:07.711573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0460414 (* 1 = 0.0460414 loss)
I0906 08:50:07.711591 90901 sgd_solver.cpp:106] Iteration 98430, lr = 0.001
I0906 08:50:16.119899 90901 solver.cpp:228] Iteration 98440, loss = 0.253343
I0906 08:50:16.120187 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253344 (* 1 = 0.253344 loss)
I0906 08:50:16.120206 90901 sgd_solver.cpp:106] Iteration 98440, lr = 0.001
I0906 08:50:24.035243 90901 solver.cpp:228] Iteration 98450, loss = 0.148865
I0906 08:50:24.035322 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148866 (* 1 = 0.148866 loss)
I0906 08:50:24.035339 90901 sgd_solver.cpp:106] Iteration 98450, lr = 0.001
I0906 08:50:32.642666 90901 solver.cpp:228] Iteration 98460, loss = 0.117929
I0906 08:50:32.642736 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117931 (* 1 = 0.117931 loss)
I0906 08:50:32.642757 90901 sgd_solver.cpp:106] Iteration 98460, lr = 0.001
I0906 08:50:41.054395 90901 solver.cpp:228] Iteration 98470, loss = 0.0850702
I0906 08:50:41.054479 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0850713 (* 1 = 0.0850713 loss)
I0906 08:50:41.054494 90901 sgd_solver.cpp:106] Iteration 98470, lr = 0.001
I0906 08:50:49.205072 90901 solver.cpp:228] Iteration 98480, loss = 0.0832113
I0906 08:50:49.205308 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0832125 (* 1 = 0.0832125 loss)
I0906 08:50:49.205333 90901 sgd_solver.cpp:106] Iteration 98480, lr = 0.001
I0906 08:50:57.315785 90901 solver.cpp:228] Iteration 98490, loss = 0.32901
I0906 08:50:57.315856 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.329012 (* 1 = 0.329012 loss)
I0906 08:50:57.315874 90901 sgd_solver.cpp:106] Iteration 98490, lr = 0.001
I0906 08:51:05.471211 90901 solver.cpp:228] Iteration 98500, loss = 0.026718
I0906 08:51:05.471285 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0267191 (* 1 = 0.0267191 loss)
I0906 08:51:05.471307 90901 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I0906 08:51:13.819670 90901 solver.cpp:228] Iteration 98510, loss = 0.358885
I0906 08:51:13.819737 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.358886 (* 1 = 0.358886 loss)
I0906 08:51:13.819756 90901 sgd_solver.cpp:106] Iteration 98510, lr = 0.001
I0906 08:51:21.962483 90901 solver.cpp:228] Iteration 98520, loss = 0.0696545
I0906 08:51:21.962818 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0696556 (* 1 = 0.0696556 loss)
I0906 08:51:21.962867 90901 sgd_solver.cpp:106] Iteration 98520, lr = 0.001
I0906 08:51:30.337340 90901 solver.cpp:228] Iteration 98530, loss = 0.059668
I0906 08:51:30.337404 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596692 (* 1 = 0.0596692 loss)
I0906 08:51:30.337420 90901 sgd_solver.cpp:106] Iteration 98530, lr = 0.001
I0906 08:51:38.735221 90901 solver.cpp:228] Iteration 98540, loss = 0.0982039
I0906 08:51:38.735309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0982051 (* 1 = 0.0982051 loss)
I0906 08:51:38.735327 90901 sgd_solver.cpp:106] Iteration 98540, lr = 0.001
I0906 08:51:47.334750 90901 solver.cpp:228] Iteration 98550, loss = 0.722168
I0906 08:51:47.334828 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.722169 (* 1 = 0.722169 loss)
I0906 08:51:47.334846 90901 sgd_solver.cpp:106] Iteration 98550, lr = 0.001
I0906 08:51:55.773408 90901 solver.cpp:228] Iteration 98560, loss = 0.0947241
I0906 08:51:55.773598 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0947252 (* 1 = 0.0947252 loss)
I0906 08:51:55.773617 90901 sgd_solver.cpp:106] Iteration 98560, lr = 0.001
I0906 08:52:03.892860 90901 solver.cpp:228] Iteration 98570, loss = 0.0496388
I0906 08:52:03.892922 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0496399 (* 1 = 0.0496399 loss)
I0906 08:52:03.892938 90901 sgd_solver.cpp:106] Iteration 98570, lr = 0.001
I0906 08:52:12.193090 90901 solver.cpp:228] Iteration 98580, loss = 0.0908941
I0906 08:52:12.193179 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0908952 (* 1 = 0.0908952 loss)
I0906 08:52:12.193197 90901 sgd_solver.cpp:106] Iteration 98580, lr = 0.001
I0906 08:52:20.267894 90901 solver.cpp:228] Iteration 98590, loss = 0.317299
I0906 08:52:20.267966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.3173 (* 1 = 0.3173 loss)
I0906 08:52:20.267984 90901 sgd_solver.cpp:106] Iteration 98590, lr = 0.001
I0906 08:52:28.645323 90901 solver.cpp:228] Iteration 98600, loss = 0.0619239
I0906 08:52:28.645514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.061925 (* 1 = 0.061925 loss)
I0906 08:52:28.645532 90901 sgd_solver.cpp:106] Iteration 98600, lr = 0.001
I0906 08:52:36.736685 90901 solver.cpp:228] Iteration 98610, loss = 0.17153
I0906 08:52:36.736763 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171531 (* 1 = 0.171531 loss)
I0906 08:52:36.736781 90901 sgd_solver.cpp:106] Iteration 98610, lr = 0.001
I0906 08:52:45.156586 90901 solver.cpp:228] Iteration 98620, loss = 0.0376646
I0906 08:52:45.156675 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0376658 (* 1 = 0.0376658 loss)
I0906 08:52:45.156692 90901 sgd_solver.cpp:106] Iteration 98620, lr = 0.001
I0906 08:52:53.726203 90901 solver.cpp:228] Iteration 98630, loss = 0.0725297
I0906 08:52:53.726272 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0725309 (* 1 = 0.0725309 loss)
I0906 08:52:53.726289 90901 sgd_solver.cpp:106] Iteration 98630, lr = 0.001
I0906 08:53:02.066316 90901 solver.cpp:228] Iteration 98640, loss = 0.0689447
I0906 08:53:02.066531 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0689459 (* 1 = 0.0689459 loss)
I0906 08:53:02.066562 90901 sgd_solver.cpp:106] Iteration 98640, lr = 0.001
I0906 08:53:10.711887 90901 solver.cpp:228] Iteration 98650, loss = 0.156981
I0906 08:53:10.711966 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156982 (* 1 = 0.156982 loss)
I0906 08:53:10.711983 90901 sgd_solver.cpp:106] Iteration 98650, lr = 0.001
I0906 08:53:18.806676 90901 solver.cpp:228] Iteration 98660, loss = 0.114375
I0906 08:53:18.806746 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114376 (* 1 = 0.114376 loss)
I0906 08:53:18.806762 90901 sgd_solver.cpp:106] Iteration 98660, lr = 0.001
I0906 08:53:26.991122 90901 solver.cpp:228] Iteration 98670, loss = 0.0637527
I0906 08:53:26.991192 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0637539 (* 1 = 0.0637539 loss)
I0906 08:53:26.991209 90901 sgd_solver.cpp:106] Iteration 98670, lr = 0.001
I0906 08:53:35.591224 90901 solver.cpp:228] Iteration 98680, loss = 0.0736971
I0906 08:53:35.591820 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0736983 (* 1 = 0.0736983 loss)
I0906 08:53:35.591858 90901 sgd_solver.cpp:106] Iteration 98680, lr = 0.001
I0906 08:53:44.201212 90901 solver.cpp:228] Iteration 98690, loss = 0.127433
I0906 08:53:44.201288 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127435 (* 1 = 0.127435 loss)
I0906 08:53:44.201306 90901 sgd_solver.cpp:106] Iteration 98690, lr = 0.001
I0906 08:53:52.590044 90901 solver.cpp:228] Iteration 98700, loss = 0.0988653
I0906 08:53:52.590102 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0988665 (* 1 = 0.0988665 loss)
I0906 08:53:52.590118 90901 sgd_solver.cpp:106] Iteration 98700, lr = 0.001
I0906 08:54:01.478025 90901 solver.cpp:228] Iteration 98710, loss = 0.0397464
I0906 08:54:01.478104 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0397476 (* 1 = 0.0397476 loss)
I0906 08:54:01.478121 90901 sgd_solver.cpp:106] Iteration 98710, lr = 0.001
I0906 08:54:09.552220 90901 solver.cpp:228] Iteration 98720, loss = 0.166129
I0906 08:54:09.553948 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16613 (* 1 = 0.16613 loss)
I0906 08:54:09.553972 90901 sgd_solver.cpp:106] Iteration 98720, lr = 0.001
I0906 08:54:18.053333 90901 solver.cpp:228] Iteration 98730, loss = 0.083011
I0906 08:54:18.053407 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0830122 (* 1 = 0.0830122 loss)
I0906 08:54:18.053424 90901 sgd_solver.cpp:106] Iteration 98730, lr = 0.001
I0906 08:54:26.152948 90901 solver.cpp:228] Iteration 98740, loss = 0.0244932
I0906 08:54:26.153019 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0244944 (* 1 = 0.0244944 loss)
I0906 08:54:26.153035 90901 sgd_solver.cpp:106] Iteration 98740, lr = 0.001
I0906 08:54:34.787398 90901 solver.cpp:228] Iteration 98750, loss = 0.0654719
I0906 08:54:34.787467 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.065473 (* 1 = 0.065473 loss)
I0906 08:54:34.787483 90901 sgd_solver.cpp:106] Iteration 98750, lr = 0.001
I0906 08:54:43.280829 90901 solver.cpp:228] Iteration 98760, loss = 0.228668
I0906 08:54:43.281002 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.228669 (* 1 = 0.228669 loss)
I0906 08:54:43.281033 90901 sgd_solver.cpp:106] Iteration 98760, lr = 0.001
I0906 08:54:51.510665 90901 solver.cpp:228] Iteration 98770, loss = 0.0619559
I0906 08:54:51.510725 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.061957 (* 1 = 0.061957 loss)
I0906 08:54:51.510741 90901 sgd_solver.cpp:106] Iteration 98770, lr = 0.001
I0906 08:55:00.040909 90901 solver.cpp:228] Iteration 98780, loss = 0.0541182
I0906 08:55:00.041191 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0541193 (* 1 = 0.0541193 loss)
I0906 08:55:00.041244 90901 sgd_solver.cpp:106] Iteration 98780, lr = 0.001
I0906 08:55:08.235194 90901 solver.cpp:228] Iteration 98790, loss = 0.225212
I0906 08:55:08.235263 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225213 (* 1 = 0.225213 loss)
I0906 08:55:08.235280 90901 sgd_solver.cpp:106] Iteration 98790, lr = 0.001
I0906 08:55:16.725721 90901 solver.cpp:228] Iteration 98800, loss = 0.172312
I0906 08:55:16.725913 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172313 (* 1 = 0.172313 loss)
I0906 08:55:16.725953 90901 sgd_solver.cpp:106] Iteration 98800, lr = 0.001
I0906 08:55:24.512961 90901 solver.cpp:228] Iteration 98810, loss = 0.0548278
I0906 08:55:24.513032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0548289 (* 1 = 0.0548289 loss)
I0906 08:55:24.513049 90901 sgd_solver.cpp:106] Iteration 98810, lr = 0.001
I0906 08:55:32.568305 90901 solver.cpp:228] Iteration 98820, loss = 0.0457848
I0906 08:55:32.568366 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0457859 (* 1 = 0.0457859 loss)
I0906 08:55:32.568382 90901 sgd_solver.cpp:106] Iteration 98820, lr = 0.001
I0906 08:55:40.681895 90901 solver.cpp:228] Iteration 98830, loss = 0.3455
I0906 08:55:40.681972 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.345501 (* 1 = 0.345501 loss)
I0906 08:55:40.682003 90901 sgd_solver.cpp:106] Iteration 98830, lr = 0.001
I0906 08:55:49.774436 90901 solver.cpp:228] Iteration 98840, loss = 0.0570996
I0906 08:55:49.774581 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0571008 (* 1 = 0.0571008 loss)
I0906 08:55:49.774602 90901 sgd_solver.cpp:106] Iteration 98840, lr = 0.001
I0906 08:55:56.562929 90901 solver.cpp:228] Iteration 98850, loss = 0.254527
I0906 08:55:56.562988 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254528 (* 1 = 0.254528 loss)
I0906 08:55:56.563004 90901 sgd_solver.cpp:106] Iteration 98850, lr = 0.001
I0906 08:56:01.758196 90901 solver.cpp:228] Iteration 98860, loss = 0.566607
I0906 08:56:01.758277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.566608 (* 1 = 0.566608 loss)
I0906 08:56:01.758298 90901 sgd_solver.cpp:106] Iteration 98860, lr = 0.001
I0906 08:56:07.283475 90901 solver.cpp:228] Iteration 98870, loss = 0.0904407
I0906 08:56:07.283545 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0904418 (* 1 = 0.0904418 loss)
I0906 08:56:07.283562 90901 sgd_solver.cpp:106] Iteration 98870, lr = 0.001
I0906 08:56:12.487920 90901 solver.cpp:228] Iteration 98880, loss = 0.296866
I0906 08:56:12.487993 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.296867 (* 1 = 0.296867 loss)
I0906 08:56:12.488010 90901 sgd_solver.cpp:106] Iteration 98880, lr = 0.001
I0906 08:56:18.174790 90901 solver.cpp:228] Iteration 98890, loss = 0.180065
I0906 08:56:18.174870 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180066 (* 1 = 0.180066 loss)
I0906 08:56:18.174895 90901 sgd_solver.cpp:106] Iteration 98890, lr = 0.001
I0906 08:56:25.463549 90901 solver.cpp:228] Iteration 98900, loss = 0.0538222
I0906 08:56:25.463812 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0538234 (* 1 = 0.0538234 loss)
I0906 08:56:25.463831 90901 sgd_solver.cpp:106] Iteration 98900, lr = 0.001
I0906 08:56:33.043104 90901 solver.cpp:228] Iteration 98910, loss = 0.108397
I0906 08:56:33.043170 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108398 (* 1 = 0.108398 loss)
I0906 08:56:33.043187 90901 sgd_solver.cpp:106] Iteration 98910, lr = 0.001
I0906 08:56:41.164227 90901 solver.cpp:228] Iteration 98920, loss = 0.101524
I0906 08:56:41.164293 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101526 (* 1 = 0.101526 loss)
I0906 08:56:41.164314 90901 sgd_solver.cpp:106] Iteration 98920, lr = 0.001
I0906 08:56:49.258332 90901 solver.cpp:228] Iteration 98930, loss = 0.0367922
I0906 08:56:49.258426 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0367933 (* 1 = 0.0367933 loss)
I0906 08:56:49.258447 90901 sgd_solver.cpp:106] Iteration 98930, lr = 0.001
I0906 08:56:56.833534 90901 solver.cpp:228] Iteration 98940, loss = 0.134744
I0906 08:56:56.833724 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134745 (* 1 = 0.134745 loss)
I0906 08:56:56.833742 90901 sgd_solver.cpp:106] Iteration 98940, lr = 0.001
I0906 08:57:05.177806 90901 solver.cpp:228] Iteration 98950, loss = 0.178254
I0906 08:57:05.177901 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178255 (* 1 = 0.178255 loss)
I0906 08:57:05.177925 90901 sgd_solver.cpp:106] Iteration 98950, lr = 0.001
I0906 08:57:13.284940 90901 solver.cpp:228] Iteration 98960, loss = 0.064823
I0906 08:57:13.285004 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0648242 (* 1 = 0.0648242 loss)
I0906 08:57:13.285022 90901 sgd_solver.cpp:106] Iteration 98960, lr = 0.001
I0906 08:57:20.836801 90901 solver.cpp:228] Iteration 98970, loss = 0.0215165
I0906 08:57:20.836892 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0215177 (* 1 = 0.0215177 loss)
I0906 08:57:20.836912 90901 sgd_solver.cpp:106] Iteration 98970, lr = 0.001
I0906 08:57:28.694125 90901 solver.cpp:228] Iteration 98980, loss = 0.0727995
I0906 08:57:28.694293 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0728007 (* 1 = 0.0728007 loss)
I0906 08:57:28.694317 90901 sgd_solver.cpp:106] Iteration 98980, lr = 0.001
I0906 08:57:36.587570 90901 solver.cpp:228] Iteration 98990, loss = 0.0737033
I0906 08:57:36.587643 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0737046 (* 1 = 0.0737046 loss)
I0906 08:57:36.587659 90901 sgd_solver.cpp:106] Iteration 98990, lr = 0.001
I0906 08:57:44.793756 90901 solver.cpp:228] Iteration 99000, loss = 0.178369
I0906 08:57:44.793833 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.17837 (* 1 = 0.17837 loss)
I0906 08:57:44.793850 90901 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0906 08:57:52.671478 90901 solver.cpp:228] Iteration 99010, loss = 0.0785085
I0906 08:57:52.671573 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0785098 (* 1 = 0.0785098 loss)
I0906 08:57:52.671591 90901 sgd_solver.cpp:106] Iteration 99010, lr = 0.001
I0906 08:58:00.945960 90901 solver.cpp:228] Iteration 99020, loss = 0.0707618
I0906 08:58:00.946202 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.070763 (* 1 = 0.070763 loss)
I0906 08:58:00.946229 90901 sgd_solver.cpp:106] Iteration 99020, lr = 0.001
I0906 08:58:08.976788 90901 solver.cpp:228] Iteration 99030, loss = 0.129921
I0906 08:58:08.976864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129923 (* 1 = 0.129923 loss)
I0906 08:58:08.976886 90901 sgd_solver.cpp:106] Iteration 99030, lr = 0.001
I0906 08:58:16.942821 90901 solver.cpp:228] Iteration 99040, loss = 0.171849
I0906 08:58:16.942883 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171851 (* 1 = 0.171851 loss)
I0906 08:58:16.942898 90901 sgd_solver.cpp:106] Iteration 99040, lr = 0.001
I0906 08:58:25.146927 90901 solver.cpp:228] Iteration 99050, loss = 0.0573415
I0906 08:58:25.147006 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0573428 (* 1 = 0.0573428 loss)
I0906 08:58:25.147034 90901 sgd_solver.cpp:106] Iteration 99050, lr = 0.001
I0906 08:58:33.286717 90901 solver.cpp:228] Iteration 99060, loss = 0.13494
I0906 08:58:33.286937 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134942 (* 1 = 0.134942 loss)
I0906 08:58:33.286962 90901 sgd_solver.cpp:106] Iteration 99060, lr = 0.001
I0906 08:58:41.630094 90901 solver.cpp:228] Iteration 99070, loss = 0.161695
I0906 08:58:41.630190 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161696 (* 1 = 0.161696 loss)
I0906 08:58:41.630213 90901 sgd_solver.cpp:106] Iteration 99070, lr = 0.001
I0906 08:58:49.621953 90901 solver.cpp:228] Iteration 99080, loss = 0.0790875
I0906 08:58:49.622032 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0790888 (* 1 = 0.0790888 loss)
I0906 08:58:49.622054 90901 sgd_solver.cpp:106] Iteration 99080, lr = 0.001
I0906 08:58:58.094205 90901 solver.cpp:228] Iteration 99090, loss = 0.145698
I0906 08:58:58.094307 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1457 (* 1 = 0.1457 loss)
I0906 08:58:58.094333 90901 sgd_solver.cpp:106] Iteration 99090, lr = 0.001
I0906 08:59:05.894088 90901 solver.cpp:228] Iteration 99100, loss = 0.183326
I0906 08:59:05.894290 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.183327 (* 1 = 0.183327 loss)
I0906 08:59:05.894321 90901 sgd_solver.cpp:106] Iteration 99100, lr = 0.001
I0906 08:59:13.764842 90901 solver.cpp:228] Iteration 99110, loss = 0.410193
I0906 08:59:13.764912 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.410194 (* 1 = 0.410194 loss)
I0906 08:59:13.764930 90901 sgd_solver.cpp:106] Iteration 99110, lr = 0.001
I0906 08:59:21.318578 90901 solver.cpp:228] Iteration 99120, loss = 0.15356
I0906 08:59:21.318684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153562 (* 1 = 0.153562 loss)
I0906 08:59:21.318703 90901 sgd_solver.cpp:106] Iteration 99120, lr = 0.001
I0906 08:59:28.748088 90901 solver.cpp:228] Iteration 99130, loss = 0.0342206
I0906 08:59:28.748154 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0342219 (* 1 = 0.0342219 loss)
I0906 08:59:28.748172 90901 sgd_solver.cpp:106] Iteration 99130, lr = 0.001
I0906 08:59:36.987486 90901 solver.cpp:228] Iteration 99140, loss = 0.207418
I0906 08:59:36.987829 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207419 (* 1 = 0.207419 loss)
I0906 08:59:36.987879 90901 sgd_solver.cpp:106] Iteration 99140, lr = 0.001
I0906 08:59:44.212327 90901 solver.cpp:228] Iteration 99150, loss = 0.0413914
I0906 08:59:44.212398 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0413927 (* 1 = 0.0413927 loss)
I0906 08:59:44.212414 90901 sgd_solver.cpp:106] Iteration 99150, lr = 0.001
I0906 08:59:51.506603 90901 solver.cpp:228] Iteration 99160, loss = 0.107044
I0906 08:59:51.506696 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107046 (* 1 = 0.107046 loss)
I0906 08:59:51.506719 90901 sgd_solver.cpp:106] Iteration 99160, lr = 0.001
I0906 08:59:56.710810 90901 solver.cpp:228] Iteration 99170, loss = 0.0937209
I0906 08:59:56.710876 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0937223 (* 1 = 0.0937223 loss)
I0906 08:59:56.710896 90901 sgd_solver.cpp:106] Iteration 99170, lr = 0.001
I0906 09:00:01.911885 90901 solver.cpp:228] Iteration 99180, loss = 0.195331
I0906 09:00:01.911957 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195333 (* 1 = 0.195333 loss)
I0906 09:00:01.911974 90901 sgd_solver.cpp:106] Iteration 99180, lr = 0.001
I0906 09:00:07.454828 90901 solver.cpp:228] Iteration 99190, loss = 0.310882
I0906 09:00:07.455108 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.310884 (* 1 = 0.310884 loss)
I0906 09:00:07.455134 90901 sgd_solver.cpp:106] Iteration 99190, lr = 0.001
I0906 09:00:13.173169 90901 solver.cpp:337] Iteration 99200, Testing net (#0)
I0906 09:01:10.310030 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.940313
I0906 09:01:10.310246 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.161145 (* 1 = 0.161145 loss)
I0906 09:01:10.562690 90901 solver.cpp:228] Iteration 99200, loss = 0.149977
I0906 09:01:10.562779 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149978 (* 1 = 0.149978 loss)
I0906 09:01:10.562800 90901 sgd_solver.cpp:106] Iteration 99200, lr = 0.001
I0906 09:01:18.692227 90901 solver.cpp:228] Iteration 99210, loss = 0.278717
I0906 09:01:18.692302 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278718 (* 1 = 0.278718 loss)
I0906 09:01:18.692320 90901 sgd_solver.cpp:106] Iteration 99210, lr = 0.001
I0906 09:01:27.211242 90901 solver.cpp:228] Iteration 99220, loss = 0.255964
I0906 09:01:27.211328 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255965 (* 1 = 0.255965 loss)
I0906 09:01:27.211346 90901 sgd_solver.cpp:106] Iteration 99220, lr = 0.001
I0906 09:01:34.884177 90901 solver.cpp:228] Iteration 99230, loss = 0.0435523
I0906 09:01:34.884261 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0435537 (* 1 = 0.0435537 loss)
I0906 09:01:34.884279 90901 sgd_solver.cpp:106] Iteration 99230, lr = 0.001
I0906 09:01:43.082061 90901 solver.cpp:228] Iteration 99240, loss = 0.0348413
I0906 09:01:43.082243 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0348426 (* 1 = 0.0348426 loss)
I0906 09:01:43.082278 90901 sgd_solver.cpp:106] Iteration 99240, lr = 0.001
I0906 09:01:51.433828 90901 solver.cpp:228] Iteration 99250, loss = 0.280543
I0906 09:01:51.433908 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.280544 (* 1 = 0.280544 loss)
I0906 09:01:51.433926 90901 sgd_solver.cpp:106] Iteration 99250, lr = 0.001
I0906 09:01:59.796856 90901 solver.cpp:228] Iteration 99260, loss = 0.186661
I0906 09:01:59.796933 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186663 (* 1 = 0.186663 loss)
I0906 09:01:59.796952 90901 sgd_solver.cpp:106] Iteration 99260, lr = 0.001
I0906 09:02:08.241314 90901 solver.cpp:228] Iteration 99270, loss = 0.172892
I0906 09:02:08.241374 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172893 (* 1 = 0.172893 loss)
I0906 09:02:08.241389 90901 sgd_solver.cpp:106] Iteration 99270, lr = 0.001
I0906 09:02:16.800793 90901 solver.cpp:228] Iteration 99280, loss = 0.163621
I0906 09:02:16.800978 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163622 (* 1 = 0.163622 loss)
I0906 09:02:16.800997 90901 sgd_solver.cpp:106] Iteration 99280, lr = 0.001
I0906 09:02:25.491066 90901 solver.cpp:228] Iteration 99290, loss = 0.080872
I0906 09:02:25.491127 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0808733 (* 1 = 0.0808733 loss)
I0906 09:02:25.491143 90901 sgd_solver.cpp:106] Iteration 99290, lr = 0.001
I0906 09:02:33.550279 90901 solver.cpp:228] Iteration 99300, loss = 0.46796
I0906 09:02:33.550375 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.467962 (* 1 = 0.467962 loss)
I0906 09:02:33.550398 90901 sgd_solver.cpp:106] Iteration 99300, lr = 0.001
I0906 09:02:41.932099 90901 solver.cpp:228] Iteration 99310, loss = 0.0350372
I0906 09:02:41.932176 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350385 (* 1 = 0.0350385 loss)
I0906 09:02:41.932194 90901 sgd_solver.cpp:106] Iteration 99310, lr = 0.001
I0906 09:02:50.069705 90901 solver.cpp:228] Iteration 99320, loss = 0.0350513
I0906 09:02:50.069989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0350526 (* 1 = 0.0350526 loss)
I0906 09:02:50.070025 90901 sgd_solver.cpp:106] Iteration 99320, lr = 0.001
I0906 09:02:58.461905 90901 solver.cpp:228] Iteration 99330, loss = 0.322487
I0906 09:02:58.461973 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.322488 (* 1 = 0.322488 loss)
I0906 09:02:58.461990 90901 sgd_solver.cpp:106] Iteration 99330, lr = 0.001
I0906 09:03:06.767313 90901 solver.cpp:228] Iteration 99340, loss = 0.0610128
I0906 09:03:06.767391 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0610141 (* 1 = 0.0610141 loss)
I0906 09:03:06.767408 90901 sgd_solver.cpp:106] Iteration 99340, lr = 0.001
I0906 09:03:14.874263 90901 solver.cpp:228] Iteration 99350, loss = 0.159255
I0906 09:03:14.874369 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.159256 (* 1 = 0.159256 loss)
I0906 09:03:14.874397 90901 sgd_solver.cpp:106] Iteration 99350, lr = 0.001
I0906 09:03:22.967380 90901 solver.cpp:228] Iteration 99360, loss = 0.193019
I0906 09:03:22.967550 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19302 (* 1 = 0.19302 loss)
I0906 09:03:22.967569 90901 sgd_solver.cpp:106] Iteration 99360, lr = 0.001
I0906 09:03:30.769238 90901 solver.cpp:228] Iteration 99370, loss = 0.308918
I0906 09:03:30.769309 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.30892 (* 1 = 0.30892 loss)
I0906 09:03:30.769328 90901 sgd_solver.cpp:106] Iteration 99370, lr = 0.001
I0906 09:03:39.553903 90901 solver.cpp:228] Iteration 99380, loss = 0.0199943
I0906 09:03:39.553989 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0199956 (* 1 = 0.0199956 loss)
I0906 09:03:39.554008 90901 sgd_solver.cpp:106] Iteration 99380, lr = 0.001
I0906 09:03:47.768345 90901 solver.cpp:228] Iteration 99390, loss = 0.0518494
I0906 09:03:47.768430 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0518507 (* 1 = 0.0518507 loss)
I0906 09:03:47.768448 90901 sgd_solver.cpp:106] Iteration 99390, lr = 0.001
I0906 09:03:56.582613 90901 solver.cpp:228] Iteration 99400, loss = 0.11711
I0906 09:03:56.586743 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117111 (* 1 = 0.117111 loss)
I0906 09:03:56.586776 90901 sgd_solver.cpp:106] Iteration 99400, lr = 0.001
I0906 09:04:05.148819 90901 solver.cpp:228] Iteration 99410, loss = 0.199023
I0906 09:04:05.148905 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199024 (* 1 = 0.199024 loss)
I0906 09:04:05.148928 90901 sgd_solver.cpp:106] Iteration 99410, lr = 0.001
I0906 09:04:13.586503 90901 solver.cpp:228] Iteration 99420, loss = 0.0966952
I0906 09:04:13.586594 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0966964 (* 1 = 0.0966964 loss)
I0906 09:04:13.586612 90901 sgd_solver.cpp:106] Iteration 99420, lr = 0.001
I0906 09:04:21.987324 90901 solver.cpp:228] Iteration 99430, loss = 0.28354
I0906 09:04:21.987387 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.283541 (* 1 = 0.283541 loss)
I0906 09:04:21.987406 90901 sgd_solver.cpp:106] Iteration 99430, lr = 0.001
I0906 09:04:30.261891 90901 solver.cpp:228] Iteration 99440, loss = 0.074555
I0906 09:04:30.262089 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0745562 (* 1 = 0.0745562 loss)
I0906 09:04:30.262117 90901 sgd_solver.cpp:106] Iteration 99440, lr = 0.001
I0906 09:04:38.250551 90901 solver.cpp:228] Iteration 99450, loss = 0.0887069
I0906 09:04:38.250658 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0887082 (* 1 = 0.0887082 loss)
I0906 09:04:38.250680 90901 sgd_solver.cpp:106] Iteration 99450, lr = 0.001
I0906 09:04:46.454164 90901 solver.cpp:228] Iteration 99460, loss = 0.0699895
I0906 09:04:46.454237 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0699907 (* 1 = 0.0699907 loss)
I0906 09:04:46.454255 90901 sgd_solver.cpp:106] Iteration 99460, lr = 0.001
I0906 09:04:55.878438 90901 solver.cpp:228] Iteration 99470, loss = 0.226648
I0906 09:04:55.878515 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226649 (* 1 = 0.226649 loss)
I0906 09:04:55.878531 90901 sgd_solver.cpp:106] Iteration 99470, lr = 0.001
I0906 09:05:04.594810 90901 solver.cpp:228] Iteration 99480, loss = 0.120746
I0906 09:05:04.594949 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120747 (* 1 = 0.120747 loss)
I0906 09:05:04.594966 90901 sgd_solver.cpp:106] Iteration 99480, lr = 0.001
I0906 09:05:12.945741 90901 solver.cpp:228] Iteration 99490, loss = 0.0753406
I0906 09:05:12.945864 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0753419 (* 1 = 0.0753419 loss)
I0906 09:05:12.945886 90901 sgd_solver.cpp:106] Iteration 99490, lr = 0.001
I0906 09:05:21.550927 90901 solver.cpp:228] Iteration 99500, loss = 0.347481
I0906 09:05:21.550992 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347483 (* 1 = 0.347483 loss)
I0906 09:05:21.551012 90901 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I0906 09:05:29.908902 90901 solver.cpp:228] Iteration 99510, loss = 0.149803
I0906 09:05:29.908970 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149804 (* 1 = 0.149804 loss)
I0906 09:05:29.908988 90901 sgd_solver.cpp:106] Iteration 99510, lr = 0.001
I0906 09:05:38.263929 90901 solver.cpp:228] Iteration 99520, loss = 0.22734
I0906 09:05:38.270711 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.227341 (* 1 = 0.227341 loss)
I0906 09:05:38.270756 90901 sgd_solver.cpp:106] Iteration 99520, lr = 0.001
I0906 09:05:46.614748 90901 solver.cpp:228] Iteration 99530, loss = 0.156524
I0906 09:05:46.614830 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156525 (* 1 = 0.156525 loss)
I0906 09:05:46.614848 90901 sgd_solver.cpp:106] Iteration 99530, lr = 0.001
I0906 09:05:55.028998 90901 solver.cpp:228] Iteration 99540, loss = 0.325475
I0906 09:05:55.029135 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.325477 (* 1 = 0.325477 loss)
I0906 09:05:55.029160 90901 sgd_solver.cpp:106] Iteration 99540, lr = 0.001
I0906 09:06:03.112429 90901 solver.cpp:228] Iteration 99550, loss = 0.105105
I0906 09:06:03.112498 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105106 (* 1 = 0.105106 loss)
I0906 09:06:03.112514 90901 sgd_solver.cpp:106] Iteration 99550, lr = 0.001
I0906 09:06:11.391813 90901 solver.cpp:228] Iteration 99560, loss = 0.171099
I0906 09:06:11.392027 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1711 (* 1 = 0.1711 loss)
I0906 09:06:11.392052 90901 sgd_solver.cpp:106] Iteration 99560, lr = 0.001
I0906 09:06:19.255306 90901 solver.cpp:228] Iteration 99570, loss = 0.209868
I0906 09:06:19.255399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209869 (* 1 = 0.209869 loss)
I0906 09:06:19.255421 90901 sgd_solver.cpp:106] Iteration 99570, lr = 0.001
I0906 09:06:27.880441 90901 solver.cpp:228] Iteration 99580, loss = 0.312564
I0906 09:06:27.880514 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.312565 (* 1 = 0.312565 loss)
I0906 09:06:27.880532 90901 sgd_solver.cpp:106] Iteration 99580, lr = 0.001
I0906 09:06:36.240525 90901 solver.cpp:228] Iteration 99590, loss = 0.0652222
I0906 09:06:36.240607 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0652235 (* 1 = 0.0652235 loss)
I0906 09:06:36.240623 90901 sgd_solver.cpp:106] Iteration 99590, lr = 0.001
I0906 09:06:44.392869 90901 solver.cpp:228] Iteration 99600, loss = 0.349013
I0906 09:06:44.393129 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.349015 (* 1 = 0.349015 loss)
I0906 09:06:44.393148 90901 sgd_solver.cpp:106] Iteration 99600, lr = 0.001
I0906 09:06:52.715857 90901 solver.cpp:228] Iteration 99610, loss = 0.13761
I0906 09:06:52.715935 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137612 (* 1 = 0.137612 loss)
I0906 09:06:52.715953 90901 sgd_solver.cpp:106] Iteration 99610, lr = 0.001
I0906 09:07:01.392537 90901 solver.cpp:228] Iteration 99620, loss = 0.189294
I0906 09:07:01.392593 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189295 (* 1 = 0.189295 loss)
I0906 09:07:01.392611 90901 sgd_solver.cpp:106] Iteration 99620, lr = 0.001
I0906 09:07:09.199306 90901 solver.cpp:228] Iteration 99630, loss = 0.0418572
I0906 09:07:09.199399 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0418584 (* 1 = 0.0418584 loss)
I0906 09:07:09.199416 90901 sgd_solver.cpp:106] Iteration 99630, lr = 0.001
I0906 09:07:17.527931 90901 solver.cpp:228] Iteration 99640, loss = 0.165563
I0906 09:07:17.528097 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.165564 (* 1 = 0.165564 loss)
I0906 09:07:17.528127 90901 sgd_solver.cpp:106] Iteration 99640, lr = 0.001
I0906 09:07:25.659185 90901 solver.cpp:228] Iteration 99650, loss = 0.276948
I0906 09:07:25.659262 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.276949 (* 1 = 0.276949 loss)
I0906 09:07:25.659279 90901 sgd_solver.cpp:106] Iteration 99650, lr = 0.001
I0906 09:07:33.817921 90901 solver.cpp:228] Iteration 99660, loss = 0.347482
I0906 09:07:33.817986 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.347483 (* 1 = 0.347483 loss)
I0906 09:07:33.818002 90901 sgd_solver.cpp:106] Iteration 99660, lr = 0.001
I0906 09:07:41.754647 90901 solver.cpp:228] Iteration 99670, loss = 0.0664891
I0906 09:07:41.754700 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0664904 (* 1 = 0.0664904 loss)
I0906 09:07:41.754717 90901 sgd_solver.cpp:106] Iteration 99670, lr = 0.001
I0906 09:07:49.912408 90901 solver.cpp:228] Iteration 99680, loss = 0.0794782
I0906 09:07:49.912576 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0794795 (* 1 = 0.0794795 loss)
I0906 09:07:49.912609 90901 sgd_solver.cpp:106] Iteration 99680, lr = 0.001
I0906 09:07:58.131180 90901 solver.cpp:228] Iteration 99690, loss = 0.0881014
I0906 09:07:58.131248 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0881027 (* 1 = 0.0881027 loss)
I0906 09:07:58.131263 90901 sgd_solver.cpp:106] Iteration 99690, lr = 0.001
I0906 09:08:06.218231 90901 solver.cpp:228] Iteration 99700, loss = 0.16398
I0906 09:08:06.218284 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163981 (* 1 = 0.163981 loss)
I0906 09:08:06.218299 90901 sgd_solver.cpp:106] Iteration 99700, lr = 0.001
I0906 09:08:14.623872 90901 solver.cpp:228] Iteration 99710, loss = 0.378486
I0906 09:08:14.623955 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378487 (* 1 = 0.378487 loss)
I0906 09:08:14.623972 90901 sgd_solver.cpp:106] Iteration 99710, lr = 0.001
I0906 09:08:22.580627 90901 solver.cpp:228] Iteration 99720, loss = 0.307324
I0906 09:08:22.580790 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.307325 (* 1 = 0.307325 loss)
I0906 09:08:22.580823 90901 sgd_solver.cpp:106] Iteration 99720, lr = 0.001
I0906 09:08:30.775501 90901 solver.cpp:228] Iteration 99730, loss = 0.04668
I0906 09:08:30.775559 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0466813 (* 1 = 0.0466813 loss)
I0906 09:08:30.775579 90901 sgd_solver.cpp:106] Iteration 99730, lr = 0.001
I0906 09:08:39.161553 90901 solver.cpp:228] Iteration 99740, loss = 0.364344
I0906 09:08:39.161617 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.364346 (* 1 = 0.364346 loss)
I0906 09:08:39.161633 90901 sgd_solver.cpp:106] Iteration 99740, lr = 0.001
I0906 09:08:47.223989 90901 solver.cpp:228] Iteration 99750, loss = 0.0516818
I0906 09:08:47.224063 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.051683 (* 1 = 0.051683 loss)
I0906 09:08:47.224081 90901 sgd_solver.cpp:106] Iteration 99750, lr = 0.001
I0906 09:08:55.589809 90901 solver.cpp:228] Iteration 99760, loss = 0.0794927
I0906 09:08:55.590034 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.079494 (* 1 = 0.079494 loss)
I0906 09:08:55.590054 90901 sgd_solver.cpp:106] Iteration 99760, lr = 0.001
I0906 09:09:03.395977 90901 solver.cpp:228] Iteration 99770, loss = 0.244079
I0906 09:09:03.396070 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.24408 (* 1 = 0.24408 loss)
I0906 09:09:03.396086 90901 sgd_solver.cpp:106] Iteration 99770, lr = 0.001
I0906 09:09:11.510200 90901 solver.cpp:228] Iteration 99780, loss = 0.0217455
I0906 09:09:11.510277 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0217468 (* 1 = 0.0217468 loss)
I0906 09:09:11.510294 90901 sgd_solver.cpp:106] Iteration 99780, lr = 0.001
I0906 09:09:19.692062 90901 solver.cpp:228] Iteration 99790, loss = 0.109386
I0906 09:09:19.692137 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.109388 (* 1 = 0.109388 loss)
I0906 09:09:19.692155 90901 sgd_solver.cpp:106] Iteration 99790, lr = 0.001
I0906 09:09:28.512301 90901 solver.cpp:228] Iteration 99800, loss = 0.17871
I0906 09:09:28.512444 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178712 (* 1 = 0.178712 loss)
I0906 09:09:28.512464 90901 sgd_solver.cpp:106] Iteration 99800, lr = 0.001
I0906 09:09:36.747203 90901 solver.cpp:228] Iteration 99810, loss = 0.0277732
I0906 09:09:36.747295 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0277745 (* 1 = 0.0277745 loss)
I0906 09:09:36.747315 90901 sgd_solver.cpp:106] Iteration 99810, lr = 0.001
I0906 09:09:42.278434 90901 solver.cpp:228] Iteration 99820, loss = 0.14935
I0906 09:09:42.278507 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149351 (* 1 = 0.149351 loss)
I0906 09:09:42.278524 90901 sgd_solver.cpp:106] Iteration 99820, lr = 0.001
I0906 09:09:47.477066 90901 solver.cpp:228] Iteration 99830, loss = 0.155586
I0906 09:09:47.477126 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155588 (* 1 = 0.155588 loss)
I0906 09:09:47.477143 90901 sgd_solver.cpp:106] Iteration 99830, lr = 0.001
I0906 09:09:52.693964 90901 solver.cpp:228] Iteration 99840, loss = 0.0693022
I0906 09:09:52.694031 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0693036 (* 1 = 0.0693036 loss)
I0906 09:09:52.694047 90901 sgd_solver.cpp:106] Iteration 99840, lr = 0.001
I0906 09:09:58.244542 90901 solver.cpp:228] Iteration 99850, loss = 0.0673823
I0906 09:09:58.244616 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0673837 (* 1 = 0.0673837 loss)
I0906 09:09:58.244632 90901 sgd_solver.cpp:106] Iteration 99850, lr = 0.001
I0906 09:10:03.449144 90901 solver.cpp:228] Iteration 99860, loss = 0.163012
I0906 09:10:03.449393 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163013 (* 1 = 0.163013 loss)
I0906 09:10:03.449411 90901 sgd_solver.cpp:106] Iteration 99860, lr = 0.001
I0906 09:10:08.641837 90901 solver.cpp:228] Iteration 99870, loss = 0.225532
I0906 09:10:08.642030 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225534 (* 1 = 0.225534 loss)
I0906 09:10:08.642050 90901 sgd_solver.cpp:106] Iteration 99870, lr = 0.001
I0906 09:10:13.870973 90901 solver.cpp:228] Iteration 99880, loss = 0.282259
I0906 09:10:13.871047 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.28226 (* 1 = 0.28226 loss)
I0906 09:10:13.871063 90901 sgd_solver.cpp:106] Iteration 99880, lr = 0.001
I0906 09:10:19.384033 90901 solver.cpp:228] Iteration 99890, loss = 0.0820498
I0906 09:10:19.384094 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0820512 (* 1 = 0.0820512 loss)
I0906 09:10:19.384110 90901 sgd_solver.cpp:106] Iteration 99890, lr = 0.001
I0906 09:10:24.594004 90901 solver.cpp:228] Iteration 99900, loss = 0.101345
I0906 09:10:24.594085 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.101346 (* 1 = 0.101346 loss)
I0906 09:10:24.594104 90901 sgd_solver.cpp:106] Iteration 99900, lr = 0.001
I0906 09:10:29.809757 90901 solver.cpp:228] Iteration 99910, loss = 0.186183
I0906 09:10:29.809844 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186184 (* 1 = 0.186184 loss)
I0906 09:10:29.809862 90901 sgd_solver.cpp:106] Iteration 99910, lr = 0.001
I0906 09:10:35.568469 90901 solver.cpp:228] Iteration 99920, loss = 0.148132
I0906 09:10:35.568684 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148134 (* 1 = 0.148134 loss)
I0906 09:10:35.568703 90901 sgd_solver.cpp:106] Iteration 99920, lr = 0.001
I0906 09:10:42.568078 90901 solver.cpp:228] Iteration 99930, loss = 0.168602
I0906 09:10:42.568141 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168604 (* 1 = 0.168604 loss)
I0906 09:10:42.568159 90901 sgd_solver.cpp:106] Iteration 99930, lr = 0.001
I0906 09:10:49.346164 90901 solver.cpp:228] Iteration 99940, loss = 0.250786
I0906 09:10:49.346232 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.250787 (* 1 = 0.250787 loss)
I0906 09:10:49.346252 90901 sgd_solver.cpp:106] Iteration 99940, lr = 0.001
I0906 09:10:56.997269 90901 solver.cpp:228] Iteration 99950, loss = 0.142505
I0906 09:10:56.997337 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142506 (* 1 = 0.142506 loss)
I0906 09:10:56.997357 90901 sgd_solver.cpp:106] Iteration 99950, lr = 0.001
I0906 09:11:04.906270 90901 solver.cpp:228] Iteration 99960, loss = 0.660496
I0906 09:11:04.906335 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.660498 (* 1 = 0.660498 loss)
I0906 09:11:04.906355 90901 sgd_solver.cpp:106] Iteration 99960, lr = 0.001
I0906 09:11:12.712735 90901 solver.cpp:228] Iteration 99970, loss = 0.170367
I0906 09:11:12.712909 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170368 (* 1 = 0.170368 loss)
I0906 09:11:12.712939 90901 sgd_solver.cpp:106] Iteration 99970, lr = 0.001
I0906 09:11:20.408615 90901 solver.cpp:228] Iteration 99980, loss = 0.243332
I0906 09:11:20.408686 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243333 (* 1 = 0.243333 loss)
I0906 09:11:20.408704 90901 sgd_solver.cpp:106] Iteration 99980, lr = 0.001
I0906 09:11:28.079390 90901 solver.cpp:228] Iteration 99990, loss = 0.288099
I0906 09:11:28.079454 90901 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.2881 (* 1 = 0.2881 loss)
I0906 09:11:28.079469 90901 sgd_solver.cpp:106] Iteration 99990, lr = 0.001
I0906 09:11:35.455812 90901 solver.cpp:454] Snapshotting to binary proto file _iter_100000.caffemodel
I0906 09:11:35.524453 90901 sgd_solver.cpp:273] Snapshotting solver state to binary proto file _iter_100000.solverstate
I0906 09:11:35.912710 90901 solver.cpp:317] Iteration 100000, loss = 0.268092
I0906 09:11:35.912758 90901 solver.cpp:337] Iteration 100000, Testing net (#0)
I0906 09:12:30.692579 90901 solver.cpp:404]     Test net output #0: Accuracy1 = 0.95
I0906 09:12:30.692714 90901 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.137836 (* 1 = 0.137836 loss)
I0906 09:12:30.692740 90901 solver.cpp:322] Optimization Done.
I0906 09:12:30.692755 90901 caffe.cpp:254] Optimization Done.
